<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri  8 Dec 23  to  Mon 11 Dec 23, announced Tue, 12 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item671">Cross-lists</a></li>
<li><a href="#item739">Replacements</a></li>
</ul>
<small>[ total of 1139 entries:  <b>1-1139</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 12 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05257" title="Abstract">arXiv:2312.05257</a> [<a href="/pdf/2312.05257" title="Download PDF">pdf</a>, <a href="/format/2312.05257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Port Navigation With Ranging Sensors Using Model-Based  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herremans%2C+S">Siemen Herremans</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A">Ali Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Troch%2C+A">Arne Troch</a>, 
<a href="/search/cs?searchtype=author&query=Ravijts%2C+I">Ian Ravijts</a>, 
<a href="/search/cs?searchtype=author&query=Vangeneugden%2C+M">Maarten Vangeneugden</a>, 
<a href="/search/cs?searchtype=author&query=Mercelis%2C+S">Siegfried Mercelis</a>, 
<a href="/search/cs?searchtype=author&query=Hellinckx%2C+P">Peter Hellinckx</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 42nd International Conference on Ocean, Offshore &amp; Arctic Engineering. June 11 - 16, 2023. Melbourne, Australia
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ASME 2023 42nd International Conference on
  Ocean, Offshore and Arctic Engineering. Volume 5: Ocean Engineering.
  Melbourne, Australia. June 11-16, 2023. V005T06A072. ASME
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Autonomous shipping has recently gained much interest in the research
community. However, little research focuses on inland - and port navigation,
even though this is identified by countries such as Belgium and the Netherlands
as an essential step towards a sustainable future. These environments pose
unique challenges, since they can contain dynamic obstacles that do not
broadcast their location, such as small vessels, kayaks or buoys. Therefore,
this research proposes a navigational algorithm which can navigate an inland
vessel in a wide variety of complex port scenarios using ranging sensors to
observe the environment. The proposed methodology is based on a machine
learning approach that has recently set benchmark results in various domains:
model-based reinforcement learning. By randomizing the port environments during
training, the trained model can navigate in scenarios that it never encountered
during training. Furthermore, results show that our approach outperforms the
commonly used dynamic window approach and a benchmark model-free reinforcement
learning algorithm. This work is therefore a significant step towards vessels
that can navigate autonomously in complex port scenarios.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05259" title="Abstract">arXiv:2312.05259</a> [<a href="/pdf/2312.05259" title="Download PDF">pdf</a>, <a href="/ps/2312.05259" title="Download PostScript">ps</a>, <a href="/format/2312.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing the Passenger Flow for Airport Security Check
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chaoyu Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Due to the necessary security for the airport and flight, passengers are
required to have strict security check before getting aboard. However, there
are frequent complaints of wasting huge amount of time while waiting for the
security check. This paper presents a potential solution aimed at optimizing
gate setup procedures specifically tailored for Chicago OHare International
Airport. By referring to queueing theory and performing Monte Carlo
simulations, we propose an approach to significantly diminish the average
waiting time to a more manageable level. Additionally, our study meticulously
examines and identifies the influential factors contributing to this
optimization, providing a comprehensive understanding of their impact.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05262" title="Abstract">arXiv:2312.05262</a> [<a href="/pdf/2312.05262" title="Download PDF">pdf</a>, <a href="/format/2312.05262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Copyright Protection in Buyer-seller Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yusheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+N">Nan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training a deep neural network (DNN) requires a high computational cost.
Buying models from sellers with a large number of computing resources has
become prevailing. However, the buyer-seller environment is not always trusted.
To protect the neural network models from leaking in an untrusted environment,
we propose a novel copyright protection scheme for DNN using an input-sensitive
neural network (ISNN). The main idea of ISNN is to make a DNN sensitive to the
key and copyright information. Therefore, only the buyer with a correct key can
utilize the ISNN. During the training phase, we add a specific perturbation to
the clean images and mark them as legal inputs, while the other inputs are
treated as illegal input. We design a loss function to make the outputs of
legal inputs close to the true ones, while the illegal inputs are far away from
true results. Experimental results demonstrate that the proposed scheme is
effective, valid, and secure.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05264" title="Abstract">arXiv:2312.05264</a> [<a href="/pdf/2312.05264" title="Download PDF">pdf</a>, <a href="/format/2312.05264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All Rivers Run to the Sea: Private Learning with Asymmetric Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yue Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+R+E">Ramy E. Ali</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+S">Saurav Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data privacy is of great concern in cloud machine-learning service platforms,
when sensitive data are exposed to service providers. While private computing
environments (e.g., secure enclaves), and cryptographic approaches (e.g.,
homomorphic encryption) provide strong privacy protection, their computing
performance still falls short compared to cloud GPUs. To achieve privacy
protection with high computing performance, we propose Delta, a new private
training and inference framework, with comparable model performance as
non-private centralized training. Delta features two asymmetric data flows: the
main information-sensitive flow and the residual flow. The main part flows into
a small model while the residuals are offloaded to a large model. Specifically,
Delta embeds the information-sensitive representations into a low-dimensional
space while pushing the information-insensitive part into high-dimension
residuals. To ensure privacy protection, the low-dimensional
information-sensitive part is secured and fed to a small model in a private
environment. On the other hand, the residual part is sent to fast cloud GPUs,
and processed by a large model. To further enhance privacy and reduce the
communication cost, Delta applies a random binary quantization technique along
with a DP-based technique to the residuals before sharing them with the public
platform. We theoretically show that Delta guarantees differential privacy in
the public environment and greatly reduces the complexity in the private
environment. We conduct empirical analyses on CIFAR-10, CIFAR-100 and ImageNet
datasets and ResNet-18 and ResNet-34, showing that Delta achieves strong
privacy protection, fast training, and inference without significantly
compromising the model utility.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05265" title="Abstract">arXiv:2312.05265</a> [<a href="/pdf/2312.05265" title="Download PDF">pdf</a>, <a href="/format/2312.05265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Group Emotion Recognition In-the-wild Using Privacy-Compliant  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Augusma%2C+A">Anderson Augusma</a> (M-PSI, SVH), 
<a href="/search/cs?searchtype=author&query=Vaufreydaz%2C+D">Dominique Vaufreydaz</a> (M-PSI), 
<a href="/search/cs?searchtype=author&query=Letu%C3%A9%2C+F">Fr&#xe9;d&#xe9;rique Letu&#xe9;</a> (SVH)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICMI '23: INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, Oct
  2023, Paris, France. pp.750-754
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper explores privacy-compliant group-level emotion recognition
''in-the-wild'' within the EmotiW Challenge 2023. Group-level emotion
recognition can be useful in many fields including social robotics,
conversational agents, e-coaching and learning analytics. This research imposes
itself using only global features avoiding individual ones, i.e. all features
that can be used to identify or track people in videos (facial landmarks, body
poses, audio diarization, etc.). The proposed multimodal model is composed of a
video and an audio branches with a cross-attention between modalities. The
video branch is based on a fine-tuned ViT architecture. The audio branch
extracts Mel-spectrograms and feed them through CNN blocks into a transformer
encoder. Our training paradigm includes a generated synthetic dataset to
increase the sensitivity of our model on facial expression within the image in
a data-driven way. The extensive experiments show the significance of our
methodology. Our privacy-compliant proposal performs fairly on the EmotiW
challenge, with 79.24% and 75.13% of accuracy respectively on validation and
test set for the best models. Noticeably, our findings highlight that it is
possible to reach this accuracy level with privacy-compliant features using
only 5 frames uniformly distributed on the video.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05269" title="Abstract">arXiv:2312.05269</a> [<a href="/pdf/2312.05269" title="Download PDF">pdf</a>, <a href="/format/2312.05269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LifelongMemory: Leveraging LLMs for Answering Queries in Egocentric  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanlai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengye Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The egocentric video natural language query (NLQ) task involves localizing a
temporal window in an egocentric video that provides an answer to a posed
query, which has wide applications in building personalized AI assistants.
Prior methods for this task have focused on improvements of network
architecture and leveraging pre-training for enhanced image and video features,
but have struggled with capturing long-range temporal dependencies in lengthy
videos, and cumbersome end-to-end training. Motivated by recent advancements in
Large Language Models (LLMs) and vision language models, we introduce
LifelongMemory, a novel framework that utilizes multiple pre-trained models to
answer queries from extensive egocentric video content. We address the unique
challenge by employing a pre-trained captioning model to create detailed
narratives of the videos. These narratives are then used to prompt a frozen LLM
to generate coarse-grained temporal window predictions, which are subsequently
refined using a pre-trained NLQ model. Empirical results demonstrate that our
method achieves competitive performance against existing supervised end-to-end
learning methods, underlining the potential of integrating multiple pre-trained
multimodal large language models in complex vision-language tasks. We provide a
comprehensive analysis of key design decisions and hyperparameters in our
pipeline, offering insights and practical guidelines.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05270" title="Abstract">arXiv:2312.05270</a> [<a href="/pdf/2312.05270" title="Download PDF">pdf</a>, <a href="/format/2312.05270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image and AIS Data Fusion Technique for Maritime Computer Vision  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BClsoylu%2C+E">Emre G&#xfc;lsoylu</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+P">Paul Koch</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+M">Mert Y&#x131;ld&#x131;z</a>, 
<a href="/search/cs?searchtype=author&query=Constapel%2C+M">Manfred Constapel</a>, 
<a href="/search/cs?searchtype=author&query=Kelm%2C+A+P">Andr&#xe9; Peter Kelm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures. Author version of paper. Accepted for publication in The 2nd Workshop on Maritime Computer Vision at WACV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning object detection methods, like YOLOv5, are effective in
identifying maritime vessels but often lack detailed information important for
practical applications. In this paper, we addressed this problem by developing
a technique that fuses Automatic Identification System (AIS) data with vessels
detected in images to create datasets. This fusion enriches ship images with
vessel-related data, such as type, size, speed, and direction. Our approach
associates detected ships to their corresponding AIS messages by estimating
distance and azimuth using a homography-based method suitable for both fixed
and periodically panning cameras. This technique is useful for creating
datasets for waterway traffic management, encounter detection, and
surveillance. We introduce a novel dataset comprising of images taken in
various weather conditions and their corresponding AIS messages. This dataset
offers a stable baseline for refining vessel detection algorithms and
trajectory prediction models. To assess our method's performance, we manually
annotated a portion of this dataset. The results are showing an overall
association accuracy of 74.76 %, with the association accuracy for fixed
cameras reaching 85.06 %. This demonstrates the potential of our approach in
creating datasets for vessel detection, pose estimation and auto-labelling
pipelines.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05272" title="Abstract">arXiv:2312.05272</a> [<a href="/pdf/2312.05272" title="Download PDF">pdf</a>, <a href="/format/2312.05272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableQ: Enhancing Data-Scarce Quantization with Text-to-Image Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Donghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+P">Priyadarshini Panda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Though low-bit quantization enables efficient storage and inference of deep
neural networks, it often requires the use of training data to maintain
resilience against quantization errors. However, training data are frequently
subject to privacy or copyright concerns. In this work, we address the
challenge of Data-Scarce Quantization, where access to training data is
severely limited or non-existent for quantization purposes. Conventional
approaches typically rely on inverting dummy images or jointly training
generative models to produce synthetic input samples. However, these methods
struggle to accurately recreate complex objects in large-scale datasets like
ImageNet. To overcome these limitations, we introduce StableQ, a novel method
that utilizes an advanced text-to-image diffusion model to generate
high-resolution, photo-realistic synthetic data. To verify the quality of the
generated data, we implement two robust filtering mechanisms. These mechanisms
are designed to select images that closely resemble the intrinsic
characteristics of the actual training data. Furthermore, in scenarios where
limited training data are available, we use these data to guide the synthetic
data generation process by inverting a learnable token embedding in the text
encoder. Our extensive experimental results demonstrate that StbaleQ sets a new
benchmark in both zero-shot and few-shot quantization, outperforming existing
methods in terms of accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05274" title="Abstract">arXiv:2312.05274</a> [<a href="/pdf/2312.05274" title="Download PDF">pdf</a>, <a href="/format/2312.05274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target to Source: Guidance-Based Diffusion Model for Test-Time  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hanjiang Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Most recent works of test-time adaptation (TTA) aim to alleviate domain shift
problems by re-training source classifiers in each domain. On the other hand,
the emergence of the diffusion model provides another solution to TTA, which
directly maps the test data from the target domain to the source domain based
on a diffusion model pre-trained in the source domain. The source classifier
does not need to be fine-tuned. However, 1) the semantic information loss from
test data to the source domain and 2) the model shift between the source
classifier and diffusion model would prevent the diffusion model from mapping
the test data back to the source domain correctly. In this paper, we propose a
novel guidance-based diffusion-driven adaptation (GDDA) to overcome the data
shift and let the diffusion model find a better way to go back to the source.
Concretely, we first propose detail and global guidance to better keep the
common semantics of the test and source data. The two guidance include a
contrastive loss and mean squared error to alleviate the information loss by
fully exploring the diffusion model and the test data. Meanwhile, we propose a
classifier-aware guidance to reduce the bias caused by the model shift, which
can incorporate the source classifier's information into the generation process
of the diffusion model. Extensive experiments on three image datasets with
three classifier backbones demonstrate that GDDA significantly performs better
than the state-of-the-art baselines. On CIFAR-10C, CIFAR-100C, and ImageNetC,
GDDA achieves 11.54\%, 19.05\%, and 11.63\% average accuracy improvements,
respectively. GDDA even achieves equal performance compared with methods of
re-training classifiers. The code is available in the supplementary material.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05275" title="Abstract">arXiv:2312.05275</a> [<a href="/pdf/2312.05275" title="Download PDF">pdf</a>, <a href="/format/2312.05275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Limits of ChatGPT in Software Security Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangzhou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bajaj%2C+A+P">Ati Priya Bajaj</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+T">Tiffany Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R+%22">Ruoyu &quot;Fish&quot; Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have undergone rapid evolution and achieved
remarkable results in recent times. OpenAI's ChatGPT, backed by GPT-3.5 or
GPT-4, has gained instant popularity due to its strong capability across a wide
range of tasks, including natural language tasks, coding, mathematics, and
engaging conversations. However, the impacts and limits of such LLMs in system
security domain are less explored. In this paper, we delve into the limits of
LLMs (i.e., ChatGPT) in seven software security applications including
vulnerability detection/repair, debugging, debloating, decompilation, patching,
root cause analysis, symbolic execution, and fuzzing. Our exploration reveals
that ChatGPT not only excels at generating code, which is the conventional
application of language models, but also demonstrates strong capability in
understanding user-provided commands in natural languages, reasoning about
control and data flows within programs, generating complex data structures, and
even decompiling assembly code. Notably, GPT-4 showcases significant
improvements over GPT-3.5 in most security tasks. Also, certain limitations of
ChatGPT in security-related tasks are identified, such as its constrained
ability to process long code contexts.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05276" title="Abstract">arXiv:2312.05276</a> [<a href="/pdf/2312.05276" title="Download PDF">pdf</a>, <a href="/format/2312.05276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Large Language Models Better Knowledge Miners for Online  Marketing with Progressive Prompting Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chunjing Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Nowadays, the rapid development of mobile economy has promoted the
flourishing of online marketing campaigns, whose success greatly hinges on the
efficient matching between user preferences and desired marketing campaigns
where a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG)
could serve as the critical "bridge" for preference propagation. In this paper,
we seek to carefully prompt a Large Language Model (LLM) with domain-level
knowledge as a better marketing-oriented knowledge miner for marketing-oriented
knowledge graph construction, which is however non-trivial, suffering from
several inevitable issues in real-world marketing scenarios, i.e.,
uncontrollable relation generation of LLMs,insufficient prompting ability of a
single prompt, the unaffordable deployment cost of LLMs. To this end, we
propose PAIR, a novel Progressive prompting Augmented mIning fRamework for
harvesting marketing-oriented knowledge graph with LLMs. In particular, we
reduce the pure relation generation to an LLM based adaptive relation filtering
process through the knowledge-empowered prompting technique. Next, we steer
LLMs for entity expansion with progressive prompting augmentation,followed by a
reliable aggregation with comprehensive consideration of both self-consistency
and semantic relatedness. In terms of online serving, we specialize in a small
and white-box PAIR (i.e.,LightPAIR),which is fine-tuned with a high-quality
corpus provided by a strong teacher-LLM. Extensive experiments and practical
applications in audience targeting verify the effectiveness of the proposed
(Light)PAIR.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05277" title="Abstract">arXiv:2312.05277</a> [<a href="/pdf/2312.05277" title="Download PDF">pdf</a>, <a href="/format/2312.05277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yunhao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong-Xing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Liu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Itti%2C+L">Laurent Itti</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project website: <a href="https://gyhandy.github.io/3D-Copy-Paste/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A major challenge in monocular 3D object detection is the limited diversity
and quantity of objects in real datasets. While augmenting real scenes with
virtual objects holds promise to improve both the diversity and quantity of the
objects, it remains elusive due to the lack of an effective 3D object insertion
method in complex real captured scenes. In this work, we study augmenting
complex real indoor scenes with virtual objects for monocular 3D object
detection. The main challenge is to automatically identify plausible physical
properties for virtual assets (e.g., locations, appearances, sizes, etc.) in
cluttered real scenes. To address this challenge, we propose a physically
plausible indoor 3D object insertion approach to automatically copy virtual
objects and paste them into real scenes. The resulting objects in scenes have
3D bounding boxes with plausible physical locations and appearances. In
particular, our method first identifies physically feasible locations and poses
for the inserted objects to prevent collisions with the existing room layout.
Subsequently, it estimates spatially-varying illumination for the insertion
location, enabling the immersive blending of the virtual objects into the
original scene with plausible appearances and cast shadows. We show that our
augmentation method significantly improves existing monocular 3D object models
and achieves state-of-the-art performance. For the first time, we demonstrate
that a physically plausible 3D object insertion, serving as a generative data
augmentation technique, can lead to significant improvements for discriminative
downstream tasks such as monocular 3D object detection. Project website:
https://gyhandy.github.io/3D-Copy-Paste/
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05278" title="Abstract">arXiv:2312.05278</a> [<a href="/pdf/2312.05278" title="Download PDF">pdf</a>, <a href="/format/2312.05278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lyrics: Boosting Fine-grained Language-Vision Alignment and  Comprehension via Semantic-aware Visual Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaojun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Vision Language Models (LVLMs) have demonstrated impressive zero-shot
capabilities in various vision-language dialogue scenarios. However, the
absence of fine-grained visual object detection hinders the model from
understanding the details of images, leading to irreparable visual
hallucinations and factual errors. In this paper, we propose Lyrics, a novel
multi-modal pre-training and instruction fine-tuning paradigm that bootstraps
vision-language alignment from fine-grained cross-modal collaboration. Building
on the foundation of BLIP-2, Lyrics infuses local visual features extracted
from a visual refiner that includes image tagging, object detection and
semantic segmentation modules into the Querying Transformer, while on the text
side, the language inputs equip the boundary boxes and tags derived from the
visual refiner. We further introduce a two-stage training scheme, in which the
pre-training stage bridges the modality gap through explicit and comprehensive
vision-language alignment targets. During the instruction fine-tuning stage, we
introduce semantic-aware visual feature extraction, a crucial method that
enables the model to extract informative features from concrete visual objects.
Our approach achieves strong performance on 13 held-out datasets across various
vision-language tasks, and demonstrates promising multi-modal understanding and
detailed depiction capabilities in real dialogue scenarios.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05281" title="Abstract">arXiv:2312.05281</a> [<a href="/pdf/2312.05281" title="Download PDF">pdf</a>, <a href="/format/2312.05281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X2-Softmax: Margin Adaptive Loss Function for Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiamu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+Y">Yain-Whar Si</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xueyuan Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning the discriminative features of different faces is an important task
in face recognition. By extracting face features in neural networks, it becomes
easy to measure the similarity of different face images, which makes face
recognition possible. To enhance the neural network's face feature
separability, incorporating an angular margin during training is common
practice. State-of-the-art loss functions CosFace and ArcFace apply fixed
margins between weights of classes to enhance the inter-class separation of
face features. Since the distribution of samples in the training set is
imbalanced, similarities between different identities are unequal. Therefore,
using an inappropriately fixed angular margin may lead to the problem that the
model is difficult to converge or the face features are not discriminative
enough. It is more in line with our intuition that the margins are angular
adaptive, which could increase with the angles between classes growing. In this
paper, we propose a new angular margin loss named X2-Softmax. X2-Softmax loss
has adaptive angular margins, which provide the margin that increases with the
angle between different classes growing. The angular adaptive margin ensures
model flexibility and effectively improves the effect of face recognition. We
have trained the neural network with X2-Softmax loss on the MS1Mv3 dataset and
tested it on several evaluation benchmarks to demonstrate the effectiveness and
superiority of our loss function. The experimental code and trained model are
published in https://github.com/xujiamu123/X2-Softmax/tree/main.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05282" title="Abstract">arXiv:2312.05282</a> [<a href="/pdf/2312.05282" title="Download PDF">pdf</a>, <a href="/format/2312.05282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards On-device Learning on the Edge: Ways to Select Neurons to Update  under a Budget Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9lennec%2C+A">A&#xeb;l Qu&#xe9;lennec</a>, 
<a href="/search/cs?searchtype=author&query=Tartaglione%2C+E">Enzo Tartaglione</a>, 
<a href="/search/cs?searchtype=author&query=Mozharovskyi%2C+P">Pavlo Mozharovskyi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Tam Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 2 tables, WACV2024 - SCIoT workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the realm of efficient on-device learning under extreme memory and
computation constraints, a significant gap in successful approaches persists.
Although considerable effort has been devoted to efficient inference, the main
obstacle to efficient learning is the prohibitive cost of backpropagation. The
resources required to compute gradients and update network parameters often
exceed the limits of tightly constrained memory budgets. This paper challenges
conventional wisdom and proposes a series of experiments that reveal the
existence of superior sub-networks. Furthermore, we hint at the potential for
substantial gains through a dynamic neuron selection strategy when fine-tuning
a target task. Our efforts extend to the adaptation of a recent dynamic neuron
selection strategy pioneered by Bragagnolo et al. (NEq), revealing its
effectiveness in the most stringent scenarios. Our experiments demonstrate, in
the average case, the superiority of a NEq-inspired approach over a random
selection. This observation prompts a compelling avenue for further exploration
in the area, highlighting the opportunity to design a new class of algorithms
designed to facilitate parameter update selection. Our findings usher in a new
era of possibilities in the field of on-device learning under extreme
constraints and encourage the pursuit of innovative strategies for efficient,
resource-friendly model fine-tuning.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05283" title="Abstract">arXiv:2312.05283</a> [<a href="/pdf/2312.05283" title="Download PDF">pdf</a>, <a href="/format/2312.05283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nuvo: Neural UV Mapping for Unruly 3D Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+P+P">Pratul P. Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Garbin%2C+S+J">Stephan J. Garbin</a>, 
<a href="/search/cs?searchtype=author&query=Verbin%2C+D">Dor Verbin</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+J+T">Jonathan T. Barron</a>, 
<a href="/search/cs?searchtype=author&query=Mildenhall%2C+B">Ben Mildenhall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://pratulsrinivasan.github.io/nuvo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Existing UV mapping algorithms are designed to operate on well-behaved
meshes, instead of the geometry representations produced by state-of-the-art 3D
reconstruction and generation techniques. As such, applying these methods to
the volume densities recovered by neural radiance fields and related techniques
(or meshes triangulated from such fields) results in texture atlases that are
too fragmented to be useful for tasks such as view synthesis or appearance
editing. We present a UV mapping method designed to operate on geometry
produced by 3D reconstruction and generation techniques. Instead of computing a
mapping defined on a mesh's vertices, our method Nuvo uses a neural field to
represent a continuous UV mapping, and optimizes it to be a valid and
well-behaved mapping for just the set of visible points, i.e. only points that
affect the scene's appearance. We show that our model is robust to the
challenges posed by ill-behaved geometry, and that it produces editable UV
mappings that can represent detailed appearance.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05284" title="Abstract">arXiv:2312.05284</a> [<a href="/pdf/2312.05284" title="Download PDF">pdf</a>, <a href="/format/2312.05284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 0.1% Data Makes Segment Anything Slim
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zigeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gongfan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The formidable model size and demanding computational requirements of Segment
Anything Model (SAM) have rendered it cumbersome for deployment on
resource-constrained devices. Existing approaches for SAM compression typically
involve training a new network from scratch, posing a challenging trade-off
between compression costs and model performance. To address this issue, this
paper introduces SlimSAM, a novel SAM compression method that achieves superior
performance with remarkably low training costs. This is achieved by the
efficient reuse of pre-trained SAMs through a unified pruning-distillation
framework. To enhance knowledge inheritance from the original SAM, we employ an
innovative alternate slimming strategy that partitions the compression process
into a progressive procedure. Diverging from prior pruning techniques, we
meticulously prune and distill decoupled model structures in an alternating
fashion. Furthermore, a novel label-free pruning criterion is also proposed to
align the pruning objective with the optimization target, thereby boosting the
post-distillation after pruning. SlimSAM yields significant performance
improvements while demanding over 10 times less training costs than any other
existing methods. Even when compared to the original SAM-H, SlimSAM achieves
approaching performance while reducing parameter counts to merely 0.9% (5.7M),
MACs to 0.8% (21G), and requiring only 0.1% (10k) of the SAM training data.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05286" title="Abstract">arXiv:2312.05286</a> [<a href="/pdf/2312.05286" title="Download PDF">pdf</a>, <a href="/format/2312.05286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Synthetic and Real Worlds for Pre-training Scene Text Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tongkun Guan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuehui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing scene text detection methods typically rely on extensive real data
for training. Due to the lack of annotated real images, recent works have
attempted to exploit large-scale labeled synthetic data (LSD) for pre-training
text detectors. However, a synth-to-real domain gap emerges, further limiting
the performance of text detectors. Differently, in this work, we propose
\textbf{FreeReal}, a real-domain-aligned pre-training paradigm that enables the
complementary strengths of both LSD and unlabeled real data (URD).
Specifically, to bridge real and synthetic worlds for pre-training, a novel
glyph-based mixing mechanism (GlyphMix) is tailored for text images. GlyphMix
delineates the character structures of synthetic images and embeds them as
graffiti-like units onto real images. Without introducing real domain drift,
GlyphMix freely yields real-world images with annotations derived from
synthetic labels. Furthermore, when given free fine-grained synthetic labels,
GlyphMix can effectively bridge the linguistic domain gap stemming from
English-dominated LSD to URD in various languages. Without bells and whistles,
FreeReal achieves average gains of 4.56\%, 3.85\%, 3.90\%, and 1.97\% in
improving the performance of DBNet, PANet, PSENet, and FCENet methods,
respectively, consistently outperforming previous pre-training methods by a
substantial margin across four public datasets. Code will be released soon.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05287" title="Abstract">arXiv:2312.05287</a> [<a href="/pdf/2312.05287" title="Download PDF">pdf</a>, <a href="/format/2312.05287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human in-the-Loop Estimation of Cluster Count in Datasets via  Similarity-Driven Nested Importance Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez%2C+G">Gustavo Perez</a>, 
<a href="/search/cs?searchtype=author&query=Sheldon%2C+D">Daniel Sheldon</a>, 
<a href="/search/cs?searchtype=author&query=Van+Horn%2C+G">Grant Van Horn</a>, 
<a href="/search/cs?searchtype=author&query=Maji%2C+S">Subhransu Maji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Identifying the number of clusters serves as a preliminary goal for many data
analysis tasks. A common approach to this problem is to vary the number of
clusters in a clustering algorithm (e.g., 'k' in $k$-means) and pick the value
that best explains the data. However, the count estimates can be unreliable
especially when the image similarity is poor. Human feedback on the pairwise
similarity can be used to improve the clustering, but existing approaches do
not guarantee accurate count estimates. We propose an approach to produce
estimates of the cluster counts in a large dataset given an approximate
pairwise similarity. Our framework samples edges guided by the pairwise
similarity, and we collect human feedback to construct a statistical estimate
of the cluster count. On the technical front we have developed a nested
importance sampling approach that yields (asymptotically) unbiased estimates of
the cluster count with confidence intervals which can guide human effort.
Compared to naive sampling, our similarity-driven sampling produces more
accurate estimates of counts and tighter confidence intervals. We evaluate our
method on a benchmark of six fine-grained image classification datasets
achieving low error rates on the estimated number of clusters with
significantly less human labeling effort compared to baselines and alternative
active clustering approaches.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05288" title="Abstract">arXiv:2312.05288</a> [<a href="/pdf/2312.05288" title="Download PDF">pdf</a>, <a href="/format/2312.05288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionCrafter: One-Shot Motion Customization of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nisha Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haibin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weiming Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The essence of a video lies in its dynamic motions, including character
actions, object movements, and camera movements. While text-to-video generative
diffusion models have recently advanced in creating diverse contents,
controlling specific motions through text prompts remains a significant
challenge. A primary issue is the coupling of appearance and motion, often
leading to overfitting on appearance. To tackle this challenge, we introduce
MotionCrafter, a novel one-shot instance-guided motion customization method.
MotionCrafter employs a parallel spatial-temporal architecture that injects the
reference motion into the temporal component of the base model, while the
spatial module is independently adjusted for character or style control. To
enhance the disentanglement of motion and appearance, we propose an innovative
dual-branch motion disentanglement approach, comprising a motion
disentanglement loss and an appearance prior enhancement strategy. During
training, a frozen base model provides appearance normalization, effectively
separating appearance from motion and thereby preserving diversity.
Comprehensive quantitative and qualitative experiments, along with user
preference tests, demonstrate that MotionCrafter can successfully integrate
dynamic motions while preserving the coherence and quality of the base model
with a wide range of appearance generation capabilities. Codes are available at
https://github.com/zyxElsa/MotionCrafter.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05289" title="Abstract">arXiv:2312.05289</a> [<a href="/pdf/2312.05289" title="Download PDF">pdf</a>, <a href="/format/2312.05289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reddiment: Eine SvelteKit- und ElasticSearch-basierte Reddit  Sentiment-Analyse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+T">Tobias Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Beer%2C+F">Fabian Beer</a>, 
<a href="/search/cs?searchtype=author&query=Holl%2C+D">Daniel Holl</a>, 
<a href="/search/cs?searchtype=author&query=Imeraj%2C+A">Ardian Imeraj</a>, 
<a href="/search/cs?searchtype=author&query=Schweiger%2C+K">Konrad Schweiger</a>, 
<a href="/search/cs?searchtype=author&query=Stangl%2C+P">Philipp Stangl</a>, 
<a href="/search/cs?searchtype=author&query=Weigl%2C+W">Wolfgang Weigl</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+C+P">Christoph P. Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ostbayerische Technische Hochschule Amberg-Weiden, CyberLytics-Lab, Technical Reports, CL-2022-06, July 2022, in German language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Reddiment is a web-based dashboard that links sentiment analysis of subreddit
texts with share prices. The system consists of a backend, frontend and various
services. The backend, in Node.js, manages the data and communicates with
crawlers that collect Reddit comments and stock market data. Sentiment is
analyzed with the help of Vader and TextBlob. The frontend, based on SvelteKit,
provides users with a dashboard for visualization. The distribution is carried
out via Docker containers and Docker Compose. The project offers expansion
options, e.g. the integration of cryptocurrency rates. Reddiment enables the
analysis of sentiment and share prices from subreddit data.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05290" title="Abstract">arXiv:2312.05290</a> [<a href="/pdf/2312.05290" title="Download PDF">pdf</a>, <a href="/format/2312.05290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Adaptor in Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+B">Bipin Rajendran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent strides in low-latency spiking neural network (SNN) algorithms have
drawn significant interest, particularly due to their event-driven computing
nature and fast inference capability. One of the most efficient ways to
construct a low-latency SNN is by converting a pre-trained, low-bit artificial
neural network (ANN) into an SNN. However, this conversion process faces two
main challenges: First, converting SNNs from low-bit ANNs can lead to
``occasional noise" -- the phenomenon where occasional spikes are generated in
spiking neurons where they should not be -- during inference, which
significantly lowers SNN accuracy. Second, although low-latency SNNs initially
show fast improvements in accuracy with time steps, these accuracy growths soon
plateau, resulting in their peak accuracy lagging behind both full-precision
ANNs and traditional ``long-latency SNNs'' that prioritize precision over
speed.
<br />In response to these two challenges, this paper introduces a novel technique
named ``noise adaptor.'' Noise adaptor can model occasional noise during
training and implicitly optimize SNN accuracy, particularly at high simulation
times $T$. Our research utilizes the ResNet model for a comprehensive analysis
of the impact of the noise adaptor on low-latency SNNs. The results demonstrate
that our method outperforms the previously reported quant-ANN-to-SNN conversion
technique. We achieved an accuracy of 95.95\% within 4 time steps on CIFAR-10
using ResNet-18, and an accuracy of 74.37\% within 64 time steps on ImageNet
using ResNet-50. Remarkably, these results were obtained without resorting to
any noise correction methods during SNN inference, such as negative spikes or
two-stage SNN simulations. Our approach significantly boosts the peak accuracy
of low-latency SNNs, bringing them on par with the accuracy of full-precision
ANNs. Code will be open source.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05291" title="Abstract">arXiv:2312.05291</a> [<a href="/pdf/2312.05291" title="Download PDF">pdf</a>, <a href="/format/2312.05291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlitchBench: Can large multimodal models detect video game glitches?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taesiri%2C+M+R">Mohammad Reza Taesiri</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tianjun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bezemer%2C+C">Cor-Paul Bezemer</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large multimodal models (LMMs) have evolved from large language models (LLMs)
to integrate multiple input modalities, such as visual inputs. This integration
augments the capacity of LLMs for tasks requiring visual comprehension and
reasoning. However, the extent and limitations of their enhanced abilities are
not fully understood, especially when it comes to real-world tasks. To address
this gap, we introduce GlitchBench, a novel benchmark derived from video game
quality assurance tasks, to test and evaluate the reasoning capabilities of
LMMs. Our benchmark is curated from a variety of unusual and glitched scenarios
from video games and aims to challenge both the visual and linguistic reasoning
powers of LMMs in detecting and interpreting out-of-the-ordinary events. We
evaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents
a new challenge for these models. Code and data are available at:
https://glitchbench.github.io/
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05295" title="Abstract">arXiv:2312.05295</a> [<a href="/pdf/2312.05295" title="Download PDF">pdf</a>, <a href="/format/2312.05295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Clothed Avatar Generation from Text Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jionghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yongqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Rong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Li Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://shanemankiw.github.io/SO-SMPL/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduced a novel text-to-avatar generation method that
separately generates the human body and the clothes and allows high-quality
animation on the generated avatar. While recent advancements in text-to-avatar
generation have yielded diverse human avatars from text prompts, these methods
typically combine all elements-clothes, hair, and body-into a single 3D
representation. Such an entangled approach poses challenges for downstream
tasks like editing or animation. To overcome these limitations, we propose a
novel disentangled 3D avatar representation named Sequentially Offset-SMPL
(SO-SMPL), building upon the SMPL model. SO-SMPL represents the human body and
clothes with two separate meshes, but associates them with offsets to ensure
the physical alignment between the body and the clothes. Then, we design an
Score Distillation Sampling(SDS)-based distillation framework to generate the
proposed SO-SMPL representation from text prompts. In comparison with existing
text-to-avatar methods, our approach not only achieves higher exture and
geometry quality and better semantic alignment with text prompts, but also
significantly improves the visual quality of character animation, virtual
try-on, and avatar editing. Our project page is at
https://shanemankiw.github.io/SO-SMPL/.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05296" title="Abstract">arXiv:2312.05296</a> [<a href="/pdf/2312.05296" title="Download PDF">pdf</a>, <a href="/ps/2312.05296" title="Download PostScript">ps</a>, <a href="/format/2312.05296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Competitions and Benchmarks: The life cycle of challenges and  benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stolovitzky%2C+G">Gustavo Stolovitzky</a>, 
<a href="/search/cs?searchtype=author&query=Saez-Rodriguez%2C+J">Julio Saez-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Bletz%2C+J">Julie Bletz</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+J">Jacob Albrecht</a>, 
<a href="/search/cs?searchtype=author&query=Andreoletti%2C+G">Gaia Andreoletti</a>, 
<a href="/search/cs?searchtype=author&query=Costello%2C+J+C">James C. Costello</a>, 
<a href="/search/cs?searchtype=author&query=Boutros%2C+P">Paul Boutros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data Science research is undergoing a revolution fueled by the transformative
power of technology, the Internet, and an ever increasing computational
capacity. The rate at which sophisticated algorithms can be developed is
unprecedented, yet they remain outpaced by the massive amounts of data that are
increasingly available to researchers. Here we argue for the need to creatively
leverage the scientific research and algorithm development community as an axis
of robust innovation. Engaging these communities in the scientific discovery
enterprise by critical assessments, community experiments, and/or crowdsourcing
will multiply opportunities to develop new data driven, reproducible and well
benchmarked algorithmic solutions to fundamental and applied problems of
current interest. Coordinated community engagement in the analysis of highly
complex and massive data has emerged as one approach to find robust
methodologies that best address these challenges. When community engagement is
done in the form of competitions, also known as challenges, the validation of
the analytical methodology is inherently addressed, establishing performance
benchmarks. Finally, challenges foster open innovation across multiple
disciplines to create communities that collaborate directly or indirectly to
address significant scientific gaps. Together, participants can solve important
problems as varied as health research, climate change, and social equity.
Ultimately, challenges can catalyze and accelerate the synthesis of complex
data into knowledge or actionable information, and should be viewed a powerful
tool to make lasting social and research contributions.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05299" title="Abstract">arXiv:2312.05299</a> [<a href="/pdf/2312.05299" title="Download PDF">pdf</a>, <a href="/format/2312.05299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to be Simple
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yang-Hui He</a>, 
<a href="/search/cs?searchtype=author&query=Jejjala%2C+V">Vishnu Jejjala</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+C">Challenger Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Sharnoff%2C+M">Max Sharnoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Physics - Theory (hep-th); Mathematical Physics (math-ph); Group Theory (math.GR)

</div>
<p class="mathjax">In this work we employ machine learning to understand structured mathematical
data involving finite groups and derive a theorem about necessary properties of
generators of finite simple groups. We create a database of all 2-generated
subgroups of the symmetric group on n-objects and conduct a classification of
finite simple groups among them using shallow feed-forward neural networks. We
show that this neural network classifier can decipher the property of
simplicity with varying accuracies depending on the features. Our neural
network model leads to a natural conjecture concerning the generators of a
finite simple group. We subsequently prove this conjecture. This new toy
theorem comments on the necessary properties of generators of finite simple
groups. We show this explicitly for a class of sporadic groups for which the
result holds. Our work further makes the case for a machine motivated study of
algebraic structures in pure mathematics and highlights the possibility of
generating new conjectures and theorems in mathematics with the aid of machine
learning.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05311" title="Abstract">arXiv:2312.05311</a> [<a href="/pdf/2312.05311" title="Download PDF">pdf</a>, <a href="/format/2312.05311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360&#xb0; Volumetric Portrait Avatar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nehvi%2C+J">Jalees Nehvi</a>, 
<a href="/search/cs?searchtype=author&query=Kabadayi%2C+B">Berna Kabadayi</a>, 
<a href="/search/cs?searchtype=author&query=Valentin%2C+J">Julien Valentin</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jalees018.github.io/3VP-Avatar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose 360{\deg} Volumetric Portrait (3VP) Avatar, a novel method for
reconstructing 360{\deg} photo-realistic portrait avatars of human subjects
solely based on monocular video inputs. State-of-the-art monocular avatar
reconstruction methods rely on stable facial performance capturing. However,
the common usage of 3DMM-based facial tracking has its limits; side-views can
hardly be captured and it fails, especially, for back-views, as required inputs
like facial landmarks or human parsing masks are missing. This results in
incomplete avatar reconstructions that only cover the frontal hemisphere. In
contrast to this, we propose a template-based tracking of the torso, head and
facial expressions which allows us to cover the appearance of a human subject
from all sides. Thus, given a sequence of a subject that is rotating in front
of a single camera, we train a neural volumetric representation based on neural
radiance fields. A key challenge to construct this representation is the
modeling of appearance changes, especially, in the mouth region (i.e., lips and
teeth). We, therefore, propose a deformation-field-based blend basis which
allows us to interpolate between different appearance states. We evaluate our
approach on captured real-world data and compare against state-of-the-art
monocular reconstruction methods. In contrast to those, our method is the first
monocular technique that reconstructs an entire 360{\deg} avatar.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05322" title="Abstract">arXiv:2312.05322</a> [<a href="/pdf/2312.05322" title="Download PDF">pdf</a>, <a href="/format/2312.05322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enforcing conserved quantities in Galerkin truncation and finite volume  discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hilliard%2C+Z+T">Zachary T. Hilliard</a>, 
<a href="/search/math?searchtype=author&query=Farazmand%2C+M">Mohammad Farazmand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Finite-dimensional truncations are routinely used to approximate partial
differential equations (PDEs), either to obtain numerical solutions or to
derive reduced-order models. The resulting discretized equations are known to
violate certain physical properties of the system. In particular, first
integrals of the PDE may not remain invariant after discretization. Here, we
use the method of reduced-order nonlinear solutions (RONS) to ensure that the
conserved quantities of the PDE survive its finite-dimensional truncation. In
particular, we develop two methods: Galerkin RONS and finite volume RONS.
Galerkin RONS ensures the conservation of first integrals in Galerkin-type
truncations, whether used for direct numerical simulations or reduced-order
modeling. Similarly, finite volume RONS conserves any number of first integrals
of the system, including its total energy, after finite volume discretization.
Both methods are applicable to general time-dependent PDEs and can be easily
incorporated in existing Galerkin-type or finite volume code. We demonstrate
the efficacy of our methods on two examples: direct numerical simulations of
the shallow water equation and a reduced-order model of the nonlinear
Schrodinger equation. As a byproduct, we also generalize RONS to phenomena
described by a system of PDEs.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05323" title="Abstract">arXiv:2312.05323</a> [<a href="/pdf/2312.05323" title="Download PDF">pdf</a>, <a href="/format/2312.05323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BaRiFlex: A Robotic Gripper with Versatility and Collision Robustness  for Robot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+G">Gu-Cheol Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Bahety%2C+A">Arpit Bahety</a>, 
<a href="/search/cs?searchtype=author&query=Pedraza%2C+G">Gabriel Pedraza</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A+D">Ashish D. Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Mart%C3%ADn%2C+R">Roberto Mart&#xed;n-Mart&#xed;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, project website: <a href="https://robin-lab.cs.utexas.edu/bariflex/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a new approach to robot hand design specifically suited for
successfully implementing robot learning methods to accomplish tasks in daily
human environments. We introduce BaRiFlex, an innovative gripper design that
alleviates the issues caused by unexpected contact and collisions during robot
learning, offering robustness, grasping versatility, task versatility, and
simplicity to the learning processes. This achievement is enabled by the
incorporation of low-inertia actuators, providing high Back-drivability, and
the strategic combination of Rigid and Flexible materials which enhances
versatility and the gripper's resilience against unpredicted collisions.
Furthermore, the integration of flexible Fin-Ray linkages and rigid linkages
allows the gripper to execute compliant grasping and precise pinching. We
conducted rigorous performance tests to characterize the novel gripper's
compliance, durability, grasping and task versatility, and precision. We also
integrated the BaRiFlex with a 7 Degree of Freedom (DoF) Franka Emika's Panda
robotic arm to evaluate its capacity to support a trial-and-error
(reinforcement learning) training procedure. The results of our experimental
study are then compared to those obtained using the original rigid Franka Hand
and a reference Fin-Ray soft gripper, demonstrating the superior capabilities
and advantages of our developed gripper system.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05325" title="Abstract">arXiv:2312.05325</a> [<a href="/pdf/2312.05325" title="Download PDF">pdf</a>, <a href="/format/2312.05325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Behaviors of Mixed Traffic via Reinforcement Learning at  Unsignalized Intersections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarker%2C+S">Supriya Sarker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this report, we delve into two critical research inquiries. Firstly, we
explore the extent to which Reinforcement Learning (RL) agents exhibit
multimodal distributions in the context of stop-and-go traffic scenarios.
Secondly, we investigate how RL-controlled Robot Vehicles (RVs) effectively
navigate their direction and coordinate with other vehicles in complex traffic
environments. Our analysis encompasses an examination of multimodality within
queue length, outflow, and platoon size distributions for both Robot and
Human-driven Vehicles (HVs). Additionally, we assess the Pearson coefficient
correlation, shedding light on relationships between queue length and outflow,
considering both identical and differing travel directions. Furthermore, we
delve into causal inference models, shedding light on the factors influencing
queue length across scenarios involving varying travel directions. Through
these investigations, this report contributes valuable insights into the
behaviors of mixed traffic (RVs and HVs) in traffic management and
coordination.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05327" title="Abstract">arXiv:2312.05327</a> [<a href="/pdf/2312.05327" title="Download PDF">pdf</a>, <a href="/format/2312.05327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Centric Machine Learning for Geospatial Remote Sensing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roscher%2C+R">Ribana Roscher</a>, 
<a href="/search/cs?searchtype=author&query=Ru%C3%9Fwurm%2C+M">Marc Ru&#xdf;wurm</a>, 
<a href="/search/cs?searchtype=author&query=Gevaert%2C+C">Caroline Gevaert</a>, 
<a href="/search/cs?searchtype=author&query=Kampffmeyer%2C+M">Michael Kampffmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+J+A+d">Jefersson A. dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Vakalopoulou%2C+M">Maria Vakalopoulou</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4nsch%2C+R">Ronny H&#xe4;nsch</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+S">Stine Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+K">Keiller Nogueira</a>, 
<a href="/search/cs?searchtype=author&query=Prexl%2C+J">Jonathan Prexl</a>, 
<a href="/search/cs?searchtype=author&query=Tuia%2C+D">Devis Tuia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent developments and research in modern machine learning have led to
substantial improvements in the geospatial field. Although numerous deep
learning models have been proposed, the majority of them have been developed on
benchmark datasets that lack strong real-world relevance. Furthermore, the
performance of many methods has already saturated on these datasets. We argue
that shifting the focus towards a complementary data-centric perspective is
necessary to achieve further improvements in accuracy, generalization ability,
and real impact in end-user applications. This work presents a definition and
precise categorization of automated data-centric learning approaches for
geospatial data. It highlights the complementary role of data-centric learning
with respect to model-centric in the larger machine learning deployment cycle.
We review papers across the entire geospatial field and categorize them into
different groups. A set of representative experiments shows concrete
implementation examples. These examples provide concrete steps to act on
geospatial data with data-centric machine learning approaches.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05328" title="Abstract">arXiv:2312.05328</a> [<a href="/pdf/2312.05328" title="Download PDF">pdf</a>, <a href="/format/2312.05328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bad Students Make Great Teachers:Active Learning Accelerates Large-Scale  Visual Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evans%2C+T">Talfan Evans</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+S">Shreya Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Merzic%2C+H">Hamza Merzic</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+J">Jonathan Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Tanno%2C+R">Ryutaro Tanno</a>, 
<a href="/search/cs?searchtype=author&query=Henaff%2C+O+J">Olivier J. Henaff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We propose a method for accelerating large-scale pre-training with online
data selection policies. For the first time, we demonstrate that model-based
data selection can reduce the total computation needed to reach the performance
of models trained with uniform sampling. The key insight which enables this
"compute-positive" regime is that small models provide good proxies for the
loss of much larger models, such that computation spent on scoring data can be
drastically scaled down without diminishing the efficiency gains afforded to
the learner. These data selection policies also strongly generalize across
datasets and tasks, opening an avenue for further amortizing the overhead of
data scoring by re-using off-the-shelf models and training sequences. Our
methods, ClassAct and ActiveCLIP, require 46% and 51% fewer training updates
and up to 25% less total computation when training visual classifiers on JFT
and multimodal models on ALIGN, respectively. Finally, our paradigm seamlessly
applies to the curation of large-scale image-text datasets, yielding a new
state-of-the-art in several multimodal transfer tasks and pre-training regimes.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05330" title="Abstract">arXiv:2312.05330</a> [<a href="/pdf/2312.05330" title="Download PDF">pdf</a>, <a href="/ps/2312.05330" title="Download PostScript">ps</a>, <a href="/format/2312.05330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Inversion for 3D-aware Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barthel%2C+F">Florian Barthel</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current 3D GAN inversion methods for human heads typically use only one
single frontal image to reconstruct the whole 3D head model. This leaves out
meaningful information when multi-view data or dynamic videos are available.
Our method builds on existing state-of-the-art 3D GAN inversion techniques to
allow for consistent and simultaneous inversion of multiple views of the same
subject. We employ a multi-latent extension to handle inconsistencies present
in dynamic face videos to re-synthesize consistent 3D representations from the
sequence. As our method uses additional information about the target subject,
we observe significant enhancements in both geometric accuracy and image
quality, particularly when rendering from wide viewing angles. Moreover, we
demonstrate the editability of our inverted 3D renderings, which distinguishes
them from NeRF-based scene reconstructions.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05332" title="Abstract">arXiv:2312.05332</a> [<a href="/pdf/2312.05332" title="Download PDF">pdf</a>, <a href="/format/2312.05332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming  Controllers Inspired by Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yiwen Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zishuo Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yihan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+N">Na Li</a>, 
<a href="/search/eess?searchtype=author&query=Mo%2C+Y">Yilin Mo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we introduce a new class of parameterized controllers, drawing
inspiration from Model Predictive Control (MPC). These controllers adopt a
Quadratic Programming (QP) structure similar to linear MPC, with problem
parameters being learned rather than derived from models. This approach may
address the limitations of commonly learned controllers with Multi-Layer
Perceptron (MLP) architecture in deep reinforcement learning, in terms of
explainability and performance guarantees.
<br />The learned controllers not only possess verifiable properties like
persistent feasibility and asymptotic stability akin to MPC, but they also
empirically match MPC and MLP controllers in control performance. Moreover,
they are more computationally efficient in implementation compared to MPC and
require significantly fewer learnable policy parameters than MLP controllers.
<br />Practical application is demonstrated through a vehicle drift maneuvering
task, showcasing the potential of these controllers in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05333" title="Abstract">arXiv:2312.05333</a> [<a href="/pdf/2312.05333" title="Download PDF">pdf</a>, <a href="/format/2312.05333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Framework for Improving Public EV Charging Infrastructure:  Modeling and Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Dahabreh%2C+N">Nassr Al-Dahabreh</a>, 
<a href="/search/cs?searchtype=author&query=Sayed%2C+M+A">Mohammad Ali Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Sarieddine%2C+K">Khaled Sarieddine</a>, 
<a href="/search/cs?searchtype=author&query=Elhattab%2C+M">Mohamed Elhattab</a>, 
<a href="/search/cs?searchtype=author&query=Khabbaz%2C+M">Maurice Khabbaz</a>, 
<a href="/search/cs?searchtype=author&query=Atallah%2C+R">Ribal Atallah</a>, 
<a href="/search/cs?searchtype=author&query=Assi%2C+C">Chadi Assi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Publication in IEEE Transactions on Intelligent Transportation Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work presents an investigation and assessment framework, which,
supported by realistic data, aims at provisioning operators with in-depth
insights into the consumer-perceived Quality-of-Experience (QoE) at public
Electric Vehicle (EV) charging infrastructures. Motivated by the unprecedented
EV market growth, it is suspected that the existing charging infrastructure
will soon be no longer capable of sustaining the rapidly growing charging
demands; let alone that the currently adopted ad hoc infrastructure expansion
strategies seem to be far from contributing any quality service sustainability
solutions that tangibly reduce (ultimately mitigate) the severity of this
problem. Without suitable QoE metrics, operators, today, face remarkable
difficulty in assessing the performance of EV Charging Stations (EVCSs) in this
regard. This paper aims at filling this gap through the formulation of novel
and original critical QoE performance metrics that provide operators with
visibility into the per-EVCS operational dynamics and allow for the
optimization of these stations' respective utilization. Such metrics shall then
be used as inputs to a Machine Learning model finely tailored and trained using
recent real-world data sets for the purpose of forecasting future long-term
EVCS loads. This will, in turn, allow for making informed optimal EV charging
infrastructure expansions that will be capable of reliably coping with the
rising EV charging demands and maintaining acceptable QoE levels. The model's
accuracy has been tested and extensive simulations are conducted to evaluate
the achieved performance in terms of the above listed metrics and show the
suitability of the recommended infrastructure expansions.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05337" title="Abstract">arXiv:2312.05337</a> [<a href="/pdf/2312.05337" title="Download PDF">pdf</a>, <a href="/format/2312.05337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Neural Nets and the Representation of Human Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freiesleben%2C+T">Timo Freiesleben</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For: Philosophy of Science for Machine Learning: Core Issues and New Perspectives, edited by Juan Duran and Giorgia Pozzi
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">What do artificial neural networks (ANNs) learn? The machine learning (ML)
community shares the narrative that ANNs must develop abstract human concepts
to perform complex tasks. Some go even further and believe that these concepts
are stored in individual units of the network. Based on current research, I
systematically investigate the assumptions underlying this narrative. I
conclude that ANNs are indeed capable of performing complex prediction tasks,
and that they may learn human and non-human concepts to do so. However,
evidence indicates that ANNs do not represent these concepts in individual
units.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05338" title="Abstract">arXiv:2312.05338</a> [<a href="/pdf/2312.05338" title="Download PDF">pdf</a>, <a href="/format/2312.05338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Robot Digging Times to Retrieve Bins in Robotic-Based Compact  Storage and Retrieval Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+A">Anni Yue</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S+L">Stephen L. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 16 figures, submitted to Transportation Science (INFORMS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Robotic-based compact storage and retrieval systems provide high-density
storage in distribution center and warehouse applications. In the system, items
are stored in bins, and the bins are organized inside a three-dimensional grid.
Robots move on top of the grid to retrieve and deliver bins. To retrieve a bin,
a robot removes all bins above one by one with its gripper, called bin digging.
The closer the target bin is to the top of the grid, the less digging is
required to retrieve the bin. In this paper, we propose a policy to optimally
arrange the bins in the grid while processing bin requests so that the most
frequently accessed bins remain near the top of the grid. This improves the
performance of the system and makes it responsive to changes in bin demand. Our
solution approach identifies the optimal bin arrangement in the storage
facility, initiates a transition to this optimal set-up, and subsequently
ensures the ongoing maintenance of this arrangement for optimal performance. We
perform extensive simulations on a custom-built discrete event model of the
system. Our simulation results show that under the proposed policy more than
half of the bins requested are located on top of the grid, reducing bin digging
compared to existing policies. Compared to existing approaches, the proposed
policy reduces the retrieval time of the requested bins by over 30% and the
number of bin requests that exceed certain time thresholds by nearly 50%.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05348" title="Abstract">arXiv:2312.05348</a> [<a href="/pdf/2312.05348" title="Download PDF">pdf</a>, <a href="/ps/2312.05348" title="Download PostScript">ps</a>, <a href="/format/2312.05348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Quality Live Video Streaming via Transcoding Time Prediction and  Preset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahre-Babak%2C+Z+N">Zahra Nabizadeh Shahre-Babak</a>, 
<a href="/search/cs?searchtype=author&query=Karimi%2C+N">Nader Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Rapaka%2C+K">Krishna Rapaka</a>, 
<a href="/search/cs?searchtype=author&query=Amara%2C+T">Tarek Amara</a>, 
<a href="/search/cs?searchtype=author&query=Samavi%2C+S">Shadrokh Samavi</a>, 
<a href="/search/cs?searchtype=author&query=Shirani%2C+S">Shahram Shirani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Video streaming often requires transcoding content into different resolutions
and bitrates to match the recipient's internet speed and screen capabilities.
Video encoders like x264 offer various presets, each with different tradeoffs
between transcoding time and rate-distortion performance. Choosing the best
preset for video transcoding is difficult, especially for live streaming, as
trying all the presets and choosing the best one is not feasible. One solution
is to predict each preset's transcoding time and select the preset that ensures
the highest quality while adhering to live streaming time constraints.
Prediction of video transcoding time is also critical in minimizing streaming
delays, deploying resource management algorithms, and load balancing. We
propose a learning-based framework for predicting the transcoding time of
videos across various presets. Our predictor's features for video transcoding
time prediction are derived directly from the ingested stream, primarily from
the header or metadata. As a result, only minimal additional delay is incurred
for feature extraction, rendering our approach ideal for live-streaming
applications. We evaluated our learning-based transcoding time prediction using
a dataset of videos. The results demonstrate that our framework can accurately
predict the transcoding time for different presets, with a mean absolute
percentage error (MAPE) of nearly 5.0%. Leveraging these predictions, we then
select the most suitable transcoding preset for live video streaming. Utilizing
our transcoding time prediction-based preset selection improved Peak
Signal-to-Noise Ratio (PSNR) of up to 5 dB.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05349" title="Abstract">arXiv:2312.05349</a> [<a href="/pdf/2312.05349" title="Download PDF">pdf</a>, <a href="/format/2312.05349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PixLore: A Dataset-driven Approach to Rich Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonilla%2C+D">Diego Bonilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper in preprint waiting for publishing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the domain of vision-language integration, generating detailed image
captions poses a significant challenge due to the lack of a curated and rich
dataset. This study introduces PixLore, a novel method that leverages Querying
Transformers through the fine-tuning of the BLIP-2 model using the LoRa method
on a standard commercial GPU. Our approach, which involves training on a
carefully assembled dataset from state-of-the-art Computer Vision models
combined and augmented by ChatGPT, addresses the question of whether intricate
image understanding can be achieved with an ensemble of smaller-scale models.
Comparative evaluations against major models such as GPT-4 and Google Bard
demonstrate that PixLore-2.7B, despite having considerably fewer parameters, is
rated higher than the existing State-of-the-Art models in over half of the
assessments. This research not only presents a groundbreaking approach but also
highlights the importance of well-curated datasets in enhancing the performance
of smaller models.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05352" title="Abstract">arXiv:2312.05352</a> [<a href="/pdf/2312.05352" title="Download PDF">pdf</a>, <a href="/format/2312.05352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Machine Learning Methods Applied to Video Analysis Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pattichis%2C+M+S">Marios S. Pattichis</a>, 
<a href="/search/cs?searchtype=author&query=Jatla%2C+V">Venkatesh Jatla</a>, 
<a href="/search/cs?searchtype=author&query=Cerna%2C+A+E+U">Alvaro E. Ullao Cerna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The paper provides a survey of the development of machine-learning techniques
for video analysis. The survey provides a summary of the most popular deep
learning methods used for human activity recognition. We discuss how popular
architectures perform on standard datasets and highlight the differences from
real-life datasets dominated by multiple activities performed by multiple
participants over long periods. For real-life datasets, we describe the use of
low-parameter models (with 200X or 1,000X fewer parameters) that are trained to
detect a single activity after the relevant objects have been successfully
detected. Our survey then turns to a summary of machine learning methods that
are specifically developed for working with a small number of labeled video
samples. Our goal here is to describe modern techniques that are specifically
designed so as to minimize the amount of ground truth that is needed for
training and testing video analysis systems. We provide summaries of the
development of self-supervised learning, semi-supervised learning, active
learning, and zero-shot learning for applications in video analysis. For each
method, we provide representative examples.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05355" title="Abstract">arXiv:2312.05355</a> [<a href="/pdf/2312.05355" title="Download PDF">pdf</a>, <a href="/ps/2312.05355" title="Download PostScript">ps</a>, <a href="/format/2312.05355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neither hype nor gloom do DNNs justice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wichmann%2C+F+A">Felix A. Wichmann</a>, 
<a href="/search/cs?searchtype=author&query=Kornblith%2C+S">Simon Kornblith</a>, 
<a href="/search/cs?searchtype=author&query=Geirhos%2C+R">Robert Geirhos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version of a commentary published by Behavioral and Brain Sciences (<a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/neither-hype-nor-gloom-do-dnns-justice/639AA5BC7F6E3B91E9B9EC8463D39F77">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Neither the hype exemplified in some exaggerated claims about deep neural
networks (DNNs), nor the gloom expressed by Bowers et al. do DNNs as models in
vision science justice: DNNs rapidly evolve, and today's limitations are often
tomorrow's successes. In addition, providing explanations as well as prediction
and image-computability are model desiderata; one should not be favoured at the
expense of the other.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05356" title="Abstract">arXiv:2312.05356</a> [<a href="/pdf/2312.05356" title="Download PDF">pdf</a>, <a href="/format/2312.05356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Aleti%2C+A">Aldeida Aleti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 6 tables, under peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models are successfully adopted in software engineering,
especially in code generation. Updating these models with new knowledge is very
expensive, and is often required to fully realize their value. In this paper,
we propose a novel and effective model editing approach, \textsc{MENT}, to
patch LLMs in coding tasks. Based on the mechanism of generative LLMs,
\textsc{MENT} enables model editing in next-token predictions, and further
supports common coding tasks. \textsc{MENT} is effective, efficient, and
reliable. It can correct a neural model by patching 1 or 2 neurons. As the
pioneer work on neuron-level model editing of generative models, we formalize
the editing process and introduce the involved concepts. Besides, we also
introduce new measures to evaluate its generalization ability, and build a
benchmark for further study. Our approach is evaluated on three coding tasks,
including API-seq recommendation, line-level code generation, and
pseudocode-to-code transaction. It outperforms the state-of-the-art by a
significant margin on both effectiveness and efficiency measures. In addition,
we demonstrate the usages of \textsc{MENT} for LLM reasoning in software
engineering. By editing the LLM knowledge with \textsc{MENT}, the directly or
indirectly dependent behaviors in the chain-of-thought change accordingly and
automatically.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05359" title="Abstract">arXiv:2312.05359</a> [<a href="/pdf/2312.05359" title="Download PDF">pdf</a>, <a href="/format/2312.05359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning 3D Particle-based Simulators from RGB-D Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Whitney%2C+W+F">William F. Whitney</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Guevara%2C+T">Tatiana Lopez-Guevara</a>, 
<a href="/search/cs?searchtype=author&query=Pfaff%2C+T">Tobias Pfaff</a>, 
<a href="/search/cs?searchtype=author&query=Rubanova%2C+Y">Yulia Rubanova</a>, 
<a href="/search/cs?searchtype=author&query=Kipf%2C+T">Thomas Kipf</a>, 
<a href="/search/cs?searchtype=author&query=Stachenfeld%2C+K">Kimberly Stachenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+K+R">Kelsey R. Allen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Realistic simulation is critical for applications ranging from robotics to
animation. Traditional analytic simulators sometimes struggle to capture
sufficiently realistic simulation which can lead to problems including the well
known "sim-to-real" gap in robotics. Learned simulators have emerged as an
alternative for better capturing real-world physical dynamics, but require
access to privileged ground truth physics information such as precise object
geometry or particle tracks. Here we propose a method for learning simulators
directly from observations. Visual Particle Dynamics (VPD) jointly learns a
latent particle-based representation of 3D scenes, a neural simulator of the
latent particle dynamics, and a renderer that can produce images of the scene
from arbitrary views. VPD learns end to end from posed RGB-D videos and does
not require access to privileged information. Unlike existing 2D video
prediction models, we show that VPD's 3D structure enables scene editing and
long-term predictions. These results pave the way for downstream applications
ranging from video editing to robotic planning.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05361" title="Abstract">arXiv:2312.05361</a> [<a href="/pdf/2312.05361" title="Download PDF">pdf</a>, <a href="/format/2312.05361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence and Function of Abstract Representations in Self-Supervised  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferry%2C+Q+R">Quentin RV. Ferry</a>, 
<a href="/search/cs?searchtype=author&query=Ching%2C+J">Joshua Ching</a>, 
<a href="/search/cs?searchtype=author&query=Kawai%2C+T">Takashi Kawai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Human intelligence relies in part on our brains' ability to create abstract
mental models that succinctly capture the hidden blueprint of our reality. Such
abstract world models notably allow us to rapidly navigate novel situations by
generalizing prior knowledge, a trait deep learning systems have historically
struggled to replicate. However, the recent shift from supervised to
self-supervised objectives, combined with expressive transformer-based
architectures, have yielded powerful foundation models that appear to learn
versatile representations that can support a wide range of downstream tasks.
This promising development raises the intriguing possibility of such models
developing in silico abstract world models. We test this hypothesis by studying
the inner workings of small-scale transformers trained to reconstruct partially
masked visual scenes generated from a simple blueprint. We show that the
network develops intermediate abstract representations, or abstractions, that
encode all semantic features of the dataset. These abstractions manifest as
low-dimensional manifolds where the embeddings of semantically related tokens
transiently converge, thus allowing for the generalization of downstream
computations. Using precise manipulation experiments, we demonstrate that
abstractions are central to the network's decision-making process. Our research
also suggests that these abstractions are compositionally structured,
exhibiting features like contextual independence and part-whole relationships
that mirror the compositional nature of the dataset. Finally, we introduce a
Language-Enhanced Architecture (LEA) designed to encourage the network to
articulate its computations. We find that LEA develops an abstraction-centric
language that can be easily interpreted, allowing us to more readily access and
steer the network's decision-making process.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05364" title="Abstract">arXiv:2312.05364</a> [<a href="/pdf/2312.05364" title="Download PDF">pdf</a>, <a href="/format/2312.05364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntGrip -- Boosting Parallel Plate Gripper Performance Inspired by the  Internal Hairs of Ant Mandibles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorour%2C+M">Mohamed Sorour</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+B">Barbara Webb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ants use their mandibles - effectively a two-finger gripper - for a wide
range of grasping activities. Here we investigate whether mimicking the
internal hairs found on ant mandibles can improve performance of a two-finger
parallel plate robot gripper. With bin picking applications in mind, the
gripper fingers are long and slim, with interchangeable soft gripping pads that
can be hairy or hairless. A total of 2400 video-documented experiments have
been conducted, comparing hairless to hairy pads with different hair patterns.
Simply by adding hairs, the grasp success rate was increased by at least 29%,
and the number of objects that remain securely gripped during manipulation more
than doubled. This result not only advances the state of the art in grasping
technology, but also provides novel insight into the mechanical role of
mandible hairs in ant biology.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05368" title="Abstract">arXiv:2312.05368</a> [<a href="/pdf/2312.05368" title="Download PDF">pdf</a>, <a href="/format/2312.05368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Scalable and Transparent Multimodal Analytics to Study Standard  Medical Procedures: Linking Hand Movement, Proximity, and Gaze Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heilala%2C+V">Ville Heilala</a>, 
<a href="/search/cs?searchtype=author&query=Lehesvuori%2C+S">Sami Lehesvuori</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4m%C3%A4l%C3%A4inen%2C+R">Raija H&#xe4;m&#xe4;l&#xe4;inen</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4rkk%C3%A4inen%2C+T">Tommi K&#xe4;rkk&#xe4;inen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing (SAC'24), April 8--12, 2024, Avila, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study employed multimodal learning analytics (MMLA) to analyze
behavioral dynamics during the ABCDE procedure in nursing education, focusing
on gaze entropy, hand movement velocities, and proximity measures. Utilizing
accelerometers and eye-tracking techniques, behaviorgrams were generated to
depict various procedural phases. Results identified four primary phases
characterized by distinct patterns of visual attention, hand movements, and
proximity to the patient or instruments. The findings suggest that MMLA can
offer valuable insights into procedural competence in medical education. This
research underscores the potential of MMLA to provide detailed, objective
evaluations of clinical procedures and their inherent complexities.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05379" title="Abstract">arXiv:2312.05379</a> [<a href="/pdf/2312.05379" title="Download PDF">pdf</a>, <a href="/format/2312.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Parity Challenges in Reinforcement Learning through Curriculum  Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">Soren Riis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper delves into applying reinforcement learning (RL) in strategy
games, particularly those characterized by parity challenges, as seen in
specific positions of Go and Chess and a broader range of impartial games. We
propose a simulated learning process, structured within a curriculum learning
framework and augmented with noisy labels, to mirror the intricacies of
self-play learning scenarios. This approach thoroughly analyses how neural
networks (NNs) adapt and evolve from elementary to increasingly complex game
positions. Our empirical research indicates that even minimal label noise can
significantly impede NNs' ability to discern effective strategies, a difficulty
that intensifies with the growing complexity of the game positions. These
findings underscore the urgent need for advanced methodologies in RL training,
specifically tailored to counter the obstacles imposed by noisy evaluations.
The development of such methodologies is crucial not only for enhancing NN
proficiency in strategy games with significant parity elements but also for
broadening the resilience and efficiency of RL systems across diverse and
complex environments.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05382" title="Abstract">arXiv:2312.05382</a> [<a href="/pdf/2312.05382" title="Download PDF">pdf</a>, <a href="/format/2312.05382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-sample Identification of Continuous-time Parameter-linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kuang%2C+S">Simon Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+X">Xinfan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Differentiating noisy, discrete measurements in order to fit an ordinary
differential equation can be unreasonably effective. Assuming square-integrable
noise and minimal flow regularity, we construct and analyze a finite-difference
differentiation filter and a Tikhonov-regularized least squares estimator for
the continuous-time parameter-linear system. Combining these contributions in
series, we obtain a finite-sample bound on mean absolute error of estimation.
As a by-product, we offer a novel analysis of stochastically perturbed
Moore-Penrose pseudoinverses.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05385" title="Abstract">arXiv:2312.05385</a> [<a href="/pdf/2312.05385" title="Download PDF">pdf</a>, <a href="/format/2312.05385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Apparate: Rethinking Early Exits to Tame Latency-Throughput Tensions in  ML Serving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yinwei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+A">Anand Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Netravali%2C+R">Ravi Netravali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally and are alphabetically ordered
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) inference platforms are tasked with balancing two
competing goals: ensuring high throughput given many requests, and delivering
low-latency responses to support interactive applications. Unfortunately,
existing platform knobs (e.g., batch sizes) fail to ease this fundamental
tension, and instead only enable users to harshly trade off one property for
the other. This paper explores an alternate strategy to taming
throughput-latency tradeoffs by changing the granularity at which inference is
performed. We present Apparate, a system that automatically applies and manages
early exits (EEs) in ML models, whereby certain inputs can exit with results at
intermediate layers. To cope with the time-varying overhead and accuracy
challenges that EEs bring, Apparate repurposes exits to provide continual
feedback that powers several novel runtime monitoring and adaptation
strategies. Apparate lowers median response latencies by 40.5-91.5% and
10.0-24.2% for diverse CV and NLP workloads, respectively, without affecting
throughputs or violating tight accuracy constraints.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05386" title="Abstract">arXiv:2312.05386</a> [<a href="/pdf/2312.05386" title="Download PDF">pdf</a>, <a href="/format/2312.05386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Extraction Attacks Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiacheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+R">Ren Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Model extraction (ME) attacks represent one major threat to
Machine-Learning-as-a-Service (MLaaS) platforms by ``stealing'' the
functionality of confidential machine-learning models through querying
black-box APIs. Over seven years have passed since ME attacks were first
conceptualized in the seminal work. During this period, substantial advances
have been made in both ME attacks and MLaaS platforms, raising the intriguing
question: How has the vulnerability of MLaaS platforms to ME attacks been
evolving? In this work, we conduct an in-depth study to answer this critical
question. Specifically, we characterize the vulnerability of current,
mainstream MLaaS platforms to ME attacks from multiple perspectives including
attack strategies, learning techniques, surrogate-model design, and benchmark
tasks. Many of our findings challenge previously reported results, suggesting
emerging patterns of ME vulnerability. Further, by analyzing the vulnerability
of the same MLaaS platforms using historical datasets from the past four years,
we retrospectively characterize the evolution of ME vulnerability over time,
leading to a set of interesting findings. Finally, we make suggestions about
improving the current practice of MLaaS in terms of attack robustness. Our
study sheds light on the current state of ME vulnerability in the wild and
points to several promising directions for future research.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05387" title="Abstract">arXiv:2312.05387</a> [<a href="/pdf/2312.05387" title="Download PDF">pdf</a>, <a href="/format/2312.05387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Domain Generative Augmentation: Domain Generalization with Latent  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemati%2C+S">Sobhan Hemati</a>, 
<a href="/search/cs?searchtype=author&query=Beitollahi%2C+M">Mahdi Beitollahi</a>, 
<a href="/search/cs?searchtype=author&query=Estiri%2C+A+H">Amir Hossein Estiri</a>, 
<a href="/search/cs?searchtype=author&query=Omari%2C+B+A">Bassel Al Omari</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guojun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the huge effort in developing novel regularizers for Domain
Generalization (DG), adding simple data augmentation to the vanilla ERM which
is a practical implementation of the Vicinal Risk Minimization principle (VRM)
\citep{chapelle2000vicinal} outperforms or stays competitive with many of the
proposed regularizers. The VRM reduces the estimation error in ERM by replacing
the point-wise kernel estimates with a more precise estimation of true data
distribution that reduces the gap between data points \textbf{within each
domain}. However, in the DG setting, the estimation error of true data
distribution by ERM is mainly caused by the distribution shift \textbf{between
domains} which cannot be fully addressed by simple data augmentation techniques
within each domain. Inspired by this limitation of VRM, we propose a novel data
augmentation named Cross Domain Generative Augmentation (CDGA) that replaces
the pointwise kernel estimates in ERM with new density estimates in the
\textbf{vicinity of domain pairs} so that the gap between domains is further
reduced. To this end, CDGA, which is built upon latent diffusion models (LDM),
generates synthetic images to fill the gap between all domains and as a result,
reduces the non-iidness. We show that CDGA outperforms SOTA DG methods under
the Domainbed benchmark. To explain the effectiveness of CDGA, we generate more
than 5 Million synthetic images and perform extensive ablation studies
including data scaling laws, distribution visualization, domain shift
quantification, adversarial robustness, and loss landscape analysis.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05390" title="Abstract">arXiv:2312.05390</a> [<a href="/pdf/2312.05390" title="Download PDF">pdf</a>, <a href="/format/2312.05390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of  Interpretable Directions in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalva%2C+Y">Yusuf Dalva</a>, 
<a href="/search/cs?searchtype=author&query=Yanardag%2C+P">Pinar Yanardag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://noiseclr.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative models have been very popular in the recent years for their image
generation capabilities. GAN-based models are highly regarded for their
disentangled latent space, which is a key feature contributing to their success
in controlled image editing. On the other hand, diffusion models have emerged
as powerful tools for generating high-quality images. However, the latent space
of diffusion models is not as thoroughly explored or understood. Existing
methods that aim to explore the latent space of diffusion models usually relies
on text prompts to pinpoint specific semantics. However, this approach may be
restrictive in areas such as art, fashion, or specialized fields like medicine,
where suitable text prompts might not be available or easy to conceive thus
limiting the scope of existing work. In this paper, we propose an unsupervised
method to discover latent semantics in text-to-image diffusion models without
relying on text prompts. Our method takes a small set of unlabeled images from
specific domains, such as faces or cats, and a pre-trained diffusion model, and
discovers diverse semantics in unsupervised fashion using a contrastive
learning objective. Moreover, the learned directions can be applied
simultaneously, either within the same domain (such as various types of facial
edits) or across different domains (such as applying cat and face edits within
the same image) without interfering with each other. Our extensive experiments
show that our method achieves highly disentangled edits, outperforming existing
approaches in both diffusion-based and GAN-based latent space editing methods.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05391" title="Abstract">arXiv:2312.05391</a> [<a href="/pdf/2312.05391" title="Download PDF">pdf</a>, <a href="/format/2312.05391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss Functions in the Era of Semantic Segmentation: A Survey and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/cs?searchtype=author&query=Heidary%2C+M">Moein Heidary</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+K">Kadir Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCttemann%2C+M">Michael H&#xfc;ttemann</a>, 
<a href="/search/cs?searchtype=author&query=Karimijafarbigloo%2C+S">Sanaz Karimijafarbigloo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuli Wu</a>, 
<a href="/search/cs?searchtype=author&query=Schmeink%2C+A">Anke Schmeink</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic image segmentation, the process of classifying each pixel in an
image into a particular class, plays an important role in many visual
understanding systems. As the predominant criterion for evaluating the
performance of statistical models, loss functions are crucial for shaping the
development of deep learning-based segmentation algorithms and improving their
overall performance. To aid researchers in identifying the optimal loss
function for their particular application, this survey provides a comprehensive
and unified review of $25$ loss functions utilized in image segmentation. We
provide a novel taxonomy and thorough review of how these loss functions are
customized and leveraged in image segmentation, with a systematic
categorization emphasizing their significant features and applications.
Furthermore, to evaluate the efficacy of these methods in real-world scenarios,
we propose unbiased evaluations of some distinct and renowned loss functions on
established medical and natural image datasets. We conclude this review by
identifying current challenges and unveiling future research opportunities.
Finally, we have compiled the reviewed studies that have open-source
implementations on our GitHub page.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05392" title="Abstract">arXiv:2312.05392</a> [<a href="/pdf/2312.05392" title="Download PDF">pdf</a>, <a href="/format/2312.05392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The logic of NTQR evaluations of noisy AI agents: Complete postulates  and logically consistent error correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corrada-Emmanuel%2C+A">Andr&#xe9;s Corrada-Emmanuel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In his "ship of state" allegory (\textit{Republic}, Book VI, 488) Plato poses
a question -- how can a crew of sailors presumed to know little about the art
of navigation recognize the true pilot among them? The allegory argues that a
simple majority voting procedure cannot safely determine who is most qualified
to pilot a ship when the voting members are ignorant or biased. We formalize
Plato's concerns by considering the problem in AI safety of monitoring noisy AI
agents in unsupervised settings. An algorithm evaluating AI agents using
unlabeled data would be subject to the evaluation dilemma - how would we know
the evaluation algorithm was correct itself? This endless validation chain can
be avoided by considering purely algebraic functions of the observed responses.
We can construct complete postulates than can prove or disprove the logical
consistency of any grading algorithm. A complete set of postulates exists
whenever we are evaluating $N$ experts that took $T$ tests with $Q$ questions
with $R$ responses each. We discuss evaluating binary classifiers that have
taken a single test - the $(N,T=1,Q,R=2)$ tests. We show how some of the
postulates have been previously identified in the ML literature but not
recognized as such - the \textbf{agreement equations} of Platanios. The
complete postulates for pair correlated binary classifiers are considered and
we show how it allows for error correlations to be quickly calculated. An
algebraic evaluator based on the assumption that the ensemble is error
independent is compared with grading by majority voting on evaluations using
the \uciadult and and \texttt{two-norm} datasets. Throughout, we demonstrate
how the formalism of logical consistency via algebraic postulates of evaluation
can help increase the safety of machines using AI algorithms.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05397" title="Abstract">arXiv:2312.05397</a> [<a href="/pdf/2312.05397" title="Download PDF">pdf</a>, <a href="/format/2312.05397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Performance of Temporal Difference Learning With Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Haoxing Tian</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidis%2C+I+C">Ioannis Ch. Paschalidis</a>, 
<a href="/search/cs?searchtype=author&query=Olshevsky%2C+A">Alex Olshevsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural Temporal Difference (TD) Learning is an approximate temporal
difference method for policy evaluation that uses a neural network for function
approximation. Analysis of Neural TD Learning has proven to be challenging. In
this paper we provide a convergence analysis of Neural TD Learning with a
projection onto $B(\theta_0, \omega)$, a ball of fixed radius $\omega$ around
the initial point $\theta_0$. We show an approximation bound of $O(\epsilon) +
\tilde{O} (1/\sqrt{m})$ where $\epsilon$ is the approximation quality of the
best neural network in $B(\theta_0, \omega)$ and $m$ is the width of all hidden
layers in the network.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05398" title="Abstract">arXiv:2312.05398</a> [<a href="/pdf/2312.05398" title="Download PDF">pdf</a>, <a href="/format/2312.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Network Layer for Communication Systems with Artificial  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thorsager%2C+M">Mathias Thorsager</a>, 
<a href="/search/cs?searchtype=author&query=Leyva-Mayorga%2C+I">Israel Leyva-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Soret%2C+B">Beatriz Soret</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Communication Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The traditional role of the network layer is the transfer of packet replicas
from source to destination through intermediate network nodes. We present a
generative network layer that uses Generative AI (GenAI) at intermediate or
edge network nodes and analyze its impact on the required data rates in the
network. We conduct a case study where the GenAI-aided nodes generate images
from prompts that consist of substantially compressed latent representations.
The results from network flow analyses under image quality constraints show
that the generative network layer can achieve an improvement of more than 100%
in terms of the required data rate.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05401" title="Abstract">arXiv:2312.05401</a> [<a href="/pdf/2312.05401" title="Download PDF">pdf</a>, <a href="/format/2312.05401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Digital Compositing Approach to obtain Animated Chinese Still-life  Paintings with Global Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Sitong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this work, we present a method for turning Chinese still-life paintings
with global illumination effects into dynamic paintings with moving lights. Our
goal is to preserve the original look and feel of still-life paintings with
moving lights and objects. We have developed a deceptively simple method that
can be computed as a composite of two animated texture images using an animated
rendering. The compositing process can be implemented directly in an animation
system such as AfterEffect, which allows for the basic compositing operation
over animations. It is also possible to control the colors by changing the
material colors in animated rendering. We have provided a proof-of-concept
based on an original digital Still-Life painting that is in realist Chinese
style. This approach can be used to turn almost any still-life painting into a
dynamic painting.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05402" title="Abstract">arXiv:2312.05402</a> [<a href="/pdf/2312.05402" title="Download PDF">pdf</a>, <a href="/format/2312.05402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Controlled Table-to-Text Generation with Scientific Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhixin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiexing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Mingxuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Ziwei He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouhan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The sheer volume of scientific experimental results and complex technical
statements, often presented in tabular formats, presents a formidable barrier
to individuals acquiring preferred information. The realms of scientific
reasoning and content generation that adhere to user preferences encounter
distinct challenges. In this work, we present a new task for generating fluent
and logical descriptions that match user preferences over scientific tabular
data, aiming to automate scientific document analysis. To facilitate research
in this direction, we construct a new challenging dataset CTRLSciTab consisting
of table-description pairs extracted from the scientific literature, with
highlighted cells and corresponding domain-specific knowledge base. We
evaluated popular pre-trained language models to establish a baseline and
proposed a novel architecture outperforming competing approaches. The results
showed that large models struggle to produce accurate content that aligns with
user preferences. As the first of its kind, our work should motivate further
research in scientific domains.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05404" title="Abstract">arXiv:2312.05404</a> [<a href="/pdf/2312.05404" title="Download PDF">pdf</a>, <a href="/format/2312.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Latent Representation Learning for Tackling the Confounding  M-Bias Problem in Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Debo Cheng</a> (1), 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yang Xie</a> (2), 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziqi Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiuyong Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jixue Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinghao Zhang</a> (2), 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zaiwen Feng</a> (2) ((1) UniSA STEM, University of South Australia, Adelaide, Australia and (2) College of Informatics, Huazhong Agricultural University, Wuhan, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures and 5 tables. Accepted by ICDM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">In causal inference, it is a fundamental task to estimate the causal effect
from observational data. However, latent confounders pose major challenges in
causal inference in observational data, for example, confounding bias and
M-bias. Recent data-driven causal effect estimators tackle the confounding bias
problem via balanced representation learning, but assume no M-bias in the
system, thus they fail to handle the M-bias. In this paper, we identify a
challenging and unsolved problem caused by a variable that leads to confounding
bias and M-bias simultaneously. To address this problem with co-occurring
M-bias and confounding bias, we propose a novel Disentangled Latent
Representation learning framework for learning latent representations from
proxy variables for unbiased Causal effect Estimation (DLRCE) from
observational data. Specifically, DLRCE learns three sets of latent
representations from the measured proxy variables to adjust for the confounding
bias and M-bias. Extensive experiments on both synthetic and three real-world
datasets demonstrate that DLRCE significantly outperforms the state-of-the-art
estimators in the case of the presence of both confounding bias and M-bias.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05405" title="Abstract">arXiv:2312.05405</a> [<a href="/pdf/2312.05405" title="Download PDF">pdf</a>, <a href="/format/2312.05405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guaranteed Trust Region Optimization via Two-Phase KL Penalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zentner%2C+K+R">K.R. Zentner</a>, 
<a href="/search/cs?searchtype=author&query=Puri%2C+U">Ujjwal Puri</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhehui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">On-policy reinforcement learning (RL) has become a popular framework for
solving sequential decision problems due to its computational efficiency and
theoretical simplicity. Some on-policy methods guarantee every policy update is
constrained to a trust region relative to the prior policy to ensure training
stability. These methods often require computationally intensive non-linear
optimization or require a particular form of action distribution. In this work,
we show that applying KL penalization alone is nearly sufficient to enforce
such trust regions. Then, we show that introducing a "fixup" phase is
sufficient to guarantee a trust region is enforced on every policy update while
adding fewer than 5% additional gradient steps in practice. The resulting
algorithm, which we call FixPO, is able to train a variety of policy
architectures and action spaces, is easy to implement, and produces results
competitive with other trust region methods.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05407" title="Abstract">arXiv:2312.05407</a> [<a href="/pdf/2312.05407" title="Download PDF">pdf</a>, <a href="/format/2312.05407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning Guided Federated Online Adaptation: Applications in  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Shazid Islam</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+S">Sayak Nag</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Arindam Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Miraj Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Niloy%2C+F+F">Fahim Faisal Niloy</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K.Roy-Chowdhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data privacy, storage, and distribution shifts are major bottlenecks in
medical image analysis. Data cannot be shared across patients, physicians, and
facilities due to privacy concerns, usually requiring each patient's data to be
analyzed in a discreet setting at a near real-time pace. However, one would
like to take advantage of the accumulated knowledge across healthcare
facilities as the computational systems analyze data of more and more patients
while incorporating feedback provided by physicians to improve accuracy.
Motivated by these, we propose a method for medical image segmentation that
adapts to each incoming data batch (online adaptation), incorporates physician
feedback through active learning, and assimilates knowledge across facilities
in a federated setup. Combining an online adaptation scheme at test time with
an efficient sampling strategy with budgeted annotation helps bridge the gap
between the source and the incoming stream of target domain data. A federated
setup allows collaborative aggregation of knowledge across distinct distributed
models without needing to share the data across different models. This
facilitates the improvement of performance over time by accumulating knowledge
across users. Towards achieving these goals, we propose a computationally
amicable, privacy-preserving image segmentation technique \textbf{DrFRODA} that
uses federated learning to adapt the model in an online manner with feedback
from doctors in the loop. Our experiments on publicly available datasets show
that the proposed distributed active learning-based online adaptation method
outperforms unsupervised online adaptation methods and shows competitive
results with offline active learning-based adaptation methods.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05409" title="Abstract">arXiv:2312.05409</a> [<a href="/pdf/2312.05409" title="Download PDF">pdf</a>, <a href="/format/2312.05409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Training of Foundation Models for Wearable Biosignals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbaspourazad%2C+S">Salar Abbaspourazad</a>, 
<a href="/search/cs?searchtype=author&query=Elachqar%2C+O">Oussama Elachqar</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+A+C">Andrew C. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Emrani%2C+S">Saba Emrani</a>, 
<a href="/search/cs?searchtype=author&query=Nallasamy%2C+U">Udhyakumar Nallasamy</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+I">Ian Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Tracking biosignals is crucial for monitoring wellness and preempting the
development of severe medical conditions. Today, wearable devices can
conveniently record various biosignals, creating the opportunity to monitor
health status without disruption to one's daily routine. Despite widespread use
of wearable devices and existing digital biomarkers, the absence of curated
data with annotated medical labels hinders the development of new biomarkers to
measure common health conditions. In fact, medical datasets are usually small
in comparison to other domains, which is an obstacle for developing neural
network models for biosignals. To address this challenge, we have employed
self-supervised learning using the unlabeled sensor data collected under
informed consent from the large longitudinal Apple Heart and Movement Study
(AHMS) to train foundation models for two common biosignals:
photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch.
We curated PPG and ECG datasets from AHMS that include data from ~141K
participants spanning ~3 years. Our self-supervised learning framework includes
participant level positive pair selection, stochastic augmentation module and a
regularized contrastive loss optimized with momentum training, and generalizes
well to both PPG and ECG modalities. We show that the pre-trained foundation
models readily encode information regarding participants' demographics and
health conditions. To the best of our knowledge, this is the first study that
builds foundation models using large-scale PPG and ECG data collected via
wearable consumer devices $\unicode{x2013}$ prior works have commonly used
smaller-size datasets collected in clinical and experimental settings. We
believe PPG and ECG foundation models can enhance future wearable devices by
reducing the reliance on labeled data and hold the potential to help the users
improve their health.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05410" title="Abstract">arXiv:2312.05410</a> [<a href="/pdf/2312.05410" title="Download PDF">pdf</a>, <a href="/format/2312.05410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking materials simulations: Blending direct numerical simulations  with neural operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oommen%2C+V">Vivek Oommen</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+K">Khemraj Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+S">Saaketh Desai</a>, 
<a href="/search/cs?searchtype=author&query=Dingreville%2C+R">Remi Dingreville</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Direct numerical simulations (DNS) are accurate but computationally expensive
for predicting materials evolution across timescales, due to the complexity of
the underlying evolution equations, the nature of multiscale spatio-temporal
interactions, and the need to reach long-time integration. We develop a new
method that blends numerical solvers with neural operators to accelerate such
simulations. This methodology is based on the integration of a community
numerical solver with a U-Net neural operator, enhanced by a
temporal-conditioning mechanism that enables accurate extrapolation and
efficient time-to-solution predictions of the dynamics. We demonstrate the
effectiveness of this framework on simulations of microstructure evolution
during physical vapor deposition modeled via the phase-field method. Such
simulations exhibit high spatial gradients due to the co-evolution of different
material phases with simultaneous slow and fast materials dynamics. We
establish accurate extrapolation of the coupled solver with up to 16.5$\times$
speed-up compared to DNS. This methodology is generalizable to a broad range of
evolutionary models, from solid mechanics, to fluid dynamics, geophysics,
climate, and more.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05412" title="Abstract">arXiv:2312.05412</a> [<a href="/pdf/2312.05412" title="Download PDF">pdf</a>, <a href="/format/2312.05412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMMD: Contrastive Multi-Modal Diffusion for Video-Audio Conditional  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruihan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gamper%2C+H">Hannes Gamper</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+S">Sebastian Braun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce a multi-modal diffusion model tailored for the bi-directional
conditional generation of video and audio. Recognizing the importance of
accurate alignment between video and audio events in multi-modal generation
tasks, we propose a joint contrastive training loss to enhance the
synchronization between visual and auditory occurrences. Our research
methodology involves conducting comprehensive experiments on multiple datasets
to thoroughly evaluate the efficacy of our proposed model. The assessment of
generation quality and alignment performance is carried out from various
angles, encompassing both objective and subjective metrics. Our findings
demonstrate that the proposed model outperforms the baseline, substantiating
its effectiveness and efficiency. Notably, the incorporation of the contrastive
loss results in improvements in audio-visual alignment, particularly in the
high-correlation video-to-audio generation task. These results indicate the
potential of our proposed model as a robust solution for improving the quality
and alignment of multi-modal generation, thereby contributing to the
advancement of video and audio conditional generation systems.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05415" title="Abstract">arXiv:2312.05415</a> [<a href="/pdf/2312.05415" title="Download PDF">pdf</a>, <a href="/ps/2312.05415" title="Download PostScript">ps</a>, <a href="/format/2312.05415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Study: Assessing the Combined Framework of WavLM and  BEST-RQ for Text-to-Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nielson%2C+V">Via Nielson</a>, 
<a href="/search/cs?searchtype=author&query=Hillis%2C+S">Steven Hillis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose a new model architecture specifically suited for text-to-speech
(TTS) models. We combine WavLM, a pre-trained self-supervised learning (SSL)
speech model, and the BEST-RQ vector quantization framework. We assess the
extent to which the more task-agnostic WavLM, coupled with the superior
suitability of the simplistic BEST-RQ framework for a wider array of downstream
tasks, yields favorable outcomes. Experiments on the LibriSpeech dataset with
SUPERB benchmarking assert that the proposed model significantly underperforms.
We speculate the underlying reason for this performance is related to the
difference between featurizing raw audio waveforms and spectrograms with a
quantizer. We discuss the limitations of this approach to better guide future
advancements in TTS.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05416" title="Abstract">arXiv:2312.05416</a> [<a href="/pdf/2312.05416" title="Download PDF">pdf</a>, <a href="/ps/2312.05416" title="Download PostScript">ps</a>, <a href="/format/2312.05416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduling Splittable Jobs on Configurable Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casey%2C+M">Matthew Casey</a>, 
<a href="/search/cs?searchtype=author&query=Rajaraman%2C+R">Rajmohan Rajaraman</a>, 
<a href="/search/cs?searchtype=author&query=Stalfa%2C+D">David Stalfa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Motivated by deep neural network applications, we study the problem of
scheduling splittable jobs (e.g., neural network inference tasks) on
configurable machines (e.g., multi-instance GPUs). We are given $n$ jobs and a
set $C$ of configurations (e.g, representing ways to configure a GPU)
consisting of multisets of blocks (e.g., representing GPU instances). A
schedule consists of a set of machines, each assigned some configuration in $C$
with each block in the configuration assigned to process one job. The amount of
a job's demand that is satisfied by a given block is an arbitrary function of
the job and block. The objective is to satisfy all demands on as few machines
as possible. We provide a tight logarithmic approximation algorithm for this
problem in the general setting, an asymptotic $(2 + \varepsilon)$-approximation
with $O(1)$ input configurations for arbitrary $\varepsilon &gt; 0$, and a
polynomial time approximation scheme when both the number and size of
configurations are $O(1)$.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05417" title="Abstract">arXiv:2312.05417</a> [<a href="/pdf/2312.05417" title="Download PDF">pdf</a>, <a href="/format/2312.05417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESPN: Memory-Efficient Multi-Vector Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+S">Susav Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+N">Narasimha Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongwang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in large language models have demonstrated remarkable
effectiveness in information retrieval (IR) tasks. While many neural IR systems
encode queries and documents into single-vector representations, multi-vector
models elevate the retrieval quality by producing multi-vector representations
and facilitating similarity searches at the granularity of individual tokens.
However, these models significantly amplify memory and storage requirements for
retrieval indices by an order of magnitude. This escalation in index size
renders the scalability of multi-vector IR models progressively challenging due
to their substantial memory demands. We introduce Embedding from Storage
Pipelined Network (ESPN) where we offload the entire re-ranking embedding
tables to SSDs and reduce the memory requirements by 5-16x. We design a
software prefetcher with hit rates exceeding 90%, improving SSD based retrieval
up to 6.4x, and demonstrate that we can maintain near memory levels of query
latency even for large query batch sizes.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05418" title="Abstract">arXiv:2312.05418</a> [<a href="/pdf/2312.05418" title="Download PDF">pdf</a>, <a href="/format/2312.05418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bauer&#x27;s Spectral Factorization Method for Low Order Multiwavelet Filter  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kolev%2C+V">Vasil Kolev</a>, 
<a href="/search/math?searchtype=author&query=Cooklev%2C+T">Todor Cooklev</a>, 
<a href="/search/math?searchtype=author&query=Keinert%2C+F">Fritz Keinert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages,5 figures, 4 tables,
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational and Applied Mathematics, Vol.441, 2024,
  115713
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Para-Hermitian polynomial matrices obtained by matrix spectral factorization
lead to functions useful in control theory systems, basis functions in
numerical methods or multiscaling functions used in signal processing. We
introduce a fast algorithm for matrix spectral factorization based on Bauer$'$s
method. We convert Bauer$'$ method into a nonlinear matrix equation (NME). The
NME is solved by two different numerical algorithms (Fixed Point Iteration and
Newton$'$s Method) which produce approximate scalar or matrix factors, as well
as a symbolic algorithm which produces exact factors in closed form for some
low-order scalar or matrix polynomial matrices, respectively. Convergence rates
of the two numerical algorithms are investigated for a number of singular and
nonsingular scalar and matrix polynomials taken from different areas. In
particular, one of the singular examples leads to new orthogonal multiscaling
and multiwavelet filters. Since the NME can also be solved as a Generalized
Discrete Time Algebraic Riccati Equation (GDARE), numerical results using
built-in routines in Maple 17.0 and 6 Matlab versions are presented.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05419" title="Abstract">arXiv:2312.05419</a> [<a href="/pdf/2312.05419" title="Download PDF">pdf</a>, <a href="/ps/2312.05419" title="Download PostScript">ps</a>, <a href="/format/2312.05419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete-time Negative Imaginary Systems from ZOH Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+K">Kanghong Shi</a>, 
<a href="/search/eess?searchtype=author&query=Petersen%2C+I+R">Ian R. Petersen</a>, 
<a href="/search/eess?searchtype=author&query=Vladimirov%2C+I+G">Igor G. Vladimirov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">A new definition of discrete-time negative imaginary (NI) systems is
provided. This definition characterizes the dissipative property of a
zero-order hold sampled continuous-time NI system. Under some assumptions,
asymptotic stability can be guaranteed for the closed-loop interconnection of
an NI system and an output strictly negative imaginary system, with one of them
having a one step advance. In the case of linear systems, we also provide
necessary and sufficient frequency-domain and LMI conditions under which the
definition is satisfied. Also provided is a simple DC gain condition for the
stability results in the linear case. We show in an example that a discretized
mass-spring system, which is NI, can be asymptotically stabilized using the
proposed results.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05421" title="Abstract">arXiv:2312.05421</a> [<a href="/pdf/2312.05421" title="Download PDF">pdf</a>, <a href="/format/2312.05421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architecture Decisions in Quantum Software Systems: An Empirical Study  on Stack Exchange and GitHub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktar%2C+M+S">Mst Shamima Aktar</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Waseem%2C+M">Muhammad Waseem</a>, 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Amjed Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Aakash Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zengyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 3 images, 10 tables, Manuscript submitted to a Journal (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Quantum computing provides a new dimension in computation, utilizing the
principles of quantum mechanics to potentially solve complex problems that are
currently intractable for classical computers. However, little research has
been conducted about the architecture decisions made in quantum software
development, which have a significant influence on the functionality,
performance, scalability, and reliability of these systems. The study aims to
empirically investigate and analyze architecture decisions made during the
development of quantum software systems, identifying prevalent challenges and
limitations by using the posts and issues from Stack Exchange and GitHub. We
used a qualitative approach to analyze the obtained data from Stack Exchange
Sites and GitHub projects. Specifically, we collected data from 151 issues
(from 47 GitHub projects) and 43 posts (from three Stack Exchange sites)
related to architecture decisions in quantum software development. The results
show that in quantum software development (1) architecture decisions are
articulated in six linguistic patterns, the most common of which are Solution
Proposal and Information Giving, (2) the two major categories of architectural
decisions are Implementation Decision and Technology Decision, (3) Quantum
Programming Framework is the most common application domain among the sixteen
application domains identified, (4) Maintainability is the most frequently
considered quality attribute, and (5) Design Issue and Performance Issue are
the major limitations and challenges that practitioners face when making
architecture decisions in quantum software development. Our results show that
the limitations and challenges encountered in architecture decision-making
during the development of quantum software systems are strongly linked to the
particular features (e.g., quantum entanglement, superposition, and
decoherence) of those systems.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05428" title="Abstract">arXiv:2312.05428</a> [<a href="/pdf/2312.05428" title="Download PDF">pdf</a>, <a href="/format/2312.05428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Estimation in Unknown Nonlinear Manifold Using Koopman  Operator Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Banks%2C+M+J">Michael J. Banks</a>, 
<a href="/search/cs?searchtype=author&query=Mezic%2C+I">Igor Mezic</a>, 
<a href="/search/cs?searchtype=author&query=Hikihara%2C+T">Takashi Hikihara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Formation coordination is a critical aspect of swarm robotics, which involves
coordinating the motion and behavior of a group of robots to achieve a specific
objective. In formation coordination, the robots must maintain a specific
spatial arrangement while in motion. In this paper, we present a
leader-follower column formation coordination problem in an unknown,
two-dimensional nonlinear manifold, where we redefining it as a trajectory
estimation problem. Leveraging Koopman operator theory and Extended Dynamic
Mode Decomposition, we estimate the measurement vectors for the follower agent
and guide its nonlinear trajectories.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05429" title="Abstract">arXiv:2312.05429</a> [<a href="/pdf/2312.05429" title="Download PDF">pdf</a>, <a href="/ps/2312.05429" title="Download PostScript">ps</a>, <a href="/format/2312.05429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Nonlinear Algorithmic Bias in Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hui%2C+W">Wendy Hui</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+W+K">Wai Kwong Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Applications (stat.AP)

</div>
<p class="mathjax">This paper proposes the use of causal modeling to detect and mitigate
algorithmic bias that is nonlinear in the protected attribute. We provide a
general overview of our approach. We use the German Credit data set, which is
available for download from the UC Irvine Machine Learning Repository, to
develop (1) a prediction model, which is treated as a black box, and (2) a
causal model for bias mitigation. In this paper, we focus on age bias and the
problem of binary classification. We show that the probability of getting
correctly classified as "low risk" is lowest among young people. The
probability increases with age nonlinearly. To incorporate the nonlinearity
into the causal model, we introduce a higher order polynomial term. Based on
the fitted causal model, the de-biased probability estimates are computed,
showing improved fairness with little impact on overall classification
accuracy. Causal modeling is intuitive and, hence, its use can enhance
explicability and promotes trust among different stakeholders of AI.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05430" title="Abstract">arXiv:2312.05430</a> [<a href="/pdf/2312.05430" title="Download PDF">pdf</a>, <a href="/format/2312.05430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FT2TF: First-Person Statement Text-To-Talking Face Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+X">Xingjian Diao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Barrios%2C+W">Wayner Barrios</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">SouYoung Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Talking face generation has gained immense popularity in the computer vision
community, with various applications including AR/VR, teleconferencing, digital
assistants, and avatars. Traditional methods are mainly audio-driven ones which
have to deal with the inevitable resource-intensive nature of audio storage and
processing. To address such a challenge, we propose FT2TF - First-Person
Statement Text-To-Talking Face Generation, a novel one-stage end-to-end
pipeline for talking face generation driven by first-person statement text.
Moreover, FT2TF implements accurate manipulation of the facial expressions by
altering the corresponding input text. Different from previous work, our model
only leverages visual and textual information without any other sources (e.g.
audio/landmark/pose) during inference. Extensive experiments are conducted on
LRS2 and LRS3 datasets, and results on multi-dimensional evaluation metrics are
reported. Both quantitative and qualitative results showcase that FT2TF
outperforms existing relevant methods and reaches the state-of-the-art. This
achievement highlights our model capability to bridge first-person statements
and dynamic face generation, providing insightful guidance for future work.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05431" title="Abstract">arXiv:2312.05431</a> [<a href="/pdf/2312.05431" title="Download PDF">pdf</a>, <a href="/format/2312.05431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantization Strategies for Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuewei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Latent Diffusion Models (LDMs) capture the dynamic evolution of latent
variables over time, blending patterns and multimodality in a generative
system. Despite the proficiency of LDM in various applications, such as
text-to-image generation, facilitated by robust text encoders and a variational
autoencoder, the critical need to deploy large generative models on edge
devices compels a search for more compact yet effective alternatives. Post
Training Quantization (PTQ), a method to compress the operational size of deep
learning models, encounters challenges when applied to LDM due to temporal and
structural complexities. This study proposes a quantization strategy that
efficiently quantize LDMs, leveraging Signal-to-Quantization-Noise Ratio (SQNR)
as a pivotal metric for evaluation. By treating the quantization discrepancy as
relative noise and identifying sensitive part(s) of a model, we propose an
efficient quantization approach encompassing both global and local strategies.
The global quantization process mitigates relative quantization noise by
initiating higher-precision quantization on sensitive blocks, while local
treatments address specific challenges in quantization-sensitive and
time-sensitive modules. The outcomes of our experiments reveal that the
implementation of both global and local treatments yields a highly efficient
and effective Post Training Quantization (PTQ) of LDMs.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05432" title="Abstract">arXiv:2312.05432</a> [<a href="/pdf/2312.05432" title="Download PDF">pdf</a>, <a href="/format/2312.05432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusing Multiple Algorithms for Heterogeneous Online Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadginmath%2C+D">Darshan Gadginmath</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+S">Shivanshu Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This study addresses the challenge of online learning in contexts where
agents accumulate disparate data, face resource constraints, and use different
local algorithms. This paper introduces the Switched Online Learning Algorithm
(SOLA), designed to solve the heterogeneous online learning problem by
amalgamating updates from diverse agents through a dynamic switching mechanism
contingent upon their respective performance and available resources. We
theoretically analyze the design of the selecting mechanism to ensure that the
regret of SOLA is bounded. Our findings show that the number of changes in
selection needs to be bounded by a parameter dependent on the performance of
the different local algorithms. Additionally, two test cases are presented to
emphasize the effectiveness of SOLA, first on an online linear regression
problem and then on an online classification problem with the MNIST dataset.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05433" title="Abstract">arXiv:2312.05433</a> [<a href="/pdf/2312.05433" title="Download PDF">pdf</a>, <a href="/format/2312.05433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Directly-Follows Process Discovery Using Grammatical  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alkhammash%2C+H">Hanan Alkhammash</a>, 
<a href="/search/cs?searchtype=author&query=Polyvyanyy%2C+A">Artem Polyvyanyy</a>, 
<a href="/search/cs?searchtype=author&query=Moffat%2C+A">Alistair Moffat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Starting with a collection of traces generated by process executions, process
discovery is the task of constructing a simple model that describes the
process, where simplicity is often measured in terms of model size. The
challenge of process discovery is that the process of interest is unknown, and
that while the input traces constitute positive examples of process executions,
no negative examples are available. Many commercial tools discover
Directly-Follows Graphs, in which nodes represent the observable actions of the
process, and directed arcs indicate execution order possibilities over the
actions. We propose a new approach for discovering sound Directly-Follows
Graphs that is grounded in grammatical inference over the input traces. To
promote the discovery of small graphs that also describe the process accurately
we design and evaluate a genetic algorithm that supports the convergence of the
inference parameters to the areas that lead to the discovery of interesting
models. Experiments over real-world datasets confirm that our new approach can
construct smaller models that represent the input traces and their frequencies
more accurately than the state-of-the-art technique. Reasoning over the
frequencies of encoded traces also becomes possible, due to the stochastic
semantics of the action graphs we propose, which, for the first time, are
interpreted as models that describe the stochastic languages of action traces.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05434" title="Abstract">arXiv:2312.05434</a> [<a href="/pdf/2312.05434" title="Download PDF">pdf</a>, <a href="/format/2312.05434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning  Distilled from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongzhan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first work to alleviate the issue of superficial understanding for harmful meme detection by explicitly utilizing commonsense knowledge, from a fresh perspective on harnessing advanced Large Language Models
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 2023 Conference on Empirical Methods in Natural Language
  Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The age of social media is rife with memes. Understanding and detecting
harmful memes pose a significant challenge due to their implicit meaning that
is not explicitly conveyed through the surface text and image. However,
existing harmful meme detection approaches only recognize superficial
harm-indicative signals in an end-to-end classification manner but ignore
in-depth cognition of the meme text and image. In this paper, we attempt to
detect harmful memes based on advanced reasoning over the interplay of
multimodal information in memes. Inspired by the success of Large Language
Models (LLMs) on complex reasoning, we first conduct abductive reasoning with
LLMs. Then we propose a novel generative framework to learn reasonable thoughts
from LLMs for better multimodal fusion and lightweight fine-tuning, which
consists of two training stages: 1) Distill multimodal reasoning knowledge from
LLMs; and 2) Fine-tune the generative framework to infer harmfulness. Extensive
experiments conducted on three meme datasets demonstrate that our proposed
approach achieves superior performance than state-of-the-art methods on the
harmful meme detection task.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05435" title="Abstract">arXiv:2312.05435</a> [<a href="/pdf/2312.05435" title="Download PDF">pdf</a>, <a href="/format/2312.05435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Robustness of Foundation Model Representations under  Provenance-related Distribution Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiruo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Z">Zhecheng Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+B">Brian Hur</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pakhomov%2C+S+V+S">Serguei V. S. Pakhomov</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+T">Trevor Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Workshop on Distribution Shifts, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Foundation models are a current focus of attention in both industry and
academia. While they have shown their capabilities in a variety of tasks,
in-depth research is required to determine their robustness to distribution
shift when used as a basis for supervised machine learning. This is especially
important in the context of clinical data, with particular limitations related
to data accessibility, lack of pretraining materials, and limited availability
of high-quality annotations. In this work, we examine the stability of models
based on representations from foundation models under distribution shift. We
focus on confounding by provenance, a form of distribution shift that emerges
in the context of multi-institutional datasets when there are differences in
source-specific language use and class distributions. Using a sampling strategy
that synthetically induces varying degrees of distribution shift, we evaluate
the extent to which representations from foundation models result in
predictions that are inherently robust to confounding by provenance.
Additionally, we examine the effectiveness of a straightforward confounding
adjustment method inspired by Pearl's conception of backdoor adjustment.
Results indicate that while foundation models do show some out-of-the-box
robustness to confounding-by-provenance related distribution shifts, this can
be considerably improved through adjustment. These findings suggest a need for
deliberate adjustment of predictive models using representations from
foundation models in the context of source-specific distributional differences.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05436" title="Abstract">arXiv:2312.05436</a> [<a href="/pdf/2312.05436" title="Download PDF">pdf</a>, <a href="/format/2312.05436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trading Off Scalability, Privacy, and Performance in Data Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xiao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Menzies%2C+T">Tim Menzies</a>, 
<a href="/search/cs?searchtype=author&query=Hazard%2C+C">Christopher Hazard</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Jack Shu</a>, 
<a href="/search/cs?searchtype=author&query=Beel%2C+J">Jacob Beel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures, 6 tables, submitted to IEEEAccess
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Synthetic data has been widely applied in the real world recently. One
typical example is the creation of synthetic data for privacy concerned
datasets. In this scenario, synthetic data substitute the real data which
contains the privacy information, and is used to public testing for machine
learning models. Another typical example is the unbalance data over-sampling
which the synthetic data is generated in the region of minority samples to
balance the positive and negative ratio when training the machine learning
models. In this study, we concentrate on the first example, and introduce (a)
the Howso engine, and (b) our proposed random projection based synthetic data
generation framework. We evaluate these two algorithms on the aspects of
privacy preservation and accuracy, and compare them to the two state-of-the-art
synthetic data generation algorithms DataSynthesizer and Synthetic Data Vault.
We show that the synthetic data generated by Howso engine has good privacy and
accuracy, which results the best overall score. On the other hand, our proposed
random projection based framework can generate synthetic data with highest
accuracy score, and has the fastest scalability.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05437" title="Abstract">arXiv:2312.05437</a> [<a href="/pdf/2312.05437" title="Download PDF">pdf</a>, <a href="/format/2312.05437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Distortion-Perception Theory for Semantic Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Jingxuan Chai</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE International Conference on Network Protocols (ICNP) Workshop, Reykjavik, Iceland, October 10-13, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Semantic communication has attracted significant interest recently due to its
capability to meet the fast growing demand on user-defined and human-oriented
communication services such as holographic communications, eXtended reality
(XR), and human-to-machine interactions. Unfortunately, recent study suggests
that the traditional Shannon information theory, focusing mainly on delivering
semantic-agnostic symbols, will not be sufficient to investigate the
semantic-level perceptual quality of the recovered messages at the receiver. In
this paper, we study the achievable data rate of semantic communication under
the symbol distortion and semantic perception constraints. Motivated by the
fact that the semantic information generally involves rich intrinsic knowledge
that cannot always be directly observed by the encoder, we consider a semantic
information source that can only be indirectly sensed by the encoder. Both
encoder and decoder can access to various types of side information that may be
closely related to the user's communication preference. We derive the
achievable region that characterizes the tradeoff among the data rate, symbol
distortion, and semantic perception, which is then theoretically proved to be
achievable by a stochastic coding scheme. We derive a closed-form achievable
rate for binary semantic information source under any given distortion and
perception constraints. We observe that there exists cases that the receiver
can directly infer the semantic information source satisfying certain
distortion and perception constraints without requiring any data communication
from the transmitter. Experimental results based on the image semantic source
signal have been presented to verify our theoretical observations.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05439" title="Abstract">arXiv:2312.05439</a> [<a href="/pdf/2312.05439" title="Download PDF">pdf</a>, <a href="/format/2312.05439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anti-symmetric and Positivity Preserving Formulation of a Spectral  Method for Vlasov-Poisson Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Issan%2C+O">Opal Issan</a>, 
<a href="/search/math?searchtype=author&query=Koshkarov%2C+O">Oleksandr Koshkarov</a>, 
<a href="/search/math?searchtype=author&query=Halpern%2C+F+D">Federico D. Halpern</a>, 
<a href="/search/math?searchtype=author&query=Kramer%2C+B">Boris Kramer</a>, 
<a href="/search/math?searchtype=author&query=Delzanno%2C+G+L">Gian Luca Delzanno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">We analyze the anti-symmetric properties of spectral discretization for the
one-dimensional Vlasov-Poisson equations. The discretization is based on a
spectral expansion in velocity with the symmetrically weighted Hermite basis
functions, central finite differencing in space, and an implicit Runge Kutta
integrator in time. The proposed discretization preserves the anti-symmetric
structure of the advection operator in the Vlasov equation, resulting in a
stable numerical method. We apply such discretization to two formulations: the
canonical Vlasov-Poisson equations and their continuously transformed
square-root representation. The latter preserves the positivity of the particle
distribution function. We derive analytically the conservation properties of
both formulations, including particle number, momentum, and energy, which are
verified numerically on the following benchmark problems: manufactured
solution, linear and nonlinear Landau damping, two-stream instability, and
bump-on-tail instability.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05440" title="Abstract">arXiv:2312.05440</a> [<a href="/pdf/2312.05440" title="Download PDF">pdf</a>, <a href="/format/2312.05440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Models for Scalable and Fast Simulation-Based Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+M">Marvin Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Pratz%2C+V">Valentin Pratz</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+S+T">Stefan T Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Simulation-based inference (SBI) is constantly in search of more expressive
algorithms for accurately inferring the parameters of complex models from noisy
data. We present consistency models for neural posterior estimation (CMPE), a
new free-form conditional sampler for scalable, fast, and amortized SBI with
generative neural networks. CMPE combines the advantages of normalizing flows
and flow matching methods into a single generative architecture: It essentially
distills a continuous probability flow and enables rapid few-shot inference
with an unconstrained architecture that can be tailored to the structure of the
estimation problem. Our empirical evaluation demonstrates that CMPE not only
outperforms current state-of-the-art algorithms on three hard low-dimensional
problems, but also achieves competitive performance in a high-dimensional
Bayesian denoising experiment and in estimating a computationally demanding
multi-scale model of tumor spheroid growth.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05447" title="Abstract">arXiv:2312.05447</a> [<a href="/pdf/2312.05447" title="Download PDF">pdf</a>, <a href="/format/2312.05447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Static to Dynamic: Adapting Landmark-Aware Image Models for Facial  Expression Recognition in Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code will be available at: <a href="https://github.com/FER-LMC/S2D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dynamic facial expression recognition (DFER) in the wild is still hindered by
data limitations, e.g., insufficient quantity and diversity of pose, occlusion
and illumination, as well as the inherent ambiguity of facial expressions. In
contrast, static facial expression recognition (SFER) currently shows much
higher performance and can benefit from more abundant high-quality training
data. Moreover, the appearance features and dynamic dependencies of DFER remain
largely unexplored. To tackle these challenges, we introduce a novel
Static-to-Dynamic model (S2D) that leverages existing SFER knowledge and
dynamic information implicitly encoded in extracted facial landmark-aware
features, thereby significantly improving DFER performance. Firstly, we build
and train an image model for SFER, which incorporates a standard Vision
Transformer (ViT) and Multi-View Complementary Prompters (MCPs) only. Then, we
obtain our video model (i.e., S2D), for DFER, by inserting Temporal-Modeling
Adapters (TMAs) into the image model. MCPs enhance facial expression features
with landmark-aware features inferred by an off-the-shelf facial landmark
detector. And the TMAs capture and model the relationships of dynamic changes
in facial expressions, effectively extending the pre-trained image model for
videos. Notably, MCPs and TMAs only increase a fraction of trainable parameters
(less than +10\%) to the original image model. Moreover, we present a novel
Emotion-Anchors (i.e., reference samples for each emotion category) based
Self-Distillation Loss to reduce the detrimental influence of ambiguous emotion
labels, further enhancing our S2D. Experiments conducted on popular SFER and
DFER datasets show that we achieve the state of the art.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05448" title="Abstract">arXiv:2312.05448</a> [<a href="/pdf/2312.05448" title="Download PDF">pdf</a>, <a href="/format/2312.05448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation of a State of the Art Text-to-SQL Model: Lessons  Learned and Challenges Found
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manotas%2C+I">Irene Manotas</a>, 
<a href="/search/cs?searchtype=author&query=Popescu%2C+O">Octavian Popescu</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+N+P+A">Ngoc Phuoc An Vo</a>, 
<a href="/search/cs?searchtype=author&query=Sheinin%2C+V">Vadim Sheinin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">There are many recent advanced developments for the Text-to-SQL task, where
the Picard model is one of the the top performing models as measured by the
Spider dataset competition. However, bringing Text-to-SQL systems to realistic
use-cases through domain adaptation remains a tough challenge. We analyze how
well the base T5 Language Model and Picard perform on query structures
different from the Spider dataset, we fine-tuned the base model on the Spider
data and on independent databases (DB). To avoid accessing the DB content
online during inference, we also present an alternative way to disambiguate the
values in an input question using a rule-based approach that relies on an
intermediate representation of the semantic concepts of an input question. In
our results we show in what cases T5 and Picard can deliver good performance,
we share the lessons learned, and discuss current domain adaptation challenges.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05449" title="Abstract">arXiv:2312.05449</a> [<a href="/pdf/2312.05449" title="Download PDF">pdf</a>, <a href="/format/2312.05449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TALDS-Net: Task-Aware Adaptive Local Descriptors Selection for Few-shot  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Q">Qian Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziyin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fanzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Few-shot image classification aims to classify images from unseen novel
classes with few samples. Recent works demonstrate that deep local descriptors
exhibit enhanced representational capabilities compared to image-level
features. However, most existing methods solely rely on either employing all
local descriptors or directly utilizing partial descriptors, potentially
resulting in the loss of crucial information. Moreover, these methods primarily
emphasize the selection of query descriptors while overlooking support
descriptors. In this paper, we propose a novel Task-Aware Adaptive Local
Descriptors Selection Network (TALDS-Net), which exhibits the capacity for
adaptive selection of task-aware support descriptors and query descriptors.
Specifically, we compare the similarity of each local support descriptor with
other local support descriptors to obtain the optimal support descriptor subset
and then compare the query descriptors with the optimal support subset to
obtain discriminative query descriptors. Extensive experiments demonstrate that
our TALDS-Net outperforms state-of-the-art methods on both general and
fine-grained datasets.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05451" title="Abstract">arXiv:2312.05451</a> [<a href="/pdf/2312.05451" title="Download PDF">pdf</a>, <a href="/ps/2312.05451" title="Download PostScript">ps</a>, <a href="/format/2312.05451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Scheduling of Building Battery Systems Under Electrical Load  Uncertainty Using Dynamic Markov Decision Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharadga%2C+H">Hussein Sharadga</a>, 
<a href="/search/eess?searchtype=author&query=Zakeri%2C+G">Golbon Zakeri</a>, 
<a href="/search/eess?searchtype=author&query=Hayajneh%2C+A">Abdullah Hayajneh</a>, 
<a href="/search/eess?searchtype=author&query=Pritchard%2C+G">Geoff Pritchard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In response to the increasing deployment of battery storage systems for cost
reduction and grid stress mitigation, this study presents the development of a
new real-time Markov decision process model to efficiently schedule battery
systems in buildings under electrical load uncertainty. The proposed model
incorporates quantile Fourier regression for load fitting, leading to a
large-scale optimization problem with approximately a million decision
variables and constraints. To address this complexity, the problem is
formulated as a linear program and solved using a commercial solver, ensuring
effective navigation and identification of optimal solutions. The model's
performance is evaluated by considering different pricing policies and
scenarios, including demand peak shaving. Validation of the Markov model is
conducted using one year of historical demand data from a school. Findings
indicate that MDP performance in adapting to uncertain loads can range from 30
to 99% depending on the pricing policy.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05454" title="Abstract">arXiv:2312.05454</a> [<a href="/pdf/2312.05454" title="Download PDF">pdf</a>, <a href="/format/2312.05454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Evaluation for Domain Identification of Unknown Classes in  Open-World Recognition: A Proposal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alfarisy%2C+G+A+F">Gusti Ahmad Fanshuri Alfarisy</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+O+A">Owais Ahmed Malik</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+O+W">Ong Wee Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Open-World Recognition (OWR) is an emerging field that makes a machine
learning model competent in rejecting the unknowns, managing them, and
incrementally adding novel samples to the base knowledge. However, this broad
objective is not practical for an agent that works on a specific task. Not all
rejected samples will be used for learning continually in the future. Some
novel images in the open environment may not belong to the domain of interest.
Hence, identifying the unknown in the domain of interest is essential for a
machine learning model to learn merely the important samples. In this study, we
propose an evaluation protocol for estimating a model's capability in
separating unknown in-domain (ID) and unknown out-of-domain (OOD). We evaluated
using three approaches with an unknown domain and demonstrated the possibility
of identifying the domain of interest using the pre-trained parameters through
traditional transfer learning, Automated Machine Learning (AutoML), and Nearest
Class Mean (NCM) classifier with First Integer Neighbor Clustering Hierarchy
(FINCH). We experimented with five different domains: garbage, food, dogs,
plants, and birds. The results show that all approaches can be used as an
initial baseline yielding a good accuracy. In addition, a Balanced Accuracy
(BACCU) score from a pre-trained model indicates a tendency to excel in one or
more domains of interest. We observed that MobileNetV3 yielded the highest
BACCU score for the garbage domain and surpassed complex models such as the
transformer network. Meanwhile, our results also suggest that a strong
representation in the pre-trained model is important for identifying unknown
classes in the same domain. This study could open the bridge toward open-world
recognition in domain-specific tasks where the relevancy of the unknown classes
is vital.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05456" title="Abstract">arXiv:2312.05456</a> [<a href="/pdf/2312.05456" title="Download PDF">pdf</a>, <a href="/format/2312.05456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the calibration of compartmental epidemiological models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nikunj Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+A">Anh Mai</a>, 
<a href="/search/cs?searchtype=author&query=Abouzied%2C+A">Azza Abouzied</a>, 
<a href="/search/cs?searchtype=author&query=Shasha%2C+D">Dennis Shasha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Physics and Society (physics.soc-ph); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Epidemiological compartmental models are useful for understanding infectious
disease propagation and directing public health policy decisions. Calibration
of these models is an important step in offering accurate forecasts of disease
dynamics and the effectiveness of interventions. In this study, we present an
overview of calibrating strategies that can be employed, including several
optimization methods and reinforcement learning (RL). We discuss the benefits
and drawbacks of these methods and highlight relevant practical conclusions
from our experiments. Optimization methods iteratively adjust the parameters of
the model until the model output matches the available data, whereas RL uses
trial and error to learn the optimal set of parameters by maximizing a reward
signal. Finally, we discuss how the calibration of parameters of
epidemiological compartmental models is an emerging field that has the
potential to improve the accuracy of disease modeling and public health
decision-making. Further research is needed to validate the effectiveness and
scalability of these approaches in different epidemiological contexts. All
codes and resources are available on
\url{https://github.com/Nikunj-Gupta/On-the-Calibration-of-Compartmental-Epidemiological-Models}.
We hope this work can facilitate related research.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05459" title="Abstract">arXiv:2312.05459</a> [<a href="/pdf/2312.05459" title="Download PDF">pdf</a>, <a href="/format/2312.05459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLoW3 -- Web3 Empowered Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurada%2C+V+R">Venkata Raghava Kurada</a>, 
<a href="/search/cs?searchtype=author&query=Baruah%2C+P+K">Pallava Kumar Baruah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Federated Learning is susceptible to various kinds of attacks like Data
Poisoning, Model Poisoning and Man in the Middle attack. We perceive Federated
Learning as a hierarchical structure, a federation of nodes with validators as
the head. The process of validation is done through consensus by employing
Novelty Detection and Snowball protocol, to identify valuable and relevant
updates while filtering out potentially malicious or irrelevant updates, thus
preventing Model Poisoning attacks. The opinion of the validators is recorded
in blockchain and trust score is calculated. In case of lack of consensus,
trust score is used to determine the impact of validators on the global model.
A hyperparameter is introduced to guide the model generation process, either to
rely on consensus or on trust score. This approach ensures transparency and
reliability in the aggregation process and allows the global model to benefit
from insights of most trusted nodes. In the training phase, the combination of
IPFS , PGP encryption provides : a) secure and decentralized storage b)
mitigates single point of failure making this system reliable and c) resilient
against man in the middle attack. The system is realized by implementing in
python and Foundry for smart contract development. Global Model is tested
against data poisoning by flipping the labels and by introducing malicious
nodes. Results found to be similar to that of Flower.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05461" title="Abstract">arXiv:2312.05461</a> [<a href="/pdf/2312.05461" title="Download PDF">pdf</a>, <a href="/format/2312.05461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STREAMLINE: An Automated Machine Learning Pipeline for Biomedicine  Applied to Examine the Utility of Photography-Based Phenotypes for OSA  Prediction Across International Sleep Centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urbanowicz%2C+R+J">Ryan J. Urbanowicz</a>, 
<a href="/search/cs?searchtype=author&query=Bandhey%2C+H">Harsh Bandhey</a>, 
<a href="/search/cs?searchtype=author&query=Keenan%2C+B+T">Brendan T. Keenan</a>, 
<a href="/search/cs?searchtype=author&query=Maislin%2C+G">Greg Maislin</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Sy Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Mowery%2C+D+L">Danielle L. Mowery</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+S+M">Shannon M. Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Mazzotti%2C+D+R">Diego R. Mazzotti</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Fang Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q+Y">Qing Yun Li</a>, 
<a href="/search/cs?searchtype=author&query=Penzel%2C+T">Thomas Penzel</a>, 
<a href="/search/cs?searchtype=author&query=Tufik%2C+S">Sergio Tufik</a>, 
<a href="/search/cs?searchtype=author&query=Bittencourt%2C+L">Lia Bittencourt</a>, 
<a href="/search/cs?searchtype=author&query=Gislason%2C+T">Thorarinn Gislason</a>, 
<a href="/search/cs?searchtype=author&query=de+Chazal%2C+P">Philip de Chazal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+B">Bhajan Singh</a>, 
<a href="/search/cs?searchtype=author&query=McArdle%2C+N">Nigel McArdle</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning-Hung Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pack%2C+A">Allan Pack</a>, 
<a href="/search/cs?searchtype=author&query=Schwab%2C+R+J">Richard J. Schwab</a>, 
<a href="/search/cs?searchtype=author&query=Cistulli%2C+P+A">Peter A. Cistulli</a>, 
<a href="/search/cs?searchtype=author&query=Magalang%2C+U+J">Ulysses J. Magalang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures, 1 table, 1 supplemental information document (77 pages), and 7 ancillary files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While machine learning (ML) includes a valuable array of tools for analyzing
biomedical data, significant time and expertise is required to assemble
effective, rigorous, and unbiased pipelines. Automated ML (AutoML) tools seek
to facilitate ML application by automating a subset of analysis pipeline
elements. In this study we develop and validate a Simple, Transparent,
End-to-end Automated Machine Learning Pipeline (STREAMLINE) and apply it to
investigate the added utility of photography-based phenotypes for predicting
obstructive sleep apnea (OSA); a common and underdiagnosed condition associated
with a variety of health, economic, and safety consequences. STREAMLINE is
designed to tackle biomedical binary classification tasks while adhering to
best practices and accommodating complexity, scalability, reproducibility,
customization, and model interpretation. Benchmarking analyses validated the
efficacy of STREAMLINE across data simulations with increasingly complex
patterns of association. Then we applied STREAMLINE to evaluate the utility of
demographics (DEM), self-reported comorbidities (DX), symptoms (SYM), and
photography-based craniofacial (CF) and intraoral (IO) anatomy measures in
predicting any OSA or moderate/severe OSA using 3,111 participants from Sleep
Apnea Global Interdisciplinary Consortium (SAGIC). OSA analyses identified a
significant increase in ROC-AUC when adding CF to DEM+DX+SYM to predict
moderate/severe OSA. A consistent but non-significant increase in PRC-AUC was
observed with the addition of each subsequent feature set to predict any OSA,
with CF and IO yielding minimal improvements. Application of STREAMLINE to OSA
data suggests that CF features provide additional value in predicting
moderate/severe OSA, but neither CF nor IO features meaningfully improved the
prediction of any OSA beyond established demographics, comorbidity and symptom
characteristics.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05462" title="Abstract">arXiv:2312.05462</a> [<a href="/pdf/2312.05462" title="Download PDF">pdf</a>, <a href="/format/2312.05462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanReg: Self-supervised Non-rigid Registration of Human Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhicheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianjiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a novel registration framework, HumanReg, that
learns a non-rigid transformation between two human point clouds end-to-end. We
introduce body prior into the registration process to efficiently handle this
type of point cloud. Unlike most exsisting supervised registration techniques
that require expensive point-wise flow annotations, HumanReg can be trained in
a self-supervised manner benefiting from a set of novel loss functions. To make
our model better converge on real-world data, we also propose a pretraining
strategy, and a synthetic dataset (HumanSyn4D) consists of dynamic, sparse
human point clouds and their auto-generated ground truth annotations. Our
experiments shows that HumanReg achieves state-of-the-art performance on
CAPE-512 dataset and gains a qualitative result on another more challenging
real-world dataset. Furthermore, our ablation studies demonstrate the
effectiveness of our synthetic dataset and novel loss functions. Our code and
synthetic dataset is available at https://github.com/chenyifanthu/HumanReg.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05463" title="Abstract">arXiv:2312.05463</a> [<a href="/pdf/2312.05463" title="Download PDF">pdf</a>, <a href="/ps/2312.05463" title="Download PostScript">ps</a>, <a href="/format/2312.05463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Socialization Restrictions Prevent Restaurants from Becoming Covid  Hotspots?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+A">Aviral Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Kharkwal%2C+H">Himanshu Kharkwal</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+J">Jaideep Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Sciences ACTA SCIENTIFIC Journal Volume 3 Issue 9, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Simulation models for infection spread can help understand what factors play
a major role in infection spread. Health agencies like the Center for Disease
Control (CDC) can accordingly mandate effective guidelines to curb the spread.
We built an infection spread model to simulate disease propagation through
airborne transmission to study the impact of restaurant operational policies on
the Covid-19 infections. We use the Wells-Riley model to measure the expected
value of new infections in a given time-frame in a particular location. For the
purpose of this study, we have restricted our analysis to bars and restaurants
in the Minneapolis-St. Paul region. Our model helps identify disease hotspots
within the Twin Cities and proves that stay-at-home orders were effective
during the recent lockdown, and the people typically followed the social
distancing guidelines. To arrive at this conclusion, we performed significance
testing by considering specific hypothetical scenarios. At the end of the
study, we discuss the reasoning behind the hotspots, and make suggestions that
could help avoid them.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05464" title="Abstract">arXiv:2312.05464</a> [<a href="/pdf/2312.05464" title="Download PDF">pdf</a>, <a href="/format/2312.05464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying and Mitigating Model Failures through Few-shot CLIP-aided  Diffusion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chegini%2C+A">Atoosa Chegini</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models can encounter unexpected failures, especially when
dealing with challenging sub-populations. One common reason for these failures
is the occurrence of objects in backgrounds that are rarely seen during
training. To gain a better understanding of these failure modes,
human-interpretable descriptions are crucial for further analysis and
improvement which is expensive. In this study, we propose an end-to-end
framework that utilizes the capabilities of large language models (ChatGPT) and
vision-language deep models (CLIP) to generate text descriptions of failure
modes associated with spurious correlations (e.g. rarely seen backgrounds)
without human-in-the-loop intervention. These descriptions can be used to
generate synthetic data using generative models, such as diffusion models. The
model can now use this generated data to learn from its weaknesses and enhance
its performance on backgrounds that are uncommon for each class of data. Our
approach serves as a broad solution, promising progress in comprehending model
failure modes and strengthening deep learning models across a wide range of
failure scenarios (e.g. bacckgrounds, colors) automatically in a few-shot
manner. Our experiments have shown remarkable \textbf{improvements in accuracy
($\sim \textbf{21%}$)} on hard sub-populations (particularly for wrong
background association) across $40$ different models, such as ResNets,
EfficientNets, DenseNets, Vision Transformer (ViT), SwAVs, MoCos, DINOs, and
CLIPs on various datasets such as ImageNet-1000, CIFAR-10, and CIFAR-100.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05465" title="Abstract">arXiv:2312.05465</a> [<a href="/pdf/2312.05465" title="Download PDF">pdf</a>, <a href="/format/2312.05465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Task-Relevant Loss Functions in Meta-Reinforcement Learning and  Online LQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jaeuk Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Giho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Howon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Joonho Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+I">Insoon Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Designing a competent meta-reinforcement learning (meta-RL) algorithm in
terms of data usage remains a central challenge to be tackled for its
successful real-world applications. In this paper, we propose a
sample-efficient meta-RL algorithm that learns a model of the system or
environment at hand in a task-directed manner. As opposed to the standard
model-based approaches to meta-RL, our method exploits the value information in
order to rapidly capture the decision-critical part of the environment. The key
component of our method is the loss function for learning the task inference
module and the system model that systematically couples the model discrepancy
and the value estimate, thereby facilitating the learning of the policy and the
task inference module with a significantly smaller amount of data compared to
the existing meta-RL algorithms. The idea is also extended to a non-meta-RL
setting, namely an online linear quadratic regulator (LQR) problem, where our
method can be simplified to reveal the essence of the strategy. The proposed
method is evaluated in high-dimensional robotic control and online LQR
problems, empirically verifying its effectiveness in extracting information
indispensable for solving the tasks from observations in a sample efficient
manner.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05467" title="Abstract">arXiv:2312.05467</a> [<a href="/pdf/2312.05467" title="Download PDF">pdf</a>, <a href="/ps/2312.05467" title="Download PostScript">ps</a>, <a href="/format/2312.05467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textual Toxicity in Social Media: Understanding the Bangla Toxic  Language Expressed in Facebook Comment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashid%2C+M+M+O">Mohammad Mamun Or Rashid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social Media is a repository of digital literature including user-generated
content. The users of social media are expressing their opinion with diverse
mediums such as text, emojis, memes, and also through other visual and textual
mediums. A major portion of these media elements could be treated as harmful to
others and they are known by many words including Cyberbullying and Toxic
Language . The goal of this research paper is to analyze a curated and
value-added dataset of toxic language titled ToxLex_bn . It is an exhaustive
wordlist that can be used as classifier material to detect toxicity in social
media. The toxic language/script used by the Bengali community as
cyberbullying, hate speech and moral policing became major trends in social
media culture in Bangladesh and West Bengal. The toxicity became so high that
the victims has to post as a counter or release explanation video for the
haters. Most cases are pointed to women celebrity and their relation, dress,
lifestyle are became trolled and toxicity flooded in comments boxes. Not only
celebrity bashing but also hates occurred between Hindu Muslims,
India-Bangladesh, Two opponents of 1971 and these are very common for virtual
conflict in the comment thread. Even many times facebook comment causes sue and
legal matters in Bangladesh and thus it requires more study. In this study, a
Bangla toxic language dataset has been analyzed which was inputted by the user
in Bengali script &amp; language. For this, about 1968 unique bigrams or phrases as
wordlists have been analyzed which are derived from 2207590 comments. It is
assumed that this analysis will reinforce the detection of Bangla's toxic
language used in social media and thus cure this virtual disease.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05468" title="Abstract">arXiv:2312.05468</a> [<a href="/pdf/2312.05468" title="Download PDF">pdf</a>, <a href="/ps/2312.05468" title="Download PostScript">ps</a>, <a href="/format/2312.05468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image and Data Mining in Reticular Chemistry Using GPT-4V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhiling Zheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiguo He</a>, 
<a href="/search/cs?searchtype=author&query=Khattab%2C+O">Omar Khattab</a>, 
<a href="/search/cs?searchtype=author&query=Rampal%2C+N">Nakul Rampal</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M+A">Matei A. Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Borgs%2C+C">Christian Borgs</a>, 
<a href="/search/cs?searchtype=author&query=Chayes%2C+J+T">Jennifer T. Chayes</a>, 
<a href="/search/cs?searchtype=author&query=Yaghi%2C+O+M">Omar M. Yaghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Materials Science (cond-mat.mtrl-sci); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The integration of artificial intelligence into scientific research has
reached a new pinnacle with GPT-4V, a large language model featuring enhanced
vision capabilities, accessible through ChatGPT or an API. This study
demonstrates the remarkable ability of GPT-4V to navigate and obtain complex
data for metal-organic frameworks, especially from graphical sources. Our
approach involved an automated process of converting 346 scholarly articles
into 6240 images, which represents a benchmark dataset in this task, followed
by deploying GPT-4V to categorize and analyze these images using natural
language prompts. This methodology enabled GPT-4V to accurately identify and
interpret key plots integral to MOF characterization, such as nitrogen
isotherms, PXRD patterns, and TGA curves, among others, with accuracy and
recall above 93%. The model's proficiency in extracting critical information
from these plots not only underscores its capability in data mining but also
highlights its potential in aiding the creation of comprehensive digital
databases for reticular chemistry. In addition, the extracted nitrogen isotherm
data from the selected literature allowed for a comparison between theoretical
and experimental porosity values for over 200 compounds, highlighting certain
discrepancies and underscoring the importance of integrating computational and
experimental data. This work highlights the potential of AI in accelerating
scientific discovery and innovation, bridging the gap between computational
tools and experimental research, and paving the way for more efficient,
inclusive, and comprehensive scientific inquiry.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05470" title="Abstract">arXiv:2312.05470</a> [<a href="/pdf/2312.05470" title="Download PDF">pdf</a>, <a href="/format/2312.05470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate Constant Matrix Contraction Method for Stiff Master Equations with  Detailed Balance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Iwata%2C+S">Satoru Iwata</a>, 
<a href="/search/math?searchtype=author&query=Oki%2C+T">Taihei Oki</a>, 
<a href="/search/math?searchtype=author&query=Sakaue%2C+S">Shinsaku Sakaue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper considers master equations for Markovian kinetic schemes that
possess the detailed balance property. Chemical kinetics, as a prime example,
often yields large-scale, highly stiff equations. Based on chemical intuitions,
Sumiya et al. (2015) presented the rate constant matrix contraction (RCMC)
method that computes approximate solutions to such intractable systems.
<br />This paper aims to establish a mathematical foundation for the RCMC method.
We present a reformulated RCMC method in terms of matrix computation, deriving
the method from several natural requirements. We then perform a theoretical
error analysis based on eigendecomposition and discuss implementation details
caring about computational efficiency and numerical stability. Through
numerical experiments on synthetic and real kinetic models, we validate the
efficiency, numerical stability, and accuracy of the presented method.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05471" title="Abstract">arXiv:2312.05471</a> [<a href="/pdf/2312.05471" title="Download PDF">pdf</a>, <a href="/format/2312.05471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Analysis of Team Collaborative Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perera%2C+I">Ian Perera</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M">Matthew Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Wilber%2C+C">Carson Wilber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Natural language analysis of human collaborative chat dialogues is an
understudied domain with many unique challenges: a large number of dialogue act
labels, underspecified and dynamic tasks, interleaved topics, and long-range
contextual dependence. While prior work has studied broad metrics of team
dialogue and associated performance using methods such as LSA, there has been
little effort in generating fine-grained descriptions of team dynamics and
individual performance from dialogue. We describe initial work towards
developing an explainable analytics tool in the software development domain
using Slack chats mined from our organization, including generation of a novel,
hierarchical labeling scheme; design of descriptive metrics based on the
frequency of occurrence of dialogue acts; and initial results using a
transformer + CRF architecture to incorporate long-range context.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05473" title="Abstract">arXiv:2312.05473</a> [<a href="/pdf/2312.05473" title="Download PDF">pdf</a>, <a href="/format/2312.05473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self Model for Embodied Intelligence: Modeling Full-Body Human  Musculoskeletal System and Locomotion Control with Hierarchical  Low-Dimensional Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kaibo He</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+C">Chenhui Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yanan Sui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Modeling and control of the human musculoskeletal system is important for
understanding human motion, developing embodied intelligence, and optimizing
human-robot interaction systems. However, current open-source models are
restricted to a limited range of body parts and often with a reduced number of
muscles. There is also a lack of algorithms capable of controlling over 600
muscles to generate reasonable human movements. To fill this gap, we build a
comprehensive musculoskeletal model with 90 body segments, 206 joints, and 700
muscle-tendon units, allowing simulation of full-body dynamics and interaction
with various devices. We develop a new algorithm using low-dimensional
representation and hierarchical deep reinforcement learning to achieve
state-of-the-art full-body control. We validate the effectiveness of our model
and algorithm in simulations and on real human locomotion data. The
musculoskeletal model, along with its control algorithm, will be made available
to the research community to promote a deeper understanding of human motion
control and better design of interactive robots.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05474" title="Abstract">arXiv:2312.05474</a> [<a href="/pdf/2312.05474" title="Download PDF">pdf</a>, <a href="/ps/2312.05474" title="Download PostScript">ps</a>, <a href="/format/2312.05474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The duals of narrow-sense BCH codes with length $\frac{q^m-1}&#x3bb;$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chengliang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dabin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">BCH codes are an interesting class of cyclic codes due to their efficient
encoding and decoding algorithms. In the past sixty years, a lot of progress on
the study of BCH codes has been made, but little is known about the properties
of their duals. Recently, in order to study the duals of BCH codes and the
lower bounds on their minimum distances, a new concept called dually-BCH code
was proposed by authors in \cite{GDL21}. In this paper, the lower bounds on the
minimum distances of the duals of narrow-sense BCH codes with length
$\frac{q^m-1}{\lambda}$ over $\mathbb{F}_q$ are developed, where $\lambda$ is a
positive integer satisfying $\lambda\, |\, q-1$, or $\lambda=q^s-1$ and $s\,
|\,m$. In addition, the sufficient and necessary conditions in terms of the
designed distances for these codes being dually-BCH codes are presented. Many
considered codes in \cite{GDL21} and \cite{Wang23} are the special cases of the
codes showed in this paper.
<br />Our lower bounds on the minimum distances of the duals of BCH codes include
the bounds stated in \cite{GDL21} as a special case. Several examples show that
the lower bounds are good in some cases.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05476" title="Abstract">arXiv:2312.05476</a> [<a href="/pdf/2312.05476" title="Download PDF">pdf</a>, <a href="/format/2312.05476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Naturalness of AI-Generated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The proliferation of Artificial Intelligence-Generated Images (AGIs) has
greatly expanded the Image Naturalness Assessment (INA) problem. Different from
early definitions that mainly focus on tone-mapped images with limited
distortions (e.g., exposure, contrast, and color reproduction), INA on
AI-generated images is especially challenging as it has more diverse contents
and could be affected by factors from multiple perspectives, including
low-level technical distortions and high-level rationality distortions. In this
paper, we take the first step to benchmark and assess the visual naturalness of
AI-generated images. First, we construct the AI-Generated Image Naturalness
(AGIN) database by conducting a large-scale subjective study to collect human
opinions on the overall naturalness as well as perceptions from technical and
rationality perspectives. AGIN verifies that naturalness is universally and
disparately affected by both technical and rationality distortions. Second, we
propose the Joint Objective Image Naturalness evaluaTor (JOINT), to
automatically learn the naturalness of AGIs that aligns human ratings.
Specifically, JOINT imitates human reasoning in naturalness evaluation by
jointly learning both technical and rationality perspectives. Experimental
results show our proposed JOINT significantly surpasses baselines for providing
more subjectively consistent results on naturalness assessment. Our database
and code will be released in https://github.com/zijianchen98/AGIN.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05479" title="Abstract">arXiv:2312.05479</a> [<a href="/pdf/2312.05479" title="Download PDF">pdf</a>, <a href="/format/2312.05479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Sparsity in Graph Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xueqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Transformers (GTs) have achieved impressive results on various
graph-related tasks. However, the huge computational cost of GTs hinders their
deployment and application, especially in resource-constrained environments.
Therefore, in this paper, we explore the feasibility of sparsifying GTs, a
significant yet under-explored topic. We first discuss the redundancy of GTs
based on the characteristics of existing GT models, and then propose a
comprehensive \textbf{G}raph \textbf{T}ransformer \textbf{SP}arsification
(GTSP) framework that helps to reduce the computational complexity of GTs from
four dimensions: the input graph data, attention heads, model layers, and model
weights. Specifically, GTSP designs differentiable masks for each individual
compressible component, enabling effective end-to-end pruning. We examine our
GTSP through extensive experiments on prominent GTs, including GraphTrans,
Graphormer, and GraphGPS. The experimental results substantiate that GTSP
effectively cuts computational costs, accompanied by only marginal decreases in
accuracy or, in some cases, even improvements. For instance, GTSP yields a
reduction of 30\% in Floating Point Operations while contributing to a 1.8\%
increase in Area Under the Curve accuracy on OGBG-HIV dataset. Furthermore, we
provide several insights on the characteristics of attention heads and the
behavior of attention mechanisms, all of which have immense potential to
inspire future research endeavors in this domain.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05482" title="Abstract">arXiv:2312.05482</a> [<a href="/pdf/2312.05482" title="Download PDF">pdf</a>, <a href="/format/2312.05482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BARET : Balanced Attention based Real image Editing driven by  Target-text Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yuming Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fanyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jingwen Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yunjie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guo-Jun Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image editing approaches with diffusion models have been rapidly developed,
yet their applicability are subject to requirements such as specific editing
types (e.g., foreground or background object editing, style transfer), multiple
conditions (e.g., mask, sketch, caption), and time consuming fine-tuning of
diffusion models. For alleviating these limitations and realizing efficient
real image editing, we propose a novel editing technique that only requires an
input image and target text for various editing types including non-rigid edits
without fine-tuning diffusion model. Our method contains three novelties:(I)
Target-text Inversion Schedule (TTIS) is designed to fine-tune the input target
text embedding to achieve fast image reconstruction without image caption and
acceleration of convergence.(II) Progressive Transition Scheme applies
progressive linear interpolation between target text embedding and its
fine-tuned version to generate transition embedding for maintaining non-rigid
editing capability.(III) Balanced Attention Module (BAM) balances the tradeoff
between textual description and image semantics.By the means of combining
self-attention map from reconstruction process and cross-attention map from
transition process, the guidance of target text embeddings in diffusion process
is optimized.In order to demonstrate editing capability, effectiveness and
efficiency of the proposed BARET, we have conducted extensive qualitative and
quantitative experiments. Moreover, results derived from user study and
ablation study further prove the superiority over other methods.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05483" title="Abstract">arXiv:2312.05483</a> [<a href="/pdf/2312.05483" title="Download PDF">pdf</a>, <a href="/ps/2312.05483" title="Download PostScript">ps</a>, <a href="/format/2312.05483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teamwork Dimensions Classification Using BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+E">Elizabeth Koh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print, AIED23 LBD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Teamwork is a necessary competency for students that is often inadequately
assessed. Towards providing a formative assessment of student teamwork, an
automated natural language processing approach was developed to identify
teamwork dimensions of students' online team chat. Developments in the field of
natural language processing and artificial intelligence have resulted in
advanced deep transfer learning approaches namely the Bidirectional Encoder
Representations from Transformers (BERT) model that allow for more in-depth
understanding of the context of the text. While traditional machine learning
algorithms were used in the previous work for the automatic classification of
chat messages into the different teamwork dimensions, our findings have shown
that classifiers based on the pre-trained language model BERT provides improved
classification performance, as well as much potential for generalizability in
the language use of varying team chat contexts and team member demographics.
This model will contribute towards an enhanced learning analytics tool for
teamwork assessment and feedback.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05486" title="Abstract">arXiv:2312.05486</a> [<a href="/pdf/2312.05486" title="Download PDF">pdf</a>, <a href="/format/2312.05486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeFlow: A Comprehensive Understanding on Diffusion Probabilistic  Models via Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bowen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shibao Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">The blooming diffusion probabilistic models (DPMs) have garnered significant
interest due to their impressive performance and the elegant inspiration they
draw from physics. While earlier DPMs relied upon the Markovian assumption,
recent methods based on differential equations have been rapidly applied to
enhance the efficiency and capabilities of these models. However, a theoretical
interpretation encapsulating these diverse algorithms is insufficient yet
pressingly required to guide further development of DPMs. In response to this
need, we present FreeFlow, a framework that provides a thorough explanation of
the diffusion formula as time-dependent optimal transport, where the
evolutionary pattern of probability density is given by the gradient flows of a
functional defined in Wasserstein space. Crucially, our framework necessitates
a unified description that not only clarifies the subtle mechanism of DPMs but
also indicates the roots of some defects through creative involvement of
Lagrangian and Eulerian views to understand the evolution of probability flow.
We particularly demonstrate that the core equation of FreeFlow condenses all
stochastic and deterministic DPMs into a single case, showcasing the
expansibility of our method. Furthermore, the Riemannian geometry employed in
our work has the potential to bridge broader subjects in mathematics, which
enable the involvement of more profound tools for the establishment of more
outstanding and generalized models in the future.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05488" title="Abstract">arXiv:2312.05488</a> [<a href="/pdf/2312.05488" title="Download PDF">pdf</a>, <a href="/format/2312.05488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Serve as Rational Players in Game Theory? A  Systematic Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Caoyun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jindou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Game theory, as an analytical tool, is frequently utilized to analyze human
behavior in social science research. With the high alignment between the
behavior of Large Language Models (LLMs) and humans, a promising research
direction is to employ LLMs as substitutes for humans in game experiments,
enabling social science research. However, despite numerous empirical
researches on the combination of LLMs and game theory, the capability
boundaries of LLMs in game theory remain unclear. In this research, we endeavor
to systematically analyze LLMs in the context of game theory. Specifically,
rationality, as the fundamental principle of game theory, serves as the metric
for evaluating players' behavior -- building a clear desire, refining belief
about uncertainty, and taking optimal actions. Accordingly, we select three
classical games (dictator game, Rock-Paper-Scissors, and ring-network game) to
analyze to what extent LLMs can achieve rationality in these three aspects. The
experimental results indicate that even the current state-of-the-art LLM
(GPT-4) exhibits substantial disparities compared to humans in game theory. For
instance, LLMs struggle to build desires based on uncommon preferences, fail to
refine belief from many simple patterns, and may overlook or modify refined
belief when taking actions. Therefore, we consider that introducing LLMs into
game experiments in the field of social science should be approached with
greater caution.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05490" title="Abstract">arXiv:2312.05490</a> [<a href="/pdf/2312.05490" title="Download PDF">pdf</a>, <a href="/format/2312.05490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shapley Values-enabled Progressive Pseudo Bag Augmentation for Whole  Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Renao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiehe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yonghong He</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tian Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In computational pathology, whole slide image (WSI) classification presents a
formidable challenge due to its gigapixel resolution and limited fine-grained
annotations. Multiple instance learning (MIL) offers a weakly supervised
solution, yet refining instance-level information from bag-level labels remains
complex. While most of the conventional MIL methods use attention scores to
estimate instance importance scores (IIS) which contribute to the prediction of
the slide labels, these often lead to skewed attention distributions and
inaccuracies in identifying crucial instances. To address these issues, we
propose a new approach inspired by cooperative game theory: employing Shapley
values to assess each instance's contribution, thereby improving IIS
estimation. The computation of the Shapley value is then accelerated using
attention, meanwhile retaining the enhanced instance identification and
prioritization. We further introduce a framework for the progressive assignment
of pseudo bags based on estimated IIS, encouraging more balanced attention
distributions in MIL models. Our extensive experiments on CAMELYON-16, BRACS,
and TCGA-LUNG datasets show our method's superiority over existing
state-of-the-art approaches, offering enhanced interpretability and class-wise
insights. We will release the code upon acceptance.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05491" title="Abstract">arXiv:2312.05491</a> [<a href="/pdf/2312.05491" title="Download PDF">pdf</a>, <a href="/format/2312.05491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Captum to Explain Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miglani%2C+V">Vivek Miglani</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A">Aobo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Markosyan%2C+A+H">Aram H. Markosyan</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Olano%2C+D">Diego Garcia-Olano</a>, 
<a href="/search/cs?searchtype=author&query=Kokhlikyan%2C+N">Narine Kokhlikyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Captum is a comprehensive library for model explainability in PyTorch,
offering a range of methods from the interpretability literature to enhance
users' understanding of PyTorch models. In this paper, we introduce new
features in Captum that are specifically designed to analyze the behavior of
generative language models. We provide an overview of the available
functionalities and example applications of their potential for understanding
learned associations within generative language models.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05492" title="Abstract">arXiv:2312.05492</a> [<a href="/pdf/2312.05492" title="Download PDF">pdf</a>, <a href="/format/2312.05492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cuSZ-I: High-Fidelity Error-Bounded Lossy Compression for Scientific  Data on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiannan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shixun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Sheng Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Boyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yafan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zizhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cappello%2C+F">Franck Cappello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICDE '24, 2nd round
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Error-bounded lossy compression is a critical technique for significantly
reducing scientific data volumes. Compared to CPU-based scientific compressors,
GPU-accelerated compressors exhibit substantially higher throughputs, which can
thus better adapt to GPU-based scientific simulation applications. However, a
critical limitation still lies in all existing GPU-accelerated error-bounded
lossy compressors: they suffer from low compression ratios, which strictly
restricts their scope of usage. To address this limitation, in this paper, we
propose a new design of GPU-accelerated scientific error-bounded lossy
compressor, namely cuSZ-I, which has achieved the following contributions: (1)
A brand new GPU-customized interpolation-based data pre-diction method is
raised in cuSZ-I for extensively improving the compression ratio and the
decompression data quality. (2) The Huffman encoding module in cuSZ-I has been
improved for both efficiency and stability. (3) cuSZ-I is the first work to
integrate the highly effective NVIDIA bitcomp lossless compression module to
maximally boost the compression ratio for GPU-accelerated lossy compressors
with nearly negligible speed degradation. In experimental evaluations, with the
same magnitude of compression throughput as existing GPU-accelerated
compressors, in terms of compression ratio and quality, cuSZ-I outperforms
other state-of-the-art GPU-based scientific lossy compressors to a significant
extent. It gains compression ratio improvements by up to 500% under the same
error bound or PSNR. In several real-world use cases, cuSZ-I also achieves the
optimized performance, having the minimized time cost for distributed lossy
data transmission tasks and the highest decompression data visualization
quality.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05496" title="Abstract">arXiv:2312.05496</a> [<a href="/pdf/2312.05496" title="Download PDF">pdf</a>, <a href="/format/2312.05496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Cross-Modal Steganography via Implicit Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Seoyun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Sojeong Song</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present INRSteg, an innovative lossless steganography framework based on a
novel data form Implicit Neural Representations (INR) that is modal-agnostic.
Our framework is considered for effectively hiding multiple data without
altering the original INR ensuring high-quality stego data. The neural
representations of secret data are first concatenated to have independent paths
that do not overlap, then weight freezing techniques are applied to the
diagonal blocks of the weight matrices for the concatenated network to preserve
the weights of secret data while additional free weights in the off-diagonal
blocks of weight matrices are fitted to the cover data. Our framework can
perform unexplored cross-modal steganography for various modalities including
image, audio, video, and 3D shapes, and it achieves state-of-the-art
performance compared to previous intra-modal steganographic methods.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05497" title="Abstract">arXiv:2312.05497</a> [<a href="/pdf/2312.05497" title="Download PDF">pdf</a>, <a href="/format/2312.05497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> History Matters: Temporal Knowledge Editing in Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunjian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The imperative task of revising or updating the knowledge stored within large
language models arises from two distinct sources: intrinsic errors inherent in
the model which should be corrected and outdated knowledge due to external
shifts in the real world which should be updated. Prevailing efforts in model
editing conflate these two distinct categories of edits arising from distinct
reasons and directly modify the original knowledge in models into new
knowledge. However, we argue that preserving the model's original knowledge
remains pertinent. Specifically, if a model's knowledge becomes outdated due to
evolving worldly dynamics, it should retain recollection of the historical
knowledge while integrating the newfound knowledge. In this work, we introduce
the task of Temporal Knowledge Editing (TKE) and establish a benchmark AToKe
(Assessment of TempOral Knowledge Editing) to evaluate current model editing
methods. We find that while existing model editing methods are effective at
making models remember new knowledge, the edited model catastrophically forgets
historical knowledge. To address this gap, we propose a simple and general
framework termed Multi-Editing with Time Objective (METO) for enhancing
existing editing models, which edits both historical and new knowledge
concurrently and optimizes the model's prediction for the time of each fact.
Our assessments demonstrate that while AToKe is still difficult, METO maintains
the effectiveness of learning new knowledge and meanwhile substantially
improves the performance of edited models on utilizing historical knowledge.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05499" title="Abstract">arXiv:2312.05499</a> [<a href="/pdf/2312.05499" title="Download PDF">pdf</a>, <a href="/ps/2312.05499" title="Download PostScript">ps</a>, <a href="/format/2312.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C*: A New Bounding Approach for the Moving-Target Traveling Salesman  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Philip%2C+A+G">Allen George Philip</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhongqiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Rathinam%2C+S">Sivakumar Rathinam</a>, 
<a href="/search/cs?searchtype=author&query=Choset%2C+H">Howie Choset</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We introduce a new bounding approach called Continuity* (C*) that provides
optimality guarantees to the Moving-Target Traveling Salesman Problem (MT-TSP).
Our approach relies on relaxing the continuity constraints on the agent's tour.
This is done by partitioning the targets' trajectories into small sub-segments
and allowing the agent to arrive at any point in one of the sub-segments and
depart from any point in the same sub-segment when visiting each target. This
lets us pose the bounding problem as a Generalized Traveling Salesman Problem
(GTSP) in a graph where the cost of traveling an edge requires us to solve a
new problem called the Shortest Feasible Travel (SFT). We also introduce
C*-lite, which follows the same approach as C*, but uses simple and easy to
compute lower-bounds to the SFT. We first prove that the proposed algorithms
provide lower bounds to the MT-TSP. We also provide computational results to
corroborate the performance of C* and C*-lite for instances with up to 15
targets. For the special case where targets travel along lines, we compare our
C* variants with the SOCP based method, which is the current state-of-the-art
solver for MT-TSP. While the SOCP based method performs well for instances with
5 and 10 targets, C* outperforms the SOCP based method for instances with 15
targets. For the general case, on average, our approaches find feasible
solutions within ~4% of the lower bounds for the tested instances.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05502" title="Abstract">arXiv:2312.05502</a> [<a href="/pdf/2312.05502" title="Download PDF">pdf</a>, <a href="/format/2312.05502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisoning $\times$ Evasion: Symbiotic Adversarial Robustness for Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erdogan%2C+E">Ege Erdogan</a>, 
<a href="/search/cs?searchtype=author&query=Geisler%2C+S">Simon Geisler</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">It is well-known that deep learning models are vulnerable to small input
perturbations. Such perturbed instances are called adversarial examples.
Adversarial examples are commonly crafted to fool a model either at training
time (poisoning) or test time (evasion). In this work, we study the symbiosis
of poisoning and evasion. We show that combining both threat models can
substantially improve the devastating efficacy of adversarial attacks.
Specifically, we study the robustness of Graph Neural Networks (GNNs) under
structure perturbations and devise a memory-efficient adaptive end-to-end
attack for the novel threat model using first-order optimization.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05503" title="Abstract">arXiv:2312.05503</a> [<a href="/pdf/2312.05503" title="Download PDF">pdf</a>, <a href="/format/2312.05503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligner: One Global Token is Worth Millions of Parameters When Aligning  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziheng%2C+Z">Zhou Ziheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingnian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Terzopoulos%2C+D">Demetri Terzopoulos</a> (University of California, Los Angeles)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 81 pages, 77 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Aligner, a novel Parameter-Efficient Fine-Tuning (PEFT) method
for aligning multi-billion-parameter-sized Large Language Models (LLMs).
Aligner employs a unique design that constructs a globally shared set of
tunable tokens that modify the attention of every layer. Remarkably with this
method, even when using one token accounting for a mere 5,000 parameters,
Aligner can still perform comparably well to state-of-the-art LLM adaptation
methods like LoRA that require millions of parameters. This capacity is
substantiated in both instruction following and value alignment tasks. Besides
the multiple order-of-magnitude improvement in parameter efficiency, the
insight Aligner provides into the internal mechanisms of LLMs is also valuable.
The architectural features and efficacy of our method, in addition to our
experiments demonstrate that an LLM separates its internal handling of "form"
and "knowledge" in a somewhat orthogonal manner. This finding promises to
motivate new research into LLM mechanism understanding and value alignment.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05505" title="Abstract">arXiv:2312.05505</a> [<a href="/pdf/2312.05505" title="Download PDF">pdf</a>, <a href="/format/2312.05505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distinct Shortest Walk Enumeration for RPQs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David%2C+C">Claire David</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+N">Nadime Francis</a>, 
<a href="/search/cs?searchtype=author&query=Marsault%2C+V">Victor Marsault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We consider the Distinct Shortest Walks problem. Given two vertices $s$ and
$t$ of a graph database $\mathcal{D}$ and a regular path query, enumerate all
walks of minimal length from $s$ to $t$ that carry a label that conforms to the
query.
<br />Usual theoretical solutions turn out to be inefficient when applied to graph
models that are closer to real-life systems, in particular because edges may
carry multiple labels. Indeed, known algorithms may repeat the same answer
exponentially many times.
<br />We propose an efficient algorithm for multi-labelled graph databases. The
preprocessing runs in $O{|\mathcal{D}|\times|\mathcal{A}|}$ and the delay
between two consecutive outputs is in $O(\lambda\times|\mathcal{A}|)$, where
$\mathcal{A}$ is a nondeterministic automaton representing the query and
$\lambda$ is the minimal length. The algorithm can handle
$\varepsilon$-transitions in $\mathcal{A}$ or queries given as regular
expressions at no additional cost.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05506" title="Abstract">arXiv:2312.05506</a> [<a href="/pdf/2312.05506" title="Download PDF">pdf</a>, <a href="/format/2312.05506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trade-off of Security, Latency, and Throughput of the Nakamoto Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shujie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongning Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper delves into the fundamental trade-off between security, latency,
and throughput in proof-of-work longest-chain-wins protocols, also known as the
Nakamoto consensus. New upper and lower bounds on the probability of violating
transaction safety are derived as a function of honest and adversarial mining
rates, an upper bound on block propagation delays, and transaction confirmation
latency, both in time and in block depth. The results include a first
closed-form finite-latency bound applicable to all delays and mining rates up
to the ultimate fault tolerance. Notably, for most parameters relevant to
Bitcoin and proof-of-work Ethereum, the gap between the upper and lower bounds
is significantly narrower than the best gaps previously established in the
literature. Furthermore, the paper reveals a fundamental trade-off between
transaction throughput and confirmation latency, ultimately determined by the
desired fault tolerance and the growth of block propagation delay as block size
increases.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05508" title="Abstract">arXiv:2312.05508</a> [<a href="/pdf/2312.05508" title="Download PDF">pdf</a>, <a href="/format/2312.05508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Robust Fairness via Anti-Bias Soft Label  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiji Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">Adversarial Training (AT) has been widely proved to be an effective method to
improve the adversarial robustness against adversarial examples for Deep Neural
Networks (DNNs). As a variant of AT, Adversarial Robustness Distillation (ARD)
has demonstrated its superior performance in improving the robustness of small
student models with the guidance of large teacher models. However, both AT and
ARD encounter the robust fairness problem: these models exhibit strong
robustness when facing part of classes (easy class), but weak robustness when
facing others (hard class). In this paper, we give an in-depth analysis of the
potential factors and argue that the smoothness degree of samples' soft labels
for different classes (i.e., hard class or easy class) will affect the robust
fairness of DNN models from both empirical observation and theoretical
analysis. Based on the above finding, we propose an Anti-Bias Soft Label
Distillation (ABSLD) method to mitigate the adversarial robust fairness problem
within the framework of Knowledge Distillation (KD). Specifically, ABSLD
adaptively reduces the student's error risk gap between different classes to
achieve fairness by adjusting the class-wise smoothness degree of samples' soft
labels during the training process, and the smoothness degree of soft labels is
controlled by assigning different temperatures in KD to different classes.
Extensive experiments demonstrate that ABSLD outperforms state-of-the-art AT,
ARD, and robust fairness methods in terms of overall performance of robustness
and fairness.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05511" title="Abstract">arXiv:2312.05511</a> [<a href="/pdf/2312.05511" title="Download PDF">pdf</a>, <a href="/format/2312.05511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error analysis of BDF 1-6 time-stepping methods for the transient Stokes  problem: velocity and pressure estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Contri%2C+A">Alessandro Contri</a>, 
<a href="/search/math?searchtype=author&query=Kov%C3%A1cs%2C+B">Bal&#xe1;zs Kov&#xe1;cs</a>, 
<a href="/search/math?searchtype=author&query=Massing%2C+A">Andr&#xe9; Massing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a new stability and error analysis of fully discrete approximation
schemes for the transient Stokes equation. For the spatial discretization, we
consider a wide class of Galerkin finite element methods which includes both
inf-sup stable spaces and symmetric pressure stabilized formulations. We extend
the results from Burman and Fern\'andez [\textit{SIAM J. Numer. Anal.}, 47
(2009), pp. 409-439] and provide a unified theoretical analysis of backward
difference formulae (BDF methods) of order 1 to 6. The main novelty of our
approach lies in the use of Dahlquist's G-stability concept together with
multiplier techniques introduced by Nevannlina-Odeh and recently by Akrivis et
al. [\textit{SIAM J. Numer. Anal.}, 59 (2021), pp. 2449-2472] to derive optimal
stability and error estimates for both the velocity and the pressure. When
combined with a method dependent Ritz projection for the initial data,
unconditional stability can be shown while for arbitrary interpolation,
pressure stability is subordinate to the fulfillment of a mild inverse CFL-type
condition between space and time discretizations.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05516" title="Abstract">arXiv:2312.05516</a> [<a href="/pdf/2312.05516" title="Download PDF">pdf</a>, <a href="/format/2312.05516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stateful Large Language Model Serving with Pensieve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lingfan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large Language Models (LLMs) have recently experienced great success, as
evident in the widespread popularity of ChatGPT. Existing LLM serving systems
are stateless across requests. Consequently, when LLMs are used in the common
setting of multi-turn conversations, a growing log of the conversation history
must be processed alongside any request by the serving system at each turn,
resulting in repeated history processing. In this paper, we design $Pensieve$,
a system optimized for multi-turn conversation LLM serving. $Pensieve$
maintains the conversation state across requests by caching previously
processed history to avoid duplicate processing. $Pensieve$'s multi-tier
caching strategy can utilize both GPU and CPU memory to efficiently store and
retrieve cached data. $Pensieve$ also generalizes the recent PagedAttention
kernel to support attention between multiple input tokens with a GPU cache
spread over non-contiguous memory. Our evaluation shows that $Pensieve$ is able
to achieve 1.51-1.95x throughput compared to vLLM and reduce latency by 60-75%.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05517" title="Abstract">arXiv:2312.05517</a> [<a href="/pdf/2312.05517" title="Download PDF">pdf</a>, <a href="/format/2312.05517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Base Station Sleeping and Resource Cooperation Enabled Green  Fully-Decoupled RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunting Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haibo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xuemin">Xuemin</a> (Sherman)
<a href="/search/cs?searchtype=author&query=Shen">Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Base station (BS) sleeping, a promising technique to address the growing
energy consumption in wireless communication networks, encounters challenges
such as coverage holes and coupled uplink and downlink transmissions. As an
innovative architecture designed for future-generation mobile communication
networks, the fully-decoupled radio access network (FD-RAN) is anticipated to
overcome these challenges by fully decoupled control-data planes and
uplink-downlink transmissions. In this paper, we investigate energy-efficient
uplink FD-RAN leveraging flexible BS sleeping and resource cooperation. First,
we introduce a holistic energy consumption model and formulate a bi-level
energy efficiency maximizing problem for FD-RAN, involved with the joint
optimization of user equipment (UE) association, BS sleeping, and power
control. Subsequently, through employing the Tammer decomposition method, the
formulated bi-level problem is converted into two equivalent upper-level and
lower-level problems. The lower-level problem encompassed with UE power control
is addressed by introducing a successive lower-bound maximization-based
Dinkelbach's algorithm, and the upper-level problem for UE association and BS
sleeping is solved through a modified low-complexity many-to-many swap matching
algorithm, respectively. Extensive simulation results not only demonstrate the
superior effectiveness of FD-RAN and our proposed algorithms but also reveal
the sources of energy efficiency gains within FD-RAN.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05519" title="Abstract">arXiv:2312.05519</a> [<a href="/pdf/2312.05519" title="Download PDF">pdf</a>, <a href="/format/2312.05519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isomorphic-Consistent Variational Graph Auto-Encoders for Multi-Level  Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qingchao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wenji Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph representation learning is a fundamental research theme and can be
generalized to benefit multiple downstream tasks from the node and link levels
to the higher graph level. In practice, it is desirable to develop
task-agnostic general graph representation learning methods that are typically
trained in an unsupervised manner. Related research reveals that the power of
graph representation learning methods depends on whether they can differentiate
distinct graph structures as different embeddings and map isomorphic graphs to
consistent embeddings (i.e., the isomorphic consistency of graph models).
However, for task-agnostic general graph representation learning, existing
unsupervised graph models, represented by the variational graph auto-encoders
(VGAEs), can only keep the isomorphic consistency within the subgraphs of 1-hop
neighborhoods and thus usually manifest inferior performance on the more
difficult higher-level tasks. To overcome the limitations of existing
unsupervised methods, in this paper, we propose the Isomorphic-Consistent VGAE
(IsoC-VGAE) for multi-level task-agnostic graph representation learning. We
first devise a decoding scheme to provide a theoretical guarantee of keeping
the isomorphic consistency under the settings of unsupervised learning. We then
propose the Inverse Graph Neural Network (Inv-GNN) decoder as its intuitive
realization, which trains the model via reconstructing the GNN node embeddings
with multi-hop neighborhood information, so as to maintain the high-order
isomorphic consistency within the VGAE framework. We conduct extensive
experiments on the representative graph learning tasks at different levels,
including node classification, link prediction and graph classification, and
the results verify that our proposed model generally outperforms both the
state-of-the-art unsupervised methods and representative supervised methods.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05520" title="Abstract">arXiv:2312.05520</a> [<a href="/pdf/2312.05520" title="Download PDF">pdf</a>, <a href="/ps/2312.05520" title="Download PostScript">ps</a>, <a href="/format/2312.05520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenty: A Python Library for Structured Text Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enevoldsen%2C+K">Kenneth Enevoldsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JOSS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Augmnety is a Python library for structured text augmentation. It is built on
top of spaCy and allows for augmentation of both the text and its annotations.
Augmenty provides a wide range of augmenters which can be combined in a
flexible manner to create complex augmentation pipelines. It also includes a
set of primitives that can be used to create custom augmenters such as word
replacement augmenters. This functionality allows for augmentations within a
range of applications such as named entity recognition (NER), part-of-speech
tagging, and dependency parsing.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05524" title="Abstract">arXiv:2312.05524</a> [<a href="/pdf/2312.05524" title="Download PDF">pdf</a>, <a href="/ps/2312.05524" title="Download PostScript">ps</a>, <a href="/format/2312.05524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Web of Science Core Collection&#x27;s coverage expansion:The forgotten Arts &amp;  Humanities Citation Index?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weishu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+R">Rong Ni</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guangyuan Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Forthcoming in Scientometrics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The expansion of Web of Science Core Collection (WoSCC) over the recent years
has partially accounted for the "norm" of growth of research output in many
bibliometric analysis studies. However, the expansion patterns of different
citation indexes may be different, which may benefit some disciplines but
hinder others. Utilizing Science Citation Index Expanded (SCIE), Social
Sciences Citation Index (SSCI), and Arts &amp; Humanities Citation Index (A&amp;HCI),
this study attempts to elaborate on WoSCC's coverage expansion patterns among
these three databases from 2001 to 2020. Results show that different from
SCIE/SSCI, both the annual publication volumes in the A&amp;HCI database and all
A&amp;HCI journals have remained relatively stagnant in all document types
considered scenario or have gained relatively slight increases in only citable
items considered scenario. Although the number of A&amp;HCI journals also has
increased remarkably, the average journal publication volume of A&amp;HCI journals
has decreased gradually if all document types are considered or kept relatively
stagnant when citable items only are considered. Besides, the A&amp;HCI database
has ceased the systematic index of individually selected items from SCIE/SSCI
journals since 2018. The study finally discusses the possible causes and
consequences of the unbalanced expansion of WoSCC's different citation indexes.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05525" title="Abstract">arXiv:2312.05525</a> [<a href="/pdf/2312.05525" title="Download PDF">pdf</a>, <a href="/format/2312.05525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Only Learn One Query: Learning Unified Human Query for Single-Stage  Multi-Person Multi-Task Human-Centric Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuhuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-centric perception (e.g. pedetrian detection, segmentation, pose
estimation, and attribute analysis) is a long-standing problem for computer
vision. This paper introduces a unified and versatile framework (HQNet) for
single-stage multi-person multi-task human-centric perception (HCP). Our
approach centers on learning a unified human query representation, denoted as
Human Query, which captures intricate instance-level features for individual
persons and disentangles complex multi-person scenarios. Although different HCP
tasks have been well-studied individually, single-stage multi-task learning of
HCP tasks has not been fully exploited in the literature due to the absence of
a comprehensive benchmark dataset. To address this gap, we propose
COCO-UniHuman benchmark dataset to enable model development and comprehensive
evaluation. Experimental results demonstrate the proposed method's
state-of-the-art performance among multi-task HCP models and its competitive
performance compared to task-specific HCP models. Moreover, our experiments
underscore Human Query's adaptability to new HCP tasks, thus demonstrating its
robust generalization capability. Codes and data will be publicly accessible.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05526" title="Abstract">arXiv:2312.05526</a> [<a href="/pdf/2312.05526" title="Download PDF">pdf</a>, <a href="/format/2312.05526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Neighborhood Selection for Unsupervised Graph Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bei%2C+Y">Yuanchen Bei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qiaoyu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+J">Jiajun Bu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1O pages, 7 figures, accepted by ICDM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised graph anomaly detection is crucial for various practical
applications as it aims to identify anomalies in a graph that exhibit rare
patterns deviating significantly from the majority of nodes. Recent
advancements have utilized Graph Neural Networks (GNNs) to learn high-quality
node representations for anomaly detection by aggregating information from
neighborhoods. However, the presence of anomalies may render the observed
neighborhood unreliable and result in misleading information aggregation for
node representation learning. Selecting the proper neighborhood is critical for
graph anomaly detection but also challenging due to the absence of
anomaly-oriented guidance and the interdependence with representation learning.
To address these issues, we utilize the advantages of reinforcement learning in
adaptively learning in complex environments and propose a novel method that
incorporates Reinforcement neighborhood selection for unsupervised graph
ANomaly Detection (RAND). RAND begins by enriching the candidate neighbor pool
of the given central node with multiple types of indirect neighbors. Next, RAND
designs a tailored reinforcement anomaly evaluation module to assess the
reliability and reward of considering the given neighbor. Finally, RAND selects
the most reliable subset of neighbors based on these rewards and introduces an
anomaly-aware aggregator to amplify messages from reliable neighbors while
diminishing messages from unreliable ones. Extensive experiments on both three
synthetic and two real-world datasets demonstrate that RAND outperforms the
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05530" title="Abstract">arXiv:2312.05530</a> [<a href="/pdf/2312.05530" title="Download PDF">pdf</a>, <a href="/format/2312.05530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Smart Healthcare: Challenges and Opportunities in IoT and ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saifuzzaman%2C+M">Munshi Saifuzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Ananna%2C+T+N">Tajkia Nuri Ananna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 3 tables, 2 figures, chapter 10 of "IoT and ML for Information Management: A Smart Healthcare Perspective" under "Springer Studies in Computational Challenge" series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The COVID-19 pandemic and other ongoing health crises have underscored the
need for prompt healthcare services worldwide. The traditional healthcare
system, centered around hospitals and clinics, has proven inadequate in the
face of such challenges. Intelligent wearable devices, a key part of
conventional healthcare, leverage Internet of Things (IoT) technology to
collect extensive data related to the environment, as well as psychological,
behavioral, and physical health. Managing the substantial data generated by
these wearables and other IoT devices in healthcare poses a significant
challenge, potentially impeding decision-making processes. Recent interest has
grown in applying data analytics for extracting information, gaining insights,
and making predictions. Additionally, machine learning (ML), known for
addressing various networking challenges, has seen increased implementation to
enhance IoT systems in healthcare. This chapter focuses exclusively on
exploring the hurdles encountered when integrating ML methods into the IoT
healthcare sector. We offer a comprehensive summary of current research
challenges and potential opportunities, categorized into three scenarios:
IoT-based, ML-based, and the implementation of ML methodologies in the
healthcare industry via the IoT. We highlight the difficulties faced by
existing methodologies, providing valuable insights for future researchers,
healthcare professionals, and government agencies. This ensures they stay
updated on the latest developments in big data analytics for intelligent
healthcare utilizing ML.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05531" title="Abstract">arXiv:2312.05531</a> [<a href="/pdf/2312.05531" title="Download PDF">pdf</a>, <a href="/format/2312.05531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KEN: Kernel Extensions using Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yusheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Maolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+A">Andrew Quinn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">The ability to modify and extend an operating system is an important feature
for improving a system's security, reliability, and performance. The extended
Berkeley Packet Filters (eBPF) ecosystem has emerged as the standard mechanism
for extending the Linux kernel and has recently been ported to Windows. eBPF
programs inject new logic into the kernel that the system will execute before
or after existing logic. While the eBPF ecosystem provides a flexible mechanism
for kernel extension, it is difficult for developers to write eBPF programs
today. An eBPF developer must have deep knowledge of the internals of the
operating system to determine where to place logic and cope with programming
limitations on the control flow and data accesses of their eBPF program
enforced by the eBPF verifier. This paper presents KEN, an alternative
framework that alleviates the difficulty of writing an eBPF program by allowing
Kernel Extensions to be written in Natural language. KEN uses recent advances
in large language models (LLMs) to synthesize an eBPF program given a user's
English language prompt. To ensure that LLM's output is semantically equivalent
to the user's prompt, KEN employs a combination of LLM-empowered program
comprehension, symbolic execution, and a series of feedback loops. KEN's key
novelty is the combination of these techniques. In particular, the system uses
symbolic execution in a novel structure that allows it to combine the results
of program synthesis and program comprehension and build on the recent success
that LLMs have shown for each of these tasks individually. To evaluate KEN, we
developed a new corpus of natural language prompts for eBPF programs. We show
that KEN produces correct eBPF programs on 80% which is an improvement of a
factor of 2.67 compared to an LLM-empowered program synthesis baseline.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05534" title="Abstract">arXiv:2312.05534</a> [<a href="/pdf/2312.05534" title="Download PDF">pdf</a>, <a href="/ps/2312.05534" title="Download PostScript">ps</a>, <a href="/format/2312.05534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended codes and deep holes of MDS codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yansheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Cunsheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tingfang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">For a given linear code $\C$ of length $n$ over $\gf(q)$ and a nonzero vector
$\bu$ in $\gf(q)^n$, Sun, Ding and Chen defined an extended linear code
$\overline{\C}(\bu)$ of $\C$, which is a generalisation of the classical
extended code $\overline{\C}(-\bone)$ of $\C$ and called the second kind of an
extended code of $\C$ (see <a href="/abs/2307.04076">arXiv:2307.04076</a> and <a href="/abs/2307.08053">arXiv:2307.08053</a>). They
developed some general theory of the extended codes $\overline{\C}(\bu)$ and
studied the extended codes $\overline{\C}(\bu)$ of several families of linear
codes, including cyclic codes, projective two-weight codes, nonbinary Hamming
codes, and a family of reversible MDS cyclic codes. The objective of this paper
is to investigate the extended codes $\overline{\C}(\bu)$ of MDS codes $\C$
over finite fields. The main result of this paper is that the extended code
$\overline{\C}(\bu)$ of an MDS $[n,k]$ code $\C$ remains MDS if and only if the
covering radius $\rho(\mathcal{C}^{\bot})=k$ and the vector $\bu$ is a deep
hole of the dual code $\C^\perp$. As applications of this main result, the
extended codes of the GRS codes and extended GRS codes are investigated and the
covering radii of several families of MDS codes are determined.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05538" title="Abstract">arXiv:2312.05538</a> [<a href="/pdf/2312.05538" title="Download PDF">pdf</a>, <a href="/format/2312.05538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSL: Class-Agnostic Structure-Constrained Learning for Segmentation  Including the Unseen
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+N">Narendra Ahuja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Addressing Out-Of-Distribution (OOD) Segmentation and Zero-Shot Semantic
Segmentation (ZS3) is challenging, necessitating segmenting unseen classes.
Existing strategies adapt the class-agnostic Mask2Former (CA-M2F) tailored to
specific tasks. However, these methods cater to singular tasks, demand training
from scratch, and we demonstrate certain deficiencies in CA-M2F, which affect
performance. We propose the Class-Agnostic Structure-Constrained Learning
(CSL), a plug-in framework that can integrate with existing methods, thereby
embedding structural constraints and achieving performance gain, including the
unseen, specifically OOD, ZS3, and domain adaptation (DA) tasks. There are two
schemes for CSL to integrate with existing methods (1) by distilling knowledge
from a base teacher network, enforcing constraints across training and
inference phrases, or (2) by leveraging established models to obtain per-pixel
distributions without retraining, appending constraints during the inference
phase. We propose soft assignment and mask split methodologies that enhance OOD
object segmentation. Empirical evaluations demonstrate CSL's prowess in
boosting the performance of existing algorithms spanning OOD segmentation, ZS3,
and DA segmentation, consistently transcending the state-of-art across all
three tasks.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05540" title="Abstract">arXiv:2312.05540</a> [<a href="/pdf/2312.05540" title="Download PDF">pdf</a>, <a href="/format/2312.05540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Causality Learning with Explainable Adaptive Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dezhi Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xintong He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Domeniconi%2C+C">Carlotta Domeniconi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinglin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Discovering the causality from observational data is a crucial task in
various scientific domains. With increasing awareness of privacy, data are not
allowed to be exposed, and it is very hard to learn causal graphs from
dispersed data, since these data may have different distributions. In this
paper, we propose a federated causal discovery strategy (FedCausal) to learn
the unified global causal graph from decentralized heterogeneous data. We
design a global optimization formula to naturally aggregate the causal graphs
from client data and constrain the acyclicity of the global graph without
exposing local data. Unlike other federated causal learning algorithms,
FedCausal unifies the local and global optimizations into a complete directed
acyclic graph (DAG) learning process with a flexible optimization objective. We
prove that this optimization objective has a high interpretability and can
adaptively handle homogeneous and heterogeneous data. Experimental results on
synthetic and real datasets show that FedCausal can effectively deal with
non-independently and identically distributed (non-iid) data and has a superior
performance.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05541" title="Abstract">arXiv:2312.05541</a> [<a href="/pdf/2312.05541" title="Download PDF">pdf</a>, <a href="/format/2312.05541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPoser: Diffusion Model as Robust 3D Human Pose Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junzhe Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+H">Hongkun Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://dposer.github.io">this https URL</a>; Code Released: <a href="https://github.com/moonbow721/DPoser">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modeling human pose is a cornerstone in applications from human-robot
interaction to augmented reality, yet crafting a robust human pose prior
remains a challenge due to biomechanical constraints and diverse human
movements. Traditional priors like VAEs and NDFs often fall short in realism
and generalization, especially in extreme conditions such as unseen noisy
poses. To address these issues, we introduce DPoser, a robust and versatile
human pose prior built upon diffusion models. Designed with optimization
frameworks, DPoser seamlessly integrates into various pose-centric
applications, including human mesh recovery, pose completion, and motion
denoising. Specifically, by formulating these tasks as inverse problems, we
employ variational diffusion sampling for efficient solving. Furthermore,
acknowledging the disparity between the articulated poses we focus on and
structured images in previous research, we propose a truncated timestep
scheduling to boost performance on downstream tasks. Our exhaustive experiments
demonstrate DPoser's superiority over existing state-of-the-art pose priors
across multiple tasks.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05547" title="Abstract">arXiv:2312.05547</a> [<a href="/pdf/2312.05547" title="Download PDF">pdf</a>, <a href="/format/2312.05547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signatures Meet Dynamic Programming: Generalizing Bellman Equations for  Trajectory Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ohnishi%2C+M">Motoya Ohnishi</a>, 
<a href="/search/eess?searchtype=author&query=Akinola%2C+I">Iretiayo Akinola</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/eess?searchtype=author&query=Mandlekar%2C+A">Ajay Mandlekar</a>, 
<a href="/search/eess?searchtype=author&query=Ramos%2C+F">Fabio Ramos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Path signatures have been proposed as a powerful representation of paths that
efficiently captures the path's analytic and geometric characteristics, having
useful algebraic properties including fast concatenation of paths through
tensor products. Signatures have recently been widely adopted in machine
learning problems for time series analysis. In this work we establish
connections between value functions typically used in optimal control and
intriguing properties of path signatures. These connections motivate our novel
control framework with signature transforms that efficiently generalizes the
Bellman equation to the space of trajectories. We analyze the properties and
advantages of the framework, termed signature control. In particular, we
demonstrate that (i) it can naturally deal with varying/adaptive time steps;
(ii) it propagates higher-level information more efficiently than value
function updates; (iii) it is robust to dynamical system misspecification over
long rollouts. As a specific case of our framework, we devise a model
predictive control method for path tracking. This method generalizes integral
control, being suitable for problems with unknown disturbances. The proposed
algorithms are tested in simulation, with differentiable physics models
including typical control and robotics tasks such as point-mass, curve
following for an ant model, and a robotic manipulator.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05549" title="Abstract">arXiv:2312.05549</a> [<a href="/pdf/2312.05549" title="Download PDF">pdf</a>, <a href="/format/2312.05549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-granularity Causal Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiaxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shuyin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Unveil, model, and comprehend the causal mechanisms underpinning natural
phenomena stand as fundamental endeavors across myriad scientific disciplines.
Meanwhile, new knowledge emerges when discovering causal relationships from
data. Existing causal learning algorithms predominantly focus on the isolated
effects of variables, overlook the intricate interplay of multiple variables
and their collective behavioral patterns. Furthermore, the ubiquity of
high-dimensional data exacts a substantial temporal cost for causal algorithms.
In this paper, we develop a novel method called MgCSL (Multi-granularity Causal
Structure Learning), which first leverages sparse auto-encoder to explore
coarse-graining strategies and causal abstractions from micro-variables to
macro-ones. MgCSL then takes multi-granularity variables as inputs to train
multilayer perceptrons and to delve the causality between variables. To enhance
the efficacy on high-dimensional data, MgCSL introduces a simplified acyclicity
constraint to adeptly search the directed acyclic graph among variables.
Experimental results show that MgCSL outperforms competitive baselines, and
finds out explainable causal connections on fMRI datasets.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05550" title="Abstract">arXiv:2312.05550</a> [<a href="/pdf/2312.05550" title="Download PDF">pdf</a>, <a href="/format/2312.05550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D3A-TS: Denoising-Driven Data Augmentation in Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solis-Martin%2C+D">David Solis-Martin</a>, 
<a href="/search/cs?searchtype=author&query=Galan-Paez%2C+J">Juan Galan-Paez</a>, 
<a href="/search/cs?searchtype=author&query=Borrego-Diaz%2C+J">Joaquin Borrego-Diaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In peer reviewing process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">It has been demonstrated that the amount of data is crucial in data-driven
machine learning methods. Data is always valuable, but in some tasks, it is
almost like gold. This occurs in engineering areas where data is scarce or very
expensive to obtain, such as predictive maintenance, where faults are rare. In
this context, a mechanism to generate synthetic data can be very useful. While
in fields such as Computer Vision or Natural Language Processing synthetic data
generation has been extensively explored with promising results, in other
domains such as time series it has received less attention. This work
specifically focuses on studying and analyzing the use of different techniques
for data augmentation in time series for classification and regression
problems. The proposed approach involves the use of diffusion probabilistic
models, which have recently achieved successful results in the field of Image
Processing, for data augmentation in time series. Additionally, the use of
meta-attributes to condition the data augmentation process is investigated. The
results highlight the high utility of this methodology in creating synthetic
data to train classification and regression models. To assess the results, six
different datasets from diverse domains were employed, showcasing versatility
in terms of input size and output types. Finally, an extensive ablation study
is conducted to further support the obtained outcomes.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05551" title="Abstract">arXiv:2312.05551</a> [<a href="/pdf/2312.05551" title="Download PDF">pdf</a>, <a href="/format/2312.05551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimensional Fair Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Cong Su</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingzhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) has emerged as a promising collaborative and secure
paradigm for training a model from decentralized data without compromising
privacy. Group fairness and client fairness are two dimensions of fairness that
are important for FL. Standard FL can result in disproportionate disadvantages
for certain clients, and it still faces the challenge of treating different
groups equitably in a population. The problem of privately training fair FL
models without compromising the generalization capability of disadvantaged
clients remains open. In this paper, we propose a method, called mFairFL, to
address this problem and achieve group fairness and client fairness
simultaneously. mFairFL leverages differential multipliers to construct an
optimization objective for empirical risk minimization with fairness
constraints. Before aggregating locally trained models, it first detects
conflicts among their gradients, and then iteratively curates the direction and
magnitude of gradients to mitigate these conflicts. Theoretical analysis proves
mFairFL facilitates the fairness in model development. The experimental
evaluations based on three benchmark datasets show significant advantages of
mFairFL compared to seven state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05556" title="Abstract">arXiv:2312.05556</a> [<a href="/pdf/2312.05556" title="Download PDF">pdf</a>, <a href="/ps/2312.05556" title="Download PostScript">ps</a>, <a href="/format/2312.05556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second-order computational homogenization of flexoelectric composites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhuang%2C+X">Xiaoying Zhuang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/math?searchtype=author&query=Nanthakumar%2C+S+S">S.S. Nanthakumar</a>, 
<a href="/search/math?searchtype=author&query=Bohlke%2C+T">Thomas Bohlke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Flexoelectricity shows promising applications for self-powered devices with
its increased power density. This paper presents a second-order computational
homogenization strategy for flexoelectric composite. The macro-micro scale
transition, Hill-Mandel energy condition, periodic boundary conditions, and
macroscopic constitutive tangents for the two-scale electromechanical coupling
are investigated and considered in the homogenization formulation. The
macrostructure and microstructure are discretized using $C^1$ triangular finite
elements. The second-order multiscale solution scheme is implemented using
ABAQUS with user subroutines. Finally, we present numerical examples including
parametric analysis of a square plate with holes and the design of
piezoelectric materials made of non-piezoelectric materials to demonstrate the
numerical implementation and the size-dependent effects of flexoelectricity.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05557" title="Abstract">arXiv:2312.05557</a> [<a href="/pdf/2312.05557" title="Download PDF">pdf</a>, <a href="/ps/2312.05557" title="Download PostScript">ps</a>, <a href="/format/2312.05557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Term Rate-Fairness-Aware Beamforming Based Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">W. Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+H+D">H. D. Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Dutkiewicz%2C+E">E. Dutkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Y. Fang</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. V. Poor</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">L. Hanzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This is the first treatise on multi-user (MU) beamforming designed for
achieving long-term rate-fairness in fulldimensional MU massive multi-input
multi-output (m-MIMO) systems. Explicitly, based on the channel covariances,
which can be assumed to be known beforehand, we address this problem by
optimizing the following objective functions: the users' signal-toleakage-noise
ratios (SLNRs) using SLNR max-min optimization, geometric mean of SLNRs
(GM-SLNR) based optimization, and SLNR soft max-min optimization. We develop a
convex-solver based algorithm, which invokes a convex subproblem of cubic
time-complexity at each iteration for solving the SLNR maxmin problem. We then
develop closed-form expression based algorithms of scalable complexity for the
solution of the GMSLNR and of the SLNR soft max-min problem. The simulations
provided confirm the users' improved-fairness ergodic rate distributions.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05559" title="Abstract">arXiv:2312.05559</a> [<a href="/pdf/2312.05559" title="Download PDF">pdf</a>, <a href="/ps/2312.05559" title="Download PostScript">ps</a>, <a href="/format/2312.05559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Jacobi approximations for Boussinesq systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dur%C3%A1n%2C+A">Angel Dur&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper is concerned with the numerical approximation of
initial-boundary-value problems of a three-parameter family of Bona-Smith
systems, derived as a model for the propagation of surface waves under a
physical Boussinesq regime. The work proposed here is focused on the
corresponding problem with Dirichlet boundary conditions and its approximation
in space with spectral methods based on Jacobi polynomials, which are defined
from the orthogonality with respect to some weighted $L^{2}$ inner product.
Well-posedness of the problem on the corresponding weighted Sobolev spaces is
first analyzed and existence and uniqueness of solution, locally in time, are
proved. Then the spectral Galerkin semidiscrete scheme and some detailed
comments on its implementation are introduced. The existence of numerical
solution and error estimates on those weighted Sobolev spaces are established.
Finally, the choice of the time integrator to complete the full discretization
takes care of different stability issues that may be relevant when
approximating the semidiscrete system. Some numerical experiments illustrate
the results.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05560" title="Abstract">arXiv:2312.05560</a> [<a href="/pdf/2312.05560" title="Download PDF">pdf</a>, <a href="/format/2312.05560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Accuracy of Predictors of Activity Sequences of Business  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M+A">Muhammad Awais Ali</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+M">Marlon Dumas</a>, 
<a href="/search/cs?searchtype=author&query=Milani%2C+F">Fredrik Milani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Predictive process monitoring is an evolving research field that studies how
to train and use predictive models for operational decision-making. One of the
problems studied in this field is that of predicting the sequence of upcoming
activities in a case up to its completion, a.k.a. the case suffix. The
prediction of case suffixes provides input to estimate short-term workloads and
execution times under different resource schedules. Existing methods to address
this problem often generate suffixes wherein some activities are repeated many
times, whereas this pattern is not observed in the data. Closer examination
shows that this shortcoming stems from the approach used to sample the
successive activity instances to generate a case suffix. Accordingly, the paper
introduces a sampling approach aimed at reducing repetitions of activities in
the predicted case suffixes. The approach, namely Daemon action, strikes a
balance between exploration and exploitation when generating the successive
activity instances. We enhance a deep learning approach for case suffix
predictions using this sampling approach, and experimentally show that the
enhanced approach outperforms the unenhanced ones with respect to control-flow
accuracy measures.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05562" title="Abstract">arXiv:2312.05562</a> [<a href="/pdf/2312.05562" title="Download PDF">pdf</a>, <a href="/format/2312.05562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Thought in Neural Code Generation: From and For Lightweight  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taolue Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> UNDER REVIEW
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable potential in code
generation. The integration of Chain of Thought (CoT) reasoning can further
boost their performance. However, current CoT methods often require manual
writing or LLMs with over 100 billion parameters to generate, impeding their
applicability in resource-constrained scenarios. In this study, we investigate
lightweight Language Models (lLMs), which are defined to have fewer than 10
billion parameters. Empirically, we find that most lLMs cannot generate
high-quality CoTs when prompted by the few-shot method, but can take advantage
of high-quality CoTs generated elsewhere to improve their performance in code
generation. Based on these findings, we design a novel approach COTTON which
can leverage lLMs to automatically generate CoTs for code generation. We
synthesize new datasets and conduct extensive experiments on various
benchmarks. The results show that the CoTs generated by COTTON outperform the
baselines in terms of automated and human evaluation metrics. In particular,
the CoTs generated by COTTON boost various lLMs to achieve higher performance
gains than those generated by LLMs such as ChatGLM (130B), and are competitive
with those generated by gpt-3.5-turbo (175B). Our study also showcases the
potential of lLMs in software engineering applications.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05563" title="Abstract">arXiv:2312.05563</a> [<a href="/pdf/2312.05563" title="Download PDF">pdf</a>, <a href="/ps/2312.05563" title="Download PostScript">ps</a>, <a href="/format/2312.05563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Administration 4.0: Administrative informatics as a customized and  necessary educational platform for a modern IT-supported federal  administration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borghoff%2C+U+M">Uwe M. Borghoff</a>, 
<a href="/search/cs?searchtype=author&query=Matzner-Vogel%2C+N">Nicol Matzner-Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Rapp%2C+S">Siegfried Rapp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented at the practitioner session of the RVI 2023 conference in Dresden, Germany, on 26-27 October, see also <a href="https://www.rvi23.de/pages/programm.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Digitalization is conquering and stressing out the federal administration.
Using selected large-scale ICT projects, we show how complex and
interdisciplinary the tasks are. The federal administration's IT strategy
requires well-trained specialists for all defined fields of action. This scarce
resource is increasingly being trained academically in separate, tailor-made
degree courses that are developed specifically for the needs of the German
ministries and authorities. We use the example of administrative informatics
courses to explain their necessity and success story. Using a
Bachelor's/Master's program developed by the authors for the ITZBund and the
Federal Ministry of Finance, we look at a concrete implementation and justify
two of our design decisions in the development of the course, namely
transdisciplinarity and design thinking. We adopt a German perspective
throughout the paper. However, the conclusions also apply to other countries.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05568" title="Abstract">arXiv:2312.05568</a> [<a href="/pdf/2312.05568" title="Download PDF">pdf</a>, <a href="/format/2312.05568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Variational Student-t Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Delu Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The theory of Bayesian learning incorporates the use of Student-t Processes
to model heavy-tailed distributions and datasets with outliers. However,
despite Student-t Processes having a similar computational complexity as
Gaussian Processes, there has been limited emphasis on the sparse
representation of this model. This is mainly due to the increased difficulty in
modeling and computation compared to previous sparse Gaussian Processes. Our
motivation is to address the need for a sparse representation framework that
reduces computational complexity, allowing Student-t Processes to be more
flexible for real-world datasets. To achieve this, we leverage the conditional
distribution of Student-t Processes to introduce sparse inducing points.
Bayesian methods and variational inference are then utilized to derive a
well-defined lower bound, facilitating more efficient optimization of our model
through stochastic gradient descent. We propose two methods for computing the
variational lower bound, one utilizing Monte Carlo sampling and the other
employing Jensen's inequality to compute the KL regularization term in the loss
function. We propose adopting these approaches as viable alternatives to
Gaussian processes when the data might contain outliers or exhibit heavy-tailed
behavior, and we provide specific recommendations for their applicability. We
evaluate the two proposed approaches on various synthetic and real-world
datasets from UCI and Kaggle, demonstrating their effectiveness compared to
baseline methods in terms of computational complexity and accuracy, as well as
their robustness to outliers.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05571" title="Abstract">arXiv:2312.05571</a> [<a href="/pdf/2312.05571" title="Download PDF">pdf</a>, <a href="/format/2312.05571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frugal LMs Trained to Invoke Symbolic Solvers Achieve  Parameter-Efficient Arithmetic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Subhabrata Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Joykirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+I">Ishan Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Manchanda%2C+S">Sunny Manchanda</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+S">Soumen Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLM) exhibit zero-shot mathematical reasoning capacity
as a behavior emergent with scale, commonly manifesting as chain-of-thoughts
(CoT) reasoning. However, multiple empirical findings suggest that this prowess
is exclusive to LLMs with exorbitant sizes (beyond 50 billion parameters).
Meanwhile, educational neuroscientists suggest that symbolic algebraic
manipulation be introduced around the same time as arithmetic word problems to
modularize language-to-formulation, symbolic manipulation of the formulation,
and endgame arithmetic. In this paper, we start with the hypothesis that much
smaller LMs, which are weak at multi-step reasoning, can achieve reasonable
arithmetic reasoning if arithmetic word problems are posed as a
formalize-then-solve task. In our architecture, which we call SYRELM, the LM
serves the role of a translator to map natural language arithmetic questions
into a formal language (FL) description. A symbolic solver then evaluates the
FL expression to obtain the answer. A small frozen LM, equipped with an
efficient low-rank adapter, is capable of generating FL expressions that
incorporate natural language descriptions of the arithmetic problem (e.g.,
variable names and their purposes, formal expressions combining variables,
etc.). We adopt policy-gradient reinforcement learning to train the adapted LM,
informed by the non-differentiable symbolic solver. This marks a sharp
departure from the recent development in tool-augmented LLMs, in which the
external tools (e.g., calculator, Web search, etc.) are essentially detached
from the learning phase of the LM. SYRELM shows massive improvements (e.g.,
+30.65 absolute point improvement in accuracy on the SVAMP dataset using GPT-J
6B model) over base LMs, while keeping our testbed easy to diagnose, interpret
and within reach of most researchers.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05572" title="Abstract">arXiv:2312.05572</a> [<a href="/pdf/2312.05572" title="Download PDF">pdf</a>, <a href="/format/2312.05572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R2-Talker: Realistic Real-Time Talking Head Synthesis with Hash Grid  Landmarks Encoding and Progressive Multilayer Conditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhiling Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">LiangGuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dingheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Quan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Ning Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dynamic NeRFs have recently garnered growing attention for 3D talking
portrait synthesis. Despite advances in rendering speed and visual quality,
challenges persist in enhancing efficiency and effectiveness. We present
R2-Talker, an efficient and effective framework enabling realistic real-time
talking head synthesis. Specifically, using multi-resolution hash grids, we
introduce a novel approach for encoding facial landmarks as conditional
features. This approach losslessly encodes landmark structures as conditional
features, decoupling input diversity, and conditional spaces by mapping
arbitrary landmarks to a unified feature space. We further propose a scheme of
progressive multilayer conditioning in the NeRF rendering pipeline for
effective conditional feature fusion. Our new approach has the following
advantages as demonstrated by extensive experiments compared with the
state-of-the-art works: 1) The lossless input encoding enables acquiring more
precise features, yielding superior visual quality. The decoupling of inputs
and conditional spaces improves generalizability. 2) The fusing of conditional
features and MLP outputs at each MLP layer enhances conditional impact,
resulting in more accurate lip synthesis and better visual quality. 3) It
compactly structures the fusion of conditional features, significantly
enhancing computational efficiency.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05576" title="Abstract">arXiv:2312.05576</a> [<a href="/pdf/2312.05576" title="Download PDF">pdf</a>, <a href="/format/2312.05576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Adjustment of Matching Radii under the Broadcasting Mode: A  Novel Multitask Learning Strategy and Temporal Modeling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zijian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Siyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linchuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+J">Jintao Ke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As ride-hailing services have experienced significant growth, the majority of
research has concentrated on the dispatching mode, where drivers must adhere to
the platform's assigned routes. However, the broadcasting mode, in which
drivers can freely choose their preferred orders from those broadcast by the
platform, has received less attention. One important but challenging task in
such a system is the determination of the optimal matching radius, which
usually varies across space, time, and real-time supply/demand characteristics.
This study develops a Transformer-Encoder-Based (TEB) model that predicts key
system performance metrics for a range of matching radii, which enables the
ride-hailing platform to select an optimal matching radius that maximizes
overall system performance according to real-time supply and demand
information. To simultaneously maximize multiple system performance metrics for
matching radius determination, we devise a novel multi-task learning algorithm
that enhances convergence speed of each task (corresponding to the optimization
of one metric) and delivers more accurate overall predictions. We evaluate our
methods in a simulation environment specifically designed for
broadcasting-mode-based ride-hailing service. Our findings reveal that
dynamically adjusting matching radii based on our proposed
predict-then-optimize approach significantly improves system performance, e.g.,
increasing platform revenue by 7.55% and enhancing order fulfillment rate by
13% compared to benchmark algorithms.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05582" title="Abstract">arXiv:2312.05582</a> [<a href="/pdf/2312.05582" title="Download PDF">pdf</a>, <a href="/ps/2312.05582" title="Download PostScript">ps</a>, <a href="/format/2312.05582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotics as a Simulation Educational Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karagounis%2C+A">Athanasios Karagounis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the evolving landscape of education, robotics has emerged as a powerful
tool for fostering creativity, critical thinking, and problem-solving skills
among students of all ages. This innovative approach to learning seamlessly
integrates STEM (Science, Technology, Engineering, and Mathematics) concepts,
creating an engaging and immersive learning experience. Educational robotics
transcends traditional classroom settings, transforming learning into a
hands-on, experiential endeavor. Students are actively involved in the design,
construction, and programming of robots, allowing them to apply theoretical
concepts to practical applications. This hands-on approach fosters deeper
understanding and retention of knowledge, making learning more meaningful and
enjoyable. In this paper, the potential of simulation robotics is evaluated as
a hands on interactive learning experience that goes beyond traditional robotic
classroom methods.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05583" title="Abstract">arXiv:2312.05583</a> [<a href="/pdf/2312.05583" title="Download PDF">pdf</a>, <a href="/format/2312.05583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Neural PDE Solvers Through Data-Free Mesh Movers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Peiyan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Recently, neural networks have been extensively employed to solve partial
differential equations (PDEs) in physical system modeling. While major studies
focus on learning system evolution on predefined static mesh discretizations,
some methods utilize reinforcement learning or supervised learning techniques
to create adaptive and dynamic meshes, due to the dynamic nature of these
systems. However, these approaches face two primary challenges: (1) the need
for expensive optimal mesh data, and (2) the change of the solution space's
degree of freedom and topology during mesh refinement. To address these
challenges, this paper proposes a neural PDE solver with a neural mesh adapter.
To begin with, we introduce a novel data-free neural mesh adaptor, called
Data-free Mesh Mover (DMM), with two main innovations. Firstly, it is an
operator that maps the solution to adaptive meshes and is trained using the
Monge-Ampere equation without optimal mesh data. Secondly, it dynamically
changes the mesh by moving existing nodes rather than adding or deleting nodes
and edges. Theoretical analysis shows that meshes generated by DMM have the
lowest interpolation error bound. Based on DMM, to efficiently and accurately
model dynamic systems, we develop a moving mesh based neural PDE solver
(MM-PDE) that embeds the moving mesh with a two-branch architecture and a
learnable interpolation framework to preserve information within the data.
Empirical experiments demonstrate that our method generates suitable meshes and
considerably enhances accuracy when modeling widely considered PDE systems.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05584" title="Abstract">arXiv:2312.05584</a> [<a href="/pdf/2312.05584" title="Download PDF">pdf</a>, <a href="/ps/2312.05584" title="Download PostScript">ps</a>, <a href="/format/2312.05584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Method of Sentiment Analysis and Machine Learning Algorithm for  the U.S. Presidential Election Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Guocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Huaiyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 tables, 3 figures, 2023 IEEE International Conference on Big Data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">U.S. Presidential Election forecasting has been a research interest for
several decades. Currently, election prediction consists of two main
approaches: traditional models that incorporate economic data and poll surveys,
and models that leverage Twitter (or X) and other social media platforms due to
their increasing popularity in the past decade. However, traditional approaches
have predominantly focused on national-level predictions, while social
media-based approaches often oversimplify the nuanced differences between
online discourse and the broader voting population's political landscape.
<br />In this work, we perform a hybrid method of both the machine learning
algorithm and the sentiment analysis on the state level with various
independent variables including census data, economic indicators, polling
averages, and the newly defined average sentiment scores from Twitter. Our
prediction for the 2020 U.S. Presidential Election yielded promising results.
Most of our models successfully predicted a victory for the Democratic
candidate with 96% accuracy using Gradient Boosting Trees and Multi-Layer
Perceptron algorithms. This novel prediction framework addresses the
limitations of existing U.S. Presidential Election forecasting approaches,
particularly in terms of state-level predictions. It provides a valuable
foundation for future research in this field and contributes to advancing our
understanding of election dynamics.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05585" title="Abstract">arXiv:2312.05585</a> [<a href="/pdf/2312.05585" title="Download PDF">pdf</a>, <a href="/ps/2312.05585" title="Download PostScript">ps</a>, <a href="/format/2312.05585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Medical Specialty Assignment to Patients using NLP Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomou%2C+C">Chris Solomou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The introduction of Large Language Models (LLMs), and the vast volume of
publicly available medical data, amplified the application of NLP to the
medical domain. However, LLMs are pretrained on data that are not explicitly
relevant to the domain that are applied to and are often biased towards the
original data they were pretrained upon. Even when pretrained on domainspecific
data, these models typically require time-consuming fine-tuning to achieve good
performance for a specific task. To address these limitations, we propose an
alternative approach that achieves superior performance while being
computationally efficient. Specifically, we utilize keywords to train a deep
learning architecture that outperforms a language model pretrained on a large
corpus of text. Our proposal does not require pretraining nor fine-tuning and
can be applied directly to a specific setting for performing multi-label
classification. Our objective is to automatically assign a new patient to the
specialty of the medical professional they require, using a dataset that
contains medical transcriptions and relevant keywords. To this end, we
fine-tune the PubMedBERT model on this dataset, which serves as the baseline
for our experiments. We then twice train/fine-tune a DNN and the RoBERTa
language model, using both the keywords and the full transcriptions as input.
We compare the performance of these approaches using relevant metrics. Our
results demonstrate that utilizing keywords for text classification
significantly improves classification performance, for both a basic DL
architecture and a large language model. Our approach represents a promising
and efficient alternative to traditional methods for finetuning language models
on domain-specific data and has potential applications in various medical
domains
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05586" title="Abstract">arXiv:2312.05586</a> [<a href="/pdf/2312.05586" title="Download PDF">pdf</a>, <a href="/format/2312.05586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deeper Understanding of Black-box Predictions via Generalized Influence  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hyeonsu Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jonggyu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Sehyun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+J">Hyun Jong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Influence functions (IFs) elucidate how learning data affects model behavior.
However, growing non-convexity and the number of parameters in modern
large-scale models lead to imprecise influence approximation and instability in
computations. We highly suspect that the first-order approximation in large
models causes such fragility, as IFs change all parameters including possibly
nuisance parameters that are irrelevant to the examined data. Thus, we attempt
to selectively analyze parameters associated with the data. However, simply
computing influence from the chosen parameters can be misleading, as it fails
to nullify the subliminal impact of unselected parameters. Our approach
introduces generalized IFs, precisely estimating target parameters' influence
while considering fixed parameters' effects. Unlike the classic IFs, we newly
adopt a method to identify pertinent target parameters closely associated with
the analyzed data. Furthermore, we tackle computational instability with a
robust inverse-Hessian-vector product approximation. Remarkably, the proposed
approximation algorithm guarantees convergence regardless of the network
configurations. We evaluated our approach on ResNet-18 and VGG-11 for class
removal and backdoor model recovery. Modifying just 10\% of the network yields
results comparable to the network retrained from scratch. Aligned with our
first guess, we also confirm that modifying an excessive number of parameters
results in a decline in network utility. We believe our proposal can become a
versatile tool for model analysis across various AI domains, appealing to both
specialists and general readers. Codes are available at
https://github.com/hslyu/GIF.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05588" title="Abstract">arXiv:2312.05588</a> [<a href="/pdf/2312.05588" title="Download PDF">pdf</a>, <a href="/format/2312.05588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-assisted Vision Model Debugger: A Sample-Free Approach to  Finding Bugs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaoquan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,8 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vision models with high overall accuracy often exhibit systematic errors in
specific scenarios, posing potential serious safety concerns. Diagnosing bugs
of vision models is gaining increased attention, however traditional diagnostic
approaches require annotation efforts (\eg rich metadata accompanying each
samples of CelebA). To address this issue,We propose a language-assisted
diagnostic method that uses texts instead of images to diagnose bugs in vision
models based on multi-modal models (\eg CLIP). Our approach connects the
embedding space of CLIP with the buggy vision model to be diagnosed; meanwhile,
utilizing a shared classifier and the cross-modal transferability of embedding
space from CLIP, the text-branch of CLIP become a proxy model to find bugs in
the buggy model. The proxy model can classify texts paired with images. During
the diagnosis, a Large Language Model (LLM) is employed to obtain task-relevant
corpora, and this corpora is used to extract keywords. Descriptions constructed
with templates containing these keywords serve as input text to probe errors in
the proxy model. Finally, we validate the ability to diagnose existing visual
models using language on the Waterbirds and CelebA datasets, we can identify
bugs comprehensible to human experts, uncovering not only known bugs but also
previously unknown ones.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05589" title="Abstract">arXiv:2312.05589</a> [<a href="/pdf/2312.05589" title="Download PDF">pdf</a>, <a href="/ps/2312.05589" title="Download PostScript">ps</a>, <a href="/format/2312.05589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Hybrid and Ensemble in Deep Learning for Natural Language  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jianguo Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youzhi Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This review presents a comprehensive exploration of hybrid and ensemble deep
learning models within Natural Language Processing (NLP), shedding light on
their transformative potential across diverse tasks such as Sentiment Analysis,
Named Entity Recognition, Machine Translation, Question Answering, Text
Classification, Generation, Speech Recognition, Summarization, and Language
Modeling. The paper systematically introduces each task, delineates key
architectures from Recurrent Neural Networks (RNNs) to Transformer-based models
like BERT, and evaluates their performance, challenges, and computational
demands. The adaptability of ensemble techniques is emphasized, highlighting
their capacity to enhance various NLP applications. Challenges in
implementation, including computational overhead, overfitting, and model
interpretation complexities, are addressed alongside the trade-off between
interpretability and performance. Serving as a concise yet invaluable guide,
this review synthesizes insights into tasks, architectures, and challenges,
offering a holistic perspective for researchers and practitioners aiming to
advance language-driven applications through ensemble deep learning in NLP.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05594" title="Abstract">arXiv:2312.05594</a> [<a href="/pdf/2312.05594" title="Download PDF">pdf</a>, <a href="/format/2312.05594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Physical Layer Communications: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Huynh%2C+N">Nguyen Van Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiacheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent evolution of generative artificial intelligence (GAI) leads to the
emergence of groundbreaking applications such as ChatGPT, which not only
enhances the efficiency of digital content production, such as text, audio,
video, or even network traffic data, but also enriches its diversity. Beyond
digital content creation, GAI's capability in analyzing complex data
distributions offers great potential for wireless communications, particularly
amidst a rapid expansion of new physical layer communication technologies. For
example, the diffusion model can learn input signal distributions and use them
to improve the channel estimation accuracy, while the variational autoencoder
can model channel distribution and infer latent variables for blind channel
equalization. Therefore, this paper presents a comprehensive investigation of
GAI's applications for communications at the physical layer, ranging from
traditional issues, including signal classification, channel estimation, and
equalization, to emerging topics, such as intelligent reflecting surfaces and
joint source channel coding. We also compare GAI-enabled physical layer
communications with those supported by traditional AI, highlighting GAI's
inherent capabilities and unique contributions in these areas. Finally, the
paper discusses open issues and proposes several future research directions,
laying a foundation for further exploration and advancement of GAI in physical
layer communications.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05596" title="Abstract">arXiv:2312.05596</a> [<a href="/pdf/2312.05596" title="Download PDF">pdf</a>, <a href="/format/2312.05596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factorized Explainer for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rundong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shirani%2C+F">Farhad Shirani</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongsheng Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have received increasing attention due to their
ability to learn from graph-structured data. To open the black-box of these
deep learning models, post-hoc instance-level explanation methods have been
proposed to understand GNN predictions. These methods seek to discover
substructures that explain the prediction behavior of a trained GNN. In this
paper, we show analytically that for a large class of explanation tasks,
conventional approaches, which are based on the principle of graph information
bottleneck (GIB), admit trivial solutions that do not align with the notion of
explainability. Instead, we argue that a modified GIB principle may be used to
avoid the aforementioned trivial solutions. We further introduce a novel
factorized explanation model with theoretical performance guarantees. The
modified GIB is used to analyze the structural properties of the proposed
factorized explainer. We conduct extensive experiments on both synthetic and
real-world datasets to validate the effectiveness of our proposed factorized
explainer over existing approaches.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05597" title="Abstract">arXiv:2312.05597</a> [<a href="/pdf/2312.05597" title="Download PDF">pdf</a>, <a href="/ps/2312.05597" title="Download PostScript">ps</a>, <a href="/format/2312.05597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence in the automatic coding of interviews on  Landscape Quality Objectives. Comparison and case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burgui-Burgui%2C+M">Mario Burgui-Burgui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this study, we conducted a comparative analysis of the automated coding
provided by three Artificial Intelligence functionalities (At-las.ti, ChatGPT
and Google Bard) in relation to the manual coding of 12 research interviews
focused on Landscape Quality Objectives for a small island in the north of Cuba
(Cayo Santa Mar\'ia). For this purpose, the following comparison criteria were
established: Accuracy, Comprehensiveness, Thematic Coherence, Redundancy,
Clarity, Detail and Regularity. The analysis showed the usefulness of AI for
the intended purpose, albeit with numerous flaws and shortcomings. In summary,
today the automatic coding of AIs can be considered useful as a guide towards a
subsequent in-depth and meticulous analysis of the information by the
researcher. However, as this is such a recently developed field, rapid
evolution is expected to bring the necessary improvements to these tools.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05598" title="Abstract">arXiv:2312.05598</a> [<a href="/pdf/2312.05598" title="Download PDF">pdf</a>, <a href="/format/2312.05598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting the Cross-Architecture Generalization of Dataset Distillation  through an Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingbao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+F">Fei Chao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The poor cross-architecture generalization of dataset distillation greatly
weakens its practical significance. This paper attempts to mitigate this issue
through an empirical study, which suggests that the synthetic datasets undergo
an inductive bias towards the distillation model. Therefore, the evaluation
model is strictly confined to having similar architectures of the distillation
model. We propose a novel method of EvaLuation with distillation Feature (ELF),
which utilizes features from intermediate layers of the distillation model for
the cross-architecture evaluation. In this manner, the evaluation model learns
from bias-free knowledge therefore its architecture becomes unfettered while
retaining performance. By performing extensive experiments, we successfully
prove that ELF can well enhance the cross-architecture generalization of
current DD methods. Code of this project is at
\url{https://github.com/Lirui-Zhao/ELF}.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05599" title="Abstract">arXiv:2312.05599</a> [<a href="/pdf/2312.05599" title="Download PDF">pdf</a>, <a href="/format/2312.05599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Data Matters: An End-to-End Adaptive Dataset Pruning Framework  for Enhancing Model Performance and Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Suorong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Suhan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Furao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While deep neural networks have demonstrated remarkable performance across
various tasks, they typically require massive training data. Due to the
presence of redundancies and biases in real-world datasets, not all data in the
training dataset contributes to the model performance. To address this issue,
dataset pruning techniques have been introduced to enhance model performance
and efficiency by eliminating redundant training samples and reducing
computational and memory overhead. However, previous works most rely on
manually crafted scalar scores, limiting their practical performance and
scalability across diverse deep networks and datasets. In this paper, we
propose AdaPruner, an end-to-end Adaptive DAtaset PRUNing framEwoRk. AdaPruner
can perform effective dataset pruning without the need for explicitly defined
metrics. Our framework jointly prunes training data and fine-tunes models with
task-specific optimization objectives. AdaPruner leverages (1) An adaptive
dataset pruning (ADP) module, which iteratively prunes redundant samples to an
expected pruning ratio; and (2) A pruning performance controller (PPC) module,
which optimizes the model performance for accurate pruning. Therefore,
AdaPruner exhibits high scalability and compatibility across various datasets
and deep networks, yielding improved dataset distribution and enhanced model
performance. AdaPruner can still significantly enhance model performance even
after pruning up to 10-30\% of the training data. Notably, these improvements
are accompanied by substantial savings in memory and computation costs.
Qualitative and quantitative experiments suggest that AdaPruner outperforms
other state-of-the-art dataset pruning methods by a large margin.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05601" title="Abstract">arXiv:2312.05601</a> [<a href="/pdf/2312.05601" title="Download PDF">pdf</a>, <a href="/format/2312.05601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Meshless Solver for Blood Flow Simulations in Elastic Vessels Using  Physics-Informed Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/math?searchtype=author&query=Chan%2C+R">Raymond Chan</a>, 
<a href="/search/math?searchtype=author&query=Tai%2C+X">Xue-Cheng Tai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Investigating blood flow in the cardiovascular system is crucial for
assessing cardiovascular health. Computational approaches offer some
non-invasive alternatives to measure blood flow dynamics. Numerical simulations
based on traditional methods such as finite-element and other numerical
discretizations have been extensively studied and have yielded excellent
results. However, adapting these methods to real-life simulations remains a
complex task. In this paper, we propose a method that offers flexibility and
can efficiently handle real-life simulations. We suggest utilizing the
physics-informed neural network (PINN) to solve the Navier-Stokes equation in a
deformable domain, specifically addressing the simulation of blood flow in
elastic vessels. Our approach models blood flow using an incompressible,
viscous Navier-Stokes equation in an Arbitrary Lagrangian-Eulerian form. The
mechanical model for the vessel wall structure is formulated by an equation of
Newton's second law of momentum and linear elasticity to the force exerted by
the fluid flow. Our method is a mesh-free approach that eliminates the need for
discretization and meshing of the computational domain. This makes it highly
efficient in solving simulations involving complex geometries. Additionally,
with the availability of well-developed open-source machine learning framework
packages and parallel modules, our method can easily be accelerated through GPU
computing and parallel computing. To evaluate our approach, we conducted
experiments on regular cylinder vessels as well as vessels with plaque on their
walls. We compared our results to a solution calculated by Finite Element
Methods using a dense grid and small time steps, which we considered as the
ground truth solution. We report the relative error and the time consumed to
solve the problem, highlighting the advantages of our method.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05602" title="Abstract">arXiv:2312.05602</a> [<a href="/pdf/2312.05602" title="Download PDF">pdf</a>, <a href="/format/2312.05602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EipFormer: Emphasizing Instance Positions in 3D Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengnan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqiu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">3D instance segmentation plays a crucial role in comprehending 3D scenes.
Despite recent advancements in this field, existing approaches exhibit certain
limitations. These methods often rely on fixed instance positions obtained from
sampled representative points in vast 3D point clouds, using center prediction
or farthest point sampling. However, these selected positions may deviate from
actual instance centers, posing challenges in precisely grouping instances.
Moreover, the common practice of grouping candidate instances from a single
type of coordinates introduces difficulties in identifying neighboring
instances or incorporating edge points. To tackle these issues, we present a
novel Transformer-based architecture, EipFormer, which comprises progressive
aggregation and dual position embedding. The progressive aggregation mechanism
leverages instance positions to refine instance proposals. It enhances the
initial instance positions through weighted farthest point sampling and further
refines the instance positions and proposals using aggregation averaging and
center matching. Additionally, dual position embedding superposes the original
and centralized position embeddings, thereby enhancing the model performance in
distinguishing adjacent instances. Extensive experiments on popular datasets
demonstrate that EipFormer achieves superior or comparable performance compared
to state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05603" title="Abstract">arXiv:2312.05603</a> [<a href="/pdf/2312.05603" title="Download PDF">pdf</a>, <a href="/format/2312.05603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-GPT: Text Similarity via GPT Annotated Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Beiming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoya Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+E">Eduard Hovy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to the lack of a large collection of high-quality labeled sentence pairs
with textual similarity scores, existing approaches for Semantic Textual
Similarity (STS) mostly rely on unsupervised techniques or training signals
that are only partially correlated with textual similarity, e.g., NLI-based
datasets. To tackle this issue, in this paper, we propose the strategy of
measuring text similarity via GPT annotated data (Sim-GPT for short). The core
idea of Sim-GPT is to generate data with STS labels using GPT-4, based on which
an STS model is trained. Sim-GPT framework utilizes LLMs to provide a
substantial amount of reliable annotated data filling the gap of the lack of
training signals for STS. Sim-GPT is trained on a one-time generated dataset
using BERT or RoBERTa as the backbone, which offers long-term savings in cost
and speed compared to repeatedly invoking LLMs for each sentence pair. Trained
on the examples from GPT-4 (371K), Sim-GPT yields SOTA performances on the
widely-used seven STS benchmarks: +0.99 over supervised-SimCSE, and +0.42 over
the current SOTA PromCSE model. To encourage further advancements of the field,
we release both models and the 371K annotated examples from GPT-4. Code, models
and annotated data are available at: https://github.com/ShuheWang1998/Sim-GPT.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05605" title="Abstract">arXiv:2312.05605</a> [<a href="/pdf/2312.05605" title="Download PDF">pdf</a>, <a href="/format/2312.05605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCNCA: Temporal Convolution Network with Chunked Attention for Scalable  Sequence Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terzic%2C+A">Aleksandar Terzic</a>, 
<a href="/search/cs?searchtype=author&query=Hersche%2C+M">Michael Hersche</a>, 
<a href="/search/cs?searchtype=author&query=Karunaratne%2C+G">Geethan Karunaratne</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abu Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A">Abbas Rahimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">MEGA is a recent transformer-based architecture, which utilizes a linear
recurrent operator whose parallel computation, based on the FFT, scales as
$O(LlogL)$, with $L$ being the sequence length. We build upon their approach by
replacing the linear recurrence with a special temporal convolutional network
which permits larger receptive field size with shallower networks, and reduces
the computational complexity to $O(L)$. The resulting model is called TCNCA, a
Temporal Convolutional Network with Chunked Attention. We evaluate TCNCA on
EnWik8 language modeling, long-range-arena (LRA) sequence classification, as
well as a synthetic reasoning benchmark associative recall. On EnWik8, TCNCA
outperforms MEGA, reaching a lower loss with $1.37\times$/$1.24\times$ faster
forward/backward pass during training. The dilated convolutions used in TCNCA
are consistently and significantly faster operations than the FFT-based
parallelized recurrence in GPUs, making them a scalable candidate for handling
very large sequence lengths: they are up to $7.07\times$/$2.86\times$ faster in
the forward/backward pass for sequences up to 131k. Further on LRA, TCNCA
achieves, on average, $1.28\times$ speed-up during inference with similar
accuracy to what MEGA achieves. On associative recall, we find that even a
simplified version of TCNCA, without excessive multiplicative and additive
interactions, remains superior or competitive to MEGA on a range of sequence
lengths and vocabulary sizes.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05607" title="Abstract">arXiv:2312.05607</a> [<a href="/pdf/2312.05607" title="Download PDF">pdf</a>, <a href="/ps/2312.05607" title="Download PostScript">ps</a>, <a href="/format/2312.05607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed-Loop Finite-Time Analysis of Suboptimal Online Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Karapetyan%2C+A">Aren Karapetyan</a>, 
<a href="/search/eess?searchtype=author&query=Balta%2C+E+C">Efe C. Balta</a>, 
<a href="/search/eess?searchtype=author&query=Iannelli%2C+A">Andrea Iannelli</a>, 
<a href="/search/eess?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Suboptimal methods in optimal control arise due to a limited computational
budget, unknown system dynamics, or a short prediction window among other
reasons. Although these methods are ubiquitous, their transient performance
remains relatively unstudied. We consider the control of discrete-time,
nonlinear time-varying dynamical systems and establish sufficient conditions to
analyze the finite-time closed-loop performance of such methods in terms of the
additional cost incurred due to suboptimality. Finite-time guarantees allow the
control design to distribute a limited computational budget over a time horizon
and estimate the on-the-go loss in performance due to sub-optimality. We study
exponential incremental input-to-state stabilizing policies, and show that for
nonlinear systems, under some mild conditions, this property is directly
implied by exponential stability without further assumptions on global
smoothness. The analysis is showcased on a suboptimal model predictive control
use case.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05611" title="Abstract">arXiv:2312.05611</a> [<a href="/pdf/2312.05611" title="Download PDF">pdf</a>, <a href="/format/2312.05611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triplet Edge Attention for Algorithmic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+Y">Yeonjoon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungsoo Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work investigates neural algorithmic reasoning to develop neural
networks capable of learning from classical algorithms. The main challenge is
to develop graph neural networks that are expressive enough to predict the
given algorithm outputs while generalizing well to out-of-distribution data. In
this work, we introduce a new graph neural network layer called Triplet Edge
Attention (TEA), an edge-aware graph attention layer. Our algorithm works by
precisely computing edge latent, aggregating multiple triplet messages using
edge-based attention. We empirically validate our TEA layer in the CLRS
benchmark and demonstrate a $5%$ improvement on average. In particular, we
achieve a $30%$ improvement for the string algorithms compared to the
state-of-the-art model.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05614" title="Abstract">arXiv:2312.05614</a> [<a href="/pdf/2312.05614" title="Download PDF">pdf</a>, <a href="/format/2312.05614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer as Linear Expansion of Learngene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shiyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaosen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose expanding the shared Transformer module to produce and initialize
Transformers with diverse depths, enabling adaptation to dynamic resource
constraints. Drawing an analogy to genetic expansibility, we term such module
as learngene. To identify the expansion mechanism, we delve into the
relationship between the layer position and its corresponding weight value, and
find that linear function appropriately approximates this relationship.
Building on this insight, we present Transformer as Linear Expansion of
learnGene (TLEG), a novel approach for flexibly producing and initializing
Transformers of diverse depths. Specifically, to learn learngene, we firstly
construct an auxiliary Transformer linearly expanded from learngene, after
which we train it through employing soft distillation. Subsequently, we can
produce and initialize Transformers of varying depths via linearly expanding
the well-trained learngene, thereby supporting diverse downstream scenarios.
Extensive experiments on ImageNet-1K classification demonstrate that TLEG
achieves comparable or better performance compared to many individual models
trained from scratch, while reducing around 2$\times$ training cost. When
transferring one model to several downstream classification datasets, TLEG
surpasses existing initialization methods by a large margin (e.g., +6.87% on
iNat 2019 and +7.66% on CIFAR-100). Under the situation where we need to
produce models of different scales adapting for different resource constraints,
TLEG achieves comparable results while reducing around 19$\times$ parameters
stored to initialize these models and around 5$\times$ training costs, in
contrast to the pre-training and fine-tuning approach.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05616" title="Abstract">arXiv:2312.05616</a> [<a href="/pdf/2312.05616" title="Download PDF">pdf</a>, <a href="/format/2312.05616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Token Evaluation and Refinement for Real-World  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shangchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI2024, <a href="https://github.com/chaofengc/ITER">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-world image super-resolution (RWSR) is a long-standing problem as
low-quality (LQ) images often have complex and unidentified degradations.
Existing methods such as Generative Adversarial Networks (GANs) or continuous
diffusion models present their own issues including GANs being difficult to
train while continuous diffusion models requiring numerous inference steps. In
this paper, we propose an Iterative Token Evaluation and Refinement (ITER)
framework for RWSR, which utilizes a discrete diffusion model operating in the
discrete token representation space, i.e., indexes of features extracted from a
VQGAN codebook pre-trained with high-quality (HQ) images. We show that ITER is
easier to train than GANs and more efficient than continuous diffusion models.
Specifically, we divide RWSR into two sub-tasks, i.e., distortion removal and
texture generation. Distortion removal involves simple HQ token prediction with
LQ images, while texture generation uses a discrete diffusion model to
iteratively refine the distortion removal output with a token refinement
network. In particular, we propose to include a token evaluation network in the
discrete diffusion process. It learns to evaluate which tokens are good
restorations and helps to improve the iterative refinement results. Moreover,
the evaluation network can first check status of the distortion removal output
and then adaptively select total refinement steps needed, thereby maintaining a
good balance between distortion removal and texture generation. Extensive
experimental results show that ITER is easy to train and performs well within
just 8 iterative steps. Our codes will be available publicly.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05621" title="Abstract">arXiv:2312.05621</a> [<a href="/pdf/2312.05621" title="Download PDF">pdf</a>, <a href="/format/2312.05621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhenting Qi</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiaoyu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shaojie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 (Industry Track), Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction fine-tuning has conventionally been employed to adapt Large
Language Models (LLMs) to a variety of tasks. Nonetheless, this technique often
necessitates substantial computational resources, making it impractical for
deployment by individuals or small-scale entities. Recently, Low-Rank
Adaptation (LoRA) has become a promising alternative, offering high
capabilities on par with full tuning with reduced resource overhead. However,
attaining satisfactory performance through the fine-tuning of LoRA is a
non-trivial challenge. In this paper, we propose PILLOW, which aims to improve
LoRA's performance by a discrimination-based prompting method, leveraging LLMs'
In-Context Learning ability. PILLOW incorporates a matching network that
selects prompts from a user-defined prompt pool, concatenates the selected
prompts with the user instruction as input, and performs inference using the
LoRA-fine-tuned LLMs. Trained with Reinforcement Learning, PILLOW exhibits
commensurate performance on various evaluation metrics compared with typical
instruction fine-tuning methods, utilizing only consumer-grade GPU resources
and exhibiting a large reduction in computational costs.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05623" title="Abstract">arXiv:2312.05623</a> [<a href="/pdf/2312.05623" title="Download PDF">pdf</a>, <a href="/format/2312.05623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Urban Street Geometry on the Detection Probability of  Automotive Radars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+M+T">Mohammad Taha Shah</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ankit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Ghatak%2C+G">Gourab Ghatak</a>, 
<a href="/search/cs?searchtype=author&query=Ram%2C+S+S">Shobha Sundar Ram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Radar Conference 2024 (RadarConf24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Prior works have analyzed the performance of millimeter wave automotive
radars in the presence of diverse clutter and interference scenarios using
stochastic geometry tools instead of more time-consuming measurement studies or
system-level simulations. In these works, the distributions of radars or
discrete clutter scatterers were modeled as Poisson point processes in the
Euclidean space. However, since most automotive radars are likely to be mounted
on vehicles and road infrastructure, road geometries are an important factor
that must be considered. Instead of considering each road geometry as an
individual case for study, in this work, we model each case as a specific
instance of an underlying Poisson line process and further model the
distribution of vehicles on the road as a Poisson point process - forming a
Poisson line Cox process. Then, through the use of stochastic geometry tools,
we estimate the average number of interfering radars for specific road and
vehicular densities and the effect of radar parameters such as noise and
beamwidth on the radar detection metrics. The numerical results are validated
with Monte Carlo simulations.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05626" title="Abstract">arXiv:2312.05626</a> [<a href="/pdf/2312.05626" title="Download PDF">pdf</a>, <a href="/format/2312.05626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Developer Assistance: Through Large Language Models in  Software Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Avik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+A">Amruit Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Joyce%2C+S+C">Sam Conrad Joyce</a>, 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we delve into the advancement of domain-specific Large
Language Models (LLMs) with a focus on their application in software
development. We introduce DevAssistLlama, a model developed through instruction
tuning, to assist developers in processing software-related natural language
queries. This model, a variant of instruction tuned LLM, is particularly adept
at handling intricate technical documentation, enhancing developer capability
in software specific tasks. The creation of DevAssistLlama involved
constructing an extensive instruction dataset from various software systems,
enabling effective handling of Named Entity Recognition (NER), Relation
Extraction (RE), and Link Prediction (LP). Our results demonstrate
DevAssistLlama's superior capabilities in these tasks, in comparison with other
models including ChatGPT. This research not only highlights the potential of
specialized LLMs in software development also the pioneer LLM for this domain.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05629" title="Abstract">arXiv:2312.05629</a> [<a href="/pdf/2312.05629" title="Download PDF">pdf</a>, <a href="/format/2312.05629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Situational Awareness in Surveillance: Leveraging Data  Visualization Techniques for Machine Learning-based Video Analytics Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ardabili%2C+B+R">Babak Rahimi Ardabili</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shanle Yao</a>, 
<a href="/search/cs?searchtype=author&query=Pazho%2C+A+D">Armin Danesh Pazho</a>, 
<a href="/search/cs?searchtype=author&query=Bourque%2C+L">Lauren Bourque</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The pervasive deployment of surveillance cameras produces a massive volume of
data, requiring nuanced interpretation. This study thoroughly examines data
representation and visualization techniques tailored for AI surveillance data
within current infrastructures. It delves into essential data metrics, methods
for situational awareness, and various visualization techniques, highlighting
their potential to enhance safety and guide urban development. This study is
built upon real-world research conducted in a community college environment,
utilizing eight cameras over eight days. This study presents tools like the
Occupancy Indicator, Statistical Anomaly Detection, Bird's Eye View, and
Heatmaps to elucidate pedestrian behaviors, surveillance, and public safety.
Given the intricate data from smart video surveillance, such as bounding boxes
and segmented images, we aim to convert these computer vision results into
intuitive visualizations and actionable insights for stakeholders, including
law enforcement, urban planners, and social scientists. The results emphasize
the crucial impact of visualizing AI surveillance data on emergency handling,
public health protocols, crowd control, resource distribution, predictive
modeling, city planning, and informed decision-making.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05631" title="Abstract">arXiv:2312.05631</a> [<a href="/pdf/2312.05631" title="Download PDF">pdf</a>, <a href="/format/2312.05631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test Generation Strategies for Building Failure Models and Explaining  Spurious Failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jodat%2C+B+A">Baharin Aliashrafi Jodat</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+A">Abhishek Chandar</a>, 
<a href="/search/cs?searchtype=author&query=Nejati%2C+S">Shiva Nejati</a>, 
<a href="/search/cs?searchtype=author&query=Sabetzadeh%2C+M">Mehrdad Sabetzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at the ACM Transactions on Software Engineering and Methodology (TOSEM) in December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Test inputs fail not only when the system under test is faulty but also when
the inputs are invalid or unrealistic. Failures resulting from invalid or
unrealistic test inputs are spurious. Avoiding spurious failures improves the
effectiveness of testing in exercising the main functions of a system,
particularly for compute-intensive (CI) systems where a single test execution
takes significant time. In this paper, we propose to build failure models for
inferring interpretable rules on test inputs that cause spurious failures. We
examine two alternative strategies for building failure models: (1) machine
learning (ML)-guided test generation and (2) surrogate-assisted test
generation. ML-guided test generation infers boundary regions that separate
passing and failing test inputs and samples test inputs from those regions.
Surrogate-assisted test generation relies on surrogate models to predict labels
for test inputs instead of exercising all the inputs. We propose a novel
surrogate-assisted algorithm that uses multiple surrogate models
simultaneously, and dynamically selects the prediction from the most accurate
model. We empirically evaluate the accuracy of failure models inferred based on
surrogate-assisted and ML-guided test generation algorithms. Using case studies
from the domains of cyber-physical systems and networks, we show that our
proposed surrogate-assisted approach generates failure models with an average
accuracy of 83%, significantly outperforming ML-guided test generation and two
baselines. Further, our approach learns failure-inducing rules that identify
genuine spurious failures as validated against domain knowledge.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05632" title="Abstract">arXiv:2312.05632</a> [<a href="/pdf/2312.05632" title="Download PDF">pdf</a>, <a href="/format/2312.05632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subject-Based Domain Adaptation for Facial Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeeshan%2C+M+O">Muhammad Osama Zeeshan</a>, 
<a href="/search/cs?searchtype=author&query=Aslam%2C+M+H">Muhammad Haseeb Aslam</a>, 
<a href="/search/cs?searchtype=author&query=Belharbi%2C+S">Soufiane Belharbi</a>, 
<a href="/search/cs?searchtype=author&query=Koerich%2C+A+L">Alessandro L. Koerich</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Bacon%2C+S">Simon Bacon</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adapting a deep learning (DL) model to a specific target individual is a
challenging task in facial expression recognition (FER) that may be achieved
using unsupervised domain adaptation (UDA) methods. Although several UDA
methods have been proposed to adapt deep FER models across source and target
data sets, multiple subject-specific source domains are needed to accurately
represent the intra- and inter-person variability in subject-based adaption. In
this paper, we consider the setting where domains correspond to individuals,
not entire datasets. Unlike UDA, multi-source domain adaptation (MSDA) methods
can leverage multiple source datasets to improve the accuracy and robustness of
the target model. However, previous methods for MSDA adapt image classification
models across datasets and do not scale well to a larger number of source
domains. In this paper, a new MSDA method is introduced for subject-based
domain adaptation in FER. It efficiently leverages information from multiple
source subjects (labeled source domain data) to adapt a deep FER model to a
single target individual (unlabeled target domain data). During adaptation, our
Subject-based MSDA first computes a between-source discrepancy loss to mitigate
the domain shift among data from several source subjects. Then, a new strategy
is employed to generate augmented confident pseudo-labels for the target
subject, allowing a reduction in the domain shift between source and target
subjects. Experiments\footnote{\textcolor{red}{\textbf{Supplementary material}
contains our code, which will be made public, and additional experimental
results.}} on the challenging BioVid heat and pain dataset (PartA) with 87
subjects shows that our Subject-based MSDA can outperform state-of-the-art
methods yet scale well to multiple subject-based source domains.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05634" title="Abstract">arXiv:2312.05634</a> [<a href="/pdf/2312.05634" title="Download PDF">pdf</a>, <a href="/format/2312.05634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose Guidance by Supervision: A Framework for Clothes-Changing Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trinh%2C+Q">Quoc-Huy Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/cs?searchtype=author&query=Thi%2C+P+V">Phuoc-Thao Vo Thi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hai-Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Person Re-Identification (ReID) task seeks to enhance the tracking of
multiple individuals by surveillance cameras. It provides additional support
for multimodal tasks, including text-based person retrieval and human matching.
One of the primary challenges in ReID is clothes-changing, which means the same
person wears different clothes. While previous methods have achieved
competitive results in maintaining clothing data consistency and handling
clothing change data, they still tend to rely excessively on clothing
information, thus limiting performance due to the dynamic nature of human
appearances. To mitigate this challenge, we propose the Pose Guidance by
Supervision (PGS) framework, an effective framework for learning pose guidance
within the ReID task. This approach leverages pose knowledge and human part
information from the pre-trained features to guide the network focus on
clothes-irrelevant information, thus alleviating the clothes' influence on the
deep learning model. Extensive experiments on five benchmark datasets
demonstrate that our framework achieves competitive results compared with other
state-of-the-art methods, which holds promise for developing robust models in
the ReID task. Our code is available at https://github.com/huyquoctrinh/PGS.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05639" title="Abstract">arXiv:2312.05639</a> [<a href="/pdf/2312.05639" title="Download PDF">pdf</a>, <a href="/format/2312.05639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JITSPMM: Just-in-Time Instruction Generation for Accelerated Sparse  Matrix-Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Rolinger%2C+T+B">Thomas B. Rolinger</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H+H">H. Howie Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF); Programming Languages (cs.PL)

</div>
<p class="mathjax">Achieving high performance for Sparse MatrixMatrix Multiplication (SpMM) has
received increasing research attention, especially on multi-core CPUs, due to
the large input data size in applications such as graph neural networks (GNNs).
Most existing solutions for SpMM computation follow the aheadof-time (AOT)
compilation approach, which compiles a program entirely before it is executed.
AOT compilation for SpMM faces three key limitations: unnecessary memory
access, additional branch overhead, and redundant instructions. These
limitations stem from the fact that crucial information pertaining to SpMM is
not known until runtime. In this paper, we propose JITSPMM, a just-in-time
(JIT) assembly code generation framework to accelerated SpMM computation on
multi-core CPUs with SIMD extensions. First, JITSPMM integrates the JIT
assembly code generation technique into three widely-used workload division
methods for SpMM to achieve balanced workload distribution among CPU threads.
Next, with the availability of runtime information, JITSPMM employs a novel
technique, coarse-grain column merging, to maximize instruction-level
parallelism by unrolling the performance-critical loop. Furthermore, JITSPMM
intelligently allocates registers to cache frequently accessed data to
minimizing memory accesses, and employs selected SIMD instructions to enhance
arithmetic throughput. We conduct a performance evaluation of JITSPMM and
compare it two AOT baselines. The first involves existing SpMM implementations
compiled using the Intel icc compiler with auto-vectorization. The second
utilizes the highly-optimized SpMM routine provided by Intel MKL. Our results
show that JITSPMM provides an average improvement of 3.8x and 1.4x,
respectively.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05640" title="Abstract">arXiv:2312.05640</a> [<a href="/pdf/2312.05640" title="Download PDF">pdf</a>, <a href="/format/2312.05640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keyword spotting -- Detecting commands in speech using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+S">Sumedha Rai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+B">Bella Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech recognition has become an important task in the development of machine
learning and artificial intelligence. In this study, we explore the important
task of keyword spotting using speech recognition machine learning and deep
learning techniques. We implement feature engineering by converting raw
waveforms to Mel Frequency Cepstral Coefficients (MFCCs), which we use as
inputs to our models. We experiment with several different algorithms such as
Hidden Markov Model with Gaussian Mixture, Convolutional Neural Networks and
variants of Recurrent Neural Networks including Long Short-Term Memory and the
Attention mechanism. In our experiments, RNN with BiLSTM and Attention achieves
the best performance with an accuracy of 93.9 %
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05642" title="Abstract">arXiv:2312.05642</a> [<a href="/pdf/2312.05642" title="Download PDF">pdf</a>, <a href="/format/2312.05642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speed Up Federated Learning in Heterogeneous Environment: A Dynamic  Tiering Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadabadi%2C+S+M+S">Seyed Mahmoud Sajjadi Mohammadabadi</a>, 
<a href="/search/cs?searchtype=author&query=Zawad%2C+S">Syed Zawad</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+F">Feng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Performance (cs.PF)

</div>
<p class="mathjax">Federated learning (FL) enables collaboratively training a model while
keeping the training data decentralized and private. However, one significant
impediment to training a model using FL, especially large models, is the
resource constraints of devices with heterogeneous computation and
communication capacities as well as varying task sizes. Such heterogeneity
would render significant variations in the training time of clients, resulting
in a longer overall training time as well as a waste of resources in faster
clients. To tackle these heterogeneity issues, we propose the Dynamic
Tiering-based Federated Learning (DTFL) system where slower clients dynamically
offload part of the model to the server to alleviate resource constraints and
speed up training. By leveraging the concept of Split Learning, DTFL offloads
different portions of the global model to clients in different tiers and
enables each client to update the models in parallel via local-loss-based
training. This helps reduce the computation and communication demand on
resource-constrained devices and thus mitigates the straggler problem. DTFL
introduces a dynamic tier scheduler that uses tier profiling to estimate the
expected training time of each client, based on their historical training time,
communication speed, and dataset size. The dynamic tier scheduler assigns
clients to suitable tiers to minimize the overall training time in each round.
We first theoretically prove the convergence properties of DTFL. We then train
large models (ResNet-56 and ResNet-110) on popular image datasets (CIFAR-10,
CIFAR-100, CINIC-10, and HAM10000) under both IID and non-IID systems.
Extensive experimental results show that compared with state-of-the-art FL
methods, DTFL can significantly reduce the training time while maintaining
model accuracy.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05643" title="Abstract">arXiv:2312.05643</a> [<a href="/pdf/2312.05643" title="Download PDF">pdf</a>, <a href="/format/2312.05643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NiSNN-A: Non-iterative Spiking Neural Networks with Attention with  Application to Motor Imagery EEG Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Motor imagery, an important category in electroencephalogram (EEG) research,
often intersects with scenarios demanding low energy consumption, such as
portable medical devices and isolated environment operations. Traditional deep
learning algorithms, despite their effectiveness, are characterized by
significant computational demands accompanied by high energy usage. As an
alternative, spiking neural networks (SNNs), inspired by the biological
functions of the brain, emerge as a promising energy-efficient solution.
However, SNNs typically exhibit lower accuracy than their counterpart
convolutional neural networks (CNNs). Although attention mechanisms
successfully increase network accuracy by focusing on relevant features, their
integration in the SNN framework remains an open question. In this work, we
combine the SNN and the attention mechanisms for the EEG classification, aiming
to improve precision and reduce energy consumption. To this end, we first
propose a Non-iterative Leaky Integrate-and-Fire (LIF) neuron model, overcoming
the gradient issues in the traditional SNNs using the Iterative LIF neurons.
Then, we introduce the sequence-based attention mechanisms to refine the
feature map. We evaluated the proposed Non-iterative SNN with Attention
(NiSNN-A) model on OpenBMI, a large-scale motor imagery dataset. Experiment
results demonstrate that 1) our model outperforms other SNN models by achieving
higher accuracy, 2) our model increases energy efficiency compared to the
counterpart CNN models (i.e., by 2.27 times) while maintaining comparable
accuracy.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05654" title="Abstract">arXiv:2312.05654</a> [<a href="/pdf/2312.05654" title="Download PDF">pdf</a>, <a href="/format/2312.05654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral methods for Neural Integral Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zappala%2C+E">Emanuele Zappala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Neural integral equations are deep learning models based on the theory of
integral equations, where the model consists of an integral operator and the
corresponding equation (of the second kind) which is learned through an
optimization procedure. This approach allows to leverage the nonlocal
properties of integral operators in machine learning, but it is computationally
expensive. In this article, we introduce a framework for neural integral
equations based on spectral methods that allows us to learn an operator in the
spectral domain, resulting in a cheaper computational cost, as well as in high
interpolation accuracy. We study the properties of our methods and show various
theoretical guarantees regarding the approximation capabilities of the model,
and convergence to solutions of the numerical methods. We provide numerical
experiments to demonstrate the practical effectiveness of the resulting model.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05657" title="Abstract">arXiv:2312.05657</a> [<a href="/pdf/2312.05657" title="Download PDF">pdf</a>, <a href="/format/2312.05657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Reinforcement Learning and Large Language Models for Code  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shukai Duan</a>, 
<a href="/search/cs?searchtype=author&query=Kanakaris%2C+N">Nikos Kanakaris</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+H">Heng Ping</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guixiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Capota%2C+M">Mihai Capota</a>, 
<a href="/search/cs?searchtype=author&query=Willke%2C+T+L">Theodore L. Willke</a>, 
<a href="/search/cs?searchtype=author&query=Nazarian%2C+S">Shahin Nazarian</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Code optimization is a daunting task that requires a significant level of
expertise from experienced programmers. This level of expertise is not
sufficient when compared to the rapid development of new hardware
architectures. Towards advancing the whole code optimization process, recent
approaches rely on machine learning and artificial intelligence techniques.
This paper introduces a new framework to decrease the complexity of code
optimization. The proposed framework builds on large language models (LLMs) and
reinforcement learning (RL) and enables LLMs to receive feedback from their
environment (i.e., unit tests) during the fine-tuning process. We compare our
framework with existing state-of-the-art models and show that it is more
efficient with respect to speed and computational usage, as a result of the
decrement in training steps and its applicability to models with fewer
parameters. Additionally, our framework reduces the possibility of logical and
syntactical errors. Toward evaluating our approach, we run several experiments
on the PIE dataset using a CodeT5 language model and RRHF, a new reinforcement
learning algorithm. We adopt a variety of evaluation metrics with regards to
optimization quality, and speedup. The evaluation results demonstrate that the
proposed framework has similar results in comparison with existing models using
shorter training times and smaller pre-trained models. In particular, we
accomplish an increase of 5.6% and 2.2 over the baseline models concerning the
%OP T and SP metrics.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05658" title="Abstract">arXiv:2312.05658</a> [<a href="/pdf/2312.05658" title="Download PDF">pdf</a>, <a href="/ps/2312.05658" title="Download PostScript">ps</a>, <a href="/format/2312.05658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monoid Theory in Alonzo: A Little Theories Formalization in Simple Type  Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farmer%2C+W+M">William M. Farmer</a>, 
<a href="/search/cs?searchtype=author&query=Zvigelsky%2C+D+Y">Dennis Y. Zvigelsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 76 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">Alonzo is a practice-oriented classical higher-order logic that extends
first-order logic and that admits undefined expressions. Named in honor of
Alonzo Church, Alonzo is based on Church's type theory, Church's formulation of
simple type theory. The little theories method is a method for formalizing
mathematical knowledge as a network of theories called a theory graph
consisting of theories as nodes and theory morphisms as directed edges. The
development of a mathematical topic is done in the "little theory" in the
theory graph that has the most convenient level of abstraction and the most
convenient vocabulary, and then the definitions and theorems produced in the
development are transported, as needed, to other theories via the theory
morphisms in the theory graph. The purpose of this paper is to illustrate how a
body of mathematical knowledge can be formalized in Alonzo using the little
theories method. This is done by formalizing monoid theory -- the body of
mathematical knowledge about monoids -- in Alonzo.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05659" title="Abstract">arXiv:2312.05659</a> [<a href="/pdf/2312.05659" title="Download PDF">pdf</a>, <a href="/format/2312.05659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Unbiased Randomizers for Regression with Label Differential  Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badanidiyuru%2C+A">Ashwinkumar Badanidiyuru</a>, 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+B">Badih Ghazi</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+P">Pritish Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ravi Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Leeman%2C+E">Ethan Leeman</a>, 
<a href="/search/cs?searchtype=author&query=Manurangsi%2C+P">Pasin Manurangsi</a>, 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+A+V">Avinash V Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings version to appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We propose a new family of label randomizers for training regression models
under the constraint of label differential privacy (DP). In particular, we
leverage the trade-offs between bias and variance to construct better label
randomizers depending on a privately estimated prior distribution over the
labels. We demonstrate that these randomizers achieve state-of-the-art
privacy-utility trade-offs on several datasets, highlighting the importance of
reducing bias when training neural networks with label DP. We also provide
theoretical results shedding light on the structural properties of the optimal
unbiased randomizers.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05662" title="Abstract">arXiv:2312.05662</a> [<a href="/pdf/2312.05662" title="Download PDF">pdf</a>, <a href="/format/2312.05662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Effect of Model Compression on Social Bias in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+G">Gustavo Gon&#xe7;alves</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) trained with self-supervision on vast corpora of
web text fit to the social biases of that text. Without intervention, these
social biases persist in the model's predictions in downstream tasks, leading
to representational harm. Many strategies have been proposed to mitigate the
effects of inappropriate social biases learned during pretraining.
Simultaneously, methods for model compression have become increasingly popular
to reduce the computational burden of LLMs. Despite the popularity and need for
both approaches, little work has been done to explore the interplay between
these two. We perform a carefully controlled study of the impact of model
compression via quantization and knowledge distillation on measures of social
bias in LLMs. Longer pretraining and larger models led to higher social bias,
and quantization showed a regularizer effect with its best trade-off around 20%
of the original pretraining time.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05664" title="Abstract">arXiv:2312.05664</a> [<a href="/pdf/2312.05664" title="Download PDF">pdf</a>, <a href="/format/2312.05664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoGS: Controllable Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Heng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Julin%2C+J">Joel Julin</a>, 
<a href="/search/cs?searchtype=author&query=Milacski%2C+Z+%C3%81">Zolt&#xe1;n &#xc1;. Milacski</a>, 
<a href="/search/cs?searchtype=author&query=Niinuma%2C+K">Koichiro Niinuma</a>, 
<a href="/search/cs?searchtype=author&query=Jeni%2C+L+A">L&#xe1;szl&#xf3; A. Jeni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Capturing and re-animating the 3D structure of articulated objects present
significant barriers. On one hand, methods requiring extensively calibrated
multi-view setups are prohibitively complex and resource-intensive, limiting
their practical applicability. On the other hand, while single-camera Neural
Radiance Fields (NeRFs) offer a more streamlined approach, they have excessive
training and rendering costs. 3D Gaussian Splatting would be a suitable
alternative but for two reasons. Firstly, existing methods for 3D dynamic
Gaussians require synchronized multi-view cameras, and secondly, the lack of
controllability in dynamic scenarios. We present CoGS, a method for
Controllable Gaussian Splatting, that enables the direct manipulation of scene
elements, offering real-time control of dynamic scenes without the prerequisite
of pre-computing control signals. We evaluated CoGS using both synthetic and
real-world datasets that include dynamic objects that differ in degree of
difficulty. In our evaluations, CoGS consistently outperformed existing dynamic
and controllable neural representations in terms of visual fidelity.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05665" title="Abstract">arXiv:2312.05665</a> [<a href="/pdf/2312.05665" title="Download PDF">pdf</a>, <a href="/format/2312.05665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Modbus TCP Protocol Security with eBPF Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jhan%2C+J">Jia-Yi Jhan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hung-Min Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The core component of an Industrial Control System (ICS) is often a
Programmable Logic Controller (PLC) combined with various modules. In such
systems, the communication between devices is mainly based on the Modbus
protocol, which was developed by Modicon (now Schneider Electric) in 1979 as an
application-level communication protocol and has become a de facto standard for
ICS for the past 40 years. Modbus TCP is a variant of this protocol for
communications over the TCP/IP network. However, the Modbus protocol was not
designed with security in mind, and the use of plaintext transmissions during
communication makes information easily accessible to the attackers, while the
lack of an authentication mechanism gives any protocol-compliant device the
ability to take over control. In this study, we use the eBPF technology to
shift the process of protocol change to the lower level of the operating
system, making the change transparent to the existing software, and enhancing
the security of the Modbus TCP protocol without affecting the existing software
ecosystem as much as possible.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05666" title="Abstract">arXiv:2312.05666</a> [<a href="/pdf/2312.05666" title="Download PDF">pdf</a>, <a href="/ps/2312.05666" title="Download PostScript">ps</a>, <a href="/format/2312.05666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Graph Neural Network-Based Approach for Estimating Hidden  States in Cyber Attack Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+P">Pontus Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Ekstedt%2C+M">Mathias Ekstedt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This work-in-progress paper introduces a prototype for a novel Graph Neural
Network (GNN) based approach to estimate hidden states in cyber attack
simulations. Utilizing the Meta Attack Language (MAL) in conjunction with
Relational Dynamic Decision Language (RDDL) conformant simulations, our
framework aims to map the intricate complexity of cyber attacks with a vast
number of possible vectors in the simulations. While the prototype is yet to be
completed and validated, we discuss its foundational concepts, the
architecture, and the potential implications for the field of computer
security.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05668" title="Abstract">arXiv:2312.05668</a> [<a href="/pdf/2312.05668" title="Download PDF">pdf</a>, <a href="/ps/2312.05668" title="Download PostScript">ps</a>, <a href="/format/2312.05668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polarization in Decentralized Online Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=La+Cava%2C+L">Lucio La Cava</a>, 
<a href="/search/cs?searchtype=author&query=Mandaglio%2C+D">Domenico Mandaglio</a>, 
<a href="/search/cs?searchtype=author&query=Tagarelli%2C+A">Andrea Tagarelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Centralized social media platforms are currently experiencing a shift in user
engagement, drawing attention to alternative paradigms like Decentralized
Online Social Networks (DOSNs). The rising popularity of DOSNs finds its root
in the accessibility of open-source software, enabling anyone to create a new
instance (i.e., server) and participate in a decentralized network known as
Fediverse. Despite this growing momentum, there has been a lack of studies
addressing the effect of positive and negative interactions among instances
within DOSNs. This work aims to fill this gap by presenting a preliminary
examination of instances' polarization in DOSNs, focusing on Mastodon -- the
most widely recognized decentralized social media platform, boasting over 10M
users and nearly 20K instances to date. Our results suggest that polarization
in the Fediverse emerges in unique ways, influenced by the desire to foster a
federated environment between instances, also facilitating the isolation of
instances that may pose potential risks to the Fediverse.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05669" title="Abstract">arXiv:2312.05669</a> [<a href="/pdf/2312.05669" title="Download PDF">pdf</a>, <a href="/format/2312.05669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relevance Feedback with Brain Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weihang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The Relevance Feedback (RF) process relies on accurate and real-time
relevance estimation of feedback documents to improve retrieval performance.
Since collecting explicit relevance annotations imposes an extra burden on the
user, extensive studies have explored using pseudo-relevance signals and
implicit feedback signals as substitutes. However, such signals are indirect
indicators of relevance and suffer from complex search scenarios where user
interactions are absent or biased.
<br />Recently, the advances in portable and high-precision brain-computer
interface (BCI) devices have shown the possibility to monitor user's brain
activities during search process. Brain signals can directly reflect user's
psychological responses to search results and thus it can act as additional and
unbiased RF signals. To explore the effectiveness of brain signals in the
context of RF, we propose a novel RF framework that combines BCI-based
relevance feedback with pseudo-relevance signals and implicit signals to
improve the performance of document re-ranking. The experimental results on the
user study dataset show that incorporating brain signals leads to significant
performance improvement in our RF framework. Besides, we observe that brain
signals perform particularly well in several hard search scenarios, especially
when implicit signals as feedback are missing or noisy. This reveals when and
how to exploit brain signals in the context of RF.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05670" title="Abstract">arXiv:2312.05670</a> [<a href="/pdf/2312.05670" title="Download PDF">pdf</a>, <a href="/ps/2312.05670" title="Download PostScript">ps</a>, <a href="/format/2312.05670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds for the sampling discretization error and their applications to  universal sampling discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kosov%2C+E+D">E.D. Kosov</a>, 
<a href="/search/math?searchtype=author&query=Temlyakov%2C+V+N">V.N. Temlyakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">In the first part of the paper we study absolute error of sampling
discretization of the integral $L_p$-norm for functional classes of continuous
functions. We use chaining technique to provide a general bound for the error
of sampling discretization of the $L_p$-norm on a given functional class in
terms of entropy numbers in the uniform norm of this class. The general result
yields new error bounds for sampling discretization of the $L_p$-norms on
classes of multivariate functions with mixed smoothness. In the second part of
the paper we apply the obtained bounds to study universal sampling
discretization and the problem of optimal sampling recovery.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05671" title="Abstract">arXiv:2312.05671</a> [<a href="/pdf/2312.05671" title="Download PDF">pdf</a>, <a href="/format/2312.05671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hate Speech and Offensive Content Detection in Indo-Aryan Languages: A  Battle of LSTM and Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayan%2C+N">Nikhil Narayan</a>, 
<a href="/search/cs?searchtype=author&query=Biswal%2C+M">Mrutyunjay Biswal</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Pramod Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Panigrahi%2C+A">Abhranta Panigrahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures. Accepted Working Notes at HASOC-FIRE 2023, to be published in CEUR Working Notes of FIRE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media platforms serve as accessible outlets for individuals to express
their thoughts and experiences, resulting in an influx of user-generated data
spanning all age groups. While these platforms enable free expression, they
also present significant challenges, including the proliferation of hate speech
and offensive content. Such objectionable language disrupts objective discourse
and can lead to radicalization of debates, ultimately threatening democratic
values. Consequently, organizations have taken steps to monitor and curb
abusive behavior, necessitating automated methods for identifying suspicious
posts. This paper contributes to Hate Speech and Offensive Content
Identification in English and Indo-Aryan Languages (HASOC) 2023 shared tasks
track. We, team Z-AGI Labs, conduct a comprehensive comparative analysis of
hate speech classification across five distinct languages: Bengali, Assamese,
Bodo, Sinhala, and Gujarati. Our study encompasses a wide range of pre-trained
models, including Bert variants, XLM-R, and LSTM models, to assess their
performance in identifying hate speech across these languages. Results reveal
intriguing variations in model performance. Notably, Bert Base Multilingual
Cased emerges as a strong performer across languages, achieving an F1 score of
0.67027 for Bengali and 0.70525 for Assamese. At the same time, it
significantly outperforms other models with an impressive F1 score of 0.83009
for Bodo. In Sinhala, XLM-R stands out with an F1 score of 0.83493, whereas for
Gujarati, a custom LSTM-based model outshined with an F1 score of 0.76601. This
study offers valuable insights into the suitability of various pre-trained
models for hate speech detection in multilingual settings. By considering the
nuances of each, our research contributes to an informed model selection for
building robust hate speech detection systems.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05673" title="Abstract">arXiv:2312.05673</a> [<a href="/pdf/2312.05673" title="Download PDF">pdf</a>, <a href="/format/2312.05673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Homophily in Exponential-Family Random Graph Models for  Bipartite Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bomiriya%2C+R+P">Rashmi P. Bomiriya</a> (1), 
<a href="/search/cs?searchtype=author&query=Kuvelkar%2C+A+R">Alina R. Kuvelkar</a> (2), 
<a href="/search/cs?searchtype=author&query=Hunter%2C+D+R">David R. Hunter</a> (2), 
<a href="/search/cs?searchtype=author&query=Triebel%2C+S">Steffen Triebel</a> (3) ((1) R S Metrics Asia Holdings Pvt Limited, (2) Penn State University, (3) University of Exeter Business School)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Homophily, the tendency of individuals who are alike to form ties with one
another, is an important concept in the study of social networks. Yet
accounting for homophily effects is complicated in the context of bipartite
networks where ties connect individuals not with one another but rather with a
separate set of nodes, which might also be individuals but which are often an
entirely different type of objects. As a result, much work on the effect of
homophily in a bipartite network proceeds by first eliminating the bipartite
structure, collapsing a two-mode network to a one-mode network and thereby
ignoring potentially meaningful structure in the data. We introduce a set of
methods to model homophily on bipartite networks without losing information in
this way, then we demonstrate that these methods allow for substantively
interesting findings in management science not possible using standard
techniques. These methods are implemented in the widely-used ergm package for
R.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05674" title="Abstract">arXiv:2312.05674</a> [<a href="/pdf/2312.05674" title="Download PDF">pdf</a>, <a href="/format/2312.05674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position control of an acoustic cavitation bubble by reinforcement  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Klapcsik%2C+K">K&#xe1;lm&#xe1;n Klapcsik</a>, 
<a href="/search/eess?searchtype=author&query=Gyires-T%C3%B3th%2C+B">B&#xe1;lint Gyires-T&#xf3;th</a>, 
<a href="/search/eess?searchtype=author&query=Rossell%C3%B3%2C+J+M">Juan Manuel Rossell&#xf3;</a>, 
<a href="/search/eess?searchtype=author&query=Heged%C5%B1s%2C+F">Ferenc Heged&#x171;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A control technique is developed via Reinforcement Learning that allows
arbitrary controlling of the position of an acoustic cavitation bubble in a
dual-frequency standing acoustic wave field. The agent must choose the optimal
pressure amplitude values to manipulate the bubble position in the range of
$x/\lambda_0\in[0.05, 0.25]$. To train the agent an actor-critic off-policy
algorithm (Deep Deterministic Policy Gradient) was used that supports
continuous action space, which allows setting the pressure amplitude values
continuously within $0$ and $1\, \mathrm{bar}$. A shaped reward function is
formulated that minimizes the distance between the bubble and the target
position and implicitly encourages the agent to perform the position control
within the shortest amount of time. In some cases, the optimal control can be 7
times faster than the solution expected from the linear theory.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05675" title="Abstract">arXiv:2312.05675</a> [<a href="/pdf/2312.05675" title="Download PDF">pdf</a>, <a href="/format/2312.05675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Think-Aloud Data to Understand Relations between Self-Regulation  Cycle Characteristics and Student Performance in Intelligent Tutoring Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borchers%2C+C">Conrad Borchers</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+R+S">Ryan S. Baker</a>, 
<a href="/search/cs?searchtype=author&query=Aleven%2C+V">Vincent Aleven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper accepted to Learning Analytics and Knowledge (LAK 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Numerous studies demonstrate the importance of self-regulation during
learning by problem-solving. Recent work in learning analytics has largely
examined students' use of SRL concerning overall learning gains. Limited
research has related SRL to in-the-moment performance differences among
learners. The present study investigates SRL behaviors in relationship to
learners' moment-by-moment performance while working with intelligent tutoring
systems for stoichiometry chemistry. We demonstrate the feasibility of labeling
SRL behaviors based on AI-generated think-aloud transcripts, identifying the
presence or absence of four SRL categories (processing information, planning,
enacting, and realizing errors) in each utterance. Using the SRL codes, we
conducted regression analyses to examine how the use of SRL in terms of
presence, frequency, cyclical characteristics, and recency relate to student
performance on subsequent steps in multi-step problems. A model considering
students' SRL cycle characteristics outperformed a model only using
in-the-moment SRL assessment. In line with theoretical predictions, students'
actions during earlier, process-heavy stages of SRL cycles exhibited lower
moment-by-moment correctness during problem-solving than later SRL cycle
stages. We discuss system re-design opportunities to add SRL support during
stages of processing and paths forward for using machine learning to speed
research depending on the assessment of SRL based on transcription of
think-aloud data.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05677" title="Abstract">arXiv:2312.05677</a> [<a href="/pdf/2312.05677" title="Download PDF">pdf</a>, <a href="/format/2312.05677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batched Low-Rank Adaptation of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yeming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning
foundation models by incorporating trainable low-rank matrices, thereby
reducing the number of trainable parameters. While LoRA offers numerous
advantages, its applicability for real-time serving to a diverse and global
user base is constrained by its incapability to handle multiple task-specific
adapters efficiently. This imposes a performance bottleneck in scenarios
requiring personalized, task-specific adaptations for each incoming request. To
mitigate this constraint, we introduce Fast LoRA (FLoRA), a framework in which
each input example in a minibatch can be associated with its unique low-rank
adaptation weights, allowing for efficient batching of heterogeneous requests.
We empirically demonstrate that FLoRA retains the performance merits of LoRA,
showcasing competitive results on the MultiPL-E code generation benchmark
spanning over 8 languages and a multilingual speech recognition task across 6
languages.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05679" title="Abstract">arXiv:2312.05679</a> [<a href="/pdf/2312.05679" title="Download PDF">pdf</a>, <a href="/format/2312.05679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Schr&#xf6;dinger&#x27;s control and estimation paradigm with spatio-temporal  distributions on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Eldesoukey%2C+A">Asmaa Eldesoukey</a>, 
<a href="/search/eess?searchtype=author&query=Georgiou%2C+T+T">Tryphon T. Georgiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">The problem of reconciling a prior probability law with data was introduced
by E. Schr\"odinger in 1931/32. It represents an early formulation of a maximum
likelihood problem. The specific formulation can also be seen as the control
problem to modify the law of a diffusion process so as to match specifications
on marginal distributions at given times. Thereby, in recent years, this
so-called {\em Schr\"odinger Bridge problem} has been at the center of the
development of uncertainty control. However, an unstudied facet of this program
has been to address uncertainty in space and time, modeling the effect of tasks
being completed, instead of imposing specifications at fixed times. The present
work is a first study to extend Schr\"odinger's paradigm on such an issue. It
is developed in the context of Markov chains and random walks on graphs.
Specifically, we study the case where one marginal distribution represents the
initial state occupation of a Markov chain, while others represent
first-arrival time distributions at absorbing states signifying completion of
tasks. We establish that when the prior is Markov, a Markov policy is once
again optimal with respect to a likelihood cost that follows Schr\"odinger's
dictum.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05686" title="Abstract">arXiv:2312.05686</a> [<a href="/pdf/2312.05686" title="Download PDF">pdf</a>, <a href="/format/2312.05686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Preserving Multi-Agent Reinforcement Learning in Supply Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Ananta Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Peeyush Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Boling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chandran%2C+N">Nishanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Divya Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper addresses privacy concerns in multi-agent reinforcement learning
(MARL), specifically within the context of supply chains where individual
strategic data must remain confidential. Organizations within the supply chain
are modeled as agents, each seeking to optimize their own objectives while
interacting with others. As each organization's strategy is contingent on
neighboring strategies, maintaining privacy of state and action-related
information is crucial. To tackle this challenge, we propose a game-theoretic,
privacy-preserving mechanism, utilizing a secure multi-party computation (MPC)
framework in MARL settings. Our major contribution is the successful
implementation of a secure MPC framework, SecFloat on EzPC, to solve this
problem. However, simply implementing policy gradient methods such as MADDPG
operations using SecFloat, while conceptually feasible, would be
programmatically intractable. To overcome this hurdle, we devise a novel
approach that breaks down the forward and backward pass of the neural network
into elementary operations compatible with SecFloat , creating efficient and
secure versions of the MADDPG algorithm. Furthermore, we present a learning
mechanism that carries out floating point operations in a privacy-preserving
manner, an important feature for successful learning in MARL framework.
Experiments reveal that there is on average 68.19% less supply chain wastage in
2 PC compared to no data share, while also giving on average 42.27% better
average cumulative revenue for each player. This work paves the way for
practical, privacy-preserving MARL, promising significant improvements in
secure computation within supply chain contexts and broadly.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05688" title="Abstract">arXiv:2312.05688</a> [<a href="/pdf/2312.05688" title="Download PDF">pdf</a>, <a href="/format/2312.05688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLLG Quarterly arXiv Report 09/23: What are the most influential current  AI Papers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kostikova%2C+A">Aida Kostikova</a>, 
<a href="/search/cs?searchtype=author&query=Leiter%2C+C">Christoph Leiter</a>, 
<a href="/search/cs?searchtype=author&query=Belouadi%2C+J">Jonas Belouadi</a>, 
<a href="/search/cs?searchtype=author&query=Larionov%2C+D">Daniil Larionov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fresen%2C+V">Vivian Fresen</a>, 
<a href="/search/cs?searchtype=author&query=Eger%2C+S">Steffen Eger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial Intelligence (AI) has witnessed rapid growth, especially in the
subfields Natural Language Processing (NLP), Machine Learning (ML) and Computer
Vision (CV). Keeping pace with this rapid progress poses a considerable
challenge for researchers and professionals in the field. In this arXiv report,
the second of its kind, which covers the period from January to September 2023,
we aim to provide insights and analysis that help navigate these dynamic areas
of AI. We accomplish this by 1) identifying the top-40 most cited papers from
arXiv in the given period, comparing the current top-40 papers to the previous
report, which covered the period January to June; 2) analyzing dataset
characteristics and keyword popularity; 3) examining the global sectoral
distribution of institutions to reveal differences in engagement across
geographical areas. Our findings highlight the continued dominance of NLP:
while only 16% of all submitted papers have NLP as primary category (more than
25% have CV and ML as primary category), 50% of the most cited papers have NLP
as primary category, 90% of which target LLMs. Additionally, we show that i)
the US dominates among both top-40 and top-9k papers, followed by China; ii)
Europe clearly lags behind and is hardly represented in the top-40 most cited
papers; iii) US industry is largely overrepresented in the top-40 most
influential papers.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05690" title="Abstract">arXiv:2312.05690</a> [<a href="/pdf/2312.05690" title="Download PDF">pdf</a>, <a href="/format/2312.05690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Ignorance Bliss? The Role of Post Hoc Explanation Faithfulness and  Alignment in Model Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tessa Han</a>, 
<a href="/search/cs?searchtype=author&query=Ektefaie%2C+Y">Yasha Ektefaie</a>, 
<a href="/search/cs?searchtype=author&query=Farhat%2C+M">Maha Farhat</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Post hoc explanations have emerged as a way to improve user trust in machine
learning models by providing insight into model decision-making. However,
explanations tend to be evaluated based on their alignment with prior knowledge
while the faithfulness of an explanation with respect to the model, a
fundamental criterion, is often overlooked. Furthermore, the effect of
explanation faithfulness and alignment on user trust and whether this effect
differs among laypeople and domain experts is unclear. To investigate these
questions, we conduct a user study with computer science students and doctors
in three domain areas, controlling the laypeople and domain expert groups in
each setting. The results indicate that laypeople base their trust in
explanations on explanation faithfulness while domain experts base theirs on
explanation alignment. To our knowledge, this work is the first to show that
(1) different factors affect laypeople and domain experts' trust in post hoc
explanations and (2) domain experts are subject to specific biases due to their
expertise when interpreting post hoc explanations. By uncovering this
phenomenon and exposing this cognitive bias, this work motivates the need to
educate end users about how to properly interpret explanations and overcome
their own cognitive biases, and motivates the development of simple and
interpretable faithfulness metrics for end users. This research is particularly
important and timely as post hoc explanations are increasingly being used in
high-stakes, real-world settings such as medicine.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05693" title="Abstract">arXiv:2312.05693</a> [<a href="/pdf/2312.05693" title="Download PDF">pdf</a>, <a href="/format/2312.05693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs  on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peiyan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zhenglun Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) stand out for their impressive performance in
intricate language modeling tasks. However, their demanding computational and
memory needs pose obstacles for broad use on edge devices. Quantization is then
introduced to boost LLMs' on-device efficiency. Recent works show that 8-bit or
lower weight quantization is feasible with minimal impact on end-to-end task
performance, while the activation is still not quantized. On the other hand,
mainstream commodity edge devices still struggle to execute these sub-8-bit
quantized networks effectively. In this paper, we propose Agile-Quant, an
activation-guided quantization framework for popular Large Language Models
(LLMs), and implement an end-to-end accelerator on multiple edge devices for
faster inference. Considering the hardware profiling and activation analysis,
we first introduce a basic activation quantization strategy to balance the
trade-off of task performance and real inference speed. Then we leverage the
activation-aware token pruning technique to reduce the outliers and the adverse
impact on attentivity. Ultimately, we utilize the SIMD-based 4-bit multiplier
and our efficient TRIP matrix multiplication to implement the accelerator for
LLMs on the edge. We apply our framework on different scales of LLMs including
LLaMA, OPT, and BLOOM with 4-bit or 8-bit for the activation and 4-bit for the
weight quantization. Experiments show that Agile-Quant achieves simultaneous
quantization of model weights and activations while maintaining task
performance comparable to existing weight-only quantization methods. Moreover,
in the 8- and 4-bit scenario, Agile-Quant achieves an on-device speedup of up
to 2.55x compared to its FP16 counterparts across multiple edge devices,
marking a pioneering advancement in this domain.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05695" title="Abstract">arXiv:2312.05695</a> [<a href="/pdf/2312.05695" title="Download PDF">pdf</a>, <a href="/format/2312.05695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Counterattack of CNNs in Self-Supervised Learning: Larger Kernel  Size might be All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianjin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision Transformers have been rapidly uprising in computer vision thanks to
their outstanding scaling trends, and gradually replacing convolutional neural
networks (CNNs). Recent works on self-supervised learning (SSL) introduce
siamese pre-training tasks, on which Transformer backbones continue to
demonstrate ever stronger results than CNNs. People come to believe that
Transformers or self-attention modules are inherently more suitable than CNNs
in the context of SSL. However, it is noteworthy that most if not all prior
arts of SSL with CNNs chose the standard ResNets as their backbones, whose
architecture effectiveness is known to already lag behind advanced Vision
Transformers. Therefore, it remains unclear whether the self-attention
operation is crucial for the recent advances in SSL - or CNNs can deliver the
same excellence with more advanced designs, too? Can we close the SSL
performance gap between Transformers and CNNs? To answer these intriguing
questions, we apply self-supervised pre-training to the recently proposed,
stronger lager-kernel CNN architecture and conduct an apple-to-apple comparison
with Transformers, in their SSL performance. Our results show that we are able
to build pure CNN SSL architectures that perform on par with or better than the
best SSL-trained Transformers, by just scaling up convolutional kernel sizes
besides other small tweaks. Impressively, when transferring to the downstream
tasks \texttt{MS COCO} detection and segmentation, our SSL pre-trained CNN
model (trained in 100 epochs) achieves the same good performance as the
300-epoch pre-trained Transformer counterpart. We hope this work can help to
better understand what is essential (or not) for self-supervised learning
backbones.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05696" title="Abstract">arXiv:2312.05696</a> [<a href="/pdf/2312.05696" title="Download PDF">pdf</a>, <a href="/format/2312.05696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4 and Safety Case Generation: An Exploratory Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivakumar%2C+M">Mithila Sivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine Boaye Belle</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jinjun Shan</a>, 
<a href="/search/cs?searchtype=author&query=Shahandashti%2C+K+K">Kimya Khakzad Shahandashti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the ever-evolving landscape of software engineering, the emergence of
large language models (LLMs) and conversational interfaces, exemplified by
ChatGPT, is nothing short of revolutionary. While their potential is undeniable
across various domains, this paper sets out on a captivating expedition to
investigate their uncharted territory, the exploration of generating safety
cases. In this paper, our primary objective is to delve into the existing
knowledge base of GPT-4, focusing specifically on its understanding of the Goal
Structuring Notation (GSN), a well-established notation allowing to visually
represent safety cases. Subsequently, we perform four distinct experiments with
GPT-4. These experiments are designed to assess its capacity for generating
safety cases within a defined system and application domain. To measure the
performance of GPT-4 in this context, we compare the results it generates with
ground-truth safety cases created for an X-ray system system and a
Machine-Learning (ML)-enabled component for tire noise recognition (TNR) in a
vehicle. This allowed us to gain valuable insights into the model's generative
capabilities. Our findings indicate that GPT-4 demonstrates the capacity to
produce safety arguments that are moderately accurate and reasonable.
Furthermore, it exhibits the capability to generate safety cases that closely
align with the semantic content of the reference safety cases used as
ground-truths in our experiments.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05698" title="Abstract">arXiv:2312.05698</a> [<a href="/pdf/2312.05698" title="Download PDF">pdf</a>, <a href="/format/2312.05698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Multi-modal Feature Alignment for Time Series  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhiyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianfeng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent times, the field of unsupervised representation learning (URL) for
time series data has garnered significant interest due to its remarkable
adaptability across diverse downstream applications. Unsupervised learning
goals differ from downstream tasks, making it tricky to ensure downstream task
utility by focusing only on temporal feature characterization. Researchers have
proposed multiple transformations to extract discriminative patterns implied in
informative time series, trying to fill the gap. Despite the introduction of a
variety of feature engineering techniques, e.g. spectral domain, wavelet
transformed features, features in image form and symbolic features etc. the
utilization of intricate feature fusion methods and dependence on heterogeneous
features during inference hampers the scalability of the solutions. To address
this, our study introduces an innovative approach that focuses on aligning and
binding time series representations encoded from different modalities, inspired
by spectral graph theory, thereby guiding the neural encoder to uncover latent
pattern associations among these multi-modal features. In contrast to
conventional methods that fuse features from multiple modalities, our proposed
approach simplifies the neural architecture by retaining a single time series
encoder, consequently leading to preserved scalability. We further demonstrate
and prove mechanisms for the encoder to maintain better inductive bias. In our
experimental evaluation, we validated the proposed method on a diverse set of
time series datasets from various domains. Our approach outperforms existing
state-of-the-art URL methods across diverse downstream tasks.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05704" title="Abstract">arXiv:2312.05704</a> [<a href="/pdf/2312.05704" title="Download PDF">pdf</a>, <a href="/format/2312.05704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Ground and in the Sky: A Tutorial on Radio Localization in  Ground-Air-Space Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sallouha%2C+H">Hazem Sallouha</a>, 
<a href="/search/cs?searchtype=author&query=Saleh%2C+S">Sharief Saleh</a>, 
<a href="/search/cs?searchtype=author&query=De+Bast%2C+S">Sibren De Bast</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhuangzhuang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Pollin%2C+S">Sofie Pollin</a>, 
<a href="/search/cs?searchtype=author&query=Wymeersch%2C+H">Henk Wymeersch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The inherent limitations in scaling up ground infrastructure for future
wireless networks, combined with decreasing operational costs of aerial and
space networks, are driving considerable research interest in multisegment
ground-air-space (GAS) networks. In GAS networks, where ground and aerial users
share network resources, ubiquitous and accurate user localization becomes
indispensable, not only as an end-user service but also as an enabler for
location-aware communications. This breaks the convention of having
localization as a byproduct in networks primarily designed for communications.
To address these imperative localization needs, the design and utilization of
ground, aerial, and space anchors require thorough investigation. In this
tutorial, we provide an in-depth systemic analysis of the radio localization
problem in GAS networks, considering ground and aerial users as targets to be
localized. Starting from a survey of the most relevant works, we then define
the key characteristics of anchors and targets in GAS networks. Subsequently,
we detail localization fundamentals in GAS networks, considering 3D positions
and orientations. Afterward, we thoroughly analyze radio localization systems
in GAS networks, detailing the system model, design aspects, and considerations
for each of the three GAS anchors. Preliminary results are presented to provide
a quantifiable perspective on key design aspects in GAS-based localization
scenarios. We then identify the vital roles 6G enablers are expected to play in
radio localization in GAS networks.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05705" title="Abstract">arXiv:2312.05705</a> [<a href="/pdf/2312.05705" title="Download PDF">pdf</a>, <a href="/format/2312.05705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Inverse-Free Natural Gradient: Memory-Efficient &amp;  Numerically-Stable KFAC for Large Neural Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dangel%2C+F">Felix Dangel</a>, 
<a href="/search/cs?searchtype=author&query=Eschenhagen%2C+R">Runa Eschenhagen</a>, 
<a href="/search/cs?searchtype=author&query=Neklyudov%2C+K">Kirill Neklyudov</a>, 
<a href="/search/cs?searchtype=author&query=Kristiadi%2C+A">Agustinus Kristiadi</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Makhzani%2C+A">Alireza Makhzani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Second-order methods for deep learning -- such as KFAC -- can be useful for
neural net training. However, they are often memory-inefficient and numerically
unstable for low-precision training since their preconditioning Kronecker
factors are dense, and require high-precision matrix inversion or
decomposition. Consequently, such methods are not widely used for training
large neural networks such as transformer-based models. We address these two
issues by (i) formulating an inverse-free update of KFAC and (ii) imposing
structures in each of the Kronecker factors, resulting in a method we term
structured inverse-free natural gradient descent (SINGD). On large modern
neural networks, we show that, in contrast to KFAC, SINGD is memory efficient
and numerically robust, and often outperforms AdamW even in half precision.
Hence, our work closes a gap between first-order and second-order methods in
modern low precision training for large neural nets.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05706" title="Abstract">arXiv:2312.05706</a> [<a href="/pdf/2312.05706" title="Download PDF">pdf</a>, <a href="/format/2312.05706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bit Blasting Probabilistic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+P">Poorva Garg</a>, 
<a href="/search/cs?searchtype=author&query=Holtzen%2C+S">Steven Holtzen</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>, 
<a href="/search/cs?searchtype=author&query=Millstein%2C+T">Todd Millstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Probabilistic programming languages (PPLs) are expressive means for creating
and reasoning about probabilistic models. Unfortunately hybrid probabilistic
programs, involving both continuous and discrete structures, are not well
supported by today's PPLs. In this paper we develop a new approximate inference
algorithm for hybrid probabilistic programs that first discretizes the
continuous distributions and then performs discrete inference on the resulting
program. The key novelty is a form of discretization that we call bit blasting,
which uses a binary representation of numbers such that a domain of $2^b$
discretized points can be succinctly represented as a discrete probabilistic
program over poly($b$) Boolean random variables. Surprisingly, we prove that
many common continuous distributions can be bit blasted in a manner that incurs
no loss of accuracy over an explicit discretization and supports efficient
probabilistic inference. We have built a probabilistic programming system for
hybrid programs called HyBit, which employs bit blasting followed by discrete
probabilistic inference. We empirically demonstrate the benefits of our
approach over existing sampling-based and symbolic inference approaches.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05708" title="Abstract">arXiv:2312.05708</a> [<a href="/pdf/2312.05708" title="Download PDF">pdf</a>, <a href="/format/2312.05708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Tuning for Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anantha%2C+R">Raviteja Anantha</a>, 
<a href="/search/cs?searchtype=author&query=Bethi%2C+T">Tharun Bethi</a>, 
<a href="/search/cs?searchtype=author&query=Vodianik%2C+D">Danil Vodianik</a>, 
<a href="/search/cs?searchtype=author&query=Chappidi%2C+S">Srinivas Chappidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have the remarkable ability to solve new tasks
with just a few examples, but they need access to the right tools. Retrieval
Augmented Generation (RAG) addresses this problem by retrieving a list of
relevant tools for a given task. However, RAG's tool retrieval step requires
all the required information to be explicitly present in the query. This is a
limitation, as semantic search, the widely adopted tool retrieval method, can
fail when the query is incomplete or lacks context. To address this limitation,
we propose Context Tuning for RAG, which employs a smart context retrieval
system to fetch relevant information that improves both tool retrieval and plan
generation. Our lightweight context retrieval model uses numerical,
categorical, and habitual usage signals to retrieve and rank context items. Our
empirical results demonstrate that context tuning significantly enhances
semantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for
context retrieval and tool retrieval tasks respectively, and resulting in an
11.6% increase in LLM-based planner accuracy. Additionally, we show that our
proposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART
outperforms GPT-4 based retrieval. Moreover, we observe context augmentation at
plan generation, even after tool retrieval, reduces hallucination.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05714" title="Abstract">arXiv:2312.05714</a> [<a href="/pdf/2312.05714" title="Download PDF">pdf</a>, <a href="/format/2312.05714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vivisecting the Dissection: On the Role of Trusted Components in BFT  Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bessani%2C+A">Alysson Bessani</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+M">Miguel Correia</a>, 
<a href="/search/cs?searchtype=author&query=Distler%2C+T">Tobias Distler</a>, 
<a href="/search/cs?searchtype=author&query=Kapitza%2C+R">R&#xfc;diger Kapitza</a>, 
<a href="/search/cs?searchtype=author&query=Esteves-Verissimo%2C+P">Paulo Esteves-Verissimo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiangshan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">A recent paper by Gupta et al. (EuroSys'23) challenged the usefulness of
trusted component (TC) based Byzantine fault-tolerant (BFT) protocols to lower
the replica group size from $3f+1$ to $2f+1$, identifying three limitations of
such protocols and proposing that TCs should be used instead to improve the
performance of BFT protocols. Here, we point out flaws in both arguments and
advocate that the most worthwhile use of TCs in BFT protocols is indeed to make
them as resilient as crash fault-tolerant (CFT) protocols, which can tolerate
up to $f$ faulty replicas using $2f+1$ replicas.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05715" title="Abstract">arXiv:2312.05715</a> [<a href="/pdf/2312.05715" title="Download PDF">pdf</a>, <a href="/format/2312.05715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Micro-Macro Consistency in Multiscale Modeling: Score-Based Model  Assisted Sampling of Fast/Slow Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crabtree%2C+E+R">Ellis R. Crabtree</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Rivas%2C+J+M">Juan M. Bello-Rivas</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">A valuable step in the modeling of multiscale dynamical systems in fields
such as computational chemistry, biology, materials science and more, is the
representative sampling of the phase space over long timescales of interest;
this task is not, however, without challenges. For example, the long term
behavior of a system with many degrees of freedom often cannot be efficiently
computationally explored by direct dynamical simulation; such systems can often
become trapped in local free energy minima. In the study of physics-based
multi-time-scale dynamical systems, techniques have been developed for
enhancing sampling in order to accelerate exploration beyond free energy
barriers. On the other hand, in the field of Machine Learning, a generic goal
of generative models is to sample from a target density, after training on
empirical samples from this density. Score based generative models (SGMs) have
demonstrated state-of-the-art capabilities in generating plausible data from
target training distributions. Conditional implementations of such generative
models have been shown to exhibit significant parallels with long-established
-- and physics based -- solutions to enhanced sampling. These physics-based
methods can then be enhanced through coupling with the ML generative models,
complementing the strengths and mitigating the weaknesses of each technique. In
this work, we show that that SGMs can be used in such a coupling framework to
improve sampling in multiscale dynamical systems.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05716" title="Abstract">arXiv:2312.05716</a> [<a href="/pdf/2312.05716" title="Download PDF">pdf</a>, <a href="/format/2312.05716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initialization Matters for Adversarial Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+A">Andong Hua</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhiyu Xue</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yao Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the prevalence of the Pretraining-Finetuning paradigm in transfer
learning, the robustness of downstream tasks has become a critical concern. In
this work, we delve into adversarial robustness in transfer learning and reveal
the critical role of initialization, including both the pretrained model and
the linear head. First, we discover the necessity of an adversarially robust
pretrained model. Specifically, we reveal that with a standard pretrained
model, Parameter-Efficient Finetuning~(PEFT) methods either fail to be
adversarially robust or continue to exhibit significantly degraded adversarial
robustness on downstream tasks, even with adversarial training during
finetuning. Leveraging a robust pretrained model, surprisingly, we observe that
a simple linear probing can outperform full finetuning and other PEFT methods
with random initialization on certain datasets. We further identify that linear
probing excels in preserving robustness from the robust pretraining. Based on
this, we propose Robust Linear Initialization~(RoLI) for adversarial
finetuning, which initializes the linear head with the weights obtained by
adversarial linear probing to maximally inherit the robustness from
pretraining. Across five different image classification datasets, we
demonstrate the effectiveness of RoLI and achieve new state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05717" title="Abstract">arXiv:2312.05717</a> [<a href="/pdf/2312.05717" title="Download PDF">pdf</a>, <a href="/format/2312.05717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Lithium-Ion Battery Longevity with Limited Data  Availability: Benchmarking Different Machine Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hilal%2C+H">Hudson Hilal</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+P">Pramit Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As the use of Lithium-ion batteries continues to grow, it becomes
increasingly important to be able to predict their remaining useful life. This
work aims to compare the relative performance of different machine learning
algorithms, both traditional machine learning and deep learning, in order to
determine the best-performing algorithms for battery cycle life prediction
based on minimal data. We investigated 14 different machine learning models
that were fed handcrafted features based on statistical data and split into 3
feature groups for testing. For deep learning models, we tested a variety of
neural network models including different configurations of standard Recurrent
Neural Networks, Gated Recurrent Units, and Long Short Term Memory with and
without attention mechanism. Deep learning models were fed multivariate time
series signals based on the raw data for each battery across the first 100
cycles. Our experiments revealed that the machine learning algorithms on
handcrafted features performed particularly well, resulting in 10-20% average
mean absolute percentage error. The best-performing algorithm was the Random
Forest Regressor, which gave a minimum 9.8% mean absolute percentage error.
Traditional machine learning models excelled due to their capability to
comprehend general data set trends. In comparison, deep learning models were
observed to perform particularly poorly on raw, limited data. Algorithms like
GRU and RNNs that focused on capturing medium-range data dependencies were less
adept at recognizing the gradual, slow trends critical for this task. Our
investigation reveals that implementing machine learning models with
hand-crafted features proves to be more effective than advanced deep learning
models for predicting the remaining useful Lithium-ion battery life with
limited data availability.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05719" title="Abstract">arXiv:2312.05719</a> [<a href="/pdf/2312.05719" title="Download PDF">pdf</a>, <a href="/format/2312.05719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DVANet: Disentangling View and Action Features for Multi-View Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+N">Nyle Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Tirupattur%2C+P">Praveen Tirupattur</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present a novel approach to multi-view action recognition
where we guide learned action representations to be separated from
view-relevant information in a video. When trying to classify action instances
captured from multiple viewpoints, there is a higher degree of difficulty due
to the difference in background, occlusion, and visibility of the captured
action from different camera angles. To tackle the various problems introduced
in multi-view action recognition, we propose a novel configuration of learnable
transformer decoder queries, in conjunction with two supervised contrastive
losses, to enforce the learning of action features that are robust to shifts in
viewpoints. Our disentangled feature learning occurs in two stages: the
transformer decoder uses separate queries to separately learn action and view
information, which are then further disentangled using our two contrastive
losses. We show that our model and method of training significantly outperforms
all other uni-modal models on four multi-view action recognition datasets: NTU
RGB+D, NTU RGB+D 120, PKU-MMD, and N-UCLA. Compared to previous RGB works, we
see maximal improvements of 1.5\%, 4.8\%, 2.2\%, and 4.8\% on each dataset,
respectively.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05720" title="Abstract">arXiv:2312.05720</a> [<a href="/pdf/2312.05720" title="Download PDF">pdf</a>, <a href="/format/2312.05720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated learning (FL) emphasizes decentralized training by storing data
locally and sending only model updates, underlining user privacy. Recently, a
line of works on privacy attacks impairs user privacy by extracting sensitive
training text from language models in the context of FL. Yet, these attack
techniques face distinct hurdles: some work chiefly with limited batch sizes
(e.g., batch size of 1), and others are easily detectable. This paper
introduces an innovative approach that is challenging to detect, significantly
enhancing the recovery rate of text in various batch-size settings. Building on
fundamental gradient matching and domain prior knowledge, we enhance the attack
by recovering the input of the Pooler layer of language models, which enables
us to provide additional supervised signals at the feature level. Unlike
gradient data, these signals do not average across sentences and tokens,
thereby offering more nuanced and effective insights. We benchmark our method
using text classification tasks on datasets such as CoLA, SST-2, and Rotten
Tomatoes. Across different batch sizes and models, our approach consistently
outperforms previous state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05721" title="Abstract">arXiv:2312.05721</a> [<a href="/pdf/2312.05721" title="Download PDF">pdf</a>, <a href="/format/2312.05721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Spatially-Continuous Fiber Orientation Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spears%2C+T">Tyler Spears</a>, 
<a href="/search/cs?searchtype=author&query=Fletcher%2C+P+T">P. Thomas Fletcher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for review to ISBI 2024. For project page, see <a href="https://osf.io/dvnxw/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Our understanding of the human connectome is fundamentally limited by the
resolution of diffusion MR images. Reconstructing a connectome's constituent
neural pathways with tractography requires following a continuous field of
fiber directions. Typically, this field is found with simple trilinear
interpolation in low-resolution, noisy diffusion MRIs. However, trilinear
interpolation struggles following fine-scale changes in low-quality data.
Recent deep learning methods in super-resolving diffusion MRIs have focused on
upsampling to a fixed spatial grid, but this does not satisfy tractography's
need for a continuous field. In this work, we propose FENRI, a novel method
that learns spatially-continuous fiber orientation density functions from
low-resolution diffusion-weighted images. To quantify FENRI's capabilities in
tractography, we also introduce an expanded simulated dataset built for
evaluating deep-learning tractography models. We demonstrate that FENRI
accurately predicts high-resolution fiber orientations from realistic
low-quality data, and that FENRI-based tractography offers improved streamline
reconstruction over the current use of trilinear interpolation.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05724" title="Abstract">arXiv:2312.05724</a> [<a href="/pdf/2312.05724" title="Download PDF">pdf</a>, <a href="/format/2312.05724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum-Time Trajectory Optimization With Data-Based Models: A Linear  Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/eess?searchtype=author&query=Taheri%2C+E">Ehsan Taheri</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="/search/eess?searchtype=author&query=Filev%2C+D">Dimitar Filev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we develop a computationally-efficient approach to
minimum-time trajectory optimization using input-output data-based models, to
produce an end-to-end data-to-control solution to time-optimal planning/control
of dynamic systems and hence facilitate their autonomous operation. The
approach integrates a non-parametric data-based model for trajectory prediction
and a continuous optimization formulation based on an exponential weighting
scheme for minimum-time trajectory planning. The optimization problem in its
final form is a linear program and is easy to solve. We validate the approach
and illustrate its application with a spacecraft relative motion planning
problem.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05725" title="Abstract">arXiv:2312.05725</a> [<a href="/pdf/2312.05725" title="Download PDF">pdf</a>, <a href="/format/2312.05725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FP8-BERT: Post-Training Quantization for Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianchi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+I+E">Ian En-Hsu Yen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer-based models, such as BERT, have been widely applied in a wide
range of natural language processing tasks. However, one inevitable side effect
is that they require massive memory storage and inference cost when deployed in
production. Quantization is one of the popularized ways to alleviate the cost.
However, the previous 8-bit quantization strategy based on INT8 data format
either suffers from the degradation of accuracy in a Post-Training Quantization
(PTQ) fashion or requires an expensive Quantization-Aware Training (QAT)
process. Recently, a new numeric format FP8 (i.e. floating-point of 8-bits) has
been proposed and supported in commercial AI computing platforms such as H100.
In this paper, we empirically validate the effectiveness of FP8 as a way to do
Post-Training Quantization without significant loss of accuracy, with a simple
calibration and format conversion process. We adopt the FP8 standard proposed
by~\citet{nvidia_release} in our extensive experiments of BERT variants on GLUE
and SQuAD v1.1 datasets, and show that PTQ with FP8 can significantly improve
the accuracy upon that with INT8, to the extent of the full-precision model.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05726" title="Abstract">arXiv:2312.05726</a> [<a href="/pdf/2312.05726" title="Download PDF">pdf</a>, <a href="/ps/2312.05726" title="Download PostScript">ps</a>, <a href="/format/2312.05726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Convergence Rates of Quadratic Transform and WMMSE Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yannan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zepeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H+V">Hei Victor Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Fractional programming (FP) plays an important role in information science
because of the Cramer-Rao bound,the Fisher information, and the
signal-to-interference-plus-noise ratio (SINR). A state-of-the-art method
called the quadratic transform has been extensively used to address the FP
problems. This work aims to accelerate the quadratic transform-based iterative
optimization via gradient projection and extrapolation. The main contributions
of this work are three-fold. First, we relate the quadratic transform to the
gradient projection, thereby eliminating the matrix inverse operation from the
iterative optimization; our result generalizes the weighted sum-of-rates (WSR)
maximization algorithm in [1] to a wide range of FP problems. Second, based on
this connection to gradient projection, we incorporate Nesterov's extrapolation
strategy [2] into the quadratic transform so as to accelerate the convergence
of the iterative optimization. Third, from a minorization-maximization (MM)
point of view, we examine the convergence rates of the conventional quadratic
transform methods--which include the weighted minimum mean square error (WMMSE)
algorithm as a special case--and the proposed accelerated ones. Moreover, we
illustrate the practical use of the accelerated quadratic transform in two
popular application cases of future wireless networks: (i) integrated sensing
and communication (ISAC) and (ii) massive multiple-input multiple-output
(MIMO).
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05727" title="Abstract">arXiv:2312.05727</a> [<a href="/pdf/2312.05727" title="Download PDF">pdf</a>, <a href="/format/2312.05727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyber-Physical Testbed Integrating RTAC with RTDS for Game-Theoretic  Topology Control Under Load Altering Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Selim%2C+A">Alaa Selim</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces a cyber-physical testbed that integrates the Real-Time
Digital Simulator (RTDS) with the Real-Time Automation Controller (RTAC) to
enhance cybersecurity in electrical distribution networks. Focused on
addressing vulnerabilities to cyber attacks, our testbed employs an advanced
control algorithm developed in Python and executed through real-time
controllers. Key to our approach is the seamless integration of the host PC
machine, RTDS, and RTAC via the Modbus protocol. We present a game theory-based
topology control strategy as an effective response to cyber attacks,
specifically targeting smart meters. This testbed validates the efficacy of our
method in fully eliminating voltage violations due to load altering attacks,
showcasing substantial advancements in smart grid cybersecurity via the
innovative use of RTDS and RTAC to simulate and counteract complex cyber
threats.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05730" title="Abstract">arXiv:2312.05730</a> [<a href="/pdf/2312.05730" title="Download PDF">pdf</a>, <a href="/format/2312.05730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFL-Net: Integrating Audio, Facial, and Lip Modalities with  Cross-Attention for Robust Speaker Diarization in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yongkang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuexian Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Speaker diarization in real-world videos presents significant challenges due
to varying acoustic conditions, diverse scenes, and the presence of off-screen
speakers, among other factors. This paper builds upon a previous study
(AVR-Net) and introduces a novel multi-modal speaker diarization system,
AFL-Net. Unlike AVR-Net, which independently extracts high-level
representations from each modality, AFL-Net employs a multi-modal
cross-attention mechanism. This approach generates high-level representations
from each modality while conditioning on each other, ensuring a more
comprehensive information fusion across modalities to enhance identity
discrimination. Furthermore, the proposed AFL-Net incorporates dynamic lip
movement as an additional modality to aid in distinguishing each segment's
identity. We also introduce a masking strategy during training that randomly
obscures the face and lip movement modalities, which increases the influence of
the audio modality on system outputs.Experimental results demonstrate that our
proposed model outperforms state-of-the-art baselines, such as the AVR-Net and
DyViSE. Moreover, an ablation study confirms the effectiveness of each
modification. Some demos are
provided:https://yyk77.github.io/afl_net.github.io.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05733" title="Abstract">arXiv:2312.05733</a> [<a href="/pdf/2312.05733" title="Download PDF">pdf</a>, <a href="/format/2312.05733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DevBots can co-design APIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marques%2C+V+S+S">Vinicius Soares Silva Marques</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">DevBots are automated tools that perform various tasks in order to support
software development. They are a growing trend and have been used in
repositories to automate repetitive tasks, as code generators, and as
collaborators in eliciting requirements and defining architectures. In this
study, we analyzed 24 articles to investigate the state of the art of using
DevBots in software development, trying to understand their characteristics,
identify use cases, learn the relationship between DevBots and conversational
software development, and discuss how prompt engineering can enable
collaboration between human developers and bots. Additionally, we identified a
gap to address by applying prompt engineering to collaborative API design
between human designers and DevBots and proposed an experiment to assess what
approach, between using Retrieval Augmented Generation or not, is more
suitable. Our conclusion is that DevBots can collaborate with human API
designers, but the two approaches have advantages and disadvantages.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05735" title="Abstract">arXiv:2312.05735</a> [<a href="/pdf/2312.05735" title="Download PDF">pdf</a>, <a href="/format/2312.05735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Multi-modal Conversational Emotion Recognition  with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shou%2C+Y">Yuntao Shou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Nan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multi-modal conversation emotion recognition (MCER) aims to recognize and
track the speaker's emotional state using text, speech, and visual information
in the conversation scene. Analyzing and studying MCER issues is significant to
affective computing, intelligent recommendations, and human-computer
interaction fields. Unlike the traditional single-utterance multi-modal emotion
recognition or single-modal conversation emotion recognition, MCER is a more
challenging problem that needs to deal with more complex emotional interaction
relationships. The critical issue is learning consistency and complementary
semantics for multi-modal feature fusion based on emotional interaction
relationships. To solve this problem, people have conducted extensive research
on MCER based on deep learning technology, but there is still a lack of
systematic review of the modeling methods. Therefore, a timely and
comprehensive overview of MCER's recent advances in deep learning is of great
significance to academia and industry. In this survey, we provide a
comprehensive overview of MCER modeling methods and roughly divide MCER methods
into four categories, i.e., context-free modeling, sequential context modeling,
speaker-differentiated modeling, and speaker-relationship modeling. In
addition, we further discuss MCER's publicly available popular datasets,
multi-modal feature extraction methods, application areas, existing challenges,
and future development directions. We hope that our review can help MCER
researchers understand the current research status in emotion recognition,
provide some inspiration, and develop more efficient models.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05736" title="Abstract">arXiv:2312.05736</a> [<a href="/pdf/2312.05736" title="Download PDF">pdf</a>, <a href="/format/2312.05736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASWT-SGNN: Adaptive Spectral Wavelet Transform-based Self-Supervised  Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+R">Rong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Graph Comparative Learning (GCL) is a self-supervised method that combines
the advantages of Graph Convolutional Networks (GCNs) and comparative learning,
making it promising for learning node representations. However, the GCN
encoders used in these methods rely on the Fourier transform to learn fixed
graph representations, which is inherently limited by the uncertainty principle
involving spatial and spectral localization trade-offs. To overcome the
inflexibility of existing methods and the computationally expensive
eigen-decomposition and dense matrix multiplication, this paper proposes an
Adaptive Spectral Wavelet Transform-based Self-Supervised Graph Neural Network
(ASWT-SGNN). The proposed method employs spectral adaptive polynomials to
approximate the filter function and optimize the wavelet using contrast loss.
This design enables the creation of local filters in both spectral and spatial
domains, allowing flexible aggregation of neighborhood information at various
scales and facilitating controlled transformation between local and global
information. Compared to existing methods, the proposed approach reduces
computational complexity and addresses the limitation of graph convolutional
neural networks, which are constrained by graph size and lack flexible control
over the neighborhood aspect. Extensive experiments on eight benchmark datasets
demonstrate that ASWT-SGNN accurately approximates the filter function in
high-density spectral regions, avoiding costly eigen-decomposition.
Furthermore, ASWT-SGNN achieves comparable performance to state-of-the-art
models in node classification tasks.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05737" title="Abstract">arXiv:2312.05737</a> [<a href="/pdf/2312.05737" title="Download PDF">pdf</a>, <a href="/ps/2312.05737" title="Download PostScript">ps</a>, <a href="/format/2312.05737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Threshold Schemes Under The Weak Secure Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiahong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wei Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we consider the case that sharing many secrets among a set of
participants using the threshold schemes. All secrets are assumed to be
statistically independent and the weak secure condition is focused on. Under
such circumstances we investigate the infimum of the (average) information
ratio and the (average) randomness ratio for any structure pair which consists
of the number of the participants and the threshold values of all secrets.
<br />For two structure pairs such that the two numbers of the participants are the
same and the two arrays of threshold values have the subset relationship, two
leading corollaries are proved following two directions. More specifically, the
bound related to the lengths of shares, secrets and randomness for the complex
structure pair can be truncated for the simple one; and the linear schemes for
the simple structure pair can be combined independently to be a multiple
threshold scheme for the complex one. The former corollary is useful for the
converse part and the latter one is helpful for the achievability part.
<br />Three new bounds special for the case that the number of secrets
corresponding to the same threshold value $ t $ is lager than $ t $ and two
novel linear schemes modified from the Vandermonde matrix for two similar cases
are presented. Then come the optimal results for the average information ratio,
the average randomness ratio and the randomness ratio. We introduce a tiny
example to show that there exists another type of bound that may be crucial for
the information ratio, to which we only give optimal results in three cases.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05738" title="Abstract">arXiv:2312.05738</a> [<a href="/pdf/2312.05738" title="Download PDF">pdf</a>, <a href="/format/2312.05738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedReverse: Multiparty Reversible Deep Neural Network Watermarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Junlong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huiyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengxia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhiyong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shanxiang Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The proliferation of Deep Neural Networks (DNN) in commercial applications is
expanding rapidly. Simultaneously, the increasing complexity and cost of
training DNN models have intensified the urgency surrounding the protection of
intellectual property associated with these trained models. In this regard, DNN
watermarking has emerged as a crucial safeguarding technique. This paper
presents FedReverse, a novel multiparty reversible watermarking approach for
robust copyright protection while minimizing performance impact. Unlike
existing methods, FedReverse enables collaborative watermark embedding from
multiple parties after model training, ensuring individual copyright claims. In
addition, FedReverse is reversible, enabling complete watermark removal with
unanimous client consent. FedReverse demonstrates perfect covering, ensuring
that observations of watermarked content do not reveal any information about
the hidden watermark. Additionally, it showcases resistance against Known
Original Attacks (KOA), making it highly challenging for attackers to forge
watermarks or infer the key. This paper further evaluates FedReverse through
comprehensive simulations involving Multi-layer Perceptron (MLP) and
Convolutional Neural Networks (CNN) trained on the MNIST dataset. The
simulations demonstrate FedReverse's robustness, reversibility, and minimal
impact on model accuracy across varying embedding parameters and multiple
client scenarios.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05739" title="Abstract">arXiv:2312.05739</a> [<a href="/pdf/2312.05739" title="Download PDF">pdf</a>, <a href="/format/2312.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAMC: An Unsupervised Method for Fake News Detection using Graph  Autoencoder with Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> the Thirty-Eighth AAAI Conference on Artificial Intelligence,2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rise of social media, the spread of fake news has become a
significant concern, potentially misleading public perceptions and impacting
social stability. Although deep learning methods like CNNs, RNNs, and
Transformer-based models like BERT have enhanced fake news detection, they
primarily focus on content, overlooking social context during news propagation.
Graph-based techniques have incorporated this social context but are limited by
the need for large labeled datasets. Addressing these challenges, this paper
introduces GAMC, an unsupervised fake news detection technique using the Graph
Autoencoder with Masking and Contrastive learning. By leveraging both the
context and content of news propagation as self-supervised signals, our method
negates the requirement for labeled datasets. We augment the original news
propagation graph, encode these with a graph encoder, and employ a graph
decoder for reconstruction. A unique composite loss function, including
reconstruction error and contrast loss, is designed. The method's contributions
are: introducing self-supervised learning to fake news detection, proposing a
graph autoencoder integrating two distinct losses, and validating our
approach's efficacy through real-world dataset experiments.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05741" title="Abstract">arXiv:2312.05741</a> [<a href="/pdf/2312.05741" title="Download PDF">pdf</a>, <a href="/format/2312.05741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with  Intent-Slot Co-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thinh Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Chi Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Q">Dat Quoc Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023 (<a href="https://aclanthology.org/2023.findings-emnlp.841.pdf">this https URL</a>); Long paper - 10 pages; 3 figures and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The research study of detecting multiple intents and filling slots is
becoming more popular because of its relevance to complicated real-world
situations. Recent advanced approaches, which are joint models based on graphs,
might still face two potential issues: (i) the uncertainty introduced by
constructing graphs based on preliminary intents and slots, which may transfer
intent-slot correlation information to incorrect label node destinations, and
(ii) direct incorporation of multiple intent labels for each token w.r.t.
token-level intent voting might potentially lead to incorrect slot predictions,
thereby hurting the overall performance. To address these two issues, we
propose a joint model named MISCA. Our MISCA introduces an intent-slot
co-attention mechanism and an underlying layer of label attention mechanism.
These mechanisms enable MISCA to effectively capture correlations between
intents and slot labels, eliminating the need for graph construction. They also
facilitate the transfer of correlation information in both directions: from
intents to slots and from slots to intents, through multiple levels of
label-specific representations, without relying on token-level intent
information. Experimental results show that MISCA outperforms previous models,
achieving new state-of-the-art overall accuracy performances on two benchmark
datasets MixATIS and MixSNIPS. This highlights the effectiveness of our
attention mechanisms.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05742" title="Abstract">arXiv:2312.05742</a> [<a href="/pdf/2312.05742" title="Download PDF">pdf</a>, <a href="/format/2312.05742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Generalization Gap in Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mediratta%2C+I">Ishita Mediratta</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Qingfei You</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Raileanu%2C+R">Roberta Raileanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite recent progress in offline learning, these methods are still trained
and tested on the same environment. In this paper, we compare the
generalization abilities of widely used online and offline learning methods
such as online reinforcement learning (RL), offline RL, sequence modeling, and
behavioral cloning. Our experiments show that offline learning algorithms
perform worse on new environments than online learning ones. We also introduce
the first benchmark for evaluating generalization in offline learning,
collecting datasets of varying sizes and skill-levels from Procgen (2D video
games) and WebShop (e-commerce websites). The datasets contain trajectories for
a limited number of game levels or natural language instructions and at test
time, the agent has to generalize to new levels or instructions. Our
experiments reveal that existing offline learning algorithms struggle to match
the performance of online RL on both train and test environments. Behavioral
cloning is a strong baseline, outperforming state-of-the-art offline RL and
sequence modeling approaches when trained on data from multiple environments
and tested on new ones. Finally, we find that increasing the diversity of the
data, rather than its size, improves performance on new environments for all
offline learning algorithms. Our study demonstrates the limited generalization
of current offline learning algorithms highlighting the need for more research
in this area.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05743" title="Abstract">arXiv:2312.05743</a> [<a href="/pdf/2312.05743" title="Download PDF">pdf</a>, <a href="/format/2312.05743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Variable-sized Models via Learngene Pool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shiyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Z">Zhiqiang Kou</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, Stitchable Neural Networks (SN-Net) is proposed to stitch some
pre-trained networks for quickly building numerous networks with different
complexity and performance trade-offs. In this way, the burdens of designing or
training the variable-sized networks, which can be used in application
scenarios with diverse resource constraints, are alleviated. However, SN-Net
still faces a few challenges. 1) Stitching from multiple independently
pre-trained anchors introduces high storage resource consumption. 2) SN-Net
faces challenges to build smaller models for low resource constraints. 3).
SN-Net uses an unlearned initialization method for stitch layers, limiting the
final performance. To overcome these challenges, motivated by the recently
proposed Learngene framework, we propose a novel method called Learngene Pool.
Briefly, Learngene distills the critical knowledge from a large pre-trained
model into a small part (termed as learngene) and then expands this small part
into a few variable-sized models. In our proposed method, we distill one
pretrained large model into multiple small models whose network blocks are used
as learngene instances to construct the learngene pool. Since only one large
model is used, we do not need to store more large models as SN-Net and after
distilling, smaller learngene instances can be created to build small models to
satisfy low resource constraints. We also insert learnable transformation
matrices between the instances to stitch them into variable-sized models to
improve the performance of these models. Exhaustive experiments have been
implemented and the results validate the effectiveness of the proposed
Learngene Pool compared with SN-Net.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05745" title="Abstract">arXiv:2312.05745</a> [<a href="/pdf/2312.05745" title="Download PDF">pdf</a>, <a href="/format/2312.05745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open World Object Detection in the Era of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zohar%2C+O">Orr Zohar</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Alejandro Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Shelly Goel</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Serena Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuan-Chieh Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Object detection is integral to a bevy of real-world applications, from
robotics to medical image analysis. To be used reliably in such applications,
models must be capable of handling unexpected - or novel - objects. The open
world object detection (OWD) paradigm addresses this challenge by enabling
models to detect unknown objects and learn discovered ones incrementally.
However, OWD method development is hindered due to the stringent benchmark and
task definitions. These definitions effectively prohibit foundation models.
Here, we aim to relax these definitions and investigate the utilization of
pre-trained foundation models in OWD. First, we show that existing benchmarks
are insufficient in evaluating methods that utilize foundation models, as even
naive integration methods nearly saturate these benchmarks. This result
motivated us to curate a new and challenging benchmark for these models.
Therefore, we introduce a new benchmark that includes five real-world
application-driven datasets, including challenging domains such as aerial and
surgical images, and establish baselines. We exploit the inherent connection
between classes in application-driven datasets and introduce a novel method,
Foundation Object detection Model for the Open world, or FOMO, which identifies
unknown objects based on their shared attributes with the base known objects.
FOMO has ~3x unknown object mAP compared to baselines on our benchmark.
However, our results indicate a significant place for improvement - suggesting
a great research opportunity in further scaling object detection methods to
real-world domains. Our code and benchmark are available at
https://orrzohar.github.io/projects/fomo/.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05746" title="Abstract">arXiv:2312.05746</a> [<a href="/pdf/2312.05746" title="Download PDF">pdf</a>, <a href="/ps/2312.05746" title="Download PostScript">ps</a>, <a href="/format/2312.05746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scalable MARL Solution for Scheduling in Conflict Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongning Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes a fully scalable multi-agent reinforcement learning
(MARL) approach for packet scheduling in conflict graphs, aiming to minimizing
average packet delays. Each agent autonomously manages the schedule of a single
link over one or multiple sub-bands, considering its own state and states of
conflicting links. The problem can be conceptualized as a decentralized
partially observable Markov decision process (Dec-POMDP). The proposed solution
leverages an on-policy reinforcement learning algorithms multi-agent proximal
policy optimization (MAPPO) within a multi-agent networked system,
incorporating advanced recurrent structures in the neural network. The MARL
design allows for fully decentralized training and execution, seamlessly
scaling to very large networks. Extensive simulations across a diverse range of
conflict graphs demonstrate that the proposed solution compares favorably to
well-established schedulers in terms of both throughput and delay under various
traffic conditions.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05747" title="Abstract">arXiv:2312.05747</a> [<a href="/pdf/2312.05747" title="Download PDF">pdf</a>, <a href="/ps/2312.05747" title="Download PostScript">ps</a>, <a href="/format/2312.05747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difference of Probability and Information Entropy for Skills  Classification and Prediction in Student Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehimwenma%2C+K+E">Kennedy Efosa Ehimwenma</a>, 
<a href="/search/cs?searchtype=author&query=Sharji%2C+S+A">Safiya Al Sharji</a>, 
<a href="/search/cs?searchtype=author&query=Raheem%2C+M">Maruf Raheem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The probability of an event is in the range of [0, 1]. In a sample space S,
the value of probability determines whether an outcome is true or false. The
probability of an event Pr(A) that will never occur = 0. The probability of the
event Pr(B) that will certainly occur = 1. This makes both events A and B thus
a certainty. Furthermore, the sum of probabilities Pr(E1) + Pr(E2) + ... +
Pr(En) of a finite set of events in a given sample space S = 1. Conversely, the
difference of the sum of two probabilities that will certainly occur is 0.
Firstly, this paper discusses Bayes' theorem, then complement of probability
and the difference of probability for occurrences of learning-events, before
applying these in the prediction of learning objects in student learning. Given
the sum total of 1; to make recommendation for student learning, this paper
submits that the difference of argMaxPr(S) and probability of
student-performance quantifies the weight of learning objects for students.
Using a dataset of skill-set, the computational procedure demonstrates: i) the
probability of skill-set events that has occurred that would lead to higher
level learning; ii) the probability of the events that has not occurred that
requires subject-matter relearning; iii) accuracy of decision tree in the
prediction of student performance into class labels; and iv) information
entropy about skill-set data and its implication on student cognitive
performance and recommendation of learning [1].
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05748" title="Abstract">arXiv:2312.05748</a> [<a href="/pdf/2312.05748" title="Download PDF">pdf</a>, <a href="/format/2312.05748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IL-NeRF: Incremental Learning for Neural Radiance Fields with Camera  Pose Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Letian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural radiance fields (NeRF) is a promising approach for generating
photorealistic images and representing complex scenes. However, when processing
data sequentially, it can suffer from catastrophic forgetting, where previous
data is easily forgotten after training with new data. Existing incremental
learning methods using knowledge distillation assume that continuous data
chunks contain both 2D images and corresponding camera pose parameters,
pre-estimated from the complete dataset. This poses a paradox as the necessary
camera pose must be estimated from the entire dataset, even though the data
arrives sequentially and future chunks are inaccessible. In contrast, we focus
on a practical scenario where camera poses are unknown. We propose IL-NeRF, a
novel framework for incremental NeRF training, to address this challenge.
IL-NeRF's key idea lies in selecting a set of past camera poses as references
to initialize and align the camera poses of incoming image data. This is
followed by a joint optimization of camera poses and replay-based NeRF
distillation. Our experiments on real-world indoor and outdoor scenes show that
IL-NeRF handles incremental NeRF training and outperforms the baselines by up
to $54.04\%$ in rendering quality.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05750" title="Abstract">arXiv:2312.05750</a> [<a href="/pdf/2312.05750" title="Download PDF">pdf</a>, <a href="/ps/2312.05750" title="Download PostScript">ps</a>, <a href="/format/2312.05750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperresolution for Multi-step Fuzzy Inference in Goedel Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guller%2C+D">Dusan Guller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">This paper is a continuation of our work concerning the logical and
computational foundations of multi-step fuzzy inference. We bring further
results on the implementation of the Mamdani-Assilian type of fuzzy rules and
inference in Goedel logic with truth constants. In our previous work, we have
provided translation of Mamdani-Assilian fuzzy rules to formulae of Goedel
logic, and subsequently, to suitable clausal form. Moreover, we have outlined a
class of problems regarding general properties of fuzzy inference and shown its
reduction to a class of deduction/unsatisfiability problems. We now focus on
solving such problems using an adapted hyperresolution calculus.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05751" title="Abstract">arXiv:2312.05751</a> [<a href="/pdf/2312.05751" title="Download PDF">pdf</a>, <a href="/format/2312.05751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking of Query Strategies: Towards Future Deep Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ueno%2C+S">Shiryu Ueno</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+Y">Yusei Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Nakatsuka%2C+S">Shunsuke Nakatsuka</a>, 
<a href="/search/cs?searchtype=author&query=Kato%2C+K">Kunihito Kato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we benchmark query strategies for deep actice learning~(DAL).
DAL reduces annotation costs by annotating only high-quality samples selected
by query strategies. Existing research has two main problems, that the
experimental settings are not standardized, making the evaluation of existing
methods is difficult, and that most of experiments were conducted on the CIFAR
or MNIST datasets. Therefore, we develop standardized experimental settings for
DAL and investigate the effectiveness of various query strategies using six
datasets, including those that contain medical and visual inspection images. In
addition, since most current DAL approaches are model-based, we perform
verification experiments using fully-trained models for querying to investigate
the effectiveness of these approaches for the six datasets. Our code is
available at
\href{https://github.com/ia-gu/Benchmarking-of-Query-Strategies-Towards-Future-Deep-Active-Learning}
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05752" title="Abstract">arXiv:2312.05752</a> [<a href="/pdf/2312.05752" title="Download PDF">pdf</a>, <a href="/format/2312.05752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camera-based 3D Semantic Scene Completion with Sparse Guidance Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jianbiao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengmeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangrui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ra%2C+J">Jongwon Ra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Laijian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic scene completion (SSC) aims to predict the semantic occupancy of
each voxel in the entire 3D scene from limited observations, which is an
emerging and critical task for autonomous driving. Recently, many studies have
turned to camera-based SSC solutions due to the richer visual cues and
cost-effectiveness of cameras. However, existing methods usually rely on
sophisticated and heavy 3D models to directly process the lifted 3D features
that are not discriminative enough for clear segmentation boundaries. In this
paper, we adopt the dense-sparse-dense design and propose an end-to-end
camera-based SSC framework, termed SGN, to diffuse semantics from the semantic-
and occupancy-aware seed voxels to the whole scene based on geometry prior and
occupancy information. By designing hybrid guidance (sparse semantic and
geometry guidance) and effective voxel aggregation for spatial occupancy and
geometry priors, we enhance the feature separation between different categories
and expedite the convergence of semantic diffusion. Extensive experimental
results on the SemanticKITTI dataset demonstrate the superiority of our SGN
over existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05756" title="Abstract">arXiv:2312.05756</a> [<a href="/pdf/2312.05756" title="Download PDF">pdf</a>, <a href="/ps/2312.05756" title="Download PostScript">ps</a>, <a href="/format/2312.05756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantitative fusion strategy of stock picking and timing based on  Particle Swarm Optimized-Back Propagation Neural Network and Multivariate  Gaussian-Hidden Markov Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huajian Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Weinan Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 4 tables, 26 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">In recent years, machine learning (ML) has brought effective approaches and
novel techniques to economic decision, investment forecasting, and risk
management, etc., coping the variable and intricate nature of economic and
financial environments. For the investment in stock market, this research
introduces a pioneering quantitative fusion model combining stock timing and
picking strategy by leveraging the Multivariate Gaussian-Hidden Markov Model
(MGHMM) and Back Propagation Neural Network optimized by Particle Swarm
(PSO-BPNN). After the information coefficients (IC) between fifty-two factors
that have been winsorized, neutralized and standardized and the return of CSI
300 index are calculated, a given amount of factors that rank ahead are choose
to be candidate factors heading for the input of PSO-BPNN after dimension
reduction by Principal Component Analysis (PCA), followed by a certain amount
of constituent stocks outputted. Subsequently, we conduct the prediction and
trading on the basis of the screening stocks and stock market state outputted
by MGHMM trained using inputting CSI 300 index data after Box-Cox
transformation, bespeaking eximious performance during the period of past four
years. Ultimately, some conventional forecast and trading methods are compared
with our strategy in Chinese stock market. Our fusion strategy incorporating
stock picking and timing presented in this article provide a innovative
technique for financial analysis.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05757" title="Abstract">arXiv:2312.05757</a> [<a href="/pdf/2312.05757" title="Download PDF">pdf</a>, <a href="/ps/2312.05757" title="Download PostScript">ps</a>, <a href="/format/2312.05757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Human-like Perception: Learning Structural Causal Model in  Heterogeneous Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianqianjin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaisong Song</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhuoren Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yangyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weikang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xurui Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changlong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Cui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures, 6 tables, accepted by Information Processing &amp; Management
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Processing &amp; Management, 60 (2024) 1-21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Social and Information Networks (cs.SI); Methodology (stat.ME)

</div>
<p class="mathjax">Heterogeneous graph neural networks have become popular in various domains.
However, their generalizability and interpretability are limited due to the
discrepancy between their inherent inference flows and human reasoning logic or
underlying causal relationships for the learning problem. This study introduces
a novel solution, HG-SCM (Heterogeneous Graph as Structural Causal Model). It
can mimic the human perception and decision process through two key steps:
constructing intelligible variables based on semantics derived from the graph
schema and automatically learning task-level causal relationships among these
variables by incorporating advanced causal discovery techniques. We compared
HG-SCM to seven state-of-the-art baseline models on three real-world datasets,
under three distinct and ubiquitous out-of-distribution settings. HG-SCM
achieved the highest average performance rank with minimal standard deviation,
substantiating its effectiveness and superiority in terms of both predictive
power and generalizability. Additionally, the visualization and analysis of the
auto-learned causal diagrams for the three tasks aligned well with domain
knowledge and human cognition, demonstrating prominent interpretability.
HG-SCM's human-like nature and its enhanced generalizability and
interpretability make it a promising solution for special scenarios where
transparency and trustworthiness are paramount.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05758" title="Abstract">arXiv:2312.05758</a> [<a href="/pdf/2312.05758" title="Download PDF">pdf</a>, <a href="/format/2312.05758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLeaRForecast: Contrastive Learning of High-Purity Representations for  Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qinglong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+S">Siqi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Time series forecasting (TSF) holds significant importance in modern society,
spanning numerous domains. Previous representation learning-based TSF
algorithms typically embrace a contrastive learning paradigm featuring
segregated trend-periodicity representations. Yet, these methodologies
disregard the inherent high-impact noise embedded within time series data,
resulting in representation inaccuracies and seriously demoting the forecasting
performance. To address this issue, we propose CLeaRForecast, a novel
contrastive learning framework to learn high-purity time series representations
with proposed sample, feature, and architecture purifying methods. More
specifically, to avoid more noise adding caused by the transformations of
original samples (series), transformations are respectively applied for trendy
and periodic parts to provide better positive samples with obviously less
noise. Moreover, we introduce a channel independent training manner to mitigate
noise originating from unrelated variables in the multivariate series. By
employing a streamlined deep-learning backbone and a comprehensive global
contrastive loss function, we prevent noise introduction due to redundant or
uneven learning of periodicity and trend. Experimental results show the
superior performance of CLeaRForecast in various downstream TSF tasks.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05759" title="Abstract">arXiv:2312.05759</a> [<a href="/pdf/2312.05759" title="Download PDF">pdf</a>, <a href="/format/2312.05759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond One Model Fits All: Ensemble Deep Learning for Autonomous  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manjunatha%2C+H">Hemanth Manjunatha</a>, 
<a href="/search/cs?searchtype=author&query=Tsiotras%2C+P">Panagiotis Tsiotras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has revolutionized autonomous driving by enabling vehicles to
perceive and interpret their surroundings with remarkable accuracy. This
progress is attributed to various deep learning models, including Mediated
Perception, Behavior Reflex, and Direct Perception, each offering unique
advantages and challenges in enhancing autonomous driving capabilities.
However, there is a gap in research addressing integrating these approaches and
understanding their relevance in diverse driving scenarios. This study
introduces three distinct neural network models corresponding to Mediated
Perception, Behavior Reflex, and Direct Perception approaches. We explore their
significance across varying driving conditions, shedding light on the strengths
and limitations of each approach. Our architecture fuses information from the
base, future latent vector prediction, and auxiliary task networks, using
global routing commands to select appropriate action sub-networks. We aim to
provide insights into effectively utilizing diverse modeling strategies in
autonomous driving by conducting experiments and evaluations. The results show
that the ensemble model performs better than the individual approaches,
suggesting that each modality contributes uniquely toward the performance of
the overall model. Moreover, by exploring the significance of each modality,
this study offers a roadmap for future research in autonomous driving,
emphasizing the importance of leveraging multiple models to achieve robust
performance.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05760" title="Abstract">arXiv:2312.05760</a> [<a href="/pdf/2312.05760" title="Download PDF">pdf</a>, <a href="/format/2312.05760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RepViT-SAM: Towards Real-Time Segmenting Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Ao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segment Anything Model (SAM) has shown impressive zero-shot transfer
performance for various computer vision tasks recently. However, its heavy
computation costs remain daunting for practical applications. MobileSAM
proposes to replace the heavyweight image encoder in SAM with TinyViT by
employing distillation, which results in a significant reduction in
computational requirements. However, its deployment on resource-constrained
mobile devices still encounters challenges due to the substantial memory and
computational overhead caused by self-attention mechanisms. Recently, RepViT
achieves the state-of-the-art performance and latency trade-off on mobile
devices by incorporating efficient architectural designs of ViTs into CNNs.
Here, to achieve real-time segmenting anything on mobile devices, following
MobileSAM, we replace the heavyweight image encoder in SAM with RepViT model,
ending up with the RepViT-SAM model. Extensive experiments show that RepViT-SAM
can enjoy significantly better zero-shot transfer capability than MobileSAM,
along with nearly $10\times$ faster inference speed. The code and models are
available at \url{https://github.com/THU-MIG/RepViT}.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05761" title="Abstract">arXiv:2312.05761</a> [<a href="/pdf/2312.05761" title="Download PDF">pdf</a>, <a href="/format/2312.05761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QMGeo: Differentially Private Federated Learning via Stochastic  Quantization with Mixed Truncated Geometric Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gursoy%2C+M+C">M. Cenk Gursoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) is a framework which allows multiple users to jointly
train a global machine learning (ML) model by transmitting only model updates
under the coordination of a parameter server, while being able to keep their
datasets local. One key motivation of such distributed frameworks is to provide
privacy guarantees to the users. However, preserving the users' datasets
locally is shown to be not sufficient for privacy. Several differential privacy
(DP) mechanisms have been proposed to provide provable privacy guarantees by
introducing randomness into the framework, and majority of these mechanisms
rely on injecting additive noise. FL frameworks also face the challenge of
communication efficiency, especially as machine learning models grow in
complexity and size. Quantization is a commonly utilized method, reducing the
communication cost by transmitting compressed representation of the underlying
information. Although there have been several studies on DP and quantization in
FL, the potential contribution of the quantization method alone in providing
privacy guarantees has not been extensively analyzed yet. We in this paper
present a novel stochastic quantization method, utilizing a mixed geometric
distribution to introduce the randomness needed to provide DP, without any
additive noise. We provide convergence analysis for our framework and
empirically study its performance.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05762" title="Abstract">arXiv:2312.05762</a> [<a href="/pdf/2312.05762" title="Download PDF">pdf</a>, <a href="/format/2312.05762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yougang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jitai Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multiple defendants in a criminal fact description generally exhibit complex
interactions, and cannot be well handled by existing Legal Judgment Prediction
(LJP) methods which focus on predicting judgment results (e.g., law articles,
charges, and terms of penalty) for single-defendant cases. To address this
problem, we propose the task of multi-defendant LJP, which aims to
automatically predict the judgment results for each defendant of
multi-defendant cases. Two challenges arise with the task of multi-defendant
LJP: (1) indistinguishable judgment results among various defendants; and (2)
the lack of a real-world dataset for training and evaluation. To tackle the
first challenge, we formalize the multi-defendant judgment process as
hierarchical reasoning chains and introduce a multi-defendant LJP method, named
Hierarchical Reasoning Network (HRN), which follows the hierarchical reasoning
chains to determine criminal relationships, sentencing circumstances, law
articles, charges, and terms of penalty for each defendant. To tackle the
second challenge, we collect a real-world multi-defendant LJP dataset, namely
MultiLJP, to accelerate the relevant research in the future. Extensive
experiments on MultiLJP verify the effectiveness of our proposed HRN.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05763" title="Abstract">arXiv:2312.05763</a> [<a href="/pdf/2312.05763" title="Download PDF">pdf</a>, <a href="/ps/2312.05763" title="Download PostScript">ps</a>, <a href="/format/2312.05763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Movable-Antenna Array Enabled Multiuser Uplink: A Low-Complexity  Gradient Descent for Total Transmit Power Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guojie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jian Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+J">Jiangbo Si</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yunlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Al-Dhahir%2C+N">Naofal Al-Dhahir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We investigate multiuser uplink communication from multiple single-antenna
users to a base station (BS), which is equipped with a movable-antenna (MA)
array and adopts zero-forcing receivers to decode multiple signals. We aim to
optimize the MAs' positions at the BS, to minimize the total transmit power of
all users subject to the minimum rate requirement. After applying
transformations, we show that the problem is equivalent to minimizing the sum
of each eigenvalue's reciprocal of a matrix, which is a function of all MAs'
positions. Subsequently, the projected gradient descent (PGD) method is
utilized to find a locally optimal solution. In particular, different from the
latest related work, we exploit the eigenvalue decomposition to successfully
derive a closed-form gradient for the PGD, which facilitates the practical
implementation greatly. We demonstrate by simulations that via careful
optimization for all MAs' positions in our proposed design, the total transmit
power of all users can be decreased significantly as compared to competitive
benchmarks.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05764" title="Abstract">arXiv:2312.05764</a> [<a href="/pdf/2312.05764" title="Download PDF">pdf</a>, <a href="/format/2312.05764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesis of Temporally-Robust Policies for Signal Temporal Logic Tasks  using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Siqi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shaoyuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiang Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper investigates the problem of designing control policies that
satisfy high-level specifications described by signal temporal logic (STL) in
unknown, stochastic environments. While many existing works concentrate on
optimizing the spatial robustness of a system, our work takes a step further by
also considering temporal robustness as a critical metric to quantify the
tolerance of time uncertainty in STL. To this end, we formulate two relevant
control objectives to enhance the temporal robustness of the synthesized
policies. The first objective is to maximize the probability of being
temporally robust for a given threshold. The second objective is to maximize
the worst-case spatial robustness value within a bounded time shift. We use
reinforcement learning to solve both control synthesis problems for unknown
systems. Specifically, we approximate both control objectives in a way that
enables us to apply the standard Q-learning algorithm. Theoretical bounds in
terms of the approximations are also derived. We present case studies to
demonstrate the feasibility of our approach.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05767" title="Abstract">arXiv:2312.05767</a> [<a href="/pdf/2312.05767" title="Download PDF">pdf</a>, <a href="/format/2312.05767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnomalyDiffusion: Few-Shot Anomaly Image Generation with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Teng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Ran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuzhen Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Anomaly inspection plays an important role in industrial manufacture.
Existing anomaly inspection methods are limited in their performance due to
insufficient anomaly data. Although anomaly generation methods have been
proposed to augment the anomaly data, they either suffer from poor generation
authenticity or inaccurate alignment between the generated anomalies and masks.
To address the above problems, we propose AnomalyDiffusion, a novel
diffusion-based few-shot anomaly generation model, which utilizes the strong
prior information of latent diffusion model learned from large-scale dataset to
enhance the generation authenticity under few-shot training data. Firstly, we
propose Spatial Anomaly Embedding, which consists of a learnable anomaly
embedding and a spatial embedding encoded from an anomaly mask, disentangling
the anomaly information into anomaly appearance and location information.
Moreover, to improve the alignment between the generated anomalies and the
anomaly masks, we introduce a novel Adaptive Attention Re-weighting Mechanism.
Based on the disparities between the generated anomaly image and normal sample,
it dynamically guides the model to focus more on the areas with less noticeable
generated anomalies, enabling generation of accurately-matched anomalous
image-mask pairs. Extensive experiments demonstrate that our model
significantly outperforms the state-of-the-art methods in generation
authenticity and diversity, and effectively improves the performance of
downstream anomaly inspection tasks. The code and data are available in
https://github.com/sjtuplayer/anomalydiffusion.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05770" title="Abstract">arXiv:2312.05770</a> [<a href="/pdf/2312.05770" title="Download PDF">pdf</a>, <a href="/format/2312.05770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedASMU: Efficient Asynchronous Federated Learning with Dynamic  Staleness-aware Model Update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Juncheng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+T">Tianshi Che</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+C">Chao Huo</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiaxiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huaiyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+D">Dejing Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, to appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">As a promising approach to deal with distributed data, Federated Learning
(FL) achieves major advancements in recent years. FL enables collaborative
model training by exploiting the raw data dispersed in multiple edge devices.
However, the data is generally non-independent and identically distributed,
i.e., statistical heterogeneity, and the edge devices significantly differ in
terms of both computation and communication capacity, i.e., system
heterogeneity. The statistical heterogeneity leads to severe accuracy
degradation while the system heterogeneity significantly prolongs the training
process. In order to address the heterogeneity issue, we propose an
Asynchronous Staleness-aware Model Update FL framework, i.e., FedASMU, with two
novel methods. First, we propose an asynchronous FL system model with a
dynamical model aggregation method between updated local models and the global
model on the server for superior accuracy and high efficiency. Then, we propose
an adaptive local model adjustment method by aggregating the fresh global model
with local models on devices to further improve the accuracy. Extensive
experimentation with 6 models and 5 public datasets demonstrates that FedASMU
significantly outperforms baseline approaches in terms of accuracy (0.60% to
23.90% higher) and efficiency (3.54% to 97.98% faster).
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05771" title="Abstract">arXiv:2312.05771</a> [<a href="/pdf/2312.05771" title="Download PDF">pdf</a>, <a href="/format/2312.05771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hacking Task Confounder in Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zeen Song</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xingzhe Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Meta-learning enables rapid generalization to new tasks by learning
meta-knowledge from a variety of tasks. It is intuitively assumed that the more
tasks a model learns in one training batch, the richer knowledge it acquires,
leading to better generalization performance. However, contrary to this
intuition, our experiments reveal an unexpected result: adding more tasks
within a single batch actually degrades the generalization performance. To
explain this unexpected phenomenon, we conduct a Structural Causal Model (SCM)
for causal analysis. Our investigation uncovers the presence of spurious
correlations between task-specific causal factors and labels in meta-learning.
Furthermore, the confounding factors differ across different batches. We refer
to these confounding factors as ``Task Confounders". Based on this insight, we
propose a plug-and-play Meta-learning Causal Representation Learner (MetaCRL)
to eliminate task confounders. It encodes decoupled causal factors from
multiple tasks and utilizes an invariant-based bi-level optimization mechanism
to ensure their causality for meta-learning. Extensive experiments on various
benchmark datasets demonstrate that our work achieves state-of-the-art (SOTA)
performance.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05772" title="Abstract">arXiv:2312.05772</a> [<a href="/pdf/2312.05772" title="Download PDF">pdf</a>, <a href="/format/2312.05772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Code Generation Framework for Code Repositories: Local,  Global, and Third-Party Library Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Dianshu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoxue Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Huan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinying Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code generation tools are essential to help developers in the software
development process. Existing tools often disconnect with the working context,
i.e., the code repository, causing the generated code to be not similar to
human developers. In this paper, we propose a novel code generation framework,
dubbed \textbf{$A^3$}-CodGen, to harness information within the code repository
to generate code with fewer logical errors, code redundancy, and
library-related compatibility issues. We identify three categories of
representative information for the code repository: local-aware information
from current code file, global-aware information from other code files, and
third-party-library information. Results demonstrate that by adopting the
\textbf{$A^3$}-CodGen framework, we successfully extract, fuse, and feed code
repository information into the LLM, generating more accurate, efficient, and
highly reusable code. The effectiveness of our framework is further underscored
by generating code with a higher reuse rate, compared to human developers. This
research contributes significantly to the field of code generation, providing
developers with a more powerful tool to address the evolving demands in
software development in practice.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05773" title="Abstract">arXiv:2312.05773</a> [<a href="/pdf/2312.05773" title="Download PDF">pdf</a>, <a href="/format/2312.05773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explosive Legged Robotic Hopping: Energy Accumulation and Power  Amplification via Pneumatic Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gamboa-Gonzalez%2C+A">Arturo Gamboa-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Wehner%2C+M">Michael Wehner</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiaobin Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures. Updated version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a novel pneumatic augmentation to traditional electric
motor-actuated legged robot to increase intermittent power density to perform
infrequent explosive hopping behaviors. The pneumatic system is composed of a
pneumatic pump, a tank, and a pneumatic actuator. The tank is charged up by the
pump during regular hopping motion that is created by the electric motors. At
any time after reaching a desired air pressure in the tank, a solenoid valve is
utilized to rapidly release the air pressure to the pneumatic actuator (piston)
which is used in conjunction with the electric motors to perform explosive
hopping, increasing maximum hopping height for one or subsequent cycles. We
show that, on a custom-designed one-legged hopping robot, without any
additional power source and with this novel pneumatic augmentation system,
their associated system identification and optimal control, the robot is able
to realize highly explosive hopping with power amplification per cycle by a
factor of approximately 5.4 times the power of electric motor actuation alone.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05777" title="Abstract">arXiv:2312.05777</a> [<a href="/pdf/2312.05777" title="Download PDF">pdf</a>, <a href="/format/2312.05777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negative Pre-aware for Noisy Cross-modal Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+L">Li Hao</a>, 
<a href="/search/cs?searchtype=author&query=Mang%2C+Y">Ye Mang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-modal noise-robust learning is a challenging task since noisy
correspondence is hard to recognize and rectify. Due to the cumulative and
unavoidable negative impact of unresolved noise, existing methods cannot
maintain a stable performance when the noise increases. In this paper, we
present a novel Negative Pre-aware Cross-modal (NPC) matching solution for
large visual-language model fine-tuning on noisy downstream tasks. It is
featured in two aspects: (1) For noise recognition and resistance, previous
methods usually directly filter out a noise subset, we propose to estimate the
negative impact of each sample. It does not need additional correction
mechanisms that may predict unreliable correction results, leading to
self-reinforcing error. We assign a confidence weight to each sample according
to its negative impact in the training process. This adaptively adjusts the
contribution of each sample to avoid noisy accumulation. (2) For maintaining
stable performance with increasing noise, we utilize the memorization effect of
DNNs by maintaining a memory bank. Specifically, we apply GMM to select
high-confident clean samples as the memory entry, where the memory entry is
used to estimate the negative impact of each sample. Since clean samples are
easier distinguished by GMM with increasing noise, the memory bank can still
maintain high quality at a high noise ratio. Compared to the correction
mechanism focusing on noise samples, memory bank-based estimation is more
robust, which makes the model performance stable on noisy datasets. Extensive
experiments demonstrate that our method significantly improves matching
accuracy and performance stability at increasing noise ratio. Our approach also
surpasses the state-of-the-art methods by a large margin.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05778" title="Abstract">arXiv:2312.05778</a> [<a href="/pdf/2312.05778" title="Download PDF">pdf</a>, <a href="/format/2312.05778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding ChatGPT to Fix Web UI Tests via Explanation-Consistency Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuolin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuanzhang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiushi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S+H">Shin Hwei Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The rapid evolution of Web UI incurs time and effort in maintaining UI tests.
Existing techniques in Web UI test repair focus on finding the target elements
on the new web page that match the old ones so that the corresponding broken
statements can be repaired. We present the first study that investigates the
feasibility of using prior Web UI repair techniques for initial local matching
and then using ChatGPT to perform global matching. Our key insight is that
given a list of elements matched by prior techniques, ChatGPT can leverage the
language understanding to perform global view matching and use its code
generation model for fixing the broken statements. To mitigate hallucination in
ChatGPT, we design an explanation validator that checks whether the provided
explanation for the matching results is consistent, and provides hints to
ChatGPT via a self-correction prompt to further improve its results. Our
evaluation on a widely used dataset shows that the ChatGPT-enhanced techniques
improve the effectiveness of existing Web test repair techniques. Our study
also shares several important insights in improving future Web UI test repair
techniques.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05779" title="Abstract">arXiv:2312.05779</a> [<a href="/pdf/2312.05779" title="Download PDF">pdf</a>, <a href="/ps/2312.05779" title="Download PostScript">ps</a>, <a href="/format/2312.05779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autotuning by Changing Directives and Number of Threads in OpenMP using  ppOpen-AT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakurai%2C+T">Toma Sakurai</a>, 
<a href="/search/cs?searchtype=author&query=Ohshima%2C+S">Satoshi Ohshima</a>, 
<a href="/search/cs?searchtype=author&query=Katagiri%2C+T">Takahiro Katagiri</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+T">Toru Nagai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recently, computers have diversified architectures. To achieve high numerical
calculation software performance, it is necessary to tune the software
according to the target computer architecture. However, code optimization for
each environment is difficult unless it is performed by a specialist who knows
computer architectures well. By applying autotuning (AT), the tuning effort can
be reduced. Optimized implementation by AT that enhances computer performance
can be used even by non-experts. In this research, we propose a technique for
AT for programs using open multi-processing (OpenMP). We propose an AT method
using an AT language that changes the OpenMP optimized loop and dynamically
changes the number of threads in OpenMP according to computational kernels.
Performance evaluation was performed using the Fujitsu PRIMEHPC FX100, which is
a K-computer type supercomputer installed at the Information Technology Center,
Nagoya University. As a result, we found there was a performance increase of
1.801 times that of the original code in a plasma turbulence analysis.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05780" title="Abstract">arXiv:2312.05780</a> [<a href="/pdf/2312.05780" title="Download PDF">pdf</a>, <a href="/format/2312.05780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PULSAR: Graph based Positive Unlabeled Learning with Multi Stream  Adaptive Convolutions for Parkinson&#x27;s Disease Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+Z+U">Md. Zarif Ul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Saiful Islam</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+E">Ehsan Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+S">M Saifur Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Parkinson's disease (PD) is a neuro-degenerative disorder that affects
movement, speech, and coordination. Timely diagnosis and treatment can improve
the quality of life for PD patients. However, access to clinical diagnosis is
limited in low and middle income countries (LMICs). Therefore, development of
automated screening tools for PD can have a huge social impact, particularly in
the public health sector. In this paper, we present PULSAR, a novel method to
screen for PD from webcam-recorded videos of the finger-tapping task from the
Movement Disorder Society - Unified Parkinson's Disease Rating Scale
(MDS-UPDRS). PULSAR is trained and evaluated on data collected from 382
participants (183 self-reported as PD patients). We used an adaptive graph
convolutional neural network to dynamically learn the spatio temporal graph
edges specific to the finger-tapping task. We enhanced this idea with a multi
stream adaptive convolution model to learn features from different modalities
of data critical to detect PD, such as relative location of the finger joints,
velocity and acceleration of tapping. As the labels of the videos are
self-reported, there could be cases of undiagnosed PD in the non-PD labeled
samples. We leveraged the idea of Positive Unlabeled (PU) Learning that does
not need labeled negative data. Our experiments show clear benefit of modeling
the problem in this way. PULSAR achieved 80.95% accuracy in validation set and
a mean accuracy of 71.29% (2.49% standard deviation) in independent test,
despite being trained with limited amount of data. This is specially promising
as labeled data is scarce in health care sector. We hope PULSAR will make PD
screening more accessible to everyone. The proposed techniques could be
extended for assessment of other movement disorders, such as ataxia, and
Huntington's disease.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05783" title="Abstract">arXiv:2312.05783</a> [<a href="/pdf/2312.05783" title="Download PDF">pdf</a>, <a href="/format/2312.05783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCIR: Dynamic Consistency Intrinsic Reward for Multi-Agent Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kunyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+R">Runhao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 pages for main paper, 4 pages for supplementary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning optimal behavior policy for each agent in multi-agent systems is an
essential yet difficult problem. Despite fruitful progress in multi-agent
reinforcement learning, the challenge of addressing the dynamics of whether two
agents should exhibit consistent behaviors is still under-explored. In this
paper, we propose a new approach that enables agents to learn whether their
behaviors should be consistent with that of other agents by utilizing intrinsic
rewards to learn the optimal policy for each agent. We begin by defining
behavior consistency as the divergence in output actions between two agents
when provided with the same observation. Subsequently, we introduce dynamic
consistency intrinsic reward (DCIR) to stimulate agents to be aware of others'
behaviors and determine whether to be consistent with them. Lastly, we devise a
dynamic scale network (DSN) that provides learnable scale factors for the agent
at every time step to dynamically ascertain whether to award consistent
behavior and the magnitude of rewards. We evaluate DCIR in multiple
environments including Multi-agent Particle, Google Research Football and
StarCraft II Micromanagement, demonstrating its efficacy.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05784" title="Abstract">arXiv:2312.05784</a> [<a href="/pdf/2312.05784" title="Download PDF">pdf</a>, <a href="/format/2312.05784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-based Prediction and Planning Policy Network (GP3Net) for scalable  self-driving in dynamic environments using Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+J">Jayabrata Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Shivaraman%2C+V">Venkataramanan Shivaraman</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+S">Suresh Sundaram</a>, 
<a href="/search/cs?searchtype=author&query=Sujit%2C+P+B">P B Sujit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Recent advancements in motion planning for Autonomous Vehicles (AVs) show
great promise in using expert driver behaviors in non-stationary driving
environments. However, learning only through expert drivers needs more
generalizability to recover from domain shifts and near-failure scenarios due
to the dynamic behavior of traffic participants and weather conditions. A deep
Graph-based Prediction and Planning Policy Network (GP3Net) framework is
proposed for non-stationary environments that encodes the interactions between
traffic participants with contextual information and provides a decision for
safe maneuver for AV. A spatio-temporal graph models the interactions between
traffic participants for predicting the future trajectories of those
participants. The predicted trajectories are utilized to generate a future
occupancy map around the AV with uncertainties embedded to anticipate the
evolving non-stationary driving environments. Then the contextual information
and future occupancy maps are input to the policy network of the GP3Net
framework and trained using Proximal Policy Optimization (PPO) algorithm. The
proposed GP3Net performance is evaluated on standard CARLA benchmarking
scenarios with domain shifts of traffic patterns (urban, highway, and mixed).
The results show that the GP3Net outperforms previous state-of-the-art
imitation learning-based planning models for different towns. Further, in
unseen new weather conditions, GP3Net completes the desired route with fewer
traffic infractions. Finally, the results emphasize the advantage of including
the prediction module to enhance safety measures in non-stationary
environments.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05787" title="Abstract">arXiv:2312.05787</a> [<a href="/pdf/2312.05787" title="Download PDF">pdf</a>, <a href="/format/2312.05787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Sparse-Reward Goal-Conditioned Reinforcement Learning with a  High Replay Ratio and Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+T">Takuya Hiraoka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code: <a href="https://github.com/TakuyaHiraoka/Efficient-SRGC-RL-with-a-High-RR-and-Regularization">this https URL</a> Demo video: <a href="https://drive.google.com/file/d/1UHd7JVPCwFLNFhy1QcycQfwU_nll_yII/view?usp=drive_link">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement learning (RL) methods with a high replay ratio (RR) and
regularization have gained interest due to their superior sample efficiency.
However, these methods have mainly been developed for dense-reward tasks. In
this paper, we aim to extend these RL methods to sparse-reward goal-conditioned
tasks. We use Randomized Ensemble Double Q-learning (REDQ) (Chen et al., 2021),
an RL method with a high RR and regularization. To apply REDQ to sparse-reward
goal-conditioned tasks, we make the following modifications to it: (i) using
hindsight experience replay and (ii) bounding target Q-values. We evaluate REDQ
with these modifications on 12 sparse-reward goal-conditioned tasks of Robotics
(Plappert et al., 2018), and show that it achieves about $2 \times$ better
sample efficiency than previous state-of-the-art (SoTA) RL methods.
Furthermore, we reconsider the necessity of specific components of REDQ and
simplify it by removing unnecessary ones. The simplified REDQ with our
modifications achieves $\sim 8 \times$ better sample efficiency than the SoTA
methods in 4 Fetch tasks of Robotics.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05790" title="Abstract">arXiv:2312.05790</a> [<a href="/pdf/2312.05790" title="Download PDF">pdf</a>, <a href="/format/2312.05790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimPSI: A Simple Strategy to Preserve Spectral Information in Time  Series Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryu%2C+H">Hyun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sunjae Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H+S">Hee Suk Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+E">Eunseop Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Data augmentation is a crucial component in training neural networks to
overcome the limitation imposed by data size, and several techniques have been
studied for time series. Although these techniques are effective in certain
tasks, they have yet to be generalized to time series benchmarks. We find that
current data augmentation techniques ruin the core information contained within
the frequency domain. To address this issue, we propose a simple strategy to
preserve spectral information (SimPSI) in time series data augmentation. SimPSI
preserves the spectral information by mixing the original and augmented input
spectrum weighted by a preservation map, which indicates the importance score
of each frequency. Specifically, our experimental contributions are to build
three distinct preservation maps: magnitude spectrum, saliency map, and
spectrum-preservative map. We apply SimPSI to various time series data
augmentations and evaluate its effectiveness across a wide range of time series
benchmarks. Our experimental results support that SimPSI considerably enhances
the performance of time series data augmentations by preserving core spectral
information. The source code used in the paper is available at
https://github.com/Hyun-Ryu/simpsi.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05792" title="Abstract">arXiv:2312.05792</a> [<a href="/pdf/2312.05792" title="Download PDF">pdf</a>, <a href="/format/2312.05792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Take an Irregular Route: Enhance the Decoder of Time-Series Forecasting  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuning Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yangzhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongguang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE IoT; Open sources; Response letter provided
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the development of Internet of Things (IoT) systems, precise long-term
forecasting method is requisite for decision makers to evaluate current
statuses and formulate future policies. Currently, Transformer and MLP are two
paradigms for deep time-series forecasting and the former one is more
prevailing in virtue of its exquisite attention mechanism and encoder-decoder
architecture. However, data scientists seem to be more willing to dive into the
research of encoder, leaving decoder unconcerned. Some researchers even adopt
linear projections in lieu of the decoder to reduce the complexity. We argue
that both extracting the features of input sequence and seeking the relations
of input and prediction sequence, which are respective functions of encoder and
decoder, are of paramount significance. Motivated from the success of FPN in CV
field, we propose FPPformer to utilize bottom-up and top-down architectures
respectively in encoder and decoder to build the full and rational hierarchy.
The cutting-edge patch-wise attention is exploited and further developed with
the combination, whose format is also different in encoder and decoder, of
revamped element-wise attention in this work. Extensive experiments with six
state-of-the-art baselines on twelve benchmarks verify the promising
performances of FPPformer and the importance of elaborately devising decoder in
time-series forecasting Transformer. The source code is released in
https://github.com/OrigamiSL/FPPformer.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05795" title="Abstract">arXiv:2312.05795</a> [<a href="/pdf/2312.05795" title="Download PDF">pdf</a>, <a href="/format/2312.05795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Multimodal Model Compression via Efficient Pruning and  Distillation at AntGroup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiajia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chenyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The deployment of Large Multimodal Models (LMMs) within AntGroup has
significantly advanced multimodal tasks in payment, security, and advertising,
notably enhancing advertisement audition tasks in Alipay. However, the
deployment of such sizable models introduces challenges, particularly in
increased latency and carbon emissions, which are antithetical to the ideals of
Green AI. This paper introduces a novel multi-stage compression strategy for
our proprietary LLM, AntGMM. Our methodology pivots on three main aspects:
employing small training sample sizes, addressing multi-level redundancy
through multi-stage pruning, and introducing an advanced distillation loss
design. In our research, we constructed a dataset, the Multimodal Advertisement
Audition Dataset (MAAD), from real-world scenarios within Alipay, and conducted
experiments to validate the reliability of our proposed strategy. Furthermore,
the effectiveness of our strategy is evident in its operational success in
Alipay's real-world multimodal advertisement audition for three months from
September 2023. Notably, our approach achieved a substantial reduction in
latency, decreasing it from 700ms to 90ms, while maintaining online performance
with only a slight performance decrease. Moreover, our compressed model is
estimated to reduce electricity consumption by approximately 75 million kWh
annually compared to the direct deployment of AntGMM, demonstrating our
commitment to green AI initiatives. We will publicly release our code and the
MAAD dataset after some
reviews\footnote{https://github.com/MorinW/AntGMM$\_$Pruning}.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05797" title="Abstract">arXiv:2312.05797</a> [<a href="/pdf/2312.05797" title="Download PDF">pdf</a>, <a href="/format/2312.05797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality in Online Education: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Immadisetty%2C+P">Praneeta Immadisetty</a>, 
<a href="/search/cs?searchtype=author&query=Rajesh%2C+P">Pooja Rajesh</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+A+M">Anala M R</a>, 
<a href="/search/cs?searchtype=author&query=A%2C+S">Soumya A</a>, 
<a href="/search/cs?searchtype=author&query=Subramanya%2C+K+N">K. N. Subramanya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The commencement of the decade brought along with it a grave pandemic and in
response the movement of education forums predominantly into the online world.
With a surge in the usage of online video conferencing platforms and tools to
better gauge student understanding, there needs to be a mechanism to assess
whether instructors can grasp the extent to which students understand the
subject and their response to the educational stimuli. The current systems
consider only a single cue with a lack of focus in the educational domain.
Thus, there is a necessity for the measurement of an all-encompassing holistic
overview of the students' reaction to the subject matter. This paper highlights
the need for a multimodal approach to affect recognition and its deployment in
the online classroom while considering four cues, posture and gesture, facial,
eye tracking and verbal recognition. It compares the various machine learning
models available for each cue and provides the most suitable approach given the
available dataset and parameters of classroom footage. A multimodal approach
derived from weighted majority voting is proposed by combining the most fitting
models from this analysis of individual cues based on accuracy, ease of
procuring data corpus, sensitivity and any major drawbacks.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05798" title="Abstract">arXiv:2312.05798</a> [<a href="/pdf/2312.05798" title="Download PDF">pdf</a>, <a href="/format/2312.05798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation Learning for Controllable Person Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenju Xu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Chengjiang Long</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yongwei Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanghui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel framework named DRL-CPG to learn
disentangled latent representation for controllable person image generation,
which can produce realistic person images with desired poses and human
attributes (e.g., pose, head, upper clothes, and pants) provided by various
source persons. Unlike the existing works leveraging the semantic masks to
obtain the representation of each component, we propose to generate
disentangled latent code via a novel attribute encoder with transformers
trained in a manner of curriculum learning from a relatively easy step to a
gradually hard one. A random component mask-agnostic strategy is introduced to
randomly remove component masks from the person segmentation masks, which aims
at increasing the difficulty of training and promoting the transformer encoder
to recognize the underlying boundaries between each component. This enables the
model to transfer both the shape and texture of the components. Furthermore, we
propose a novel attribute decoder network to integrate multi-level attributes
(e.g., the structure feature and the attribute representation) with
well-designed Dual Adaptive Denormalization (DAD) residual blocks. Extensive
experiments strongly demonstrate that the proposed approach is able to transfer
both the texture and shape of different human parts and yield realistic
results. To our knowledge, we are the first to learn disentangled latent
representations with transformers for person image generation.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05799" title="Abstract">arXiv:2312.05799</a> [<a href="/pdf/2312.05799" title="Download PDF">pdf</a>, <a href="/format/2312.05799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGNet: Structure Guided Network via Gradient-Frequency Awareness for  Depth Map Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth super-resolution (DSR) aims to restore high-resolution (HR) depth from
low-resolution (LR) one, where RGB image is often used to promote this task.
Recent image guided DSR approaches mainly focus on spatial domain to rebuild
depth structure. However, since the structure of LR depth is usually blurry,
only considering spatial domain is not very sufficient to acquire satisfactory
results. In this paper, we propose structure guided network (SGNet), a method
that pays more attention to gradient and frequency domains, both of which have
the inherent ability to capture high-frequency structure. Specifically, we
first introduce the gradient calibration module (GCM), which employs the
accurate gradient prior of RGB to sharpen the LR depth structure. Then we
present the Frequency Awareness Module (FAM) that recursively conducts multiple
spectrum differencing blocks (SDB), each of which propagates the precise
high-frequency components of RGB into the LR depth. Extensive experimental
results on both real and synthetic datasets demonstrate the superiority of our
SGNet, reaching the state-of-the-art. Codes and pre-trained models are
available at https://github.com/yanzq95/SGNet.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05803" title="Abstract">arXiv:2312.05803</a> [<a href="/pdf/2312.05803" title="Download PDF">pdf</a>, <a href="/format/2312.05803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Selective Super-Resolution for Efficient Image  Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kasichainula%2C+K">Kishore Kasichainula</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+Y">Yaoxin Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baoxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jae-sun Seo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional super-resolution methods suffer from two drawbacks: substantial
computational cost in upscaling an entire large image, and the introduction of
extraneous or potentially detrimental information for downstream computer
vision tasks during the refinement of the background. To solve these issues, we
propose a novel transformer-based algorithm, Selective Super-Resolution (SSR),
which partitions images into non-overlapping tiles, selects tiles of interest
at various scales with a pyramid architecture, and exclusively reconstructs
these selected tiles with deep features. Experimental results on three datasets
demonstrate the efficiency and robust performance of our approach for
super-resolution. Compared to the state-of-the-art methods, the FID score is
reduced from 26.78 to 10.41 with 40% reduction in computation cost for the
BDD100K dataset. The source code is available at
https://github.com/destiny301/SSR.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05804" title="Abstract">arXiv:2312.05804</a> [<a href="/pdf/2312.05804" title="Download PDF">pdf</a>, <a href="/format/2312.05804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanCoser: Layered 3D Human Generation via Semantic-Aware Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Ruizhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The generation of 3D clothed humans has attracted increasing attention in
recent years. However, existing work cannot generate layered high-quality 3D
humans with consistent body structures. As a result, these methods are unable
to arbitrarily and separately change and edit the body and clothing of the
human. In this paper, we propose a text-driven layered 3D human generation
framework based on a novel physically-decoupled semantic-aware diffusion model.
To keep the generated clothing consistent with the target text, we propose a
semantic-confidence strategy for clothing that can eliminate the non-clothing
content generated by the model. To match the clothing with different body
shapes, we propose a SMPL-driven implicit field deformation network that
enables the free transfer and reuse of clothing. Besides, we introduce uniform
shape priors based on the SMPL model for body and clothing, respectively, which
generates more diverse 3D content without being constrained by specific
templates. The experimental results demonstrate that the proposed method not
only generates 3D humans with consistent body structures but also allows free
editing in a layered manner. The source code will be made public.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05805" title="Abstract">arXiv:2312.05805</a> [<a href="/pdf/2312.05805" title="Download PDF">pdf</a>, <a href="/format/2312.05805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Global, Socio-Economic, and Culturally Aware Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yohe%2C+K+A">Kelley Ann Yohe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Recommender systems have gained increasing attention to personalise consumer
preferences. While these systems have primarily focused on applications such as
advertisement recommendations (e.g., Google), personalized suggestions (e.g.,
Netflix and Spotify), and retail selection (e.g., Amazon), there is potential
for these systems to benefit from a more global, socio-economic, and culturally
aware approach, particularly as companies seek to expand into diverse markets.
This paper aims to investigate the potential of a recommender system that
considers cultural identity and socio-economic factors. We review the most
recent developments in recommender systems and explore the impact of cultural
identity and socio-economic factors on consumer preferences. We then propose an
ontology and approach for incorporating these factors into recommender systems.
To illustrate the potential of our approach, we present a scenario in consumer
subscription plan selection within the entertainment industry. We argue that
existing recommender systems have limited ability to precisely understand user
preferences due to a lack of awareness of socio-economic factors and cultural
identity. They also fail to update recommendations in response to changing
socio-economic conditions. We explore various machine learning models and
develop a final artificial neural network model (ANN) that addresses this gap.
We evaluate the effectiveness of socio-economic and culturally aware
recommender systems across four dimensions: Precision, Accuracy, F1, and
Recall. We find that a highly tuned ANN model incorporating domain-specific
data, select cultural indices and relevant socio-economic factors predicts user
preference in subscriptions with an accuracy of 95%, a precision of 94%, a F1
Score of 92\%, and a Recall of 90\%.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05807" title="Abstract">arXiv:2312.05807</a> [<a href="/pdf/2312.05807" title="Download PDF">pdf</a>, <a href="/format/2312.05807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Empowered by Generative Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Jingyi Chai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated learning (FL) enables leveraging distributed private data for model
training in a privacy-preserving way. However, data heterogeneity significantly
limits the performance of current FL methods. In this paper, we propose a novel
FL framework termed FedGC, designed to mitigate data heterogeneity issues by
diversifying private data with generative content. FedGC is a
simple-to-implement framework as it only introduces a one-shot step of data
generation. In data generation, we summarize three crucial and worth-exploring
aspects (budget allocation, prompt design, and generation guidance) and propose
three solution candidates for each aspect. Specifically, to achieve a better
trade-off between data diversity and fidelity for generation guidance, we
propose to generate data based on the guidance of prompts and real data
simultaneously. The generated data is then merged with private data to
facilitate local model training. Such generative data increases the diversity
of private data to prevent each client from fitting the potentially biased
private data, alleviating the issue of data heterogeneity. We conduct a
systematic empirical study on FedGC, covering diverse baselines, datasets,
scenarios, and modalities. Interesting findings include (1) FedGC consistently
and significantly enhances the performance of FL methods, even when notable
disparities exist between generative and private data; (2) FedGC achieves both
better performance and privacy-preservation. We wish this work can inspire
future works to further explore the potential of enhancing FL with generative
content.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05814" title="Abstract">arXiv:2312.05814</a> [<a href="/pdf/2312.05814" title="Download PDF">pdf</a>, <a href="/format/2312.05814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Speech Embeddings for Speech Synthesis Based on Deep Generative  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seo-Hyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Young-Eun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Soowon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+B">Byung-Kwan Ko</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jun-Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Brain-to-speech technology represents a fusion of interdisciplinary
applications encompassing fields of artificial intelligence, brain-computer
interfaces, and speech synthesis. Neural representation learning based
intention decoding and speech synthesis directly connects the neural activity
to the means of human linguistic communication, which may greatly enhance the
naturalness of communication. With the current discoveries on representation
learning and the development of the speech synthesis technologies, direct
translation of brain signals into speech has shown great promise. Especially,
the processed input features and neural speech embeddings which are given to
the neural network play a significant role in the overall performance when
using deep generative models for speech generation from brain signals. In this
paper, we introduce the current brain-to-speech technology with the possibility
of speech synthesis from brain signals, which may ultimately facilitate
innovation in non-verbal communication. Also, we perform comprehensive analysis
on the neural features and neural speech embeddings underlying the
neurophysiological activation while performing speech, which may play a
significant role in the speech synthesis works.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05815" title="Abstract">arXiv:2312.05815</a> [<a href="/pdf/2312.05815" title="Download PDF">pdf</a>, <a href="/format/2312.05815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voice Activity Detection (VAD) in Noisy Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ball%2C+J">Joshua Ball</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the realm of digital audio processing, Voice Activity Detection (VAD)
plays a pivotal role in distinguishing speech from non-speech elements, a task
that becomes increasingly complex in noisy environments. This paper details the
development and implementation of a VAD system, specifically engineered to
maintain high accuracy in the presence of various ambient noises. We introduce
a novel algorithm enhanced with a specially designed filtering technique,
effectively isolating speech even amidst diverse background sounds. Our
comprehensive testing and validation demonstrate the system's robustness,
highlighting its capability to discern speech from noise with remarkable
precision. The exploration delves into: (1) the core principles underpinning
VAD and its crucial role in modern audio processing; (2) the methodologies we
employed to filter ambient noise; and (3) a presentation of evidence affirming
our system's superior performance in noisy conditions.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05818" title="Abstract">arXiv:2312.05818</a> [<a href="/pdf/2312.05818" title="Download PDF">pdf</a>, <a href="/format/2312.05818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICTSurF: Implicit Continuous-Time Survival Functions with Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puttanawarut%2C+C">Chanon Puttanawarut</a>, 
<a href="/search/cs?searchtype=author&query=Looareesuwan%2C+P">Panu Looareesuwan</a>, 
<a href="/search/cs?searchtype=author&query=Wabina%2C+R+S">Romen Samuel Wabina</a>, 
<a href="/search/cs?searchtype=author&query=Saowaprut%2C+P">Prut Saowaprut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Survival analysis is a widely known method for predicting the likelihood of
an event over time. The challenge of dealing with censored samples still
remains. Traditional methods, such as the Cox Proportional Hazards (CPH) model,
hinge on the limitations due to the strong assumptions of proportional hazards
and the predetermined relationships between covariates. The rise of models
based on deep neural networks (DNNs) has demonstrated enhanced effectiveness in
survival analysis. This research introduces the Implicit Continuous-Time
Survival Function (ICTSurF), built on a continuous-time survival model, and
constructs survival distribution through implicit representation. As a result,
our method is capable of accepting inputs in continuous-time space and
producing survival probabilities in continuous-time space, independent of
neural network architecture. Comparative assessments with existing methods
underscore the high competitiveness of our proposed approach. Our
implementation of ICTSurF is available at https://github.com/44REAM/ICTSurF.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05821" title="Abstract">arXiv:2312.05821</a> [<a href="/pdf/2312.05821" title="Download PDF">pdf</a>, <a href="/format/2312.05821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASVD: Activation-aware Singular Value Decomposition for Compressing  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yue Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangyu Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper explores a new post-hoc training-free compression paradigm for
compressing Large Language Models (LLMs) to facilitate their wider adoption in
various computing environments. We delve into the challenges of LLM
compression, notably their dependency on extensive training data and
computational resources. We propose a training-free approach dubbed
Activation-aware Singular Value Decomposition (ASVD) to address these
limitations. ASVD effectively manages activation outliers by adjusting the
weight matrix based on the activation distribution, improving decomposition
accuracy and efficiency. Our method also addresses the varying sensitivity of
different LLM layers to decomposition, with an iterative calibration process
for optimal layer-specific decomposition. Experiments demonstrate that ASVD can
compress network by 10%-20% without losing reasoning capacities. Additionally,
it can be seamlessly integrated with other LLM compression paradigms,
showcasing its flexible compatibility. Code and compressed models are available
at https://github.com/hahnyuan/ASVD4LLM.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05822" title="Abstract">arXiv:2312.05822</a> [<a href="/pdf/2312.05822" title="Download PDF">pdf</a>, <a href="/format/2312.05822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Open-ended Embodied Tasks Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+W">William Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xufang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yifei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C">Charles Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Empowering embodied agents, such as robots, with Artificial Intelligence (AI)
has become increasingly important in recent years. A major challenge is task
open-endedness. In practice, robots often need to perform tasks with novel
goals that are multifaceted, dynamic, lack a definitive "end-state", and were
not encountered during training. To tackle this problem, this paper introduces
\textit{Diffusion for Open-ended Goals} (DOG), a novel framework designed to
enable embodied AI to plan and act flexibly and dynamically for open-ended task
goals. DOG synergizes the generative prowess of diffusion models with
state-of-the-art, training-free guidance techniques to adaptively perform
online planning and control. Our evaluations demonstrate that DOG can handle
various kinds of novel task goals not seen during training, in both maze
navigation and robot control problems. Our work sheds light on enhancing
embodied AI's adaptability and competency in tackling open-ended goals.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05826" title="Abstract">arXiv:2312.05826</a> [<a href="/pdf/2312.05826" title="Download PDF">pdf</a>, <a href="/format/2312.05826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R2Human: Real-Time 3D Human Appearance Rendering from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuanwang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing 3D human appearance from a single image is crucial for
achieving holographic communication and immersive social experiences. However,
this remains a challenge for existing methods, which typically rely on
multi-camera setups or are limited to offline operations. In this paper, we
propose R$^2$Human, the first approach for real-time inference and rendering of
photorealistic 3D human appearance from a single image. The core of our
approach is to combine the strengths of implicit texture fields and explicit
neural rendering with our novel representation, namely Z-map. Based on this, we
present an end-to-end network that performs high-fidelity color reconstruction
of visible areas and provides reliable color inference for occluded regions. To
further enhance the 3D perception ability of our network, we leverage the
Fourier occupancy field to reconstruct a detailed 3D geometry, which serves as
a prior for the texture field generation and provides a sampling surface in the
rendering stage. Experiments show that our end-to-end method achieves
state-of-the-art performance on both synthetic data and challenging real-world
images and even outperforms many offline methods. The project page is available
for research purposes at <a href="http://cic.tju.edu.cn/faculty/likun/projects/R2Human.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05828" title="Abstract">arXiv:2312.05828</a> [<a href="/pdf/2312.05828" title="Download PDF">pdf</a>, <a href="/format/2312.05828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Multitask Learning for Efficient Neural Representation of Motor  Imagery and Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hye-Bin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Kang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the quest for efficient neural network models for neural data
interpretation and user intent classification in brain-computer interfaces
(BCIs), learning meaningful sparse representations of the underlying neural
subspaces is crucial. The present study introduces a sparse multitask learning
framework for motor imagery (MI) and motor execution (ME) tasks, inspired by
the natural partitioning of associated neural subspaces observed in the human
brain. Given a dual-task CNN model for MI-ME classification, we apply a
saliency-based sparsification approach to prune superfluous connections and
reinforce those that show high importance in both tasks. Through our approach,
we seek to elucidate the distinct and common neural ensembles associated with
each task, employing principled sparsification techniques to eliminate
redundant connections and boost the fidelity of neural signal decoding. Our
results indicate that this tailored sparsity can mitigate the overfitting
problem and improve the test performance with small amount of data, suggesting
a viable path forward for computationally efficient and robust BCI systems.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05829" title="Abstract">arXiv:2312.05829</a> [<a href="/pdf/2312.05829" title="Download PDF">pdf</a>, <a href="/format/2312.05829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EM Based p-norm-like Constraint RLS Algorithm for Sparse System  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kung Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, journal manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, the recursive least squares (RLS) algorithm is considered in
the sparse system identification setting. The cost function of RLS algorithm is
regularized by a $p$-norm-like ($0 \leq p \leq 1$) constraint of the estimated
system parameters. In order to minimize the regularized cost function, we
transform it into a penalized maximum likelihood (ML) problem, which is solved
by the expectation-maximization (EM) algorithm. With the introduction of a
thresholding operator, the update equation of the tap-weight vector is derived.
We also exploit the underlying sparsity to implement the proposed algorithm in
a low computational complexity fashion. Numerical simulations demonstrate the
superiority of the new algorithm over conventional sparse RLS algorithms, as
well as regular RLS algorithm.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05830" title="Abstract">arXiv:2312.05830</a> [<a href="/pdf/2312.05830" title="Download PDF">pdf</a>, <a href="/format/2312.05830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Decoupled Spatio-Temporal Framework for Skeleton-based Action  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shanghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Effectively modeling discriminative spatio-temporal information is essential
for segmenting activities in long action sequences. However, we observe that
existing methods are limited in weak spatio-temporal modeling capability due to
two forms of decoupled modeling: (i) cascaded interaction couples spatial and
temporal modeling, which over-smooths motion modeling over the long sequence,
and (ii) joint-shared temporal modeling adopts shared weights to model each
joint, ignoring the distinct motion patterns of different joints. We propose a
Decoupled Spatio-Temporal Framework (DeST) to address the above issues.
Firstly, we decouple the cascaded spatio-temporal interaction to avoid stacking
multiple spatio-temporal blocks, while achieving sufficient spatio-temporal
interaction. Specifically, DeST performs once unified spatial modeling and
divides the spatial features into different groups of subfeatures, which then
adaptively interact with temporal features from different layers. Since the
different sub-features contain distinct spatial semantics, the model could
learn the optimal interaction pattern at each layer. Meanwhile, inspired by the
fact that different joints move at different speeds, we propose joint-decoupled
temporal modeling, which employs independent trainable weights to capture
distinctive temporal features of each joint. On four large-scale benchmarks of
different scenes, DeST significantly outperforms current state-of-the-art
methods with less computational complexity.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05831" title="Abstract">arXiv:2312.05831</a> [<a href="/pdf/2312.05831" title="Download PDF">pdf</a>, <a href="/format/2312.05831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Aware Multifidelity Bayesian Optimization: a Generalized  Formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Fiore%2C+F">Francesco Di Fiore</a>, 
<a href="/search/cs?searchtype=author&query=Mainini%2C+L">Laura Mainini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The adoption of high-fidelity models for many-query optimization problems is
majorly limited by the significant computational cost required for their
evaluation at every query. Multifidelity Bayesian methods (MFBO) allow to
include costly high-fidelity responses for a sub-selection of queries only, and
use fast lower-fidelity models to accelerate the optimization process.
State-of-the-art methods rely on a purely data-driven search and do not include
explicit information about the physical context. This paper acknowledges that
prior knowledge about the physical domains of engineering problems can be
leveraged to accelerate these data-driven searches, and proposes a generalized
formulation for MFBO to embed a form of domain awareness during the
optimization procedure. In particular, we formalize a bias as a multifidelity
acquisition function that captures the physical structure of the domain. This
permits to partially alleviate the data-driven search from learning the domain
properties on-the-fly, and sensitively enhances the management of multiple
sources of information. The method allows to efficiently include high-fidelity
simulations to guide the optimization search while containing the overall
computational expense. Our physics-aware multifidelity Bayesian optimization is
presented and illustrated for two classes of optimization problems frequently
met in science and engineering, namely design optimization and health
monitoring problems.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05832" title="Abstract">arXiv:2312.05832</a> [<a href="/pdf/2312.05832" title="Download PDF">pdf</a>, <a href="/format/2312.05832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-wise Dynamic Distillation for MLP-like Efficient Visual Fault  Detection of Freight Trains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Huilin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingying Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">An Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongliang Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Despite the successful application of convolutional neural networks (CNNs) in
object detection tasks, their efficiency in detecting faults from freight train
images remains inadequate for implementation in real-world engineering
scenarios. Existing modeling shortcomings of spatial invariance and pooling
layers in conventional CNNs often ignore the neglect of crucial global
information, resulting in error localization for fault objection tasks of
freight trains. To solve these problems, we design a spatial-wise dynamic
distillation framework based on multi-layer perceptron (MLP) for visual fault
detection of freight trains. We initially present the axial shift strategy,
which allows the MLP-like architecture to overcome the challenge of spatial
invariance and effectively incorporate both local and global cues. We propose a
dynamic distillation method without a pre-training teacher, including a dynamic
teacher mechanism that can effectively eliminate the semantic discrepancy with
the student model. Such an approach mines more abundant details from
lower-level feature appearances and higher-level label semantics as the extra
supervision signal, which utilizes efficient instance embedding to model the
global spatial and semantic information. In addition, the proposed dynamic
teacher can jointly train with students to further enhance the distillation
efficiency. Extensive experiments executed on six typical fault datasets reveal
that our approach outperforms the current state-of-the-art detectors and
achieves the highest accuracy with real-time detection at a lower computational
cost. The source code will be available at
\url{https://github.com/MVME-HBUT/SDD-FTI-FDet}.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05833" title="Abstract">arXiv:2312.05833</a> [<a href="/pdf/2312.05833" title="Download PDF">pdf</a>, <a href="/ps/2312.05833" title="Download PostScript">ps</a>, <a href="/format/2312.05833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Robust Covariance Control for Uncertain Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pilipovsky%2C+J">Joshua Pilipovsky</a>, 
<a href="/search/eess?searchtype=author&query=Tsiotras%2C+P">Panagiotis Tsiotras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to L4DC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The theory of covariance control and covariance steering (CS) deals with
controlling the dispersion of trajectories of a dynamical system, under the
implicit assumption that accurate prior knowledge of the system being
controlled is available. In this work, we consider the problem of steering the
distribution of a discrete-time, linear system subject to exogenous
disturbances under an unknown dynamics model. Leveraging concepts from
behavioral systems theory, the trajectories of this unknown, noisy system may
be (approximately) represented using system data collected through
experimentation. Using this fact, we formulate a direct data-driven covariance
control problem using input-state data. We then propose a maximum likelihood
uncertainty quantification method to estimate and bound the noise realizations
in the data collection process. Lastly, we utilize robust convex optimization
techniques to solve the resulting norm-bounded uncertain convex program. We
illustrate the proposed end-to-end data-driven CS algorithm on a double
integrator example and showcase the efficacy and accuracy of the proposed
method compared to that of model-based methods
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05834" title="Abstract">arXiv:2312.05834</a> [<a href="/pdf/2312.05834" title="Download PDF">pdf</a>, <a href="/format/2312.05834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence-based Interpretable Open-domain Fact-checking with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+B">Bowei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Aw%2C+A+T">Ai Ti Aw</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Universal fact-checking systems for real-world claims face significant
challenges in gathering valid and sufficient real-time evidence and making
reasoned decisions. In this work, we introduce the Open-domain Explainable
Fact-checking (OE-Fact) system for claim-checking in real-world scenarios. The
OE-Fact system can leverage the powerful understanding and reasoning
capabilities of large language models (LLMs) to validate claims and generate
causal explanations for fact-checking decisions. To adapt the traditional
three-module fact-checking framework to the open domain setting, we first
retrieve claim-related information as relevant evidence from open websites.
After that, we retain the evidence relevant to the claim through LLM and
similarity calculation for subsequent verification. We evaluate the performance
of our adapted three-module OE-Fact system on the Fact Extraction and
Verification (FEVER) dataset. Experimental results show that our OE-Fact system
outperforms general fact-checking baseline systems in both closed- and
open-domain scenarios, ensuring stable and accurate verdicts while providing
concise and convincing real-time explanations for fact-checking decisions.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05836" title="Abstract">arXiv:2312.05836</a> [<a href="/pdf/2312.05836" title="Download PDF">pdf</a>, <a href="/format/2312.05836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault tree reliability analysis via squarefree polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopuha%C3%A4-Zwakenberg%2C+M">Milan Lopuha&#xe4;-Zwakenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at MODELSWARD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Fault tree (FT) analysis is a prominent risk assessment method in industrial
systems. Unreliability is one of the key safety metrics in quantitative FT
analysis. Existing algorithms for unreliability analysis are based on binary
decision diagrams, for which it is hard to give time complexity guarantees
beyond a worst-case exponential bound. In this paper, we present a novel method
to calculate FT unreliability based on algebras of squarefree polynomials and
prove its validity. We furthermore prove that time complexity is low when the
number of multiparent nodes is limited. Experiments show that our method is
competitive with the state-of-the-art and outperforms it for FTs with few
multiparent nodes.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05840" title="Abstract">arXiv:2312.05840</a> [<a href="/pdf/2312.05840" title="Download PDF">pdf</a>, <a href="/format/2312.05840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Data Analysis for Neural Network Analysis: A Comprehensive  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ballester%2C+R">Rub&#xe9;n Ballester</a>, 
<a href="/search/cs?searchtype=author&query=Casacuberta%2C+C">Carles Casacuberta</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">This survey provides a comprehensive exploration of applications of
Topological Data Analysis (TDA) within neural network analysis. Using TDA tools
such as persistent homology and Mapper, we delve into the intricate structures
and behaviors of neural networks and their datasets. We discuss different
strategies to obtain topological information from data and neural networks by
means of TDA. Additionally, we review how topological information can be
leveraged to analyze properties of neural networks, such as their
generalization capacity or expressivity. We explore practical implications of
deep learning, specifically focusing on areas like adversarial detection and
model selection. Our survey organizes the examined works into four broad
domains: 1. Characterization of neural network architectures; 2. Analysis of
decision regions and boundaries; 3. Study of internal representations,
activations, and parameters; 4. Exploration of training dynamics and loss
functions. Within each category, we discuss several articles, offering
background information to aid in understanding the various methodologies. We
conclude with a synthesis of key insights gained from our study, accompanied by
a discussion of challenges and potential advancements in the field.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05842" title="Abstract">arXiv:2312.05842</a> [<a href="/pdf/2312.05842" title="Download PDF">pdf</a>, <a href="/format/2312.05842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Enhancement of Large and Small Language Models with Cross-Silo  Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yongheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Ziqing Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Ju Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaoxue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">While large language models (LLMs) are empowered with broad knowledge, their
task-specific performance is often suboptimal. It necessitates fine-tuning LLMs
with task-specific data, but such data may be inaccessible due to privacy
concerns. In this paper, we propose a novel approach to enhance LLMs with
smaller language models (SLMs) that are trained on clients using their private
task-specific data. To enable mutual enhancement between LLMs and SLMs, we
propose CrossLM, where the SLMs promote the LLM to generate task-specific
high-quality data, and both the LLM and SLMs are enhanced with the generated
data. We evaluate CrossLM using publicly accessible language models across a
range of benchmark tasks. The results demonstrate that CrossLM significantly
enhances the task-specific performance of SLMs on clients and the LLM on the
cloud server simultaneously while preserving the LLM's generalization
capability.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05848" title="Abstract">arXiv:2312.05848</a> [<a href="/pdf/2312.05848" title="Download PDF">pdf</a>, <a href="/ps/2312.05848" title="Download PostScript">ps</a>, <a href="/format/2312.05848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-rays grouping scheme and novel coding architecture for  computational time reduction of graph-based Light Field coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gia%2C+B+N">Bach Nguyen Gia</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C+M">Chanh Minh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Duc%2C+T+N">Tho Nguyen Duc</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+T+P">Tan Phan Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Kamioka%2C+E">Eiji Kamioka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Graph-based Light Field coding using the concept of super-rays is powerful to
exploit signal redundancy along irregular shapes and achieves good energy
compaction, compared to rectangular block -based approaches. However, its main
limitation lies in the high time complexity for eigen-decomposition of each
super-ray local graph, a high number of which can be found in a Light Field
when segmented into super-rays. This paper examines a grouping scheme for
super-rays in order to reduce the number of eigen-decomposition times, and
proposes a novel coding architecture to handle the signal residual data arising
for each super-ray group, as a tradeoff to achieve lower computational time.
Experimental results have shown to reduce a considerable amount of decoding
time for Light Field scenes, despite having a slight increase in the coding
bitrates when compared with the original non-grouping super-ray -based
approach. The proposal also remains to have competitive performance in Rate
Distortion in comparison to HEVC-based and JPEG Pleno -based methods.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05849" title="Abstract">arXiv:2312.05849</a> [<a href="/pdf/2312.05849" title="Download PDF">pdf</a>, <a href="/format/2312.05849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoe%2C+J+T">Jiun Tian Hoe</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yap-Peng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weipeng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://jiuntian.github.io/interactdiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
<p class="mathjax">Large-scale text-to-image (T2I) diffusion models have showcased incredible
capabilities in generating coherent images based on textual descriptions,
enabling vast applications in content generation. While recent advancements
have introduced control over factors such as object localization, posture, and
image contours, a crucial gap remains in our ability to control the
interactions between objects in the generated content. Well-controlling
interactions in generated images could yield meaningful applications, such as
creating realistic scenes with interacting characters. In this work, we study
the problems of conditioning T2I diffusion models with Human-Object Interaction
(HOI) information, consisting of a triplet label (person, action, object) and
corresponding bounding boxes. We propose a pluggable interaction control model,
called InteractDiffusion that extends existing pre-trained T2I diffusion models
to enable them being better conditioned on interactions. Specifically, we
tokenize the HOI information and learn their relationships via interaction
embeddings. A conditioning self-attention layer is trained to map HOI tokens to
visual tokens, thereby conditioning the visual tokens better in existing T2I
diffusion models. Our model attains the ability to control the interaction and
location on existing T2I diffusion models, which outperforms existing baselines
by a large margin in HOI detection score, as well as fidelity in FID and KID.
Project page: https://jiuntian.github.io/interactdiffusion.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05851" title="Abstract">arXiv:2312.05851</a> [<a href="/pdf/2312.05851" title="Download PDF">pdf</a>, <a href="/format/2312.05851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Copula modeling and uncertainty propagation in field-scale simulation of  CO$_2$ fault leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pettersson%2C+P">Per Pettersson</a>, 
<a href="/search/math?searchtype=author&query=Keilegavlen%2C+E">Eirik Keilegavlen</a>, 
<a href="/search/math?searchtype=author&query=Sandve%2C+T+H">Tor Harald Sandve</a>, 
<a href="/search/math?searchtype=author&query=Gasda%2C+S">Sarah Gasda</a>, 
<a href="/search/math?searchtype=author&query=Krumscheid%2C+S">Sebastian Krumscheid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Subsurface storage of CO$_2$ is an important means to mitigate climate
change, and to investigate the fate of CO$_2$ over several decades in vast
reservoirs, numerical simulation based on realistic models is essential. Faults
and other complex geological structures introduce modeling challenges as their
effects on storage operations are uncertain due to limited data. In this work,
we present a computational framework for forward propagation of uncertainty,
including stochastic upscaling and copula representation of flow functions for
a CO$_2$ storage site using the Vette fault zone in the Smeaheia formation in
the North Sea as a test case. The upscaling method leads to a reduction of the
number of stochastic dimensions and the cost of evaluating the reservoir model.
A viable model that represents the upscaled data needs to capture dependencies
between variables, and allow sampling. Copulas provide representation of
dependent multidimensional random variables and a good fit to data, allow fast
sampling, and coupling to the forward propagation method via independent
uniform random variables. The non-stationary correlation within some of the
upscaled flow function are accurately captured by a data-driven transformation
model. The uncertainty in upscaled flow functions and other parameters are
propagated to uncertain leakage estimates using numerical reservoir simulation
of a two-phase system. The expectations of leakage are estimated by an adaptive
stratified sampling technique, where samples are sequentially concentrated to
regions of the parameter space to greedily maximize variance reduction. We
demonstrate cost reduction compared to standard Monte Carlo of one or two
orders of magnitude for simpler test cases with only fault and reservoir layer
permeabilities assumed uncertain, and factors 2--8 cost reduction for
stochastic multi-phase flow properties and more complex stochastic models.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05852" title="Abstract">arXiv:2312.05852</a> [<a href="/pdf/2312.05852" title="Download PDF">pdf</a>, <a href="/format/2312.05852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Estimation of DoS Duration and Frequency for Security Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jianquan Lu</a>, 
<a href="/search/eess?searchtype=author&query=Ho%2C+D+W+C">Daniel W. C. Ho</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lulu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we develop a new denial-of-service (DoS) estimator, enabling
defenders to identify duration and frequency parameters of any DoS attacker,
except for three edge cases, exclusively using real-time data. The key
advantage of the estimator lies in its capability to facilitate security
control in a wide range of practical scenarios, even when the attacker's
information is previously unknown. We demonstrate the advantage and application
of our new estimator in the context of two classical control scenarios, namely
consensus of multi-agent systems and impulsive stabilization of nonlinear
systems, for illustration.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05854" title="Abstract">arXiv:2312.05854</a> [<a href="/pdf/2312.05854" title="Download PDF">pdf</a>, <a href="/format/2312.05854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite Survival Analysis: Learning with Auxiliary Aggregated  Baselines and Survival Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomou%2C+C">Chris Solomou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Survival Analysis (SA) constitutes the default method for time-to-event
modeling due to its ability to estimate event probabilities of sparsely
occurring events over time. In this work, we show how to improve the training
and inference of SA models by decoupling their full expression into (1) an
aggregated baseline hazard, which captures the overall behavior of a given
population, and (2) independently distributed survival scores, which model
idiosyncratic probabilistic dynamics of its given members, in a fully
parametric setting. The proposed inference method is shown to dynamically
handle right-censored observation horizons, and to achieve competitive
performance when compared to other state-of-the-art methods in a variety of
real-world datasets, including computationally inefficient Deep Learning-based
SA methods and models that require MCMC for inference. Nevertheless, our method
achieves robust results from the outset, while not being subjected to
fine-tuning or hyperparameter optimization.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05855" title="Abstract">arXiv:2312.05855</a> [<a href="/pdf/2312.05855" title="Download PDF">pdf</a>, <a href="/format/2312.05855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeVRF: Neural Video-based Radiance Fields for Long-duration Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adopting Neural Radiance Fields (NeRF) to long-duration dynamic sequences has
been challenging. Existing methods struggle to balance between quality and
storage size and encounter difficulties with complex scene changes such as
topological changes and large motions. To tackle these issues, we propose a
novel neural video-based radiance fields (NeVRF) representation. NeVRF marries
neural radiance field with image-based rendering to support photo-realistic
novel view synthesis on long-duration dynamic inward-looking scenes. We
introduce a novel multi-view radiance blending approach to predict radiance
directly from multi-view videos. By incorporating continual learning
techniques, NeVRF can efficiently reconstruct frames from sequential data
without revisiting previous frames, enabling long-duration free-viewpoint
video. Furthermore, with a tailored compression approach, NeVRF can compactly
represent dynamic scenes, making dynamic radiance fields more practical in
real-world scenarios. Our extensive experiments demonstrate the effectiveness
of NeVRF in enabling long-duration sequence rendering, sequential data
reconstruction, and compact data storage.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05856" title="Abstract">arXiv:2312.05856</a> [<a href="/pdf/2312.05856" title="Download PDF">pdf</a>, <a href="/format/2312.05856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization  Inversion for Zero-Shot Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Maomao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+D">Dongxu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhihui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, Project page: <a href="https://stem-inv.github.io/page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a video inversion approach for zero-shot video editing,
which aims to model the input video with low-rank representation during the
inversion process. The existing video editing methods usually apply the typical
2D DDIM inversion or na\"ive spatial-temporal DDIM inversion before editing,
which leverages time-varying representation for each frame to derive noisy
latent. Unlike most existing approaches, we propose a Spatial-Temporal
Expectation-Maximization (STEM) inversion, which formulates the dense video
feature under an expectation-maximization manner and iteratively estimates a
more compact basis set to represent the whole video. Each frame applies the
fixed and global representation for inversion, which is more friendly for
temporal consistency during reconstruction and editing. Extensive qualitative
and quantitative experiments demonstrate that our STEM inversion can achieve
consistent improvement on two state-of-the-art video editing methods.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05864" title="Abstract">arXiv:2312.05864</a> [<a href="/pdf/2312.05864" title="Download PDF">pdf</a>, <a href="/format/2312.05864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Concept Representations in Neural Networks with Self-Organizing  Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=d%27Aquin%2C+M">Mathieu d&#x27;Aquin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in proceedings of K-CAP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In sufficiently complex tasks, it is expected that as a side effect of
learning to solve a problem, a neural network will learn relevant abstractions
of the representation of that problem. This has been confirmed in particular in
machine vision where a number of works showed that correlations could be found
between the activations of specific units (neurons) in a neural network and the
visual concepts (textures, colors, objects) present in the image. Here, we
explore the use of self-organizing maps as a way to both visually and
computationally inspect how activation vectors of whole layers of neural
networks correspond to neural representations of abstract concepts such as
`female person' or `realist painter'. We experiment with multiple measures
applied to those maps to assess the level of representation of a concept in a
network's layer. We show that, among the measures tested, the relative entropy
of the activation map for a concept compared to the map for the whole data is a
suitable candidate and can be used as part of a methodology to identify and
locate the neural representation of a concept, visualize it, and understand its
importance in solving the prediction task at hand.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05866" title="Abstract">arXiv:2312.05866</a> [<a href="/pdf/2312.05866" title="Download PDF">pdf</a>, <a href="/format/2312.05866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaBIIC: Taxonomy Building through Iterative and Interactive Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=d%27Aquin%2C+M">Mathieu d&#x27;Aquin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in proceedings of FOIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Building taxonomies is often a significant part of building an ontology, and
many attempts have been made to automate the creation of such taxonomies from
relevant data. The idea in such approaches is either that relevant definitions
of the intension of concepts can be extracted as patterns in the data (e.g. in
formal concept analysis) or that their extension can be built from grouping
data objects based on similarity (clustering). In both cases, the process leads
to an automatically constructed structure, which can either be too coarse and
lacking in definition, or too fined-grained and detailed, therefore requiring
to be refined into the desired taxonomy. In this paper, we explore a method
that takes inspiration from both approaches in an iterative and interactive
process, so that refinement and definition of the concepts in the taxonomy
occur at the time of identifying those concepts in the data. We show that this
method is applicable on a variety of data sources and leads to taxonomies that
can be more directly integrated into ontologies.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05869" title="Abstract">arXiv:2312.05869</a> [<a href="/pdf/2312.05869" title="Download PDF">pdf</a>, <a href="/format/2312.05869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Internet Computer Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albarello%2C+M">Massimo Albarello</a>, 
<a href="/search/cs?searchtype=author&query=Sliwinski%2C+J">Jakub Sliwinski</a>, 
<a href="/search/cs?searchtype=author&query=Vonlanthen%2C+Y">Yann Vonlanthen</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper presents the first rotating leader state machine replication (SMR)
protocol that allows transactions to be confirmed in just a single round-trip
time in the Byzantine fault tolerance (BFT) setting. Based on minimal
alterations to the Internet Computer Consensus (ICC) protocol and with
negligible communication overhead, we introduce a novel dual mode mechanism
that enables optimal block finalization latency in the fast path. Crucially,
the modes of operation are integrated, such that even if the fast path is not
effective, no penalties are incurred. Moreover, our algorithm maintains the
core attributes of the original ICC protocol, including optimistic
responsiveness and rotating leaders without the necessity for a view-change
protocol.
<br />We prove the correctness of our Fast Internet Computer Consensus (FICC)
protocol and provide an open-source implementation of it. Both the FICC and
original ICC protocol are compared in a globally distributed wide-area network.
Our evaluation reveals that the FICC protocol achieves reduced latency compared
to the ICC protocol, without requiring additional security assumptions.
Furthermore, by increasing the number of replicas to $n = 5f + 1$, we exhibit
that latency improvements close to the theoretical maximum of 33% are
attainable. We conclude by highlighting the network topology as a significant
factor in evaluating and comparing the latency of consensus algorithms.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05871" title="Abstract">arXiv:2312.05871</a> [<a href="/pdf/2312.05871" title="Download PDF">pdf</a>, <a href="/format/2312.05871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization for the Metaverse over Mobile Edge Computing with Play to  Earn
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T+J">Terence Jie Chua</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work appears as a full paper in IEEE Conference on Computer Communications (INFOCOM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The concept of the Metaverse has garnered growing interest from both academic
and industry circles. The decentralization of both the integrity and security
of digital items has spurred the popularity of play-to-earn (P2E) games, where
players are entitled to earn and own digital assets which they may trade for
physical-world currencies. However, these computationally-intensive games are
hardly playable on resource-limited mobile devices and the computational tasks
have to be offloaded to an edge server. Through mobile edge computing (MEC),
users can upload data to the Metaverse Service Provider (MSP) edge servers for
computing. Nevertheless, there is a trade-off between user-perceived in-game
latency and user visual experience. The downlink transmission of
lower-resolution videos lowers user-perceived latency while lowering the visual
fidelity and consequently, earnings of users. In this paper, we design a method
to enhance the Metaverse-based mobile augmented reality (MAR) in-game user
experience. Specifically, we formulate and solve a multi-objective optimization
problem. Given the inherent NP-hardness of the problem, we present a
low-complexity algorithm to address it, mitigating the trade-off between delay
and earnings. The experiment results show that our method can effectively
balance the user-perceived latency and profitability, thus improving the
performance of Metaverse-based MAR systems.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05873" title="Abstract">arXiv:2312.05873</a> [<a href="/pdf/2312.05873" title="Download PDF">pdf</a>, <a href="/format/2312.05873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning for CasADi: Data-driven Models in Numerical Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salzmann%2C+T">Tim Salzmann</a>, 
<a href="/search/eess?searchtype=author&query=Arrizabalaga%2C+J">Jon Arrizabalaga</a>, 
<a href="/search/eess?searchtype=author&query=Andersson%2C+J">Joel Andersson</a>, 
<a href="/search/eess?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/eess?searchtype=author&query=Ryll%2C+M">Markus Ryll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">While real-world problems are often challenging to analyze analytically, deep
learning excels in modeling complex processes from data. Existing optimization
frameworks like CasADi facilitate seamless usage of solvers but face challenges
when integrating learned process models into numerical optimizations. To
address this gap, we present the Learning for CasADi (L4CasADi) framework,
enabling the seamless integration of PyTorch-learned models with CasADi for
efficient and potentially hardware-accelerated numerical optimization. The
applicability of L4CasADi is demonstrated with two tutorial examples: First, we
optimize a fish's trajectory in a turbulent river for energy efficiency where
the turbulent flow is represented by a PyTorch model. Second, we demonstrate
how an implicit Neural Radiance Field environment representation can be easily
leveraged for optimal control with L4CasADi. L4CasADi, along with examples and
documentation, is available under MIT license at
https://github.com/Tim-Salzmann/l4casadi
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05875" title="Abstract">arXiv:2312.05875</a> [<a href="/pdf/2312.05875" title="Download PDF">pdf</a>, <a href="/format/2312.05875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Aware Pruning for Efficient Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mengnan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingcun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Eldebiky%2C+A">Amro Eldebiky</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+I">Ing-Chao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G+L">Grace Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Design Automation and Test in Europe (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have demonstrated remarkable success in various
fields. However, the large number of floating-point operations (FLOPs) in DNNs
poses challenges for their deployment in resource-constrained applications,
e.g., edge devices. To address the problem, pruning has been introduced to
reduce the computational cost in executing DNNs. Previous pruning strategies
are based on weight values, gradient values and activation outputs. Different
from previous pruning solutions, in this paper, we propose a class-aware
pruning technique to compress DNNs, which provides a novel perspective to
reduce the computational cost of DNNs. In each iteration, the neural network
training is modified to facilitate the class-aware pruning. Afterwards, the
importance of filters with respect to the number of classes is evaluated. The
filters that are only important for a few number of classes are removed. The
neural network is then retrained to compensate for the incurred accuracy loss.
The pruning iterations end until no filter can be removed anymore, indicating
that the remaining filters are very important for many classes. This pruning
technique outperforms previous pruning solutions in terms of accuracy, pruning
ratio and the reduction of FLOPs. Experimental results confirm that this
class-aware pruning technique can significantly reduce the number of weights
and FLOPs, while maintaining a high inference accuracy.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05877" title="Abstract">arXiv:2312.05877</a> [<a href="/pdf/2312.05877" title="Download PDF">pdf</a>, <a href="/format/2312.05877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the 2023 XCSP3 Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Audemard%2C+G">Gilles Audemard</a>, 
<a href="/search/cs?searchtype=author&query=Lecoutre%2C+C">Christophe Lecoutre</a>, 
<a href="/search/cs?searchtype=author&query=Lonca%2C+E">Emmanuel Lonca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This document represents the proceedings of the 2023 XCSP3 Competition. The
results of this competition of constraint solvers were presented at CP'23 (the
29th International Conference on Principles and Practice of Constraint
Programming, held in Toronto, Canada from 27th to 31th August, 2023).
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05879" title="Abstract">arXiv:2312.05879</a> [<a href="/pdf/2312.05879" title="Download PDF">pdf</a>, <a href="/format/2312.05879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wild Motion Unleashed: Markerless 3D Kinematics and Force Estimation in  Cheetahs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+Z">Zico da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Shield%2C+S">Stacy Shield</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+P+E">Penny E. Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+M">Alan M. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Nicolls%2C+F">Fred Nicolls</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+A">Amir Patel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The complex dynamics of animal manoeuvrability in the wild is extremely
challenging to study. The cheetah ($\textit{Acinonyx jubatus}$) is a perfect
example: despite great interest in its unmatched speed and manoeuvrability,
obtaining complete whole-body motion data from these animals remains an
unsolved problem. This is especially difficult in wild cheetahs, where it is
essential that the methods used are remote and do not constrain the animal's
motion. In this work, we use data obtained from cheetahs in the wild to present
a trajectory optimisation approach for estimating the 3D kinematics and joint
torques of subjects remotely. We call this approach kinetic full trajectory
estimation (K-FTE). We validate the method on a dataset comprising synchronised
video and force plate data. We are able to reconstruct the 3D kinematics with
an average reprojection error of 17.69 pixels (62.94 $\%$ PCK using the
nose-to-eye(s) length segment as a threshold), while the estimates produce an
average root-mean-square error of 171.3 N ($\approx$ 17.16 $\%$ of peak force
during stride) for the estimated ground reaction force when compared against
the force plate data. While the joint torques cannot be directly validated
against ground truth data, as no such data is available for cheetahs, the
estimated torques agree with previous studies of quadrupeds in controlled
settings. These results will enable deeper insight into the study of animal
locomotion in a more natural environment for both biologists and roboticists.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05881" title="Abstract">arXiv:2312.05881</a> [<a href="/pdf/2312.05881" title="Download PDF">pdf</a>, <a href="/ps/2312.05881" title="Download PostScript">ps</a>, <a href="/format/2312.05881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum capacity path problem with loss factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deaconu%2C+A+M">Adrian Marius Deaconu</a>, 
<a href="/search/cs?searchtype=author&query=Tayyebi%2C+J">Javad Tayyebi</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%AEtan%2C+M">Mihai-Lucian R&#xee;tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">The maximum capacity path problem is to find a path from a source to a sink
which has the maximum capacity among all paths. This paper addresses an
extension of this problem which considers loss factors. It is called the
generalized maximum capacity path problem. The problem is a network flow
optimization problem whose network contains capacities as well as loss factors
for arcs. The aim of the problem is to find a path from an origin to a
destination so as to send a maximum flow along the path considering loss
factors and respecting capacity constraints. The paper presents a zero-one
formulation of the problem and moreover, it presents two efficient algorithms
which solve the problem in polynomial time.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05884" title="Abstract">arXiv:2312.05884</a> [<a href="/pdf/2312.05884" title="Download PDF">pdf</a>, <a href="/ps/2312.05884" title="Download PostScript">ps</a>, <a href="/format/2312.05884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Analytical Framework for the Resolution of Near-Field  Beamforming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+C">Chenguang Rao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xuchu Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The resolution is an important performance metric of near-field communication
networks. In particular, the resolution of near field beamforming measures how
effectively users can be distinguished in the distance-angle domain, which is
one of the most significant features of near-field communications. In a
comparison, conventional far-field beamforming can distinguish users in the
angle domain only, which means that near-field communication yields the full
utilization of user spatial resources to improve spectrum efficiency. In the
literature of near-field communications, there have been a few studies on
whether the resolution of near-field beamforming is perfect. However, each of
the existing results suffers its own limitations, e.g., each is accurate for
special cases only, and cannot precisely and comprehensively characterize the
resolution. In this letter, a general analytical framework is developed to
evaluate the resolution of near-field beamforming. Based on this derived
expression, the impacts of parameters on the resolution are investigated, which
can shed light on the design of the near-field communications, including the
designs of beamforming and multiple access tequniques.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05885" title="Abstract">arXiv:2312.05885</a> [<a href="/pdf/2312.05885" title="Download PDF">pdf</a>, <a href="/ps/2312.05885" title="Download PostScript">ps</a>, <a href="/format/2312.05885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Parameter Selection for Kernel Ridge Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shao-Bo Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">This paper focuses on parameter selection issues of kernel ridge regression
(KRR). Due to special spectral properties of KRR, we find that delicate
subdivision of the parameter interval shrinks the difference between two
successive KRR estimates. Based on this observation, we develop an
early-stopping type parameter selection strategy for KRR according to the
so-called Lepskii-type principle. Theoretical verifications are presented in
the framework of learning theory to show that KRR equipped with the proposed
parameter selection strategy succeeds in achieving optimal learning rates and
adapts to different norms, providing a new record of parameter selection for
kernel methods.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05887" title="Abstract">arXiv:2312.05887</a> [<a href="/pdf/2312.05887" title="Download PDF">pdf</a>, <a href="/format/2312.05887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three-dimensional numerical schemes for the segmentation of the psoas  muscle in X-ray computed tomography images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Paolucci%2C+G">Giulio Paolucci</a>, 
<a href="/search/math?searchtype=author&query=Cama%2C+I">Isabella Cama</a>, 
<a href="/search/math?searchtype=author&query=Campi%2C+C">Cristina Campi</a>, 
<a href="/search/math?searchtype=author&query=Piana%2C+M">Michele Piana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The analysis of the psoas muscle in morphological and functional imaging has
proved to be an accurate approach to assess sarcopenia, i.e. a systemic loss of
skeletal muscle mass and function that may be correlated to multifactorial
etiological aspects. The inclusion of sarcopenia assessment into a radiological
workflow would need the implementation of computational pipelines for image
processing that guarantee segmentation reliability and a significant degree of
automation. The present study utilizes three-dimensional numerical schemes for
psoas segmentation in low-dose X-ray computed tomography images. Specifically,
here we focused on the level set methodology and compared the performances of
two standard approaches, a classical evolution model and a three-dimension
geodesic model, with the performances of an original first-order modification
of this latter one. The results of this analysis show that these gradient-based
schemes guarantee reliability with respect to manual segmentation and that the
first-order scheme requires a computational burden that is significantly
smaller than the one needed by the second-order approach.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05889" title="Abstract">arXiv:2312.05889</a> [<a href="/pdf/2312.05889" title="Download PDF">pdf</a>, <a href="/format/2312.05889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperPrimitive: Scene Reconstruction at a Primitive Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazur%2C+K">Kirill Mazur</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+G">Gwangbin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+A+J">Andrew J. Davison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Joint camera pose and dense geometry estimation from a set of images or a
monocular video remains a challenging problem due to its computational
complexity and inherent visual ambiguities. Most dense incremental
reconstruction systems operate directly on image pixels and solve for their 3D
positions using multi-view geometry cues. Such pixel-level approaches suffer
from ambiguities or violations of multi-view consistency (e.g. caused by
textureless or specular surfaces).
<br />We address this issue with a new image representation which we call a
SuperPrimitive. SuperPrimitives are obtained by splitting images into
semantically correlated local regions and enhancing them with estimated surface
normal directions, both of which are predicted by state-of-the-art single image
neural networks. This provides a local geometry estimate per SuperPrimitive,
while their relative positions are adjusted based on multi-view observations.
<br />We demonstrate the versatility of our new representation by addressing three
3D reconstruction tasks: depth completion, few-view structure from motion, and
monocular dense visual odometry.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05890" title="Abstract">arXiv:2312.05890</a> [<a href="/pdf/2312.05890" title="Download PDF">pdf</a>, <a href="/format/2312.05890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling #DNN-Verification Tools with Efficient Bound Propagation and  Parallel Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marzari%2C+L">Luca Marzari</a>, 
<a href="/search/cs?searchtype=author&query=Roncolato%2C+G">Gabriele Roncolato</a>, 
<a href="/search/cs?searchtype=author&query=Farinelli%2C+A">Alessandro Farinelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AIRO 2023 the 10th Italian Workshop on Artificial Intelligence and Robotics co-located with the 22nd International Conference of the Italian Association for Artificial Intelligence (AI*IA 2023), Rome, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are powerful tools that have shown extraordinary
results in many scenarios, ranging from pattern recognition to complex robotic
problems. However, their intricate designs and lack of transparency raise
safety concerns when applied in real-world applications. In this context,
Formal Verification (FV) of DNNs has emerged as a valuable solution to provide
provable guarantees on the safety aspect. Nonetheless, the binary answer (i.e.,
safe or unsafe) could be not informative enough for direct safety interventions
such as safety model ranking or selection. To address this limitation, the FV
problem has recently been extended to the counting version, called
#DNN-Verification, for the computation of the size of the unsafe regions in a
given safety property's domain. Still, due to the complexity of the problem,
existing solutions struggle to scale on real-world robotic scenarios, where the
DNN can be large and complex. To address this limitation, inspired by advances
in FV, in this work, we propose a novel strategy based on reachability analysis
combined with Symbolic Linear Relaxation and parallel computing to enhance the
efficiency of existing exact and approximate FV for DNN counters. The empirical
evaluation on standard FV benchmarks and realistic robotic scenarios shows a
remarkable improvement in scalability and efficiency, enabling the use of such
techniques even for complex robotic applications.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05891" title="Abstract">arXiv:2312.05891</a> [<a href="/pdf/2312.05891" title="Download PDF">pdf</a>, <a href="/format/2312.05891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A conservative hybrid physics-informed neural network method for  Maxwell-Amp&#xe8;re-Nernst-Planck equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chang%2C+C">Cheng Chang</a>, 
<a href="/search/math?searchtype=author&query=Xin%2C+Z">Zhouping Xin</a>, 
<a href="/search/math?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Maxwell-Amp\`{e}re-Nernst-Planck (MANP) equations were recently proposed to
model the dynamics of charged particles. In this study, we enhance a numerical
algorithm of this system with deep learning tools. The proposed hybrid
algorithm provides an automated means to determine a proper approximation for
the dummy variables, which can otherwise only be obtained through massive
numerical tests. In addition, the original method is validated for
2-dimensional problems. However, when the spatial dimension is one, the
original curl-free relaxation component is inapplicable, and the approximation
formula for dummy variables, which works well in a 2-dimensional scenario,
fails to provide a reasonable output in the 1-dimensional case. The proposed
method can be readily generalised to cases with one spatial dimension.
Experiments show numerical stability and good convergence to the steady-state
solution obtained from Poisson-Boltzmann type equations in the 1-dimensional
case. The experiments conducted in the 2-dimensional case indicate that the
proposed method preserves the conservation properties.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05897" title="Abstract">arXiv:2312.05897</a> [<a href="/pdf/2312.05897" title="Download PDF">pdf</a>, <a href="/format/2312.05897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSCR: Patches Sampling-based Contrastive Regression for AIGC Image  Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiquan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Linjing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinlong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xixin Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, Artificial Intelligence Generated Content (AIGC) has gained
widespread attention beyond the computer science community. Due to various
issues arising from continuous creation of AI-generated images (AIGI), AIGC
image quality assessment (AIGCIQA), which aims to evaluate the quality of AIGIs
from human perception perspectives, has emerged as a novel topic in the field
of computer vision. However, most existing AIGCIQA methods directly regress
predicted scores from a single generated image, overlooking the inherent
differences among AIGIs and scores. Additionally, operations like resizing and
cropping may cause global geometric distortions and information loss, thus
limiting the performance of models. To address these issues, we propose a
patches sampling-based contrastive regression (PSCR) framework. We suggest
introducing a contrastive regression framework to leverage differences among
various generated images for learning a better representation space. In this
space, differences and score rankings among images can be measured by their
relative scores. By selecting exemplar AIGIs as references, we also overcome
the limitations of previous models that could not utilize reference images on
the no-reference image databases. To avoid geometric distortions and
information loss in image inputs, we further propose a patches sampling
strategy. To demonstrate the effectiveness of our proposed PSCR framework, we
conduct extensive experiments on three mainstream AIGCIQA databases including
AGIQA-1K, AGIQA-3K and AIGCIQA2023. The results show significant improvements
in model performance with the introduction of our proposed PSCR framework. Code
will be available at \url{https://github.com/jiquan123/PSCR}.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05900" title="Abstract">arXiv:2312.05900</a> [<a href="/pdf/2312.05900" title="Download PDF">pdf</a>, <a href="/format/2312.05900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Learning-Assisted Analysis of Cataract Surgery Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghamsarian%2C+N">Negin Ghamsarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 201 pages, Dissertation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Following the technological advancements in medicine, the operation rooms are
evolving into intelligent environments. The context-aware systems (CAS) can
comprehensively interpret the surgical state, enable real-time warning, and
support decision-making, especially for novice surgeons. These systems can
automatically analyze surgical videos and perform indexing, documentation, and
post-operative report generation. The ever-increasing demand for such automatic
systems has sparked machine-learning-based approaches for surgical video
analysis. This thesis addresses the significant challenges in cataract surgery
video analysis to pave the way for building efficient context-aware systems.
The main contributions of this thesis are five folds: (1) This thesis
demonstrates that spatio-temporal localization of the relevant content can
considerably improve phase recognition accuracy. (2) This thesis proposes a
novel deep-learning-based framework for relevance-based compression to enable
real-time streaming and adaptive storage of cataract surgery videos. (3)
Several convolutional modules are proposed to boost the networks' semantic
interpretation performance in challenging conditions. These challenges include
blur and reflection distortion, transparency, deformability, color and texture
variation, blunt edges, and scale variation. (4) This thesis proposes and
evaluates the first framework for automatic irregularity detection in cataract
surgery videos. (5) To alleviate the requirement for manual pixel-based
annotations, this thesis proposes novel strategies for self-supervised
representation learning adapted to semantic segmentation.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05905" title="Abstract">arXiv:2312.05905</a> [<a href="/pdf/2312.05905" title="Download PDF">pdf</a>, <a href="/format/2312.05905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Subgraph-GNNs via Edge-Level Ego-Network Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvarez-Gonzalez%2C+N">Nurudin Alvarez-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Kaltenbrunner%2C+A">Andreas Kaltenbrunner</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+V">Vicen&#xe7; G&#xf3;mez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> graph neural networks, weisfeiler-lehman, expressivity, higher-order GNNs, 3-WL, 1-WL, edge-level, ego-networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a novel edge-level ego-network encoding for learning on graphs
that can boost Message Passing Graph Neural Networks (MP-GNNs) by providing
additional node and edge features or extending message-passing formats. The
proposed encoding is sufficient to distinguish Strongly Regular Graphs, a
family of challenging 3-WL equivalent graphs. We show theoretically that such
encoding is more expressive than node-based sub-graph MP-GNNs. In an empirical
evaluation on four benchmarks with 10 graph datasets, our results match or
improve previous baselines on expressivity, graph classification, graph
regression, and proximity tasks -- while reducing memory usage by 18.1x in
certain real-world settings.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05907" title="Abstract">arXiv:2312.05907</a> [<a href="/pdf/2312.05907" title="Download PDF">pdf</a>, <a href="/format/2312.05907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph-Guided Disentangled Spectrum Transformer Networks for  Near-Infrared Facial Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bingjun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With the strong robusticity on illumination variations, near-infrared (NIR)
can be an effective and essential complement to visible (VIS) facial expression
recognition in low lighting or complete darkness conditions. However, facial
expression recognition (FER) from NIR images presents more challenging problem
than traditional FER due to the limitations imposed by the data scale and the
difficulty of extracting discriminative features from incomplete visible
lighting contents. In this paper, we give the first attempt to deep NIR facial
expression recognition and proposed a novel method called near-infrared facial
expression transformer (NFER-Former). Specifically, to make full use of the
abundant label information in the field of VIS, we introduce a Self-Attention
Orthogonal Decomposition mechanism that disentangles the expression information
and spectrum information from the input image, so that the expression features
can be extracted without the interference of spectrum variation. We also
propose a Hypergraph-Guided Feature Embedding method that models some key
facial behaviors and learns the structure of the complex correlations between
them, thereby alleviating the interference of inter-class similarity.
Additionally, we have constructed a large NIR-VIS Facial Expression dataset
that includes 360 subjects to better validate the efficiency of NFER-Former.
Extensive experiments and ablation studies show that NFER-Former significantly
improves the performance of NIR FER and achieves state-of-the-art results on
the only two available NIR FER datasets, Oulu-CASIA and Large-HFE.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05908" title="Abstract">arXiv:2312.05908</a> [<a href="/pdf/2312.05908" title="Download PDF">pdf</a>, <a href="/format/2312.05908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Energy Guided Image Translation with Stochastic Differential  Equations for Near-Infrared Facial Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bingjun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zewen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Illumination variation has been a long-term challenge in real-world facial
expression recognition(FER). Under uncontrolled or non-visible light
conditions, Near-infrared (NIR) can provide a simple and alternative solution
to obtain high-quality images and supplement the geometric and texture details
that are missing in the visible domain. Due to the lack of existing large-scale
NIR facial expression datasets, directly extending VIS FER methods to the NIR
spectrum may be ineffective. Additionally, previous heterogeneous image
synthesis methods are restricted by low controllability without prior task
knowledge. To tackle these issues, we present the first approach, called for
NIR-FER Stochastic Differential Equations (NFER-SDE), that transforms face
expression appearance between heterogeneous modalities to the overfitting
problem on small-scale NIR data. NFER-SDE is able to take the whole VIS source
image as input and, together with domain-specific knowledge, guide the
preservation of modality-invariant information in the high-frequency content of
the image. Extensive experiments and ablation studies show that NFER-SDE
significantly improves the performance of NIR FER and achieves state-of-the-art
results on the only two available NIR FER datasets, Oulu-CASIA and Large-HFE.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05909" title="Abstract">arXiv:2312.05909</a> [<a href="/pdf/2312.05909" title="Download PDF">pdf</a>, <a href="/format/2312.05909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the rank of the communication matrix for deterministic two-way finite  automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrov%2C+S">Semyon Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Petrov%2C+F">Fedor Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Okhotin%2C+A">Alexander Okhotin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Combinatorics (math.CO); Representation Theory (math.RT)

</div>
<p class="mathjax">The communication matrix for two-way deterministic finite automata (2DFA)
with $n$ states is defined for an automaton over a full alphabet of all
$(2n+1)^n$ possible symbols: its rows and columns are indexed by strings, and
the entry $(u, v)$ is $1$ if $uv$ is accepted by the automaton, and $0$
otherwise. With duplicate rows and columns removed, this is a square matrix of
order $n(n^n-(n-1)^n)+1$, and its rank is known to be a lower bound on the
number of states necessary to transform an $n$-state 2DFA to a one-way
unambiguous finite automaton (UFA). This paper determines this rank, showing
that it is exactly $f(n)=\sum_{k=1}^n \binom{n}{k-1} \binom{n}{k}
\binom{2k-2}{k-1} =(1+o(1)) \frac{3\sqrt{3}}{8\pi n} 9^n$, and this function
becomes the new lower bound on the state complexity of the 2DFA to UFA
transformation, thus improving a recent lower bound by S. Petrov and Okhotin
(``On the transformation of two-way deterministic finite automata to
unambiguous finite automata'', Inf. Comput., 2023). The key element of the
proof is determining the rank of a $k! \times k!$ submatrix, with its rows and
columns indexed by permutations, where the entry $(\pi, \sigma)$ is $1$ if
$\sigma \circ \pi$ is a cycle of length $k$, and 0 otherwise; using the methods
of group representation theory it is shown that its rank is exactly
$\binom{2k-2}{k-1}$, and this implies the above formula for $f(n)$.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05910" title="Abstract">arXiv:2312.05910</a> [<a href="/pdf/2312.05910" title="Download PDF">pdf</a>, <a href="/format/2312.05910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Kalman Filtering-Aided Variational Inference for Gaussian  Process State-Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhidi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Thi%C3%A9ry%2C+A">Alexandre Thi&#xe9;ry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Gaussian process state-space models (GPSSMs) provide a principled and
flexible approach to model latent state dynamics observed through emission
models. However, existing variational methods for learning GPSSMs face a
substantial challenge in optimizing a large number of parameters, particularly
with the introduction of amortized inference networks. To address this
challenge, we leverage the ensemble Kalman filter (EnKF), a well-established
model-based filtering technique, to approximate the posterior distribution of
latent states within the variational inference framework. This approach
eliminates the need for inference networks, significantly reducing the number
of variational parameters. Moreover, we demonstrate that with the aid of EnKF,
the straightforward evaluation of approximated evidence lower bound (ELBO) in
the variational inference can be easily obtained through the summation of
multiple terms with closed-form solutions. By leveraging automatic
differentiation tools, we thus can maximize the ELBO and train the GPSSM
efficiently. We also extend the proposed method to an online setting and
provide comprehensive algorithm analyses and insights. Extensive testing on
diverse real and simulated datasets demonstrates that our variational inference
algorithms, integrated with EnKF, outperform existing methods in terms of
learning and inference performance.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05915" title="Abstract">arXiv:2312.05915</a> [<a href="/pdf/2312.05915" title="Download PDF">pdf</a>, <a href="/format/2312.05915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion for Natural Image Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yihan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We aim to leverage diffusion to address the challenging image matting task.
However, the presence of high computational overhead and the inconsistency of
noise sampling between the training and inference processes pose significant
obstacles to achieving this goal. In this paper, we present DiffMatte, a
solution designed to effectively overcome these challenges. First, DiffMatte
decouples the decoder from the intricately coupled matting network design,
involving only one lightweight decoder in the iterations of the diffusion
process. With such a strategy, DiffMatte mitigates the growth of computational
overhead as the number of samples increases. Second, we employ a self-aligned
training strategy with uniform time intervals, ensuring a consistent noise
sampling between training and inference across the entire time domain. Our
DiffMatte is designed with flexibility in mind and can seamlessly integrate
into various modern matting architectures. Extensive experimental results
demonstrate that DiffMatte not only reaches the state-of-the-art level on the
Composition-1k test set, surpassing the best methods in the past by 5% and 15%
in the SAD metric and MSE metric respectively, but also show stronger
generalization ability in other benchmarks.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05919" title="Abstract">arXiv:2312.05919</a> [<a href="/pdf/2312.05919" title="Download PDF">pdf</a>, <a href="/ps/2312.05919" title="Download PostScript">ps</a>, <a href="/format/2312.05919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Logical Framework with Infinitary Terms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Logical frameworks are successful in modeling proof systems. Recently, CoLF
extended the logical framework LF to support higher-order rational terms that
enable adequate encoding of circular objects and derivations. In this paper, we
propose CoLF$^\omega$ as an alternative interpretation of CoLF-style signatures
where terms are taken to be all possibly infinitary terms that are consistent
with a given signature. In particular, we propose the notion of productive
B\"ohm trees, a particular kind of typed $\bot$-free B\"ohm trees that are
closed under hereditary substitution. We show that the productive B\"ohm trees
are capable of meta-encoding their own structure. Overall, we hope to establish
CoLF$^\omega$ as a new formal framework for the encoding of infinitary regular
and non-regular structures.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05920" title="Abstract">arXiv:2312.05920</a> [<a href="/pdf/2312.05920" title="Download PDF">pdf</a>, <a href="/format/2312.05920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Randomized Neural Networks with Hybridized Discontinuous  Petrov-Galerkin Methods for Stokes-Darcy Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dang%2C+H">Haoning Dang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+F">Fei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a new numerical approach that integrates local
randomized neural networks (LRNNs) and the hybridized discontinuous
Petrov-Galerkin (HDPG) method for solving coupled fluid flow problems. The
proposed method partitions the domain of interest into several subdomains and
constructs an LRNN on each subdomain. Then, the HDPG scheme is used to couple
the LRNNs to approximate the unknown functions. We develop LRNN-HDPG methods
based on velocity-stress formulation to solve two types of problems:
Stokes-Darcy problems and Brinkman equations, which model the flow in porous
media and free flow. We devise a simple and effective way to deal with the
interface conditions in the Stokes-Darcy problems without adding extra terms to
the numerical scheme. We conduct extensive numerical experiments to demonstrate
the stability, efficiency, and robustness of the proposed method. The numerical
results show that the LRNN-HDPG method can achieve high accuracy with a small
number of degrees of freedom.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05921" title="Abstract">arXiv:2312.05921</a> [<a href="/pdf/2312.05921" title="Download PDF">pdf</a>, <a href="/format/2312.05921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dig-CSI: A Distributed and Generative Model Assisted CSI Feedback  Training Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhilin Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haozhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shilong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xinyu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The advent of deep learning (DL)-based models has significantly advanced
Channel State Information (CSI) feedback mechanisms in wireless communication
systems. However, traditional approaches often suffer from high communication
overhead and potential privacy risks due to the centralized nature of CSI data
processing. To address these challenges, we design a CSI feedback training
framework called Dig-CSI, in which the dataset for training the CSI feedback
model is produced by the distributed generators uploaded by each user equipment
(UE), but not through local data upload. Each UE trains an autoencoder, where
the decoder is considered as the distributed generator, with local data to gain
reconstruction accuracy and the ability to generate. Experimental results show
that Dig-CSI can train a global CSI feedback model with comparable performance
to the model trained with classical centralized learning with a much lighter
communication overhead.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05923" title="Abstract">arXiv:2312.05923</a> [<a href="/pdf/2312.05923" title="Download PDF">pdf</a>, <a href="/format/2312.05923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Video Individual CountingWeakly Supervised Video  Individual Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guorong Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuankai Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Ziheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhenjun Han</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Individual Counting (VIC) aims to predict the number of unique
individuals in a single video. % Existing methods learn representations based
on trajectory labels for individuals, which are annotation-expensive. % To
provide a more realistic reflection of the underlying practical challenge, we
introduce a weakly supervised VIC task, wherein trajectory labels are not
provided. Instead, two types of labels are provided to indicate traffic
entering the field of view (inflow) and leaving the field view (outflow). % We
also propose the first solution as a baseline that formulates the task as a
weakly supervised contrastive learning problem under group-level matching. In
doing so, we devise an end-to-end trainable soft contrastive loss to drive the
network to distinguish inflow, outflow, and the remaining. % To facilitate
future study in this direction, we generate annotations from the existing VIC
datasets SenseCrowd and CroHD and also build a new dataset, UAVVIC. % Extensive
results show that our baseline weakly supervised method outperforms supervised
methods, and thus, little information is lost in the transition to the more
practically relevant weakly supervised task. The code and trained model will be
public at \href{https://github.com/streamer-AP/CGNet}{CGNet}
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05924" title="Abstract">arXiv:2312.05924</a> [<a href="/pdf/2312.05924" title="Download PDF">pdf</a>, <a href="/format/2312.05924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Free Hard-Label Robustness Stealing Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaojian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The popularity of Machine Learning as a Service (MLaaS) has led to increased
concerns about Model Stealing Attacks (MSA), which aim to craft a clone model
by querying MLaaS. Currently, most research on MSA assumes that MLaaS can
provide soft labels and that the attacker has a proxy dataset with a similar
distribution. However, this fails to encapsulate the more practical scenario
where only hard labels are returned by MLaaS and the data distribution remains
elusive. Furthermore, most existing work focuses solely on stealing the model
accuracy, neglecting the model robustness, while robustness is essential in
security-sensitive scenarios, e.g., face-scan payment. Notably, improving model
robustness often necessitates the use of expensive techniques such as
adversarial training, thereby further making stealing robustness a more
lucrative prospect. In response to these identified gaps, we introduce a novel
Data-Free Hard-Label Robustness Stealing (DFHL-RS) attack in this paper, which
enables the stealing of both model accuracy and robustness by simply querying
hard labels of the target model without the help of any natural data.
Comprehensive experiments demonstrate the effectiveness of our method. The
clone model achieves a clean accuracy of 77.86% and a robust accuracy of 39.51%
against AutoAttack, which are only 4.71% and 8.40% lower than the target model
on the CIFAR-10 dataset, significantly exceeding the baselines. Our code is
available at: https://github.com/LetheSec/DFHL-RS-Attack
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05925" title="Abstract">arXiv:2312.05925</a> [<a href="/pdf/2312.05925" title="Download PDF">pdf</a>, <a href="/format/2312.05925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Conditioned Semantic Search-Based Policy for Robotic  Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheikh%2C+J">Jannik Sheikh</a>, 
<a href="/search/cs?searchtype=author&query=Melnik%2C+A">Andrew Melnik</a>, 
<a href="/search/cs?searchtype=author&query=Nandi%2C+G+C">Gora Chand Nandi</a>, 
<a href="/search/cs?searchtype=author&query=Haschke%2C+R">Robert Haschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement learning and Imitation Learning approaches utilize policy
learning strategies that are difficult to generalize well with just a few
examples of a task. In this work, we propose a language-conditioned semantic
search-based method to produce an online search-based policy from the available
demonstration dataset of state-action trajectories. Here we directly acquire
actions from the most similar manipulation trajectories found in the dataset.
Our approach surpasses the performance of the baselines on the CALVIN benchmark
and exhibits strong zero-shot adaptation capabilities. This holds great
potential for expanding the use of our online search-based policy approach to
tasks typically addressed by Imitation Learning or Reinforcement Learning-based
policies.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05927" title="Abstract">arXiv:2312.05927</a> [<a href="/pdf/2312.05927" title="Download PDF">pdf</a>, <a href="/format/2312.05927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The survival of scientific stylization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yuanyuan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+T">Tianxing Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages (23 main text, 32 SI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">This study elaborates a text-based metric to quantify the unique position of
stylized scientific research, characterized by its innovative integration of
diverse knowledge components and potential to pivot established scientific
paradigms. Our analysis reveals a concerning decline in stylized research,
highlighted by its comparative undervaluation in terms of citation counts and
protracted peer-review duration. Despite facing these challenges, the
disruptive potential of stylized research remains robust, consistently
introducing groundbreaking questions and theories. This paper posits that
substantive reforms are necessary to incentivize and recognize the value of
stylized research, including optimizations to the peer-review process and the
criteria for evaluating scientific impact. Embracing these changes may be
imperative to halt the downturn in stylized research and ensure enduring
scholarly exploration in endless frontiers.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05928" title="Abstract">arXiv:2312.05928</a> [<a href="/pdf/2312.05928" title="Download PDF">pdf</a>, <a href="/format/2312.05928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+J">Joonwoo Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sooyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuewei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Jiook Cha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural style transfer (NST) has evolved significantly in recent years. Yet,
despite its rapid progress and advancement, existing NST methods either
struggle to transfer aesthetic information from a style effectively or suffer
from high computational costs and inefficiencies in feature disentanglement due
to using pre-trained models. This work proposes a lightweight but effective
model, AesFA -- Aesthetic Feature-Aware NST. The primary idea is to decompose
the image via its frequencies to better disentangle aesthetic styles from the
reference image while training the entire model in an end-to-end manner to
exclude pre-trained models at inference completely. To improve the network's
ability to extract more distinct representations and further enhance the
stylization quality, this work introduces a new aesthetic feature: contrastive
loss. Extensive experiments and ablations show the approach not only
outperforms recent NST methods in terms of stylization quality, but it also
achieves faster inference. Codes are available at
https://github.com/Sooyyoungg/AesFA.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05933" title="Abstract">arXiv:2312.05933</a> [<a href="/pdf/2312.05933" title="Download PDF">pdf</a>, <a href="/format/2312.05933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Supervised Contrastive Learning for Modeling Patient Risk  Progression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noroozizadeh%2C+S">Shahriar Noroozizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+J+C">Jeremy C. Weiss</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G+H">George H. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Health (ML4H 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of predicting how the likelihood of an outcome of
interest for a patient changes over time as we observe more of the patient
data. To solve this problem, we propose a supervised contrastive learning
framework that learns an embedding representation for each time step of a
patient time series. Our framework learns the embedding space to have the
following properties: (1) nearby points in the embedding space have similar
predicted class probabilities, (2) adjacent time steps of the same time series
map to nearby points in the embedding space, and (3) time steps with very
different raw feature vectors map to far apart regions of the embedding space.
To achieve property (3), we employ a nearest neighbor pairing mechanism in the
raw feature space. This mechanism also serves as an alternative to data
augmentation, a key ingredient of contrastive learning, which lacks a standard
procedure that is adequately realistic for clinical tabular data, to our
knowledge. We demonstrate that our approach outperforms state-of-the-art
baselines in predicting mortality of septic patients (MIMIC-III dataset) and
tracking progression of cognitive impairment (ADNI dataset). Our method also
consistently recovers the correct synthetic dataset embedding structure across
experiments, a feat not achieved by baselines. Our ablation experiments show
the pivotal role of our nearest neighbor pairing.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05934" title="Abstract">arXiv:2312.05934</a> [<a href="/pdf/2312.05934" title="Download PDF">pdf</a>, <a href="/format/2312.05934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ovadia%2C+O">Oded Ovadia</a>, 
<a href="/search/cs?searchtype=author&query=Brief%2C+M">Menachem Brief</a>, 
<a href="/search/cs?searchtype=author&query=Mishaeli%2C+M">Moshik Mishaeli</a>, 
<a href="/search/cs?searchtype=author&query=Elisha%2C+O">Oren Elisha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) encapsulate a vast amount of factual information
within their pre-trained weights, as evidenced by their ability to answer
diverse questions across different domains. However, this knowledge is
inherently limited, relying heavily on the characteristics of the training
data. Consequently, using external datasets to incorporate new information or
refine the capabilities of LLMs on previously seen information poses a
significant challenge. In this study, we compare two common approaches:
fine-tuning and retrieval-augmented generation (RAG). We evaluate both
approaches on a variety of knowledge-intensive tasks across different topics.
Our findings reveal that while fine-tuning offers some improvement, RAG
consistently outperforms it, both for existing knowledge encountered during
training and entirely new knowledge. Moreover, we find that LLMs struggle to
learn new factual information through fine-tuning, and that exposing them to
numerous variations of the same fact during training could alleviate this
problem.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05937" title="Abstract">arXiv:2312.05937</a> [<a href="/pdf/2312.05937" title="Download PDF">pdf</a>, <a href="/format/2312.05937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lagrangian Properties and Control of Soft Robots Modeled with Discrete  Cosserat Rods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molu%2C+L">Lekan Molu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sedal%2C+A">Audrey Sedal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The characteristic ``in-plane" bending associated with soft robots'
deformation make them preferred over rigid robots in sophisticated manipulation
and movement tasks. Executing such motion strategies to precision in soft
deformable robots and structures is however fraught with modeling and control
challenges given their infinite degrees-of-freedom. Imposing \textit{piecewise
constant strains} (PCS) across (discretized) Cosserat microsolids on the
continuum material however, their dynamics become amenable to tractable
mathematical analysis. While this PCS model handles the characteristic
difficult-to-model ``in-plane" bending well, its Lagrangian properties are not
exploited for control in literature neither is there a rigorous study on the
dynamic performance of multisection deformable materials for ``in-plane"
bending that guarantees steady-state convergence. In this sentiment, we first
establish the PCS model's structural Lagrangian properties. Second, we exploit
these for control on various strain goal states. Third, we benchmark our
hypotheses against an Octopus-inspired robot arm under different constant tip
loads. These induce non-constant ``in-plane" deformation and we regulate strain
states throughout the continuum in these configurations. Our numerical results
establish convergence to desired equilibrium throughout the continuum in all of
our tests. Within the bounds here set, we conjecture that our methods can find
wide adoption in the control of cable- and fluid-driven multisection soft
robotic arms; and may be extensible to the (learning-based) control of
deformable agents employed in simulated, mixed, or augmented reality.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05941" title="Abstract">arXiv:2312.05941</a> [<a href="/pdf/2312.05941" title="Download PDF">pdf</a>, <a href="/format/2312.05941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASH: Animatable Gaussian Splats for Efficient and Photoreal Human  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+H">Haokai Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Heming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures. For project page, see <a href="https://vcai.mpi-inf.mpg.de/projects/ash/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time rendering of photorealistic and controllable human avatars stands
as a cornerstone in Computer Vision and Graphics. While recent advances in
neural implicit rendering have unlocked unprecedented photorealism for digital
avatars, real-time performance has mostly been demonstrated for static scenes
only. To address this, we propose ASH, an animatable Gaussian splatting
approach for photorealistic rendering of dynamic humans in real-time. We
parameterize the clothed human as animatable 3D Gaussians, which can be
efficiently splatted into image space to generate the final rendering. However,
naively learning the Gaussian parameters in 3D space poses a severe challenge
in terms of compute. Instead, we attach the Gaussians onto a deformable
character model, and learn their parameters in 2D texture space, which allows
leveraging efficient 2D convolutional architectures that easily scale with the
required number of Gaussians. We benchmark ASH with competing methods on
pose-controllable avatars, demonstrating that our method outperforms existing
real-time methods by a large margin and shows comparable or even better results
than offline methods.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05946" title="Abstract">arXiv:2312.05946</a> [<a href="/pdf/2312.05946" title="Download PDF">pdf</a>, <a href="/format/2312.05946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Propagation through Trained Deep Neural Networks Using  Factor Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daruna%2C+A">Angel Daruna</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yunye Gong</a>, 
<a href="/search/cs?searchtype=author&query=Rajvanshi%2C+A">Abhinav Rajvanshi</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+H">Han-Pang Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yi Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predictive uncertainty estimation remains a challenging problem precluding
the use of deep neural networks as subsystems within safety-critical
applications. Aleatoric uncertainty is a component of predictive uncertainty
that cannot be reduced through model improvements. Uncertainty propagation
seeks to estimate aleatoric uncertainty by propagating input uncertainties to
network predictions. Existing uncertainty propagation techniques use one-way
information flows, propagating uncertainties layer-by-layer or across the
entire neural network while relying either on sampling or analytical techniques
for propagation. Motivated by the complex information flows within deep neural
networks (e.g. skip connections), we developed and evaluated a novel approach
by posing uncertainty propagation as a non-linear optimization problem using
factor graphs. We observed statistically significant improvements in
performance over prior work when using factor graphs across most of our
experiments that included three datasets and two neural network architectures.
Our implementation balances the benefits of sampling and analytical propagation
techniques, which we believe, is a key factor in achieving performance
improvements.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05947" title="Abstract">arXiv:2312.05947</a> [<a href="/pdf/2312.05947" title="Download PDF">pdf</a>, <a href="/format/2312.05947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards non-stochastic targeted exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Venkatasubramanian%2C+J">Janani Venkatasubramanian</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=Cannon%2C+M">Mark Cannon</a>, 
<a href="/search/eess?searchtype=author&query=Allg%C3%B6wer%2C+F">Frank Allg&#xf6;wer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IFAC Symposium on System Identification, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We present a novel targeted exploration strategy for linear time-invariant
systems without stochastic assumptions on the noise, i.e., without requiring
independence or zero mean, allowing for deterministic model misspecifications.
This work utilizes classical data-dependent uncertainty bounds on the
least-squares parameter estimates in the presence of energy-bounded noise. We
provide a sufficient condition on the exploration data that ensures a desired
error bound on the estimated parameter. Using common approximations, we derive
a semidefinite program to compute the optimal sinusoidal input excitation.
Finally, we highlight the differences and commonalities between the developed
non-stochastic targeted exploration strategy and conventional exploration
strategies based on classical identification bounds through a numerical
example.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05952" title="Abstract">arXiv:2312.05952</a> [<a href="/pdf/2312.05952" title="Download PDF">pdf</a>, <a href="/ps/2312.05952" title="Download PostScript">ps</a>, <a href="/format/2312.05952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Dynamic Programming based Model Predictive Control of  Nonlinear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chacko%2C+K">Keerthi Chacko</a>, 
<a href="/search/eess?searchtype=author&query=Augustine%2C+M+T">Midhun T. Augustine</a>, 
<a href="/search/eess?searchtype=author&query=Janardhanan%2C+S">S. Janardhanan</a>, 
<a href="/search/eess?searchtype=author&query=Patil%2C+D+U">Deepak U. Patil</a>, 
<a href="/search/eess?searchtype=author&query=Kar%2C+I+N">I. N. Kar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper studies the optimal control problem for discrete-time nonlinear
systems and an approximate dynamic programming-based Model Predictive Control
(MPC) scheme is proposed for minimizing a quadratic performance measure. In the
proposed approach, the value function is approximated as a quadratic function
for which the parametric matrix is computed using a switched system approximate
of the nonlinear system. The approach is modified further using a multi-stage
scheme to improve the control accuracy and an extension to incorporate state
constraints. The MPC scheme is validated experimentally on a multi-tank system
which is modeled as a third-order nonlinear system. The experimental results
show the proposed MPC scheme results in significantly lesser online computation
compared to the Nonlinear MPC scheme.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05955" title="Abstract">arXiv:2312.05955</a> [<a href="/pdf/2312.05955" title="Download PDF">pdf</a>, <a href="/format/2312.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Differentiable Particle Filter on the Fly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiongjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Differentiable particle filters are an emerging class of sequential Bayesian
inference techniques that use neural networks to construct components in state
space models. Existing approaches are mostly based on offline supervised
training strategies. This leads to the delay of the model deployment and the
obtained filters are susceptible to distribution shift of test-time data. In
this paper, we propose an online learning framework for differentiable particle
filters so that model parameters can be updated as data arrive. The technical
constraint is that there is no known ground truth state information in the
online inference setting. We address this by adopting an unsupervised loss to
construct the online model updating procedure, which involves a sequence of
filtering operations for online maximum likelihood-based parameter estimation.
We empirically evaluate the effectiveness of the proposed method, and compare
it with supervised learning methods in simulation settings including a
multivariate linear Gaussian state-space model and a simulated object tracking
experiment.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05959" title="Abstract">arXiv:2312.05959</a> [<a href="/pdf/2312.05959" title="Download PDF">pdf</a>, <a href="/ps/2312.05959" title="Download PostScript">ps</a>, <a href="/format/2312.05959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VAE-IF: Deep feature extraction with averaging for unsupervised artifact  detection in routine acquired ICU time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haule%2C+H">Hollan Haule</a>, 
<a href="/search/cs?searchtype=author&query=Piper%2C+I">Ian Piper</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+P">Patricia Jones</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+T+M">Tsz-Yan Milly Lo</a>, 
<a href="/search/cs?searchtype=author&query=Escudero%2C+J">Javier Escudero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Artifacts are a common problem in physiological time-series data collected
from intensive care units (ICU) and other settings. They affect the quality and
reliability of clinical research and patient care. Manual annotation of
artifacts is costly and time-consuming, rendering it impractical. Automated
methods are desired. Here, we propose a novel unsupervised approach to detect
artifacts in clinical-standard minute-by-minute resolution ICU data without any
prior labeling or signal-specific knowledge. Our approach combines a
variational autoencoder (VAE) and an isolation forest (iForest) model to learn
features and identify anomalies in different types of vital signs, such as
blood pressure, heart rate, and intracranial pressure. We evaluate our approach
on a real-world ICU dataset and compare it with supervised models based on long
short-term memory (LSTM) and XGBoost. We show that our approach achieves
comparable sensitivity and generalizes well to an external dataset. We also
visualize the latent space learned by the VAE and demonstrate its ability to
disentangle clean and noisy samples. Our approach offers a promising solution
for cleaning ICU data in clinical research and practice without the need for
any labels whatsoever.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05961" title="Abstract">arXiv:2312.05961</a> [<a href="/pdf/2312.05961" title="Download PDF">pdf</a>, <a href="/format/2312.05961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransGlow: Attention-augmented Transduction model based on Graph Neural  Networks for Water Flow Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roudbari%2C+N+S">Naghmeh Shafiee Roudbari</a>, 
<a href="/search/cs?searchtype=author&query=Poullis%2C+C">Charalambos Poullis</a>, 
<a href="/search/cs?searchtype=author&query=Patterson%2C+Z">Zachary Patterson</a>, 
<a href="/search/cs?searchtype=author&query=Eicker%2C+U">Ursula Eicker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The hydrometric prediction of water quantity is useful for a variety of
applications, including water management, flood forecasting, and flood control.
However, the task is difficult due to the dynamic nature and limited data of
water systems. Highly interconnected water systems can significantly affect
hydrometric forecasting. Consequently, it is crucial to develop models that
represent the relationships between other system components. In recent years,
numerous hydrological applications have been studied, including streamflow
prediction, flood forecasting, and water quality prediction. Existing methods
are unable to model the influence of adjacent regions between pairs of
variables. In this paper, we propose a spatiotemporal forecasting model that
augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN)
encoder-decoder using an efficient version of the attention mechanism. The
attention layer allows the decoder to access different parts of the input
sequence selectively. Since water systems are interconnected and the
connectivity information between the stations is implicit, the proposed model
leverages a graph learning module to extract a sparse graph adjacency matrix
adaptively based on the data. Spatiotemporal forecasting relies on historical
data. In some regions, however, historical data may be limited or incomplete,
making it difficult to accurately predict future water conditions. Further, we
present a new benchmark dataset of water flow from a network of Canadian
stations on rivers, streams, and lakes. Experimental results demonstrate that
our proposed model TransGlow significantly outperforms baseline methods by a
wide margin.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05962" title="Abstract">arXiv:2312.05962</a> [<a href="/pdf/2312.05962" title="Download PDF">pdf</a>, <a href="/ps/2312.05962" title="Download PostScript">ps</a>, <a href="/format/2312.05962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aikyam: A Video Conferencing Utility for Deaf and Dumb
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+K">Kshitij Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Mashalkar%2C+V">Varad Mashalkar</a>, 
<a href="/search/cs?searchtype=author&query=Mhaisekar%2C+K">Kaustubh Mhaisekar</a>, 
<a href="/search/cs?searchtype=author&query=Naikwadi%2C+A">Amaan Naikwadi</a>, 
<a href="/search/cs?searchtype=author&query=Ghotkar%2C+A">Archana Ghotkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, accepted at the ICSCC, IEEE 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the advent of the pandemic, the use of video conferencing platforms as a
means of communication has greatly increased and with it, so have the remote
opportunities. The deaf and dumb have traditionally faced several issues in
communication, but now the effect is felt more severely. This paper proposes an
all-encompassing video conferencing utility that can be used with existing
video conferencing platforms to address these issues. Appropriate semantically
correct sentences are generated from the signer's gestures which would be
interpreted by the system. Along with an audio to emit this sentence, the
user's feed is also used to annotate the sentence. This can be viewed by all
participants, thus aiding smooth communication with all parties involved. This
utility utilizes a simple LSTM model for classification of gestures. The
sentences are constructed by a t5 based model. In order to achieve the required
data flow, a virtual camera is used.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05964" title="Abstract">arXiv:2312.05964</a> [<a href="/pdf/2312.05964" title="Download PDF">pdf</a>, <a href="/format/2312.05964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConSequence: Synthesizing Logically Constrained Sequences for Electronic  Health Record Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+B">Brandon Theodorou</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shrusti Jain</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Cao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Generative models can produce synthetic patient records for analytical tasks
when real data is unavailable or limited. However, current methods struggle
with adhering to domain-specific knowledge and removing invalid data. We
present ConSequence, an effective approach to integrating domain knowledge into
sequential generative neural network outputs. Our rule-based formulation
includes temporal aggregation and antecedent evaluation modules, ensured by an
efficient matrix multiplication formulation, to satisfy hard and soft logical
constraints across time steps. Existing constraint methods often fail to
guarantee constraint satisfaction, lack the ability to handle temporal
constraints, and hinder the learning and computational efficiency of the model.
In contrast, our approach efficiently handles all types of constraints with
guaranteed logical coherence. We demonstrate ConSequence's effectiveness in
generating electronic health records, outperforming competitors in achieving
complete temporal and spatial constraint satisfaction without compromising
runtime performance or generative quality. Specifically, ConSequence
successfully prevents all rule violations while improving the model quality in
reducing its test perplexity by 5% and incurring less than a 13% slowdown in
generation speed compared to an unconstrained model.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05966" title="Abstract">arXiv:2312.05966</a> [<a href="/pdf/2312.05966" title="Download PDF">pdf</a>, <a href="/format/2312.05966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake It Till Make It: Federated Learning with Consensus-Oriented  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yaxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhenyang Ni</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In federated learning (FL), data heterogeneity is one key bottleneck that
causes model divergence and limits performance. Addressing this, existing
methods often regard data heterogeneity as an inherent property and propose to
mitigate its adverse effects by correcting models. In this paper, we seek to
break this inherent property by generating data to complement the original
dataset to fundamentally mitigate heterogeneity level. As a novel attempt from
the perspective of data, we propose federated learning with consensus-oriented
generation (FedCOG). FedCOG consists of two key components at the client side:
complementary data generation, which generates data extracted from the shared
global model to complement the original dataset, and
knowledge-distillation-based model training, which distills knowledge from
global model to local model based on the generated data to mitigate
over-fitting the original heterogeneous dataset. FedCOG has two critical
advantages: 1) it can be a plug-and-play module to further improve the
performance of most existing FL methods, and 2) it is naturally compatible with
standard FL protocols such as Secure Aggregation since it makes no modification
in communication process. Extensive experiments on classical and real-world FL
datasets show that FedCOG consistently outperforms state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05968" title="Abstract">arXiv:2312.05968</a> [<a href="/pdf/2312.05968" title="Download PDF">pdf</a>, <a href="/format/2312.05968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jumpstarting Surgical Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alapatt%2C+D">Deepak Alapatt</a>, 
<a href="/search/cs?searchtype=author&query=Murali%2C+A">Aditya Murali</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+V">Vinkle Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Consortium%2C+A">AI4SafeChole Consortium</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Purpose: General consensus amongst researchers and industry points to a lack
of large, representative annotated datasets as the biggest obstacle to progress
in the field of surgical data science. Self-supervised learning represents a
solution to part of this problem, removing the reliance on annotations.
However, the robustness of current self-supervised learning methods to domain
shifts remains unclear, limiting our understanding of its utility for
leveraging diverse sources of surgical data. Methods: In this work, we employ
self-supervised learning to flexibly leverage diverse surgical datasets,
thereby learning taskagnostic representations that can be used for various
surgical downstream tasks. Based on this approach, to elucidate the impact of
pre-training on downstream task performance, we explore 22 different
pre-training dataset combinations by modulating three variables: source
hospital, type of surgical procedure, and pre-training scale (number of
videos). We then finetune the resulting model initializations on three diverse
downstream tasks: namely, phase recognition and critical view of safety in
laparoscopic cholecystectomy and phase recognition in laparoscopic
hysterectomy. Results: Controlled experimentation highlights sizable boosts in
performance across various tasks, datasets, and labeling budgets. However, this
performance is intricately linked to the composition of the pre-training
dataset, robustly proven through several study stages. Conclusion: The
composition of pre-training datasets can severely affect the effectiveness of
SSL methods for various downstream tasks and should critically inform future
data collection efforts to scale the application of SSL methodologies.
<br />Keywords: Self-Supervised Learning, Transfer Learning, Surgical Computer
Vision, Endoscopic Videos, Critical View of Safety, Phase Recognition
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05972" title="Abstract">arXiv:2312.05972</a> [<a href="/pdf/2312.05972" title="Download PDF">pdf</a>, <a href="/format/2312.05972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activating Frequency and ViT for 3D Point Cloud Quality Assessment  without Reference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Messai%2C+O">Oussama Messai</a>, 
<a href="/search/cs?searchtype=author&query=Bentamou%2C+A">Abdelouahid Bentamou</a>, 
<a href="/search/cs?searchtype=author&query=Zein-Eddine%2C+A">Abbass Zein-Eddine</a>, 
<a href="/search/cs?searchtype=author&query=Gavet%2C+Y">Yann Gavet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep learning-based quality assessments have significantly enhanced
perceptual multimedia quality assessment, however it is still in the early
stages for 3D visual data such as 3D point clouds (PCs). Due to the high volume
of 3D-PCs, such quantities are frequently compressed for transmission and
viewing, which may affect perceived quality. Therefore, we propose no-reference
quality metric of a given 3D-PC. Comparing to existing methods that mostly
focus on geometry or color aspects, we propose integrating frequency magnitudes
as indicator of spatial degradation patterns caused by the compression. To map
the input attributes to quality score, we use a light-weight hybrid deep model;
combined of Deformable Convolutional Network (DCN) and Vision Transformers
(ViT). Experiments are carried out on ICIP20 [1], PointXR [2] dataset, and a
new big dataset called BASICS [3]. The results show that our approach
outperforms state-of-the-art NR-PCQA measures and even some FR-PCQA on PointXR.
The implementation code can be found at: https://github.com/o-messai/3D-PCQA
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05974" title="Abstract">arXiv:2312.05974</a> [<a href="/pdf/2312.05974" title="Download PDF">pdf</a>, <a href="/format/2312.05974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Causal Structure of Networked Dynamical Systems under  Latent Nodes and Structured Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+A">Augusto Santos</a>, 
<a href="/search/cs?searchtype=author&query=Rente%2C+D">Diogo Rente</a>, 
<a href="/search/cs?searchtype=author&query=Seabra%2C+R">Rui Seabra</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J+M+F">Jos&#xe9; M. F. Moura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 38th AAAI Conference on Artificial Intelligence (Main Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">This paper considers learning the hidden causal network of a linear networked
dynamical system (NDS) from the time series data at some of its nodes --
partial observability. The dynamics of the NDS are driven by colored noise that
generates spurious associations across pairs of nodes, rendering the problem
much harder. To address the challenge of noise correlation and partial
observability, we assign to each pair of nodes a feature vector computed from
the time series data of observed nodes. The feature embedding is engineered to
yield structural consistency: there exists an affine hyperplane that
consistently partitions the set of features, separating the feature vectors
corresponding to connected pairs of nodes from those corresponding to
disconnected pairs. The causal inference problem is thus addressed via
clustering the designed features. We demonstrate with simple baseline
supervised methods the competitive performance of the proposed causal inference
mechanism under broad connectivity regimes and noise correlation levels,
including a real world network. Further, we devise novel technical guarantees
of structural consistency for linear NDS under the considered regime.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05975" title="Abstract">arXiv:2312.05975</a> [<a href="/pdf/2312.05975" title="Download PDF">pdf</a>, <a href="/format/2312.05975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FM-G-CAM: A Holistic Approach for Explainable AI in Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+R+S+R">Ravidu Suien Rammuni Silva</a>, 
<a href="/search/cs?searchtype=author&query=Bird%2C+J+J">Jordan J. Bird</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainability is an aspect of modern AI that is vital for impact and
usability in the real world. The main objective of this paper is to emphasise
the need to understand the predictions of Computer Vision models, specifically
Convolutional Neural Network (CNN) based models. Existing methods of explaining
CNN predictions are mostly based on Gradient-weighted Class Activation Maps
(Grad-CAM) and solely focus on a single target class. We show that from the
point of the target class selection, we make an assumption on the prediction
process, hence neglecting a large portion of the predictor CNN model's thinking
process. In this paper, we present an exhaustive methodology called Fused
Multi-class Gradient-weighted Class Activation Map (FM-G-CAM) that considers
multiple top predicted classes, which provides a holistic explanation of the
predictor CNN's thinking rationale. We also provide a detailed and
comprehensive mathematical and algorithmic description of our method.
Furthermore, along with a concise comparison of existing methods, we compare
FM-G-CAM with Grad-CAM, highlighting its benefits through real-world practical
use cases. Finally, we present an open-source Python library with FM-G-CAM
implementation to conveniently generate saliency maps for CNN-based model
predictions.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05976" title="Abstract">arXiv:2312.05976</a> [<a href="/pdf/2312.05976" title="Download PDF">pdf</a>, <a href="/format/2312.05976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Representative Study on Human Detection of Artificially Generated  Media Across Countries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frank%2C+J">Joel Frank</a>, 
<a href="/search/cs?searchtype=author&query=Herbert%2C+F">Franziska Herbert</a>, 
<a href="/search/cs?searchtype=author&query=Ricker%2C+J">Jonas Ricker</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nherr%2C+L">Lea Sch&#xf6;nherr</a>, 
<a href="/search/cs?searchtype=author&query=Eisenhofer%2C+T">Thorsten Eisenhofer</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+A">Asja Fischer</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCrmuth%2C+M">Markus D&#xfc;rmuth</a>, 
<a href="/search/cs?searchtype=author&query=Holz%2C+T">Thorsten Holz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Security and Privacy 2024 (S&amp;P 24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">AI-generated media has become a threat to our digital society as we know it.
These forgeries can be created automatically and on a large scale based on
publicly available technology. Recognizing this challenge, academics and
practitioners have proposed a multitude of automatic detection strategies to
detect such artificial media. However, in contrast to these technical advances,
the human perception of generated media has not been thoroughly studied yet.
<br />In this paper, we aim at closing this research gap. We perform the first
comprehensive survey into people's ability to detect generated media, spanning
three countries (USA, Germany, and China) with 3,002 participants across audio,
image, and text media. Our results indicate that state-of-the-art forgeries are
almost indistinguishable from "real" media, with the majority of participants
simply guessing when asked to rate them as human- or machine-generated. In
addition, AI-generated media receive is voted more human like across all media
types and all countries. To further understand which factors influence people's
ability to detect generated media, we include personal variables, chosen based
on a literature review in the domains of deepfake and fake news research. In a
regression analysis, we found that generalized trust, cognitive reflection, and
self-reported familiarity with deepfakes significantly influence participant's
decision across all media categories.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05978" title="Abstract">arXiv:2312.05978</a> [<a href="/pdf/2312.05978" title="Download PDF">pdf</a>, <a href="/format/2312.05978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Architecture Codesign for Fast Bragg Peak Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDermott%2C+L">Luke McDermott</a>, 
<a href="/search/cs?searchtype=author&query=Weitz%2C+J">Jason Weitz</a>, 
<a href="/search/cs?searchtype=author&query=Demler%2C+D">Dmitri Demler</a>, 
<a href="/search/cs?searchtype=author&query=Cummings%2C+D">Daniel Cummings</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N">Nhan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We develop an automated pipeline to streamline neural architecture codesign
for fast, real-time Bragg peak analysis in high-energy diffraction microscopy.
Traditional approaches, notably pseudo-Voigt fitting, demand significant
computational resources, prompting interest in deep learning models for more
efficient solutions. Our method employs neural architecture search and AutoML
to enhance these models, including hardware costs, leading to the discovery of
more hardware-efficient neural architectures. Our results match the
performance, while achieving a 13$\times$ reduction in bit operations compared
to the previous state-of-the-art. We show further speedup through model
compression techniques such as quantization-aware-training and neural network
pruning. Additionally, our hierarchical search space provides greater
flexibility in optimization, which can easily extend to other tasks and
domains.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05979" title="Abstract">arXiv:2312.05979</a> [<a href="/pdf/2312.05979" title="Download PDF">pdf</a>, <a href="/format/2312.05979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=West%2C+P">Peter West</a>, 
<a href="/search/cs?searchtype=author&query=Bras%2C+R+L">Ronan Le Bras</a>, 
<a href="/search/cs?searchtype=author&query=Sorensen%2C+T">Taylor Sorensen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K">Khyathi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Baheti%2C+A">Ashutosh Baheti</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present NovaCOMET, an open commonsense knowledge model, that combines the
best aspects of knowledge and general task models. Compared to previous
knowledge models, NovaCOMET allows open-format relations enabling direct
application to reasoning tasks; compared to general task models like Flan-T5,
it explicitly centers knowledge, enabling superior performance for commonsense
reasoning.
<br />NovaCOMET leverages the knowledge of opaque proprietary models to create an
open knowledge pipeline. First, knowledge is symbolically distilled into
NovATOMIC, a publicly-released discrete knowledge graph which can be audited,
critiqued, and filtered. Next, we train NovaCOMET on NovATOMIC by fine-tuning
an open-source pretrained model. NovaCOMET uses an open-format training
objective, replacing the fixed relation sets of past knowledge models, enabling
arbitrary structures within the data to serve as inputs or outputs.
<br />The resulting generation model, optionally augmented with human annotation,
matches or exceeds comparable open task models like Flan-T5 on a range of
commonsense generation tasks. NovaCOMET serves as a counterexample to the
contemporary focus on instruction tuning only, demonstrating a distinct
advantage to explicitly modeling commonsense knowledge as well.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05984" title="Abstract">arXiv:2312.05984</a> [<a href="/pdf/2312.05984" title="Download PDF">pdf</a>, <a href="/format/2312.05984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Differential Operators for Hybrid Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chetan%2C+A">Aditya Chetan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guandao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Marschner%2C+S">Steve Marschner</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural fields have become widely used in various fields, from shape
representation to neural rendering, and for solving partial differential
equations (PDEs). With the advent of hybrid neural field representations like
Instant NGP that leverage small MLPs and explicit representations, these models
train quickly and can fit large scenes. Yet in many applications like rendering
and simulation, hybrid neural fields can cause noticeable and unreasonable
artifacts. This is because they do not yield accurate spatial derivatives
needed for these downstream applications. In this work, we propose two ways to
circumvent these challenges. Our first approach is a post hoc operator that
uses local polynomial-fitting to obtain more accurate derivatives from
pre-trained hybrid neural fields. Additionally, we also propose a
self-supervised fine-tuning approach that refines the neural field to yield
accurate derivatives directly while preserving the initial signal. We show the
application of our method on rendering, collision simulation, and solving PDEs.
We observe that using our approach yields more accurate derivatives, reducing
artifacts and leading to more accurate simulations in downstream applications.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05987" title="Abstract">arXiv:2312.05987</a> [<a href="/pdf/2312.05987" title="Download PDF">pdf</a>, <a href="/format/2312.05987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delaunay Triangulations in the Hilbert Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gezalyan%2C+A">Auguste Gezalyan</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Soo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+C">Carlos Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Skora%2C+D">Daniel Skora</a>, 
<a href="/search/cs?searchtype=author&query=Stefankovic%2C+Z">Zofia Stefankovic</a>, 
<a href="/search/cs?searchtype=author&query=Mount%2C+D+M">David M. Mount</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The Hilbert metric is a distance function defined for points lying within the
interior of a convex body. It arises in the analysis and processing of convex
bodies, machine learning, and quantum information theory. In this paper, we
show how to adapt the Euclidean Delaunay triangulation to the Hilbert geometry
defined by a convex polygon in the plane. We analyze the geometric properties
of the Hilbert Delaunay triangulation, which has some notable differences with
respect to the Euclidean case, including the fact that the triangulation does
not necessarily cover the convex hull of the point set. We also introduce the
notion of a Hilbert ball at infinity, which is a Hilbert metric ball centered
on the boundary of the convex polygon. We present a simple randomized
incremental algorithm that computes the Hilbert Delaunay triangulation for a
set of $n$ points in the Hilbert geometry defined by a convex $m$-gon. The
algorithm runs in $O(n (\log n + \log^3 m))$ expected time. In addition we
introduce the notion of the Hilbert hull of a set of points, which we define to
be the region covered by their Hilbert Delaunay triangulation. We present an
algorithm for computing the Hilbert hull in time $O(n h \log^2 m)$, where $h$
is the number of points on the hull's boundary.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05988" title="Abstract">arXiv:2312.05988</a> [<a href="/pdf/2312.05988" title="Download PDF">pdf</a>, <a href="/ps/2312.05988" title="Download PostScript">ps</a>, <a href="/format/2312.05988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Interaction Modalities for Human-CPS Interaction in Construction  Progress Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halder%2C+S">Srijeet Halder</a>, 
<a href="/search/cs?searchtype=author&query=Afsari%2C+K">Kereshmeh Afsari</a>, 
<a href="/search/cs?searchtype=author&query=Shojaei%2C+A">Alireza Shojaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This article explores natural interaction modalities for human-cyber-physical
systems (CPS) interaction in construction. CPS has been applied in construction
for many purposes with the promise of improving the safety and productivity of
construction operations. However, there is little research on human-CPS
interaction in construction. This study proposes two methodologies for
human-CPS interactions for construction progress monitoring - a) hand gesture
interaction using transfer learning, and b) voice command interaction using
natural language processing. User studies with thirty-two users validated the
generalizability of the proposed methodologies. The proposed hand gesture
recognition method achieved higher accuracy (99.69% vs 87.72%) and speed
(36.05ms vs 578.91ms) than the proposed voice command recognition method,
though users performed the progress monitoring task more correctly with voice
commands than hand gestures (88% vs 66.1%). The main contribution of the study
is the development of an ML pipeline and computational framework to recognize
hand gestures and voice commands without the need for a large training dataset
for human-CPS interaction.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05989" title="Abstract">arXiv:2312.05989</a> [<a href="/pdf/2312.05989" title="Download PDF">pdf</a>, <a href="/format/2312.05989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on the Convergence of Denoising Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mbacke%2C+S+D">Sokhna Diarra Mbacke</a>, 
<a href="/search/cs?searchtype=author&query=Rivasplata%2C+O">Omar Rivasplata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Diffusion models are one of the most important families of deep generative
models. In this note, we derive a quantitative upper bound on the Wasserstein
distance between the data-generating distribution and the distribution learned
by a diffusion model. Unlike previous works in this field, our result does not
make assumptions on the learned score function. Moreover, our bound holds for
arbitrary data-generating distributions on bounded instance spaces, even those
without a density w.r.t. the Lebesgue measure, and the upper bound does not
suffer from exponential dependencies. Our main result builds upon the recent
work of Mbacke et al. (2023) and our proofs are elementary.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05990" title="Abstract">arXiv:2312.05990</a> [<a href="/pdf/2312.05990" title="Download PDF">pdf</a>, <a href="/ps/2312.05990" title="Download PostScript">ps</a>, <a href="/format/2312.05990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Vec-tionaries to Extract Latent Message Features from  Texts: A Case Study of Moral Appeals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zening Duan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+A">Anqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yicheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Heysung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xining Liao</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y+J">Yoo Ji Suh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai-Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaiping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sijia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While communication research frequently studies latent message features like
moral appeals, their quantification remains a challenge. Conventional human
coding struggles with scalability and intercoder reliability. While
dictionary-based methods are cost-effective and computationally efficient, they
often lack contextual sensitivity and are limited by the vocabularies developed
for the original applications. In this paper, we present a novel approach to
construct vec-tionary measurement tools that boost validated dictionaries with
word embeddings through nonlinear optimization. By harnessing semantic
relationships encoded by embeddings, vec-tionaries improve the measurement of
latent message features by expanding the applicability of original vocabularies
to other contexts. Vec-tionaries can also help extract semantic information
from texts, especially those in short format, beyond the original vocabulary of
a dictionary. Importantly, a vec-tionary can produce additional metrics to
capture the valence and ambivalence of a latent feature beyond its strength in
texts. Using moral appeals in COVID-19-related tweets as a case study, we
illustrate the steps to construct the moral foundations vec-tionary, showcasing
its ability to process posts missed by dictionary methods and to produce
measurements better aligned with crowdsourced human assessments. Furthermore,
additional metrics from the moral foundations vec-tionary unveiled unique
insights that facilitated predicting outcomes such as message retransmission.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05991" title="Abstract">arXiv:2312.05991</a> [<a href="/pdf/2312.05991" title="Download PDF">pdf</a>, <a href="/format/2312.05991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modifying RL Policies with Imagined Actions: How Predictable Policies  Can Enable Users to Perform Novel Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheidlower%2C+I">Isaac Sheidlower</a>, 
<a href="/search/cs?searchtype=author&query=Aronson%2C+R">Reuben Aronson</a>, 
<a href="/search/cs?searchtype=author&query=Short%2C+E">Elaine Short</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print to be published in the AAAI Fall Symposium 2023 Proceedings (part of the AI-HRI Symposium)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">It is crucial that users are empowered to use the functionalities of a robot
to creatively solve problems on the fly. A user who has access to a
Reinforcement Learning (RL) based robot may want to use the robot's autonomy
and their knowledge of its behavior to complete new tasks. One way is for the
user to take control of some of the robot's action space through teleoperation
while the RL policy simultaneously controls the rest. However, an
out-of-the-box RL policy may not readily facilitate this. For example, a user's
control may bring the robot into a failure state from the policy's perspective,
causing it to act in a way the user is not familiar with, hindering the success
of the user's desired task. In this work, we formalize this problem and present
Imaginary Out-of-Distribution Actions, IODA, an initial algorithm for
addressing that problem and empowering user's to leverage their expectation of
a robot's behavior to accomplish new tasks.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05994" title="Abstract">arXiv:2312.05994</a> [<a href="/pdf/2312.05994" title="Download PDF">pdf</a>, <a href="/format/2312.05994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mir_ref: A Representation Evaluation Framework for Music Information  Retrieval Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plachouras%2C+C">Christos Plachouras</a>, 
<a href="/search/cs?searchtype=author&query=Alonson-Jim%C3%A9nez%2C+P">Pablo Alonson-Jim&#xe9;nez</a>, 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+D">Dmitry Bogdanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Audio Workshop, Neural Information Processing Systems (NeurIPS) 2023, New Orleans, LA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music Information Retrieval (MIR) research is increasingly leveraging
representation learning to obtain more compact, powerful music audio
representations for various downstream MIR tasks. However, current
representation evaluation methods are fragmented due to discrepancies in audio
and label preprocessing, downstream model and metric implementations, data
availability, and computational resources, often leading to inconsistent and
limited results. In this work, we introduce mir_ref, an MIR Representation
Evaluation Framework focused on seamless, transparent, local-first experiment
orchestration to support representation development. It features
implementations of a variety of components such as MIR datasets, tasks,
embedding models, and tools for result analysis and visualization, while
facilitating the implementation of custom components. To demonstrate its
utility, we use it to conduct an extensive evaluation of several embedding
models across various tasks and datasets, including evaluating their robustness
to various audio perturbations and the ease of extracting relevant information
from them.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05995" title="Abstract">arXiv:2312.05995</a> [<a href="/pdf/2312.05995" title="Download PDF">pdf</a>, <a href="/format/2312.05995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Correspondences to Pose: Non-minimal Certifiably Optimal Relative  Pose without Disambiguation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tirado-Gar%C3%ADn%2C+J">Javier Tirado-Gar&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Estimating the relative camera pose from $n \geq 5$ correspondences between
two calibrated views is a fundamental task in computer vision. This process
typically involves two stages: 1) estimating the essential matrix between the
views, and 2) disambiguating among the four candidate relative poses that
satisfy the epipolar geometry. In this paper, we demonstrate a novel approach
that, for the first time, bypasses the second stage. Specifically, we show that
it is possible to directly estimate the correct relative camera pose from
correspondences without needing a post-processing step to enforce the
cheirality constraint on the correspondences. Building on recent advances in
certifiable non-minimal optimization, we frame the relative pose estimation as
a Quadratically Constrained Quadratic Program (QCQP). By applying the
appropriate constraints, we ensure the estimation of a camera pose that
corresponds to a valid 3D geometry and that is globally optimal when certified.
We validate our method through exhaustive synthetic and real-world experiments,
confirming the efficacy, efficiency and accuracy of the proposed approach. Code
is available at https://github.com/javrtg/C2P.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06001" title="Abstract">arXiv:2312.06001</a> [<a href="/pdf/2312.06001" title="Download PDF">pdf</a>, <a href="/format/2312.06001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The SyGuS Language Standard Version 2.1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padhi%2C+S">Saswat Padhi</a>, 
<a href="/search/cs?searchtype=author&query=Polgreen%2C+E">Elizabeth Polgreen</a>, 
<a href="/search/cs?searchtype=author&query=Raghothaman%2C+M">Mukund Raghothaman</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+A">Andrew Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Udupa%2C+A">Abhishek Udupa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, introduced in the SYNT workshop at CAV 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The classical formulation of the program-synthesis problem is to find a
program that meets a correctness specification given as a logical formula.
Syntax-guided synthesis (SyGuS) is a standardized format for specifying the
correctness specification with a syntactic template that constrains the space
of allowed implementations.
<br />The input to SyGuS consists of a background theory, a semantic correctness
specification for the desired program given by a logical formula, and a
syntactic set of candidate implementations given by a grammar. The
computational problem then is to find an implementation from the set of
candidate expressions that satisfies the specification in the given theory. The
formulation of the problem builds on SMT-LIB.
<br />This document defines the SyGuS 2.1 standard, which is intended to be used as
the standard input and output language for solvers targeting the syntax-guided
synthesis problem. It borrows many concepts and language constructs from the
standard format for Satisfiability Modulo Theories (SMT) solvers, the SMT-LIB
2.6 standard.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06002" title="Abstract">arXiv:2312.06002</a> [<a href="/pdf/2312.06002" title="Download PDF">pdf</a>, <a href="/format/2312.06002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models on Lexical Semantic Change Detection: An  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Matthew Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Lexical Semantic Change Detection stands out as one of the few areas where
Large Language Models (LLMs) have not been extensively involved. Traditional
methods like PPMI, and SGNS remain prevalent in research, alongside newer
BERT-based approaches. Despite the comprehensive coverage of various natural
language processing domains by LLMs, there is a notable scarcity of literature
concerning their application in this specific realm. In this work, we seek to
bridge this gap by introducing LLMs into the domain of Lexical Semantic Change
Detection. Our work presents novel prompting solutions and a comprehensive
evaluation that spans all three generations of language models, contributing to
the exploration of LLMs in this research area.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06004" title="Abstract">arXiv:2312.06004</a> [<a href="/pdf/2312.06004" title="Download PDF">pdf</a>, <a href="/format/2312.06004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplier Optimization via E-Graph Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wanna%2C+A">Andy Wanna</a> (1), 
<a href="/search/cs?searchtype=author&query=Coward%2C+S">Samuel Coward</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Drane%2C+T">Theo Drane</a> (2), 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a> (1), 
<a href="/search/cs?searchtype=author&query=Ercegovac%2C+M+D">Milo&#x161; D. Ercegovac</a> (3) ((1) Imperial College London, (2) Intel Corporation (3) University of California Los Angeles)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for work presented at the 2023 Asilomar Conference on Signals, Systems and Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Multiplier circuits account for significant resource usage in
datapath-dominated circuit designs, and RTL designers continue to build bespoke
hand-crafted multiplication arrays for their particular application. The
construction of an optimized multiplier presents trade-offs between
pre-processing to generate a smaller array and array reduction. A data
structure known as an e-graph has recently been applied to datapath
optimization, where the e-graph's ability to efficiently explore trade-offs has
been shown to be crucial. We propose an e-graph based rewriting framework to
construct optimized multiplier circuits. Such a framework can express
alternative multiplier representations and generate customized circuit designs.
We demonstrate that the proposed tool, which we call OptiMult, can reduce the
latency of a squarer by up to 46% and reduce the latency of a standard
multiplier by up to 9% when compared against logic synthesis instantiated
components.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06005" title="Abstract">arXiv:2312.06005</a> [<a href="/pdf/2312.06005" title="Download PDF">pdf</a>, <a href="/format/2312.06005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software issues report for bug fixing process: An empirical study of  machine-learning libraries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajibode%2C+A">Adekunle Ajibode</a>, 
<a href="/search/cs?searchtype=author&query=Yunwei%2C+D">Dong Yunwei</a>, 
<a href="/search/cs?searchtype=author&query=Hongji%2C+Y">Yang Hongji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Issue resolution and bug-fixing processes are essential in the development of
machine-learning libraries, similar to software development, to ensure
well-optimized functions. Understanding the issue resolution and bug-fixing
process of machine-learning libraries can help developers identify areas for
improvement and optimize their strategies for issue resolution and bug-fixing.
However, detailed studies on this topic are lacking. Therefore, we investigated
the effectiveness of issue resolution for bug-fixing processes in six
machine-learning libraries: Tensorflow, Keras, Theano, Pytorch, Caffe, and
Scikit-learn. We addressed seven research questions (RQs) using 16,921 issues
extracted from the GitHub repository via the GitHub Rest API. We employed
several quantitative methods of data analysis, including correlation, OLS
regression, percentage and frequency count, and heatmap to analyze the RQs. We
found the following through our empirical investigation: (1) The most common
categories of issues that arise in machine-learning libraries are bugs,
documentation, optimization, crashes, enhancement, new feature requests,
build/CI, support, and performance. (2) Effective strategies for addressing
these problems include fixing critical bugs, optimizing performance, and
improving documentation. (3) These categorized issues are related to testing
and runtime and are common among all six machine-learning libraries. (4)
Monitoring the total number of comments on issues can provide insights into the
duration of the issues. (5) It is crucial to strike a balance between
prioritizing critical issues and addressing other issues in a timely manner.
Therefore, this study concludes that efficient issue-tracking processes,
effective communication, and collaboration are vital for effective resolution
of issues and bug fixing processes in machine-learning libraries.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06008" title="Abstract">arXiv:2312.06008</a> [<a href="/pdf/2312.06008" title="Download PDF">pdf</a>, <a href="/ps/2312.06008" title="Download PostScript">ps</a>, <a href="/format/2312.06008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guardians of Trust: Navigating Data Security in AIOps through Vendor  Partnerships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Subhadip Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Intelligence for IT Operations (AIOps) is a rapidly growing field
that applies artificial intelligence and machine learning to automate and
optimize IT operations. AIOps vendors provide services that ingest end-to-end
logs, traces, and metrics to offer a full stack observability of IT systems.
However, these data sources may contain sensitive information such as internal
IP addresses, hostnames, HTTP headers, SQLs, method/argument return values,
URLs, personal identifiable information (PII), or confidential business data.
Therefore, data security is a crucial concern when working with AIOps vendors.
In this article, we will discuss the security features offered by different
vendors and how we can adopt best practices to ensure data protection and
privacy.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06010" title="Abstract">arXiv:2312.06010</a> [<a href="/pdf/2312.06010" title="Download PDF">pdf</a>, <a href="/format/2312.06010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Survey on Emerging Threats from AI-driven Voice Attacks: How  Vulnerable are Commercial Voice Control Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiben Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+N">Nikolay Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The emergence of Artificial Intelligence (AI)-driven audio attacks has
revealed new security vulnerabilities in voice control systems. While
researchers have introduced a multitude of attack strategies targeting voice
control systems (VCS), the continual advancements of VCS have diminished the
impact of many such attacks. Recognizing this dynamic landscape, our study
endeavors to comprehensively assess the resilience of commercial voice control
systems against a spectrum of malicious audio attacks. Through extensive
experimentation, we evaluate six prominent attack techniques across a
collection of voice control interfaces and devices. Contrary to prevailing
narratives, our results suggest that commercial voice control systems exhibit
enhanced resistance to existing threats. Particularly, our research highlights
the ineffectiveness of white-box attacks in black-box scenarios. Furthermore,
the adversaries encounter substantial obstacles in obtaining precise gradient
estimations during query-based interactions with commercial systems, such as
Apple Siri and Samsung Bixby. Meanwhile, we find that current defense
strategies are not completely immune to advanced attacks. Our findings
contribute valuable insights for enhancing defense mechanisms in VCS. Through
this survey, we aim to raise awareness within the academic community about the
security concerns of VCS and advocate for continued research in this crucial
area.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06021" title="Abstract">arXiv:2312.06021</a> [<a href="/pdf/2312.06021" title="Download PDF">pdf</a>, <a href="/format/2312.06021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenDepth: Generalizing Monocular Depth Estimation for Arbitrary Camera  Parameters via Ground Plane Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koledi%C4%87%2C+K">Karlo Koledi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Petrovi%C4%87%2C+L">Luka Petrovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Petrovi%C4%87%2C+I">Ivan Petrovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Markovi%C4%87%2C+I">Ivan Markovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Learning-based monocular depth estimation leverages geometric priors present
in the training data to enable metric depth perception from a single image, a
traditionally ill-posed problem. However, these priors are often specific to a
particular domain, leading to limited generalization performance on unseen
data. Apart from the well studied environmental domain gap, monocular depth
estimation is also sensitive to the domain gap induced by varying camera
parameters, an aspect that is often overlooked in current state-of-the-art
approaches. This issue is particularly evident in autonomous driving scenarios,
where datasets are typically collected with a single vehicle-camera setup,
leading to a bias in the training data due to a fixed perspective geometry. In
this paper, we challenge this trend and introduce GenDepth, a novel model
capable of performing metric depth estimation for arbitrary vehicle-camera
setups. To address the lack of data with sufficiently diverse camera
parameters, we first create a bespoke synthetic dataset collected with
different vehicle-camera systems. Then, we design GenDepth to simultaneously
optimize two objectives: (i) equivariance to the camera parameter variations on
synthetic data, (ii) transferring the learned equivariance to real-world
environmental features using a single real-world dataset with a fixed
vehicle-camera system. To achieve this, we propose a novel embedding of camera
parameters as the ground plane depth and present a novel architecture that
integrates these embeddings with adversarial domain alignment. We validate
GenDepth on several autonomous driving datasets, demonstrating its
state-of-the-art generalization capability for different vehicle-camera
systems.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06022" title="Abstract">arXiv:2312.06022</a> [<a href="/pdf/2312.06022" title="Download PDF">pdf</a>, <a href="/format/2312.06022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Representation Bias for Data Distillation in Abstractive Text  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atri%2C+Y+K">Yash Kumar Atri</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vikram Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Abstractive text summarization is surging with the number of training samples
to cater to the needs of the deep learning models. These models tend to exploit
the training data representations to attain superior performance by improving
the quantitative element of the resultant summary. However, increasing the size
of the training set may not always be the ideal solution to maximize the
performance, and therefore, a need to revisit the quality of training samples
and the learning protocol of deep learning models is a must. In this paper, we
aim to discretize the vector space of the abstractive text summarization models
to understand the characteristics learned between the input embedding space and
the models' encoder space. We show that deep models fail to capture the
diversity of the input space. Further, the distribution of data points on the
encoder space indicates that an unchecked increase in the training samples does
not add value; rather, a tear-down of data samples is highly needed to make the
models focus on variability and faithfulness. We employ clustering techniques
to learn the diversity of a model's sample space and how data points are mapped
from the embedding space to the encoder space and vice versa. Further, we
devise a metric to filter out redundant data points to make the model more
robust and less data hungry. We benchmark our proposed method using
quantitative metrics, such as Rouge, and qualitative metrics, such as
BERTScore, FEQA and Pyramid score. We also quantify the reasons that inhibit
the models from learning the diversity from the varied input samples.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06024" title="Abstract">arXiv:2312.06024</a> [<a href="/pdf/2312.06024" title="Download PDF">pdf</a>, <a href="/format/2312.06024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thinking Assistants: LLM-Based Conversational Assistants that Help Users  Think By Asking rather than Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Soya Park</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+C">Chinmay Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We introduce the concept of "thinking assistants", an approach that
encourages users to engage in deep reflection and critical thinking through
brainstorming and thought-provoking queries. We instantiate one such thinking
assistant, Gradschool.chat, as a virtual assistant tailored to assist
prospective graduate students. We posit that thinking assistants are
particularly relevant to situations like applying to graduate school, a phase
often characterized by the challenges of academic preparation and the
development of a unique research identity. In such situations, students often
lack direct mentorship from professors, or may feel hesitant to approach
faculty with their queries, making thinking assistants particularly useful.
<br />Leveraging a Large Language Model (LLM), Gradschool.chat is a demonstration
system built as a thinking assistant for working with specific professors in
the field of human-computer interaction (HCI). It was designed through training
on information specific to these professors and a validation processes in
collaboration with these academics. This technical report delineates the
system's architecture and offers a preliminary analysis of our deployment
study. Additionally, this report covers the spectrum of questions posed to our
chatbots by users. The system recorded 223 conversations, with participants
responding positively to approximately 65% of responses. Our findings indicate
that users who discuss and brainstorm their research interests with
Gradschool.chat engage more deeply, often interacting with the chatbot twice as
long compared to those who only pose questions about professors.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06029" title="Abstract">arXiv:2312.06029</a> [<a href="/pdf/2312.06029" title="Download PDF">pdf</a>, <a href="/ps/2312.06029" title="Download PostScript">ps</a>, <a href="/format/2312.06029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Classification of Large Time Series Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuad%2C+M+M+M">Muhammad Marwan Muhammad Fuad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series classification (TSC) is the most import task in time series
mining as it has several applications in medicine, meteorology, finance cyber
security, and many others. With the ever increasing size of time series
datasets, several traditional TSC methods are no longer efficient enough to
perform this task on such very large datasets. Yet, most recent papers on TSC
focus mainly on accuracy by using methods that apply deep learning, for
instance, which require extensive computational resources that cannot be
applied efficiently to very large datasets. The method we introduce in this
paper focuses on these very large time series datasets with the main objective
being efficiency. We achieve this through a simplified representation of the
time series. This in turn is enhanced by a distance measure that considers only
some of the values of the represented time series. The result of this
combination is a very efficient representation method for TSC. This has been
tested experimentally against another time series method that is particularly
popular for its efficiency. The experiments show that our method is not only 4
times faster, on average, but it is also superior in terms of classification
accuracy, as it gives better results on 24 out of the 29 tested time series
datasets. .
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06032" title="Abstract">arXiv:2312.06032</a> [<a href="/pdf/2312.06032" title="Download PDF">pdf</a>, <a href="/format/2312.06032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Utility of Model Explanations for Model Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Shawn Im</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yilun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06033" title="Abstract">arXiv:2312.06033</a> [<a href="/pdf/2312.06033" title="Download PDF">pdf</a>, <a href="/ps/2312.06033" title="Download PostScript">ps</a>, <a href="/format/2312.06033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of Multiuser Multiple-Antenna Wireless Communications Systems  Based on Super-Resolution Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinto%2C+S">S. Pinto</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures, 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This work studies multiple-antenna wireless communication systems based on
super-resolution arrays (SRAs). We consider the uplink of a multiple-antenna
system in which users communicate with a multiple-antenna base station equipped
with SRAs. In particular, we develop linear minimum mean-square error (MMSE)
receive filters along with linear and successive interference cancellation
receivers for processing signals with the difference co-array originating from
the SRAs. We then derive analytical expressions to assess the achievable
sum-rates associated with the proposed multiple-antenna systems with SRAs.
Simulations show that the proposed multiple-antenna systems with SRAs
outperform existing systems with standard arrays that have a larger number of
antenna elements.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06034" title="Abstract">arXiv:2312.06034</a> [<a href="/pdf/2312.06034" title="Download PDF">pdf</a>, <a href="/format/2312.06034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Uncertainty in Personalized Emotion Prediction with Normalizing  Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%C5%82kowski%2C+P">Piotr Mi&#x142;kowski</a>, 
<a href="/search/cs?searchtype=author&query=Karanowski%2C+K">Konrad Karanowski</a>, 
<a href="/search/cs?searchtype=author&query=Wielopolski%2C+P">Patryk Wielopolski</a>, 
<a href="/search/cs?searchtype=author&query=Koco%C5%84%2C+J">Jan Koco&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=Kazienko%2C+P">Przemys&#x142;aw Kazienko</a>, 
<a href="/search/cs?searchtype=author&query=Zi%C4%99ba%2C+M">Maciej Zi&#x119;ba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, SENTIRE'23 (ICDM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Designing predictive models for subjective problems in natural language
processing (NLP) remains challenging. This is mainly due to its
non-deterministic nature and different perceptions of the content by different
humans. It may be solved by Personalized Natural Language Processing (PNLP),
where the model exploits additional information about the reader to make more
accurate predictions. However, current approaches require complete information
about the recipients to be straight embedded. Besides, the recent methods focus
on deterministic inference or simple frequency-based estimations of the
probabilities. In this work, we overcome this limitation by proposing a novel
approach to capture the uncertainty of the forecast using conditional
Normalizing Flows. This allows us to model complex multimodal distributions and
to compare various models using negative log-likelihood (NLL). In addition, the
new solution allows for various interpretations of possible reader perception
thanks to the available sampling function. We validated our method on three
challenging, subjective NLP tasks, including emotion recognition and hate
speech. The comparative analysis of generalized and personalized approaches
revealed that our personalized solutions significantly outperform the baseline
and provide more precise uncertainty estimates. The impact on the text
interpretability and uncertainty studies are presented as well. The information
brought by the developed methods makes it possible to build hybrid models whose
effectiveness surpasses classic solutions. In addition, an analysis and
visualization of the probabilities of the given decisions for texts with high
entropy of annotations and annotators with mixed views were carried out.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06036" title="Abstract">arXiv:2312.06036</a> [<a href="/pdf/2312.06036" title="Download PDF">pdf</a>, <a href="/format/2312.06036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Competitions and Benchmarks: How to ensure a long-lasting impact of a  challenge with post-challenge paper, benchmarks and other dissemination  action
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marot%2C+A">Antoine Marot</a>, 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+D">David Rousseau</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhen Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5th chapter of book "AI Competitions and Benchmarks: the science behind the contests" see: <a href="https://sites.google.com/chalearn.">this https URL</a> org/book/home
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Organising an AI challenge does not end with the final event. The
long-lasting impact also needs to be organised. This chapter covers the various
activities after the challenge is formally finished. The target audience of
different post-challenge activities is identified. The various outputs of the
challenge are listed with the means to collect them. The main part of the
chapter is a template for a typical post-challenge paper, including possible
graphs as well as advice on how to turn the challenge into a long-lasting
benchmark.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06037" title="Abstract">arXiv:2312.06037</a> [<a href="/pdf/2312.06037" title="Download PDF">pdf</a>, <a href="/format/2312.06037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality of AI for Education: Towards Artificial General  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lehong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yizhu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bewersdorf%2C+A">Arne Bewersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Nyaaba%2C+M">Matthew Nyaaba</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shuchen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+G">Gengchen Mai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper presents a comprehensive examination of how multimodal artificial
intelligence (AI) approaches are paving the way towards the realization of
Artificial General Intelligence (AGI) in educational contexts. It scrutinizes
the evolution and integration of AI in educational systems, emphasizing the
crucial role of multimodality, which encompasses auditory, visual, kinesthetic,
and linguistic modes of learning. This research delves deeply into the key
facets of AGI, including cognitive frameworks, advanced knowledge
representation, adaptive learning mechanisms, strategic planning, sophisticated
language processing, and the integration of diverse multimodal data sources. It
critically assesses AGI's transformative potential in reshaping educational
paradigms, focusing on enhancing teaching and learning effectiveness, filling
gaps in existing methodologies, and addressing ethical considerations and
responsible usage of AGI in educational settings. The paper also discusses the
implications of multimodal AI's role in education, offering insights into
future directions and challenges in AGI development. This exploration aims to
provide a nuanced understanding of the intersection between AI, multimodality,
and education, setting a foundation for future research and development in AGI.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06038" title="Abstract">arXiv:2312.06038</a> [<a href="/pdf/2312.06038" title="Download PDF">pdf</a>, <a href="/format/2312.06038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting Diffusion Generation through Resampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite diffusion models' superior capabilities in modeling complex
distributions, there are still non-trivial distributional discrepancies between
generated and ground-truth images, which has resulted in several notable
problems in image generation, including missing object errors in text-to-image
generation and low image quality. Existing methods that attempt to address
these problems mostly do not tend to address the fundamental cause behind these
problems, which is the distributional discrepancies, and hence achieve
sub-optimal results. In this paper, we propose a particle filtering framework
that can effectively address both problems by explicitly reducing the
distributional discrepancies. Specifically, our method relies on a set of
external guidance, including a small set of real images and a pre-trained
object detector, to gauge the distribution gap, and then design the resampling
weight accordingly to correct the gap. Experiments show that our methods can
effectively correct missing object errors and improve image quality in various
image generation tasks. Notably, our method outperforms the existing strongest
baseline by 5% in object occurrence and 1.0 in FID on MS-COCO. Our code is
publicly available at
https://github.com/UCSB-NLP-Chang/diffusion_resampling.git.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06039" title="Abstract">arXiv:2312.06039</a> [<a href="/pdf/2312.06039" title="Download PDF">pdf</a>, <a href="/format/2312.06039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singularly Perturbed Layered Control of Deformable Bodies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Molu%2C+L">Lekan Molu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Variable curvature modeling tools provide an accurate means of controlling
infinite degrees-of-freedom deformable bodies and structures. However, their
forward and inverse Newton-Euler dynamics are fraught with high computational
costs. Assuming piecewise constant strains across discretized Cosserat rods
imposed on the soft material, a composite two time-scale singularly perturbed
nonlinear backstepping control scheme is here introduced. This is to alleviate
the long computational times of the recursive Newton-Euler dynamics for soft
structures. Our contribution is three-pronged: (i) we decompose the system's
Newton-Euler dynamics to a two coupled sub-dynamics by introducing a
perturbation parameter; (ii) we then prescribe a set of stabilizing controllers
for regulating each subsystem's dynamics; and (iii) we study the interconnected
singularly perturbed system and analyze its stability.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06049" title="Abstract">arXiv:2312.06049</a> [<a href="/pdf/2312.06049" title="Download PDF">pdf</a>, <a href="/format/2312.06049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSPNet: Scale and Spatial Priors Guided Generalizable and Interpretable  Pedestrian Attribute Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jifeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Teng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+X">Xin Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wankou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 11 figures, Accepted by Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Global feature based Pedestrian Attribute Recognition (PAR) models are often
poorly localized when using Grad-CAM for attribute response analysis, which has
a significant impact on the interpretability, generalizability and performance.
Previous researches have attempted to improve generalization and interpretation
through meticulous model design, yet they often have neglected or underutilized
effective prior information crucial for PAR. To this end, a novel Scale and
Spatial Priors Guided Network (SSPNet) is proposed for PAR, which is mainly
composed of the Adaptive Feature Scale Selection (AFSS) and Prior Location
Extraction (PLE) modules. The AFSS module learns to provide reasonable scale
prior information for different attribute groups, allowing the model to focus
on different levels of feature maps with varying semantic granularity. The PLE
module reveals potential attribute spatial prior information, which avoids
unnecessary attention on irrelevant areas and lowers the risk of model
over-fitting. More specifically, the scale prior in AFSS is adaptively learned
from different layers of feature pyramid with maximum accuracy, while the
spatial priors in PLE can be revealed from part feature with different
granularity (such as image blocks, human pose keypoint and sparse sampling
points). Besides, a novel IoU based attribute localization metric is proposed
for Weakly-supervised Pedestrian Attribute Localization (WPAL) based on the
improved Grad-CAM for attribute response mask. The experimental results on the
intra-dataset and cross-dataset evaluations demonstrate the effectiveness of
our proposed method in terms of mean accuracy (mA). Furthermore, it also
achieves superior performance on the PCS dataset for attribute localization in
terms of IoU. Code will be released at https://github.com/guotengg/SSPNet.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06050" title="Abstract">arXiv:2312.06050</a> [<a href="/pdf/2312.06050" title="Download PDF">pdf</a>, <a href="/format/2312.06050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Multilinear Principal Component Analysis with Applications in  Prognostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuqi Su</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tangbin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiaolei Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multilinear Principal Component Analysis (MPCA) is a widely utilized method
for the dimension reduction of tensor data. However, the integration of MPCA
into federated learning remains unexplored in existing research. To tackle this
gap, this article proposes a Federated Multilinear Principal Component Analysis
(FMPCA) method, which enables multiple users to collaboratively reduce the
dimension of their tensor data while keeping each user's data local and
confidential. The proposed FMPCA method is guaranteed to have the same
performance as traditional MPCA. An application of the proposed FMPCA in
industrial prognostics is also demonstrated. Simulated data and a real-world
data set are used to validate the performance of the proposed method.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06052" title="Abstract">arXiv:2312.06052</a> [<a href="/pdf/2312.06052" title="Download PDF">pdf</a>, <a href="/format/2312.06052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaskConver: Revisiting Pure Convolution Model for Panoptic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashwan%2C+A">Abdullah Rashwan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiageng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Taalimi%2C+A">Ali Taalimi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chaochao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang-Chieh Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yeqing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, transformer-based models have dominated panoptic
segmentation, thanks to their strong modeling capabilities and their unified
representation for both semantic and instance classes as global binary masks.
In this paper, we revisit pure convolution model and propose a novel panoptic
architecture named MaskConver. MaskConver proposes to fully unify things and
stuff representation by predicting their centers. To that extent, it creates a
lightweight class embedding module that can break the ties when multiple
centers co-exist in the same location. Furthermore, our study shows that the
decoder design is critical in ensuring that the model has sufficient context
for accurate detection and segmentation. We introduce a powerful ConvNeXt-UNet
decoder that closes the performance gap between convolution- and
transformerbased models. With ResNet50 backbone, our MaskConver achieves 53.6%
PQ on the COCO panoptic val set, outperforming the modern convolution-based
model, Panoptic FCN, by 9.3% as well as transformer-based models such as
Mask2Former (+1.7% PQ) and kMaX-DeepLab (+0.6% PQ). Additionally, MaskConver
with a MobileNet backbone reaches 37.2% PQ, improving over Panoptic-DeepLab by
+6.4% under the same FLOPs/latency constraints. A further optimized version of
MaskConver achieves 29.7% PQ, while running in real-time on mobile devices. The
code and model weights will be publicly available
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06053" title="Abstract">arXiv:2312.06053</a> [<a href="/pdf/2312.06053" title="Download PDF">pdf</a>, <a href="/format/2312.06053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K+T">Kellen Tan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Nanniyur%2C+S+V">Srihari Venkat Nanniyur</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S">Suma Bhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Idiomatic expression (IE) processing and comprehension have challenged
pre-trained language models (PTLMs) because their meanings are
non-compositional. Unlike prior works that enable IE comprehension through
fine-tuning PTLMs with sentences containing IEs, in this work, we construct
IEKG, a commonsense knowledge graph for figurative interpretations of IEs. This
extends the established ATOMIC2020 graph, converting PTLMs into knowledge
models (KMs) that encode and infer commonsense knowledge related to IE use.
Experiments show that various PTLMs can be converted into KMs with IEKG. We
verify the quality of IEKG and the ability of the trained KMs with automatic
and human evaluation. Through applications in natural language understanding,
we show that a PTLM injected with knowledge from IEKG exhibits improved IE
comprehension ability and can generalize to IEs unseen during training.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06055" title="Abstract">arXiv:2312.06055</a> [<a href="/pdf/2312.06055" title="Download PDF">pdf</a>, <a href="/format/2312.06055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker-Text Retrieval via Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuechen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+E">Erica Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xiaoxiao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Yamagishi%2C+J">Junichi Yamagishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Signal Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this study, we introduce a novel cross-modal retrieval task involving
speaker descriptions and their corresponding audio samples. Utilizing
pre-trained speaker and text encoders, we present a simple learning framework
based on contrastive learning. Additionally, we explore the impact of
incorporating speaker labels into the training process. Our findings establish
the effectiveness of linking speaker and text information for the task for both
English and Japanese languages, across diverse data configurations. Additional
visual analysis unveils potential nuanced associations between speaker
clustering and retrieval performance.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06056" title="Abstract">arXiv:2312.06056</a> [<a href="/pdf/2312.06056" title="Download PDF">pdf</a>, <a href="/format/2312.06056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> METAL: Metamorphic Testing Framework for Analyzing Large-Language Model  Qualities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyun%2C+S">Sangwon Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+M+A">M. Ali Babar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to International Conference on Software Testing, Verification and Validation (ICST) 2024 / Key words: Large-language models, Metamorphic testing, Quality evaluation, Text perturbations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large-Language Models (LLMs) have shifted the paradigm of natural language
data processing. However, their black-boxed and probabilistic characteristics
can lead to potential risks in the quality of outputs in diverse LLM
applications. Recent studies have tested Quality Attributes (QAs), such as
robustness or fairness, of LLMs by generating adversarial input texts. However,
existing studies have limited their coverage of QAs and tasks in LLMs and are
difficult to extend. Additionally, these studies have only used one evaluation
metric, Attack Success Rate (ASR), to assess the effectiveness of their
approaches. We propose a MEtamorphic Testing for Analyzing LLMs (METAL)
framework to address these issues by applying Metamorphic Testing (MT)
techniques. This approach facilitates the systematic testing of LLM qualities
by defining Metamorphic Relations (MRs), which serve as modularized evaluation
metrics. The METAL framework can automatically generate hundreds of MRs from
templates that cover various QAs and tasks. In addition, we introduced novel
metrics that integrate the ASR method into the semantic qualities of text to
assess the effectiveness of MRs accurately. Through the experiments conducted
with three prominent LLMs, we have confirmed that the METAL framework
effectively evaluates essential QAs on primary LLM tasks and reveals the
quality risks in LLMs. Moreover, the newly proposed metrics can guide the
optimal MRs for testing each task and suggest the most effective method for
generating MRs.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06059" title="Abstract">arXiv:2312.06059</a> [<a href="/pdf/2312.06059" title="Download PDF">pdf</a>, <a href="/format/2312.06059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CONFORM: Contrast is All You Need For High-Fidelity Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meral%2C+T+H+S">Tuna Han Salih Meral</a>, 
<a href="/search/cs?searchtype=author&query=Simsar%2C+E">Enis Simsar</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Yanardag%2C+P">Pinar Yanardag</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Images produced by text-to-image diffusion models might not always faithfully
represent the semantic intent of the provided text prompt, where the model
might overlook or entirely fail to produce certain objects. Existing solutions
often require customly tailored functions for each of these problems, leading
to sub-optimal results, especially for complex prompts. Our work introduces a
novel perspective by tackling this challenge in a contrastive context. Our
approach intuitively promotes the segregation of objects in attention maps
while also maintaining that pairs of related attributes are kept close to each
other. We conduct extensive experiments across a wide variety of scenarios,
each involving unique combinations of objects, attributes, and scenes. These
experiments effectively showcase the versatility, efficiency, and flexibility
of our method in working with both latent and pixel-based diffusion models,
including Stable Diffusion and Imagen. Moreover, we publicly share our source
code to facilitate further research.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06060" title="Abstract">arXiv:2312.06060</a> [<a href="/pdf/2312.06060" title="Download PDF">pdf</a>, <a href="/ps/2312.06060" title="Download PostScript">ps</a>, <a href="/format/2312.06060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Time-History Analysis of Soil-Structure Systems Incorporating  Frequency-Dependent Impedance Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghahari%2C+S+F">S. Farid Ghahari</a>, 
<a href="/search/cs?searchtype=author&query=Ghofrani%2C+A">Alborz Ghofrani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Taciroglu%2C+E">Ertugrul Taciroglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">To accurately analyze structures, soil-structure interaction effects must be
taken into account. One approach is to create a complete finite element model
of the full system wherein the soil is represented as a semi-infinite domain.
This direct method is frequently adopted in research studies, but it is
typically avoided in engineering practice due to the labor-intensive model
development, and the high computational cost. In practice, soil-structure
interaction analysis is mostly carried out through a substructure approach
where the superstructure is modeled through a detailed model and is placed on a
soil-foundation substructure which is represented by a system called impedance
function. Then, the entire system is analyzed under foundation input motions.
While the method is theoretically designed for linear-elastic behavior, it can
be partially applied to nonlinear systems too. Although impedance functions for
various soil and foundation configurations can be obtained from analytical,
numerical, or experimental analyses, their implementation in the time-domain is
not trivial because they are frequency-dependent. A simple solution for this
problem has been to convert them to some physical models with
frequency-independent components, but there is no straightforward way to
connect these components. More importantly, the coefficients of these
components could be non-physical parameters that cannot be modeled in software
like OpenSEES. To resolve these problems, various alternative approaches have
been proposed in the literature. In this project, we review some of the
existing solutions and verify them through numerical examples. After extensive
review and evaluation, the Hybrid Time Frequency Domain method seems a more
practical solution with fewer stability issues. This method is implemented in
Opensees to be used by researchers and practitioners.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06063" title="Abstract">arXiv:2312.06063</a> [<a href="/pdf/2312.06063" title="Download PDF">pdf</a>, <a href="/format/2312.06063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCRDiffusion: Diffusion Probabilistic Models for Point Cloud  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yongzhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaolong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Maoguo Gong</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Q">Qiguang Miao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a new framework that formulates point cloud registration as a
denoising diffusion process from noisy transformation to object transformation.
During training stage, object transformation diffuses from ground-truth
transformation to random distribution, and the model learns to reverse this
noising process. In sampling stage, the model refines randomly generated
transformation to the output result in a progressive way. We derive the
variational bound in closed form for training and provide implementations of
the model. Our work provides the following crucial findings: (i) In contrast to
most existing methods, our framework, Diffusion Probabilistic Models for Point
Cloud Registration (PCRDiffusion) does not require repeatedly update source
point cloud to refine the predicted transformation. (ii) Point cloud
registration, one of the representative discriminative tasks, can be solved by
a generative way and the unified probabilistic formulation. Finally, we discuss
and provide an outlook on the application of diffusion model in different
scenarios for point cloud registration. Experimental results demonstrate that
our model achieves competitive performance in point cloud registration. In
correspondence-free and correspondence-based scenarios, PCRDifussion can both
achieve exceeding 50\% performance improvements.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06068" title="Abstract">arXiv:2312.06068</a> [<a href="/pdf/2312.06068" title="Download PDF">pdf</a>, <a href="/format/2312.06068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Multi-view Subspace Clustering of Hyperspectral Images based  on Graph Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+R">Renxiang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianju Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruyi Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">High-dimensional and complex spectral structures make the clustering of
hyperspectral images (HSI) a challenging task. Subspace clustering is an
effective approach for addressing this problem. However, current subspace
clustering algorithms are primarily designed for a single view and do not fully
exploit the spatial or textural feature information in HSI. In this study,
contrastive multi-view subspace clustering of HSI was proposed based on graph
convolutional networks. Pixel neighbor textural and spatial-spectral
information were sent to construct two graph convolutional subspaces to learn
their affinity matrices. To maximize the interaction between different views, a
contrastive learning algorithm was introduced to promote the consistency of
positive samples and assist the model in extracting robust features. An
attention-based fusion module was used to adaptively integrate these affinity
matrices, constructing a more discriminative affinity matrix. The model was
evaluated using four popular HSI datasets: Indian Pines, Pavia University,
Houston, and Xu Zhou. It achieved overall accuracies of 97.61%, 96.69%, 87.21%,
and 97.65%, respectively, and significantly outperformed state-of-the-art
clustering methods. In conclusion, the proposed model effectively improves the
clustering accuracy of HSI.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06069" title="Abstract">arXiv:2312.06069</a> [<a href="/pdf/2312.06069" title="Download PDF">pdf</a>, <a href="/format/2312.06069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *These authors contributed equally. Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Obtaining large-scale radiology reports can be difficult for medical images
due to various reasons, limiting the effectiveness of contrastive pre-training
in the medical image domain and underscoring the need for alternative methods.
In this paper, we propose eye-tracking as an alternative to text reports, as it
allows for the passive collection of gaze signals without disturbing
radiologist's routine diagnosis process. By tracking the gaze of radiologists
as they read and diagnose medical images, we can understand their visual
attention and clinical reasoning. When a radiologist has similar gazes for two
medical images, it may indicate semantic similarity for diagnosis, and these
images should be treated as positive pairs when pre-training a
computer-assisted diagnosis (CAD) network through contrastive learning.
Accordingly, we introduce the Medical contrastive Gaze Image Pre-training
(McGIP) as a plug-and-play module for contrastive learning frameworks. McGIP
uses radiologist's gaze to guide contrastive pre-training. We evaluate our
method using two representative types of medical images and two common types of
gaze data. The experimental results demonstrate the practicality of McGIP,
indicating its high potential for various clinical scenarios and applications.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06071" title="Abstract">arXiv:2312.06071</a> [<a href="/pdf/2312.06071" title="Download PDF">pdf</a>, <a href="/format/2312.06071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Precipitation Downscaling with Optical Flow-Guided  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+P">Prakhar Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruihan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kerrigan%2C+G">Gavin Kerrigan</a>, 
<a href="/search/cs?searchtype=author&query=Dresdner%2C+G">Gideon Dresdner</a>, 
<a href="/search/cs?searchtype=author&query=McGibbon%2C+J">Jeremy McGibbon</a>, 
<a href="/search/cs?searchtype=author&query=Bretherton%2C+C">Christopher Bretherton</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">In climate science and meteorology, local precipitation predictions are
limited by the immense computational costs induced by the high spatial
resolution that simulation methods require. A common workaround is statistical
downscaling (aka superresolution), where a low-resolution prediction is
super-resolved using statistical approaches. While traditional computer vision
tasks mainly focus on human perception or mean squared error, applications in
weather and climate require capturing the conditional distribution of
high-resolution patterns given low-resolution patterns so that reliable
ensemble averages can be taken. Our approach relies on extending recent video
diffusion models to precipitation superresolution: an optical flow on the
high-resolution output induces temporally coherent predictions, whereas a
temporally-conditioned diffusion model generates residuals that capture the
correct noise characteristics and high-frequency patterns. We test our approach
on X-SHiELD, an established large-scale climate simulation dataset, and compare
against two state-of-the-art baselines, focusing on CRPS, MSE, precipitation
distributions, as well as an illustrative case -- the complex terrain of
California. Our approach sets a new standard for data-driven precipitation
downscaling.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06072" title="Abstract">arXiv:2312.06072</a> [<a href="/pdf/2312.06072" title="Download PDF">pdf</a>, <a href="/format/2312.06072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A dynamic interactive learning framework for automated 3D medical image  segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Mu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Many deep learning based automated medical image segmentation systems, in
reality, face difficulties in deployment due to the cost of massive data
annotation and high latency in model iteration. We propose a dynamic
interactive learning framework that addresses these challenges by integrating
interactive segmentation into end-to-end weak supervised learning with
streaming tasks. We develop novel replay and label smoothing schemes that
overcome catastrophic forgetting and improve online learning robustness. For
each image, our multi-round interactive segmentation module simultaneously
optimizes both front-end predictions and deep learning segmenter. In each
round, a 3D "proxy mask" is propagated from sparse user inputs based on image
registration, serving as weak supervision that enable knowledge distillation
from the unknown ground truth. In return, the trained segmenter explicitly
guides next step's user interventions according to a spatial residual map from
consecutive front or back-end predictions. Evaluation on 3D segmentation tasks
(NCI-ISBI2013 and BraTS2015) shows that our framework generates online learning
performances that match offline training benchmark. In addition, with a 62%
reduction in total annotation efforts, our framework produces competitive dice
scores comparing to online and offline learning which equipped with full ground
truth. Furthermore, such a framework, with its flexibility and responsiveness,
could be deployed behind hospital firewall that guarantees data security and
easy maintenance.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06074" title="Abstract">arXiv:2312.06074</a> [<a href="/pdf/2312.06074" title="Download PDF">pdf</a>, <a href="/ps/2312.06074" title="Download PostScript">ps</a>, <a href="/format/2312.06074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Vision for Operationalising Diversity and Inclusion in AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bano%2C+M">Muneera Bano</a>, 
<a href="/search/cs?searchtype=author&query=Zowghi%2C+D">Didar Zowghi</a>, 
<a href="/search/cs?searchtype=author&query=Gervasi%2C+V">Vincenzo Gervasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The growing presence of Artificial Intelligence (AI) in various sectors
necessitates systems that accurately reflect societal diversity. This study
seeks to envision the operationalization of the ethical imperatives of
diversity and inclusion (D&amp;I) within AI ecosystems, addressing the current
disconnect between ethical guidelines and their practical implementation. A
significant challenge in AI development is the effective operationalization of
D&amp;I principles, which is critical to prevent the reinforcement of existing
biases and ensure equity across AI applications. This paper proposes a vision
of a framework for developing a tool utilizing persona-based simulation by
Generative AI (GenAI). The approach aims to facilitate the representation of
the needs of diverse users in the requirements analysis process for AI
software. The proposed framework is expected to lead to a comprehensive persona
repository with diverse attributes that inform the development process with
detailed user narratives. This research contributes to the development of an
inclusive AI paradigm that ensures future technological advances are designed
with a commitment to the diverse fabric of humanity.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06075" title="Abstract">arXiv:2312.06075</a> [<a href="/pdf/2312.06075" title="Download PDF">pdf</a>, <a href="/format/2312.06075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oracle Character Recognition using Unsupervised Discriminative  Consistency Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Sen Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ancient history relies on the study of ancient characters. However,
real-world scanned oracle characters are difficult to collect and annotate,
posing a major obstacle for oracle character recognition (OrCR). Besides,
serious abrasion and inter-class similarity also make OrCR more challenging. In
this paper, we propose a novel unsupervised domain adaptation method for OrCR,
which enables to transfer knowledge from labeled handprinted oracle characters
to unlabeled scanned data. We leverage pseudo-labeling to incorporate the
semantic information into adaptation and constrain augmentation consistency to
make the predictions of scanned samples consistent under different
perturbations, leading to the model robustness to abrasion, stain and
distortion. Simultaneously, an unsupervised transition loss is proposed to
learn more discriminative features on the scanned domain by optimizing both
between-class and within-class transition probability. Extensive experiments
show that our approach achieves state-of-the-art result on Oracle-241 dataset
and substantially outperforms the recently proposed structure-texture
separation network by 15.1%.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06077" title="Abstract">arXiv:2312.06077</a> [<a href="/pdf/2312.06077" title="Download PDF">pdf</a>, <a href="/format/2312.06077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ambiguity Measure for Recognizing the Unknowns in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousefzadeh%2C+R">Roozbeh Yousefzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the understanding of deep neural networks from the scope in which
they are trained on. While the accuracy of these models is usually impressive
on the aggregate level, they still make mistakes, sometimes on cases that
appear to be trivial. Moreover, these models are not reliable in realizing what
they do not know leading to failures such as adversarial vulnerability and
out-of-distribution failures. Here, we propose a measure for quantifying the
ambiguity of inputs for any given model with regard to the scope of its
training. We define the ambiguity based on the geometric arrangements of the
decision boundaries and the convex hull of training set in the feature space
learned by the trained model, and demonstrate that a single ambiguity measure
may detect a considerable portion of mistakes of a model on in-distribution
samples, adversarial inputs, as well as out-of-distribution inputs. Using our
ambiguity measure, a model may abstain from classification when it encounters
ambiguous inputs leading to a better model accuracy not just on a given testing
set, but on the inputs it may encounter at the world at large. In pursuit of
this measure, we develop a theoretical framework that can identify the unknowns
of the model in relation to its scope. We put this in perspective with the
confidence of the model and develop formulations to identify the regions of the
domain which are unknown to the model, yet the model is guaranteed to have high
confidence.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06080" title="Abstract">arXiv:2312.06080</a> [<a href="/pdf/2312.06080" title="Download PDF">pdf</a>, <a href="/format/2312.06080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Prediction-Traversal Approach for Compressing Scientific Data on  Unstructured Meshes with Bounded Error
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Congrong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hanqi Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We explore an error-bounded lossy compression approach for reducing
scientific data associated with 2D/3D unstructured meshes. While existing lossy
compressors offer a high compression ratio with bounded error for regular grid
data, methodologies tailored for unstructured mesh data are lacking; for
example, one can compress nodal data as 1D arrays, neglecting the spatial
coherency of the mesh nodes. Inspired by the SZ compressor, which predicts and
quantizes values in a multidimensional array, we dynamically reorganize nodal
data into sequences. Each sequence starts with a seed cell; based on a
predefined traversal order, the next cell is added to the sequence if the
current cell can predict and quantize the nodal data in the next cell with the
given error bound. As a result, one can efficiently compress the quantized
nodal data in each sequence until all mesh nodes are traversed. This paper also
introduces a suite of novel error metrics, namely continuous mean squared error
(CMSE) and continuous peak signal-to-noise ratio (CPSNR), to assess compression
results for unstructured mesh data. The continuous error metrics are defined by
integrating the error function on all cells, providing objective statistics
across nonuniformly distributed nodes/cells in the mesh. We evaluate our
methods with several scientific simulations ranging from ocean-climate models
and computational fluid dynamics simulations with both traditional and
continuous error metrics. We demonstrated superior compression ratios and
quality than existing lossy compressors.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06082" title="Abstract">arXiv:2312.06082</a> [<a href="/pdf/2312.06082" title="Download PDF">pdf</a>, <a href="/format/2312.06082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAI meets Biology: A Comprehensive Review of Explainable AI in  Bioinformatics Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhongliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengxuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Salcedo%2C+M">Mariah Salcedo</a>, 
<a href="/search/cs?searchtype=author&query=Gravel%2C+N">Nathan Gravel</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+W">Wayland Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Venkat%2C+A">Aarya Venkat</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jielu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+N">Natarajan Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Artificial intelligence (AI), particularly machine learning and deep learning
models, has significantly impacted bioinformatics research by offering powerful
tools for analyzing complex biological data. However, the lack of
interpretability and transparency of these models presents challenges in
leveraging these models for deeper biological insights and for generating
testable hypotheses. Explainable AI (XAI) has emerged as a promising solution
to enhance the transparency and interpretability of AI models in
bioinformatics. This review provides a comprehensive analysis of various XAI
techniques and their applications across various bioinformatics domains
including DNA, RNA, and protein sequence analysis, structural analysis, gene
expression and genome analysis, and bioimaging analysis. We introduce the most
pertinent machine learning and XAI methods, then discuss their diverse
applications and address the current limitations of available XAI tools. By
offering insights into XAI's potential and challenges, this review aims to
facilitate its practical implementation in bioinformatics research and help
researchers navigate the landscape of XAI tools.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06085" title="Abstract">arXiv:2312.06085</a> [<a href="/pdf/2312.06085" title="Download PDF">pdf</a>, <a href="/format/2312.06085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Geometry and Reflectance Disentanglement for 3D Face  Reconstruction from Sparse-view Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Daisheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiangbei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel two-stage approach for reconstructing human faces
from sparse-view images, a task made challenging by the unique geometry and
complex skin reflectance of each individual. Our method focuses on decomposing
key facial attributes, including geometry, diffuse reflectance, and specular
reflectance, from ambient light. Initially, we create a general facial template
from a diverse collection of individual faces, capturing essential geometric
and reflectance characteristics. Guided by this template, we refine each
specific face model in the second stage, which further considers the
interaction between geometry and reflectance, as well as the subsurface
scattering effects on facial skin. Our method enables the reconstruction of
high-quality facial representations from as few as three images, offering
improved geometric accuracy and reflectance detail. Through comprehensive
evaluations and comparisons, our method demonstrates superiority over existing
techniques. Our method effectively disentangles geometry and reflectance
components, leading to enhanced quality in synthesizing new views and opening
up possibilities for applications such as relighting and reflectance editing.
We will make the code publicly available.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06086" title="Abstract">arXiv:2312.06086</a> [<a href="/pdf/2312.06086" title="Download PDF">pdf</a>, <a href="/format/2312.06086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HALO-CAT: A Hidden Network Processor with Activation-Localized CIM  Architecture and Layer-Penetrative Tiling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yung-Chin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ando%2C+S">Shimpei Ando</a>, 
<a href="/search/cs?searchtype=author&query=Fujiki%2C+D">Daichi Fujiki</a>, 
<a href="/search/cs?searchtype=author&query=Takamaeda-Yamazaki%2C+S">Shinya Takamaeda-Yamazaki</a>, 
<a href="/search/cs?searchtype=author&query=Yoshioka%2C+K">Kentaro Yoshioka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">To address the 'memory wall' problem in NN hardware acceleration, we
introduce HALO-CAT, a software-hardware co-design optimized for Hidden Neural
Network (HNN) processing. HALO-CAT integrates Layer-Penetrative Tiling (LPT)
for algorithmic efficiency, reducing intermediate result sizes. Furthermore,
the architecture employs an activation-localized computing-in-memory approach
to minimize data movement. This design significantly enhances energy
efficiency, achieving a 14.2x reduction in activation memory capacity and a
17.8x decrease in energy consumption, with only a 1.5% loss in accuracy,
compared to traditional HNN processors.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06087" title="Abstract">arXiv:2312.06087</a> [<a href="/pdf/2312.06087" title="Download PDF">pdf</a>, <a href="/format/2312.06087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex-valued Neural Networks -- Theory and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdalla%2C+R">Rayyan Abdalla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)

</div>
<p class="mathjax">Complex-valued neural networks (CVNNs) have recently been successful in
various pioneering areas which involve wave-typed information and
frequency-domain processing. This work addresses different structures and
classification of CVNNs. The theory behind complex activation functions,
implications related to complex differentiability and special activations for
CVNN output layers are presented. The work also discusses CVNN learning and
optimization using gradient and non-gradient based algorithms. Complex
Backpropagation utilizing complex chain rule is also explained in terms of
Wirtinger calculus. Moreover, special modules for building CVNN models, such as
complex batch normalization and complex random initialization are also
discussed. The work also highlights libraries and software blocks proposed for
CVNN implementations and discusses future directions. The objective of this
work is to understand the dynamics and most recent developments of CVNNs.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06088" title="Abstract">arXiv:2312.06088</a> [<a href="/pdf/2312.06088" title="Download PDF">pdf</a>, <a href="/format/2312.06088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SECNN: Squeeze-and-Excitation Convolutional Neural Network for Sentence  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shandong Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4pages,3figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentence classification is one of the basic tasks of natural language
processing. Convolution neural network (CNN) has the ability to extract n-grams
features through convolutional filters and capture local correlations between
consecutive words in parallel, so CNN is a popular neural network architecture
to dealing with the task. But restricted by the width of convolutional filters,
it is difficult for CNN to capture long term contextual dependencies. Attention
is a mechanism that considers global information and pays more attention to
keywords in sentences, thus attention mechanism is cooperated with CNN network
to improve performance in sentence classification task. In our work, we don't
focus on keyword in a sentence, but on which CNN's output feature map is more
important. We propose a Squeeze-and-Excitation Convolutional neural Network
(SECNN) for sentence classification. SECNN takes the feature maps from multiple
CNN as different channels of sentence representation, and then, we can utilize
channel attention mechanism, that is SE attention mechanism, to enable the
model to learn the attention weights of different channel features. The results
show that our model achieves advanced performance in the sentence
classification task.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06089" title="Abstract">arXiv:2312.06089</a> [<a href="/pdf/2312.06089" title="Download PDF">pdf</a>, <a href="/format/2312.06089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TabMT: Generating tabular data with masked transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gulati%2C+M+S">Manbir S Gulati</a>, 
<a href="/search/cs?searchtype=author&query=Roysdon%2C+P+F">Paul F Roysdon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (<a href="https://openreview.net/forum?id=qs4swxtIAQ">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Autoregressive and Masked Transformers are incredibly effective as generative
models and classifiers. While these models are most prevalent in NLP, they also
exhibit strong performance in other domains, such as vision. This work
contributes to the exploration of transformer-based models in synthetic data
generation for diverse application domains. In this paper, we present TabMT, a
novel Masked Transformer design for generating synthetic tabular data. TabMT
effectively addresses the unique challenges posed by heterogeneous data fields
and is natively able to handle missing data. Our design leverages improved
masking techniques to allow for generation and demonstrates state-of-the-art
performance from extremely small to extremely large tabular datasets. We
evaluate TabMT for privacy-focused applications and find that it is able to
generate high quality data with superior privacy tradeoffs.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06091" title="Abstract">arXiv:2312.06091</a> [<a href="/pdf/2312.06091" title="Download PDF">pdf</a>, <a href="/format/2312.06091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Unknown Intervention Targets in Structural Causal Models from  Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Salehkaleybar%2C+S">Saber Salehkaleybar</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of identifying the unknown intervention targets in
structural causal models where we have access to heterogeneous data collected
from multiple environments. The unknown intervention targets are the set of
endogenous variables whose corresponding exogenous noises change across the
environments. We propose a two-phase approach which in the first phase recovers
the exogenous noises corresponding to unknown intervention targets whose
distributions have changed across environments. In the second phase, the
recovered noises are matched with the corresponding endogenous variables. For
the recovery phase, we provide sufficient conditions for learning these
exogenous noises up to some component-wise invertible transformation. For the
matching phase, under the causal sufficiency assumption, we show that the
proposed method uniquely identifies the intervention targets. In the presence
of latent confounders, the intervention targets among the observed variables
cannot be determined uniquely. We provide a candidate intervention target set
which is a superset of the true intervention targets. Our approach improves
upon the state of the art as the returned candidate set is always a subset of
the target set returned by previous work. Moreover, we do not require
restrictive assumptions such as linearity of the causal model or performing
invariance tests to learn whether a distribution is changing across
environments which could be highly sample inefficient. Our experimental results
show the effectiveness of our proposed algorithm in practice.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06093" title="Abstract">arXiv:2312.06093</a> [<a href="/pdf/2312.06093" title="Download PDF">pdf</a>, <a href="/format/2312.06093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prakash%2C+N">Nirmalendu Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N+K">Nguyen Khoi Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Hee%2C+M+S">Ming Shan Hee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+K">Roy Ka-Wei Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Multimedia'23 Research Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">The proliferation of social media has given rise to a new form of
communication: memes. Memes are multimodal and often contain a combination of
text and visual elements that convey meaning, humor, and cultural significance.
While meme analysis has been an active area of research, little work has been
done on unsupervised multimodal topic modeling of memes, which is important for
content moderation, social media analysis, and cultural studies. We propose
\textsf{PromptMTopic}, a novel multimodal prompt-based model designed to learn
topics from both text and visual modalities by leveraging the language modeling
capabilities of large language models. Our model effectively extracts and
clusters topics learned from memes, considering the semantic interaction
between the text and visual modalities. We evaluate our proposed model through
extensive experiments on three real-world meme datasets, which demonstrate its
superiority over state-of-the-art topic modeling baselines in learning
descriptive topics in memes. Additionally, our qualitative analysis shows that
\textsf{PromptMTopic} can identify meaningful and culturally relevant topics
from memes. Our work contributes to the understanding of the topics and themes
of memes, a crucial form of communication in today's society.\\
\red{\textbf{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}}
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06094" title="Abstract">arXiv:2312.06094</a> [<a href="/pdf/2312.06094" title="Download PDF">pdf</a>, <a href="/format/2312.06094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MATK: The Meme Analytical Tool Kit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hee%2C+M+S">Ming Shan Hee</a>, 
<a href="/search/cs?searchtype=author&query=Kumaresan%2C+A">Aditi Kumaresan</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N+K">Nguyen Khoi Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+N">Nirmalendu Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Rui Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+K">Roy Ka-Wei Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Multimedia'23 Open-Source Software Competition Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">The rise of social media platforms has brought about a new digital culture
called memes. Memes, which combine visuals and text, can strongly influence
public opinions on social and cultural issues. As a result, people have become
interested in categorizing memes, leading to the development of various
datasets and multimodal models that show promising results in this field.
However, there is currently a lack of a single library that allows for the
reproduction, evaluation, and comparison of these models using fair benchmarks
and settings. To fill this gap, we introduce the Meme Analytical Tool Kit
(MATK), an open-source toolkit specifically designed to support existing memes
datasets and cutting-edge multimodal models. MATK aims to assist researchers
and engineers in training and reproducing these multimodal models for meme
classification tasks, while also providing analysis techniques to gain insights
into their strengths and weaknesses. To access MATK, please visit
\url{https://github.com/Social-AI-Studio/MATK}.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06099" title="Abstract">arXiv:2312.06099</a> [<a href="/pdf/2312.06099" title="Download PDF">pdf</a>, <a href="/ps/2312.06099" title="Download PostScript">ps</a>, <a href="/format/2312.06099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Large Language Models Are All-purpose Text Analytics Engines:  Text-to-text Learning Is All Your Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zehao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+E">Kaleb E Smith</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+A+B">Anthony B Costa</a>, 
<a href="/search/cs?searchtype=author&query=Flores%2C+M+G">Mona G Flores</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yonghui Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Objective To solve major clinical natural language processing (NLP) tasks
using a unified text-to-text learning architecture based on a generative large
language model (LLM) via prompt tuning. Methods We formulated 7 key clinical
NLP tasks as text-to-text learning and solved them using one unified generative
clinical LLM, GatorTronGPT, developed using GPT-3 architecture and trained with
up to 20 billion parameters. We adopted soft prompts (i.e., trainable vectors)
with frozen LLM, where the LLM parameters were not updated (i.e., frozen) and
only the vectors of soft prompts were updated, known as prompt tuning. We added
additional soft prompts as a prefix to the input layer, which were optimized
during the prompt tuning. We evaluated the proposed method using 7 clinical NLP
tasks and compared them with previous task-specific solutions based on
Transformer models. Results and Conclusion The proposed approach achieved
state-of-the-art performance for 5 out of 7 major clinical NLP tasks using one
unified generative LLM. Our approach outperformed previous task-specific
transformer models by ~3% for concept extraction and 7% for relation extraction
applied to social determinants of health, 3.4% for clinical concept
normalization, 3.4~10% for clinical abbreviation disambiguation, and 5.5~9% for
natural language inference. Our approach also outperformed a previously
developed prompt-based machine reading comprehension (MRC) model,
GatorTron-MRC, for clinical concept and relation extraction. The proposed
approach can deliver the ``one model for all`` promise from training to
deployment using a unified generative LLM.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06103" title="Abstract">arXiv:2312.06103</a> [<a href="/pdf/2312.06103" title="Download PDF">pdf</a>, <a href="/ps/2312.06103" title="Download PostScript">ps</a>, <a href="/format/2312.06103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Formalization of Monadic Equational Reasoning in  Dependent-type Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Affeldt%2C+R">Reynald Affeldt</a>, 
<a href="/search/cs?searchtype=author&query=Garrigue%2C+J">Jacques Garrigue</a>, 
<a href="/search/cs?searchtype=author&query=Saikawa%2C+T">Takafumi Saikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">One can perform equational reasoning about computational effects with a
purely functional programming language thanks to monads. Even though equational
reasoning for effectful programs is desirable, it is not yet mainstream. This
is partly because it is difficult to maintain pencil-and-paper proofs of large
examples. We propose a formalization of a hierarchy of effects using monads in
the Coq proof assistant that makes monadic equational reasoning practical. Our
main idea is to formalize the hierarchy of effects and algebraic laws as
interfaces like it is done when formalizing hierarchy of algebras in dependent
type theory. Thanks to this approach, we clearly separate equational laws from
models. We can then take advantage of the sophisticated rewriting capabilities
of Coq and build libraries of lemmas to achieve concise proofs of programs. We
can also use the resulting framework to leverage on Coq's mathematical theories
and formalize models of monads. In this article, we explain how we formalize a
rich hierarchy of effects (nondeterminism, state, probability, etc.), how we
mechanize examples of monadic equational reasoning from the literature, and how
we apply our framework to the design of equational laws for a subset of ML with
references.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06106" title="Abstract">arXiv:2312.06106</a> [<a href="/pdf/2312.06106" title="Download PDF">pdf</a>, <a href="/format/2312.06106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AUGCAL: Improving Sim2Rreal Adaptation by Uncertainty Calibration on  Augmented Synthetic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+B">Bharat Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Ecsedi%2C+B">Boglarka Ecsedi</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+V">Viraj Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Synthetic data (SIM) drawn from simulators have emerged as a popular
alternative for training models where acquiring annotated real-world images is
difficult. However, transferring models trained on synthetic images to
real-world applications can be challenging due to appearance disparities. A
commonly employed solution to counter this SIM2REAL gap is unsupervised domain
adaptation, where models are trained using labeled SIM data and unlabeled REAL
data. Mispredictions made by such SIM2REAL adapted models are often associated
with miscalibration - stemming from overconfident predictions on real data. In
this paper, we introduce AUGCAL, a simple training-time patch for unsupervised
adaptation that improves SIM2REAL adapted models by - (1) reducing overall
miscalibration, (2) reducing overconfidence in incorrect predictions and (3)
improving confidence score reliability by better guiding misclassification
detection - all while retaining or improving SIM2REAL performance. Given a base
SIM2REAL adaptation algorithm, at training time, AUGCAL involves replacing
vanilla SIM images with strongly augmented views (AUG intervention) and
additionally optimizing for a training time calibration loss on augmented SIM
predictions (CAL intervention). We motivate AUGCAL using a brief analytical
justification of how to reduce miscalibration on unlabeled REAL data. Through
our experiments, we empirically show the efficacy of AUGCAL across multiple
adaptation methods, backbones, tasks and shifts.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06109" title="Abstract">arXiv:2312.06109</a> [<a href="/pdf/2312.06109" title="Download PDF">pdf</a>, <a href="/format/2312.06109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Haoran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingyu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinrong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianjian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chunrui Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modern Large Vision-Language Models (LVLMs) enjoy the same vision vocabulary
-- CLIP, which can cover most common vision tasks. However, for some special
vision task that needs dense and fine-grained vision perception, e.g.,
document-level OCR or chart understanding, especially in non-English scenarios,
the CLIP-style vocabulary may encounter low efficiency in tokenizing the vision
knowledge and even suffer out-of-vocabulary problem. Accordingly, we propose
Vary, an efficient and effective method to scale up the vision vocabulary of
LVLMs. The procedures of Vary are naturally divided into two folds: the
generation and integration of a new vision vocabulary. In the first phase, we
devise a vocabulary network along with a tiny decoder-only transformer to
produce the desired vocabulary via autoregression. In the next, we scale up the
vanilla vision vocabulary by merging the new one with the original one (CLIP),
enabling the LVLMs can quickly garner new features. Compared to the popular
BLIP-2, MiniGPT4, and LLaVA, Vary can maintain its vanilla capabilities while
enjoying more excellent fine-grained perception and understanding ability.
Specifically, Vary is competent in new document parsing features (OCR or
markdown conversion) while achieving 78.2% ANLS in DocVQA and 36.2% in MMVet.
Our code will be publicly available on the homepage.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06112" title="Abstract">arXiv:2312.06112</a> [<a href="/pdf/2312.06112" title="Download PDF">pdf</a>, <a href="/format/2312.06112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Converting and Smoothing False Negatives for Vision-Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Byun%2C+J">Jaeseok Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dohoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+T">Taesup Moon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the critical issue of false negatives in Vision-Language
Pre-training (VLP), a challenge that arises from the inherent many-to-many
correspondence of image-text pairs in large-scale web-crawled datasets. The
presence of false negatives can impede achieving optimal performance and even
lead to learning failures. To address this challenge, we propose a method
called COSMO (COnverting and SMOoothing false negatives) that manages the false
negative issues, especially powerful in hard negative sampling. Building upon
the recently developed GRouped mIni-baTch sampling (GRIT) strategy, our
approach consists of two pivotal components: 1) an efficient connection mining
process that identifies and converts false negatives into positives, and 2)
label smoothing for the image-text contrastive loss (ITC). Our comprehensive
experiments verify the effectiveness of COSMO across multiple downstream tasks,
emphasizing the crucial role of addressing false negatives in VLP, potentially
even surpassing the importance of addressing false positives. In addition, the
compatibility of COSMO with the recent BLIP-family model is also demonstrated.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06113" title="Abstract">arXiv:2312.06113</a> [<a href="/pdf/2312.06113" title="Download PDF">pdf</a>, <a href="/format/2312.06113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimMining-3D: Altitude-Aware 3D Object Detection in Complex Mining  Environments: A Novel Dataset and ROS-Based Automatic Annotation Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balamurali%2C+M">Mehala Balamurali</a>, 
<a href="/search/cs?searchtype=author&query=Mihankhah%2C+E">Ehsan Mihankhah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Australasian Joint Conference on Artificial Intelligence, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate and efficient object detection is crucial for safe and efficient
operation of earth-moving equipment in mining. Traditional 2D image-based
methods face limitations in dynamic and complex mine environments. To overcome
these challenges, 3D object detection using point cloud data has emerged as a
comprehensive approach. However, training models for mining scenarios is
challenging due to sensor height variations, viewpoint changes, and the need
for diverse annotated datasets. This paper presents novel contributions to
address these challenges. We introduce a synthetic dataset SimMining 3D [1]
specifically designed for 3D object detection in mining environments. The
dataset captures objects and sensors positioned at various heights within mine
benches, accurately reflecting authentic mining scenarios. An automatic
annotation pipeline through ROS interface reduces manual labor and accelerates
dataset creation. We propose evaluation metrics accounting for sensor-to-object
height variations and point cloud density, enabling accurate model assessment
in mining scenarios. Real data tests validate our models effectiveness in
object prediction. Our ablation study emphasizes the importance of altitude and
height variation augmentations in improving accuracy and reliability. The
publicly accessible synthetic dataset [1] serves as a benchmark for supervised
learning and advances object detection techniques in mining with complimentary
pointwise annotations for each scene. In conclusion, our work bridges the gap
between synthetic and real data, addressing the domain shift challenge in 3D
object detection for mining. We envision robust object detection systems
enhancing safety and efficiency in mining and related domains.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06116" title="Abstract">arXiv:2312.06116</a> [<a href="/pdf/2312.06116" title="Download PDF">pdf</a>, <a href="/format/2312.06116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stellar: Systematic Evaluation of Human-Centric Personalized  Text-to-Image Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Achlioptas%2C+P">Panos Achlioptas</a>, 
<a href="/search/cs?searchtype=author&query=Benetatos%2C+A">Alexandros Benetatos</a>, 
<a href="/search/cs?searchtype=author&query=Fostiropoulos%2C+I">Iordanis Fostiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Skourtis%2C+D">Dimitris Skourtis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Project page: <a href="https://stellar-gen-ai.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we systematically study the problem of personalized
text-to-image generation, where the output image is expected to portray
information about specific human subjects. E.g., generating images of oneself
appearing at imaginative places, interacting with various items, or engaging in
fictional activities. To this end, we focus on text-to-image systems that input
a single image of an individual to ground the generation process along with
text describing the desired visual context. Our first contribution is to fill
the literature gap by curating high-quality, appropriate data for this task.
Namely, we introduce a standardized dataset (Stellar) that contains
personalized prompts coupled with images of individuals that is an order of
magnitude larger than existing relevant datasets and where rich semantic
ground-truth annotations are readily available. Having established Stellar to
promote cross-systems fine-grained comparisons further, we introduce a rigorous
ensemble of specialized metrics that highlight and disentangle fundamental
properties such systems should obey. Besides being intuitive, our new metrics
correlate significantly more strongly with human judgment than currently used
metrics on this task. Last but not least, drawing inspiration from the recent
works of ELITE and SDXL, we derive a simple yet efficient, personalized
text-to-image baseline that does not require test-time fine-tuning for each
subject and which sets quantitatively and in human trials a new SoTA. For more
information, please visit our project's website:
https://stellar-gen-ai.github.io/.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06117" title="Abstract">arXiv:2312.06117</a> [<a href="/pdf/2312.06117" title="Download PDF">pdf</a>, <a href="/format/2312.06117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3SOT: Multi-frame, Multi-field, Multi-space 3D Single Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Maoguo Gong</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Q">Qiguang Miao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Can Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 10 tables, AAAI 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D Single Object Tracking (SOT) stands a forefront task of computer vision,
proving essential for applications like autonomous driving. Sparse and occluded
data in scene point clouds introduce variations in the appearance of tracked
objects, adding complexity to the task. In this research, we unveil M3SOT, a
novel 3D SOT framework, which synergizes multiple input frames (template sets),
multiple receptive fields (continuous contexts), and multiple solution spaces
(distinct tasks) in ONE model. Remarkably, M3SOT pioneers in modeling
temporality, contexts, and tasks directly from point clouds, revisiting a
perspective on the key factors influencing SOT. To this end, we design a
transformer-based network centered on point cloud targets in the search area,
aggregating diverse contextual representations and propagating target cues by
employing historical frames. As M3SOT spans varied processing perspectives,
we've streamlined the network-trimming its depth and optimizing its
structure-to ensure a lightweight and efficient deployment for SOT
applications. We posit that, backed by practical construction, M3SOT sidesteps
the need for complex frameworks and auxiliary components to deliver sterling
results. Extensive experiments on benchmarks such as KITTI, nuScenes, and Waymo
Open Dataset demonstrate that M3SOT achieves state-of-the-art performance at 38
FPS. Our code and models are available at
https://github.com/ywu0912/TeamCode.git.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06118" title="Abstract">arXiv:2312.06118</a> [<a href="/pdf/2312.06118" title="Download PDF">pdf</a>, <a href="/format/2312.06118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROSE: A Recognition-Oriented Speech Enhancement Framework in Air Traffic  Control Using Multi-Objective Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xincheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongyue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Radio speech echo is a specific phenomenon in the air traffic control (ATC)
domain, which degrades speech quality and further impacts automatic speech
recognition (ASR) accuracy. In this work, a recognition-oriented speech
enhancement (ROSE) framework is proposed to improve speech intelligibility and
also advance ASR accuracy, which serves as a plug-and-play tool in ATC
scenarios and does not require additional retraining of the ASR model.
Specifically, an encoder-decoder-based U-Net framework is proposed to eliminate
the radio speech echo based on the real-world collected corpus. By
incorporating the SE-oriented and ASR-oriented loss, ROSE is implemented in a
multi-objective manner by learning shared representations across the two
optimization objectives. An attention-based skip-fusion (ABSF) mechanism is
applied to skip connections to refine the features. A channel and sequence
attention (CSAtt) block is innovatively designed to guide the model to focus on
informative representations and suppress disturbing features. The experimental
results show that the ROSE significantly outperforms other state-of-the-art
methods for both the SE and ASR tasks. In addition, the proposed approach can
contribute to the desired performance improvements on public datasets.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06121" title="Abstract">arXiv:2312.06121</a> [<a href="/pdf/2312.06121" title="Download PDF">pdf</a>, <a href="/format/2312.06121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLMs Configure Software Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kannan%2C+J">Jai Kannan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In software engineering, the meticulous configuration of software tools is
crucial in ensuring optimal performance within intricate systems. However, the
complexity inherent in selecting optimal configurations is exacerbated by the
high-dimensional search spaces presented in modern applications. Conventional
trial-and-error or intuition-driven methods are both inefficient and
error-prone, impeding scalability and reproducibility. In this study, we embark
on an exploration of leveraging Large-Language Models (LLMs) to streamline the
software configuration process. We identify that the task of hyperparameter
configuration for machine learning components within intelligent applications
is particularly challenging due to the extensive search space and
performance-critical nature. Existing methods, including Bayesian optimization,
have limitations regarding initial setup, computational cost, and convergence
efficiency. Our work presents a novel approach that employs LLMs, such as
Chat-GPT, to identify starting conditions and narrow down the search space,
improving configuration efficiency. We conducted a series of experiments to
investigate the variability of LLM-generated responses, uncovering intriguing
findings such as potential response caching and consistent behavior based on
domain-specific keywords. Furthermore, our results from hyperparameter
optimization experiments reveal the potential of LLMs in expediting
initialization processes and optimizing configurations. While our initial
insights are promising, they also indicate the need for further in-depth
investigations and experiments in this domain.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06122" title="Abstract">arXiv:2312.06122</a> [<a href="/pdf/2312.06122" title="Download PDF">pdf</a>, <a href="/format/2312.06122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GTA: Gated Toxicity Avoidance for LM Performance Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heegyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hyunsouk Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Caution: This paper includes offensive words that could potentially cause
unpleasantness. The fast-paced evolution of generative language models such as
GPT-4 has demonstrated outstanding results in various NLP generation tasks.
However, due to the potential generation of offensive words related to race or
gender, various Controllable Text Generation (CTG) methods have been proposed
to mitigate the occurrence of harmful words. However, existing CTG methods not
only reduce toxicity but also negatively impact several aspects of the language
model's generation performance, including topic consistency, grammar, and
perplexity. This paper explores the limitations of previous methods and
introduces a novel solution in the form of a simple Gated Toxicity Avoidance
(GTA) that can be applied to any CTG method. We also evaluate the effectiveness
of the proposed GTA by comparing it with state-of-the-art CTG methods across
various datasets. Our findings reveal that gated toxicity avoidance efficiently
achieves comparable levels of toxicity reduction to the original CTG methods
while preserving the generation performance of the language model.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06123" title="Abstract">arXiv:2312.06123</a> [<a href="/pdf/2312.06123" title="Download PDF">pdf</a>, <a href="/format/2312.06123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Estimation of Pairwise Effective Resistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Renchi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A paper published in SIGMOD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Given an undirected graph G, the effective resistance r(s,t) measures the
dissimilarity of node pair s,t in G, which finds numerous applications in
real-world problems, such as recommender systems, combinatorial optimization,
molecular chemistry, and electric power networks. Existing techniques towards
pairwise effective resistance estimation either trade approximation guarantees
for practical efficiency, or vice versa. In particular, the state-of-the-art
solution is based on a multitude of Monte Carlo random walks, rendering it
rather inefficient in practice, especially on large graphs.
<br />Motivated by this, this paper first presents an improved Monte Carlo
approach, AMC, which reduces both the length and amount of random walks
required without degrading the theoretical accuracy guarantee, through careful
theoretical analysis and an adaptive sampling scheme. Further, we develop a
greedy approach, GEER, which combines AMC with sparse matrix-vector
multiplications in an optimized and non-trivial way. GEER offers significantly
improved practical efficiency over AMC without compromising its asymptotic
performance and accuracy guarantees. Extensive experiments on multiple
benchmark datasets reveal that GEER is orders of magnitude faster than the
state of the art in terms of computational time when achieving the same
accuracy.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06125" title="Abstract">arXiv:2312.06125</a> [<a href="/pdf/2312.06125" title="Download PDF">pdf</a>, <a href="/format/2312.06125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-Evolved Model for Complex Multi-objective Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Haokai Hong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Min Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Multi-objective optimization problems (MOPs) necessitate the simultaneous
optimization of multiple objectives. Numerous studies have demonstrated that
evolutionary computation is a promising paradigm for solving complex MOPs,
which involve optimization problems with large-scale decision variables, many
objectives, and expensive evaluation functions. However, existing
multi-objective evolutionary algorithms (MOEAs) encounter significant
challenges in generating high-quality populations when solving diverse complex
MOPs. Specifically, the distinct requirements and constraints of the population
result in the inefficiency or even incompetence of MOEAs in addressing various
complex MOPs. Therefore, this paper proposes the concept of pre-evolving for
MOEAs to generate high-quality populations for diverse complex MOPs. Drawing
inspiration from the classical transformer architecture, we devise dimension
embedding and objective encoding techniques to configure the pre-evolved model
(PEM). The PEM is pre-evolved on a substantial number of existing MOPs.
Subsequently, when fine-evolving on new complex MOPs, the PEM transforms the
population into the next generation to approximate the Pareto-optimal front.
Furthermore, it utilizes evaluations on new solutions to iteratively update the
PEM for subsequent generations, thereby efficiently solving various complex
MOPs. Experimental results demonstrate that the PEM outperforms
state-of-the-art MOEAs on a range of complex MOPs.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06126" title="Abstract">arXiv:2312.06126</a> [<a href="/pdf/2312.06126" title="Download PDF">pdf</a>, <a href="/format/2312.06126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spreeze: High-Throughput Parallel Reinforcement Learning Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shangding Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, submitted to IEEE Transactions Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The promotion of large-scale applications of reinforcement learning (RL)
requires efficient training computation. While existing parallel RL frameworks
encompass a variety of RL algorithms and parallelization techniques, the
excessively burdensome communication frameworks hinder the attainment of the
hardware's limit for final throughput and training effects on a single desktop.
In this paper, we propose Spreeze, a lightweight parallel framework for RL that
efficiently utilizes a single desktop hardware resource to approach the
throughput limit. We asynchronously parallelize the experience sampling,
network update, performance evaluation, and visualization operations, and
employ multiple efficient data transmission techniques to transfer various
types of data between processes. The framework can automatically adjust the
parallelization hyperparameters based on the computing ability of the hardware
device in order to perform efficient large-batch updates. Based on the
characteristics of the "Actor-Critic" RL algorithm, our framework uses dual
GPUs to independently update the network of actors and critics in order to
further improve throughput. Simulation results show that our framework can
achieve up to 15,000Hz experience sampling and 370,000Hz network update frame
rate using only a personal desktop computer, which is an order of magnitude
higher than other mainstream parallel RL frameworks, resulting in a 73%
reduction of training time. Our work on fully utilizing the hardware resources
of a single desktop computer is fundamental to enabling efficient large-scale
distributed RL training.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06129" title="Abstract">arXiv:2312.06129</a> [<a href="/pdf/2312.06129" title="Download PDF">pdf</a>, <a href="/format/2312.06129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Household navigation and manipulation for everyday object rearrangement  tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iyer%2C+S+R">Shrutheesh R. Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Anwesan Pal</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Adeleye%2C+A">Akanimoh Adeleye</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+A">Aditya Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I. Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at IEEE IRC-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We consider the problem of building an assistive robotic system that can help
humans in daily household cleanup tasks. Creating such an autonomous system in
real-world environments is inherently quite challenging, as a general solution
may not suit the preferences of a particular customer. Moreover, such a system
consists of multi-objective tasks comprising -- (i) Detection of misplaced
objects and prediction of their potentially correct placements, (ii)
Fine-grained manipulation for stable object grasping, and (iii) Room-to-room
navigation for transferring objects in unseen environments. This work
systematically tackles each component and integrates them into a complete
object rearrangement pipeline. To validate our proposed system, we conduct
multiple experiments on a real robotic platform involving multi-room object
transfer, user preference-based placement, and complex pick-and-place tasks.
Project page: https://sites.google.com/eng.ucsd.edu/home-robot
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06131" title="Abstract">arXiv:2312.06131</a> [<a href="/pdf/2312.06131" title="Download PDF">pdf</a>, <a href="/format/2312.06131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ML-based Modeling to Predict I/O Performance on Different Storage  Sub-systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+P">Pranav Sivaraman</a>, 
<a href="/search/cs?searchtype=author&query=Devarajan%2C+H">Hariharan Devarajan</a>, 
<a href="/search/cs?searchtype=author&query=Mohror%2C+K">Kathryn Mohror</a>, 
<a href="/search/cs?searchtype=author&query=Bhatele%2C+A">Abhinav Bhatele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Parallel applications can spend a significant amount of time performing I/O
on large-scale supercomputers. Fast near-compute storage accelerators called
burst buffers can reduce the time a processor spends performing I/O and
mitigate I/O bottlenecks. However, determining if a given application could be
accelerated using burst buffers is not straightforward even for storage
experts. The relationship between an application's I/O characteristics (such as
I/O volume, processes involved, etc.) and the best storage sub-system for it
can be complicated. As a result, adapting parallel applications to use burst
buffers efficiently is a trial-and-error process. In this work, we present a
Python-based tool called PrismIO that enables programmatic analysis of I/O
traces. Using PrismIO, we identify bottlenecks on burst buffers and parallel
file systems and explain why certain I/O patterns perform poorly. Further, we
use machine learning to model the relationship between I/O characteristics and
burst buffer selections. We run IOR (an I/O benchmark) with various I/O
characteristics on different storage systems and collect performance data. We
use the data as the input for training the model. Our model can predict if a
file of an application should be placed on BBs for unseen IOR scenarios with an
accuracy of 94.47% and for four real applications with an accuracy of 95.86%.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06134" title="Abstract">arXiv:2312.06134</a> [<a href="/pdf/2312.06134" title="Download PDF">pdf</a>, <a href="/format/2312.06134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order Matters in the Presence of Dataset Imbalance for Multilingual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dami Choi</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+D">Derrick Xin</a>, 
<a href="/search/cs?searchtype=author&query=Dadkhahi%2C+H">Hamid Dadkhahi</a>, 
<a href="/search/cs?searchtype=author&query=Gilmer%2C+J">Justin Gilmer</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Ankush Garg</a>, 
<a href="/search/cs?searchtype=author&query=Firat%2C+O">Orhan Firat</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Chih-Kuan Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A+M">Andrew M. Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbani%2C+B">Behrooz Ghorbani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we empirically study the optimization dynamics of multi-task
learning, particularly focusing on those that govern a collection of tasks with
significant data imbalance. We present a simple yet effective method of
pre-training on high-resource tasks, followed by fine-tuning on a mixture of
high/low-resource tasks. We provide a thorough empirical study and analysis of
this method's benefits showing that it achieves consistent improvements
relative to the performance trade-off profile of standard static weighting. We
analyze under what data regimes this method is applicable and show its
improvements empirically in neural machine translation (NMT) and multi-lingual
language modeling.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06135" title="Abstract">arXiv:2312.06135</a> [<a href="/pdf/2312.06135" title="Download PDF">pdf</a>, <a href="/format/2312.06135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArtBank: Artistic Style Transfer with Pre-trained Diffusion Model and  Implicit Style Prompt Bank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhanjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiakai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zehua Lan</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+J">Junsheng Luan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiling Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Huaizhong Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Artistic style transfer aims to repaint the content image with the learned
artistic style. Existing artistic style transfer methods can be divided into
two categories: small model-based approaches and pre-trained large-scale
model-based approaches. Small model-based approaches can preserve the content
strucuture, but fail to produce highly realistic stylized images and introduce
artifacts and disharmonious patterns; Pre-trained large-scale model-based
approaches can generate highly realistic stylized images but struggle with
preserving the content structure. To address the above issues, we propose
ArtBank, a novel artistic style transfer framework, to generate highly
realistic stylized images while preserving the content structure of the content
images. Specifically, to sufficiently dig out the knowledge embedded in
pre-trained large-scale models, an Implicit Style Prompt Bank (ISPB), a set of
trainable parameter matrices, is designed to learn and store knowledge from the
collection of artworks and behave as a visual prompt to guide pre-trained
large-scale models to generate highly realistic stylized images while
preserving content structure. Besides, to accelerate training the above ISPB,
we propose a novel Spatial-Statistical-based self-Attention Module (SSAM). The
qualitative and quantitative experiments demonstrate the superiority of our
proposed method over state-of-the-art artistic style transfer methods.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06136" title="Abstract">arXiv:2312.06136</a> [<a href="/pdf/2312.06136" title="Download PDF">pdf</a>, <a href="/format/2312.06136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BACTrack: Building Appearance Collection for Aerial Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xincong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingfa Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhinong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaoying Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haolin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Circuits and Systems for Video Technology, to be published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Siamese network-based trackers have shown remarkable success in aerial
tracking. Most previous works, however, usually perform template matching only
between the initial template and the search region and thus fail to deal with
rapidly changing targets that often appear in aerial tracking. As a remedy,
this work presents Building Appearance Collection Tracking (BACTrack). This
simple yet effective tracking framework builds a dynamic collection of target
templates online and performs efficient multi-template matching to achieve
robust tracking. Specifically, BACTrack mainly comprises a Mixed-Temporal
Transformer (MTT) and an appearance discriminator. The former is responsible
for efficiently building relationships between the search region and multiple
target templates in parallel through a mixed-temporal attention mechanism. At
the same time, the appearance discriminator employs an online adaptive
template-update strategy to ensure that the collected multiple templates remain
reliable and diverse, allowing them to closely follow rapid changes in the
target's appearance and suppress background interference during tracking.
Extensive experiments show that our BACTrack achieves top performance on four
challenging aerial tracking benchmarks while maintaining an impressive speed of
over 87 FPS on a single GPU. Speed tests on embedded platforms also validate
our potential suitability for deployment on UAV platforms.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06137" title="Abstract">arXiv:2312.06137</a> [<a href="/pdf/2312.06137" title="Download PDF">pdf</a>, <a href="/format/2312.06137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compute-in-Memory based Neural Network Accelerators for Safety-Critical  Systems: Worst-Case Scenarios and Protections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zheyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">Xiaobo Sharon Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Emerging non-volatile memory (NVM)-based Computing-in-Memory (CiM)
architectures show substantial promise in accelerating deep neural networks
(DNNs) due to their exceptional energy efficiency. However, NVM devices are
prone to device variations. Consequently, the actual DNN weights mapped to NVM
devices can differ considerably from their targeted values, inducing
significant performance degradation. Many existing solutions aim to optimize
average performance amidst device variations, which is a suitable strategy for
general-purpose conditions. However, the worst-case performance that is crucial
for safety-critical applications is largely overlooked in current research. In
this study, we define the problem of pinpointing the worst-case performance of
CiM DNN accelerators affected by device variations. Additionally, we introduce
a strategy to identify a specific pattern of the device value deviations in the
complex, high-dimensional value deviation space, responsible for this
worst-case outcome. Our findings reveal that even subtle device variations can
precipitate a dramatic decline in DNN accuracy, posing risks for CiM-based
platforms in supporting safety-critical applications. Notably, we observe that
prevailing techniques to bolster average DNN performance in CiM accelerators
fall short in enhancing worst-case scenarios. In light of this issue, we
propose a novel worst-case-aware training technique named A-TRICE that
efficiently combines adversarial training and noise-injection training with
right-censored Gaussian noise to improve the DNN accuracy in the worst-case
scenarios. Our experimental results demonstrate that A-TRICE improves the
worst-case accuracy under device variations by up to 33%.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06140" title="Abstract">arXiv:2312.06140</a> [<a href="/pdf/2312.06140" title="Download PDF">pdf</a>, <a href="/format/2312.06140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICS-Sniper: A Targeted Blackhole Attack on Encrypted ICS Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+G">Gargi Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Dash%2C+P">Pritam Dash</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y+E">Yingao Elaine Yao</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Aastha Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Pattabiraman%2C+K">Karthik Pattabiraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 4 tables, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Operational Technology (OT) networks of industrial control systems (ICS) are
increasingly connected to the public Internet, which has prompted ICSes to
implement strong security measures (e.g., authentication and encryption) to
protect end-to-end control communication. Despite the security measures, we
show that an Internet adversary in the path of an ICS's communication can cause
damage to the ICS without infiltrating it. We present ICS-Sniper, a targeted
blackhole attack that analyzes the packet metadata (sizes, timing) to identify
the packets carrying critical ICS commands or data, and drops the critical
packets to disrupt the ICS's operations. We demonstrate two attacks on an
emulation of a Secure Water Treatment (SWaT) plant that can potentially violate
the operational safety of the ICS while evading state-of-the-art detection
systems.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06141" title="Abstract">arXiv:2312.06141</a> [<a href="/pdf/2312.06141" title="Download PDF">pdf</a>, <a href="/format/2312.06141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Memory-Augmented Neural Networks: Cognitive Insights to AI  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khosla%2C+S">Savya Khosla</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yifie He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper explores Memory-Augmented Neural Networks (MANNs), delving into
how they blend human-like memory processes into AI. It covers different memory
types, like sensory, short-term, and long-term memory, linking psychological
theories with AI applications. The study investigates advanced architectures
such as Hopfield Networks, Neural Turing Machines, Correlation Matrix Memories,
Memformer, and Neural Attention Memory, explaining how they work and where they
excel. It dives into real-world uses of MANNs across Natural Language
Processing, Computer Vision, Multimodal Learning, and Retrieval Models, showing
how memory boosters enhance accuracy, efficiency, and reliability in AI tasks.
Overall, this survey provides a comprehensive view of MANNs, offering insights
for future research in memory-based AI systems.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06144" title="Abstract">arXiv:2312.06144</a> [<a href="/pdf/2312.06144" title="Download PDF">pdf</a>, <a href="/format/2312.06144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Term Carbon-Efficient Planning for Geographically Shiftable  Resources: A Monte Carlo Tree Search Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xuan He</a>, 
<a href="/search/eess?searchtype=author&query=Tsang%2C+D+H+K">Danny H.K. Tsang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yize Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures, in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Global climate challenge is demanding urgent actions for decarbonization,
while electric power systems take the major roles in clean energy transition.
Due to the existence of spatially and temporally dispersed renewable energy
resources and the uneven distribution of carbon emission intensity throughout
the grid, it is worth investigating future load planning and demand management
to offset those generations with higher carbon emission rates. Such techniques
include inter-region utilization of geographically shiftable resources and
stochastic renewable energy. For instance, data center is considered to be a
major carbon emission producer in the future due to increasing information
load, while it holds the capability of geographical load balancing. In this
paper, we propose a novel planning and operation model minimizing the
system-level carbon emissions via sitting and operating geographically
shiftable resources. This model decides the optimal locations for shiftable
resources expansion along with power dispatch schedule. To accommodate future
system operation patterns and a wide range of operating conditions, we
incorporate 20-year fine-grained load and renewables scenarios for grid
simulations of realistic sizes (e.g., up to 1888 buses). To tackle the
computational challenges coming from the combinatorial nature of such
large-scale planning problem, we develop a customized Monte Carlo Tree Search
(MCTS) method, which can find reasonable solutions satisfying solution time
limits. Besides, MCTS enables flexible time window settings and offline
solution adjustments. Extensive simulations validate that our planning model
can reduce more than 10\% carbon emission across all setups. Compared to
off-the-shelf optimization solvers such as Gurobi, our method achieves up to
8.1X acceleration while the solution gaps are less than 1.5\% in large-scale
cases.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06145" title="Abstract">arXiv:2312.06145</a> [<a href="/pdf/2312.06145" title="Download PDF">pdf</a>, <a href="/format/2312.06145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proxy-based Item Representation for Attribute and Context-aware  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seol%2C+J">Jinseok Seol</a>, 
<a href="/search/cs?searchtype=author&query=Gang%2C+M">Minseok Gang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-goo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehui Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, accepted in The 17th ACM International Conference on Web Search and Data Mining (WSDM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural network approaches in recommender systems have shown remarkable
success by representing a large set of items as a learnable vector embedding
table. However, infrequent items may suffer from inadequate training
opportunities, making it difficult to learn meaningful representations. We
examine that in attribute and context-aware settings, the poorly learned
embeddings of infrequent items impair the recommendation accuracy. To address
such an issue, we propose a proxy-based item representation that allows each
item to be expressed as a weighted sum of learnable proxy embeddings. Here, the
proxy weight is determined by the attributes and context of each item and may
incorporate bias terms in case of frequent items to further reflect
collaborative signals. The proxy-based method calculates the item
representations compositionally, ensuring each representation resides inside a
well-trained simplex and, thus, acquires guaranteed quality. Additionally, that
the proxy embeddings are shared across all items allows the infrequent items to
borrow training signals of frequent items in a unified model structure and
end-to-end manner. Our proposed method is a plug-and-play model that can
replace the item encoding layer of any neural network-based recommendation
model, while consistently improving the recommendation performance with much
smaller parameter usage. Experiments conducted on real-world recommendation
benchmark datasets demonstrate that our proposed model outperforms
state-of-the-art models in terms of recommendation accuracy by up to 17% while
using only 10% of the parameters.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06147" title="Abstract">arXiv:2312.06147</a> [<a href="/pdf/2312.06147" title="Download PDF">pdf</a>, <a href="/format/2312.06147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;What&#x27;s important here?&quot;: Opportunities and Challenges of Using LLMs in  Retrieving Information from Web Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huq%2C+F">Faria Huq</a>, 
<a href="/search/cs?searchtype=author&query=Bigham%2C+J+P">Jeffrey P. Bigham</a>, 
<a href="/search/cs?searchtype=author&query=Martelaro%2C+N">Nikolas Martelaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 R0-FoMo Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Large language models (LLMs) that have been trained on a corpus that includes
large amount of code exhibit a remarkable ability to understand HTML code. As
web interfaces are primarily constructed using HTML, we design an in-depth
study to see how LLMs can be used to retrieve and locate important elements for
a user given query (i.e. task description) in a web interface. In contrast with
prior works, which primarily focused on autonomous web navigation, we decompose
the problem as an even atomic operation - Can LLMs identify the important
information in the web page for a user given query? This decomposition enables
us to scrutinize the current capabilities of LLMs and uncover the opportunities
and challenges they present. Our empirical experiments show that while LLMs
exhibit a reasonable level of performance in retrieving important UI elements,
there is still a substantial room for improvement. We hope our investigation
will inspire follow-up works in overcoming the current challenges in this
domain.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06149" title="Abstract">arXiv:2312.06149</a> [<a href="/pdf/2312.06149" title="Download PDF">pdf</a>, <a href="/format/2312.06149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Anticipatory Text Generation: A Constrained Approach for  Faithful Decoding with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+L">Lifu Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+S">Semih Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Jin Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiacheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+R">Rui Meng</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated a powerful ability for text
generation. However, achieving optimal results with a given prompt or
instruction can be challenging, especially for billion-sized models.
Additionally, undesired behaviors such as toxicity or hallucinations can
manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in
mitigating these issues, there is still no guarantee of complete prevention. In
this work, we propose formalizing text generation as a future-constrained
generation problem to minimize undesirable behaviors and enforce faithfulness
to instructions. The estimation of future constraint satisfaction, accomplished
using LLMs, guides the text generation process. Our extensive experiments
demonstrate the effectiveness of the proposed approach across three distinct
text generation tasks: keyword-constrained generation (Lin et al., 2020),
toxicity reduction (Gehman et al., 2020), and factual correctness in
question-answering (Gao et al., 2023).
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06153" title="Abstract">arXiv:2312.06153</a> [<a href="/pdf/2312.06153" title="Download PDF">pdf</a>, <a href="/format/2312.06153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Datasheets: Machine-readable Documentation for Open Datasets and  Responsible AI Assessments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roman%2C+A+C">Anthony Cintron Roman</a>, 
<a href="/search/cs?searchtype=author&query=Vaughan%2C+J+W">Jennifer Wortman Vaughan</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+V">Valerie See</a>, 
<a href="/search/cs?searchtype=author&query=Ballard%2C+S">Steph Ballard</a>, 
<a href="/search/cs?searchtype=author&query=Schifano%2C+N">Nicolas Schifano</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+J">Jehu Torres</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+C">Caleb Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Ferres%2C+J+M+L">Juan M. Lavista Ferres</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper introduces a no-code, machine-readable documentation framework for
open datasets, with a focus on Responsible AI (RAI) considerations. The
framework aims to improve the accessibility, comprehensibility, and usability
of open datasets, facilitating easier discovery and use, better understanding
of content and context, and evaluation of dataset quality and accuracy. The
proposed framework is designed to streamline the evaluation of datasets,
helping researchers, data scientists, and other open data users quickly
identify datasets that meet their needs and/or organizational policies or
regulations. The paper also discusses the implementation of the framework and
provides recommendations to maximize its potential. The framework is expected
to enhance the quality and reliability of data used in research and
decision-making, fostering the development of more responsible and trustworthy
AI systems.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06154" title="Abstract">arXiv:2312.06154</a> [<a href="/pdf/2312.06154" title="Download PDF">pdf</a>, <a href="/format/2312.06154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Reliability Assessment of Distribution Grids with Residential  Distributed Energy Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Karngala%2C+A+K">Arun Kumar Karngala</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+C">Chanan Singh</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Le Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 6 figures, Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Distribution system end users are transforming from passive to active
participants, marked by the push towards widespread adoption of edge-level
Distributed Energy Resources (DERs). This paper addresses the challenges in
distribution system planning arising from these dynamic changes. We introduce a
bottom-up probabilistic approach that integrates these edge-level DERs into the
reliability evaluation process. Our methodology leverages joint probability
distributions to characterize and model the penetration of rooftop photovoltaic
(PV) systems and energy storage across a distribution network at the individual
residential level. Employing a scenario-based approach, we showcase the
application of our probabilistic method using a Monte Carlo Simulation process
to assess average system reliability indices and their variations at the user
level. To validate our approach, we applied this methodology to the RBTS test
system across various adoption scenarios, effectively showcasing the capability
of our proposed method in quantifying the variation in end-user reliability
indices for each scenario within the distribution system.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06158" title="Abstract">arXiv:2312.06158</a> [<a href="/pdf/2312.06158" title="Download PDF">pdf</a>, <a href="/format/2312.06158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Feature Selection for No-Reference Image Quality Assessment  using Contrastive Mitigating Semantic Noise Sensitivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xudong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Timin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Runze Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jingyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yutao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+P">Pingyang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The current state-of-the-art No-Reference Image Quality Assessment (NR-IQA)
methods typically use feature extraction in upstream backbone networks, which
assumes that all extracted features are relevant. However, we argue that not
all features are beneficial, and some may even be harmful, necessitating
careful selection. Empirically, we find that many image pairs with small
feature spatial distances can have vastly different quality scores. To address
this issue, we propose a Quality-Aware Feature Matching IQA metric(QFM-IQM)
that employs contrastive learning to remove harmful features from the upstream
task. Specifically, our approach enhances the semantic noise distinguish
capabilities of neural networks by comparing image pairs with similar semantic
features but varying quality scores and adaptively adjusting the upstream
task's features by introducing disturbance. Furthermore, we utilize a
distillation framework to expand the dataset and improve the model's
generalization ability. Our approach achieves superior performance to the
state-of-the-art NR-IQA methods on 8 standard NR-IQA datasets, achieving PLCC
values of 0.932 (vs. 0.908 in TID2013) and 0.913 (vs. 0.894 in LIVEC).
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06162" title="Abstract">arXiv:2312.06162</a> [<a href="/pdf/2312.06162" title="Download PDF">pdf</a>, <a href="/format/2312.06162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textual Prompt Guided Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiuhai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+A">Aiwen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Long Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qiaosi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunjie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image restoration has always been a cutting-edge topic in the academic and
industrial fields of computer vision. Since degradation signals are often
random and diverse, "all-in-one" models that can do blind image restoration
have been concerned in recent years. Early works require training specialized
headers and tails to handle each degradation of concern, which are manually
cumbersome. Recent works focus on learning visual prompts from data
distribution to identify degradation type. However, the prompts employed in
most of models are non-text, lacking sufficient emphasis on the importance of
human-in-the-loop. In this paper, an effective textual prompt guided image
restoration model has been proposed. In this model, task-specific BERT is
fine-tuned to accurately understand user's instructions and generating textual
prompt guidance. Depth-wise multi-head transposed attentions and gated
convolution modules are designed to bridge the gap between textual prompts and
visual features. The proposed model has innovatively introduced semantic
prompts into low-level visual domain. It highlights the potential to provide a
natural, precise, and controllable way to perform image restoration tasks.
Extensive experiments have been done on public denoising, dehazing and
deraining datasets. The experiment results demonstrate that, compared with
popular state-of-the-art methods, the proposed model can obtain much more
superior performance, achieving accurate recognition and removal of degradation
without increasing model's complexity. Related source codes and data will be
publicly available on github site
https://github.com/MoTong-AI-studio/TextPromptIR.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06163" title="Abstract">arXiv:2312.06163</a> [<a href="/pdf/2312.06163" title="Download PDF">pdf</a>, <a href="/format/2312.06163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Camera Patch: An Effective and Robust Physical-World Attack  on Object Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiliwalidi%2C+K">Kalibinuer Tiliwalidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nowadays, the susceptibility of deep neural networks (DNNs) has garnered
significant attention. Researchers are exploring patch-based physical attacks,
yet traditional approaches, while effective, often result in conspicuous
patches covering target objects. This leads to easy detection by human
observers. Recently, novel camera-based physical attacks have emerged,
leveraging camera patches to execute stealthy attacks. These methods circumvent
target object modifications by introducing perturbations directly to the camera
lens, achieving a notable breakthrough in stealthiness. However, prevailing
camera-based strategies necessitate the deployment of multiple patches on the
camera lens, which introduces complexity. To address this issue, we propose an
Adversarial Camera Patch (ADCP).
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06164" title="Abstract">arXiv:2312.06164</a> [<a href="/pdf/2312.06164" title="Download PDF">pdf</a>, <a href="/format/2312.06164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Shape Modeling for Anatomical Structure Refinement of  Volumetric Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xin You</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yun Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Shape modeling of volumetric medical images is a critical task for
quantitative analysis and surgical plans in computer-aided diagnosis. To
relieve the burden of expert clinicians, the reconstructed shapes are widely
acquired from deep learning models, e.g. Convolutional Neural Networks (CNNs),
followed by marching cube algorithm. However, automatically obtaining
reconstructed shapes can not always achieve perfect results due to the limited
resolution of images and lack of shape prior constraints. In this paper, we
design a unified framework for the refinement of medical image segmentation on
top of an implicit neural network. Specifically, To learn a sharable shape
prior from different instances within the same category in the training phase,
the physical information of volumetric medical images are firstly utilized to
construct the Physical-Informed Continuous Coordinate Transform (PICCT). PICCT
transforms the input data in an aligned manner fed into the implicit shape
modeling. To better learn shape representation, we introduce implicit shape
constraints on top of the signed distance function (SDF) into the implicit
shape modeling of both instances and latent template. For the inference phase,
a template interaction module (TIM) is proposed to refine initial results
produced by CNNs via deforming deep implicit templates with latent codes.
Experimental results on three datasets demonstrated the superiority of our
approach in shape refinement. The Chamfer Distance/Earth Mover's Distance
achieved by the proposed method are 0.232/0.087 on the Liver dataset,
0.128/0.069 on the Pancreas dataset, and 0.417/0.100 on the Lung Lobe dataset.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06165" title="Abstract">arXiv:2312.06165</a> [<a href="/pdf/2312.06165" title="Download PDF">pdf</a>, <a href="/format/2312.06165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecJPQ: Training Large-Catalogue Sequential Recommenders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrov%2C+A+V">Aleksandr V. Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommender systems rank items based on the likelihood of their
next appearance in user-item interactions. Current models such as BERT4Rec and
SASRec generate sequence embeddings and compute scores for catalogue items, but
the increasing catalogue size makes training these models costly. The Joint
Product Quantisation method, originally proposed for passage retrieval,
markedly reduces the size of the retrieval index with minimal effect on model
effectiveness by replacing passage embeddings with a limited number of shared
centroid embeddings. This paper introduces RecJPQ, a novel adaptation of JPQ
for sequential recommendations. We apply RecJPQ to SASRec, BERT4Rec, and
GRU4rec models on three large-scale sequential datasets. Our results showed
that RecJPQ could notably reduce the model size (e.g., 48x reduction for the
Gowalla dataset with no effectiveness degradation). RecJPQ can also improve
model performance through a regularisation effect (e.g. +0.96% NDCG@10
improvement on the Booking.com dataset).
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06168" title="Abstract">arXiv:2312.06168</a> [<a href="/pdf/2312.06168" title="Download PDF">pdf</a>, <a href="/format/2312.06168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Planning for Multiple Mobile Manipulator System in Complex  Flipping Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kun Song</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Meng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiawei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+Y">Michael Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhenhua Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multiple robot systems are favored for object manipulation and
transportation, especially for large objects. However, in more complex
manipulation such as flipping, these systems encounter a new challenge,
configuration disconnectivity of manipulators. Grasping objects by manipulators
will impose closed-chain constraints on the system, which in turn limits the
feasible motions of manipulators and further compromises the configuration
connectivity. Multiple mobile manipulator systems show much more flexibility in
object manipulation with the mobility of the mobile platform and have the
potential to address the above problem. In this paper, a novel planning
framework is proposed for complex flipping manipulation by incorporating
platform motions and regrasping. Firstly, two types of trajectories, mobile
manipulator planning and regrasping planning, are classified and can be
assigned different priorities for different tasks. Secondly, corresponding
planning methods are designed for each type of trajectory. Specifically, in
mobile manipulator planning, the configuration of the platform is determined
through optimization to ensure connectivity when the manipulator approaches
configuration boundaries. In regrasping planning, closed-chain constraints are
temporarily disregarded and the manipulation capabilities are prioritized to
facilitate subsequent planning. Finally, the structure of the overall planning
framework is provided. Experimental results demonstrate that the proposed
planner efficiently plans the motions of the system to accomplish flipping
manipulation. Additionally, a comprehensive experiment emphasizes the
significance of our planner in extending the capabilities of multiple mobile
manipulator systems in complex tasks.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06169" title="Abstract">arXiv:2312.06169</a> [<a href="/pdf/2312.06169" title="Download PDF">pdf</a>, <a href="/ps/2312.06169" title="Download PostScript">ps</a>, <a href="/format/2312.06169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bag of Tricks: Semi-Supervised Cross-domain Crater Detection with Poor  Data Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tiecheng Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the development of spaceflight and the exploration of extraterrestrial
planets, exoplanet crater detection has gradually gained attention. However,
with the current scarcity of relevant datasets, high sample background
complexity, and large inter-domain differences, few existing detection models
can achieve good robustness and generalization across domains by training on
data with more background interference. To obtain a better robust model with
better cross-domain generalization in the presence of poor data quality, we
propose the SCPQ model, in which we first propose a method for fusing shallow
information using attention mechanism (FSIAM), which utilizes feature maps
fused with deep convolved feature maps after fully extracting the global
sensory field of shallow information via the attention mechanism module, which
can fully fit the data to obtain a better sense of the domain in the presence
of poor data, and thus better multiscale adaptability. Secondly, we propose a
pseudo-label and data augment strategy (PDAS) and a smooth hard example mining
(SHEM) loss function to improve cross-domain performance. PDAS adopts
high-quality pseudo-labeled data from the target domain to the finetune model,
and adopts different strong and weak data enhancement strategies for different
domains, which mitigates the different distribution of information inherent in
the source and target domains, and obtains a better generalization effect.
Meanwhile, our proposed SHEM loss function can solve the problem of poor
robustness of hard examples due to partial background interference learning
during the training process. The SHEM loss function can smooth this
interference and has generalization while learning hard examples. Experimental
results show that we achieved better performance on the DACD dataset and
improved the Recall of cross-domain detection by 24.04\% over baseline.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06170" title="Abstract">arXiv:2312.06170</a> [<a href="/pdf/2312.06170" title="Download PDF">pdf</a>, <a href="/ps/2312.06170" title="Download PostScript">ps</a>, <a href="/format/2312.06170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral properties of flipped Toeplitz matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barbarino%2C+G">Giovanni Barbarino</a>, 
<a href="/search/math?searchtype=author&query=Ekstr%C3%B6m%2C+S">Sven-Erik Ekstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=Garoni%2C+C">Carlo Garoni</a>, 
<a href="/search/math?searchtype=author&query=Meadon%2C+D">David Meadon</a>, 
<a href="/search/math?searchtype=author&query=Serra-Capizzano%2C+S">Stefano Serra-Capizzano</a>, 
<a href="/search/math?searchtype=author&query=Vassalos%2C+P">Paris Vassalos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the spectral properties of flipped Toeplitz matrices of the form
$H_n(f)=Y_nT_n(f)$, where $T_n(f)$ is the $n\times n$ Toeplitz matrix generated
by the function $f$ and $Y_n$ is the $n\times n$ exchange (or flip) matrix
having $1$ on the main anti-diagonal and $0$ elsewhere. In particular, under
suitable assumptions on $f$, we establish an alternating sign relationship
between the eigenvalues of $H_n(f)$, the eigenvalues of $T_n(f)$, and the
quasi-uniform samples of $f$. Moreover, after fine-tuning a few known theorems
on Toeplitz matrices, we use them to provide localization results for the
eigenvalues of $H_n(f)$. Our study is motivated by the convergence analysis of
the minimal residual (MINRES) method for the solution of real non-symmetric
Toeplitz linear systems of the form $T_n(f)\mathbf x=\mathbf b$ after
pre-multiplication of both sides by $Y_n$, as suggested by Pestana and Wathen.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06171" title="Abstract">arXiv:2312.06171</a> [<a href="/pdf/2312.06171" title="Download PDF">pdf</a>, <a href="/format/2312.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Explicit and Implicit Cross-Modal Interaction Network for  Anterior Chamber Inflammation Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Q">Qian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Ye Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Haochao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+W">Wei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Uveitis demands the precise diagnosis of anterior chamber inflammation (ACI)
for optimal treatment. However, current diagnostic methods only rely on a
limited single-modal disease perspective, which leads to poor performance. In
this paper, we investigate a promising yet challenging way to fuse multimodal
data for ACI diagnosis. Notably, existing fusion paradigms focus on empowering
implicit modality interactions (i.e., self-attention and its variants), but
neglect to inject explicit modality interactions, especially from clinical
knowledge and imaging property. To this end, we propose a jointly Explicit and
implicit Cross-Modal Interaction Network (EiCI-Net) for Anterior Chamber
Inflammation Diagnosis that uses anterior segment optical coherence tomography
(AS-OCT) images, slit-lamp images, and clinical data jointly. Specifically, we
first develop CNN-Based Encoders and Tabular Processing Module (TPM) to extract
efficient feature representations in different modalities. Then, we devise an
Explicit Cross-Modal Interaction Module (ECIM) to generate attention maps as a
kind of explicit clinical knowledge based on the tabular feature maps, then
integrated them into the slit-lamp feature maps, allowing the CNN-Based Encoder
to focus on more effective informativeness of the slit-lamp images. After that,
the Implicit Cross-Modal Interaction Module (ICIM), a transformer-based
network, further implicitly enhances modality interactions. Finally, we
construct a considerable real-world dataset from our collaborative hospital and
conduct sufficient experiments to demonstrate the superior performance of our
proposed EiCI-Net compared with the state-of-the-art classification methods in
various metrics.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06172" title="Abstract">arXiv:2312.06172</a> [<a href="/pdf/2312.06172" title="Download PDF">pdf</a>, <a href="/format/2312.06172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling SQL Query Hardness Parsing for Text-to-SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiawen Yi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The fundamental goal of the Text-to-SQL task is to translate natural language
question into SQL query. Current research primarily emphasizes the information
coupling between natural language questions and schemas, and significant
progress has been made in this area. The natural language questions as the
primary task requirements source determines the hardness of correspond SQL
queries, the correlation between the two always be ignored. However, when the
correlation between questions and queries was decoupled, it may simplify the
task. In this paper, we introduce an innovative framework for Text-to-SQL based
on decoupling SQL query hardness parsing. This framework decouples the
Text-to-SQL task based on query hardness by analyzing questions and schemas,
simplifying the multi-hardness task into a single-hardness challenge. This
greatly reduces the parsing pressure on the language model. We evaluate our
proposed framework and achieve a new state-of-the-art performance of
fine-turning methods on Spider dev.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06173" title="Abstract">arXiv:2312.06173</a> [<a href="/pdf/2312.06173" title="Download PDF">pdf</a>, <a href="/format/2312.06173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concrete Subspace Learning based Interference Elimination for Multi-task  Model Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Anke Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Merging models fine-tuned from a common, extensively pre-trained large model
but specialized for different tasks has been demonstrated as a cheap and
scalable strategy to construct a multi-task model that performs well across
diverse tasks. Recent research, exemplified by task arithmetic, highlights that
this multi-task model can be derived through arithmetic operations on task
vectors. Nevertheless, current merging techniques frequently resolve potential
conflicts among parameters from task-specific models by evaluating individual
attributes, such as the parameters' magnitude or sign, overlooking their
collective impact on the overall functionality of the model. In this work, we
propose the CONtinuous relaxation of disCRETE (Concrete) subspace learning
method to identify a common low-dimensional subspace and utilize its shared
information to track the interference problem without sacrificing much
performance. Specifically, we model the problem as a bi-level optimization
problem and introduce a meta-learning framework to find the Concrete subspace
mask through gradient-based techniques. At the upper level, we focus on
learning a shared Concrete mask to identify the subspace, while at the inner
level, model merging is performed to maximize the performance of the merged
model. We conduct extensive experiments on both vision domain and language
domain, and the results demonstrate the effectiveness of our method. The code
is available at https://github.com/tanganke/subspace_fusion
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06174" title="Abstract">arXiv:2312.06174</a> [<a href="/pdf/2312.06174" title="Download PDF">pdf</a>, <a href="/format/2312.06174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Percentile Risk-Constrained Budget Pacing for Guaranteed Display  Advertising in Online Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Liang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+K">Kejie Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guangming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zu%2C+Z">Zhonglin Zu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Guaranteed display (GD) advertising is a critical component of advertising
since it provides publishers with stable revenue and enables advertisers to
target specific audiences with guaranteed impressions. However, smooth pacing
control for online ad delivery presents a challenge due to significant budget
disparities, user arrival distribution drift, and dynamic change between supply
and demand. This paper presents robust risk-constrained pacing (RCPacing) that
utilizes Lagrangian dual multipliers to fine-tune probabilistic throttling
through monotonic mapping functions within the percentile space of impression
performance distribution. RCPacing combines distribution drift resilience and
compatibility with guaranteed allocation mechanism, enabling us to provide
near-optimal online services. We also show that RCPacing achieves $O(\sqrt{T})$
dynamic regret where $T$ is the length of the horizon. RCPacing's effectiveness
is validated through offline evaluations and online A/B testing conducted on
Taobao brand advertising platform.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06177" title="Abstract">arXiv:2312.06177</a> [<a href="/pdf/2312.06177" title="Download PDF">pdf</a>, <a href="/format/2312.06177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Physics-Informed Machine Learning for Uncertainty  Quantification in High-Dimensional Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yifei Zong</a>, 
<a href="/search/cs?searchtype=author&query=Barajas-Solano%2C+D">David Barajas-Solano</a>, 
<a href="/search/cs?searchtype=author&query=Tartakovsky%2C+A+M">Alexandre M. Tartakovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a physics-informed machine learning method for uncertainty
quantification (UQ) in high-dimensional inverse problems. In this method, the
states and parameters of partial differential equations (PDEs) are approximated
with truncated conditional Karhunen-Lo\`eve expansions (CKLEs), which, by
construction, match the measurements of the respective variables. The maximum a
posteriori (MAP) solution of the inverse problem is formulated as a
minimization problem over CKLE coefficients where the loss function is the sum
of the norm of PDE residuals and $\ell_2$ regularization term. This MAP
formulation is known as the physics-informed CKLE (PICKLE) method. Uncertainty
in the inverse solution is quantified in terms of the posterior distribution of
CKLE coefficients, and we sample the posterior by solving a randomized PICKLE
minimization problem, formulated by adding zero-mean Gaussian perturbations in
the PICKLE loss function. We call the proposed approach the randomized PICKLE
(rPICKLE) method.
<br />We test rPICKLE for the inverse problems of estimating parameters and states
in groundwater models described by the diffusion (Darcy) equation with low and
high-dimensional parameter space. We validate rPICKLE for the low-dimensional
case with 15 unknown CKLE parameters by showing that rPICKLE and Hamiltonian
Monte Carlo (HMC) produce similar posterior distributions. The execution times
of both methods increase with the dimensionality of the problem. However, the
execution time of HMC increases significantly faster with the problem
dimensionality than that of rPICKLE. For the high-dimensional case (2000 CKLE
parameters) with HMC does not reach the stopping criterion (the set number of
samples) after running the code for 30 days. On the other hand, rPICKLE
generates the same number of samples in four to five days.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06178" title="Abstract">arXiv:2312.06178</a> [<a href="/pdf/2312.06178" title="Download PDF">pdf</a>, <a href="/format/2312.06178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Event-triggered Control For Strict-feedback Systems With  Time-varying Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tan%2C+Y">Yan Tan</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+L">Liucang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wenqi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this article, we develop a new adaptive event-triggered asymptotic control
scheme for strict-feedback systems with fast time-varying parameters. To deal
with time-varying parameters with unknown variation boundaries in the feedback
path and the input path, we construct three adaptive laws for parameter
estimation, two for the uncertain parameters in the feedback path and one for
the uncertain parameters in the input path. In particular, two sets of tuning
functions are introduced to avoid over-parametrization. Additionally, an
event-triggering mechanism is embedded in this adaptive control framework to
reduce the data transmission from the controller to the actuator. We also
introduce a soft sign function to handle the perturbations caused by sampling
errors to achieve asymptotic stability and avoid the so-called parameter drift.
The stability analysis shows that the closed-loop system is globally uniformly
asymptotically stable and the Zeno behavior can be excluded. Simulation results
verify the effectiveness and performance of the proposed adaptive scheme.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06179" title="Abstract">arXiv:2312.06179</a> [<a href="/pdf/2312.06179" title="Download PDF">pdf</a>, <a href="/format/2312.06179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Weighted Combiner for Mixed-Modal Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fuxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaowei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Suqi Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures and 12 tables. To appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Mixed-Modal Image Retrieval (MMIR) as a flexible search paradigm has
attracted wide attention. However, previous approaches always achieve limited
performance, due to two critical factors are seriously overlooked. 1) The
contribution of image and text modalities is different, but incorrectly treated
equally. 2) There exist inherent labeling noises in describing users'
intentions with text in web datasets from diverse real-world scenarios, giving
rise to overfitting. We propose a Dynamic Weighted Combiner (DWC) to tackle the
above challenges, which includes three merits. First, we propose an Editable
Modality De-equalizer (EMD) by taking into account the contribution disparity
between modalities, containing two modality feature editors and an adaptive
weighted combiner. Second, to alleviate labeling noises and data bias, we
propose a dynamic soft-similarity label generator (SSG) to implicitly improve
noisy supervision. Finally, to bridge modality gaps and facilitate similarity
learning, we propose a CLIP-based mutual enhancement module alternately trained
by a mixed-modality contrastive loss. Extensive experiments verify that our
proposed model significantly outperforms state-of-the-art methods on real-world
datasets. The source code is available at
\url{https://github.com/fuxianghuang1/DWC}.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06180" title="Abstract">arXiv:2312.06180</a> [<a href="/pdf/2312.06180" title="Download PDF">pdf</a>, <a href="/ps/2312.06180" title="Download PostScript">ps</a>, <a href="/format/2312.06180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contraction analysis of time-varying DAE systems via auxiliary ODE  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yin%2C+H">Hao Yin</a>, 
<a href="/search/eess?searchtype=author&query=Jayawardhana%2C+B">Bayu Jayawardhana</a>, 
<a href="/search/eess?searchtype=author&query=Trenn%2C+S">Stephan Trenn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">This paper studies the contraction property of time-varying
differential-algebraic equation (DAE) systems by embedding them to
higher-dimension ordinary differential equation (ODE) systems. The first result
pertains to the equivalence of the contraction of a DAE system and the uniform
global exponential stability (UGES) of its variational DAE system. Such
equivalence inherits the well-known property of contracting ODE systems on a
specific manifold. Subsequently, we construct an auxiliary ODE system from a
DAE system whose trajectories encapsulate those of the corresponding
variational DAE system. Using the auxiliary ODE system, a sufficient condition
for contraction of the time-varying DAE system is established by using matrix
measure which allows us to estimate an lower bound on the parameters of the
auxiliary system. Finally, we apply the results to analyze the stability of
time-invariant DAE systems, and to design observers for time-varying ODE
systems.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06182" title="Abstract">arXiv:2312.06182</a> [<a href="/pdf/2312.06182" title="Download PDF">pdf</a>, <a href="/format/2312.06182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why &quot;classic&quot; Transformers are shallow and how to make them go deep
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yueyao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Since its introduction in 2017, Transformer has emerged as the leading neural
network architecture, catalyzing revolutionary advancements in many AI
disciplines. The key innovation in Transformer is a Self-Attention (SA)
mechanism designed to capture contextual information. However, extending the
original Transformer design to models of greater depth has proven exceedingly
challenging, if not impossible. Even though various modifications have been
proposed in order to stack more layers of SA mechanism into deeper models, a
full understanding of this depth problem remains elusive. In this paper, we
conduct a comprehensive investigation, both theoretically and empirically, to
substantiate the claim that the depth problem is caused by \emph{token
similarity escalation}; that is, tokens grow increasingly alike after repeated
applications of the SA mechanism. Our analysis reveals that, driven by the
invariant leading eigenspace and large spectral gaps of attention matrices,
token similarity provably escalates at a linear rate. Based on the gained
insight, we propose a simple strategy that, unlike most existing methods,
surgically removes excessive similarity without discounting the SA mechanism as
a whole. Preliminary experimental results confirm the effectiveness of the
proposed approach on moderate-scale post-norm Transformer models.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06184" title="Abstract">arXiv:2312.06184</a> [<a href="/pdf/2312.06184" title="Download PDF">pdf</a>, <a href="/format/2312.06184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances in Deterministic Human Motion Prediction: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+T">Tenghao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, with the continuous advancement of deep learning and the
emergence of large-scale human motion datasets, human motion prediction
technology has gradually gained prominence in various fields such as
human-computer interaction, autonomous driving, sports analysis, and personnel
tracking. This article introduces common model architectures in this domain
along with their respective advantages and disadvantages. It also
systematically summarizes recent research innovations, focusing on in-depth
discussions of relevant papers in these areas, thereby highlighting
forward-looking insights into the field's development. Furthermore, this paper
provides a comprehensive overview of existing methods, commonly used datasets,
and evaluation metrics in this field. Finally, it discusses some of the current
limitations in the field and proposes potential future research directions to
address these challenges and promote further advancements in human motion
prediction.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06185" title="Abstract">arXiv:2312.06185</a> [<a href="/pdf/2312.06185" title="Download PDF">pdf</a>, <a href="/format/2312.06185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowGPT: Black-Box Knowledge Injection for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junnan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zailiang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Large Language Models (LLMs), such as ChatGPT, offer interactive
APIs that can answer common questions at a human-expert level. However, these
models often give inaccurate or incorrect responses when faced with questions
requiring domain-specific or professional-specific knowledge not covered in
their training corpus. Furthermore, many state-of-the-art LLMs are not
open-source, making it challenging to inject knowledge with model APIs only. In
this work, we introduce KnowGPT, a black-box knowledge injection framework for
LLMs in question answering. KnowGPT leverages deep reinforcement learning (RL)
to extract relevant knowledge from Knowledge Graphs (KGs) and use Multi-Armed
Bandit (MAB) to construct the most suitable prompt for each question. Our
extensive experiments on three benchmark datasets showcase that KnowGPT
significantly enhances the existing methods. Notably, KnowGPT achieves an
average improvement of 23.7% over ChatGPT and an average improvement of 2.9%
over GPT-4. Additionally, KnowGPT attains a 91.6% accuracy on the OpenbookQA
official leaderboard, which is comparable to human-level performance.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06188" title="Abstract">arXiv:2312.06188</a> [<a href="/pdf/2312.06188" title="Download PDF">pdf</a>, <a href="/format/2312.06188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Ultra-Fine to Fine: Fine-tuning Ultra-Fine Entity Typing Models to  Fine-grained
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hongliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziqian Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">For the task of fine-grained entity typing (FET), due to the use of a large
number of entity types, it is usually considered too costly to manually
annotating a training dataset that contains an ample number of examples for
each type. A common way to address this problem is to use distantly annotated
training data that contains incorrect labels. However, the performance of
models trained solely with such data can be limited by the errors in the
automatic annotation. Recently, there are a few approaches that no longer
follow this conventional way. But without using sufficient direct entity typing
supervision may also cause them to yield inferior performance. In this paper,
we propose a new approach that can avoid the need of creating distantly labeled
data whenever there is a new type schema. We first train an entity typing model
that have an extremely board type coverage by using the ultra-fine entity
typing data. Then, when there is a need to produce a model for a newly designed
fine-grained entity type schema. We can simply fine-tune the previously trained
model with a small number of examples annotated under this schema. Experimental
results show that our approach achieves outstanding performance for FET under
the few-shot setting. It can also outperform state-of-the-art weak supervision
based methods after fine-tuning the model with only a small size manually
annotated training set.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06191" title="Abstract">arXiv:2312.06191</a> [<a href="/pdf/2312.06191" title="Download PDF">pdf</a>, <a href="/ps/2312.06191" title="Download PostScript">ps</a>, <a href="/format/2312.06191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative methods of linearized moment equations for rarefied gases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+X">Xiaoyu Dong</a>, 
<a href="/search/math?searchtype=author&query=Cai%2C+Z">Zhenning Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We study the iterative methods for large moment systems derived from the
linearized Boltzmann equation. By Fourier analysis, it is shown that the direct
application of the block symmetric Gauss-Seidel (BSGS) method has slower
convergence for smaller Knudsen numbers. Better convergence rates for dense
flows are then achieved by coupling the BSGS method with the micro-macro
decomposition, which treats the moment equations as a coupled system with a
microscopic part and a macroscopic part. Since the macroscopic part contains
only a small number of equations, it can be solved accurately during the
iteration with a relatively small computational cost, which accelerates the
overall iteration. The method is further generalized to the multiscale
decomposition which splits the moment system into many subsystems with
different orders of magnitude. Both one- and two-dimensional numerical tests
are carried out to examine the performances of these methods. Possible issues
regarding the efficiency and convergence are discussed in the conclusion.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06192" title="Abstract">arXiv:2312.06192</a> [<a href="/pdf/2312.06192" title="Download PDF">pdf</a>, <a href="/format/2312.06192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NutritionVerse-Synth: An Open Access Synthetically Generated 2D Food  Scene Dataset for Dietary Intake Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+S">Saeejith Nair</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+C+A">Chi-en Amy Tai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Manually tracking nutritional intake via food diaries is error-prone and
burdensome. Automated computer vision techniques show promise for dietary
monitoring but require large and diverse food image datasets. To address this
need, we introduce NutritionVerse-Synth (NV-Synth), a large-scale synthetic
food image dataset. NV-Synth contains 84,984 photorealistic meal images
rendered from 7,082 dynamically plated 3D scenes. Each scene is captured from
12 viewpoints and includes perfect ground truth annotations such as RGB, depth,
semantic, instance, and amodal segmentation masks, bounding boxes, and detailed
nutritional information per food item. We demonstrate the diversity of NV-Synth
across foods, compositions, viewpoints, and lighting. As the largest
open-source synthetic food dataset, NV-Synth highlights the value of
physics-based simulations for enabling scalable and controllable generation of
diverse photorealistic meal images to overcome data limitations and drive
advancements in automated dietary assessment using computer vision. In addition
to the dataset, the source code for our data generation framework is also made
publicly available at https://saeejithnair.github.io/nvsynth.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06193" title="Abstract">arXiv:2312.06193</a> [<a href="/pdf/2312.06193" title="Download PDF">pdf</a>, <a href="/format/2312.06193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DisControlFace: Disentangled Control for Personalized Facial Image  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Haozhe Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hengfei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Di Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changpeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we focus on exploring explicit fine-grained control of
generative facial image editing, all while generating faithful and consistent
personalized facial appearances. We identify the key challenge of this task as
the exploration of disentangled conditional control in the generation process,
and accordingly propose a novel diffusion-based framework, named
DisControlFace, comprising two decoupled components. Specifically, we leverage
an off-the-shelf diffusion reconstruction model as the backbone and freeze its
pre-trained weights, which helps to reduce identity shift and recover
editing-unrelated details of the input image. Furthermore, we construct a
parallel control network that is compatible with the reconstruction backbone to
generate spatial control conditions based on estimated explicit face
parameters. Finally, we further reformulate the training pipeline into a
masked-autoencoding form to effectively achieve disentangled training of our
DisControlFace. Our DisControlNet can perform robust editing on any facial
image through training on large-scale 2D in-the-wild portraits and also
supports low-cost fine-tuning with few additional images to further learn
diverse personalized priors of a specific person. Extensive experiments
demonstrate that DisControlFace can generate realistic facial images
corresponding to various face control conditions, while significantly improving
the preservation of the personalized facial details.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06195" title="Abstract">arXiv:2312.06195</a> [<a href="/pdf/2312.06195" title="Download PDF">pdf</a>, <a href="/format/2312.06195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stealing Maggie&#x27;s Secrets -- On the Challenges of IP Theft Through FPGA  Reverse Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klix%2C+S">Simon Klix</a>, 
<a href="/search/cs?searchtype=author&query=Albartus%2C+N">Nils Albartus</a>, 
<a href="/search/cs?searchtype=author&query=Speith%2C+J">Julian Speith</a>, 
<a href="/search/cs?searchtype=author&query=Staat%2C+P">Paul Staat</a>, 
<a href="/search/cs?searchtype=author&query=Verstege%2C+A">Alice Verstege</a>, 
<a href="/search/cs?searchtype=author&query=Wilde%2C+A">Annika Wilde</a>, 
<a href="/search/cs?searchtype=author&query=Lammers%2C+D">Daniel Lammers</a>, 
<a href="/search/cs?searchtype=author&query=Langheinrich%2C+J">J&#xf6;rn Langheinrich</a>, 
<a href="/search/cs?searchtype=author&query=Kison%2C+C">Christian Kison</a>, 
<a href="/search/cs?searchtype=author&query=Sester%2C+S">Sebastian Sester</a>, 
<a href="/search/cs?searchtype=author&query=Holcomb%2C+D">Daniel Holcomb</a>, 
<a href="/search/cs?searchtype=author&query=Paar%2C+C">Christof Paar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Intellectual Property (IP) theft is a cause for major financial and
reputational damage, reportedly in the range of hundreds of billions of dollars
annually in the U.S. alone. Field Programmable Gate Arrays (FPGAs) are
particularly exposed to IP theft, because their configuration file contains the
IP in a proprietary format that can be mapped to a gate-level netlist with
moderate effort. Despite this threat, the scientific understanding of this
issue lacks behind reality, thereby preventing an in-depth assessment of IP
theft from FPGAs in academia. We address this discrepancy through a real-world
case study on a Lattice iCE40 FPGA found inside iPhone 7. Apple refers to this
FPGA as Maggie. By reverse engineering the proprietary signal-processing
algorithm implemented on Maggie, we generate novel insights into the actual
efforts required to commit FPGA IP theft and the challenges an attacker faces
on the way. Informed by our case study, we then introduce generalized netlist
reverse engineering techniques that drastically reduce the required manual
effort and are applicable across a diverse spectrum of FPGA implementations and
architectures. We evaluate these techniques on seven benchmarks that are
representative for different FPGA applications and have been synthesized for
Xilinx and Lattice FPGAs. Finally, we provide a comprehensive open-source
tool-suite of netlist reverse engineering techniques to foster future research,
enable the community to perform realistic threat assessments, and facilitate
the evaluation of novel countermeasures.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06197" title="Abstract">arXiv:2312.06197</a> [<a href="/pdf/2312.06197" title="Download PDF">pdf</a>, <a href="/format/2312.06197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Music-PAW: Learning Music Representations via Hierarchical Part-whole  Interaction and Contrast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Liqun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenhua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The excellent performance of recent self-supervised learning methods on
various downstream tasks has attracted great attention from academia and
industry. Some recent research efforts have been devoted to self-supervised
music representation learning. Nevertheless, most of them learn to represent
equally-sized music clips in the waveform or a spectrogram. Despite being
effective in some tasks, learning music representations in such a manner
largely neglect the inherent part-whole hierarchies of music. Due to the
hierarchical nature of the auditory cortex [24], understanding the bottom-up
structure of music, i.e., how different parts constitute the whole at different
levels, is essential for music understanding and representation learning. This
work pursues hierarchical music representation learning and introduces the
Music-PAW framework, which enables feature interactions of cropped music clips
with part-whole hierarchies. From a technical perspective, we propose a
transformer-based part-whole interaction module to progressively reason the
structural relationships between part-whole music clips at adjacent levels.
Besides, to create a multi-hierarchy representation space, we devise a
hierarchical contrastive learning objective to align part-whole music
representations in adjacent hierarchies. The merits of audio representation
learning from part-whole hierarchies have been validated on various downstream
tasks, including music classification (single-label and multi-label), cover
song identification and acoustic scene classification.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06198" title="Abstract">arXiv:2312.06198</a> [<a href="/pdf/2312.06198" title="Download PDF">pdf</a>, <a href="/format/2312.06198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized View and Geometry Distillation from Multi-view Diffuser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating multi-view images from a single input view using image-conditioned
diffusion models is a recent advancement and has shown considerable potential.
However, issues such as the lack of consistency in synthesized views and
over-smoothing in extracted geometry persist. Previous methods integrate
multi-view consistency modules or impose additional supervisory to enhance view
consistency while compromising on the flexibility of camera positioning and
limiting the versatility of view synthesis. In this study, we consider the
radiance field optimized during geometry extraction as a more rigid consistency
prior, compared to volume and ray aggregation used in previous works. We
further identify and rectify a critical bias in the traditional radiance field
optimization process through score distillation from a multi-view diffuser. We
introduce an Unbiased Score Distillation (USD) that utilizes unconditioned
noises from a 2D diffusion model, greatly refining the radiance field fidelity.
we leverage the rendered views from the optimized radiance field as the basis
and develop a two-step specialization process of a 2D diffusion model, which is
adept at conducting object-specific denoising and generating high-quality
multi-view images. Finally, we recover faithful geometry and texture directly
from the refined multi-view images. Empirical evaluations demonstrate that our
optimized geometry and view distillation technique generates comparable results
to the state-of-the-art models trained on extensive datasets, all while
maintaining freedom in camera positioning.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06199" title="Abstract">arXiv:2312.06199</a> [<a href="/pdf/2312.06199" title="Download PDF">pdf</a>, <a href="/format/2312.06199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transferable Adversarial Attacks with Centralized Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yu-an Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yajie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruinan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wencong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, to appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adversarial transferability enables black-box attacks on unknown victim deep
neural networks (DNNs), rendering attacks viable in real-world scenarios.
Current transferable attacks create adversarial perturbation over the entire
image, resulting in excessive noise that overfit the source model.
Concentrating perturbation to dominant image regions that are model-agnostic is
crucial to improving adversarial efficacy. However, limiting perturbation to
local regions in the spatial domain proves inadequate in augmenting
transferability. To this end, we propose a transferable adversarial attack with
fine-grained perturbation optimization in the frequency domain, creating
centralized perturbation. We devise a systematic pipeline to dynamically
constrain perturbation optimization to dominant frequency coefficients. The
constraint is optimized in parallel at each iteration, ensuring the directional
alignment of perturbation optimization with model prediction. Our approach
allows us to centralize perturbation towards sample-specific important
frequency features, which are shared by DNNs, effectively mitigating source
model overfitting. Experiments demonstrate that by dynamically centralizing
perturbation on dominating frequency coefficients, crafted adversarial examples
exhibit stronger transferability, and allowing them to bypass various defenses.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06200" title="Abstract">arXiv:2312.06200</a> [<a href="/pdf/2312.06200" title="Download PDF">pdf</a>, <a href="/format/2312.06200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving the Fundamental Limit of Lossless Analog Compression via  Polarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Liuquan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huazi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures. The short version is presented at the IEEE Global Communications Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we study the lossless analog compression for i.i.d.
nonsingular signals via the polarization-based framework. We prove that for
nonsingular source, the error probability of maximum a posteriori (MAP)
estimation polarizes under the Hadamard transform. Building on this insight, we
propose partial Hadamard compression and develop the corresponding analog
successive cancellation (SC) decoder. The proposed scheme consists of
deterministic measurement matrices and non-iterative reconstruction algorithm,
providing benefits in both space and computational complexity. Using the
polarization of error probability, we prove that our approach achieves the
information-theoretical limit for lossless analog compression developed by Wu
and Verdu.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06202" title="Abstract">arXiv:2312.06202</a> [<a href="/pdf/2312.06202" title="Download PDF">pdf</a>, <a href="/ps/2312.06202" title="Download PostScript">ps</a>, <a href="/format/2312.06202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforms for Multiplicative and Fractional Programming with Broad  Applications in Edge Computing and Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Performance (cs.PF); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Multiplicative Programming (MP) pertains to a spectrum of optimization
problems that involve product term(s). As computational paradigms of
communication systems continue to evolve, particularly concerning the
offloading strategies of computationally intensive tasks simultaneously to
centralized or decentralized servers, designing or optimizing effective
communication systems with MP techniques becomes increasingly indispensable.
Similarly, Fractional Programming (FP) is another significant branch in the
optimization domain, addressing various essential scenarios in communication.
For instance, in minimization optimization problems, transmission power and
processing delay of communication systems are considered critical metrics. In a
very recent JSAC paper by Zhao et al. [2], an innovative transform (Zhao's
Optimization Transform) was proposed for solving the minimization of MP and FP
problems. Nevertheless, the resolution of optimization problems in
communication systems encounters several limitations when adopting Zhao's
optimization transform, especially in MP problems. Primarily, objective
functions proposed in these optimization problems typically involve
sum-of-products terms and the optimization variables are always discrete
leading to NP-hard problems. Furthermore, multiple functions mapping to the
non-negative domain in these scenarios can result in auxiliary variables being
zero values, while the same situation is avoidable in FP problems due to the
presence of these functions in the denominator. In this paper, we introduce an
updated transform, building on the foundations of Zhao's original method,
designed to effectively overcome these challenges by reformulating the original
problem into a series of convex or concave problems. This introduced problem
reformulation provides a superior iteration algorithm with demonstrable
convergence to a stationary point.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06203" title="Abstract">arXiv:2312.06203</a> [<a href="/pdf/2312.06203" title="Download PDF">pdf</a>, <a href="/ps/2312.06203" title="Download PostScript">ps</a>, <a href="/format/2312.06203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offloading and Quality Control for AI Generated Content Services in Edge  Computing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI); Performance (cs.PF)

</div>
<p class="mathjax">AI-Generated Content (AIGC), as a novel manner of providing Metaverse
services in the forthcoming Internet paradigm, can resolve the obstacles of
immersion requirements. Concurrently, edge computing, as an evolutionary
paradigm of computing in communication systems, effectively augments real-time
interactive services. In pursuit of enhancing the accessibility of AIGC
services, the deployment of AIGC models (e.g., diffusion models) to edge
servers and local devices has become a prevailing trend. Nevertheless, this
approach faces constraints imposed by battery life and computational resources
when tasks are offloaded to local devices, limiting the capacity to deliver
high-quality content to users while adhering to stringent latency requirements.
So there will be a tradeoff between the utility of AIGC models and offloading
decisions in the edge computing paradigm. This paper proposes a joint
optimization algorithm for offloading decisions, computation time, and
diffusion steps of the diffusion models in the reverse diffusion stage.
Moreover, we take the average error into consideration as the metric for
evaluating the quality of the generated results. Experimental results
conclusively demonstrate that the proposed algorithm achieves superior joint
optimization performance compared to the baselines.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06205" title="Abstract">arXiv:2312.06205</a> [<a href="/pdf/2312.06205" title="Download PDF">pdf</a>, <a href="/format/2312.06205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Journey, Not the Destination: How Data Guides Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+K">Kristian Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Vendrow%2C+J">Joshua Vendrow</a>, 
<a href="/search/cs?searchtype=author&query=Salman%2C+H">Hadi Salman</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S+M">Sung Min Park</a>, 
<a href="/search/cs?searchtype=author&query=Madry%2C+A">Aleksander Madry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models trained on large datasets can synthesize photo-realistic
images of remarkable quality and diversity. However, attributing these images
back to the training data-that is, identifying specific training examples which
caused an image to be generated-remains a challenge. In this paper, we propose
a framework that: (i) provides a formal notion of data attribution in the
context of diffusion models, and (ii) allows us to counterfactually validate
such attributions. Then, we provide a method for computing these attributions
efficiently. Finally, we apply our method to find (and evaluate) such
attributions for denoising diffusion probabilistic models trained on CIFAR-10
and latent diffusion models trained on MS COCO. We provide code at
https://github.com/MadryLab/journey-TRAK .
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06206" title="Abstract">arXiv:2312.06206</a> [<a href="/pdf/2312.06206" title="Download PDF">pdf</a>, <a href="/ps/2312.06206" title="Download PostScript">ps</a>, <a href="/format/2312.06206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splitting ADI scheme for fractional Laplacian wave equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sun%2C+T">Tao Sun</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+H">Hai-Wei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 27 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we investigate the numerical solution of the two-dimensional
fractional Laplacian wave equations. After splitting out the Riesz fractional
derivatives from the fractional Laplacian, we treat the Riesz fractional
derivatives with an implicit scheme while solving the rest part explicitly.
Thanks to the tensor structure of the Riesz fractional derivatives, a splitting
alternative direction implicit (S-ADI) scheme is proposed by incorporating an
ADI remainder. Then the Gohberg-Semencul formula, combined with fast Fourier
transform, is proposed to solve the derived Toeplitz linear systems at each
time integration. Theoretically, we demonstrate that the S-ADI scheme is
unconditionally stable and possesses second-order accuracy. Finally, numerical
experiments are performed to demonstrate the accuracy and efficiency of the
S-ADI scheme.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06207" title="Abstract">arXiv:2312.06207</a> [<a href="/pdf/2312.06207" title="Download PDF">pdf</a>, <a href="/format/2312.06207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primer on RecoNIC: RDMA-enabled Compute Offloading on SmartNIC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+G">Guanwen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Kolekar%2C+A">Aditya Kolekar</a>, 
<a href="/search/cs?searchtype=author&query=Amornpaisannon%2C+B">Burin Amornpaisannon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+I">Inho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Javaid%2C+H">Haris Javaid</a>, 
<a href="/search/cs?searchtype=author&query=Baldi%2C+M">Mario Baldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RecoNIC is available at <a href="https://github.com/Xilinx/RecoNIC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Today's data centers consist of thousands of network-connected hosts, each
with CPUs and accelerators such as GPUs and FPGAs. These hosts also contain
network interface cards (NICs), operating at speeds of 100Gb/s or higher, that
are used to communicate with each other. We propose RecoNIC, an FPGA-based
RDMA-enabled SmartNIC platform that is designed for compute acceleration while
minimizing the overhead associated with data copies (in CPU-centric accelerator
systems) by bringing network data as close to computation as possible. Since
RDMA is the defacto transport-layer protocol for improved communication in data
center workloads, RecoNIC includes an RDMA offload engine for high throughput
and low latency data transfers. Developers have the flexibility to design their
accelerators using RTL, HLS or Vitis Networking P4 within the RecoNIC's
programmable compute blocks. These compute blocks can access host memory as
well as memory in remote peers through the RDMA offload engine. Furthermore,
the RDMA offload engine is shared by both the host and compute blocks, which
makes RecoNIC a very flexible platform. Lastly, we have open-sourced RecoNIC
for the research community to enable experimentation with RDMA-based
applications and use-cases.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06209" title="Abstract">arXiv:2312.06209</a> [<a href="/pdf/2312.06209" title="Download PDF">pdf</a>, <a href="/format/2312.06209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-field chemo-mechanical modelling of corrosion-induced cracking in  reinforced concrete subjected to non-uniform chloride-induced corrosion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korec%2C+E">E. Korec</a>, 
<a href="/search/cs?searchtype=author&query=Jirasek%2C+M">M. Jirasek</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+H+S">H.S. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Pa%C3%B1eda%2C+E">E. Mart&#xed;nez-Pa&#xf1;eda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">A model for corrosion-induced cracking of reinforced concrete subjected to
non-uniform chloride-induced corrosion is presented. The gradual corrosion
initiation of the steel surface is investigated by simulating chloride
transport considering binding. The transport of iron from the steel surface,
its subsequent precipitation into rust, and the associated
precipitation-induced pressure are explicitly modelled. Model results, obtained
through finite element simulations, agree very well with experimental data,
showing significantly improved accuracy over uniform corrosion modelling. The
results obtained from case studies reveal that crack-facilitated transport of
chlorides cannot be neglected, that the size of the anodic region must be
considered, and that precipitate accumulation in pores can take years.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06211" title="Abstract">arXiv:2312.06211</a> [<a href="/pdf/2312.06211" title="Download PDF">pdf</a>, <a href="/format/2312.06211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured state-space models are deep Wiener models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bonassi%2C+F">Fabio Bonassi</a>, 
<a href="/search/eess?searchtype=author&query=Andersson%2C+C">Carl Andersson</a>, 
<a href="/search/eess?searchtype=author&query=Mattsson%2C+P">Per Mattsson</a>, 
<a href="/search/eess?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is an extended version of a manuscript submitted to IFAC for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The goal of this paper is to provide a system identification-friendly
introduction to the Structured State-space Models (SSMs). These models have
become recently popular in the machine learning community since, owing to their
parallelizability, they can be efficiently and scalably trained to tackle
extremely-long sequence classification and regression problems. Interestingly,
SSMs appear as an effective way to learn deep Wiener models, which allows to
reframe SSMs as an extension of a model class commonly used in system
identification. In order to stimulate a fruitful exchange of ideas between the
machine learning and system identification communities, we deem it useful to
summarize the recent contributions on the topic in a structured and accessible
form. At last, we highlight future research directions for which this community
could provide impactful contributions.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06217" title="Abstract">arXiv:2312.06217</a> [<a href="/pdf/2312.06217" title="Download PDF">pdf</a>, <a href="/format/2312.06217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Reduced-Order Linear Parameter-Varying Models of Nonlinear  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Koelewijn%2C+P+J+W">Patrick J. W. Koelewijn</a>, 
<a href="/search/eess?searchtype=author&query=Sing%2C+R">Rajiv Sing</a>, 
<a href="/search/eess?searchtype=author&query=Seiler%2C+P">Peter Seiler</a>, 
<a href="/search/eess?searchtype=author&query=T%C3%B3th%2C+R">Roland T&#xf3;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 20th IFAC Symposium on System Identification (SYSID 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we consider the learning of a Reduced-Order Linear
Parameter-Varying Model (ROLPVM) of a nonlinear dynamical system based on data.
This is achieved by a two-step procedure. In the first step, we learn a
projection to a lower dimensional state-space. In step two, an LPV model is
learned on the reduced-order state-space by means of a novel, efficient
parameterization of the LPV model in terms neural networks. The improved
modeling accuracy of the method compared to an existing method is demonstrated
by simulation examples.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06219" title="Abstract">arXiv:2312.06219</a> [<a href="/pdf/2312.06219" title="Download PDF">pdf</a>, <a href="/format/2312.06219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Long Term Waypoint-Based Trajectory Prediction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghoul%2C+A">Amina Ghoul</a>, 
<a href="/search/cs?searchtype=author&query=Yahiaoui%2C+I">Itheri Yahiaoui</a> (URCA), 
<a href="/search/cs?searchtype=author&query=Nashashibi%2C+F">Fawzi Nashashibi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.04312">arXiv:2308.04312</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ITSC, Sep 2023, Bilbao, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Predicting the future trajectories of dynamic agents in complex environments
is crucial for a variety of applications, including autonomous driving,
robotics, and human-computer interaction. It is a challenging task as the
behavior of the agent is unknown and intrinsically multimodal. Our key insight
is that the agents behaviors are influenced not only by their past trajectories
and their interaction with their immediate environment but also largely with
their long term waypoint (LTW). In this paper, we study the impact of adding a
long-term goal on the performance of a trajectory prediction framework. We
present an interpretable long term waypoint-driven prediction framework
(WayDCM). WayDCM first predict an agent's intermediate goal (IG) by encoding
his interactions with the environment as well as his LTW using a combination of
a Discrete choice Model (DCM) and a Neural Network model (NN). Then, our model
predicts the corresponding trajectories. This is in contrast to previous work
which does not consider the ultimate intent of the agent to predict his
trajectory. We evaluate and show the effectiveness of our approach on the Waymo
Open dataset.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06220" title="Abstract">arXiv:2312.06220</a> [<a href="/pdf/2312.06220" title="Download PDF">pdf</a>, <a href="/format/2312.06220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dance of Channel and Sequence: An Efficient Attention-Based Approach for  Multivariate Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yipeng Mo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Nan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Honghe Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bixiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Songhai Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Site Mo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent developments, predictive models for multivariate time series
analysis have exhibited commendable performance through the adoption of the
prevalent principle of channel independence. Nevertheless, it is imperative to
acknowledge the intricate interplay among channels, which fundamentally
influences the outcomes of multivariate predictions. Consequently, the notion
of channel independence, while offering utility to a certain extent, becomes
increasingly impractical, leading to information degradation. In response to
this pressing concern, we present CSformer, an innovative framework
characterized by a meticulously engineered two-stage self-attention mechanism.
This mechanism is purposefully designed to enable the segregated extraction of
sequence-specific and channel-specific information, while sharing parameters to
promote synergy and mutual reinforcement between sequences and channels.
Simultaneously, we introduce sequence adapters and channel adapters, ensuring
the model's ability to discern salient features across various dimensions.
Rigorous experimentation, spanning multiple real-world datasets, underscores
the robustness of our approach, consistently establishing its position at the
forefront of predictive performance across all datasets. This augmentation
substantially enhances the capacity for feature extraction inherent to
multivariate time series data, facilitating a more comprehensive exploitation
of the available information.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06221" title="Abstract">arXiv:2312.06221</a> [<a href="/pdf/2312.06221" title="Download PDF">pdf</a>, <a href="/format/2312.06221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSOT: Curriculum and Structure-Aware Optimal Transport for Learning with  Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wanxing Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning with noisy labels (LNL) poses a significant challenge in training a
well-generalized model while avoiding overfitting to corrupted labels. Recent
advances have achieved impressive performance by identifying clean labels and
correcting corrupted labels for training. However, the current approaches rely
heavily on the model's predictions and evaluate each sample independently
without considering either the global and local structure of the sample
distribution. These limitations typically result in a suboptimal solution for
the identification and correction processes, which eventually leads to models
overfitting to incorrect labels. In this paper, we propose a novel optimal
transport (OT) formulation, called Curriculum and Structure-aware Optimal
Transport (CSOT). CSOT concurrently considers the inter- and intra-distribution
structure of the samples to construct a robust denoising and relabeling
allocator. During the training process, the allocator incrementally assigns
reliable labels to a fraction of the samples with the highest confidence. These
labels have both global discriminability and local coherence. Notably, CSOT is
a new OT formulation with a nonconvex objective function and curriculum
constraints, so it is not directly compatible with classical OT solvers. Here,
we develop a lightspeed computational method that involves a scaling iteration
within a generalized conditional gradient framework to solve CSOT efficiently.
Extensive experiments demonstrate the superiority of our method over the
current state-of-the-arts in LNL. Code is available at
https://github.com/changwxx/CSOT-for-LNL.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06224" title="Abstract">arXiv:2312.06224</a> [<a href="/pdf/2312.06224" title="Download PDF">pdf</a>, <a href="/format/2312.06224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Vision Language Pretraining: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+P">Prashant Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Amgain%2C+S">Sanskar Amgain</a>, 
<a href="/search/cs?searchtype=author&query=Khanal%2C+B">Bidur Khanal</a>, 
<a href="/search/cs?searchtype=author&query=Linte%2C+C+A">Cristian A. Linte</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+B">Binod Bhattarai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Medical Vision Language Pretraining (VLP) has recently emerged as a promising
solution to the scarcity of labeled data in the medical domain. By leveraging
paired/unpaired vision and text datasets through self-supervised learning,
models can be trained to acquire vast knowledge and learn robust feature
representations. Such pretrained models have the potential to enhance multiple
downstream medical tasks simultaneously, reducing the dependency on labeled
data. However, despite recent progress and its potential, there is no such
comprehensive survey paper that has explored the various aspects and
advancements in medical VLP. In this paper, we specifically review existing
works through the lens of different pretraining objectives, architectures,
downstream evaluation tasks, and datasets utilized for pretraining and
downstream tasks. Subsequently, we delve into current challenges in medical
VLP, discussing existing and potential solutions, and conclude by highlighting
future directions. To the best of our knowledge, this is the first survey
focused on medical VLP.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06226" title="Abstract">arXiv:2312.06226</a> [<a href="/pdf/2312.06226" title="Download PDF">pdf</a>, <a href="/format/2312.06226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Representation Learning via Decoupling Style and Spurious  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruimeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yuanhao Pu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaoyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper considers the out-of-distribution (OOD) generalization problem
under the setting that both style distribution shift and spurious features
exist and domain labels are missing. This setting frequently arises in
real-world applications and is underlooked because previous approaches mainly
handle either of these two factors. The critical challenge is decoupling style
and spurious features in the absence of domain labels. To address this
challenge, we first propose a structural causal model (SCM) for the image
generation process, which captures both style distribution shift and spurious
features. The proposed SCM enables us to design a new framework called IRSS,
which can gradually separate style distribution and spurious features from
images by introducing adversarial neural networks and multi-environment
optimization, thus achieving OOD generalization. Moreover, it does not require
additional supervision (e.g., domain labels) other than the images and their
corresponding labels. Experiments on benchmark datasets demonstrate that IRSS
outperforms traditional OOD methods and solves the problem of Invariant risk
minimization (IRM) degradation, enabling the extraction of invariant features
under distribution shift.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06227" title="Abstract">arXiv:2312.06227</a> [<a href="/pdf/2312.06227" title="Download PDF">pdf</a>, <a href="/format/2312.06227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers&#x27; Coding  Practices with Insecure Suggestions from Poisoned AI Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sanghak Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kiho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonhye Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doowon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyoungshick Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the 45th IEEE Symposium on Security and Privacy (S&amp;P) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">AI-powered coding assistant tools have revolutionized the software
engineering ecosystem. However, prior work has demonstrated that these tools
are vulnerable to poisoning attacks. In a poisoning attack, an attacker
intentionally injects maliciously crafted insecure code snippets into training
datasets to manipulate these tools. The poisoned tools can suggest insecure
code to developers, resulting in vulnerabilities in their products that
attackers can exploit. However, it is still little understood whether such
poisoning attacks against the tools would be practical in real-world settings
and how developers address the poisoning attacks during software development.
To understand the real-world impact of poisoning attacks on developers who rely
on AI-powered coding assistants, we conducted two user studies: an online
survey and an in-lab study. The online survey involved 238 participants,
including software developers and computer science students. The survey results
revealed widespread adoption of these tools among participants, primarily to
enhance coding speed, eliminate repetition, and gain boilerplate code. However,
the survey also found that developers may misplace trust in these tools because
they overlooked the risk of poisoning attacks. The in-lab study was conducted
with 30 professional developers. The developers were asked to complete three
programming tasks with a representative type of AI-powered coding assistant
tool, running on Visual Studio Code. The in-lab study results showed that
developers using a poisoned ChatGPT-like tool were more prone to including
insecure code than those using an IntelliCode-like tool or no tool. This
demonstrates the strong influence of these tools on the security of generated
code. Our study results highlight the need for education and improved coding
practices to address new security issues introduced by AI-powered coding
assistant tools.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06229" title="Abstract">arXiv:2312.06229</a> [<a href="/pdf/2312.06229" title="Download PDF">pdf</a>, <a href="/format/2312.06229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Cyberattacks through AI-based Reactive Systems: A Holistic  Review and Future Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molina%2C+S+B">Sergio Bernardez Molina</a>, 
<a href="/search/cs?searchtype=author&query=Nespoli%2C+P">Pantaleone Nespoli</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A1rmol%2C+F+G">F&#xe9;lix G&#xf3;mez M&#xe1;rmol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There is no denying that the use of Information Technology (IT) is undergoing
exponential growth in today's world. This digital transformation has also given
rise to a multitude of security challenges, notably in the realm of cybercrime.
In response to these growing threats, public and private sectors have
prioritized the strengthening of IT security measures. In light of the growing
security concern, Artificial Intelligence (AI) has gained prominence within the
cybersecurity landscape. This paper presents a comprehensive survey of recent
advancements in AI-driven threat response systems. To the best of our
knowledge, the most recent survey covering the AI reaction domain was conducted
in 2017. Since then, considerable literature has been published and therefore
it is worth reviewing it. By means of several shared features, each of the
studies is compared on a common ground. Through an analysis of the research
papers conducted on a standardized basis, this survey aims to unravel the
complexities and opportunities of integrating AI into cyber defense. The
conclusions drawn from this collective analysis provide a comprehensive
snapshot of the evolving landscape at the intersection of AI and cybersecurity.
This landscape underscores the growing significance of not only anticipating
and detecting threats but also responding to them effectively. Additionally,
from these reviews, various research challenges for the future are presented.
These challenges serve as a roadmap for researchers and practitioners in the
field of AI-integrated reactive strategies.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06230" title="Abstract">arXiv:2312.06230</a> [<a href="/pdf/2312.06230" title="Download PDF">pdf</a>, <a href="/format/2312.06230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activation Gradient based Poisoned Sample Detection Against Backdoor  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Danni Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shaokui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This work focuses on defending against the data poisoning based backdoor
attacks, which bring in serious security threats to deep neural networks
(DNNs). Specifically, given a untrustworthy training dataset, we aim to filter
out potential poisoned samples, \ie, poisoned sample detection (PSD). The key
solution for this task is to find a discriminative metric between clean and
poisoned samples, even though there is no information about the potential
poisoned samples (\eg, the attack method, the poisoning ratio). In this work,
we develop an innovative detection approach from the perspective of the
gradient \wrt activation (\ie, activation gradient direction, AGD) of each
sample in the backdoored model trained on the untrustworthy dataset. We present
an interesting observation that the circular distribution of AGDs among all
samples of the target class is much more dispersed than that of one clean
class. Motivated by this observation, we firstly design a novel metric called
Cosine similarity Variation towards Basis Transition (CVBT) to measure the
circular distribution's dispersion of each class. Then, we design a simple yet
effective algorithm with identifying the target class(es) using outlier
detection on CVBT scores of all classes, followed by progressively filtering of
poisoned samples according to the cosine similarities of AGDs between every
potential sample and a few additional clean samples. Extensive experiments
under various settings verify that given very few clean samples of each class,
the proposed method could filter out most poisoned samples, while avoiding
filtering out clean samples, verifying its effectiveness on the PSD task. Codes
are available at
https://github.com/SCLBD/bdzoo2/blob/dev/detection_pretrain/agpd.py.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06231" title="Abstract">arXiv:2312.06231</a> [<a href="/pdf/2312.06231" title="Download PDF">pdf</a>, <a href="/format/2312.06231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering communities of pipelines in the task-fMRI analytical space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Germani%2C+E">Elodie Germani</a> (EMPENN), 
<a href="/search/cs?searchtype=author&query=Fromont%2C+E">Elisa Fromont</a> (LACODAM), 
<a href="/search/cs?searchtype=author&query=Maumet%2C+C">Camille Maumet</a> (EMPENN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Functional magnetic resonance imaging analytical workflows are highly
flexible with no definite consensus on how to choose a pipeline. While methods
have been developed to explore this analytical space, there is still a lack of
understanding of the relationships between the different pipelines. We use
community detection algorithms to explore the pipeline space and assess its
stability across different contexts. We show that there are subsets of
pipelines that give similar results, especially those sharing specific
parameters (e.g. number of motion regressors, software packages, etc.), with
relative stability across groups of participants. By visualizing the
differences between these subsets, we describe the effect of pipeline
parameters and derive general relationships in the analytical space.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06235" title="Abstract">arXiv:2312.06235</a> [<a href="/pdf/2312.06235" title="Download PDF">pdf</a>, <a href="/format/2312.06235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Effect of Replacement Policies on The Security of Randomized  Cache Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peters%2C+M">Moritz Peters</a>, 
<a href="/search/cs?searchtype=author&query=Gaudin%2C+N">Nicolas Gaudin</a>, 
<a href="/search/cs?searchtype=author&query=Thoma%2C+J+P">Jan Philipp Thoma</a>, 
<a href="/search/cs?searchtype=author&query=Lap%C3%B4tre%2C+V">Vianney Lap&#xf4;tre</a>, 
<a href="/search/cs?searchtype=author&query=Cotret%2C+P">Pascal Cotret</a>, 
<a href="/search/cs?searchtype=author&query=Gogniat%2C+G">Guy Gogniat</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCneysu%2C+T">Tim G&#xfc;neysu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Randomizing the mapping of addresses to cache entries has proven to be an
effective technique for hardening caches against contention-based attacks like
Prime+Prome. While attacks and defenses are still evolving, it is clear that
randomized caches significantly increase the security against such attacks.
However, one aspect that is missing from most analyses of randomized cache
architectures is the choice of the replacement policy. Often, only the random-
and LRU replacement policies are investigated. However, LRU is not applicable
to randomized caches due to its immense hardware overhead, while the random
replacement policy is not ideal from a performance and security perspective.
<br />In this paper, we explore replacement policies for randomized caches. We
develop two new replacement policies and evaluate a total of five replacement
policies regarding their security against Prime+Prune+Probe attackers.
Moreover, we analyze the effect of the replacement policy on the system's
performance and quantify the introduced hardware overhead. We implement
randomized caches with configurable replacement policies in software and
hardware using a custom cache simulator, gem5, and the CV32E40P RISC-V core.
Among others, we show that the construction of eviction sets with our new
policy, VARP-64, requires over 25-times more cache accesses than with the
random replacement policy while also enhancing overall performance.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06236" title="Abstract">arXiv:2312.06236</a> [<a href="/pdf/2312.06236" title="Download PDF">pdf</a>, <a href="/format/2312.06236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Startup Success with Text Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gavrilenko%2C+E">Emily Gavrilenko</a>, 
<a href="/search/cs?searchtype=author&query=Khosmood%2C+F">Foaad Khosmood</a>, 
<a href="/search/cs?searchtype=author&query=Rastad%2C+M">Mahdi Rastad</a>, 
<a href="/search/cs?searchtype=author&query=Moghaddam%2C+S+A">Sadra Amiri Moghaddam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages. Accepted and presented at ICAIF 2023: ACM International Conference on AI in Finance, Workshop on NLP and Network Analysis, Nov. 27, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Investors are interested in predicting future success of startup companies,
preferably using publicly available data which can be gathered using free
online sources. Using public-only data has been shown to work, but there is
still much room for improvement. Two of the best performing prediction
experiments use 17 and 49 features respectively, mostly numeric and categorical
in nature. In this paper, we significantly expand and diversify both the
sources and the number of features (to 171) to achieve better prediction. Data
collected from Crunchbase, the Google Search API, and Twitter (now X) are used
to predict whether a company will raise a round of funding within a fixed time
horizon. Much of the new features are textual and the Twitter subset include
linguistic metrics such as measures of passive voice and parts-of-speech. A
total of ten machine learning models are also evaluated for best performance.
The adaptable model can be used to predict funding 1-5 years into the future,
with a variable cutoff threshold to favor either precision or recall.
Prediction with comparable assumptions generally achieves F scores above 0.730
which outperforms previous attempts in the literature (0.531), and does so with
fewer examples. Furthermore, we find that the vast majority of the performance
impact comes from the top 18 of 171 features which are mostly generic company
observations, including the best performing individual feature which is the
free-form text description of the company.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06240" title="Abstract">arXiv:2312.06240</a> [<a href="/pdf/2312.06240" title="Download PDF">pdf</a>, <a href="/format/2312.06240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UIEDP:Underwater Image Enhancement with Diffusion Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dazhao Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Enhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lingyu Si</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fanjiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+J">Jianwei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater image enhancement (UIE) aims to generate clear images from
low-quality underwater images. Due to the unavailability of clear reference
images, researchers often synthesize them to construct paired datasets for
training deep models. However, these synthesized images may sometimes lack
quality, adversely affecting training outcomes. To address this issue, we
propose UIE with Diffusion Prior (UIEDP), a novel framework treating UIE as a
posterior distribution sampling process of clear images conditioned on degraded
underwater inputs. Specifically, UIEDP combines a pre-trained diffusion model
capturing natural image priors with any existing UIE algorithm, leveraging the
latter to guide conditional generation. The diffusion prior mitigates the
drawbacks of inferior synthetic images, resulting in higher-quality image
generation. Extensive experiments have demonstrated that our UIEDP yields
significant improvements across various metrics, especially no-reference image
quality assessment. And the generated enhanced images also exhibit a more
natural appearance.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06244" title="Abstract">arXiv:2312.06244</a> [<a href="/pdf/2312.06244" title="Download PDF">pdf</a>, <a href="/format/2312.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Team-related Features in Code Review Prediction Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Witter%2C+E">Eduardo Witter</a>, 
<a href="/search/cs?searchtype=author&query=Nunes%2C+I">Ingrid Nunes</a>, 
<a href="/search/cs?searchtype=author&query=Jannach%2C+D">Dietmar Jannach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern Code Review (MCR) is an informal tool-assisted quality assurance
practice. It relies on the asynchronous communication among the authors of code
changes and reviewers, who are developers that provide feedback. However, from
candidate developers, some are able to provide better feedback than others
given a particular context. The selection of reviewers is thus an important
task, which can benefit from automated support. Many approaches have been
proposed in this direction, using for example data from code review
repositories to recommend reviewers. In this paper, we propose the use of
team-related features to improve the performance of predictions that are
helpful to build code reviewer recommenders, with our target predictions being
the identification of reviewers that would participate in a review and the
provided amount of feedback. We evaluate the prediction power of these
features, which are related to code ownership, workload, and team relationship.
This evaluation was done by carefully addressing challenges imposed by the MCR
domain, such as temporal aspects of the dataset and unbalanced classes.
Moreover, given that it is currently unknown how much past data is needed for
building MCR prediction models with acceptable performance, we explore the
amount of past data used to build prediction models. Our results show that,
individually, features related to code ownership have the best prediction
power. However, based on feature selection, we conclude that all proposed
features together with lines of code can make the best predictions for both
reviewer participation and amount of feedback. Regarding the amount of past
data, the timeframes of 3, 6, 9, and 12 months of data produce similar results.
Therefore, models can be trained considering short timeframes, thus reducing
the computational costs with negligible impact in the prediction performance
...
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06250" title="Abstract">arXiv:2312.06250</a> [<a href="/pdf/2312.06250" title="Download PDF">pdf</a>, <a href="/format/2312.06250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Decentralized Reinforcement Learning for UAV Path Planning in  IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xueyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Gursoy%2C+M+C">M. Cenk Gursoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Unmanned aerial vehicle (UAV)-based networks and Internet of Things (IoT) are
being considered as integral components of current and next-generation wireless
networks.
<br />In particular, UAVs can provide IoT devices with seamless connectivity and
high coverage and this can be accomplished with effective UAV path planning.
<br />In this article, we study robust and decentralized UAV path planning for data
collection in IoT networks in the presence of other noncooperative UAVs and
adversarial jamming attacks. We address three different practical scenarios,
including single UAV path planning, UAV swarm path planning, and single UAV
path planning in the presence of an intelligent mobile UAV jammer. We advocate
a reinforcement learning framework for UAV path planning in these three
scenarios under practical constraints. The simulation results demonstrate that
with learning-based path planning, the UAVs can complete their missions with
high success rates and data collection rates. In addition, the UAVs can adapt
and execute different trajectories as a defensive measure against the
intelligent jammer.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06253" title="Abstract">arXiv:2312.06253</a> [<a href="/pdf/2312.06253" title="Download PDF">pdf</a>, <a href="/format/2312.06253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Attractors for Robust and Efficient End-to-End Neural  Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samarakoon%2C+L">Lahiru Samarakoon</a>, 
<a href="/search/cs?searchtype=author&query=Broughton%2C+S+J">Samuel J. Broughton</a>, 
<a href="/search/cs?searchtype=author&query=Hark%C3%B6nen%2C+M">Marc Hark&#xf6;nen</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+I">Ivan Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">End-to-end neural diarization with encoder-decoder based attractors
(EEND-EDA) is a method to perform diarization in a single neural network. EDA
handles the diarization of a flexible number of speakers by using an LSTM-based
encoder-decoder that generates a set of speaker-wise attractors in an
autoregressive manner. In this paper, we propose to replace EDA with a
transformer-based attractor calculation (TA) module. TA is composed of a
Combiner block and a Transformer decoder. The main function of the combiner
block is to generate conversational dependent (CD) embeddings by incorporating
learned conversational information into a global set of embeddings. These CD
embeddings will then serve as the input for the transformer decoder. Results on
public datasets show that EEND-TA achieves 2.68% absolute DER improvement over
EEND-EDA. EEND-TA inference is 1.28 times faster than that of EEND-EDA.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06254" title="Abstract">arXiv:2312.06254</a> [<a href="/pdf/2312.06254" title="Download PDF">pdf</a>, <a href="/format/2312.06254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modyn: A Platform for Model Training on Dynamic Datasets With  Sample-Level Data Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ther%2C+M">Maximilian B&#xf6;ther</a>, 
<a href="/search/cs?searchtype=author&query=Gsteiger%2C+V">Viktor Gsteiger</a>, 
<a href="/search/cs?searchtype=author&query=Robroek%2C+T">Ties Robroek</a>, 
<a href="/search/cs?searchtype=author&query=Klimovic%2C+A">Ana Klimovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> currently under review, 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine learning training data is often dynamic in real-world use cases,
i.e., data is added or removed and may experience distribution shifts over
time. Models must incorporate this evolving training data to improve
generalization, adapt to potential distribution shifts, and adhere to privacy
regulations. However, the cost of model (re)training is proportional to how
often the model trains and on how much data it trains on. While ML research
explores these topics in isolation, there is no end-to-end open-source platform
to facilitate the exploration of model retraining and data selection policies
and the deployment these algorithms efficiently at scale.
<br />We present Modyn, a platform for model training on dynamic datasets that
enables sample-level data selection and triggering policies. Modyn orchestrates
continuous training pipelines while optimizing the underlying system
infrastructure to support fast access to arbitrary data samples for efficient
data selection. Modyn's extensible architecture allows users to run training
pipelines without modifying the platform code, and enables researchers to
effortlessly extend the system. We evaluate Modyn's training throughput,
showing that even in memory-bound recommendation systems workloads, Modyn is
able to reach 80 to 100 % of the throughput compared to loading big chunks of
data locally without sample-level data selection. Additionally, we showcase
Modyn's functionality with three different data selection policies.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06255" title="Abstract">arXiv:2312.06255</a> [<a href="/pdf/2312.06255" title="Download PDF">pdf</a>, <a href="/ps/2312.06255" title="Download PostScript">ps</a>, <a href="/format/2312.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Interpretation: A Unified Method for Interpretable Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Chao Min</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+G">Guoyong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+G">Guoquan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xing Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">To address the issues of stability and fidelity in interpretable learning, a
novel interpretable methodology, ensemble interpretation, is presented in this
paper which integrates multi-perspective explanation of various interpretation
methods. On one hand, we define a unified paradigm to describe the common
mechanism of different interpretation methods, and then integrate the multiple
interpretation results to achieve more stable explanation. On the other hand, a
supervised evaluation method based on prior knowledge is proposed to evaluate
the explaining performance of an interpretation method. The experiment results
show that the ensemble interpretation is more stable and more consistent with
human experience and cognition. As an application, we use the ensemble
interpretation for feature selection, and then the generalization performance
of the corresponding learning model is significantly improved.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06256" title="Abstract">arXiv:2312.06256</a> [<a href="/pdf/2312.06256" title="Download PDF">pdf</a>, <a href="/format/2312.06256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Autoencoder-Based Structure-Preserving Model Order Reduction and  Control Design for High-Dimensional Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lepri%2C+M">Marco Lepri</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work concerns control-oriented and structure-preserving learning of
low-dimensional approximations of high-dimensional physical systems, with a
focus on mechanical systems. We investigate the integration of neural
autoencoders in model order reduction, while at the same time preserving
Hamiltonian or Lagrangian structures. We focus on extensively evaluating the
considered methodology by performing simulation and control experiments on
large mass-spring-damper networks, with hundreds of states. The empirical
findings reveal that compressed latent dynamics with less than 5 degrees of
freedom can accurately reconstruct the original systems' transient and
steady-state behavior with a relative total error of around 4\%, while
simultaneously accurately reconstructing the total energy. Leveraging this
system compression technique, we introduce a model-based controller that
exploits the mathematical structure of the compressed model to regulate the
configuration of heavily underactuated mechanical systems.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06258" title="Abstract">arXiv:2312.06258</a> [<a href="/pdf/2312.06258" title="Download PDF">pdf</a>, <a href="/format/2312.06258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Prior Mask: Eliminate Redundant Action for Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+D">Dianyu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qianchuan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The large action space is one fundamental obstacle to deploying Reinforcement
Learning methods in the real world. The numerous redundant actions will cause
the agents to make repeated or invalid attempts, even leading to task failure.
Although current algorithms conduct some initial explorations for this issue,
they either suffer from rule-based systems or depend on expert demonstrations,
which significantly limits their applicability in many real-world settings. In
this work, we examine the theoretical analysis of what action can be eliminated
in policy optimization and propose a novel redundant action filtering
mechanism. Unlike other works, our method constructs the similarity factor by
estimating the distance between the state distributions, which requires no
prior knowledge. In addition, we combine the modified inverse model to avoid
extensive computation in high-dimensional state space. We reveal the underlying
structure of action spaces and propose a simple yet efficient redundant action
filtering mechanism named No Prior Mask (NPM) based on the above techniques. We
show the superior performance of our method by conducting extensive experiments
on high-dimensional, pixel-input, and stochastic problems with various action
redundancy. Our code is public online at https://github.com/zhongdy15/npm.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06259" title="Abstract">arXiv:2312.06259</a> [<a href="/pdf/2312.06259" title="Download PDF">pdf</a>, <a href="/format/2312.06259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Annotation Distribution for Weakly Supervised Point Cloud  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weakly supervised point cloud semantic segmentation has attracted a lot of
attention due to its ability to alleviate the heavy reliance on fine-grained
annotations of point clouds. However, in practice, sparse annotation usually
exhibits a distinct non-uniform distribution in point cloud, which poses
challenges for weak supervision. To address these issues, we propose an
adaptive annotation distribution method for weakly supervised point cloud
semantic segmentation. Specifically, we introduce the probability density
function into the gradient sampling approximation analysis and investigate the
impact of sparse annotations distributions. Based on our analysis, we propose a
label-aware point cloud downsampling strategy to increase the proportion of
annotations involved in the training stage. Furthermore, we design the
multiplicative dynamic entropy as the gradient calibration function to mitigate
the gradient bias caused by non-uniformly distributed sparse annotations and
explicitly reduce the epistemic uncertainty. Without any prior restrictions and
additional information, our proposed method achieves comprehensive performance
improvements at multiple label rates with different annotation distributions on
S3DIS, ScanNetV2 and SemanticKITTI.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06260" title="Abstract">arXiv:2312.06260</a> [<a href="/pdf/2312.06260" title="Download PDF">pdf</a>, <a href="/ps/2312.06260" title="Download PostScript">ps</a>, <a href="/format/2312.06260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In search of the lost tree: Hardness and relaxation of spanning trees in  temporal graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casteigts%2C+A">Arnaud Casteigts</a>, 
<a href="/search/cs?searchtype=author&query=Corsini%2C+T">Timoth&#xe9;e Corsini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">A graph whose edges only appear at certain points in time is called a
temporal graph (among other names). These graphs are temporally connected if
all ordered pairs of vertices are connected by a path that traverses edges in
chronological order (a temporal path). Reachability in temporal graphs departs
significantly from standard reachability; in particular, it is not transitive,
with structural and algorithmic consequences. For instance, temporally
connected graphs do not always admit spanning trees, i.e., subsets of edges
that form a tree and preserve temporal connectivity among the nodes.
<br />In this paper, we revisit fundamental questions about the loss of
universality of spanning trees. To start, we show that deciding if a spanning
tree exists in a given temporal graph is NP-complete. What could be appropriate
replacement for the concept? Beyond having minimum size, spanning trees enjoy
the feature of enabling reachability along the same underlying paths in both
directions, a pretty uncommon feature in temporal graphs. We explore
relaxations in this direction and show that testing the existence of
bidirectional spanning structures (bi-spanners) is tractable in general. On the
down side, finding \emph{minimum} such structures is NP-hard even in simple
temporal graphs. Still, the fact that bidirectionality can be tested
efficiently may find applications, e.g. for routing and security, and the
corresponding primitive that we introduce in the algorithm may be of
independent interest.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06261" title="Abstract">arXiv:2312.06261</a> [<a href="/pdf/2312.06261" title="Download PDF">pdf</a>, <a href="/format/2312.06261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Foundation Models for Prognostics and Health Management in  Industrial Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruonan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanhu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Te Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+L+P">C. L. Philip Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Industrial Cyber-Physical Systems (ICPS) integrate the disciplines of
computer science, communication technology, and engineering, and have emerged
as integral components of contemporary manufacturing and industries. However,
ICPS encounters various challenges in long-term operation, including equipment
failures, performance degradation, and security threats. To achieve efficient
maintenance and management, prognostics and health management (PHM) finds
widespread application in ICPS for critical tasks, including failure
prediction, health monitoring, and maintenance decision-making. The emergence
of large-scale foundation models (LFMs) like BERT and GPT signifies a
significant advancement in AI technology, and ChatGPT stands as a remarkable
accomplishment within this research paradigm, harboring potential for General
Artificial Intelligence. Considering the ongoing enhancement in data
acquisition technology and data processing capability, LFMs are anticipated to
assume a crucial role in the PHM domain of ICPS. However, at present, a
consensus is lacking regarding the application of LFMs to PHM in ICPS,
necessitating systematic reviews and roadmaps to elucidate future directions.
To bridge this gap, this paper elucidates the key components and recent
advances in the underlying model.A comprehensive examination and comprehension
of the latest advances in grand modeling for PHM in ICPS can offer valuable
references for decision makers and researchers in the industrial field while
facilitating further enhancements in the reliability, availability, and safety
of ICPS.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06266" title="Abstract">arXiv:2312.06266</a> [<a href="/pdf/2312.06266" title="Download PDF">pdf</a>, <a href="/format/2312.06266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating Spoken Dialog Systems in Ultra-Low Resourced Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elamin%2C+M">Moayad Elamin</a>, 
<a href="/search/cs?searchtype=author&query=Omer%2C+M">Muhammad Omer</a>, 
<a href="/search/cs?searchtype=author&query=Chanie%2C+Y">Yonas Chanie</a>, 
<a href="/search/cs?searchtype=author&query=Ndlovu%2C+H">Henslaac Ndlovu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic Speech Recognition (ASR) systems are a crucial technology that is
used today to design a wide variety of applications, most notably, smart
assistants, such as Alexa. ASR systems are essentially dialogue systems that
employ Spoken Language Understanding (SLU) to extract meaningful information
from speech. The main challenge with designing such systems is that they
require a huge amount of labeled clean data to perform competitively, such data
is extremely hard to collect and annotate to respective SLU tasks, furthermore,
when designing such systems for low resource languages, where data is extremely
limited, the severity of the problem intensifies. In this paper, we focus on a
fairly popular SLU task, that is, Intent Classification while working with a
low resource language, namely, Flemish. Intent Classification is a task
concerned with understanding the intents of the user interacting with the
system. We build on existing light models for intent classification in Flemish,
and our main contribution is applying different augmentation techniques on two
levels -- the voice level, and the phonetic transcripts level -- to the
existing models to counter the problem of scarce labeled data in low-resource
languages. We find that our data augmentation techniques, on both levels, have
improved the model performance on a number of tasks.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06268" title="Abstract">arXiv:2312.06268</a> [<a href="/pdf/2312.06268" title="Download PDF">pdf</a>, <a href="/ps/2312.06268" title="Download PostScript">ps</a>, <a href="/format/2312.06268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Reliability Evaluation of Countermeasures implemented using  High-Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koufopoulou%2C+A+A">Amalia Artemis Koufopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Xevgeni%2C+K">Kalliopi Xevgeni</a>, 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+A">Athanasios Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+M">Mihalis Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Hely%2C+D">David Hely</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 2 tables, submitted to 2022 IEEE 28th International Symposium on On-Line Testing and Robust System Design (IOLTS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">As the complexity of digital circuits increases, High-Level Synthesis (HLS)
is becoming a valuable tool to increase productivity and design reuse by
utilizing relevant Electronic Design Automation (EDA) flows, either for
Application-Specific Integrated Circuits (ASIC) or for Field Programmable Gate
Arrays (FPGA). Side Channel Analysis (SCA) and Fault Injection (FI) attacks are
powerful hardware attacks, capable of greatly weakening the theoretical
security levels of secure implementations. Furthermore, critical applications
demand high levels of reliability including fault tolerance. The lack of
security and reliability driven optimizations in HLS tools makes it necessary
for the HLS-based designs to validate that the properties of the algorithm and
the countermeasures have not been compromised due to the HLS flow. In this
work, we provide results on the resilience evaluation of HLS-based FPGA
implementations for the aforementioned threats. As a test case, we use multiple
versions of an on-the-fly SBOX algorithm integrating different countermeasures
(hiding and masking), written in C and implemented using Vivado HLS. We perform
extensive evaluations for all the designs and their optimization scenarios. The
results provide evidence of issues arising due to HLS optimizations on the
security and the reliability of cryptographic implementations. Furthermore, the
results put HLS algorithms to the test of designing secure accelerators and can
lead to improving them towards the goal of increasing productivity in the
domain of secure and reliable cryptographic implementations.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06272" title="Abstract">arXiv:2312.06272</a> [<a href="/pdf/2312.06272" title="Download PDF">pdf</a>, <a href="/format/2312.06272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-MixFormer: UNet-like Transformer with Mix-Attention for Efficient  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeom%2C+S">Seul-Ki Yeom</a>, 
<a href="/search/cs?searchtype=author&query=von+Klitzing%2C+J">Julian von Klitzing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 6 Tables, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation has witnessed remarkable advancements with the
adaptation of the Transformer architecture. Parallel to the strides made by the
Transformer, CNN-based U-Net has seen significant progress, especially in
high-resolution medical imaging and remote sensing. This dual success inspired
us to merge the strengths of both, leading to the inception of a U-Net-based
vision transformer decoder tailored for efficient contextual encoding. Here, we
propose a novel transformer decoder, U-MixFormer, built upon the U-Net
structure, designed for efficient semantic segmentation. Our approach
distinguishes itself from the previous transformer methods by leveraging
lateral connections between the encoder and decoder stages as feature queries
for the attention modules, apart from the traditional reliance on skip
connections. Moreover, we innovatively mix hierarchical feature maps from
various encoder and decoder stages to form a unified representation for keys
and values, giving rise to our unique mix-attention module. Our approach
demonstrates state-of-the-art performance across various configurations.
Extensive experiments show that U-MixFormer outperforms SegFormer, FeedFormer,
and SegNeXt by a large margin. For example, U-MixFormer-B0 surpasses
SegFormer-B0 and FeedFormer-B0 with 3.8% and 2.0% higher mIoU and 27.3% and
21.8% less computation and outperforms SegNext with 3.3% higher mIoU with
MSCAN-T encoder on ADE20K. Code available at
https://github.com/julian-klitzing/u-mixformer.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06273" title="Abstract">arXiv:2312.06273</a> [<a href="/pdf/2312.06273" title="Download PDF">pdf</a>, <a href="/format/2312.06273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regroup Median Loss for Combating Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kemou Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinyu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The deep model training procedure requires large-scale datasets of annotated
data. Due to the difficulty of annotating a large number of samples, label
noise caused by incorrect annotations is inevitable, resulting in low model
performance and poor model generalization. To combat label noise, current
methods usually select clean samples based on the small-loss criterion and use
these samples for training. Due to some noisy samples similar to clean ones,
these small-loss criterion-based methods are still affected by label noise. To
address this issue, in this work, we propose Regroup Median Loss (RML) to
reduce the probability of selecting noisy samples and correct losses of noisy
samples. RML randomly selects samples with the same label as the training
samples based on a new loss processing method. Then, we combine the stable mean
loss and the robust median loss through a proposed regrouping strategy to
obtain robust loss estimation for noisy samples. To further improve the model
performance against label noise, we propose a new sample selection strategy and
build a semi-supervised method based on RML. Compared to state-of-the-art
methods, for both the traditionally trained and semi-supervised models, RML
achieves a significant improvement on synthetic and complex real-world
datasets. The source code of the paper has been released.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06275" title="Abstract">arXiv:2312.06275</a> [<a href="/pdf/2312.06275" title="Download PDF">pdf</a>, <a href="/format/2312.06275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DG-TTA: Out-of-domain medical image segmentation through Domain  Generalization and Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weihsbach%2C+C">Christian Weihsbach</a>, 
<a href="/search/cs?searchtype=author&query=Kruse%2C+C+N">Christian N. Kruse</a>, 
<a href="/search/cs?searchtype=author&query=Bigalke%2C+A">Alexander Bigalke</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+M+P">Mattias P. Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Applying pre-trained medical segmentation models on out-of-domain images
often yields predictions of insufficient quality. Several strategies have been
proposed to maintain model performance, such as finetuning or unsupervised- and
source-free domain adaptation. These strategies set restrictive requirements
for data availability. In this study, we propose to combine domain
generalization and test-time adaptation to create a highly effective approach
for reusing pre-trained models in unseen target domains. Domain-generalized
pre-training on source data is used to obtain the best initial performance in
the target domain. We introduce the MIND descriptor previously used in image
registration tasks as a further technique to achieve generalization and present
superior performance for small-scale datasets compared to existing approaches.
At test-time, high-quality segmentation for every single unseen scan is ensured
by optimizing the model weights for consistency given different image
augmentations. That way, our method enables separate use of source and target
data and thus removes current data availability barriers. Moreover, the
presented method is highly modular as it does not require specific model
architectures or prior knowledge of involved domains and labels. We demonstrate
this by integrating it into the nnUNet, which is currently the most popular and
accurate framework for medical image segmentation. We employ multiple datasets
covering abdominal, cardiac, and lumbar spine scans and compose several
out-of-domain scenarios in this study. We demonstrate that our method, combined
with pre-trained whole-body CT models, can effectively segment MR images with
high accuracy in all of the aforementioned scenarios. Open-source code can be
found here: https://github.com/multimodallearning/DG-TTA
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06276" title="Abstract">arXiv:2312.06276</a> [<a href="/pdf/2312.06276" title="Download PDF">pdf</a>, <a href="/format/2312.06276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Evaluation of Methods for Estimating Frequency Response  Functions of a 6-axes Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+S+A">Stefanie A. Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Moberg%2C+S">Stig Moberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Nonparametric estimates of frequency response functions (FRFs) are often
suitable for describing the dynamics of a mechanical system. If treating these
estimates as measurement inputs, they can be used for parametric identification
of, e.g., a gray-box model. Classical methods for nonparametric FRF estimation
of MIMO systems require at least as many experiments as the system has inputs.
Local parametric FRF estimation methods have been developed for avoiding
multiple experiments. In this paper, these local methods are adapted and
applied for estimating the FRFs of a 6-axes robotic manipulator, which is a
nonlinear MIMO system operating in closed loop. The aim is to reduce the
experiment time and amount of data needed for identification. The resulting
FRFs are analyzed in an experimental study and compared to estimates obtained
by classical MIMO techniques. It is furthermore shown that an accurate
parametric model identification is possible based on local parametric FRF
estimates and that the total experiment time can be significantly reduced.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06278" title="Abstract">arXiv:2312.06278</a> [<a href="/pdf/2312.06278" title="Download PDF">pdf</a>, <a href="/ps/2312.06278" title="Download PostScript">ps</a>, <a href="/format/2312.06278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-analytic PINN methods for boundary layer problems in a rectangular  domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gie%2C+G">Gung-Min Gie</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+Y">Youngjoon Hong</a>, 
<a href="/search/math?searchtype=author&query=Jung%2C+C">Chang-Yeol Jung</a>, 
<a href="/search/math?searchtype=author&query=Munkhjin%2C+T">Tselmuun Munkhjin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Singularly perturbed boundary value problems pose a significant challenge for
their numerical approximations because of the presence of sharp boundary
layers. These sharp boundary layers are responsible for the stiffness of
solutions, which leads to large computational errors, if not properly handled.
It is well-known that the classical numerical methods as well as the
Physics-Informed Neural Networks (PINNs) require some special treatments near
the boundary, e.g., using extensive mesh refinements or finer collocation
points, in order to obtain an accurate approximate solution especially inside
of the stiff boundary layer. In this article, we modify the PINNs and construct
our new semi-analytic SL-PINNs suitable for singularly perturbed boundary value
problems. Performing the boundary layer analysis, we first find the corrector
functions describing the singular behavior of the stiff solutions inside
boundary layers. Then we obtain the SL-PINN approximations of the singularly
perturbed problems by embedding the explicit correctors in the structure of
PINNs or by training the correctors together with the PINN approximations. Our
numerical experiments confirm that our new SL-PINN methods produce stable and
accurate approximations for stiff solutions.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06279" title="Abstract">arXiv:2312.06279</a> [<a href="/pdf/2312.06279" title="Download PDF">pdf</a>, <a href="/format/2312.06279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regional Correlation Aided Mobile Traffic Prediction with Spatiotemporal  Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">JeongJun Park</a>, 
<a href="/search/cs?searchtype=author&query=Mwasinga%2C+L+J">Lusungu J. Mwasinga</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huigyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S+M">Syed M. Raza</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc-Tai Le</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Moonseong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+M+Y">Min Young Chung</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+H">Hyunseung Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures, 1 table. This paper is already accepted on IEEE Consumer Communications &amp; Networking Conference(CCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mobile traffic data in urban regions shows differentiated patterns during
different hours of the day. The exploitation of these patterns enables highly
accurate mobile traffic prediction for proactive network management. However,
recent Deep Learning (DL) driven studies have only exploited spatiotemporal
features and have ignored the geographical correlations, causing high
complexity and erroneous mobile traffic predictions. This paper addresses these
limitations by proposing an enhanced mobile traffic prediction scheme that
combines the clustering strategy of daily mobile traffic peak time and novel
multi Temporal Convolutional Network with a Long Short Term Memory (multi
TCN-LSTM) model. The mobile network cells that exhibit peak traffic during the
same hour of the day are clustered together. Our experiments on large-scale
real-world mobile traffic data show up to 28% performance improvement compared
to state-of-the-art studies, which confirms the efficacy and viability of the
proposed approach.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06280" title="Abstract">arXiv:2312.06280</a> [<a href="/pdf/2312.06280" title="Download PDF">pdf</a>, <a href="/format/2312.06280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Compression of the Latent Space in Variational Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sejnova%2C+G">Gabriela Sejnova</a>, 
<a href="/search/cs?searchtype=author&query=Vavrecka%2C+M">Michal Vavrecka</a>, 
<a href="/search/cs?searchtype=author&query=Stepanova%2C+K">Karla Stepanova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Variational Autoencoders (VAEs) are powerful generative models that have been
widely used in various fields, including image and text generation. However,
one of the known challenges in using VAEs is the model's sensitivity to its
hyperparameters, such as the latent space size. This paper presents a simple
extension of VAEs for automatically determining the optimal latent space size
during the training process by gradually decreasing the latent size through
neuron removal and observing the model performance. The proposed method is
compared to traditional hyperparameter grid search and is shown to be
significantly faster while still achieving the best optimal dimensionality on
four image datasets. Furthermore, we show that the final performance of our
method is comparable to training on the optimal latent size from scratch, and
might thus serve as a convenient substitute.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06281" title="Abstract">arXiv:2312.06281</a> [<a href="/pdf/2312.06281" title="Download PDF">pdf</a>, <a href="/format/2312.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paech%2C+S+J">Samuel J. Paech</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of
emotional intelligence in Large Language Models (LLMs). We assess the ability
of LLMs to understand complex emotions and social interactions by asking them
to predict the intensity of emotional states of characters in a dialogue. The
benchmark is able to discriminate effectively between a wide range of models.
We find that EQ-Bench correlates strongly with comprehensive multi-domain
benchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may
be capturing similar aspects of broad intelligence. Our benchmark produces
highly repeatable results using a set of 60 English-language questions. We also
provide open-source code for an automated benchmarking pipeline at
https://github.com/EQ-bench/EQ-Bench and a leaderboard at
https://www.eqbench.com
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06282" title="Abstract">arXiv:2312.06282</a> [<a href="/pdf/2312.06282" title="Download PDF">pdf</a>, <a href="/ps/2312.06282" title="Download PostScript">ps</a>, <a href="/format/2312.06282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank-Metric Codes and Their Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruica%2C+A">Anina Gruica</a>, 
<a href="/search/cs?searchtype=author&query=Kilic%2C+A+B">Altan B. Kilic</a>, 
<a href="/search/cs?searchtype=author&query=Ravagnani%2C+A">Alberto Ravagnani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Invited book chapter (to appear)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We present the theory of linear rank-metric codes from the point of view of
their fundamental parameters. These are: the minimum rank distance, the rank
distribution, the maximum rank, the covering radius, and the field size. The
focus of this chapter is on the interplay among these parameters and on their
significance for the code's (combinatorial) structure. The results covered in
this chapter span from the theory of optimal codes and anticodes to very recent
developments on the asymptotic density of MRD codes.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06283" title="Abstract">arXiv:2312.06283</a> [<a href="/pdf/2312.06283" title="Download PDF">pdf</a>, <a href="/format/2312.06283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extrapolating tipping points and simulating non-stationary dynamics of  complex systems using efficient machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6glmayr%2C+D">Daniel K&#xf6;glmayr</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4th%2C+C">Christoph R&#xe4;th</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Chaotic Dynamics (nlin.CD); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Model-free and data-driven prediction of tipping point transitions in
nonlinear dynamical systems is a challenging and outstanding task in complex
systems science. We propose a novel, fully data-driven machine learning
algorithm based on next-generation reservoir computing to extrapolate the
bifurcation behavior of nonlinear dynamical systems using stationary training
data samples. We show that this method can extrapolate tipping point
transitions. Furthermore, it is demonstrated that the trained next-generation
reservoir computing architecture can be used to predict non-stationary dynamics
with time-varying bifurcation parameters. In doing so, post-tipping point
dynamics of unseen parameter regions can be simulated.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06285" title="Abstract">arXiv:2312.06285</a> [<a href="/pdf/2312.06285" title="Download PDF">pdf</a>, <a href="/format/2312.06285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compensation Sampling for Improved Convergence in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Salah%2C+A+a">Albert ali Salah</a>, 
<a href="/search/cs?searchtype=author&query=Poppe%2C+R">Ronald Poppe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models achieve remarkable quality in image generation, but at a
cost. Iterative denoising requires many time steps to produce high fidelity
images. We argue that the denoising process is crucially limited by an
accumulation of the reconstruction error due to an initial inaccurate
reconstruction of the target data. This leads to lower quality outputs, and
slower convergence. To address this issue, we propose compensation sampling to
guide the generation towards the target domain. We introduce a compensation
term, implemented as a U-Net, which adds negligible computation overhead during
training and, optionally, inference. Our approach is flexible and we
demonstrate its application in unconditional generation, face inpainting, and
face de-occlusion using benchmark datasets CIFAR-10, CelebA, CelebA-HQ,
FFHQ-256, and FSG. Our approach consistently yields state-of-the-art results in
terms of image quality, while accelerating the denoising process to converge
during training by up to an order of magnitude.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06287" title="Abstract">arXiv:2312.06287</a> [<a href="/pdf/2312.06287" title="Download PDF">pdf</a>, <a href="/ps/2312.06287" title="Download PostScript">ps</a>, <a href="/format/2312.06287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Cognitive Distraction and Measurement Noise: Strategies for  Humans and Engineering Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Delrobaei%2C+M">Mehdi Delrobaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary discussion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Cognitive distraction and measurement noise are two distinct factors that
significantly impact the performance of humans and engineering systems.
Cognitive distraction occurs when an individual's attention is diverted from a
task, while measurement noise refers to the random variation that can occur in
system measurements. Although humans and engineering systems employ different
methods to overcome these obstacles, the ultimate goal is to achieve optimal
performance. An intriguing question arises: what are the similarities and
differences between using the term "noise" in engineering and cognitive
psychology? Additionally, it is worthwhile to explore whether the human brain
and engineering control systems use similar or different approaches to
attenuate noise. While this article does not provide a definitive answer, it
emphasizes the importance of addressing this question and encourages further
investigation.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06290" title="Abstract">arXiv:2312.06290</a> [<a href="/pdf/2312.06290" title="Download PDF">pdf</a>, <a href="/format/2312.06290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Label Skews in Federated Learning with Model Concatenation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+Y">Yiqun Diao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) has emerged as a promising solution to perform deep
learning on different data owners without exchanging raw data. However, non-IID
data has been a key challenge in FL, which could significantly degrade the
accuracy of the final model. Among different non-IID types, label skews have
been challenging and common in image classification and other tasks. Instead of
averaging the local models in most previous studies, we propose FedConcat, a
simple and effective approach that concatenates these local models as the base
of the global model to effectively aggregate the local knowledge. To reduce the
size of the global model, we adopt the clustering technique to group the
clients by their label distributions and collaboratively train a model inside
each cluster. We theoretically analyze the advantage of concatenation over
averaging by analyzing the information bottleneck of deep neural networks.
Experimental results demonstrate that FedConcat achieves significantly higher
accuracy than previous state-of-the-art FL methods in various heterogeneous
label skew distribution settings and meanwhile has lower communication costs.
Our code is publicly available.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06292" title="Abstract">arXiv:2312.06292</a> [<a href="/pdf/2312.06292" title="Download PDF">pdf</a>, <a href="/format/2312.06292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoLLiE C -- A Multifunctional Bimanual Mobile Robot Supporting Versatile  Care Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steffen%2C+L">Lea Steffen</a>, 
<a href="/search/cs?searchtype=author&query=Schulze%2C+M">Martin Schulze</a>, 
<a href="/search/cs?searchtype=author&query=Eichmann%2C+C">Christian Eichmann</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+R">Robin Koch</a>, 
<a href="/search/cs?searchtype=author&query=Hermann%2C+A">Andreas Hermann</a>, 
<a href="/search/cs?searchtype=author&query=Mussulin%2C+R+F">Rosa Frietsch Mussulin</a>, 
<a href="/search/cs?searchtype=author&query=Graaf%2C+F">Friedrich Graaf</a>, 
<a href="/search/cs?searchtype=author&query=Wilbrandt%2C+R">Robert Wilbrandt</a>, 
<a href="/search/cs?searchtype=author&query=Besselmann%2C+M+G">Marvin Gro&#xdf;e Besselmann</a>, 
<a href="/search/cs?searchtype=author&query=Roennau%2C+A">Arne Roennau</a>, 
<a href="/search/cs?searchtype=author&query=Dillmann%2C+R">R&#xfc;diger Dillmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18th international conference on Intelligent Autonomous Systems (IAS18 - 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Care robotics as a research field has developed a lot in recent years, driven
by the rapidly increasing need for it. However, these technologies are mostly
limited to a very concrete and usually relatively simple use case. The bimanual
robot House of Living Labs intelligent Escort (HoLLiE) includes an
omnidirectional mobile platform. This paper presents how HoLLiE is adapted, by
flexible software and hardware modules, for different care applications. The
design goal of HoLLiE was to be human-like but abstract enough to ensure a high
level of acceptance, which is very advantageous for its use in hospitals. After
a short retrospect of previous generations of HoLLiE, it is highlighted how the
current version is equipped with a variety of additional sensors and actuators
to allow a wide range of possible applications. Then, the software stack of
HoLLiE is depicted, with the focus on navigation and force sensitive intention
recognition.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06293" title="Abstract">arXiv:2312.06293</a> [<a href="/pdf/2312.06293" title="Download PDF">pdf</a>, <a href="/format/2312.06293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile Edge Computing and AI Enabled Web3 Metaverse over 6G Wireless  Communications: A Deep Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T+J">Terence Jie Chua</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appears on 2023 IEEE 97th Vehicular Technology Conference (VTC2023-Spring)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Metaverse is gaining attention among academics as maturing technologies
empower the promises and envisagements of a multi-purpose, integrated virtual
environment. An interactive and immersive socialization experience between
people is one of the promises of the Metaverse. In spite of the rapid
advancements in current technologies, the computation required for a smooth,
seamless and immersive socialization experience in the Metaverse is
overbearing, and the accumulated user experience is essential to be considered.
The computation burden calls for computation offloading, where the integration
of virtual and physical world scenes is offloaded to an edge server. This paper
introduces a novel Quality-of-Service (QoS) model for the accumulated
experience in multi-user socialization on a multichannel wireless network. This
QoS model utilizes deep reinforcement learning approaches to find the
near-optimal channel resource allocation. Comprehensive experiments demonstrate
that the adoption of the QoS model enhances the overall socialization
experience.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06295" title="Abstract">arXiv:2312.06295</a> [<a href="/pdf/2312.06295" title="Download PDF">pdf</a>, <a href="/format/2312.06295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cataract-1K: Cataract Surgery Dataset for Scene Segmentation, Phase  Recognition, and Irregularity Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghamsarian%2C+N">Negin Ghamsarian</a>, 
<a href="/search/cs?searchtype=author&query=El-Shabrawi%2C+Y">Yosuf El-Shabrawi</a>, 
<a href="/search/cs?searchtype=author&query=Nasirihaghighi%2C+S">Sahar Nasirihaghighi</a>, 
<a href="/search/cs?searchtype=author&query=Putzgruber-Adamitsch%2C+D">Doris Putzgruber-Adamitsch</a>, 
<a href="/search/cs?searchtype=author&query=Zinkernagel%2C+M">Martin Zinkernagel</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+S">Sebastian Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Schoeffmann%2C+K">Klaus Schoeffmann</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, the landscape of computer-assisted interventions and
post-operative surgical video analysis has been dramatically reshaped by
deep-learning techniques, resulting in significant advancements in surgeons'
skills, operation room management, and overall surgical outcomes. However, the
progression of deep-learning-powered surgical technologies is profoundly
reliant on large-scale datasets and annotations. Particularly, surgical scene
understanding and phase recognition stand as pivotal pillars within the realm
of computer-assisted surgery and post-operative assessment of cataract surgery
videos. In this context, we present the largest cataract surgery video dataset
that addresses diverse requisites for constructing computerized surgical
workflow analysis and detecting post-operative irregularities in cataract
surgery. We validate the quality of annotations by benchmarking the performance
of several state-of-the-art neural network architectures for phase recognition
and surgical scene segmentation. Besides, we initiate the research on domain
adaptation for instrument segmentation in cataract surgery by evaluating
cross-domain instrument segmentation performance in cataract surgery videos.
The dataset and annotations will be publicly available upon acceptance of the
paper.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06296" title="Abstract">arXiv:2312.06296</a> [<a href="/pdf/2312.06296" title="Download PDF">pdf</a>, <a href="/ps/2312.06296" title="Download PostScript">ps</a>, <a href="/format/2312.06296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Approximate Functional Dependencies: a Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parciak%2C+M">Marcel Parciak</a>, 
<a href="/search/cs?searchtype=author&query=Weytjens%2C+S">Sebastiaan Weytjens</a>, 
<a href="/search/cs?searchtype=author&query=Hens%2C+N">Niel Hens</a>, 
<a href="/search/cs?searchtype=author&query=Neven%2C+F">Frank Neven</a>, 
<a href="/search/cs?searchtype=author&query=Peeters%2C+L+M">Liesbet M. Peeters</a>, 
<a href="/search/cs?searchtype=author&query=Vansummeren%2C+S">Stijn Vansummeren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40th IEEE International Conference on Data Engineering (ICDE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Approximate functional dependencies (AFDs) are functional dependencies (FDs)
that "almost" hold in a relation. While various measures have been proposed to
quantify the level to which an FD holds approximately, they are difficult to
compare and it is unclear which measure is preferable when one needs to
discover FDs in real-world data, i.e., data that only approximately satisfies
the FD. In response, this paper formally and qualitatively compares AFD
measures. We obtain a formal comparison through a novel presentation of
measures in terms of Shannon and logical entropy. Qualitatively, we perform a
sensitivity analysis w.r.t. structural properties of input relations and
quantitatively study the effectiveness of AFD measures for ranking AFDs on real
world data. Based on this analysis, we give clear recommendations for the AFD
measures to use in practice.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06297" title="Abstract">arXiv:2312.06297</a> [<a href="/pdf/2312.06297" title="Download PDF">pdf</a>, <a href="/format/2312.06297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMDesign: Multi-Modality Transfer Learning for Generative Protein Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiangbin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yufei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bozhen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Ge Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Protein design involves generating protein sequences based on their
corresponding protein backbones. While deep generative models show promise for
learning protein design directly from data, the lack of publicly available
structure-sequence pairings limits their generalization capabilities. Previous
efforts of generative protein design have focused on architectural improvements
and pseudo-data augmentation to overcome this bottleneck. To further address
this challenge, we propose a novel protein design paradigm called MMDesign,
which leverages multi-modality transfer learning. To our knowledge, MMDesign is
the first framework that combines a pretrained structural module with a
pretrained contextual module, using an auto-encoder (AE) based language model
to incorporate prior semantic knowledge of protein sequences. We also introduce
a cross-layer cross-modal alignment algorithm to enable the structural module
to learn long-term temporal information and ensure consistency between
structural and contextual modalities. Experimental results, only training with
the small CATH dataset, demonstrate that our MMDesign framework consistently
outperforms other baselines on various public test sets. To further assess the
biological plausibility of the generated protein sequences and data
distribution, we present systematic quantitative analysis techniques that
provide interpretability and reveal more about the laws of protein design.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06298" title="Abstract">arXiv:2312.06298</a> [<a href="/pdf/2312.06298" title="Download PDF">pdf</a>, <a href="/ps/2312.06298" title="Download PostScript">ps</a>, <a href="/format/2312.06298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Musical Sonification of Daily Physical Activity Data: A Proof of Concept  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mendoza%2C+J+I">Juan Ignacio Mendoza</a>, 
<a href="/search/cs?searchtype=author&query=Danso%2C+A">Andrew Danso</a>, 
<a href="/search/cs?searchtype=author&query=Rantalainen%2C+T">Timo Rantalainen</a>, 
<a href="/search/cs?searchtype=author&query=Palmberg%2C+L">Lotta Palmberg</a>, 
<a href="/search/cs?searchtype=author&query=Luck%2C+G">Geoff Luck</a>, 
<a href="/search/cs?searchtype=author&query=Chastin%2C+S">Sebastien Chastin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Previous research has shown that the temporal dynamics of human activity
recorded by accelerometers share a similar structure with music. This opens the
possibility to use musical sonification of motion data as a means of raising
awareness of an individuals own daily physical activity and promote healthy
activity behaviour, granted that human activity and music also share similar
temporal structure. In this study a method was developed for quantifying the
daily structure of human activity using multigranular temporal segmentation and
applying it to produce musical sonifications. To that extent, two accelerometry
recordings of physical activity were selected from a dataset, such that one
shows more physical activity than the other. These data were segmented in
different timescales so that segmentation boundaries at a given timescale have
a corresponding boundary at a finer timescale, occurring at the same point in
time. These properties are useful to display the hierarchical structure of
daily events embedded in larger events, which is akin to musical structure. The
segmented physical activity data for one day was mapped to musical sounds,
resulting in two short musical pieces, one for each subject. A survey measured
the extent to which people would identify the piece corresponding to the most
active subject, resulting in a majority of correct answers. We propose that
this method has potential to be a valuable and innovative technique for
behavioural change. We discuss its potential to aid in interventions for
behavioural change towards reducing sedentary behaviour and increasing physical
activity.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06299" title="Abstract">arXiv:2312.06299</a> [<a href="/pdf/2312.06299" title="Download PDF">pdf</a>, <a href="/format/2312.06299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RCA-NOC: Relative Contrastive Alignment for Novel Object Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiashuo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaoyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Leyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaolun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023,10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel approach to novel object captioning which
employs relative contrastive learning to learn visual and semantic alignment.
Our approach maximizes compatibility between regions and object tags in a
contrastive manner. To set up a proper contrastive learning objective, for each
image, we augment tags by leveraging the relative nature of positive and
negative pairs obtained from foundation models such as CLIP. We then use the
rank of each augmented tag in a list as a relative relevance label to contrast
each top-ranked tag with a set of lower-ranked tags. This learning objective
encourages the top-ranked tags to be more compatible with their image and text
context than lower-ranked tags, thus improving the discriminative ability of
the learned multi-modality representation. We evaluate our approach on two
datasets and show that our proposed RCA-NOC approach outperforms
state-of-the-art methods by a large margin, demonstrating its effectiveness in
improving vision-language representation for novel object captioning.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06304" title="Abstract">arXiv:2312.06304</a> [<a href="/pdf/2312.06304" title="Download PDF">pdf</a>, <a href="/ps/2312.06304" title="Download PostScript">ps</a>, <a href="/format/2312.06304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orchestrated Robust Controller for the Precision Control of Heavy-duty  Hydraulic Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hejrati%2C+M">Mahdi Hejrati</a>, 
<a href="/search/cs?searchtype=author&query=Mattila%2C+J">Jouni Mattila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted for possible publication in IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Vast industrial investment along with increased academic research on
hydraulic heavy-duty manipulators has unavoidably paved the way for their
automatization, necessitating the design of robust and high-precision
controllers. In this study, an orchestrated robust controller is designed to
address the mentioned issue. To do so, the entire robotic system is decomposed
into subsystems, and a robust controller is designed at each local subsystem by
considering unknown model uncertainties, unknown disturbances, and compound
input constraints, thanks to virtual decomposition control (VDC). As such,
radial basic function neural networks (RBFNNs) are incorporated into VDC to
tackle unknown disturbances and uncertainties, resulting in novel decentralized
RBFNNs. All these robust local controllers designed at each local subsystem
are, then, orchestrated to accomplish high-precision control. In the end, for
the first time in the context of VDC, a semi-globally uniformly ultimate
boundedness is achieved under the designed controller. The validity of the
theoretical results is verified by performing extensive simulations and
experiments on a 6-degrees-of-freedom industrial manipulator with a nominal
lifting capacity of $600\, kg$ at $5$ meters reach. Comparing the simulation
result to state-of-the-art controller along with provided experimental results,
demonstrates that the proposed method established all the promises and
performed excellently.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06305" title="Abstract">arXiv:2312.06305</a> [<a href="/pdf/2312.06305" title="Download PDF">pdf</a>, <a href="/format/2312.06305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Meta-Level Learning Algorithm for Sequential Hyper-Parameter Space  Reduction in AutoML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borboudakis%2C+G">Giorgos Borboudakis</a>, 
<a href="/search/cs?searchtype=author&query=Charonyktakis%2C+P">Paulos Charonyktakis</a>, 
<a href="/search/cs?searchtype=author&query=Paraschakis%2C+K">Konstantinos Paraschakis</a>, 
<a href="/search/cs?searchtype=author&query=Tsamardinos%2C+I">Ioannis Tsamardinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">AutoML platforms have numerous options for the algorithms to try for each
step of the analysis, i.e., different possible algorithms for imputation,
transformations, feature selection, and modelling. Finding the optimal
combination of algorithms and hyper-parameter values is computationally
expensive, as the number of combinations to explore leads to an exponential
explosion of the space. In this paper, we present the Sequential
Hyper-parameter Space Reduction (SHSR) algorithm that reduces the space for an
AutoML tool with negligible drop in its predictive performance. SHSR is a
meta-level learning algorithm that analyzes past runs of an AutoML tool on
several datasets and learns which hyper-parameter values to filter out from
consideration on a new dataset to analyze. SHSR is evaluated on 284
classification and 375 regression problems, showing an approximate 30%
reduction in execution time with a performance drop of less than 0.1%.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06306" title="Abstract">arXiv:2312.06306</a> [<a href="/pdf/2312.06306" title="Download PDF">pdf</a>, <a href="/format/2312.06306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Annotation and Bias Evaluation in Visual Datasets for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Llorca%2C+D+F">David Fern&#xe1;ndez Llorca</a>, 
<a href="/search/cs?searchtype=author&query=Frau%2C+P">Pedro Frau</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+I">Ignacio Parra</a>, 
<a href="/search/cs?searchtype=author&query=Izquierdo%2C+R">Rub&#xe9;n Izquierdo</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+E">Emilia G&#xf3;mez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submitted to the IEEE TIV journal; 17 pages, 16 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper addresses the often overlooked issue of fairness in the autonomous
driving domain, particularly in vision-based perception and prediction systems,
which play a pivotal role in the overall functioning of Autonomous Vehicles
(AVs). We focus our analysis on biases present in some of the most commonly
used visual datasets for training person and vehicle detection systems. We
introduce an annotation methodology and a specialised annotation tool, both
designed to annotate protected attributes of agents in visual datasets. We
validate our methodology through an inter-rater agreement analysis and provide
the distribution of attributes across all datasets. These include annotations
for the attributes age, sex, skin tone, group, and means of transport for more
than 90K people, as well as vehicle type, colour, and car type for over 50K
vehicles. Generally, diversity is very low for most attributes, with some
groups, such as children, wheelchair users, or personal mobility vehicle users,
being extremely underrepresented in the analysed datasets. The study
contributes significantly to efforts to consider fairness in the evaluation of
perception and prediction systems for AVs. This paper follows reproducibility
principles. The annotation tool, scripts and the annotated attributes can be
accessed publicly at https://github.com/ec-jrc/humaint_annotator.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06309" title="Abstract">arXiv:2312.06309</a> [<a href="/pdf/2312.06309" title="Download PDF">pdf</a>, <a href="/format/2312.06309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An unsupervised learning approach to evaluate questionnaire data -- what  one can learn from violations of measurement invariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hahn-Klimroth%2C+M">Max Hahn-Klimroth</a>, 
<a href="/search/cs?searchtype=author&query=Dierkes%2C+P+W">Paul W. Dierkes</a>, 
<a href="/search/cs?searchtype=author&query=Kleespies%2C+M+W">Matthias W. Kleespies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">In several branches of the social sciences and humanities, surveys based on
standardized questionnaires are a prominent research tool. While there are a
variety of ways to analyze the data, some standard procedures have become
established. When those surveys want to analyze differences in the answer
patterns of different groups (e.g., countries, gender, age, ...), these
procedures can only be carried out in a meaningful way if there is measurement
invariance, i.e., the measured construct has psychometric equivalence across
groups. As recently raised as an open problem by Sauerwein et al. (2021), new
evaluation methods that work in the absence of measurement invariance are
needed.
<br />This paper promotes an unsupervised learning-based approach to such research
data by proposing a procedure that works in three phases: data preparation,
clustering of questionnaires, and measuring similarity based on the obtained
clustering and the properties of each group. We generate synthetic data in
three data sets, which allows us to compare our approach with the PCA approach
under measurement invariance and under violated measurement invariance. As a
main result, we obtain that the approach provides a natural comparison between
groups and a natural description of the response patterns of the groups.
Moreover, it can be safely applied to a wide variety of data sets, even in the
absence of measurement invariance. Finally, this approach allows us to
translate (violations of) measurement invariance into a meaningful measure of
similarity.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06310" title="Abstract">arXiv:2312.06310</a> [<a href="/pdf/2312.06310" title="Download PDF">pdf</a>, <a href="/format/2312.06310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of the Lifelike Head Unit for a Humanoid Cybernetic Avatar  `Yui&#x27; and Its Operation Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+M">Mizuki Nakajima</a>, 
<a href="/search/cs?searchtype=author&query=Shinkawa%2C+K">Kaoruko Shinkawa</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+Y">Yoshihiro Nakata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the context of avatar-mediated communication, it is crucial for the
face-to-face interlocutor to sense the operator's presence and emotions via the
avatar. Although androids resembling humans have been developed to convey
presence through appearance and movement, few studies have prioritized
deepening the communication experience for both operator and interlocutor using
android robot as an avatar. Addressing this gap, we introduce the ``Cybernetic
Avatar `Yui','' featuring a human-like head unit with 28 degrees of freedom,
capable of expressing gaze, facial emotions, and speech-related mouth
movements. Through an eye-tracking unit in a Head-Mounted Display (HMD) and
degrees of freedom on both eyes of Yui, operators can control the avatar's gaze
naturally. Additionally, microphones embedded in Yui's ears allow operators to
hear surrounding sounds in three dimensions, enabling them to discern the
direction of calls based solely on auditory information. An HMD's face-tracking
unit synchronizes the avatar's facial movements with those of the operator.
This immersive interface, coupled with Yui's human-like appearance, enables
real-time emotion transmission and communication, enhancing the sense of
presence for both parties. Our experiments demonstrate Yui's facial expression
capabilities, and validate the system's efficacy through teleoperation trials,
suggesting potential advancements in avatar technology.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06314" title="Abstract">arXiv:2312.06314</a> [<a href="/pdf/2312.06314" title="Download PDF">pdf</a>, <a href="/format/2312.06314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMS*: Minimizing Makespan for Multi-Agent Combinatorial Path Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhongqiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Nandy%2C+A">Anushtup Nandy</a>, 
<a href="/search/cs?searchtype=author&query=Rathinam%2C+S">Sivakumar Rathinam</a>, 
<a href="/search/cs?searchtype=author&query=Choset%2C+H">Howie Choset</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-Agent Combinatorial Path Finding (MCPF) seeks collision-free paths for
multiple agents from their initial to goal locations, while visiting a set of
intermediate target locations in the middle of the paths. MCPF is challenging
as it involves both planning collision-free paths for multiple agents and
target sequencing, i.e., solving traveling salesman problems to assign targets
to and find the visiting order for the agents. Recent work develops methods to
address MCPF while minimizing the sum of individual arrival times at goals.
Such a problem formulation may result in paths with different arrival times and
lead to a long makespan, the maximum arrival time, among the agents. This paper
proposes a min-max variant of MCPF, denoted as MCPF-max, that minimizes the
makespan of the agents. While the existing methods (such as MS*) for MCPF can
be adapted to solve MCPF-max, we further develop two new techniques based on
MS* to defer the expensive target sequencing during planning to expedite the
overall computation. We analyze the properties of the resulting algorithm
Deferred MS* (DMS*), and test DMS* with up to 20 agents and 80 targets. We
demonstrate the use of DMS* on differential-drive robots.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06315" title="Abstract">arXiv:2312.06315</a> [<a href="/pdf/2312.06315" title="Download PDF">pdf</a>, <a href="/format/2312.06315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Warning: This paper contains content that may be offensive or upsetting.
There has been a significant increase in the usage of large language models
(LLMs) in various applications, both in their original form and through
fine-tuned adaptations. As a result, LLMs have gained popularity and are being
widely adopted by a large user community. However, one of the concerns with
LLMs is the potential generation of socially biased content. The existing
evaluation methods have many constraints, and their results exhibit a limited
degree of interpretability. In this work, we propose a bias evaluation
framework named GPTBIAS that leverages the high performance of LLMs (e.g.,
GPT-4 \cite{openai2023gpt4}) to assess bias in models. We also introduce
prompts called Bias Attack Instructions, which are specifically designed for
evaluating model bias. To enhance the credibility and interpretability of bias
evaluation, our framework not only provides a bias score but also offers
detailed information, including bias types, affected demographics, keywords,
reasons behind the biases, and suggestions for improvement. We conduct
extensive experiments to demonstrate the effectiveness and usability of our
bias evaluation framework.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06316" title="Abstract">arXiv:2312.06316</a> [<a href="/pdf/2312.06316" title="Download PDF">pdf</a>, <a href="/format/2312.06316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemiSAM: Exploring SAM for Enhancing Semi-Supervised Medical Image  Segmentation with Extremely Limited Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised learning has attracted much attention due to its less
dependence on acquiring abundant annotations from experts compared to fully
supervised methods, which is especially important for medical image
segmentation which typically requires intensive pixel/voxel-wise labeling by
domain experts. Although semi-supervised methods can improve the performance by
utilizing unlabeled data, there are still gaps between fully supervised methods
under extremely limited annotation scenarios. In this paper, we propose a
simple yet efficient strategy to explore the usage of the Segment Anything
Model (SAM) for enhancing semi-supervised medical image segmentation.
Concretely, the segmentation model trained with domain knowledge provides
information for localization and generating input prompts to the SAM. Then the
generated pseudo-labels of SAM are utilized as additional supervision to assist
in the learning procedure of the semi-supervised framework. Experimental
results demonstrate that SAM's assistance significantly enhances the
performance of existing semi-supervised frameworks, especially when only one or
a few labeled images are available.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06317" title="Abstract">arXiv:2312.06317</a> [<a href="/pdf/2312.06317" title="Download PDF">pdf</a>, <a href="/format/2312.06317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow Symmetrization for Parameterized Constrained Diffeomorphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangopadhyay%2C+A">Aalok Gangopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Dalal%2C+D">Dwip Dalal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P">Progyan Das</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+S">Shanmuganathan Raman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Diffeomorphisms play a crucial role while searching for shapes with fixed
topological properties, allowing for smooth deformation of template shapes.
Several approaches use diffeomorphism for shape search. However, these
approaches employ only unconstrained diffeomorphisms. In this work, we develop
Flow Symmetrization - a method to represent a parametric family of constrained
diffeomorphisms that contain additional symmetry constraints such as
periodicity, rotation equivariance, and transflection equivariance. Our
representation is differentiable in nature, making it suitable for
gradient-based optimization approaches for shape search. As these symmetry
constraints naturally arise in tiling classes, our method is ideal for
representing tile shapes belonging to any tiling class. To demonstrate the
efficacy of our method, we design two frameworks for addressing the challenging
problems of Escherization and Density Estimation. The first framework is
dedicated to the Escherization problem, where we parameterize tile shapes
belonging to different isohedral classes. Given a target shape, the template
tile is deformed using gradient-based optimization to resemble the target
shape. The second framework focuses on density estimation in identification
spaces. By leveraging the inherent link between tiling theory and
identification topology, we design constrained diffeomorphisms for the plane
that result in unconstrained diffeomorphisms on the identification spaces.
Specifically, we perform density estimation on identification spaces such as
torus, sphere, Klein bottle, and projective plane. Through results and
experiments, we demonstrate that our method obtains impressive results for
Escherization on the Euclidean plane and density estimation on non-Euclidean
identification spaces.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06323" title="Abstract">arXiv:2312.06323</a> [<a href="/pdf/2312.06323" title="Download PDF">pdf</a>, <a href="/format/2312.06323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Hierarchical Prompt with Structured Linguistic Knowledge for  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yubin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">De Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cairong Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt learning has become a prevalent strategy for adapting vision-language
foundation models to downstream tasks. As large language models (LLMs) have
emerged, recent studies have explored the use of category-related descriptions
as input to enhance prompt effectiveness. Nevertheless, conventional
descriptions fall short of structured information that effectively represents
the interconnections among entities or attributes linked to a particular
category. To address this limitation and prioritize harnessing structured
knowledge, this paper advocates for leveraging LLMs to build a graph for each
description to model the entities and attributes describing the category, as
well as their correlations. Preexisting prompt tuning methods exhibit
inadequacies in managing this structured knowledge. Consequently, we propose a
novel approach called Hierarchical Prompt Tuning (HPT), which enables
simultaneous modeling of both structured and conventional linguistic knowledge.
Specifically, we introduce a relationship-guided attention module to capture
pair-wise associations among entities and attributes for low-level prompt
learning. In addition, by incorporating high-level and global-level prompts
modeling overall semantics, the proposed hierarchical structure forges
cross-level interlinks and empowers the model to handle more complex and
long-term relationships. Extensive experiments demonstrate that our HPT shows
strong effectiveness and generalizes much better than existing SOTA methods.
Our code is available at https://github.com/Vill-Lab/2024-AAAI-HPT.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06328" title="Abstract">arXiv:2312.06328</a> [<a href="/pdf/2312.06328" title="Download PDF">pdf</a>, <a href="/format/2312.06328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPRNN: A Top-Down Pyramidal Recurrent Neural Network for Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiahua Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to TKDD, 15 pages, and 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Time series refer to a series of data points indexed in time order, which can
be found in various fields, e.g., transportation, healthcare, and finance.
Accurate time series forecasting can enhance optimization planning and
decision-making support. Time series have multi-scale characteristics, i.e.,
different temporal patterns at different scales, which presents a challenge for
time series forecasting. In this paper, we propose TPRNN, a Top-down Pyramidal
Recurrent Neural Network for time series forecasting. We first construct
subsequences of different scales from the input, forming a pyramid structure.
Then by executing a multi-scale information interaction module from top to
bottom, we model both the temporal dependencies of each scale and the
influences of subsequences of different scales, resulting in a complete
modeling of multi-scale temporal patterns in time series. Experiments on seven
real-world datasets demonstrate that TPRNN has achieved the state-of-the-art
performance with an average improvement of 8.13% in MSE compared to the best
baseline.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06330" title="Abstract">arXiv:2312.06330</a> [<a href="/pdf/2312.06330" title="Download PDF">pdf</a>, <a href="/format/2312.06330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Open Set Scenarios for Skeleton-based Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Cheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+D">David Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>, 
<a href="/search/cs?searchtype=author&query=Roitberg%2C+A">Alina Roitberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. The benchmark, code, and models will be released at <a href="https://github.com/KPeng9510/OS-SAR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In real-world scenarios, human actions often fall outside the distribution of
training data, making it crucial for models to recognize known actions and
reject unknown ones. However, using pure skeleton data in such open-set
conditions poses challenges due to the lack of visual background cues and the
distinct sparse structure of body pose sequences. In this paper, we tackle the
unexplored Open-Set Skeleton-based Action Recognition (OS-SAR) task and
formalize the benchmark on three skeleton-based datasets. We assess the
performance of seven established open-set approaches on our task and identify
their limits and critical generalization issues when dealing with skeleton
information. To address these challenges, we propose a distance-based
cross-modality ensemble method that leverages the cross-modal alignment of
skeleton joints, bones, and velocities to achieve superior open-set recognition
performance. We refer to the key idea as CrossMax - an approach that utilizes a
novel cross-modality mean max discrepancy suppression mechanism to align latent
spaces during training and a cross-modality distance-based logits refinement
method during testing. CrossMax outperforms existing approaches and
consistently yields state-of-the-art results across all datasets and backbones.
The benchmark, code, and models will be released at
https://github.com/KPeng9510/OS-SAR.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06331" title="Abstract">arXiv:2312.06331</a> [<a href="/pdf/2312.06331" title="Download PDF">pdf</a>, <a href="/format/2312.06331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Connectivity-Driven Pseudo-labeling for Cross-domain  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruizhi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Q">Qi Zang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhun Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Presently, self-training stands as a prevailing approach in cross-domain
semantic segmentation, enhancing model efficacy by training with pixels
assigned with reliable pseudo-labels. However, we find two critical limitations
in this paradigm. (1) The majority of reliable pixels exhibit a speckle-shaped
pattern and are primarily located in the central semantic region. This presents
challenges for the model in accurately learning semantics. (2) Category noise
in speckle pixels is difficult to locate and correct, leading to error
accumulation in self-training. To address these limitations, we propose a novel
approach called Semantic Connectivity-driven pseudo-labeling (SeCo). This
approach formulates pseudo-labels at the connectivity level and thus can
facilitate learning structured and low-noise semantics. Specifically, SeCo
comprises two key components: Pixel Semantic Aggregation (PSA) and Semantic
Connectivity Correction (SCC). Initially, PSA divides semantics into 'stuff'
and 'things' categories and aggregates speckled pseudo-labels into semantic
connectivity through efficient interaction with the Segment Anything Model
(SAM). This enables us not only to obtain accurate boundaries but also
simplifies noise localization. Subsequently, SCC introduces a simple
connectivity classification task, which enables locating and correcting
connectivity noise with the guidance of loss distribution. Extensive
experiments demonstrate that SeCo can be flexibly applied to various
cross-domain semantic segmentation tasks, including traditional unsupervised,
source-free, and black-box domain adaptation, significantly improving the
performance of existing state-of-the-art methods. The code is available at
https://github.com/DZhaoXd/SeCo.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06336" title="Abstract">arXiv:2312.06336</a> [<a href="/pdf/2312.06336" title="Download PDF">pdf</a>, <a href="/format/2312.06336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle Lane Change Prediction based on Knowledge Graph Embeddings and  Bayesian Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manzour%2C+M">M. Manzour</a>, 
<a href="/search/cs?searchtype=author&query=Ballardini%2C+A">A. Ballardini</a>, 
<a href="/search/cs?searchtype=author&query=Izquierdo%2C+R">R. Izquierdo</a>, 
<a href="/search/cs?searchtype=author&query=Sotelo%2C+M+A">M. A. Sotelo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Prediction of vehicle lane change maneuvers has gained a lot of momentum in
the last few years. Some recent works focus on predicting a vehicle's intention
by predicting its trajectory first. This is not enough, as it ignores the
context of the scene and the state of the surrounding vehicles (as they might
be risky to the target vehicle). Other works assessed the risk made by the
surrounding vehicles only by considering their existence around the target
vehicle, or by considering the distance and relative velocities between them
and the target vehicle as two separate numerical features. In this work, we
propose a solution that leverages Knowledge Graphs (KGs) to anticipate lane
changes based on linguistic contextual information in a way that goes well
beyond the capabilities of current perception systems. Our solution takes the
Time To Collision (TTC) with surrounding vehicles as input to assess the risk
on the target vehicle. Moreover, our KG is trained on the HighD dataset using
the TransE model to obtain the Knowledge Graph Embeddings (KGE). Then, we apply
Bayesian inference on top of the KG using the embeddings learned during
training. Finally, the model can predict lane changes two seconds ahead with
97.95% f1-score, which surpassed the state of the art, and three seconds before
changing lanes with 93.60% f1-score.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06337" title="Abstract">arXiv:2312.06337</a> [<a href="/pdf/2312.06337" title="Download PDF">pdf</a>, <a href="/format/2312.06337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Imbalanced Learning for Multimodal Emotion Recognition in  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+Y">Yuntao Shou</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Nan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The main task of Multimodal Emotion Recognition in Conversations (MERC) is to
identify the emotions in modalities, e.g., text, audio, image and video, which
is a significant development direction for realizing machine intelligence.
However, many data in MERC naturally exhibit an imbalanced distribution of
emotion categories, and researchers ignore the negative impact of imbalanced
data on emotion recognition. To tackle this problem, we systematically analyze
it from three aspects: data augmentation, loss sensitivity, and sampling
strategy, and propose the Class Boundary Enhanced Representation Learning
(CBERL) model. Concretely, we first design a multimodal generative adversarial
network to address the imbalanced distribution of {emotion} categories in raw
data. Secondly, a deep joint variational autoencoder is proposed to fuse
complementary semantic information across modalities and obtain discriminative
feature representations. Finally, we implement a multi-task graph neural
network with mask reconstruction and classification optimization to solve the
problem of overfitting and underfitting in class boundary learning, and achieve
cross-modal emotion recognition. We have conducted extensive experiments on the
IEMOCAP and MELD benchmark datasets, and the results show that CBERL has
achieved a certain performance improvement in the effectiveness of emotion
recognition. Especially on the minority class fear and disgust emotion labels,
our model improves the accuracy and F1 value by 10% to 20%.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06338" title="Abstract">arXiv:2312.06338</a> [<a href="/pdf/2312.06338" title="Download PDF">pdf</a>, <a href="/format/2312.06338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoschAI @ Causal News Corpus 2023: Robust Cause-Effect Span Extraction  using Multi-Layer Sequence Tagging and Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schrader%2C+T+P">Timo Pierre Schrader</a>, 
<a href="/search/cs?searchtype=author&query=Razniewski%2C+S">Simon Razniewski</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+L">Lukas Lange</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+A">Annemarie Friedrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 tables, 1 figure, published in "Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding causality is a core aspect of intelligence. The Event Causality
Identification with Causal News Corpus Shared Task addresses two aspects of
this challenge: Subtask 1 aims at detecting causal relationships in texts, and
Subtask 2 requires identifying signal words and the spans that refer to the
cause or effect, respectively. Our system, which is based on pre-trained
transformers, stacked sequence tagging, and synthetic data augmentation, ranks
third in Subtask 1 and wins Subtask 2 with an F1 score of 72.8, corresponding
to a margin of 13 pp. to the second-best system.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06340" title="Abstract">arXiv:2312.06340</a> [<a href="/pdf/2312.06340" title="Download PDF">pdf</a>, <a href="/format/2312.06340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Shape-Servoing for Vision-based Robotic Manipulation with Model  Estimation and Performance Regulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangqing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces a manipulation framework for the elastic rod, including
shape representation, sensorimotor-model estimation, and shape controller.
Until now, the manipulation of the elastic rod has faced several challenges: 1)
shape learning from high-dimensional to low-space dimensional; 2) the modeling
of robot manipulation of the elastic rod; 3) the determination of the shape
controller. A novel manipulation framework for the elastic rod is presented in
this paper, which only uses the input and output data of the system without any
prior knowledge of the robot, camera, and object. The proposed approach runs in
a model-free manner. For the approximation of the sensorimotor model, adaptive
Kalman filtering (AKF) is used as the online estimation. Model-free adaptive
control (MFAC) is designed according to the obtained differential model of
robot-object configuration and then is combined with the performance regulation
requirement to give the final format of the shape controller. Hence, the
proposed approach can enhance the autonomous capability of deformation object
manipulation. Detailed simulation results are conducted with a single robot
manipulation to evaluate the effectiveness of the proposed manipulation
framework.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06342" title="Abstract">arXiv:2312.06342</a> [<a href="/pdf/2312.06342" title="Download PDF">pdf</a>, <a href="/format/2312.06342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Contextual Network Anomalies with Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif-Mart%C3%ADnez%2C+H">Hamid Latif-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Su%C3%A1rez-Varela%2C+J">Jos&#xe9; Su&#xe1;rez-Varela</a>, 
<a href="/search/cs?searchtype=author&query=Cabellos-Aparicio%2C+A">Albert Cabellos-Aparicio</a>, 
<a href="/search/cs?searchtype=author&query=Barlet-Ros%2C+P">Pere Barlet-Ros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 2nd International Workshop on Graph Neural Networking (GNNet '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Detecting anomalies on network traffic is a complex task due to the massive
amount of traffic flows in today's networks, as well as the highly-dynamic
nature of traffic over time. In this paper, we propose the use of Graph Neural
Networks (GNN) for network traffic anomaly detection. We formulate the problem
as contextual anomaly detection on network traffic measurements, and propose a
custom GNN-based solution that detects traffic anomalies on origin-destination
flows. In our evaluation, we use real-world data from Abilene (6 months), and
make a comparison with other widely used methods for the same task (PCA, EWMA,
RNN). The results show that the anomalies detected by our solution are quite
complementary to those captured by the baselines (with a max. of 36.33%
overlapping anomalies for PCA). Moreover, we manually inspect the anomalies
detected by our method, and find that a large portion of them can be visually
validated by a network expert (64% with high confidence, 18% with mid
confidence, 18% normal traffic). Lastly, we analyze the characteristics of the
anomalies through two paradigmatic cases that are quite representative of the
bulk of anomalies.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06343" title="Abstract">arXiv:2312.06343</a> [<a href="/pdf/2312.06343" title="Download PDF">pdf</a>, <a href="/format/2312.06343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankMatch: A Novel Approach to Semi-Supervised Label Distribution  Learning Leveraging Inter-label Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+K+Y">Kouzhiqiang Yucheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuheng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper introduces RankMatch, an innovative approach for Semi-Supervised
Label Distribution Learning (SSLDL). Addressing the challenge of limited
labeled data, RankMatch effectively utilizes a small number of labeled examples
in conjunction with a larger quantity of unlabeled data, reducing the need for
extensive manual labeling in Deep Neural Network (DNN) applications.
Specifically, RankMatch introduces an ensemble learning-inspired averaging
strategy that creates a pseudo-label distribution from multiple weakly
augmented images. This not only stabilizes predictions but also enhances the
model's robustness. Beyond this, RankMatch integrates a pairwise relevance
ranking (PRR) loss, capturing the complex inter-label correlations and ensuring
that the predicted label distributions align with the ground truth.
<br />We establish a theoretical generalization bound for RankMatch, and through
extensive experiments, demonstrate its superiority in performance against
existing SSLDL methods.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06344" title="Abstract">arXiv:2312.06344</a> [<a href="/pdf/2312.06344" title="Download PDF">pdf</a>, <a href="/format/2312.06344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Policies for Uncertain Parametric Markov Decision  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rickard%2C+L">Luke Rickard</a>, 
<a href="/search/eess?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/eess?searchtype=author&query=Margellos%2C+K">Kostas Margellos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, submitted to L4DC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Synthesising verifiably correct controllers for dynamical systems is crucial
for safety-critical problems. To achieve this, it is important to account for
uncertainty in a robust manner, while at the same time it is often of interest
to avoid being overly conservative with the view of achieving a better cost. We
propose a method for verifiably safe policy synthesis for a class of finite
state models, under the presence of structural uncertainty. In particular, we
consider uncertain parametric Markov decision processes (upMDPs), a special
class of Markov decision processes, with parameterised transition functions,
where such parameters are drawn from a (potentially) unknown distribution. Our
framework leverages recent advancements in the so-called scenario approach
theory, where we represent the uncertainty by means of scenarios, and provide
guarantees on synthesised policies satisfying probabilistic computation tree
logic (PCTL) formulae. We consider several common benchmarks/problems and
compare our work to recent developments for verifying upMDPs.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06346" title="Abstract">arXiv:2312.06346</a> [<a href="/pdf/2312.06346" title="Download PDF">pdf</a>, <a href="/ps/2312.06346" title="Download PostScript">ps</a>, <a href="/format/2312.06346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability Analysis of LQR-ANFIS Control Schemes on 2-degree-of-freedom  Inverted Pendulum Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=S%2C+S">Shamanth S</a>, 
<a href="/search/eess?searchtype=author&query=Chari%2C+A+K">Aditya Kumar Chari</a>, 
<a href="/search/eess?searchtype=author&query=S%2C+H">Harshitha S</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The concepts of stability and balance represent many critical problems faced
by engineering today. The inverted pendulum on a cart is one such non-linear,
unstable, multivariate system whose goal is to determine a suitable control
action given to the cart such that it stabilizes the pendulum in an upright
vertical position. This paper therefore, aims to design and study a highly
robust MISO control structure using Linear Quadratic Regulation, Fuzzy logic
and Neural Networks called Two-Stage LQR-based-ANFIS (referred to as TS-LA) for
the stabilization of Inverted Pendulums. The proposed controller is implemented
on a Simulink model of the Inverted Pendulum constructed through relevant
mathematical and state space modelling using Newtonian and Lagrangian
mechanics. Applying external disturbances, transient parameters are obtained
and are benchmarked against standard conventional controllers to perform
comparative analysis and showcase its disturbance rejection capabilities.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06348" title="Abstract">arXiv:2312.06348</a> [<a href="/pdf/2312.06348" title="Download PDF">pdf</a>, <a href="/format/2312.06348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAIL: Diffusion Adversarial Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingzheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+T">Teng Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guoqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yilong Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in aaai24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Imitation learning aims to solve the problem of defining reward functions in
real-world decision-making tasks. The current popular approach is the
Adversarial Imitation Learning (AIL) framework, which matches expert
state-action occupancy measures to obtain a surrogate reward for forward
reinforcement learning. However, the traditional discriminator is a simple
binary classifier and doesn't learn an accurate distribution, which may result
in failing to identify expert-level state-action pairs induced by the policy
interacting with the environment. To address this issue, we propose a method
named diffusion adversarial imitation learning (DiffAIL), which introduces the
diffusion model into the AIL framework. Specifically, DiffAIL models the
state-action pairs as unconditional diffusion models and uses diffusion loss as
part of the discriminator's learning objective, which enables the discriminator
to capture better expert demonstrations and improve generalization.
Experimentally, the results show that our method achieves state-of-the-art
performance and significantly surpasses expert demonstration on two benchmark
tasks, including the standard state-action setting and state-only settings. Our
code can be available at an anonymous link
https://github.com/ML-Group-SDU/DiffAIL.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06351" title="Abstract">arXiv:2312.06351</a> [<a href="/pdf/2312.06351" title="Download PDF">pdf</a>, <a href="/format/2312.06351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Large Language Models for Decision Making in Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanahashi%2C+K">Kotaro Tanahashi</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+Y">Yuichi Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+Y">Yu Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Yaginuma%2C+H">Hidetatsu Yaginuma</a>, 
<a href="/search/cs?searchtype=author&query=Shiotsuka%2C+D">Daiki Shiotsuka</a>, 
<a href="/search/cs?searchtype=author&query=Shimatani%2C+H">Hiroyuki Shimatani</a>, 
<a href="/search/cs?searchtype=author&query=Iwamasa%2C+K">Kohei Iwamasa</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+Y">Yoshiaki Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+T">Takafumi Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Igari%2C+K">Koki Igari</a>, 
<a href="/search/cs?searchtype=author&query=Horinouchi%2C+T">Tsukasa Horinouchi</a>, 
<a href="/search/cs?searchtype=author&query=Tokuhiro%2C+K">Kento Tokuhiro</a>, 
<a href="/search/cs?searchtype=author&query=Tokuchi%2C+Y">Yugo Tokuchi</a>, 
<a href="/search/cs?searchtype=author&query=Aoki%2C+S">Shunsuke Aoki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2023 Symposium on Machine Learning for Autonomous Driving collocated with NeurIPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">Various methods have been proposed for utilizing Large Language Models (LLMs)
in autonomous driving. One strategy of using LLMs for autonomous driving
involves inputting surrounding objects as text prompts to the LLMs, along with
their coordinate and velocity information, and then outputting the subsequent
movements of the vehicle. When using LLMs for such purposes, capabilities such
as spatial recognition and planning are essential. In particular, two
foundational capabilities are required: (1) spatial-aware decision making,
which is the ability to recognize space from coordinate information and make
decisions to avoid collisions, and (2) the ability to adhere to traffic rules.
However, quantitative research has not been conducted on how accurately
different types of LLMs can handle these problems. In this study, we
quantitatively evaluated these two abilities of LLMs in the context of
autonomous driving. Furthermore, to conduct a Proof of Concept (POC) for the
feasibility of implementing these abilities in actual vehicles, we developed a
system that uses LLMs to drive a vehicle.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06352" title="Abstract">arXiv:2312.06352</a> [<a href="/pdf/2312.06352" title="Download PDF">pdf</a>, <a href="/format/2312.06352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NuScenes-MQA: Integrated Evaluation of Captions and QA for Autonomous  Driving Datasets using Markup Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inoue%2C+Y">Yuichi Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Yada%2C+Y">Yuki Yada</a>, 
<a href="/search/cs?searchtype=author&query=Tanahashi%2C+K">Kotaro Tanahashi</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+Y">Yu Yamaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LLVM-AD Workshop @ WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Visual Question Answering (VQA) is one of the most important tasks in
autonomous driving, which requires accurate recognition and complex situation
evaluations. However, datasets annotated in a QA format, which guarantees
precise language generation and scene recognition from driving scenes, have not
been established yet. In this work, we introduce Markup-QA, a novel dataset
annotation technique in which QAs are enclosed within markups. This approach
facilitates the simultaneous evaluation of a model's capabilities in sentence
generation and VQA. Moreover, using this annotation methodology, we designed
the NuScenes-MQA dataset. This dataset empowers the development of vision
language models, especially for autonomous driving tasks, by focusing on both
descriptive capabilities and precise QA. The dataset is available at
https://github.com/turingmotors/NuScenes-MQA.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06353" title="Abstract">arXiv:2312.06353</a> [<a href="/pdf/2312.06353" title="Download PDF">pdf</a>, <a href="/format/2312.06353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Full-Parameter Tuning of Billion-Sized Language Models with  Communication Cost under 18 Kilobytes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Daoyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+B">Bingchen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We will continuously update the codebase and arXiv version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Pre-trained large language models (LLMs) require fine-tuning to improve their
responsiveness to natural language instructions. Federated learning (FL) offers
a way to perform fine-tuning using the abundant data on end devices without
compromising data privacy. Most existing federated fine-tuning methods for LLMs
rely on parameter-efficient fine-tuning techniques, which may not reach the
performance heights possible with full-parameter tuning. However, the
communication overhead associated with full-parameter tuning is prohibitively
high for both servers and clients. This work introduces FedKSeed, a novel
approach that employs zeroth-order optimization (ZOO) with a set of random
seeds. It enables federated full-parameter tuning of billion-sized LLMs
directly on devices. Our method significantly reduces transmission requirements
between the server and clients to just a few scalar gradients and random seeds,
amounting to only a few thousand bytes. Building on this, we develop a strategy
to assess the significance of ZOO perturbations for FL, allowing for
probability-differentiated seed sampling. This prioritizes perturbations that
have a greater impact on model accuracy. Experiments across six scenarios with
different LLMs, datasets and data partitions demonstrate that our approach
outperforms existing federated LLM fine-tuning methods in terms of both
communication efficiency and new task generalization.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06354" title="Abstract">arXiv:2312.06354</a> [<a href="/pdf/2312.06354" title="Download PDF">pdf</a>, <a href="/format/2312.06354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved  Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Boyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Ying Tai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Donghao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Taisong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in personalized image generation using diffusion models
have been noteworthy. However, existing methods suffer from inefficiencies due
to the requirement for subject-specific fine-tuning. This computationally
intensive process hinders efficient deployment, limiting practical usability.
Moreover, these methods often grapple with identity distortion and limited
expression diversity. In light of these challenges, we propose PortraitBooth,
an innovative approach designed for high efficiency, robust identity
preservation, and expression-editable text-to-image generation, without the
need for fine-tuning. PortraitBooth leverages subject embeddings from a face
recognition model for personalized image generation without fine-tuning. It
eliminates computational overhead and mitigates identity distortion. The
introduced dynamic identity preservation strategy further ensures close
resemblance to the original image identity. Moreover, PortraitBooth
incorporates emotion-aware cross-attention control for diverse facial
expressions in generated images, supporting text-driven expression editing. Its
scalability enables efficient and high-quality image creation, including
multi-subject generation. Extensive results demonstrate superior performance
over other state-of-the-art methods in both single and multiple image
generation scenarios.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06355" title="Abstract">arXiv:2312.06355</a> [<a href="/pdf/2312.06355" title="Download PDF">pdf</a>, <a href="/ps/2312.06355" title="Download PostScript">ps</a>, <a href="/format/2312.06355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Basis of Engineering Design Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddharth%2C+L">L. Siddharth</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianxi Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Digital Libraries (cs.DL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Engineering design knowledge is embodied in natural language text through
intricate placement of entities and relationships. Ontological constructs of
design knowledge often limit the performances of NLP techniques to extract
design knowledge. Also, large-language models could be less useful for
generating and explicating design knowledge, as these are trained predominantly
on common-sense text. In this article, we present the constituents of design
knowledge based on empirical observations from patent documents. We obtain a
sample of 33,881 patents and populate over 24 million facts from the sentences
in these. We conduct Zipf distribution analyses using the frequencies of unique
entities and relationships that are present in the facts thus populated. While
the literal entities cannot be generalised from the sample of patents, the
relationships largely capture attributes ('of'), structure ('in', 'with'),
purpose ('to', 'for'), hierarchy ('include'), exemplification ('such as'), and
behaviour ('to', 'from'). The analyses reveal that over half of entities and
relationships could be generalised to 64 and 24 linguistic syntaxes
respectively, while hierarchical relationships include 75 syntaxes. These
syntaxes represent the linguistic basis of engineering design knowledge. We
combine facts within each patent into a knowledge graph, from which we discover
motifs that are statistically over-represented subgraph patterns. Across all
patents in the sample, we identify eight patterns that could be simplified into
sequence [-&gt;...-&gt;], aggregation [-&gt;...&lt;-], and hierarchy [&lt;-...-&gt;] that form
the structural basis of engineering design knowledge. We propose regulatory
precepts for concretising abstract entities and relationships within subgraphs,
while also explicating hierarchical structures. These precepts could be useful
for better construction and management of knowledge in a design environment.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06357" title="Abstract">arXiv:2312.06357</a> [<a href="/pdf/2312.06357" title="Download PDF">pdf</a>, <a href="/format/2312.06357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOSS: A Self-Learned Doctor for Query Optimizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+K">Kai Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Luming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cuiping Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Various works have utilized deep reinforcement learning (DRL) to address the
query optimization problem in database system. They either learn to construct
plans from scratch in a bottom-up manner or guide the plan generation behavior
of traditional optimizer using hints. While these methods have achieved some
success, they face challenges in either low training efficiency or limited plan
search space. To address these challenges, we introduce FOSS, a novel DRL-based
framework for query optimization. FOSS initiates optimization from the original
plan generated by a traditional optimizer and incrementally refines suboptimal
nodes of the plan through a sequence of actions. Additionally, we devise an
asymmetric advantage model to evaluate the advantage between two plans. We
integrate it with a traditional optimizer to form a simulated environment.
Leveraging this simulated environment, FOSS can bootstrap itself to rapidly
generate a large amount of high-quality simulated experiences. FOSS then learns
and improves its optimization capability from these simulated experiences. We
evaluate the performance of FOSS on Join Order Benchmark, TPC-DS, and Stack
Overflow. The experimental results demonstrate that FOSS outperforms the
state-of-the-art methods in terms of latency performance and optimization time.
Compared to PostgreSQL, FOSS achieves savings ranging from 15% to 83% in total
latency across different benchmarks.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06358" title="Abstract">arXiv:2312.06358</a> [<a href="/pdf/2312.06358" title="Download PDF">pdf</a>, <a href="/format/2312.06358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intraoperative 2D/3D Image Registration via Differentiable X-ray  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+V">Vivek Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+N">Neel Dey</a>, 
<a href="/search/cs?searchtype=author&query=Golland%2C+P">Polina Golland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vivekg.dev/DiffPose/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Surgical decisions are informed by aligning rapid portable 2D intraoperative
images (e.g., X-rays) to a high-fidelity 3D preoperative reference scan (e.g.,
CT). 2D/3D image registration often fails in practice: conventional
optimization methods are prohibitively slow and susceptible to local minima,
while neural networks trained on small datasets fail on new patients or require
impractical landmark supervision. We present DiffPose, a self-supervised
approach that leverages patient-specific simulation and differentiable
physics-based rendering to achieve accurate 2D/3D registration without relying
on manually labeled data. Preoperatively, a CNN is trained to regress the pose
of a randomly oriented synthetic X-ray rendered from the preoperative CT. The
CNN then initializes rapid intraoperative test-time optimization that uses the
differentiable X-ray renderer to refine the solution. Our work further proposes
several geometrically principled methods for sampling camera poses from
$\mathbf{SE}(3)$, for sparse differentiable rendering, and for driving
registration in the tangent space $\mathfrak{se}(3)$ with geodesic and
multiscale locality-sensitive losses. DiffPose achieves sub-millimeter accuracy
across surgical datasets at intraoperative speeds, improving upon existing
unsupervised methods by an order of magnitude and even outperforming supervised
baselines. Our code is available at https://github.com/eigenvivek/DiffPose.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06363" title="Abstract">arXiv:2312.06363</a> [<a href="/pdf/2312.06363" title="Download PDF">pdf</a>, <a href="/format/2312.06363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although In-Context Learning (ICL) brings remarkable performance gains to
Large Language Models (LLMs), the improvements remain lower than fine-tuning on
downstream tasks. This paper introduces Multi-Modal In-Context Tuning (MMICT),
a novel multi-modal fine-tuning paradigm that boosts multi-modal fine-tuning by
fully leveraging the promising ICL capability of multi-modal LLMs (MM-LLMs). We
propose the Multi-Modal Hub (M-Hub), a unified module that captures various
multi-modal features according to different inputs and objectives. Based on
M-Hub, MMICT enables MM-LLMs to learn from in-context visual-guided textual
features and subsequently generate outputs conditioned on the textual-guided
visual features. Moreover, leveraging the flexibility of M-Hub, we design a
variety of in-context demonstrations. Extensive experiments on a diverse range
of downstream multi-modal tasks demonstrate that MMICT significantly
outperforms traditional fine-tuning strategy and the vanilla ICT method that
directly takes the concatenation of all information from different modalities
as input.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06364" title="Abstract">arXiv:2312.06364</a> [<a href="/pdf/2312.06364" title="Download PDF">pdf</a>, <a href="/format/2312.06364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embodied Carbon Accounting through Spatial-Temporal Embodied Carbon  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Embodied carbon is the total carbon released from the processes associated
with a product from cradle to gate. In many industry sectors, embodied carbon
dominates the overall carbon footprint. Embodied carbon accounting, i.e., to
estimate the embodied carbon of a product, has become an important research
topic.
<br />Existing studies derive the embodied carbon through life cycle analysis (LCA)
reports. Current LCA reports only provide the carbon emission of a product
class, e.g., 28nm CPU, yet a product instance can be manufactured from diverse
regions and in diverse time periods, e.g., a winter period of Ireland (Intel).
It is known that the carbon emission depends on the electricity generation
process which has spatial and temporal dynamics. Therefore, the embodied carbon
of a specific product instance can largely differ from its product class. In
this paper, we present new spatial-temporal embodied carbon models for embodied
carbon accounting. We observe significant differences between current embodied
carbon models and our spatial-temporal embodied carbon models, e.g., for 7nm
CPU the difference can be 13.69%.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06365" title="Abstract">arXiv:2312.06365</a> [<a href="/pdf/2312.06365" title="Download PDF">pdf</a>, <a href="/ps/2312.06365" title="Download PostScript">ps</a>, <a href="/format/2312.06365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study and Kinematics Analysis of a Quadruped Robot by the Protype  Building Leg
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+A">Abid Shahriar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Kinematics analysis is a crucial part for multiple joint enabled robot. For
Mmathematically moving a multi joined enabled robot, it needs some mathematical
calculations to be done that way so the end effector's position can be
determined with respect to the other connective joints involved and their
respective frames in a specific co-ordinate system. For a locomotive quadruped
robot, it is essential to determine two types of kinematics for the robot's leg
position on the co-ordinate. For the part of forward kinematics, it measures
the position and er can calculate the joint angles by using inverse kinematics.
in this study, we mathematically analyze and derived the forward and the
inverse kinematics of the quadruped robot and first we have done the simulation
with Jupiter notebook in Python environment for the mathematical analysis and
verification and also test our kinematics code on a prototype build leg.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06367" title="Abstract">arXiv:2312.06367</a> [<a href="/pdf/2312.06367" title="Download PDF">pdf</a>, <a href="/format/2312.06367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stabilized time-domain combined field integral equation using the  quasi-Helmholtz projectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Le%2C+V+C">Van Chien Le</a>, 
<a href="/search/math?searchtype=author&query=Cordel%2C+P">Pierrick Cordel</a>, 
<a href="/search/math?searchtype=author&query=Andriulli%2C+F+P">Francesco P. Andriulli</a>, 
<a href="/search/math?searchtype=author&query=Cools%2C+K">Kristof Cools</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a time-domain combined field integral equation for
electromagnetic scattering by a perfect electric conductor. The new equation is
obtained by leveraging the quasi-Helmholtz projectors, which separate both the
unknown and the source fields into solenoidal and irrotational components.
These two components are then appropriately rescaled to cure the solution from
a loss of accuracy occurring when the time step is large. Yukawa-type integral
operators of a purely imaginary wave number are also used as a Calderon
preconditioner to eliminate the ill-conditioning of matrix systems. The
stabilized time-domain electric and magnetic field integral equations are
linearly combined in a Calderon-like fashion, then temporally discretized using
a proper pair of trial functions, resulting in a marching-on-in-time linear
system. The novel formulation is immune to spurious resonances, dense
discretization breakdown, large-time step breakdown and dc instabilities
stemming from non-trivial kernels. Numerical results for both simply-connected
and multiply-connected scatterers corroborate the theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06371" title="Abstract">arXiv:2312.06371</a> [<a href="/pdf/2312.06371" title="Download PDF">pdf</a>, <a href="/format/2312.06371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAT: Behavior-Aware Human-Like Trajectory Prediction for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Haicheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenning Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huanming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenxuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guofa Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The ability to accurately predict the trajectory of surrounding vehicles is a
critical hurdle to overcome on the journey to fully autonomous vehicles. To
address this challenge, we pioneer a novel behavior-aware trajectory prediction
model (BAT) that incorporates insights and findings from traffic psychology,
human behavior, and decision-making. Our model consists of behavior-aware,
interaction-aware, priority-aware, and position-aware modules that perceive and
understand the underlying interactions and account for uncertainty and
variability in prediction, enabling higher-level learning and flexibility
without rigid categorization of driving behavior. Importantly, this approach
eliminates the need for manual labeling in the training process and addresses
the challenges of non-continuous behavior labeling and the selection of
appropriate time windows. We evaluate BAT's performance across the Next
Generation Simulation (NGSIM), Highway Drone (HighD), Roundabout Drone (RounD),
and Macao Connected Autonomous Driving (MoCAD) datasets, showcasing its
superiority over prevailing state-of-the-art (SOTA) benchmarks in terms of
prediction accuracy and efficiency. Remarkably, even when trained on reduced
portions of the training data (25%), our model outperforms most of the
baselines, demonstrating its robustness and efficiency in predicting vehicle
trajectories, and the potential to reduce the amount of data required to train
autonomous vehicles, especially in corner cases. In conclusion, the
behavior-aware model represents a significant advancement in the development of
autonomous vehicles capable of predicting trajectories with the same level of
proficiency as human drivers. The project page is available at
https://github.com/Petrichor625/BATraj-Behavior-aware-Model.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06372" title="Abstract">arXiv:2312.06372</a> [<a href="/pdf/2312.06372" title="Download PDF">pdf</a>, <a href="/format/2312.06372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ternary Spike: Learning Ternary Spikes for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yufei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaode Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhe Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Spiking Neural Network (SNN), as one of the biologically inspired neural
network infrastructures, has drawn increasing attention recently. It adopts
binary spike activations to transmit information, thus the multiplications of
activations and weights can be substituted by additions, which brings high
energy efficiency. However, in the paper, we theoretically and experimentally
prove that the binary spike activation map cannot carry enough information,
thus causing information loss and resulting in accuracy decreasing. To handle
the problem, we propose a ternary spike neuron to transmit information. The
ternary spike neuron can also enjoy the event-driven and multiplication-free
operation advantages of the binary spike neuron but will boost the information
capacity. Furthermore, we also embed a trainable factor in the ternary spike
neuron to learn the suitable spike amplitude, thus our SNN will adopt different
spike amplitudes along layers, which can better suit the phenomenon that the
membrane potential distributions are different along layers. To retain the
efficiency of the vanilla ternary spike, the trainable ternary spike SNN will
be converted to a standard one again via a re-parameterization technique in the
inference. Extensive experiments with several popular network structures over
static and dynamic datasets show that the ternary spike can consistently
outperform state-of-the-art methods. Our code is open-sourced at
https://github.com/yfguo91/Ternary-Spike.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06374" title="Abstract">arXiv:2312.06374</a> [<a href="/pdf/2312.06374" title="Download PDF">pdf</a>, <a href="/ps/2312.06374" title="Download PostScript">ps</a>, <a href="/format/2312.06374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UstanceBR: a multimodal language resource for stance prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+C">Camila Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Pavan%2C+M">Matheus Pavan</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungwon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+R">Ricelli Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+P">Pablo Costa</a>, 
<a href="/search/cs?searchtype=author&query=Cavalheiro%2C+L">Lais Cavalheiro</a>, 
<a href="/search/cs?searchtype=author&query=Paraboni%2C+I">Ivandre Paraboni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work introduces UstanceBR, a multimodal corpus in the Brazilian
Portuguese Twitter domain for target-based stance prediction. The corpus
comprises 86.8 k labelled stances towards selected target topics, and extensive
network information about the users who published these stances on social
media. In this article we describe the corpus multimodal data, and a number of
usage examples in both in-domain and zero-shot stance prediction based on text-
and network-related information, which are intended to provide initial baseline
results for future studies in the field.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06377" title="Abstract">arXiv:2312.06377</a> [<a href="/pdf/2312.06377" title="Download PDF">pdf</a>, <a href="/ps/2312.06377" title="Download PostScript">ps</a>, <a href="/format/2312.06377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms and Turing Kernels for Detecting and Counting Small Patterns  in Unit Disk Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nederlof%2C+J">Jesper Nederlof</a>, 
<a href="/search/cs?searchtype=author&query=Szil%C3%A1gyi%2C+K">Krisztina Szil&#xe1;gyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper we investigate the parameterized complexity of the task of
counting and detecting occurrences of small patterns in unit disk graphs: Given
an $n$-vertex unit disk graph $G$ with an embedding of ply $p$ (that is, the
graph is represented as intersection graph with closed disks of unit size, and
each point is contained in at most $p$ disks) and a $k$-vertex unit disk graph
$P$, count the number of (induced) copies of $P$ in $G$.
<br />For general patterns $P$, we give an $2^{O(p k /\log k)}n^{O(1)}$ time
algorithm for counting pattern occurrences. We show this is tight, even for ply
$p=2$ and $k=n$: any $2^{o(n/\log n)}n^{O(1)}$ time algorithm violates the
Exponential Time Hypothesis (ETH).
<br />For most natural classes of patterns, such as connected graphs and
independent sets we present the following results: First, we give an
$(pk)^{O(\sqrt{pk})}n^{O(1)}$ time algorithm, which is nearly tight under the
ETH for bounded ply and many patterns. Second, for $p= k^{O(1)}$ we provide a
Turing kernelization (i.e. we give a polynomial time preprocessing algorithm to
reduce the instance size to $k^{O(1)}$).
<br />Our approach combines previous tools developed for planar subgraph
isomorphism such as `efficient inclusion-exclusion' from [Nederlof STOC'20],
and `isomorphisms checks' from [Bodlaender et al. ICALP'16] with a different
separator hierarchy and a new bound on the number of non-isomorphic separations
of small order tailored for unit disk graphs.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06382" title="Abstract">arXiv:2312.06382</a> [<a href="/pdf/2312.06382" title="Download PDF">pdf</a>, <a href="/format/2312.06382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciCat: A Curated Dataset of Scientific Software Repositories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malviya-Thakur%2C+A">Addi Malviya-Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Milewicz%2C+R">Reed Milewicz</a>, 
<a href="/search/cs?searchtype=author&query=Paganini%2C+L">Lavinia Paganini</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoud%2C+A+S+I">Ahmed Samir Imam Mahmoud</a>, 
<a href="/search/cs?searchtype=author&query=Mockus%2C+A">Audris Mockus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computational Engineering, Finance, and Science (cs.CE); Digital Libraries (cs.DL)

</div>
<p class="mathjax">The proliferation of open-source scientific software for science and research
presents opportunities and challenges. In this paper, we introduce the SciCat
dataset -- a comprehensive collection of Free-Libre Open Source Software
(FLOSS) projects, designed to address the need for a curated repository of
scientific and research software. This collection is crucial for understanding
the creation of scientific software and aiding in its development. To ensure
extensive coverage, our approach involves selecting projects from a pool of 131
million deforked repositories from the World of Code data source. Subsequently,
we analyze README.md files using OpenAI's advanced language models. Our
classification focuses on software designed for scientific purposes,
research-related projects, and research support software. The SciCat dataset
aims to become an invaluable tool for researching science-related software,
shedding light on emerging trends, prevalent practices, and challenges in the
field of scientific software development. Furthermore, it includes data that
can be linked to the World of Code, GitHub, and other platforms, providing a
solid foundation for conducting comparative studies between scientific and
non-scientific software.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06384" title="Abstract">arXiv:2312.06384</a> [<a href="/pdf/2312.06384" title="Download PDF">pdf</a>, <a href="/ps/2312.06384" title="Download PostScript">ps</a>, <a href="/format/2312.06384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Output contraction analysis of nonlinear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yin%2C+H">Hao Yin</a>, 
<a href="/search/eess?searchtype=author&query=Jayawardhana%2C+B">Bayu Jayawardhana</a>, 
<a href="/search/eess?searchtype=author&query=Trenn%2C+S">Stephan Trenn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduce the notion of output contraction that expands the
contraction notion to the time-varying nonlinear systems with output. It
pertains to the systems' property that any pair of outputs from the system
converge to each other exponentially. This concept exhibits a more expansive
nature when contrasted with another generalized contraction framework known as
partial contraction. The first result establishes a connection between the
output contraction of a time-varying system and the output exponential
stability of its variational system. Subsequently, we derive a sufficient
condition for achieving output contraction in time-varying systems by applying
the output contraction Lyapunov criterion. Finally, we apply the results to
analyze the output exponential stability of nonlinear time-invariant systems.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06386" title="Abstract">arXiv:2312.06386</a> [<a href="/pdf/2312.06386" title="Download PDF">pdf</a>, <a href="/format/2312.06386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ManiPose: Manifold-Constrained Multi-Hypothesis 3D Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rommel%2C+C">C&#xe9;dric Rommel</a>, 
<a href="/search/cs?searchtype=author&query=Letzelter%2C+V">Victor Letzelter</a>, 
<a href="/search/cs?searchtype=author&query=Samet%2C+N">Nermin Samet</a>, 
<a href="/search/cs?searchtype=author&query=Marlet%2C+R">Renaud Marlet</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+E">Eduardo Valle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Monocular 3D human pose estimation (3D-HPE) is an inherently ambiguous task,
as a 2D pose in an image might originate from different possible 3D poses. Yet,
most 3D-HPE methods rely on regression models, which assume a one-to-one
mapping between inputs and outputs. In this work, we provide theoretical and
empirical evidence that, because of this ambiguity, common regression models
are bound to predict topologically inconsistent poses, and that traditional
evaluation metrics, such as the MPJPE, P-MPJPE and PCK, are insufficient to
assess this aspect. As a solution, we propose ManiPose, a novel
manifold-constrained multi-hypothesis model capable of proposing multiple
candidate 3D poses for each 2D input, together with their corresponding
plausibility. Unlike previous multi-hypothesis approaches, our solution is
completely supervised and does not rely on complex generative models, thus
greatly facilitating its training and usage. Furthermore, by constraining our
model to lie within the human pose manifold, we can guarantee the consistency
of all hypothetical poses predicted with our approach, which was not possible
in previous works. We illustrate the usefulness of ManiPose in a synthetic
1D-to-2D lifting setting and demonstrate on real-world datasets that it
outperforms state-of-the-art models in pose consistency by a large margin,
while still reaching competitive MPJPE performance.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06393" title="Abstract">arXiv:2312.06393</a> [<a href="/pdf/2312.06393" title="Download PDF">pdf</a>, <a href="/ps/2312.06393" title="Download PostScript">ps</a>, <a href="/format/2312.06393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Algorithms for Covering by Arithmetic Progressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bliznets%2C+I">Ivan Bliznets</a>, 
<a href="/search/cs?searchtype=author&query=Nederlof%2C+J">Jesper Nederlof</a>, 
<a href="/search/cs?searchtype=author&query=Szil%C3%A1gyi%2C+K">Krisztina Szil&#xe1;gyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">An arithmetic progression is a sequence of integers in which the difference
between any two consecutive elements is the same. We investigate the
parameterized complexity of two problems related to arithmetic progressions,
called Cover by Arithmetic Progressions (CAP) and Exact Cover by Arithmetic
Progressions (XCAP). In both problems, we are given a set $X$ consisting of $n$
integers along with an integer $k$, and our goal is to find $k$ arithmetic
progressions whose union is $X$. In XCAP we additionally require the arithmetic
progressions to be disjoint. Both problems were shown to be NP-complete by
Heath [IPL'90].
<br />We present a $2^{O(k^2)} poly(n)$ time algorithm for CAP and a $2^{O(k^3)}
poly(n)$ time algorithm for XCAP. We also give a fixed parameter tractable
algorithm for CAP parameterized below some guaranteed solution size. We
complement these findings by proving that CAP is Strongly NP-complete in the
field $\mathbb{Z}_p$, if $p$ is a prime number part of the input.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06395" title="Abstract">arXiv:2312.06395</a> [<a href="/pdf/2312.06395" title="Download PDF">pdf</a>, <a href="/format/2312.06395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threshold Decision-Making Dynamics Adaptive to Physical Constraints and  Changing Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amorim%2C+G">Giovanna Amorim</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+M">Mar&#xed;a Santos</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Shinkyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Franci%2C+A">Alessio Franci</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+N+E">Naomi Ehrich Leonard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a threshold decision-making framework for controlling the physical
dynamics of an agent switching between two spatial tasks. Our framework couples
a nonlinear opinion dynamics model that represents the evolution of an agent's
preference for a particular task with the physical dynamics of the agent. We
prove the bifurcation that governs the behavior of the coupled dynamics. We
show by means of the bifurcation behavior how the coupled dynamics are adaptive
to the physical constraints of the agent. We also show how the bifurcation can
be modulated to allow the agent to switch tasks based on thresholds adaptive to
environmental conditions. We illustrate the benefits of the approach through a
decentralized multi-robot task allocation application for trash collection.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06396" title="Abstract">arXiv:2312.06396</a> [<a href="/pdf/2312.06396" title="Download PDF">pdf</a>, <a href="/ps/2312.06396" title="Download PostScript">ps</a>, <a href="/format/2312.06396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiDiTeR: Similarity Discovering Techniques for Robotic Process  Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prucha%2C+P">Petr Prucha</a>, 
<a href="/search/cs?searchtype=author&query=Madzik%2C+P">Peter Madzik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic Process Automation (RPA) has gained widespread adoption in corporate
organizations, streamlining work processes while also introducing additional
maintenance tasks. Effective governance of RPA can be achieved through the
reusability of RPA components. However, refactoring RPA processes poses
challenges when dealing with larger development teams, outsourcing, and staff
turnover. This research aims to explore the possibility of identifying
similarities in RPA processes for refactoring. To address this issue, we have
developed Similarity Discovering Techniques for RPA (SiDiTeR). SiDiTeR utilizes
source code or process logs from RPAautomations to search for similar or
identical parts within RPA processes. The techniques introduced are
specifically tailored to the RPA domain. We have expanded the potential matches
by introducing a dictionary feature which helps identify different activities
that produce the same output, and this has led to improved results in the RPA
domain. Through our analysis, we have discovered 655 matches across 156
processes, with the longest match spanning 163 occurrences in 15 processes.
Process similarity within the RPA domain proves to be a viable solution for
mitigating the maintenance burden associated with RPA. This underscores the
significance of process similarity in the RPA domain.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06397" title="Abstract">arXiv:2312.06397</a> [<a href="/pdf/2312.06397" title="Download PDF">pdf</a>, <a href="/format/2312.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUST: An Effective and Scalable Framework for Multimodal Search of  Target Modality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+X">Xiangyu Ke</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Pinpin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Runkai Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">We investigate the problem of multimodal search of target modality, where the
task involves enhancing a query in a specific target modality by integrating
information from auxiliary modalities. The goal is to retrieve relevant objects
whose contents in the target modality match the specified multimodal query. The
paper first introduces two baseline approaches that integrate techniques from
the Database, Information Retrieval, and Computer Vision communities. These
baselines either merge the results of separate vector searches for each
modality or perform a single-channel vector search by fusing all modalities.
However, both baselines have limitations in terms of efficiency and accuracy as
they fail to adequately consider the varying importance of fusing information
across modalities. To overcome these limitations, the paper proposes a novel
framework, called MUST. Our framework employs a hybrid fusion mechanism,
combining different modalities at multiple stages. Notably, we leverage vector
weight learning to determine the importance of each modality, thereby enhancing
the accuracy of joint similarity measurement. Additionally, the proposed
framework utilizes a fused proximity graph index, enabling efficient joint
search for multimodal queries. MUST offers several other advantageous
properties, including pluggable design to integrate any advanced embedding
techniques, user flexibility to customize weight preferences, and modularized
index construction. Extensive experiments on real-world datasets demonstrate
the superiority of MUST over the baselines in terms of both search accuracy and
efficiency. Our framework achieves over 10x faster search times while attaining
an average of 93% higher accuracy. Furthermore, MUST exhibits scalability to
datasets containing more than 10 million data elements.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06398" title="Abstract">arXiv:2312.06398</a> [<a href="/pdf/2312.06398" title="Download PDF">pdf</a>, <a href="/format/2312.06398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code and data are available at: <a href="https://github.com/vLAR-group/NVFi">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we aim to model 3D scene dynamics from multi-view videos.
Unlike the majority of existing works which usually focus on the common task of
novel view synthesis within the training time period, we propose to
simultaneously learn the geometry, appearance, and physical velocity of 3D
scenes only from video frames, such that multiple desirable applications can be
supported, including future frame extrapolation, unsupervised 3D semantic scene
decomposition, and dynamic motion transfer. Our method consists of three major
components, 1) the keyframe dynamic radiance field, 2) the interframe velocity
field, and 3) a joint keyframe and interframe optimization module which is the
core of our framework to effectively train both networks. To validate our
method, we further introduce two dynamic 3D datasets: 1) Dynamic Object
dataset, and 2) Dynamic Indoor Scene dataset. We conduct extensive experiments
on multiple datasets, demonstrating the superior performance of our method over
all baselines, particularly in the critical tasks of future frame extrapolation
and unsupervised 3D semantic scene decomposition.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06399" title="Abstract">arXiv:2312.06399</a> [<a href="/pdf/2312.06399" title="Download PDF">pdf</a>, <a href="/ps/2312.06399" title="Download PostScript">ps</a>, <a href="/format/2312.06399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Are Tweeting About Academic Publications? A Cochrane Systematic  Review and Meta-Analysis of Altmetric Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maleki%2C+A">Ashraf Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Holmberg%2C+K">Kim Holmberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Previous studies have developed different categorizations of Twitter users
who interact with scientific publications online, reflecting the difficulty in
creating a unified approach. Using Cochrane Review meta-analysis to analyse
earlier research (including 79,014 Twitter users, over twenty million tweets,
and over five million tweeted publications from 23 studies), we created a
consolidated robust categorization consisting of 11 user categories, at
different dimensions, covering most of any future needs for user
categorizations on Twitter and possibly also other social media platforms. Our
findings showed, with moderate certainty, covering all the earlier different
approaches employed, that the predominant Twitter group was individual users
(66%), responsible for the majority of tweets (55%) and tweeted publications
(50%), while organizations (22%, 27%, and 28%, respectively) and science
communicators (16%, 13%, and 30%) clearly contributed smaller proportions. The
cumulative findings from prior investigations indicated a statistically equal
extent of academic individuals (33%) and other individuals (28%). While
academic individuals shared more academic publications than other individuals
(42% vs. 31%), they posted fewer tweets overall (22% vs. 30%), but these
differences do not reach statistical significance. Despite significant
heterogeneity arising from variations in categorization methods, the findings
consistently indicate the importance of academics in disseminating academic
publications.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06400" title="Abstract">arXiv:2312.06400</a> [<a href="/pdf/2312.06400" title="Download PDF">pdf</a>, <a href="/format/2312.06400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiT-Head: High-Resolution Talking Head Synthesis using Diffusion  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mir%2C+A">Aaron Mir</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+E">Eduardo Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Mondrag%C3%B3n%2C+E">Esther Mondrag&#xf3;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a novel talking head synthesis pipeline called "DiT-Head", which
is based on diffusion transformers and uses audio as a condition to drive the
denoising process of a diffusion model. Our method is scalable and can
generalise to multiple identities while producing high-quality results. We
train and evaluate our proposed approach and compare it against existing
methods of talking head synthesis. We show that our model can compete with
these methods in terms of visual quality and lip-sync accuracy. Our results
highlight the potential of our proposed approach to be used for a wide range of
applications, including virtual assistants, entertainment, and education. For a
video demonstration of the results and our user study, please refer to our
supplementary material.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06401" title="Abstract">arXiv:2312.06401</a> [<a href="/pdf/2312.06401" title="Download PDF">pdf</a>, <a href="/format/2312.06401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compound Text-Guided Prompt Tuning via Image-Adaptive Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yizhuang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Models (VLMs) such as CLIP have demonstrated remarkable
generalization capabilities to downstream tasks. However, existing prompt
tuning based frameworks need to parallelize learnable textual inputs for all
categories, suffering from massive GPU memory consumption when there is a large
number of categories in the target dataset. Moreover, previous works require to
include category names within prompts, exhibiting subpar performance when
dealing with ambiguous category names. To address these shortcomings, we
propose Compound Text-Guided Prompt Tuning (TGP-T) that significantly reduces
resource demand while achieving superior performance. We introduce text
supervision to the optimization of prompts, which enables two benefits: 1)
releasing the model reliance on the pre-defined category names during
inference, thereby enabling more flexible prompt generation; 2) reducing the
number of inputs to the text encoder, which decreases GPU memory consumption
significantly. Specifically, we found that compound text supervisions, i.e.,
category-wise and content-wise, is highly effective, since they provide
inter-class separability and capture intra-class variations, respectively.
Moreover, we condition the prompt generation on visual features through a
module called Bonder, which facilitates the alignment between prompts and
visual features. Extensive experiments on few-shot recognition and domain
generalization demonstrate that TGP-T achieves superior performance with
consistently lower training costs. It reduces GPU memory usage by 93% and
attains a 2.5% performance gain on 16-shot ImageNet. The code is available at
https://github.com/EricTan7/TGP-T.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06406" title="Abstract">arXiv:2312.06406</a> [<a href="/pdf/2312.06406" title="Download PDF">pdf</a>, <a href="/format/2312.06406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial End-to-end Reinforcement Learning for Robustness Against  Modelling Error in Autonomous Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murdoch%2C+A">Andrew Murdoch</a>, 
<a href="/search/cs?searchtype=author&query=Schoeman%2C+J+C">Johannes Cornelius Schoeman</a>, 
<a href="/search/cs?searchtype=author&query=Jordaan%2C+H+W">Hendrik Willem Jordaan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Intelligent Transport Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we address the issue of increasing the performance of
reinforcement learning (RL) solutions for autonomous racing cars when
navigating under conditions where practical vehicle modelling errors (commonly
known as \emph{model mismatches}) are present. To address this challenge, we
propose a partial end-to-end algorithm that decouples the planning and control
tasks. Within this framework, an RL agent generates a trajectory comprising a
path and velocity, which is subsequently tracked using a pure pursuit steering
controller and a proportional velocity controller, respectively. In contrast,
many current learning-based (i.e., reinforcement and imitation learning)
algorithms utilise an end-to-end approach whereby a deep neural network
directly maps from sensor data to control commands. By leveraging the
robustness of a classical controller, our partial end-to-end driving algorithm
exhibits better robustness towards model mismatches than standard end-to-end
algorithms.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06408" title="Abstract">arXiv:2312.06408</a> [<a href="/pdf/2312.06408" title="Download PDF">pdf</a>, <a href="/format/2312.06408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven  Differentiable Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yewen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Combining gradient-based trajectory optimization with differentiable physics
simulation is an efficient technique for solving soft-body manipulation
problems. Using a well-crafted optimization objective, the solver can quickly
converge onto a valid trajectory. However, writing the appropriate objective
functions requires expert knowledge, making it difficult to collect a large set
of naturalistic problems from non-expert users. We introduce DiffVL, a method
that enables non-expert users to communicate soft-body manipulation tasks -- a
combination of vision and natural language, given in multiple stages -- that
can be readily leveraged by a differential physics solver. We have developed
GUI tools that enable non-expert users to specify 100 tasks inspired by
real-life soft-body manipulations from online videos, which we'll make public.
We leverage large language models to translate task descriptions into
machine-interpretable optimization objectives. The optimization objectives can
help differentiable physics solvers to solve these long-horizon multistage
tasks that are challenging for previous baselines.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06409" title="Abstract">arXiv:2312.06409</a> [<a href="/pdf/2312.06409" title="Download PDF">pdf</a>, <a href="/format/2312.06409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointVoxel: A Simple and Effective Pipeline for Multi-View Multi-Modal  3D Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhicheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianjiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, several methods have been proposed to estimate 3D human pose from
multi-view images and achieved impressive performance on public datasets
collected in relatively easy scenarios. However, there are limited approaches
for extracting 3D human skeletons from multimodal inputs (e.g., RGB and
pointcloud) that can enhance the accuracy of predicting 3D poses in challenging
situations. We fill this gap by introducing a pipeline called PointVoxel that
fuses multi-view RGB and pointcloud inputs to obtain 3D human poses. We
demonstrate that volumetric representation is an effective architecture for
integrating these different modalities. Moreover, in order to overcome the
challenges of annotating 3D human pose labels in difficult scenarios, we
develop a synthetic dataset generator for pretraining and design an
unsupervised domain adaptation strategy so that we can obtain a well-trained 3D
human pose estimator without using any manual annotations. We evaluate our
approach on four datasets (two public datasets, one synthetic dataset, and one
challenging dataset named BasketBall collected by ourselves), showing promising
results. The code and dataset will be released soon.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06417" title="Abstract">arXiv:2312.06417</a> [<a href="/pdf/2312.06417" title="Download PDF">pdf</a>, <a href="/format/2312.06417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Matrix Truncation Method for Improving Approximate Factorisation  Preconditioners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bock%2C+A+A">Andreas A. Bock</a>, 
<a href="/search/math?searchtype=author&query=Andersen%2C+M+S">Martin S. Andersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a general framework for preconditioning Hermitian positive
definite linear systems based on the Bregman log determinant divergence. This
divergence provides a measure of discrepancy between a preconditioner and a
target matrix. Given an approximate factorisation of a target matrix, the
proposed framework tells us how to construct a low-rank approximation of the
typically indefinite factorisation error. The resulting preconditioner is
therefore a sum of a Hermitian positive definite matrix given by an approximate
factorisation plus a low-rank matrix. Notably, the low-rank term is not
generally obtained as a truncated singular value decomposition. This framework
leads to a new truncation where principal directions are not based on the
magnitude of the singular values. We describe a procedure for determining these
\emph{Bregman directions} and prove that preconditioners constructed in this
way are minimisers of the aforementioned divergence. Finally, we demonstrate
using several numerical examples how the proposed preconditioner performs in
terms of convergence of the preconditioned conjugate gradient method (PCG). For
the examples we consider, an incomplete Cholesky preconditioner can be greatly
improved in this way, and in some cases only a modest low-rank compensation
term is required to obtain a considerable improvement in convergence. We also
consider matrices arising from interior point methods for linear programming
that do not admit such an incomplete factorisation by default, and present a
robust incomplete Cholesky preconditioner based on the proposed methodology.
The results highlight that the choice of truncation is critical for
ill-conditioned matrices. We show numerous examples where PCG converges to a
small tolerance by using the proposed preconditioner, whereas PCG with a
SVD-based preconditioner fails to do so.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06420" title="Abstract">arXiv:2312.06420</a> [<a href="/pdf/2312.06420" title="Download PDF">pdf</a>, <a href="/format/2312.06420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization Is All You Evaluate: Data Leakage in Online Mapping  Datasets and How to Fix It
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lilja%2C+A">Adam Lilja</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Junsheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Stenborg%2C+E">Erik Stenborg</a>, 
<a href="/search/cs?searchtype=author&query=Hammarstrand%2C+L">Lars Hammarstrand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data leakage is a critical issue when training and evaluating any method
based on supervised learning. The state-of-the-art methods for online mapping
are based on supervised learning and are trained predominantly using two
datasets: nuScenes and Argoverse 2. These datasets revisit the same geographic
locations across training, validation, and test sets. Specifically, over $80$%
of nuScenes and $40$% of Argoverse 2 validation and test samples are located
less than $5$ m from a training sample. This allows methods to localize within
a memorized implicit map during testing and leads to inflated performance
numbers being reported. To reveal the true performance in unseen environments,
we introduce geographical splits of the data. Experimental results show
significantly lower performance numbers, for some methods dropping with more
than $45$ mAP, when retraining and reevaluating existing online mapping models
with the proposed split. Additionally, a reassessment of prior design choices
reveals diverging conclusions from those based on the original split. Notably,
the impact of the lifting method and the support from auxiliary tasks (e.g.,
depth supervision) on performance appears less substantial or follows a
different trajectory than previously perceived. Geographical splits can be
found https://github.com/LiljaAdam/geographical-splits
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06422" title="Abstract">arXiv:2312.06422</a> [<a href="/pdf/2312.06422" title="Download PDF">pdf</a>, <a href="/ps/2312.06422" title="Download PostScript">ps</a>, <a href="/format/2312.06422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean field limits for discrete-time dynamical systems via kernel mean  embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fiedler%2C+C">Christian Fiedler</a>, 
<a href="/search/eess?searchtype=author&query=Herty%2C+M">Michael Herty</a>, 
<a href="/search/eess?searchtype=author&query=Trimpe%2C+S">Sebastian Trimpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Control Systems Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">Mean field limits are an important tool in the context of large-scale
dynamical systems, in particular, when studying multiagent and interacting
particle systems. While the continuous-time theory is well-developed, few works
have considered mean field limits for deterministic discrete-time systems,
which are relevant for the analysis and control of large-scale discrete-time
multiagent system. We prove existence results for the mean field limit of very
general discrete-time control systems, for which we utilize kernel mean
embeddings. These results are then applied in a typical optimal control setup,
where we establish the mean field limit of the relaxed dynamic programming
principle. Our results can serve as a rigorous foundation for many applications
of mean field approaches for discrete-time dynamical systems.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06423" title="Abstract">arXiv:2312.06423</a> [<a href="/pdf/2312.06423" title="Download PDF">pdf</a>, <a href="/format/2312.06423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MalPurifier: Enhancing Android Malware Detection with Adversarial  Purification against Evasion Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shui Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages; In submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) has gained significant adoption in Android malware
detection to address the escalating threats posed by the rapid proliferation of
malware attacks. However, recent studies have revealed the inherent
vulnerabilities of ML-based detection systems to evasion attacks. While efforts
have been made to address this critical issue, many of the existing defensive
methods encounter challenges such as lower effectiveness or reduced
generalization capabilities. In this paper, we introduce a novel Android
malware detection method, MalPurifier, which exploits adversarial purification
to eliminate perturbations independently, resulting in attack mitigation in a
light and flexible way. Specifically, MalPurifier employs a Denoising
AutoEncoder (DAE)-based purification model to preprocess input samples,
removing potential perturbations from them and then leading to correct
classification. To enhance defense effectiveness, we propose a diversified
adversarial perturbation mechanism that strengthens the purification model
against different manipulations from various evasion attacks. We also
incorporate randomized "protective noises" onto benign samples to prevent
excessive purification. Furthermore, we customize a loss function for improving
the DAE model, combining reconstruction loss and prediction loss, to enhance
feature representation learning, resulting in accurate reconstruction and
classification. Experimental results on two Android malware datasets
demonstrate that MalPurifier outperforms the state-of-the-art defenses, and it
significantly strengthens the vulnerable malware detector against 37 evasion
attacks, achieving accuracies over 90.91%. Notably, MalPurifier demonstrates
easy scalability to other detectors, offering flexibility and robustness in its
implementation.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06424" title="Abstract">arXiv:2312.06424</a> [<a href="/pdf/2312.06424" title="Download PDF">pdf</a>, <a href="/format/2312.06424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Domain LifeLong Sequential Modeling for Online Click-Through Rate  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Ruijie Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Y">Yu Ming</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhuobin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Q">Qinsong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) that incorporated lifelong sequential modeling
(LSM) have brought great success to recommendation systems in various social
media platforms. While continuous improvements have been made in
domain-specific LSM, limited work has been done in cross-domain LSM, which
considers modeling of lifelong sequences of both target domain and source
domain. In this paper, we propose Lifelong Cross Network (LCN) to incorporate
cross-domain LSM to improve the click-through rate (CTR) prediction in the
target domain. The proposed LCN contains a LifeLong Attention Pyramid (LAP)
module that comprises of three levels of cascaded attentions to effectively
extract interest representations with respect to the candidate item from
lifelong sequences. We also propose Cross Representation Production (CRP)
module to enforce additional supervision on the learning and alignment of
cross-domain representations so that they can be better reused on learning of
the CTR prediction in the target domain. We conducted extensive experiments on
WeChat Channels industrial dataset as well as on benchmark dataset. Results
have revealed that the proposed LCN outperforms existing work in terms of both
prediction accuracy and online performance.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06425" title="Abstract">arXiv:2312.06425</a> [<a href="/pdf/2312.06425" title="Download PDF">pdf</a>, <a href="/format/2312.06425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numeric Truncation Security Predicate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mezhuev%2C+T">Timofey Mezhuev</a>, 
<a href="/search/cs?searchtype=author&query=Kobrin%2C+I">Ilay Kobrin</a>, 
<a href="/search/cs?searchtype=author&query=Vishnyakov%2C+A">Alexey Vishnyakov</a>, 
<a href="/search/cs?searchtype=author&query=Kuts%2C+D">Daniil Kuts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Numeric truncation is a widely spread error in software written in languages
with static data typing, such as C/C++ or Java. It occurs when the significant
bits of the value with a bigger type size are truncated during value conversion
to the smaller type. Utilizing one of the most powerful methods for path
exploration and automated bug detection called dynamic symbolic execution
(DSE), we propose the symbolic security predicate for numeric truncation error
detection, developed on top of DSE tool Sydr. Firstly, we execute the program
on the data, which does not lead to any errors. During program execution we
update symbolic shadow stack and shadow registers to track symbolic sizes of
the symbolic variables to avoid false positives. Then, if we meet the
instruction, which truncates the symbolic variable, we build the security
predicate, try to solve it with the SMT-solver and in case of success save new
input file to reproduce the error. We tested our approach on Juliet Dynamic
test suite for CWE-197 and achieved 100% accuracy. We approved the workability
of our approach by detecting 12 new errors of numeric truncation in 5 different
real-world open source projects within OSS-Sydr-Fuzz project. All of the errors
were reported, most of the reports were equipped with appropriate fixes,
successfully confirmed and applied by project maintainers.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06428" title="Abstract">arXiv:2312.06428</a> [<a href="/pdf/2312.06428" title="Download PDF">pdf</a>, <a href="/format/2312.06428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisionTraj: A Noise-Robust Trajectory Recovery Framework based on  Large-scale Camera Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoru Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+G">Guoqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yunhao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Trajectory recovery based on the snapshots from the city-wide multi-camera
network facilitates urban mobility sensing and driveway optimization. The
state-of-the-art solutions devoted to such a vision-based scheme typically
incorporate predefined rules or unsupervised iterative feedback, struggling
with multi-fold challenges such as lack of open-source datasets for training
the whole pipeline, and the vulnerability to the noises from visual inputs. In
response to the dilemma, this paper proposes VisionTraj, the first
learning-based model that reconstructs vehicle trajectories from snapshots
recorded by road network cameras. Coupled with it, we elaborate on two rational
vision-trajectory datasets, which produce extensive trajectory data along with
corresponding visual snapshots, enabling supervised vision-trajectory interplay
extraction. Following the data creation, based on the results from the
off-the-shelf multi-modal vehicle clustering, we first re-formulate the
trajectory recovery problem as a generative task and introduce the canonical
Transformer as the autoregressive backbone. Then, to identify clustering noises
(e.g., false positives) with the bound on the snapshots' spatiotemporal
dependencies, a GCN-based soft-denoising module is conducted based on the fine-
and coarse-grained Re-ID clusters. Additionally, we harness strong semantic
information extracted from the tracklet to provide detailed insights into the
vehicle's entry and exit actions during trajectory recovery. The denoising and
tracklet components can also act as plug-and-play modules to boost baselines.
Experimental results on the two hand-crafted datasets show that the proposed
VisionTraj achieves a maximum +11.5% improvement against the sub-best model.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06432" title="Abstract">arXiv:2312.06432</a> [<a href="/pdf/2312.06432" title="Download PDF">pdf</a>, <a href="/format/2312.06432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internet of Federated Digital Twins (IoFDT): Connecting Twins Beyond  Borders for Society 5.0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongdian Li</a>, 
<a href="/search/cs?searchtype=author&query=Sakaguchi%2C+K">Kei Sakaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Hashash%2C+O">Omar Hashash</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The concept of digital twin (DT), which enables the creation of a
programmable, digital representation of physical systems, is expected to
revolutionize future industries and will lie at the heart of the vision of a
future smart society, namely, Society 5.0, in which high integration between
cyber (digital) and physical spaces is exploited to bring economic and societal
advancements. However, the success of such a DT-driven Society 5.0 requires a
synergistic convergence of artificial intelligence and networking technologies
into an integrated, programmable system that can coordinate networks of DTs to
effectively deliver diverse Society 5.0 services. Prior works remain restricted
to either qualitative study, simple analysis or software implementations of a
single DT, and thus, they cannot provide the highly synergistic integration of
digital and physical spaces as required by Society 5.0. In contrast, this paper
envisions a novel concept of an Internet of Federated Digital Twins (IoFDT)
that holistically integrates heterogeneous and physically separated DTs
representing different Society 5.0 services within a single framework and
system. For this concept of IoFDT, we first introduce a hierarchical
architecture that integrates federated DTs through horizontal and vertical
interactions, bridging the cyber and physical spaces to unlock new
possibilities. Then, we discuss the challenges of realizing IoFDT, highlighting
the intricacies across communication, computing, and AI-native networks while
also underscoring potential innovative solutions. Subsequently, we elaborate on
the importance of the implementation of a unified IoFDT platform that
integrates all technical components and orchestrates their interactions,
emphasizing the necessity of practical experimental platforms with a focus on
real-world applications in areas like smart mobility.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06436" title="Abstract">arXiv:2312.06436</a> [<a href="/pdf/2312.06436" title="Download PDF">pdf</a>, <a href="/format/2312.06436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Certification for Policy Smoothed Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+R">Ronghui Mu</a>, 
<a href="/search/cs?searchtype=author&query=Marcolino%2C+L+S">Leandro Soriano Marcolino</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+W">Wenjie Ruan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement Learning (RL) has achieved remarkable success in
safety-critical areas, but it can be weakened by adversarial attacks. Recent
studies have introduced "smoothed policies" in order to enhance its robustness.
Yet, it is still challenging to establish a provable guarantee to certify the
bound of its total reward. Prior methods relied primarily on computing bounds
using Lipschitz continuity or calculating the probability of cumulative reward
above specific thresholds. However, these techniques are only suited for
continuous perturbations on the RL agent's observations and are restricted to
perturbations bounded by the l_2-norm. To address these limitations, this paper
proposes a general black-box certification method capable of directly
certifying the cumulative reward of the smoothed policy under various
$l_p$-norm bounded perturbations. Furthermore, we extend our methodology to
certify perturbations on action spaces. Our approach leverages f-divergence to
measure the distinction between the original distribution and the perturbed
distribution, subsequently determining the certification bound by solving a
convex optimisation problem. We provide a comprehensive theoretical analysis
and run sufficient experiments in multiple environments. Our results show that
our method not only improves the certified lower bound of mean cumulative
reward but also demonstrates better efficiency than state-of-the-art
techniques.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06439" title="Abstract">arXiv:2312.06439</a> [<a href="/pdf/2312.06439" title="Download PDF">pdf</a>, <a href="/format/2312.06439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamControl: Control-Based Text-to-3D Generation with 3D Self-Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W. H. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D generation has raised great attention in recent years. With the success of
text-to-image diffusion models, the 2D-lifting technique becomes a promising
route to controllable 3D generation. However, these methods tend to present
inconsistent geometry, which is also known as the Janus problem. We observe
that the problem is caused mainly by two aspects, i.e., viewpoint bias in 2D
diffusion models and overfitting of the optimization objective. To address it,
we propose a two-stage 2D-lifting framework, namely DreamControl, which
optimizes coarse NeRF scenes as 3D self-prior and then generates fine-grained
objects with control-based score distillation. Specifically, adaptive viewpoint
sampling and boundary integrity metric are proposed to ensure the consistency
of generated priors. The priors are then regarded as input conditions to
maintain reasonable geometries, in which conditional LoRA and weighted score
are further proposed to optimize detailed textures. DreamControl can generate
high-quality 3D content in terms of both geometry consistency and texture
fidelity. Moreover, our control-based optimization guidance is applicable to
more downstream tasks, including user-guided generation and 3D animation. The
project page is available at https://github.com/tyhuang0428/DreamControl.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06440" title="Abstract">arXiv:2312.06440</a> [<a href="/pdf/2312.06440" title="Download PDF">pdf</a>, <a href="/format/2312.06440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards A Flexible Accuracy-Oriented Deep Learning Module Inference  Latency Prediction Framework for Adaptive Optimization Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jingran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tziritas%2C+N">Nikos Tziritas</a>, 
<a href="/search/cs?searchtype=author&query=Theodoropoulos%2C+G">Georgios Theodoropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
<p class="mathjax">With the rapid development of Deep Learning, more and more applications on
the cloud and edge tend to utilize large DNN (Deep Neural Network) models for
improved task execution efficiency as well as decision-making quality. Due to
memory constraints, models are commonly optimized using compression, pruning,
and partitioning algorithms to become deployable onto resource-constrained
devices. As the conditions in the computational platform change dynamically,
the deployed optimization algorithms should accordingly adapt their solutions.
To perform frequent evaluations of these solutions in a timely fashion, RMs
(Regression Models) are commonly trained to predict the relevant solution
quality metrics, such as the resulted DNN module inference latency, which is
the focus of this paper. Existing prediction frameworks specify different RM
training workflows, but none of them allow flexible configurations of the input
parameters (e.g., batch size, device utilization rate) and of the selected RMs
for different modules. In this paper, a deep learning module inference latency
prediction framework is proposed, which i) hosts a set of customizable input
parameters to train multiple different RMs per DNN module (e.g., convolutional
layer) with self-generated datasets, and ii) automatically selects a set of
trained RMs leading to the highest possible overall prediction accuracy, while
keeping the prediction time / space consumption as low as possible.
Furthermore, a new RM, namely MEDN (Multi-task Encoder-Decoder Network), is
proposed as an alternative solution. Comprehensive experiment results show that
MEDN is fast and lightweight, and capable of achieving the highest overall
prediction accuracy and R-squared value. The Time/Space-efficient
Auto-selection algorithm also manages to improve the overall accuracy by 2.5%
and R-squared by 0.39%, compared to the MEDN single-selection scheme.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06441" title="Abstract">arXiv:2312.06441</a> [<a href="/pdf/2312.06441" title="Download PDF">pdf</a>, <a href="/format/2312.06441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Graph-based Fraud Detection in Sight of Heterophily and  Spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xuezhi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph-based fraud detection (GFD) can be regarded as a challenging
semi-supervised node binary classification task. In recent years, Graph Neural
Networks(GNN) have been widely applied to GFD, characterizing the anomalous
possibility of a node by aggregating neighbor information. However, fraud
graphs are inherently heterophilic, thus most of GNNs perform poorly due to
their assumption of homophily. In addition, due to the existence of heterophily
and class imbalance problem, the existing models do not fully utilize the
precious node label information. To address the above issues, this paper
proposes a semi-supervised GNN-based fraud detector SEC-GFD. This detector
includes a hybrid filtering module and a local environmental constraint module,
the two modules are utilized to solve heterophily and label utilization problem
respectively. The first module starts from the perspective of the spectral
domain, and solves the heterophily problem to a certain extent. Specifically,
it divides the spectrum into multiple mixed frequency bands according to the
correlation between spectrum energy distribution and heterophily. Then in order
to make full use of the node label information, a local environmental
constraint module is adaptively designed. The comprehensive experimental
results on four real-world fraud detection datasets show that SEC-GFD
outperforms other competitive graph-based fraud detectors.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06443" title="Abstract">arXiv:2312.06443</a> [<a href="/pdf/2312.06443" title="Download PDF">pdf</a>, <a href="/ps/2312.06443" title="Download PostScript">ps</a>, <a href="/format/2312.06443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Leximin Principle for Fair Core-Selecting Combinatorial  Auctions: Payment Rule Design and Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shufeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yanchen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Caihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaohu Wu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongjun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Core-selecting combinatorial auctions (CAs) restrict the auction result in
the core such that no coalitions could improve their utilities by engaging in
collusion. The minimum-revenue-core (MRC) rule is a widely used core-selecting
payment rule to maximize the total utilities of all bidders. However, the MRC
rule can suffer from severe unfairness since it ignores individuals' utilities.
To address this limitation, we propose to explore the leximin principle to
achieve fairness in core-selecting CAs since the leximin principle prefers to
maximize the utility of the worst-off; the resulting bidder-leximin-optimal
(BLO) payment rule is then theoretically analyzed and an effective algorithm is
further provided to compute the BLO outcome. Moreover, we conduct extensive
experiments to show that our algorithm returns fairer utility distributions and
is faster than existing algorithms of core-selecting payment rules.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06445" title="Abstract">arXiv:2312.06445</a> [<a href="/pdf/2312.06445" title="Download PDF">pdf</a>, <a href="/format/2312.06445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Naming Scheme for Thermo-Active Soft Actuators: A  Review of Materials, Working Principles, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Exley%2C+T">Trevor Exley</a>, 
<a href="/search/cs?searchtype=author&query=Hays%2C+E">Emilly Hays</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+D">Daniel Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Moridani%2C+A">Arian Moridani</a>, 
<a href="/search/cs?searchtype=author&query=Motati%2C+R">Ramya Motati</a>, 
<a href="/search/cs?searchtype=author&query=Jafari%2C+A">Amir Jafari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, accepted to Robotics Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Soft robotics is a rapidly growing field that spans the fields of chemistry,
materials science, and engineering. Due to the diverse background of the field,
there have been contrasting naming schemes such as 'intelligent', 'smart' and
'adaptive' materials which add vagueness to the broad innovation among
literature. Therefore, a clear, functional and descriptive naming scheme is
proposed in which a previously vague name -- Soft Material for Soft Actuators
-- can remain clear and concise -- Phase-Change Elastomers for Artificial
Muscles. By synthesizing the working principle, material, and application into
a naming scheme, the searchability of soft robotics can be enhanced and applied
to other fields. The field of thermo-active soft actuators spans multiple
domains and requires added clarity. Thermo-active actuators have potential for
a variety of applications spanning virtual reality haptics to assistive
devices. This review offers a comprehensive guide to selecting the type of
thermo-active actuator when one has an application in mind. Additionally, it
discusses future directions and improvements that are necessary for
implementation.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06446" title="Abstract">arXiv:2312.06446</a> [<a href="/pdf/2312.06446" title="Download PDF">pdf</a>, <a href="/format/2312.06446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental demonstration of a robust training method for strongly  defective neuromorphic hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borders%2C+W+A">William A. Borders</a>, 
<a href="/search/cs?searchtype=author&query=Madhavan%2C+A">Advait Madhavan</a>, 
<a href="/search/cs?searchtype=author&query=Daniels%2C+M+W">Matthew W. Daniels</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+V">Vasileia Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Lueker-Boden%2C+M">Martin Lueker-Boden</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+T+S">Tiffany S. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Braganca%2C+P+M">Patrick M. Braganca</a>, 
<a href="/search/cs?searchtype=author&query=Stiles%2C+M+D">Mark D. Stiles</a>, 
<a href="/search/cs?searchtype=author&query=McClelland%2C+J+J">Jabez J. McClelland</a>, 
<a href="/search/cs?searchtype=author&query=Hoskins%2C+B+D">Brian D. Hoskins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">The increasing scale of neural networks needed to support more complex
applications has led to an increasing requirement for area- and
energy-efficient hardware. One route to meeting the budget for these
applications is to circumvent the von Neumann bottleneck by performing
computation in or near memory. An inevitability of transferring neural networks
onto hardware is that non-idealities such as device-to-device variations or
poor device yield impact performance. Methods such as hardware-aware training,
where substrate non-idealities are incorporated during network training, are
one way to recover performance at the cost of solution generality. In this
work, we demonstrate inference on hardware neural networks consisting of 20,000
magnetic tunnel junction arrays integrated on a complementary
metal-oxide-semiconductor chips that closely resembles market-ready spin
transfer-torque magnetoresistive random access memory technology. Using 36
dies, each containing a crossbar array with its own non-idealities, we show
that even a small number of defects in physically mapped networks significantly
degrades the performance of networks trained without defects and show that, at
the cost of generality, hardware-aware training accounting for specific defects
on each die can recover to comparable performance with ideal networks. We then
demonstrate a robust training method that extends hardware-aware training to
statistics-aware training, producing network weights that perform well on most
defective dies regardless of their specific defect locations. When evaluated on
the 36 physical dies, statistics-aware trained solutions can achieve a mean
misclassification error on the MNIST dataset that differs from the
software-baseline by only 2 %. This statistics-aware training method could be
generalized to networks with many layers that are mapped to hardware suited for
industry-ready applications.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06448" title="Abstract">arXiv:2312.06448</a> [<a href="/pdf/2312.06448" title="Download PDF">pdf</a>, <a href="/format/2312.06448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Publishing Strategies on a Base Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bar-On%2C+Y">Yogev Bar-On</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+Y">Yishay Mansour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at Financial Cryptography and Data Security 2024 (FC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">A growing number of products use layer 2 solutions to expand the capabilities
of primary blockchains like Ethereum, where computation is off-loaded from the
root chain, and the results are published to it in bulk. Those include
optimistic and zero-knowledge rollups, information oracles, and app-specific
chains. This work presents an analysis of layer 2 blockchain strategies
determining the optimal times for publishing transactions on the root chain.
There is a trade-off between waiting for a better layer 1 gas price and the
urgency to finalize layer 2 transactions. We present a model for the problem
that captures this trade-off, generalizing previous works, and we analyze the
properties of optimal publishing strategies. We show that such optimal
strategies hold a computable simple form for a large class of cost functions.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06453" title="Abstract">arXiv:2312.06453</a> [<a href="/pdf/2312.06453" title="Download PDF">pdf</a>, <a href="/format/2312.06453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Image Synthesis for Abdominal CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+B">Benjamin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Mathai%2C+T+S">Tejas Sudharshan Mathai</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+P">Pritam Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Boah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at Deep Generative Models workshop at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">As a new emerging and promising type of generative models, diffusion models
have proven to outperform Generative Adversarial Networks (GANs) in multiple
tasks, including image synthesis. In this work, we explore semantic image
synthesis for abdominal CT using conditional diffusion models, which can be
used for downstream applications such as data augmentation. We systematically
evaluated the performance of three diffusion models, as well as to other
state-of-the-art GAN-based approaches, and studied the different conditioning
scenarios for the semantic mask. Experimental results demonstrated that
diffusion models were able to synthesize abdominal CT images with better
quality. Additionally, encoding the mask and the input separately is more
effective than na\"ive concatenating.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06455" title="Abstract">arXiv:2312.06455</a> [<a href="/pdf/2312.06455" title="Download PDF">pdf</a>, <a href="/ps/2312.06455" title="Download PostScript">ps</a>, <a href="/format/2312.06455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ownership Types for Verification of Programs with Pointer Arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+I">Izumi Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Sakayori%2C+K">Ken Sakayori</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+N">Naoki Kobayashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended version of the paper to appear in Proceedings of PEPM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Toman et al. have proposed a type system for automatic verification of
low-level programs, which combines ownership types and refinement types to
enable strong updates of refinement types in the presence of pointer aliases.
We extend their type system to support pointer arithmetic, and prove its
soundness. Based on the proposed type system, we have implemented a prototype
tool for automated verification of the lack of assertion errors of low-level
programs with pointer arithmetic, and confirmed its effectiveness through
experiments.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06457" title="Abstract">arXiv:2312.06457</a> [<a href="/pdf/2312.06457" title="Download PDF">pdf</a>, <a href="/format/2312.06457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models with Retrieval-Augmented Generation for Zero-Shot  Disease Phenotyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thompson%2C+W+E">Will E. Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Vidmar%2C+D+M">David M. Vidmar</a>, 
<a href="/search/cs?searchtype=author&query=De+Freitas%2C+J+K">Jessica K. De Freitas</a>, 
<a href="/search/cs?searchtype=author&query=Pfeifer%2C+J+M">John M. Pfeifer</a>, 
<a href="/search/cs?searchtype=author&query=Fornwalt%2C+B+K">Brandon K. Fornwalt</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Altay%2C+G">Gabriel Altay</a>, 
<a href="/search/cs?searchtype=author&query=Manghnani%2C+K">Kabir Manghnani</a>, 
<a href="/search/cs?searchtype=author&query=Nelsen%2C+A+C">Andrew C. Nelsen</a>, 
<a href="/search/cs?searchtype=author&query=Morland%2C+K">Kellie Morland</a>, 
<a href="/search/cs?searchtype=author&query=Stumpe%2C+M+C">Martin C. Stumpe</a>, 
<a href="/search/cs?searchtype=author&query=Miotto%2C+R">Riccardo Miotto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Deep Generative Models for Health Workshop NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Identifying disease phenotypes from electronic health records (EHRs) is
critical for numerous secondary uses. Manually encoding physician knowledge
into rules is particularly challenging for rare diseases due to inadequate EHR
coding, necessitating review of clinical notes. Large language models (LLMs)
offer promise in text understanding but may not efficiently handle real-world
clinical documentation. We propose a zero-shot LLM-based method enriched by
retrieval-augmented generation and MapReduce, which pre-identifies
disease-related text snippets to be used in parallel as queries for the LLM to
establish diagnosis. We show that this method as applied to pulmonary
hypertension (PH), a rare disease characterized by elevated arterial pressures
in the lungs, significantly outperforms physician logic rules ($F_1$ score of
0.62 vs. 0.75). This method has the potential to enhance rare disease cohort
identification, expanding the scope of robust clinical research and care gap
identification.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06458" title="Abstract">arXiv:2312.06458</a> [<a href="/pdf/2312.06458" title="Download PDF">pdf</a>, <a href="/ps/2312.06458" title="Download PostScript">ps</a>, <a href="/format/2312.06458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASF-YOLO: A Novel YOLO Model with Attentional Scale Sequence Fusion for  Cell Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Ming Kang</a>, 
<a href="/search/cs?searchtype=author&query=Ting%2C+C">Chee-Ming Ting</a>, 
<a href="/search/cs?searchtype=author&query=Ting%2C+F+F">Fung Fung Ting</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+R+C+-">Rapha&#xeb;l C.-W. Phan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP); Applications (stat.AP)

</div>
<p class="mathjax">We propose a novel Attentional Scale Sequence Fusion based You Only Look Once
(YOLO) framework (ASF-YOLO) which combines spatial and scale features for
accurate and fast cell instance segmentation. Built on the YOLO segmentation
framework, we employ the Scale Sequence Feature Fusion (SSFF) module to enhance
the multi-scale information extraction capability of the network, and the
Triple Feature Encoder (TPE) module to fuse feature maps of different scales to
increase detailed information. We further introduce a Channel and Position
Attention Mechanism (CPAM) to integrate both the SSFF and TPE modules, which
focus on informative channels and spatial position-related small objects for
improved detection and segmentation performance. Experimental validations on
two cell datasets show remarkable segmentation accuracy and speed of the
proposed ASF-YOLO model. It achieves a box mAP of 0.91, mask mAP of 0.887, and
an inference speed of 47.3 FPS on the 2018 Data Science Bowl dataset,
outperforming the state-of-the-art methods. The source code is available at
https://github.com/mkang315/ASF-YOLO.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06460" title="Abstract">arXiv:2312.06460</a> [<a href="/pdf/2312.06460" title="Download PDF">pdf</a>, <a href="/format/2312.06460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Kalman Inversion for Image Guided Guide Wire Navigation in  Vascular Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hanu%2C+M">Matei Hanu</a>, 
<a href="/search/math?searchtype=author&query=Hesser%2C+J">J&#xfc;rgen Hesser</a>, 
<a href="/search/math?searchtype=author&query=Kanschat%2C+G">Guido Kanschat</a>, 
<a href="/search/math?searchtype=author&query=Moviglia%2C+J">Javier Moviglia</a>, 
<a href="/search/math?searchtype=author&query=Schillings%2C+C">Claudia Schillings</a>, 
<a href="/search/math?searchtype=author&query=Stallkamp%2C+J">Jan Stallkamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper addresses the challenging task of guide wire navigation in
cardiovascular interventions, focusing on the parameter estimation of a guide
wire system using Ensemble Kalman Inversion (EKI) with a subsampling technique.
The EKI uses an ensemble of particles to estimate the unknown quantities.
However since the data misfit has to be computed for each particle in each
iteration, the EKI may become computationally infeasible in the case of
high-dimensional data, e.g. high-resolution images. This issue can been
addressed by randomised algorithms that utilize only a random subset of the
data in each iteration. We introduce and analyse a subsampling technique for
the EKI, which is based on a continuous-time representation of stochastic
gradient methods and apply it to on the parameter estimation of our guide wire
system. Numerical experiments with real data from a simplified test setting
demonstrate the potential of the method.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06462" title="Abstract">arXiv:2312.06462</a> [<a href="/pdf/2312.06462" title="Download PDF">pdf</a>, <a href="/format/2312.06462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for  Audio-Visual Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+X">Xing Nie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengfei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Ying Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+C">Cheng Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pengfei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Shiming Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, an audio-visual segmentation (AVS) task has been introduced, aiming
to group pixels with sounding objects within a given video. This task
necessitates a first-ever audio-driven pixel-level understanding of the scene,
posing significant challenges. In this paper, we propose an innovative
audio-visual transformer framework, termed COMBO, an acronym for COoperation of
Multi-order Bilateral relatiOns. For the first time, our framework explores
three types of bilateral entanglements within AVS: pixel entanglement, modality
entanglement, and temporal entanglement. Regarding pixel entanglement, we
employ a Siam-Encoder Module (SEM) that leverages prior knowledge to generate
more precise visual features from the foundational model. For modality
entanglement, we design a Bilateral-Fusion Module (BFM), enabling COMBO to
align corresponding visual and auditory signals bi-directionally. As for
temporal entanglement, we introduce an innovative adaptive inter-frame
consistency loss according to the inherent rules of temporal. Comprehensive
experiments and ablation studies on AVSBench-object (84.7 mIoU on S4, 59.2 mIou
on MS3) and AVSBench-semantic (42.1 mIoU on AVSS) datasets demonstrate that
COMBO surpasses previous state-of-the-art methods. Code and more results will
be publicly available at https://combo-avs.github.io/.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06466" title="Abstract">arXiv:2312.06466</a> [<a href="/pdf/2312.06466" title="Download PDF">pdf</a>, <a href="/format/2312.06466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Domain-Specific Cross-Corpus Speech Emotion Recognition Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yuan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+H">Hailun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jingang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenming Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Cross-corpus speech emotion recognition (SER) poses a challenge due to
feature distribution mismatch, potentially degrading the performance of
established SER methods. In this paper, we tackle this challenge by proposing a
novel transfer subspace learning method called acoustic knowledgeguided
transfer linear regression (AKTLR). Unlike existing approaches, which often
overlook domain-specific knowledge related to SER and simply treat cross-corpus
SER as a generic transfer learning task, our AKTLR method is built upon a
well-designed acoustic knowledge-guided dual sparsity constraint mechanism.
This mechanism emphasizes the potential of minimalistic acoustic parameter
feature sets to alleviate classifier overadaptation, which is empirically
validated acoustic knowledge in SER, enabling superior generalization in
cross-corpus SER tasks compared to using large feature sets. Through this
mechanism, we extend a simple transfer linear regression model to AKTLR. This
extension harnesses its full capability to seek emotiondiscriminative and
corpus-invariant features from established acoustic parameter feature sets used
for describing speech signals across two scales: contributive acoustic
parameter groups and constituent elements within each contributive group. Our
proposed method is evaluated through extensive cross-corpus SER experiments on
three widely-used speech emotion corpora: EmoDB, eNTERFACE, and CASIA. The
results confirm the effectiveness and superior performance of our method,
outperforming recent state-of-the-art transfer subspace learning and deep
transfer learning-based cross-corpus SER methods. Furthermore, our work
provides experimental evidence supporting the feasibility and superiority of
incorporating domain-specific knowledge into the transfer learning model to
address cross-corpus SER tasks.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06467" title="Abstract">arXiv:2312.06467</a> [<a href="/pdf/2312.06467" title="Download PDF">pdf</a>, <a href="/format/2312.06467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning brain functions boosts the decoding of visual semantics in  novel subjects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thual%2C+A">Alexis Thual</a>, 
<a href="/search/cs?searchtype=author&query=Benchetrit%2C+Y">Yohann Benchetrit</a>, 
<a href="/search/cs?searchtype=author&query=Geilert%2C+F">Felix Geilert</a>, 
<a href="/search/cs?searchtype=author&query=Rapin%2C+J">J&#xe9;r&#xe9;my Rapin</a>, 
<a href="/search/cs?searchtype=author&query=Makarov%2C+I">Iurii Makarov</a>, 
<a href="/search/cs?searchtype=author&query=Banville%2C+H">Hubert Banville</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+J">Jean-R&#xe9;mi King</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Deep learning is leading to major advances in the realm of brain decoding
from functional Magnetic Resonance Imaging (fMRI). However, the large
inter-subject variability in brain characteristics has limited most studies to
train models on one subject at a time. Consequently, this approach hampers the
training of deep learning models, which typically requires very large datasets.
Here, we propose to boost brain decoding by aligning brain responses to videos
and static images across subjects. Compared to the anatomically-aligned
baseline, our method improves out-of-subject decoding performance by up to 75%.
Moreover, it also outperforms classical single-subject approaches when fewer
than 100 minutes of data is available for the tested subject. Furthermore, we
propose a new multi-subject alignment method, which obtains comparable results
to that of classical single-subject approaches while improving out-of-subject
generalization. Finally, we show that this method aligns neural representations
in accordance with brain anatomy. Overall, this study lays the foundations for
leveraging extensive neuroimaging datasets and enhancing the decoding of
individuals with a limited amount of brain recordings.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06471" title="Abstract">arXiv:2312.06471</a> [<a href="/pdf/2312.06471" title="Download PDF">pdf</a>, <a href="/ps/2312.06471" title="Download PostScript">ps</a>, <a href="/format/2312.06471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A priori Belief Updates as a Method for Agent Self-Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cignarale%2C+G">Giorgio Cignarale</a>, 
<a href="/search/cs?searchtype=author&query=Kuznets%2C+R">Roman Kuznets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Standard epistemic logic is concerned with describing agents' epistemic
attitudes given the current set of alternatives the agents consider possible.
While distributed systems can (and often are) discussed without mentioning
epistemics, it has been well established that epistemic phenomena lie at the
heart of what agents, or processes, can and cannot do. Dynamic epistemic logic
(DEL) aims to describe how epistemic attitudes of the agents/processes change
based on the new information they receive, e.g., based on their observations of
events and actions in a distributed system. In a broader philosophical view,
this appeals to an a posteriori kind of reasoning, where agents update the set
of alternatives considered possible based on their "experiences."
<br />Until recently, there was little incentive to formalize a priori reasoning,
which plays a role in designing and maintaining distributed systems, e.g., in
determining which states must be considered possible by agents in order to
solve the distributed task at hand, and consequently in updating these states
when unforeseen situations arise during runtime. With systems becoming more and
more complex and large, the task of fixing design errors "on the fly" is
shifted to individual agents, such as in the increasingly popular self-adaptive
and self-organizing (SASO) systems. Rather than updating agents' a posteriori
beliefs, this requires modifying their a priori beliefs about the system's
global design and parameters.
<br />The goal of this paper is to provide a formalization of such a priori
reasoning by using standard epistemic semantic tools, including Kripke models
and DEL-style updates, and provide heuristics that would pave the way to
streamlining this inherently non-deterministic and ad hoc process for SASO
systems.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06472" title="Abstract">arXiv:2312.06472</a> [<a href="/pdf/2312.06472" title="Download PDF">pdf</a>, <a href="/format/2312.06472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissipativity-Based Decentralized Co-Design of Distributed Controllers  and Communication Topologies for Vehicular Platoons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Welikala%2C+S">Shirantha Welikala</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zihao Song</a>, 
<a href="/search/eess?searchtype=author&query=Antsaklis%2C+P+J">Panos J. Antsaklis</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures, one manuscript has been submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Vehicular platoons provide an appealing option for future transportation
systems. Most of the existing work on platoons separated the design of the
controller and its communication topologies. However, it is beneficial to
design both the platooning controller and the communication topology
simultaneously, i.e., controller and topology co-design, especially in the
cases of platoon splitting and merging. We are, therefore, motivated to propose
a co-design framework for vehicular platoons that maintains both the
compositionality of the controller and the string stability of the platoon,
which enables the merging and splitting of the vehicles in a platoon.To this
end, we first formulate the co-design problem as a centralized linear matrix
inequality (LMI) problem and then decompose it using Sylvester's criterion to
obtain a set of smaller decentralized LMI problems that can be solved
sequentially at individual vehicles in the platoon. Moreover, in the formulated
decentralized LMI problems, we encode a specifically derived local LMI to
enforce the $L_2$ stability of the closed-loop platooning system, further
implying the $L_2$ weak string stability of the vehicular platoon. Besides, by
providing extra constraints on the control parameters, the disturbance string
stability is formally guaranteed. Finally, to validate the proposed co-design
method and its features in terms of merging/splitting, we provide an extensive
collection of simulation results generated from a specifically developed
simulation framework. Available in GitHub:
<a href="HTTP://github.com/NDzsong2/Longitudinal-Vehicular-Platoon-Simulator.git">this HTTP URL</a> that we
have made publicly available.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06474" title="Abstract">arXiv:2312.06474</a> [<a href="/pdf/2312.06474" title="Download PDF">pdf</a>, <a href="/format/2312.06474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xiaoyi Bao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jie Qin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Siyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For few-shot semantic segmentation, the primary task is to extract
class-specific intrinsic information from limited labeled data. However, the
semantic ambiguity and inter-class similarity of previous methods limit the
accuracy of pixel-level foreground-background classification. To alleviate
these issues, we propose the Relevant Intrinsic Feature Enhancement Network
(RiFeNet). To improve the semantic consistency of foreground instances, we
propose an unlabeled branch as an efficient data utilization method, which
teaches the model how to extract intrinsic features robust to intra-class
differences. Notably, during testing, the proposed unlabeled branch is excluded
without extra unlabeled data and computation. Furthermore, we extend the
inter-class variability between foreground and background by proposing a novel
multi-level prototype generation and interaction module. The different-grained
complementarity between global and local prototypes allows for better
distinction between similar categories. The qualitative and quantitative
performance of RiFeNet surpasses the state-of-the-art methods on PASCAL-5i and
COCO benchmarks.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06475" title="Abstract">arXiv:2312.06475</a> [<a href="/pdf/2312.06475" title="Download PDF">pdf</a>, <a href="/format/2312.06475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NetROS-5G: Enhancing Personalization through 5G Network Slicing and Edge  Computing in Human-Robot Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalgkitsis%2C+A">Anestis Dalgkitsis</a>, 
<a href="/search/cs?searchtype=author&query=Verikoukis%2C+C">Christos Verikoukis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robots are increasingly being used in a variety of applications, from
manufacturing and healthcare to education and customer service. However, the
mobility, power, and price points of these robots often dictate that they do
not have sufficient computing power on board to run modern algorithms for
personalization in human-robot interaction at desired rates. This can limit the
effectiveness of the interaction and limit the potential applications for these
robots. 5G connectivity provides a solution to this problem by offering high
data rates, bandwidth, and low latency that can facilitate robotics services.
Additionally, the widespread availability of cloud computing has made it easy
to access almost unlimited computing power at a low cost. Edge computing, which
involves placing compute resources closer to the action, can offer even lower
latency than cloud computing. In this paper, we explore the potential of
combining 5G, edge, and cloud computing to provide improved personalization in
human-robot interaction. We design, develop, and demonstrate a new framework,
entitled NetROS-5G, to show how the performance gained by utilizing these
technologies can overcome network latency and significantly enhance
personalization in robotics. Our results show that the integration of 5G
network slicing, edge computing, and cloud computing can collectively offer a
cost-efficient and superior level of personalization in a modern human-robot
interaction scenario.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06481" title="Abstract">arXiv:2312.06481</a> [<a href="/pdf/2312.06481" title="Download PDF">pdf</a>, <a href="/format/2312.06481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the perception of the personalized activities with CloudIA  robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorrentino%2C+A">Alessandra Sorrentino</a>, 
<a href="/search/cs?searchtype=author&query=Fiorini%2C+L">Laura Fiorini</a>, 
<a href="/search/cs?searchtype=author&query=La+Viola%2C+C">Carlo La Viola</a>, 
<a href="/search/cs?searchtype=author&query=Cavallo%2C+F">Filippo Cavallo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Socially Assistive Robots represent a valid solution for improving the
quality of life and the mood of older adults. In this context, this work
presents the CloudIA robot, a non-human-like robot intended to promote
sociality and well-being among older adults. The design of the robot and of the
provided services were carried out by a multidisciplinary team of designers and
technology developers in tandem with professional caregivers. The capabilities
of the robot were implemented according to the received guidelines and tested
in two nursing facilities by 15 older people. Qualitative and quantitative
metrics were used to investigate the engagement of the participants during the
interaction with the robot, and to investigate any differences in the
interaction during the proposed activities. The results highlighted the general
tendency of humanizing the robotic platform and demonstrated the feasibility of
introducing the CloudIA robot in support of the professional caregivers' work.
From this pilot test, further ideas on improving the personalization of the
robotic platform emerged.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06486" title="Abstract">arXiv:2312.06486</a> [<a href="/pdf/2312.06486" title="Download PDF">pdf</a>, <a href="/format/2312.06486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STDiff: Spatio-temporal Diffusion for Continuous Stochastic Video  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Bilodeau%2C+G">Guillaume-Alexandre Bilodeau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Predicting future frames of a video is challenging because it is difficult to
learn the uncertainty of the underlying factors influencing their contents. In
this paper, we propose a novel video prediction model, which has
infinite-dimensional latent variables over the spatio-temporal domain.
Specifically, we first decompose the video motion and content information, then
take a neural stochastic differential equation to predict the temporal motion
information, and finally, an image diffusion model autoregressively generates
the video frame by conditioning on the predicted motion feature and the
previous frame. The better expressiveness and stronger stochasticity learning
capability of our model lead to state-of-the-art video prediction performances.
As well, our model is able to achieve temporal continuous prediction, i.e.,
predicting in an unsupervised way the future video frames with an arbitrarily
high frame rate. Our code is available at
\url{https://github.com/XiYe20/STDiffProject}.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06488" title="Abstract">arXiv:2312.06488</a> [<a href="/pdf/2312.06488" title="Download PDF">pdf</a>, <a href="/format/2312.06488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance-lossless Black-box Model Watermarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Na Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the development of deep learning, high-value and high-cost models have
become valuable assets, and related intellectual property protection
technologies have become a hot topic. However, existing model watermarking work
in black-box scenarios mainly originates from training-based backdoor methods,
which probably degrade original task performance. To address this, we propose a
branch backdoor-based model watermarking protocol to protect model intellectual
property, where a construction based on a message authentication scheme is
adopted as the branch indicator. We prove the lossless performance of the
protocol by reduction. Taking the language generation task as an instance, we
show the effectiveness of the proposed protocol.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06490" title="Abstract">arXiv:2312.06490</a> [<a href="/pdf/2312.06490" title="Download PDF">pdf</a>, <a href="/format/2312.06490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Planning Techniques for Elementary Proofs in Abstract Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrov%2C+A">Alice Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Muise%2C+C">Christian Muise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Automated Planning Techniques for Elementary Proofs in Abstract Algebra. Petrov, A. &amp; Muise, C. In Scheduling and Planning Applications woRKshop. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper explores the application of automated planning to automated
theorem proving, which is a branch of automated reasoning concerned with the
development of algorithms and computer programs to construct mathematical
proofs. In particular, we investigate the use of planning to construct
elementary proofs in abstract algebra, which provides a rigorous and axiomatic
framework for studying algebraic structures such as groups, rings, fields, and
modules. We implement basic implications, equalities, and rules in both
deterministic and non-deterministic domains to model commutative rings and
deduce elementary results about them. The success of this initial
implementation suggests that the well-established techniques seen in automated
planning are applicable to the relatively newer field of automated theorem
proving. Likewise, automated theorem proving provides a new, challenging domain
for automated planning.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06495" title="Abstract">arXiv:2312.06495</a> [<a href="/pdf/2312.06495" title="Download PDF">pdf</a>, <a href="/format/2312.06495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Events in Crowds Through Changes in Geometrical Dimensions of  Pedestrians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+M+S+H">Matheus Schreiner Homrich da Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza+Pinto+Neto%2C+P+B">Paulo Brossard de Souza Pinto Neto</a>, 
<a href="/search/cs?searchtype=author&query=Favaretto%2C+R+M">Rodolfo Migon Favaretto</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S+R">Soraia Raupp Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SBGames 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Security is an important topic in our contemporary world, and the ability to
automate the detection of any events of interest that can take place in a crowd
is of great interest to a population. We hypothesize that the detection of
events in videos is correlated with significant changes in pedestrian
behaviors. In this paper, we examine three different scenarios of crowd
behavior, containing both the cases where an event triggers a change in the
behavior of the crowd and two video sequences where the crowd and its motion
remain mostly unchanged. With both the videos and the tracking of the
individual pedestrians (performed in a pre-processed phase), we use Geomind, a
software we developed to extract significant data about the scene, in
particular, the geometrical features, personalities, and emotions of each
person. We then examine the output, seeking a significant change in the way
each person acts as a function of the time, that could be used as a basis to
identify events or to model realistic crowd actions. When applied to the games
area, our method can use the detected events to find some sort of pattern to be
then used in agent simulation. Results indicate that our hypothesis seems valid
in the sense that the visually observed events could be automatically detected
using GeoMind.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06498" title="Abstract">arXiv:2312.06498</a> [<a href="/pdf/2312.06498" title="Download PDF">pdf</a>, <a href="/format/2312.06498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainability through Optimal Design of Buildings for Natural  Ventilation using Updated Comfort and Occupancy Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jihoon Chung</a>, 
<a href="/search/cs?searchtype=author&query=Shahmansouri%2C+N">Nastaran Shahmansouri</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+R">Rhys Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Stoddart%2C+J">James Stoddart</a>, 
<a href="/search/cs?searchtype=author&query=Locke%2C+J">John Locke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper explores the benefits of incorporating natural ventilation (NV)
simulation into a generative process of designing residential buildings to
improve energy efficiency and indoor thermal comfort. Our proposed workflow
uses the Wave Function Collapse algorithm to generate a diverse set of
plausible floor plans. It also includes post-COVID occupant presence models
while incorporating adaptive comfort models. We conduct four sets of
experiments using the workflow, and the simulated results suggest that
multi-mode cooling strategies combining conventional air conditioning with NV
can often significantly reduce energy use while introducing only slight
reductions in thermal comfort.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06499" title="Abstract">arXiv:2312.06499</a> [<a href="/pdf/2312.06499" title="Download PDF">pdf</a>, <a href="/format/2312.06499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaCo: Targeted Concept Removal in Output Embeddings for NLP via  Information Theory and Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jourdan%2C+F">Fanny Jourdan</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A9thune%2C+L">Louis B&#xe9;thune</a>, 
<a href="/search/cs?searchtype=author&query=Picard%2C+A">Agustin Picard</a>, 
<a href="/search/cs?searchtype=author&query=Risser%2C+L">Laurent Risser</a>, 
<a href="/search/cs?searchtype=author&query=Asher%2C+N">Nicholas Asher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The fairness of Natural Language Processing (NLP) models has emerged as a
crucial concern. Information theory indicates that to achieve fairness, a model
should not be able to predict sensitive variables, such as gender, ethnicity,
and age. However, information related to these variables often appears
implicitly in language, posing a challenge in identifying and mitigating biases
effectively. To tackle this issue, we present a novel approach that operates at
the embedding level of an NLP model, independent of the specific architecture.
Our method leverages insights from recent advances in XAI techniques and
employs an embedding transformation to eliminate implicit information from a
selected variable. By directly manipulating the embeddings in the final layer,
our approach enables a seamless integration into existing models without
requiring significant modifications or retraining. In evaluation, we show that
the proposed post-hoc approach significantly reduces gender-related
associations in NLP models while preserving the overall performance and
functionality of the models. An implementation of our method is available:
https://github.com/fanny-jourdan/TaCo
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06500" title="Abstract">arXiv:2312.06500</a> [<a href="/pdf/2312.06500" title="Download PDF">pdf</a>, <a href="/format/2312.06500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating micro-learning content in traditional e-learning platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Caeiro-Rodr%C3%ADguez%2C+M">Manuel Caeiro-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Escobar%2C+J+J">Juan Jos&#xe9; L&#xf3;pez-Escobar</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 16 figures, journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Multimedia Tools and Applications, 80, 3121-3151 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Lifelong learning requires appropriate solutions, especially for corporate
training. Workers usually have difficulty combining training and their normal
work. In this context, micro-learning emerges as a suitable solution, since it
is based on breaking down new concepts into small fragments or pills of
content, which can be consumed in short periods of time. The purpose of this
paper is twofold. First, we offer an updated overview of the research on this
training paradigm, as well as the different technologies leading to potential
commercial solutions. Second, we introduce a proposal to add micro-learning
content to more formal distance learning environments (traditional Learning
Management Systems or LMS), with the aim of taking advantage of both learning
philosophies. Our approach is based on a Service-Oriented Architecture (SOA)
that is deployed in the cloud. In order to ensure the full integration of the
micro-learning approach in traditional LMSs, we have used two well-known
standards in the distance learning field: LTI (Learning Tools Interoperability)
and LIS (Learning Information Service). The combination of these two
technologies allows the exchange of data with the LMS to monitor the student's
activity and results. Finally, we have collected the opinion of lectures from
different countries in order to know their thoughts about the potential of this
new approach in higher education, obtaining positive feedback.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06502" title="Abstract">arXiv:2312.06502</a> [<a href="/pdf/2312.06502" title="Download PDF">pdf</a>, <a href="/ps/2312.06502" title="Download PostScript">ps</a>, <a href="/format/2312.06502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On enforcing dyadic-type homogeneous binary function product constraints  in MatBase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mancas%2C+C">Christian Mancas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted on Dec. 7, 2023, to the Journal of Data Science and Intelligent Systems (JDSIS), Bon View Publishing, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Homogeneous binary function products are often encountered in the
sub-universes modeled by databases, from genealogical trees to sports, from
education to healthcare, etc. Their properties must be discovered and enforced
by the software applications managing such data to guarantee plausibility. The
(Elementary) Mathematical Data Model provides 18 dyadic-type homogeneous binary
function product constraint types. MatBase, an intelligent data and knowledge
base management system prototype, allows database designers to simply declare
them by only clicking corresponding checkboxes and automatically generates code
for enforcing them. This paper describes the algorithms that MatBase uses for
enforcing all these 18 homogeneous binary function product constraint types,
which may also be used by developers not having access to MatBase.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06504" title="Abstract">arXiv:2312.06504</a> [<a href="/pdf/2312.06504" title="Download PDF">pdf</a>, <a href="/ps/2312.06504" title="Download PostScript">ps</a>, <a href="/format/2312.06504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite class of quantum codes derived from duadic constacyclic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dastbasteh%2C+R">Reza Dastbasteh</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+J+E">Josu Etxezarreta Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Nemec%2C+A">Andrew Nemec</a>, 
<a href="/search/cs?searchtype=author&query=iOlius%2C+A+d">Antonio deMarti iOlius</a>, 
<a href="/search/cs?searchtype=author&query=Bofill%2C+P+C">Pedro Crespo Bofill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We present a family of non-CSS quantum stabilizer codes using the structure
of duadic constacyclic codes over $\mathbb{F}_4$. Within this family, quantum
codes can possess varying dimensions, and their minimum distances are bounded
by a square root bound. For each fixed dimension, this allows us to construct
an infinite sequence of binary quantum codes with a growing minimum distance.
Additionally, we demonstrate that this quantum family includes an infinite
subclass of degenerate codes with the mentioned properties. We also introduce a
technique for extending splittings of duadic constacyclic codes, providing new
insights into the minimum distance and minimum odd-like weight of specific
duadic constacyclic codes. Finally, we establish that many best-known quantum
codes belong to this family and provide numerical examples of quantum codes
with short lengths within this family.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06505" title="Abstract">arXiv:2312.06505</a> [<a href="/pdf/2312.06505" title="Download PDF">pdf</a>, <a href="/format/2312.06505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounded Question-Answering in Long Egocentric Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Shangzhe Di</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing approaches to video understanding, mainly designed for short videos
from a third-person perspective, are limited in their applicability in certain
fields, such as robotics. In this paper, we delve into open-ended
question-answering (QA) in long, egocentric videos, which allows individuals or
robots to inquire about their own past visual experiences. This task presents
unique challenges, including the complexity of temporally grounding queries
within extensive video content, the high resource demands for precise data
annotation, and the inherent difficulty of evaluating open-ended answers due to
their ambiguous nature. Our proposed approach tackles these challenges by (i)
integrating query grounding and answering within a unified model to reduce
error propagation; (ii) employing large language models for efficient and
scalable data synthesis; and (iii) introducing a close-ended QA task for
evaluation, to manage answer ambiguity. Extensive experiments demonstrate the
effectiveness of our method, which also achieves state-of-the-art performance
on the QAEgo4D and Ego4D-NLQ benchmarks. We plan to publicly release the codes,
model, and constructed datasets for future research.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06506" title="Abstract">arXiv:2312.06506</a> [<a href="/pdf/2312.06506" title="Download PDF">pdf</a>, <a href="/ps/2312.06506" title="Download PostScript">ps</a>, <a href="/format/2312.06506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Directed Van Kampen Theorem in Lean
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basold%2C+H">Henning Basold</a>, 
<a href="/search/cs?searchtype=author&query=Bruin%2C+P">Peter Bruin</a>, 
<a href="/search/cs?searchtype=author&query=Lawson%2C+D">Dominique Lawson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Directed topology is an area of mathematics with applications in concurrency.
It extends the concept of a topological space by adding a notion of
directedness, which restricts how paths can evolve through a space and enables
thereby a faithful representation of computation with their direction. In this
paper, we present a Lean formalisation of directed spaces and a Van Kampen
theorem for them. This theorem allows the calculation of the homotopy type of a
space by combining local knowledge the homotopy type of subspaces. With this
theorem, the reasoning about spaces can be reduced to subspaces and, by
representing concurrent systems as directed spaces, we can reduce the deduction
of properties of a composed system to that of subsystems. The formalisation in
Lean can serve to support computer-assisted reasoning about the behaviour of
concurrent systems.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06510" title="Abstract">arXiv:2312.06510</a> [<a href="/pdf/2312.06510" title="Download PDF">pdf</a>, <a href="/ps/2312.06510" title="Download PostScript">ps</a>, <a href="/format/2312.06510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trusting a Smart Contract Means Trusting Its Owners: Understanding  Centralization Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamby%2C+M">Metin Lamby</a>, 
<a href="/search/cs?searchtype=author&query=Zieglmeier%2C+V">Valentin Zieglmeier</a>, 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+C">Christian Ziegler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-reviewed version accepted for publication in the proceedings of the 5th Conference on Blockchain Research &amp; Applications for Innovative Networks and Services (BRAINS '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">Smart contract access control mechanisms can introduce centralization into
supposedly decentralized ecosystems. In our view, such centralization is an
overlooked risk of smart contracts that underlies well-known smart contract
security incidents. Critically, mitigating the known vulnerability of missing
permission verification by implementing authorization patterns can in turn
introduce centralization. To delineate the issue, we define centralization risk
and describe smart contract source code patterns for Ethereum and Algorand that
can introduce it to smart contracts. We explain under which circumstances the
centralization can be exploited. Finally, we discuss implications of
centralization risk for different smart contract stakeholders.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06512" title="Abstract">arXiv:2312.06512</a> [<a href="/pdf/2312.06512" title="Download PDF">pdf</a>, <a href="/format/2312.06512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stoch BiRo: Design and Control of a low cost bipedal robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mothish%2C+G">GVS Mothish</a>, 
<a href="/search/cs?searchtype=author&query=Rajgopal%2C+K">Karthik Rajgopal</a>, 
<a href="/search/cs?searchtype=author&query=Kola%2C+R">Ravi Kola</a>, 
<a href="/search/cs?searchtype=author&query=Tayal%2C+M">Manan Tayal</a>, 
<a href="/search/cs?searchtype=author&query=Kolathaya%2C+S">Shishir Kolathaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces the Stoch BiRo, a cost-effective bipedal robot designed
with a modular mechanical structure having point feet to navigate uneven and
unfamiliar terrains. The robot employs proprioceptive actuation in abduction,
hips, and knees, leveraging a Raspberry Pi4 for control. Overcoming
computational limitations, a Learning-based Linear Policy controller manages
balance and locomotion with only 3 degrees of freedom (DoF) per leg, distinct
from the typical 5DoF in bipedal systems. Integrated within a modular control
architecture, these controllers enable autonomous handling of unforeseen
terrain disturbances without external sensors or prior environment knowledge.
The robot's policies are trained and simulated using MuJoCo, transferring
learned behaviors to the Stoch BiRo hardware for initial walking validations.
This work highlights the Stoch BiRo's adaptability and cost-effectiveness in
mechanical design, control strategies, and autonomous navigation, promising
diverse applications in real-world robotics scenarios.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06514" title="Abstract">arXiv:2312.06514</a> [<a href="/pdf/2312.06514" title="Download PDF">pdf</a>, <a href="/format/2312.06514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where exactly does contextualization in a PLM happen?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+S">Soniya Vijayakumar</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4umel%2C+T">Tanja B&#xe4;umel</a>, 
<a href="/search/cs?searchtype=author&query=Ostermann%2C+S">Simon Ostermann</a>, 
<a href="/search/cs?searchtype=author&query=van+Genabith%2C+J">Josef van Genabith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 BlackBloxNLP 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained Language Models (PLMs) have shown to be consistently successful
in a plethora of NLP tasks due to their ability to learn contextualized
representations of words (Ethayarajh, 2019). BERT (Devlin et al., 2018), ELMo
(Peters et al., 2018) and other PLMs encode word meaning via textual context,
as opposed to static word embeddings, which encode all meanings of a word in a
single vector representation. In this work, we present a study that aims to
localize where exactly in a PLM word contextualization happens. In order to
find the location of this word meaning transformation, we investigate
representations of polysemous words in the basic BERT uncased 12 layer
architecture (Devlin et al., 2018), a masked language model trained on an
additional sentence adjacency objective, using qualitative and quantitative
measures.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06515" title="Abstract">arXiv:2312.06515</a> [<a href="/pdf/2312.06515" title="Download PDF">pdf</a>, <a href="/format/2312.06515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Golden-Free Formal Method for Trojan Detection in Non-Interfering  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ant%C3%B3n%2C+A+L+D">Anna Lena Duque Ant&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">Johannes M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Deutschmann%2C+L">Lucas Deutschmann</a>, 
<a href="/search/cs?searchtype=author&query=Fadiheh%2C+M+R">Mohammad Rahmani Fadiheh</a>, 
<a href="/search/cs?searchtype=author&query=Stoffel%2C+D">Dominik Stoffel</a>, 
<a href="/search/cs?searchtype=author&query=Kunz%2C+W">Wolfgang Kunz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 27th Design, Automation and Test in Europe Conference (DATE'24), Mar 25-27 2024, Valencia, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The threat of hardware Trojans (HTs) in security-critical IPs like
cryptographic accelerators poses severe security risks. The HT detection
methods available today mostly rely on golden models and detailed circuit
specifications. Often they are specific to certain HT payload types, making
pre-silicon verification difficult and leading to security gaps. We propose a
novel formal verification method for HT detection in non-interfering
accelerators at the Register Transfer Level (RTL), employing standard formal
property checking. Our method guarantees the exhaustive detection of any
sequential HT independently of its payload behavior, including physical side
channels. It does not require a golden model or a functional specification of
the design. The experimental results demonstrate efficient and effective
detection of all sequential HTs in accelerators available on Trust-Hub,
including those with complex triggers and payloads.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06516" title="Abstract">arXiv:2312.06516</a> [<a href="/pdf/2312.06516" title="Download PDF">pdf</a>, <a href="/format/2312.06516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Irregular Repetition Slotted Aloha with Multipacket Detection: A Density  Evolution Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Veiga%2C+M">Manuel Fern&#xe1;ndez-Veiga</a>, 
<a href="/search/cs?searchtype=author&query=Sousa-Vieira%2C+M+E">M.E. Sousa-Vieira</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P D&#xed;az-Redondo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 12 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Networks, 234, 109921, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Irregular repetition slotted Aloha (IRSA) has shown significant advantages as
a modern technique for uncoordinated random access with massive number of users
due to its capability of achieving theoretically a throughput of $1$ packet per
slot. When the receiver has also the multi-packet reception of multi-user (MUD)
detection property, by applying successive interference cancellation, IRSA also
obtains very low packet loss probabilities at low traffic loads, but is unable
in general to achieve a normalized throughput close to the $1$. In this paper,
we reconsider the case of IRSA with $k$-MUD receivers and derive the general
density evolution equations for the non-asymptotic analysis of the packet loss
rate, for arbitrary frame lengths and two variants of the first slot used for
transmission. Next, using the potential function, we give new capacity bounds
on the capacity of the system, showing the threshold arrival rate for zero
decoding error probability. Our numerical results illustrate performance in
terms of throughput and average delay for $k$-MUD IRSA with finite memory at
the receiver, and also with bounded maximum delay.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06517" title="Abstract">arXiv:2312.06517</a> [<a href="/pdf/2312.06517" title="Download PDF">pdf</a>, <a href="/ps/2312.06517" title="Download PostScript">ps</a>, <a href="/format/2312.06517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facilitating Digital Agriculture with Simple Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buckmaster%2C+D">Dennis Buckmaster</a>, 
<a href="/search/cs?searchtype=author&query=Basir%2C+S">Sami Basir</a>, 
<a href="/search/cs?searchtype=author&query=Sakata%2C+H">Hanae Sakata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 table, 1 figure. Journal of Extension Tools of the Trade, in press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">As an on-ramp to databases, we offer several well-structured private database
templates as open source resources for agriculturalists, particularly those
with modest spreadsheet skills. These farmer-oriented Air table databases use
simple data-validated forms, with the look and feel of a customized app, to
yield operational data that is tidy, machine- and human-readable, editable, and
exportable for analysis in other software. Such data can facilitate logistics,
provide contextual metadata, and improve enterprise analysis. A recorded
workshop explaining how to build a database for activity records is presented.
These resources may facilitate infusion of digital agriculture principles
through Extension and structured educational programming.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06518" title="Abstract">arXiv:2312.06518</a> [<a href="/pdf/2312.06518" title="Download PDF">pdf</a>, <a href="/format/2312.06518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Meta-Reinforcement Learning with Gaussian Task Contexts and  Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hongcai He</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Anjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shuang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jie Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 (this version includes appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Offline meta-reinforcement learning (meta-RL) methods, which adapt to unseen
target tasks with prior experience, are essential in robot control tasks.
Current methods typically utilize task contexts and skills as prior experience,
where task contexts are related to the information within each task and skills
represent a set of temporally extended actions for solving subtasks. However,
these methods still suffer from limited performance when adapting to unseen
target tasks, mainly because the learned prior experience lacks generalization,
i.e., they are unable to extract effective prior experience from meta-training
tasks by exploration and learning of continuous latent spaces. We propose a
framework called decoupled meta-reinforcement learning (DCMRL), which (1)
contrastively restricts the learning of task contexts through pulling in
similar task contexts within the same task and pushing away different task
contexts of different tasks, and (2) utilizes a Gaussian quantization
variational autoencoder (GQ-VAE) for clustering the Gaussian distributions of
the task contexts and skills respectively, and decoupling the exploration and
learning processes of their spaces. These cluster centers which serve as
representative and discrete distributions of task context and skill are stored
in task context codebook and skill codebook, respectively. DCMRL can acquire
generalizable prior experience and achieve effective adaptation to unseen
target tasks during the meta-testing phase. Experiments in the navigation and
robot manipulation continuous control tasks show that DCMRL is more effective
than previous meta-RL methods with more generalizable prior experience.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06519" title="Abstract">arXiv:2312.06519</a> [<a href="/pdf/2312.06519" title="Download PDF">pdf</a>, <a href="/format/2312.06519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A GAN Approach for Node Embedding in Heterogeneous Graphs Using Subgraph  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+H+C">Hung Chun Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo-Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Ming-Yi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Che Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chih-Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Our research addresses class imbalance issues in heterogeneous graphs using
graph neural networks (GNNs). We propose a novel method combining the strengths
of Generative Adversarial Networks (GANs) with GNNs, creating synthetic nodes
and edges that effectively balance the dataset. This approach directly targets
and rectifies imbalances at the data level. The proposed framework resolves
issues such as neglecting graph structures during data generation and creating
synthetic structures usable with GNN-based classifiers in downstream tasks. It
processes node and edge information concurrently, improving edge balance
through node augmentation and subgraph sampling. Additionally, our framework
integrates a threshold strategy, aiding in determining optimal edge thresholds
during training without time-consuming parameter adjustments. Experiments on
the Amazon and Yelp Review datasets highlight the effectiveness of the
framework we proposed, especially in minority node identification, where it
consistently outperforms baseline models across key performance metrics,
demonstrating its potential in the field.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06521" title="Abstract">arXiv:2312.06521</a> [<a href="/pdf/2312.06521" title="Download PDF">pdf</a>, <a href="/ps/2312.06521" title="Download PostScript">ps</a>, <a href="/format/2312.06521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Control of Fluid Dosing in Hemorrhage Resuscitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grant%2C+J">Jacob Grant</a>, 
<a href="/search/eess?searchtype=author&query=Mirinejad%2C+H">Hossein Mirinejad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures (with subfigures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Fluid resuscitation, also called fluid therapy, is commonly used in treatment
of critical care patients. Of the variables inherent to fluid therapy
treatment, fluid infusion types are well-studied, but volumetric optimization
is not. Automated fluid resuscitation systems employ computational control
algorithms along with physiological sensors and actuators to automatically
adjust the fluid infusion dosage in hemorrhage scenarios. Most automated
hemorrhage resuscitation control algorithms implemented to date are of empiric
nature and not effective in the presence of clinical disturbances. This work
presents preliminary results of a novel controller based on optimal control
approach for automated fluid therapy systems. A receding horizon controller is
designed to automatically adjust fluid infusion rate in hemorrhagic situations.
The proposed control approach aims to address the inefficiency of current
resuscitation control algorithms in finding the accurate fluid dosage
adjustments. Performance of the proposed approach is compared against a
proportional-integral-derivative (PID) controller for a simulated hemorrhage
scenario.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06522" title="Abstract">arXiv:2312.06522</a> [<a href="/pdf/2312.06522" title="Download PDF">pdf</a>, <a href="/format/2312.06522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Smoothing for Enhanced Text Sentiment Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yijie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+S">Shijing Si</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Label smoothing is a widely used technique in various domains, such as image
classification and speech recognition, known for effectively combating model
overfitting. However, there is few research on its application to text
sentiment classification. To fill in the gap, this study investigates the
implementation of label smoothing for sentiment classification by utilizing
different levels of smoothing. The primary objective is to enhance sentiment
classification accuracy by transforming discrete labels into smoothed label
distributions. Through extensive experiments, we demonstrate the superior
performance of label smoothing in text sentiment classification tasks across
eight diverse datasets and deep learning architectures: TextCNN, BERT, and
RoBERTa, under two learning schemes: training from scratch and fine-tuning.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06527" title="Abstract">arXiv:2312.06527</a> [<a href="/pdf/2312.06527" title="Download PDF">pdf</a>, <a href="/format/2312.06527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Reinforcement Learning support policy makers? A preliminary study  with Integrated Assessment Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+T">Theodore Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Nardelli%2C+N">Nantas Nardelli</a>, 
<a href="/search/cs?searchtype=author&query=Shawe-Taylor%2C+J">John Shawe-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Ortiz%2C+M">Maria Perez-Ortiz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS'23 Workshop on Tackling Climate Change with Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Governments around the world aspire to ground decision-making on evidence.
Many of the foundations of policy making - e.g. sensing patterns that relate to
societal needs, developing evidence-based programs, forecasting potential
outcomes of policy changes, and monitoring effectiveness of policy programs -
have the potential to benefit from the use of large-scale datasets or
simulations together with intelligent algorithms. These could, if designed and
deployed in a way that is well grounded on scientific evidence, enable a more
comprehensive, faster, and rigorous approach to policy making. Integrated
Assessment Models (IAM) is a broad umbrella covering scientific models that
attempt to link main features of society and economy with the biosphere into
one modelling framework. At present, these systems are probed by policy makers
and advisory groups in a hypothesis-driven manner. In this paper, we
empirically demonstrate that modern Reinforcement Learning can be used to probe
IAMs and explore the space of solutions in a more principled manner. While the
implication of our results are modest since the environment is simplistic, we
believe that this is a stepping stone towards more ambitious use cases, which
could allow for effective exploration of policies and understanding of their
consequences and limitations.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06528" title="Abstract">arXiv:2312.06528</a> [<a href="/pdf/2312.06528" title="Download PDF">pdf</a>, <a href="/format/2312.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers Implement Functional Gradient Descent to Learn Non-Linear  Functions In Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sra%2C+S">Suvrit Sra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many neural network architectures have been shown to be Turing Complete, and
can thus implement arbitrary algorithms. However, Transformers are unique in
that they can implement gradient-based learning algorithms \emph{under simple
parameter configurations}. A line of recent work shows that linear Transformers
naturally learn to implement gradient descent (GD) when trained on a linear
regression in-context learning task. But the linearity assumption (either in
the Transformer architecture or in the learning task) is far from realistic
settings where non-linear activations crucially enable Transformers to learn
complicated non-linear functions. In this paper, we provide theoretical and
empirical evidence that non-linear Transformers can, and \emph{in fact do},
learn to implement learning algorithms to learn non-linear functions in
context. Our results apply to a broad class of combinations of non-linear
architectures, and non-linear in-context learning tasks. Interestingly, we show
that the optimal choice of non-linear activation depends in a natural way on
the non-linearity of the learning task.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06530" title="Abstract">arXiv:2312.06530</a> [<a href="/pdf/2312.06530" title="Download PDF">pdf</a>, <a href="/format/2312.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of Non-Verbal Behavior in Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maccari%2C+C+V">Camila Vicari Maccari</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+G+G">Gustavo Galle de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Knob%2C+P+R">Paulo Ricardo Knob</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S+R">Soraia Raupp Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper presented as Final Project in Computer Science - Pontifical Catholic university of Rio Grande do Sul (Brazil)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper studies the non-verbal behavior of a conversational agent named
Arthur. We propose the development of body movements for this agent, which
interacts solely through voice commands, chat, and videos with facial
animations. This research aims to analyze users' perceptions regarding the
gestures performed by Arthur. This study was conducted with participants who
agreed to interact directly or through video with the conversational agent. The
main goal is to analyze whether including nonverbal movements alters users'
perception so that they feel more comfortable watching the video or interacting
in real-time.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06532" title="Abstract">arXiv:2312.06532</a> [<a href="/pdf/2312.06532" title="Download PDF">pdf</a>, <a href="/format/2312.06532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RACE-IT: A Reconfigurable Analog CAM-Crossbar Engine for In-Memory  Transformer Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Buonanno%2C+L">Luca Buonanno</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+R+M">Ron M. Roth</a>, 
<a href="/search/cs?searchtype=author&query=Serebryakov%2C+S">Sergey Serebryakov</a>, 
<a href="/search/cs?searchtype=author&query=Gajjar%2C+A">Archit Gajjar</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+J">John Moon</a>, 
<a href="/search/cs?searchtype=author&query=Ignowski%2C+J">Jim Ignowski</a>, 
<a href="/search/cs?searchtype=author&query=Pedretti%2C+G">Giacomo Pedretti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer models represent the cutting edge of Deep Neural Networks (DNNs)
and excel in a wide range of machine learning tasks. However, processing these
models demands significant computational resources and results in a substantial
memory footprint. While In-memory Computing (IMC) offers promise for
accelerating Matrix-Vector Multiplications (MVMs) with high computational
parallelism and minimal data movement, employing it for implementing other
crucial operators within DNNs remains a formidable task. This challenge is
exacerbated by the extensive use of Softmax and data-dependent matrix
multiplications within the attention mechanism. Furthermore, existing IMC
designs encounter difficulties in fully harnessing the benefits of analog MVM
acceleration due to the area and energy-intensive nature of Analog-to-Digital
Converters (ADCs). To tackle these challenges, we introduce a novel Compute
Analog Content Addressable Memory (Compute-ACAM) structure capable of
performing various non-MVM operations within Transformers. Together with the
crossbar structure, our proposed RACE-IT accelerator enables efficient
execution of all operations within Transformer models in the analog domain.
Given the flexibility of our proposed Compute-ACAMs to perform arbitrary
operations, RACE-IT exhibits adaptability to diverse non-traditional and future
DNN architectures without necessitating hardware modifications. Leveraging the
capability of Compute-ACAMs to process analog input and produce digital output,
we also replace ADCs, thereby reducing the overall area and energy costs. By
evaluating various Transformer models against state-of-the-art GPUs and
existing IMC accelerators, RACE-IT increases performance by 10.7x and 5.9x, and
reduces energy by 1193x, and 3.9x, respectively
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06534" title="Abstract">arXiv:2312.06534</a> [<a href="/pdf/2312.06534" title="Download PDF">pdf</a>, <a href="/ps/2312.06534" title="Download PostScript">ps</a>, <a href="/format/2312.06534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KPIs-Based Clustering and Visualization of HPC jobs: a Feature Reduction  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halawa%2C+M+S">Mohamed Soliman Halawa</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, 2021, vol. 9, p. 25522-25543
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">High-Performance Computing (HPC) systems need to be constantly monitored to
ensure their stability. The monitoring systems collect a tremendous amount of
data about different parameters or Key Performance Indicators (KPIs), such as
resource usage, IO waiting time, etc. A proper analysis of this data, usually
stored as time series, can provide insight in choosing the right management
strategies as well as the early detection of issues. In this paper, we
introduce a methodology to cluster HPC jobs according to their KPI indicators.
Our approach reduces the inherent high dimensionality of the collected data by
applying two techniques to the time series: literature-based and variance-based
feature extraction. We also define a procedure to visualize the obtained
clusters by combining the two previous approaches and the Principal Component
Analysis (PCA). Finally, we have validated our contributions on a real data set
to conclude that those KPIs related to CPU usage provide the best cohesion and
separation for clustering analysis and the good results of our visualization
methodology.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06538" title="Abstract">arXiv:2312.06538</a> [<a href="/pdf/2312.06538" title="Download PDF">pdf</a>, <a href="/ps/2312.06538" title="Download PostScript">ps</a>, <a href="/format/2312.06538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ray-Tracing With a Coherent Ray-Space Hierarchy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reis%2C+N">Nuno Reis</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+V">Vasco Costa</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J+M">Jo&#xe3;o M. Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We present an algorithm for creating an n-level ray-space hierarchy (RSH) of
coherent rays that runs on the GPU. Our algorithm uses rasterization to process
the primary rays, then uses those results as the inputs for a RSH, that
processes the secondary rays. The RSH algorithm generates bundles of rays;
hashes them, according to their attributes; and sorts them. Thus we generate a
ray list with adjacent coherent rays. To improve the rendering performance of
the RSH vs a more classical approach. In addition the scenes geometry is
partitioned into a set of bounding spheres, intersected with the RSH, to
further decrease the amount of false ray bundle-primitive intersection tests.
We show that our technique notably reduces the amount of ray-primitive
intersection tests, required to render an image. In particular, it performs up
to 50% better in this metric than other algorithms in this class.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06543" title="Abstract">arXiv:2312.06543</a> [<a href="/pdf/2312.06543" title="Download PDF">pdf</a>, <a href="/ps/2312.06543" title="Download PostScript">ps</a>, <a href="/format/2312.06543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Strategy for Virtual Synchronous Generator Based on Y-Z Source  Inverter in Islanded Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Besati%2C+S">Shirin Besati</a>, 
<a href="/search/eess?searchtype=author&query=Mosallanejad%2C+A">Ali Mosallanejad</a>, 
<a href="/search/eess?searchtype=author&query=Manjrekar%2C+M">Madhav Manjrekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at 11th ICEEE in Marmaris, Turkey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The Virtual Synchronous Machine (VSM) concept stands as a strategy for the
seamless integration of renewable energy sources into the grid. In scenarios
where symmetrical and sinusoidal operating conditions are lacking, VSMs
demonstrate multifaceted capabilities. They can operate as power sources
especially in islanded-systems, adeptly address harmonic distortions and
imbalances, offer load power compensation, and elevate voltage quality at the
grid. Even so, dead time variations, discontinuous input current, and
non-single-power-stage configuration of conventional voltage/current source
inverters and also, load variation can result in VSMs behaving as harmonic and
imbalance absorbers. This paper utilizes a specific Y-Source Inverter (YZSI)
for the first time as a solution to these challenges. Through integrating this
innovative configuration with an exceptionally adaptable voltage gain and an
enhanced multi-loop control strategy into an isolated power system
accommodating diverse load profiles, it not only achieves high efficiency in
power transfer but also enhances overall system performance quality.
Furthermore, it contributes to extending the lifespan and preserving the
quality of the input source. The controller is designed to regulate system
frequency, voltage, and manage voltage and current for YZSI, delivering
impressive performance even in non-ideal grid conditions. MATLAB/Simulink
confirms the efficacy of the proposed YZSI VSG control strategy with a high
accuracy achieved through a comprehensive examination of the internal component
parameters.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06544" title="Abstract">arXiv:2312.06544</a> [<a href="/pdf/2312.06544" title="Download PDF">pdf</a>, <a href="/ps/2312.06544" title="Download PostScript">ps</a>, <a href="/format/2312.06544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity Evaluation of Parallel Execution of the RAPiD Deep-Learning  Algorithm on Intel CPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konrad%2C+D">Dominic Konrad</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhihao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Cokbas%2C+M">Mertcan Cokbas</a>, 
<a href="/search/cs?searchtype=author&query=Ishwar%2C+P">Prakash Ishwar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Knowing how many and where are people in various indoor spaces is critical
for reducing HVAC energy waste, space management, spatial analytics and in
emergency scenarios. While a range of technologies have been proposed to detect
and track people in large indoor spaces, ceiling-mounted fisheye cameras have
recently emerged as strong contenders. Currently, RAPiD is the SOTA algorithm
for people detection in images captured by fisheye cameras. However, in large
spaces several overhead fisheye cameras are needed to assure high accuracy of
counting and thus multiple instances of RAPiD must be executed simultaneously.
This report evaluates inference time when multiple instances of RAPiD run in
parallel on an Ubuntu NUC PC with Intel I7 8559U CPU. We consider three
mechanisms of CPU-resource allocation to handle multiple instances of RAPiD: 1)
managed by Ubuntu, 2) managed by user via operating-system calls to assign
logical cores, and 3) managed by user via PyTorch-library calls to limit the
number of threads used by PyTorch. Each scenario was evaluated on 300 images.
The experimental results show, that when one or two instances of RAPiD are
executed in parallel all three approaches result in similar inference times of
1.8sec and 3.2sec, respectively. However, when three or more instances of RAPiD
run in parallel, limiting the number of threads used by PyTorch results in the
shortest inference times. On average, RAPiD completes inference of 2 images
simultaneously in about 3sec, 4 images in 6sec and 8 images in less than 14sec.
This is important for real-time system design. In HVAC-application scenarios,
with a typical reaction time of 10-15min, a latency of 14sec is negligible so a
single 8559U CPU can support 8 camera streams thus reducing the system cost.
However, in emergency scenarios, when time is of essence, a single CPU may be
needed for each camera to reduce the latency to 1.8sec.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06546" title="Abstract">arXiv:2312.06546</a> [<a href="/pdf/2312.06546" title="Download PDF">pdf</a>, <a href="/ps/2312.06546" title="Download PostScript">ps</a>, <a href="/format/2312.06546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised KPIs-Based Clustering of Jobs in HPC Data Centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halawa%2C+M+S">Mohamed S. Halawa</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 2020, vol. 20, no 15, p. 4111
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Performance analysis is an essential task in High-Performance Computing (HPC)
systems and it is applied for different purposes such as anomaly detection,
optimal resource allocation, and budget planning. HPC monitoring tasks generate
a huge number of Key Performance Indicators (KPIs) to supervise the status of
the jobs running in these systems. KPIs give data about CPU usage, memory
usage, network (interface) traffic, or other sensors that monitor the hardware.
Analyzing this data, it is possible to obtain insightful information about
running jobs, such as their characteristics, performance, and failures. The
main contribution in this paper is to identify which metric/s (KPIs) is/are the
most appropriate to identify/classify different types of jobs according to
their behavior in the HPC system. With this aim, we have applied different
clustering techniques (partition and hierarchical clustering algorithms) using
a real dataset from the Galician Computation Center (CESGA). We have concluded
that (i) those metrics (KPIs) related to the Network (interface) traffic
monitoring provide the best cohesion and separation to cluster HPC jobs, and
(ii) hierarchical clustering algorithms are the most suitable for this task.
Our approach was validated using a different real dataset from the same HPC
center.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06549" title="Abstract">arXiv:2312.06549</a> [<a href="/pdf/2312.06549" title="Download PDF">pdf</a>, <a href="/format/2312.06549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Crowd Dynamics: Simulating Structured Behaviors through Crowd  Simulation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Mello%2C+T+G+V">Thiago Gomes Vidal de Mello</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+M+S+H">Matheus Schreiner Homrich da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+G+F">Gabriel Fonseca Silva</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S+R">Soraia Raupp Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper presented as Final project of Computer Science Undergraduate Course at PUCRS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">This paper proposes the simulation of structured behaviors in a crowd of
virtual agents by extending the BioCrowds simulation model.
<br />Three behaviors were simulated and evaluated, a queue as a generic case and
two specific behaviors observed at rock concerts. The extended model
incorporates new parameters and modifications to replicate these behaviors
accurately. Experiments were conducted to analyze the impact of parameters on
simulation results, and computational performance was considered.
<br />The results demonstrate the model's effectiveness in simulating structured
behaviors and its potential for replicating complex social phenomena in diverse
scenarios.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06550" title="Abstract">arXiv:2312.06550</a> [<a href="/pdf/2312.06550" title="Download PDF">pdf</a>, <a href="/format/2312.06550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM360: Towards Fully Transparent Open-Source LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengzhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+A">Aurick Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Neiswanger%2C+W">Willie Neiswanger</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Bowen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+T">Tianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Suqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Pangarkar%2C+O">Omkar Pangarkar</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Richard Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+V">Victor Miller</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yonghao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guowei He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haonan Li</a>, 
<a href="/search/cs?searchtype=author&query=Koto%2C+F">Fajri Koto</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Liping Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+N">Nikhil Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuguang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Iriondo%2C+R">Roberto Iriondo</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+C">Cun Mu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Schulze%2C+M">Mark Schulze</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Tim Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E+P">Eric P. Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent surge in open-source Large Language Models (LLMs), such as LLaMA,
Falcon, and Mistral, provides diverse options for AI practitioners and
researchers. However, most LLMs have only released partial artifacts, such as
the final model weights or inference code, and technical reports increasingly
limit their scope to high-level design choices and surface statistics. These
choices hinder progress in the field by degrading transparency into the
training of LLMs and forcing teams to rediscover many details in the training
process. We present LLM360, an initiative to fully open-source LLMs, which
advocates for all training code and data, model checkpoints, and intermediate
results to be made available to the community. The goal of LLM360 is to support
open and collaborative AI research by making the end-to-end LLM training
process transparent and reproducible by everyone. As a first step of LLM360, we
release two 7B parameter LLMs pre-trained from scratch, Amber and CrystalCoder,
including their training code, data, intermediate checkpoints, and analyses (at
https://www.llm360.ai). We are committed to continually pushing the boundaries
of LLMs through this open-source effort. More large-scale and stronger models
are underway and will be released in the future.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06551" title="Abstract">arXiv:2312.06551</a> [<a href="/pdf/2312.06551" title="Download PDF">pdf</a>, <a href="/ps/2312.06551" title="Download PostScript">ps</a>, <a href="/format/2312.06551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successive Bayesian Reconstructor for Channel Estimation in Flexible  Antenna Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Linglong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures. This paper proposes S-BAR as a general solution to estimate FAS channels. Unlike model-based estimators, the proposed S-BAR is prior-aided, which builds the experiential kernel for CSI acquisition. Simulation codes will be provided at: <a href="http://oa.ee.tsinghua.edu.cn/dailinglong/publications/publications.html">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">Flexible antenna systems (FASs) can reconfigure their locations freely within
a spatially continuous space. To keep favorable antenna positions, the channel
state information (CSI) acquisition for FASs is essential. While some
techniques have been proposed, most existing FAS channel estimators require
several channel assumptions, such as slow variation and angular-domain
sparsity. When these assumptions are not reasonable, the model mismatch may
lead to unpredictable performance loss. In this paper, we propose the
successive Bayesian reconstructor (S-BAR) as a general solution to estimate FAS
channels. Unlike model-based estimators, the proposed S-BAR is prior-aided,
which builds the experiential kernel for CSI acquisition. Inspired by Bayesian
regression, the key idea of S-BAR is to model the FAS channels as a stochastic
process, whose uncertainty can be successively eliminated by kernel-based
sampling and regression. In this way, the predictive mean of the regressed
stochastic process can be viewed as the maximum a posterior (MAP) estimator of
FAS channels. Simulation results verify that, in both model-mismatched and
model-matched cases, the proposed S-BAR can achieve higher estimation accuracy
than the existing schemes.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06552" title="Abstract">arXiv:2312.06552</a> [<a href="/pdf/2312.06552" title="Download PDF">pdf</a>, <a href="/format/2312.06552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Data-Driven Automation of Residential Distribution Grid Modeling  with Minimal Data Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Moritz Weber</a>, 
<a href="/search/cs?searchtype=author&query=Janecke%2C+L">Luc Janecke</a>, 
<a href="/search/cs?searchtype=author&query=%C3%87akmak%2C+H+K">Huseyin K. &#xc7;akmak</a>, 
<a href="/search/cs?searchtype=author&query=Hagenmeyer%2C+V">Veit Hagenmeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures, submitted to IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In the present paper, we introduce a new method for the automated generation
of residential distribution grid models based on novel building load estimation
methods and a two-stage optimization for the generation of the 20 kV and 400 V
grid topologies. Using the introduced load estimation methods, various open or
proprietary data sources can be utilized to estimate the load of residential
buildings. These data sources include available building footprints from
OpenStreetMap, 3D building data from OSM Buildings, and the number of
electricity meters per address provided by the respective distribution system
operator (DSO).
<br />For the evaluation of the introduced methods, we compare the resulting grid
models by utilizing different available data sources for a specific suburban
residential area and the real grid topology provided by the DSO. This
evaluation yields two key findings: First, the automated 20 kV network
generation methodology works well when compared to the real network. Second,
the utilization of public 3D building data for load estimation significantly
increases the resulting model accuracy compared to 2D data and enables results
similar to models based on DSO-supplied meter data. This substantially reduces
the dependence on such normally proprietary data.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06553" title="Abstract">arXiv:2312.06553</a> [<a href="/pdf/2312.06553" title="Download PDF">pdf</a>, <a href="/format/2312.06553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOI-Diff: Text-Driven Synthesis of 3D Human-Object Interactions using  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaogang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiming Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zizhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaizu Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address the problem of generating realistic 3D human-object interactions
(HOIs) driven by textual prompts. Instead of a single model, our key insight is
to take a modular design and decompose the complex task into simpler sub-tasks.
We first develop a dual-branch diffusion model (HOI-DM) to generate both human
and object motions conditioning on the input text, and encourage coherent
motions by a cross-attention communication module between the human and object
motion generation branches. We also develop an affordance prediction diffusion
model (APDM) to predict the contacting area between the human and object during
the interactions driven by the textual prompt. The APDM is independent of the
results by the HOI-DM and thus can correct potential errors by the latter.
Moreover, it stochastically generates the contacting points to diversify the
generated motions. Finally, we incorporate the estimated contacting points into
the classifier-guidance to achieve accurate and close contact between humans
and objects. To train and evaluate our approach, we annotate BEHAVE dataset
with text descriptions. Experimental results demonstrate that our approach is
able to produce realistic HOIs with various interactions and different types of
objects.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06557" title="Abstract">arXiv:2312.06557</a> [<a href="/pdf/2312.06557" title="Download PDF">pdf</a>, <a href="/ps/2312.06557" title="Download PostScript">ps</a>, <a href="/format/2312.06557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Graph Neural Network based on Graph Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tenorio%2C+V+M">Victor M. Tenorio</a>, 
<a href="/search/cs?searchtype=author&query=Rey%2C+S">Samuel Rey</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+A+G">Antonio G. Marques</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in the 2023 Asilomar Conference on Signals, Systems, and Computers (Oct. 29th - Nov 1st, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have emerged as a notorious alternative to
address learning problems dealing with non-Euclidean datasets. However,
although most works assume that the graph is perfectly known, the observed
topology is prone to errors stemming from observational noise, graph-learning
limitations, or adversarial attacks. If ignored, these perturbations may
drastically hinder the performance of GNNs. To address this limitation, this
work proposes a robust implementation of GNNs that explicitly accounts for the
presence of perturbations in the observed topology. For any task involving
GNNs, our core idea is to i) solve an optimization problem not only over the
learnable parameters of the GNN but also over the true graph, and ii) augment
the fitting cost with a term accounting for discrepancies on the graph.
Specifically, we consider a convolutional GNN based on graph filters and follow
an alternating optimization approach to handle the (non-differentiable and
constrained) optimization problem by combining gradient descent and projected
proximal updates. The resulting algorithm is not limited to a particular type
of graph and is amenable to incorporating prior information about the
perturbations. Finally, we assess the performance of the proposed method
through several numerical experiments.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06558" title="Abstract">arXiv:2312.06558</a> [<a href="/pdf/2312.06558" title="Download PDF">pdf</a>, <a href="/format/2312.06558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Photonic Reservoir Computer for Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Picco%2C+E">Enrico Picco</a>, 
<a href="/search/cs?searchtype=author&query=Lupo%2C+A">Alessandro Lupo</a>, 
<a href="/search/cs?searchtype=author&query=Massar%2C+S">Serge Massar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Optics (physics.optics)

</div>
<p class="mathjax">Speech recognition is a critical task in the field of artificial intelligence
and has witnessed remarkable advancements thanks to large and complex neural
networks, whose training process typically requires massive amounts of labeled
data and computationally intensive operations. An alternative paradigm,
reservoir computing, is energy efficient and is well adapted to implementation
in physical substrates, but exhibits limitations in performance when compared
to more resource-intensive machine learning algorithms. In this work we address
this challenge by investigating different architectures of interconnected
reservoirs, all falling under the umbrella of deep reservoir computing. We
propose a photonic-based deep reservoir computer and evaluate its effectiveness
on different speech recognition tasks. We show specific design choices that aim
to simplify the practical implementation of a reservoir computer while
simultaneously achieving high-speed processing of high-dimensional audio
signals. Overall, with the present work we hope to help the advancement of
low-power and high-performance neuromorphic hardware.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06560" title="Abstract">arXiv:2312.06560</a> [<a href="/pdf/2312.06560" title="Download PDF">pdf</a>, <a href="/format/2312.06560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Regularization for Linear MMSE Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Pinho+Zanco%2C+D+G">Daniel Gomes de Pinho Zanco</a>, 
<a href="/search/cs?searchtype=author&query=Szczecinski%2C+L">Leszek Szczecinski</a>, 
<a href="/search/cs?searchtype=author&query=Benesty%2C+J">Jacob Benesty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we consider the problem of regularization in minimum
mean-squared error (MMSE) linear filters. Exploiting the relationship with
statistical machine learning methods, the regularization parameter is found
from the observed signals in a simple and automatic manner. The proposed
approach is illustrated through system identification examples, where the
automatic regularization yields near-optimal results.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06561" title="Abstract">arXiv:2312.06561</a> [<a href="/pdf/2312.06561" title="Download PDF">pdf</a>, <a href="/format/2312.06561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Hybrid Neural Fluid Fields from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong-Xing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yitong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project website: <a href="https://kovenyu.com/HyFluid/">this https URL</a> The first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We study recovering fluid density and velocity from sparse multiview videos.
Existing neural dynamic reconstruction methods predominantly rely on optical
flows; therefore, they cannot accurately estimate the density and uncover the
underlying velocity due to the inherent visual ambiguities of fluid velocity,
as fluids are often shapeless and lack stable visual features. The challenge is
further pronounced by the turbulent nature of fluid flows, which calls for
properly designed fluid velocity representations. To address these challenges,
we propose hybrid neural fluid fields (HyFluid), a neural approach to jointly
infer fluid density and velocity fields. Specifically, to deal with visual
ambiguities of fluid velocity, we introduce a set of physics-based losses that
enforce inferring a physically plausible velocity field, which is
divergence-free and drives the transport of density. To deal with the turbulent
nature of fluid velocity, we design a hybrid neural velocity representation
that includes a base neural velocity field that captures most irrotational
energy and a vortex particle-based velocity that models residual turbulent
velocity. We show that our method enables recovering vortical flow details. Our
approach opens up possibilities for various learning and reconstruction
applications centered around 3D incompressible flow, including fluid
re-simulation and editing, future prediction, and neural dynamic scene
composition. Project website: https://kovenyu.com/HyFluid/
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06562" title="Abstract">arXiv:2312.06562</a> [<a href="/pdf/2312.06562" title="Download PDF">pdf</a>, <a href="/format/2312.06562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Meta-Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Wynter%2C+A">Adrian de Wynter</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qilong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Si-Qing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Category Theory (math.CT)

</div>
<p class="mathjax">Certain statistical models are capable of interpreting input strings as
instructions, or prompts, and carry out tasks based on them. Many approaches to
prompting and pre-training these models involve the automated generation of
these prompts. We call these approaches meta-prompting, or prompting to obtain
prompts. We propose a theoretical framework based on category theory to
generalize and describe them. This framework is flexible enough to account for
LLM stochasticity; and allows us to obtain formal results around task
agnosticity and equivalence of various meta-prompting approaches. We experiment
with meta-prompting in two active areas of model research: creativity and
ideation. We find that user preference favors (p &lt; 0.01) the prompts generated
under meta-prompting, as well as their corresponding outputs, over a series of
hardcoded baseline prompts that include the original task prompt. Using our
framework, we argue that meta-prompting is more effective than basic prompting
at generating desirable outputs.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06564" title="Abstract">arXiv:2312.06564</a> [<a href="/pdf/2312.06564" title="Download PDF">pdf</a>, <a href="/format/2312.06564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Counterfactual Robustness through Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leofante%2C+F">Francesco Leofante</a>, 
<a href="/search/cs?searchtype=author&query=Potyka%2C+N">Nico Potyka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counterfactual explanations shed light on the decisions of black-box models
by explaining how an input can be altered to obtain a favourable decision from
the model (e.g., when a loan application has been rejected). However, as noted
recently, counterfactual explainers may lack robustness in the sense that a
minor change in the input can cause a major change in the explanation. This can
cause confusion on the user side and open the door for adversarial attacks. In
this paper, we study some sources of non-robustness. While there are
fundamental reasons for why an explainer that returns a single counterfactual
cannot be robust in all instances, we show that some interesting robustness
guarantees can be given by reporting multiple rather than a single
counterfactual. Unfortunately, the number of counterfactuals that need to be
reported for the theoretical guarantees to hold can be prohibitively large. We
therefore propose an approximation algorithm that uses a diversity criterion to
select a feasible number of most relevant explanations and study its robustness
empirically. Our experiments indicate that our method improves the
state-of-the-art in generating robust explanations, while maintaining other
desirable properties and providing competitive computational performance.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06566" title="Abstract">arXiv:2312.06566</a> [<a href="/pdf/2312.06566" title="Download PDF">pdf</a>, <a href="/format/2312.06566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Size Does not Fit All: Personalised Affordance Design for Social  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guanyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+R+K">Roger K. Moore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The proceedings of the CONCATENATE workshop at HRI23, Stockholm, Sweden. 4 pages with 2 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Personalisation is essential to achieve more acceptable and effective results
in human-robot interaction. Placing users in the central role, many studies
have focused on enhancing the abilities of social robots to perceive and
understand users. However, little is known about improving user perceptions and
interpretation of a social robot in spoken interactions. The work described in
the paper aims to find out what affects the personalisation of affordance of a
social robot, namely its appearance, voice and language behaviours. The
experimental data presented here is based on an ongoing project. It
demonstrates the many and varied ways in which people change their preferences
for the affordance of a social robot under different circumstances. It also
examines the relationship between such preferences and expectations of
characteristics of a social robot, like competence and warmth. It also shows
that individuals have different perceptions of the language behaviours of the
same robot. These results demonstrate that one-sized personalisation does not
fit all. Personalisation should be considered a comprehensive approach,
including appropriate affordance design, to suit the user expectations of
social roles.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06568" title="Abstract">arXiv:2312.06568</a> [<a href="/pdf/2312.06568" title="Download PDF">pdf</a>, <a href="/format/2312.06568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+D">Subhajit Dutta Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhiyu Ni</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qingyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Souvik Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Nuzzo%2C+P">Pierluigi Nuzzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 GLFrontiers Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Graph Lottery Tickets (GLTs), comprising a sparse adjacency matrix and a
sparse graph neural network (GNN), can significantly reduce the inference
latency and compute footprint compared to their dense counterparts. Despite
these benefits, their performance against adversarial structure perturbations
remains to be fully explored. In this work, we first investigate the resilience
of GLTs against different structure perturbation attacks and observe that they
are highly vulnerable and show a large drop in classification accuracy. Based
on this observation, we then present an adversarially robust graph
sparsification (ARGS) framework that prunes the adjacency matrix and the GNN
weights by optimizing a novel loss function capturing the graph homophily
property and information associated with both the true labels of the train
nodes and the pseudo labels of the test nodes. By iteratively applying ARGS to
prune both the perturbed graph adjacency matrix and the GNN model weights, we
can find adversarially robust graph lottery tickets that are highly sparse yet
achieve competitive performance under different untargeted training-time
structure attacks. Evaluations conducted on various benchmarks, considering
different poisoning structure attacks, namely, PGD, MetaAttack, Meta-PGD, and
PR-BCD demonstrate that the GLTs generated by ARGS can significantly improve
the robustness, even when subjected to high levels of sparsity.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06569" title="Abstract">arXiv:2312.06569</a> [<a href="/pdf/2312.06569" title="Download PDF">pdf</a>, <a href="/format/2312.06569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ambient IoT: A missing link in 3GPP IoT Devices Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butt%2C+M+M">M. Majid Butt</a>, 
<a href="/search/cs?searchtype=author&query=Mangalvedhe%2C+N+R">Nitin R. Mangalvedhe</a>, 
<a href="/search/cs?searchtype=author&query=Pratas%2C+N+K">Nuno K. Pratas</a>, 
<a href="/search/cs?searchtype=author&query=Harrebek%2C+J">Johannes Harrebek</a>, 
<a href="/search/cs?searchtype=author&query=Kimionis%2C+J">John Kimionis</a>, 
<a href="/search/cs?searchtype=author&query=Tayyab%2C+M">Muhammad Tayyab</a>, 
<a href="/search/cs?searchtype=author&query=Barbu%2C+O">Oana-Elena Barbu</a>, 
<a href="/search/cs?searchtype=author&query=Ratasuk%2C+R">Rapeepat Ratasuk</a>, 
<a href="/search/cs?searchtype=author&query=Vejlgaard%2C+B">Benny Vejlgaard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Ambient internet of things (IoT) is the network of devices which harvest
energy from ambient sources for powering their communication. After decades of
research on operation of these devices, Third Generation Partnership Project
(3GPP) has started discussing energy harvesting technology in cellular networks
to support massive deployment of IoT devices at low operational cost. This
article provides a timely update on 3GPP studies on ambient energy harvesting
devices including device types, use cases, key requirements, and related design
challenges. Supported by link budget analysis for backscattering energy
harvesting devices, which are a key component of this study, we provide insight
on system design and show how this technology will require a new system design
approach as compared to New Radio (NR) system design in 5G.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06570" title="Abstract">arXiv:2312.06570</a> [<a href="/pdf/2312.06570" title="Download PDF">pdf</a>, <a href="/format/2312.06570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving the Artifacts of the Early Digital Era: A Study of What, Why  and How?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grzeszczuk%2C+M">Maciej Grzeszczuk</a>, 
<a href="/search/cs?searchtype=author&query=Skorupska%2C+K">Kinga Skorupska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 2 tables. To be published in 11th Machine Intelligence and Digital Interaction MIDI Conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this article, we report the pilot results of a survey study (N=1036)
related to social attitudes towards the early digital heritage. On the basis of
the answers, we consider what constitutes early digital artifacts (EDA) and
outline how knowledge about them can be useful. We explore attitudes toward the
historical and cultural importance of various EDAs and chart the surveyed
requirements for their successful and sustainable preservation for current and
future generations.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06571" title="Abstract">arXiv:2312.06571</a> [<a href="/pdf/2312.06571" title="Download PDF">pdf</a>, <a href="/format/2312.06571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Motion: Grounding GPT-4 in a Humanoid Robot &quot;Alter3&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+T">Takahide Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Masumori%2C+A">Atsushi Masumori</a>, 
<a href="/search/cs?searchtype=author&query=Ikegami%2C+T">Takashi Ikegami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We report the development of Alter3, a humanoid robot capable of generating
spontaneous motion using a Large Language Model (LLM), specifically GPT-4. This
achievement was realized by integrating GPT-4 into our proprietary android,
Alter3, thereby effectively grounding the LLM with Alter's bodily movement.
Typically, low-level robot control is hardware-dependent and falls outside the
scope of LLM corpora, presenting challenges for direct LLM-based robot control.
However, in the case of humanoid robots like Alter3, direct control is feasible
by mapping the linguistic expressions of human actions onto the robot's body
through program code. Remarkably, this approach enables Alter3 to adopt various
poses, such as a 'selfie' stance or 'pretending to be a ghost,' and generate
sequences of actions over time without explicit programming for each body part.
This demonstrates the robot's zero-shot learning capabilities. Additionally,
verbal feedback can adjust poses, obviating the need for fine-tuning. A video
of Alter3's generated motions is available at
https://tnoinkwms.github.io/ALTER-LLM/
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06573" title="Abstract">arXiv:2312.06573</a> [<a href="/pdf/2312.06573" title="Download PDF">pdf</a>, <a href="/format/2312.06573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlNet-XS: Designing an Efficient and Effective Architecture for  Controlling Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zavadski%2C+D">Denis Zavadski</a>, 
<a href="/search/cs?searchtype=author&query=Feiden%2C+J">Johann-Friedrich Feiden</a>, 
<a href="/search/cs?searchtype=author&query=Rother%2C+C">Carsten Rother</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of image synthesis has made tremendous strides forward in the last
years. Besides defining the desired output image with text-prompts, an
intuitive approach is to additionally use spatial guidance in form of an image,
such as a depth map. For this, a recent and highly popular approach is to use a
controlling network, such as ControlNet, in combination with a pre-trained
image generation model, such as Stable Diffusion. When evaluating the design of
existing controlling networks, we observe that they all suffer from the same
problem of a delay in information flowing between the generation and
controlling process. This, in turn, means that the controlling network must
have generative capabilities. In this work we propose a new controlling
architecture, called ControlNet-XS, which does not suffer from this problem,
and hence can focus on the given task of learning to control. In contrast to
ControlNet, our model needs only a fraction of parameters, and hence is about
twice as fast during inference and training time. Furthermore, the generated
images are of higher quality and the control is of higher fidelity. All code
and pre-trained models will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06574" title="Abstract">arXiv:2312.06574</a> [<a href="/pdf/2312.06574" title="Download PDF">pdf</a>, <a href="/format/2312.06574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting the EIP-2930 Optional Access Lists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heimbach%2C+L">Lioba Heimbach</a>, 
<a href="/search/cs?searchtype=author&query=Kniep%2C+Q">Quentin Kniep</a>, 
<a href="/search/cs?searchtype=author&query=Vonlanthen%2C+Y">Yann Vonlanthen</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%BCst%2C+P">Patrick Z&#xfc;st</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Ethereum introduced Transaction Access Lists (TALs) in 2020 to optimize gas
costs during transaction execution. In this work, we present a comprehensive
analysis of TALs in Ethereum, focusing on adoption, quality, and gas savings.
Analyzing a full month of mainnet data with 31,954,474 transactions, we found
that only 1.46% of transactions included a TAL, even though 42.6% of
transactions would have benefited from it. On average, access lists can save
around 0.29% of gas costs, equivalent to approximately 3,450 ETH (roughly US$ 5
Mio) per year. However, 19.6% of TALs included by transactions contained
imperfections, causing almost 11.8% of transactions to pay more gas with TAL
than without. We find that these inaccuracies are caused by the unknown state
at the time of the TAL computation as well as imperfect TAL computations
provided by all major Ethereum clients. We thus compare the gas savings when
calculating the TAL at the beginning of the block vs. calculating it on the
correct state, to find that the unknown state is a major source of TAL
inaccuracies. Finally, we implement an ideal TAL computation for the Erigon
client to highlight the cost of these flawed implementations.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06575" title="Abstract">arXiv:2312.06575</a> [<a href="/pdf/2312.06575" title="Download PDF">pdf</a>, <a href="/format/2312.06575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyVolcap: Accelerating Neural Volumetric Video Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sida Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haotong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+Q">Qing Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guangzhao He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiaming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Hujun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 Technical Communications. Source code: <a href="https://github.com/zju3dv/EasyVolcap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Volumetric video is a technology that digitally records dynamic events such
as artistic performances, sporting events, and remote conversations. When
acquired, such volumography can be viewed from any viewpoint and timestamp on
flat screens, 3D displays, or VR headsets, enabling immersive viewing
experiences and more flexible content creation in a variety of applications
such as sports broadcasting, video conferencing, gaming, and movie productions.
With the recent advances and fast-growing interest in neural scene
representations for volumetric video, there is an urgent need for a unified
open-source library to streamline the process of volumetric video capturing,
reconstruction, and rendering for both researchers and non-professional users
to develop various algorithms and applications of this emerging technology. In
this paper, we present EasyVolcap, a Python &amp; Pytorch library for accelerating
neural volumetric video research with the goal of unifying the process of
multi-view data processing, 4D scene reconstruction, and efficient dynamic
volumetric video rendering. Our source code is available at
https://github.com/zju3dv/EasyVolcap.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06576" title="Abstract">arXiv:2312.06576</a> [<a href="/pdf/2312.06576" title="Download PDF">pdf</a>, <a href="/format/2312.06576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyPE-GT: where Graph Transformers meet Hyperbolic Positional Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+K">Kushal Bose</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Swagatam Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Transformers (GTs) facilitate the comprehension of graph-structured
data by calculating the self-attention of node pairs without considering node
position information. To address this limitation, we introduce an innovative
and efficient framework that introduces Positional Encodings (PEs) into the
Transformer, generating a set of learnable positional encodings in the
hyperbolic space, a non-Euclidean domain. This approach empowers us to explore
diverse options for optimal selection of PEs for specific downstream tasks,
leveraging hyperbolic neural networks or hyperbolic graph convolutional
networks. Additionally, we repurpose these positional encodings to mitigate the
impact of over-smoothing in deep Graph Neural Networks (GNNs). Comprehensive
experiments on molecular benchmark datasets, co-author, and co-purchase
networks substantiate the effectiveness of hyperbolic positional encodings in
enhancing the performance of deep GNNs.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06578" title="Abstract">arXiv:2312.06578</a> [<a href="/pdf/2312.06578" title="Download PDF">pdf</a>, <a href="/format/2312.06578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-class Support Vector Machine with Maximizing Minimum Margin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+F">Feiping Nie</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhezheng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Support Vector Machine (SVM) stands out as a prominent machine learning
technique widely applied in practical pattern recognition tasks. It achieves
binary classification by maximizing the "margin", which represents the minimum
distance between instances and the decision boundary. Although many efforts
have been dedicated to expanding SVM for multi-class case through strategies
such as one versus one and one versus the rest, satisfactory solutions remain
to be developed. In this paper, we propose a novel method for multi-class SVM
that incorporates pairwise class loss considerations and maximizes the minimum
margin. Adhering to this concept, we embrace a new formulation that imparts
heightened flexibility to multi-class SVM. Furthermore, the correlations
between the proposed method and multiple forms of multi-class SVM are analyzed.
The proposed regularizer, akin to the concept of "margin", can serve as a
seamless enhancement over the softmax in deep learning, providing guidance for
network parameter learning. Empirical evaluations demonstrate the effectiveness
and superiority of our proposed method over existing multi-classification
methods.Code is available at https://github.com/zz-haooo/M3SVM.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06580" title="Abstract">arXiv:2312.06580</a> [<a href="/pdf/2312.06580" title="Download PDF">pdf</a>, <a href="/ps/2312.06580" title="Download PostScript">ps</a>, <a href="/format/2312.06580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VGF: Value-Guided Fuzzing -- Fuzzing Hardware as Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+R">Ruochen Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Michael Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hoey%2C+P">Patrick Hoey</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Weimin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+T">Tuba Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaolong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+D">Dean Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Arias%2C+O">Orlando Arias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">As the complexity of logic designs increase, new avenues for testing digital
hardware becomes necessary. Fuzz Testing (fuzzing) has recently received
attention as a potential candidate for input vector generation on hardware
designs. Using this technique, a fuzzer is used to generate an input to a logic
design. Using a simulation engine, the logic design is given the generated
stimulus and some metric of feedback is given to the fuzzer to aid in the input
mutation. However, much like software fuzzing, hardware fuzzing uses code
coverage as a metric to find new possible fuzzing paths. Unfortunately, as we
show in this work, this coverage metric falls short of generic on some hardware
designs where designers have taken a more direct approach at expressing a
particular microarchitecture, or implementation, of the desired hardware.
<br />With this work, we introduce a new coverage metric which employs not code
coverage, but state coverage internal to a design. By observing changes in
signals within the logic circuit under testing, we are able to explore the
state space of the design and provide feedback to a fuzzer engine for input
generation. Our approach, Value-Guided Fuzzing (VGF), provides a generic metric
of coverage which can be applied to any design regardless of its
implementation. In this paper, we introduce our state-based VGF metric as well
as a sample implementation which can be used with any VPI, DPI, VHPI, or FLI
compliant simulator, making it completely HDL agnostic. We demonstrate the
generality of VGF and show how our sample implementation is capable of finding
bugs considerably faster than previous approaches.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06581" title="Abstract">arXiv:2312.06581</a> [<a href="/pdf/2312.06581" title="Download PDF">pdf</a>, <a href="/format/2312.06581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grokking Group Multiplication with Cosets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stander%2C+D">Dashiell Stander</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Honglu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Biderman%2C+S">Stella Biderman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Representation Theory (math.RT)

</div>
<p class="mathjax">We use the group Fourier transform over the symmetric group $S_n$ to reverse
engineer a 1-layer feedforward network that has "grokked" the multiplication of
$S_5$ and $S_6$. Each model discovers the true subgroup structure of the full
group and converges on circuits that decompose the group multiplication into
the multiplication of the group's conjugate subgroups. We demonstrate the value
of using the symmetries of the data and models to understand their mechanisms
and hold up the ``coset circuit'' that the model uses as a fascinating example
of the way neural networks implement computations. We also draw attention to
current challenges in conducting mechanistic interpretability research by
comparing our work to Chughtai et al. [6] which alleges to find a different
algorithm for this same problem.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06582" title="Abstract">arXiv:2312.06582</a> [<a href="/pdf/2312.06582" title="Download PDF">pdf</a>, <a href="/ps/2312.06582" title="Download PostScript">ps</a>, <a href="/format/2312.06582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing hosting capacity analysis in distribution networks:  Practical considerations, advancements and future directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+U">U. Singh</a>, 
<a href="/search/eess?searchtype=author&query=Al-Durra%2C+A">A. Al-Durra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, 5 tables, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Hosting capacity analysis is essential for effective integration of
distributed energy resources into distribution systems. This paper discusses
hosting capacity analysis with emphasis on various aspects affecting the
process. This paper addresses key research gaps, aiming to improve the
accuracy, scalability, and practicality of hosting capacity estimation.
Standardized methodologies are highlighted as a need to ensure consistent
hosting capacity estimation across distribution systems. Validation and
benchmarking frameworks are emphasized for evaluating various estimation
approaches. The potential of data-driven techniques, is also discussed for
enhancing hosting capacity analysis. Real-time and dynamic estimation
techniques which account for changing system conditions are explored, as well
as the integration of hosting capacity analysis with distribution planning and
operations. Uncertainty quantification and risk assessment in hosting capacity
analysis are identified as crucial areas, advocating for probabilistic and
stochastic modelling. This study also emphasizes the importance of considering
multiple DER interactions and synergies in hosting capacity analysis, enabling
a comprehensive understanding of system performance. This survey aims to serve
as a valuable resource for researchers, practitioners, and policymakers,
providing insights into advancements made and guiding future research efforts
to address identified gaps.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06583" title="Abstract">arXiv:2312.06583</a> [<a href="/pdf/2312.06583" title="Download PDF">pdf</a>, <a href="/format/2312.06583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Hand Pose Estimation in Egocentric Images in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Aditya Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+R">Ruisen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Matthew Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saurabh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ap229997.github.io/projects/hands/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">We present WildHands, a method for 3D hand pose estimation in egocentric
images in the wild. This is challenging due to (a) lack of 3D hand pose
annotations for images in the wild, and (b) a form of perspective
distortion-induced shape ambiguity that arises in the analysis of crops around
hands. For the former, we use auxiliary supervision on in-the-wild data in the
form of segmentation masks &amp; grasp labels in addition to 3D supervision
available in lab datasets. For the latter, we provide spatial cues about the
location of the hand crop in the camera's field of view. Our approach achieves
the best 3D hand pose on the ARCTIC leaderboard and outperforms FrankMocap, a
popular and robust approach for estimating hand pose in the wild, by 45.3% when
evaluated on 2D hand pose on our EPIC-HandKps dataset.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06585" title="Abstract">arXiv:2312.06585</a> [<a href="/pdf/2312.06585" title="Download PDF">pdf</a>, <a href="/format/2312.06585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Human Data: Scaling Self-Training for Problem-Solving with  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Avi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Co-Reyes%2C+J+D">John D. Co-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ankesh Anand</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+P">Piyush Patil</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+J">James Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kelvin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Parisi%2C+A">Aaron Parisi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Alemi%2C+A">Alex Alemi</a>, 
<a href="/search/cs?searchtype=author&query=Rizkowsky%2C+A">Alex Rizkowsky</a>, 
<a href="/search/cs?searchtype=author&query=Nova%2C+A">Azade Nova</a>, 
<a href="/search/cs?searchtype=author&query=Adlam%2C+B">Ben Adlam</a>, 
<a href="/search/cs?searchtype=author&query=Bohnet%2C+B">Bernd Bohnet</a>, 
<a href="/search/cs?searchtype=author&query=Sedghi%2C+H">Hanie Sedghi</a>, 
<a href="/search/cs?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+I">Isabelle Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+I">Izzeddin Gur</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+J">Jasper Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Pennington%2C+J">Jeffrey Pennington</a>, 
<a href="/search/cs?searchtype=author&query=Hron%2C+J">Jiri Hron</a>, 
<a href="/search/cs?searchtype=author&query=Kenealy%2C+K">Kathleen Kenealy</a>, 
<a href="/search/cs?searchtype=author&query=Swersky%2C+K">Kevin Swersky</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+K">Kshiteej Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Culp%2C+L">Laura Culp</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lechao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Bileschi%2C+M+L">Maxwell L. Bileschi</a>, 
<a href="/search/cs?searchtype=author&query=Constant%2C+N">Noah Constant</a>, 
<a href="/search/cs?searchtype=author&query=Novak%2C+R">Roman Novak</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rosanne Liu</a>, 
<a href="/search/cs?searchtype=author&query=Warkentin%2C+T">Tris Warkentin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yundi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Dyer%2C+E">Ethan Dyer</a>, 
<a href="/search/cs?searchtype=author&query=Neyshabur%2C+B">Behnam Neyshabur</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-Dickstein%2C+J">Jascha Sohl-Dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Fiedel%2C+N">Noah Fiedel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First three authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fine-tuning language models~(LMs) on human-generated data remains a prevalent
practice. However, the performance of such models is often limited by the
quantity and diversity of high-quality human data. In this paper, we explore
whether we can go beyond human data on tasks where we have access to scalar
feedback, for example, on math problems where one can verify correctness. To do
so, we investigate a simple self-training method based on
expectation-maximization, which we call ReST$^{EM}$, where we (1) generate
samples from the model and filter them using binary feedback, (2) fine-tune the
model on these samples, and (3) repeat this process a few times. Testing on
advanced MATH reasoning and APPS coding benchmarks using PaLM-2 models, we find
that ReST$^{EM}$ scales favorably with model size and significantly surpasses
fine-tuning only on human data. Overall, our findings suggest self-training
with feedback can substantially reduce dependence on human-generated data.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06592" title="Abstract">arXiv:2312.06592</a> [<a href="/pdf/2312.06592" title="Download PDF">pdf</a>, <a href="/format/2312.06592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible visual prompts for in-context learning in computer vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foster%2C+T">Thomas Foster</a>, 
<a href="/search/cs?searchtype=author&query=Croitoru%2C+I">Ioana Croitoru</a>, 
<a href="/search/cs?searchtype=author&query=Dorfman%2C+R">Robert Dorfman</a>, 
<a href="/search/cs?searchtype=author&query=Edlund%2C+C">Christoffer Edlund</a>, 
<a href="/search/cs?searchtype=author&query=Varsavsky%2C+T">Thomas Varsavsky</a>, 
<a href="/search/cs?searchtype=author&query=Almaz%C3%A1n%2C+J">Jon Almaz&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we address in-context learning (ICL) for the task of image
segmentation, introducing a novel approach that adapts a modern Video Object
Segmentation (VOS) technique for visual in-context learning. This adaptation is
inspired by the VOS method's ability to efficiently and flexibly learn objects
from a few examples. Through evaluations across a range of support set sizes
and on diverse segmentation datasets, our method consistently surpasses
existing techniques. Notably, it excels with data containing classes not
encountered during training. Additionally, we propose a technique for support
set selection, which involves choosing the most relevant images to include in
this set. By employing support set selection, the performance increases for all
tested methods without the need for additional training or prompt tuning. The
code can be found at https://github.com/v7labs/XMem_ICL/.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06594" title="Abstract">arXiv:2312.06594</a> [<a href="/pdf/2312.06594" title="Download PDF">pdf</a>, <a href="/format/2312.06594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Perspective Distortion-induced Shape Ambiguity in Image Crops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Aditya Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arjun Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saurabh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://ap229997.github.io/projects/ambiguity/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Objects undergo varying amounts of perspective distortion as they move across
a camera's field of view. Models for predicting 3D from a single image often
work with crops around the object of interest and ignore the location of the
object in the camera's field of view. We note that ignoring this location
information further exaggerates the inherent ambiguity in making 3D inferences
from 2D images and can prevent models from even fitting to the training data.
To mitigate this ambiguity, we propose Intrinsics-Aware Positional Encoding
(KPE), which incorporates information about the location of crops in the image
and camera intrinsics. Experiments on three popular 3D-from-a-single-image
benchmarks: depth prediction on NYU, 3D object detection on KITTI &amp; nuScenes,
and predicting 3D shapes of articulated objects on ARCTIC, show the benefits of
KPE.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06598" title="Abstract">arXiv:2312.06598</a> [<a href="/pdf/2312.06598" title="Download PDF">pdf</a>, <a href="/format/2312.06598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Action Recognition with Action Prototypes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camporese%2C+G">Guglielmo Camporese</a>, 
<a href="/search/cs?searchtype=author&query=Bergamo%2C+A">Alessandro Bergamo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xunyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tighe%2C+J">Joseph Tighe</a>, 
<a href="/search/cs?searchtype=author&query=Modolo%2C+D">Davide Modolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Early action recognition is an important and challenging problem that enables
the recognition of an action from a partially observed video stream where the
activity is potentially unfinished or even not started. In this work, we
propose a novel model that learns a prototypical representation of the full
action for each class and uses it to regularize the architecture and the visual
representations of the partial observations. Our model is very simple in design
and also efficient. We decompose the video into short clips, where a visual
encoder extracts features from each clip independently. Later, a decoder
aggregates together in an online fashion features from all the clips for the
final class prediction. During training, for each partial observation, the
model is jointly trained to both predict the label as well as the action
prototypical representation which acts as a regularizer. We evaluate our method
on multiple challenging real-world datasets and outperform the current
state-of-the-art by a significant margin. For example, on early recognition
observing only the first 10% of each video, our method improves the SOTA by
+2.23 Top-1 accuracy on Something-Something-v2, +3.55 on UCF-101, +3.68 on
SSsub21, and +5.03 on EPIC-Kitchens-55, where prior work used either
multi-modal inputs (e.g. optical-flow) or batched inference. Finally, we also
present exhaustive ablation studies to motivate the design choices we made, as
well as gather insights regarding what our model is learning semantically.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06607" title="Abstract">arXiv:2312.06607</a> [<a href="/pdf/2312.06607" title="Download PDF">pdf</a>, <a href="/format/2312.06607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiAD: A Diffusion-based Framework for Multi-class Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyang He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstruction-based approaches have achieved remarkable outcomes in anomaly
detection. The exceptional image reconstruction capabilities of recently
popular diffusion models have sparked research efforts to utilize them for
enhanced reconstruction of anomalous images. Nonetheless, these methods might
face challenges related to the preservation of image categories and pixel-wise
structural integrity in the more practical multi-class setting. To solve the
above problems, we propose a Difusion-based Anomaly Detection (DiAD) framework
for multi-class anomaly detection, which consists of a pixel-space autoencoder,
a latent-space Semantic-Guided (SG) network with a connection to the stable
diffusion's denoising network, and a feature-space pre-trained feature
extractor. Firstly, The SG network is proposed for reconstructing anomalous
regions while preserving the original image's semantic information. Secondly,
we introduce Spatial-aware Feature Fusion (SFF) block to maximize
reconstruction accuracy when dealing with extensively reconstructed areas.
Thirdly, the input and reconstructed images are processed by a pre-trained
feature extractor to generate anomaly maps based on features extracted at
different scales. Experiments on MVTec-AD and VisA datasets demonstrate the
effectiveness of our approach which surpasses the state-of-the-art methods,
e.g., achieving 96.8/52.6 and 97.2/99.0 (AUROC/AP) for localization and
detection respectively on multi-class MVTec-AD dataset. Code will be available
at https://lewandofskee.github.io/projects/diad.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06609" title="Abstract">arXiv:2312.06609</a> [<a href="/pdf/2312.06609" title="Download PDF">pdf</a>, <a href="/format/2312.06609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finer characterization of bounded languages described by GF(2)-grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makarov%2C+V">Vladislav Makarov</a>, 
<a href="/search/cs?searchtype=author&query=Movsin%2C+M">Marat Movsin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">GF(2)-grammars are a somewhat recently introduced grammar family that have
some unusual algebraic properties and are closely connected to unambiguous
grammars. In "Bounded languages described by GF(2)-grammars", Makarov proved a
necessary condition for subsets of $a_1^* a_2^* \cdots a_k^*$ to be described
by some GF(2)-grammar. By extending these methods further, we prove an even
stronger upper bound for these languages. Moreover, we establish a lower bound
that closely matches the proven upper bound. Also, we prove the exact
characterization for the special case of linear GF(2)-grammars. Finally, by
using the previous result, we show that the class of languages described by
linear GF(2)-grammars is not closed under GF(2)-concatenation
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06613" title="Abstract">arXiv:2312.06613</a> [<a href="/pdf/2312.06613" title="Download PDF">pdf</a>, <a href="/format/2312.06613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Text to Articulate Talk: Deep Text to Audiovisual Speech  Synthesis achieving both Auditory and Photo-realism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milis%2C+G">Georgios Milis</a>, 
<a href="/search/cs?searchtype=author&query=Filntisis%2C+P+P">Panagiotis P. Filntisis</a>, 
<a href="/search/cs?searchtype=author&query=Roussos%2C+A">Anastasios Roussos</a>, 
<a href="/search/cs?searchtype=author&query=Maragos%2C+P">Petros Maragos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent advances in deep learning for sequential data have given rise to fast
and powerful models that produce realistic videos of talking humans. The state
of the art in talking face generation focuses mainly on lip-syncing, being
conditioned on audio clips. However, having the ability to synthesize talking
humans from text transcriptions rather than audio is particularly beneficial
for many applications and is expected to receive more and more attention,
following the recent breakthroughs in large language models. For that, most
methods implement a cascaded 2-stage architecture of a text-to-speech module
followed by an audio-driven talking face generator, but this ignores the highly
complex interplay between audio and visual streams that occurs during speaking.
In this paper, we propose the first, to the best of our knowledge, text-driven
audiovisual speech synthesizer that uses Transformers and does not follow a
cascaded approach. Our method, which we call NEUral Text to ARticulate Talk
(NEUTART), is a talking face generator that uses a joint audiovisual feature
space, as well as speech-informed 3D facial reconstructions and a lip-reading
loss for visual supervision. The proposed model produces photorealistic talking
face videos with human-like articulation and well-synced audiovisual streams.
Our experiments on audiovisual datasets as well as in-the-wild videos reveal
state-of-the-art generation quality both in terms of objective metrics and
human evaluation.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06614" title="Abstract">arXiv:2312.06614</a> [<a href="/pdf/2312.06614" title="Download PDF">pdf</a>, <a href="/format/2312.06614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttenScribble: Attentive Similarity Learning for Scribble-Supervised  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Mu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qinzhu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, a modified version was submitted to Computerized Medical Imaging and Graphics and is under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The success of deep networks in medical image segmentation relies heavily on
massive labeled training data. However, acquiring dense annotations is a
time-consuming process. Weakly-supervised methods normally employ less
expensive forms of supervision, among which scribbles started to gain
popularity lately thanks to its flexibility. However, due to lack of shape and
boundary information, it is extremely challenging to train a deep network on
scribbles that generalizes on unlabeled pixels. In this paper, we present a
straightforward yet effective scribble supervised learning framework. Inspired
by recent advances of transformer based segmentation, we create a pluggable
spatial self-attention module which could be attached on top of any internal
feature layers of arbitrary fully convolutional network (FCN) backbone. The
module infuses global interaction while keeping the efficiency of convolutions.
Descended from this module, we construct a similarity metric based on
normalized and symmetrized attention. This attentive similarity leads to a
novel regularization loss that imposes consistency between segmentation
prediction and visual affinity. This attentive similarity loss optimizes the
alignment of FCN encoders, attention mapping and model prediction. Ultimately,
the proposed FCN+Attention architecture can be trained end-to-end guided by a
combination of three learning objectives: partial segmentation loss, a
customized masked conditional random fields and the proposed attentive
similarity loss. Extensive experiments on public datasets (ACDC and CHAOS)
showed that our framework not just out-performs existing state-of-the-art, but
also delivers close performance to fully-supervised benchmark. Code will be
available upon publication.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06616" title="Abstract">arXiv:2312.06616</a> [<a href="/pdf/2312.06616" title="Download PDF">pdf</a>, <a href="/format/2312.06616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The built environment and induced transport CO2 emissions: A double  machine learning approach to account for residential self-selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nachtigall%2C+F">Florian Nachtigall</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+F">Felix Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Berrill%2C+P">Peter Berrill</a>, 
<a href="/search/cs?searchtype=author&query=Creutzig%2C+F">Felix Creutzig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop 'Tackling Climate Change with Machine Learning' - Spotlight Talk
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Physics and Society (physics.soc-ph); Methodology (stat.ME)

</div>
<p class="mathjax">Understanding why travel behavior differs between residents of urban centers
and suburbs is key to sustainable urban planning. Especially in light of rapid
urban growth, identifying housing locations that minimize travel demand and
induced CO2 emissions is crucial to mitigate climate change. While the built
environment plays an important role, the precise impact on travel behavior is
obfuscated by residential self-selection. To address this issue, we propose a
double machine learning approach to obtain unbiased, spatially-explicit
estimates of the effect of the built environment on travel-related CO2
emissions for each neighborhood by controlling for residential self-selection.
We examine how socio-demographics and travel-related attitudes moderate the
effect and how it decomposes across the 5Ds of the built environment. Based on
a case study for Berlin and the travel diaries of 32,000 residents, we find
that the built environment causes household travel-related CO2 emissions to
differ by a factor of almost two between central and suburban neighborhoods in
Berlin. To highlight the practical importance for urban climate mitigation, we
evaluate current plans for 64,000 new residential units in terms of total
induced transport CO2 emissions. Our findings underscore the significance of
spatially differentiated compact development to decarbonize the transport
sector.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06622" title="Abstract">arXiv:2312.06622</a> [<a href="/pdf/2312.06622" title="Download PDF">pdf</a>, <a href="/ps/2312.06622" title="Download PostScript">ps</a>, <a href="/format/2312.06622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search and Rescue on a Poset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brethouwer%2C+J">Jan-Tino Brethouwer</a>, 
<a href="/search/cs?searchtype=author&query=Fokkink%2C+R">Robbert Fokkink</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">A Search and Rescue game (SR game) is a new type of game on a graph that has
quickly found applications in scheduling, object detection, and adaptive
search. In this paper, we broaden the definition of SR games by putting them
into the context of ordered sets and Bayesian networks, extending known
solutions of these games and opening up the way to further applications.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06624" title="Abstract">arXiv:2312.06624</a> [<a href="/pdf/2312.06624" title="Download PDF">pdf</a>, <a href="/format/2312.06624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How To Program Your Own Quantum Computer or QUBE: QUantum computing for  BEginners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+M+N+P">Martin N. P. Nilsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Do you think you need to know quantum physics to understand how a quantum
computer works? Nope, no worries there. You don't need a deep dive into physics
or mathematics, just a bit of familiarity with vectors and matrix
multiplication. That's really it. A good handle on Python programming and a few
numpy functions will do the trick, specifically reshape(), kron(), matmul(),
swapaxes(), linalg.norm(), and random.choice(). In fact, an appendix shows that
twelve lines of Python code suffice to define a complete simulator.
<br />The whole point of this article is to give you an informal, brief, hopefully
digestible and educational description of how you can easily implement your own
quantum computer simulator. It's not about `Yet Another Quantum Computer
Simulator' (YAQCS?), which are a dime a dozen, but about how to build your own.
And, honestly, there's probably no better way to learn how a quantum computer
works!
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06625" title="Abstract">arXiv:2312.06625</a> [<a href="/pdf/2312.06625" title="Download PDF">pdf</a>, <a href="/format/2312.06625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Mean Field Games from Population and Environment Observations  By Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jinyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chenchen Mou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xianjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper presents a Gaussian Process (GP) framework, a non-parametric
technique widely acknowledged for regression and classification tasks, to
address inverse problems in mean field games (MFGs). By leveraging GPs, we aim
to recover agents' strategic actions and the environment's configurations from
partial and noisy observations of the population of agents and the setup of the
environment. Our method is a probabilistic tool to infer the behaviors of
agents in MFGs from data in scenarios where the comprehensive dataset is either
inaccessible or contaminated by noises.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06627" title="Abstract">arXiv:2312.06627</a> [<a href="/pdf/2312.06627" title="Download PDF">pdf</a>, <a href="/ps/2312.06627" title="Download PostScript">ps</a>, <a href="/format/2312.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adversarial attack approach for eXplainable AI evaluation on deepfake  detection models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gowrisankar%2C+B">Balachandar Gowrisankar</a>, 
<a href="/search/cs?searchtype=author&query=Thing%2C+V+L+L">Vrizlynn L.L. Thing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">With the rising concern on model interpretability, the application of
eXplainable AI (XAI) tools on deepfake detection models has been a topic of
interest recently. In image classification tasks, XAI tools highlight pixels
influencing the decision given by a model. This helps in troubleshooting the
model and determining areas that may require further tuning of parameters. With
a wide range of tools available in the market, choosing the right tool for a
model becomes necessary as each one may highlight different sets of pixels for
a given image. There is a need to evaluate different tools and decide the best
performing ones among them. Generic XAI evaluation methods like insertion or
removal of salient pixels/segments are applicable for general image
classification tasks but may produce less meaningful results when applied on
deepfake detection models due to their functionality. In this paper, we perform
experiments to show that generic removal/insertion XAI evaluation methods are
not suitable for deepfake detection models. We also propose and implement an
XAI evaluation approach specifically suited for deepfake detection models.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06630" title="Abstract">arXiv:2312.06630</a> [<a href="/pdf/2312.06630" title="Download PDF">pdf</a>, <a href="/format/2312.06630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMT-VIS: Taxonomy-aware Multi-dataset Joint Training for Video Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rongkun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training on large-scale datasets can boost the performance of video instance
segmentation while the annotated datasets for VIS are hard to scale up due to
the high labor cost. What we possess are numerous isolated filed-specific
datasets, thus, it is appealing to jointly train models across the aggregation
of datasets to enhance data volume and diversity. However, due to the
heterogeneity in category space, as mask precision increases with the data
volume, simply utilizing multiple datasets will dilute the attention of models
on different taxonomies. Thus, increasing the data scale and enriching taxonomy
space while improving classification precision is important. In this work, we
analyze that providing extra taxonomy information can help models concentrate
on specific taxonomy, and propose our model named Taxonomy-aware Multi-dataset
Joint Training for Video Instance Segmentation (TMT-VIS) to address this vital
challenge. Specifically, we design a two-stage taxonomy aggregation module that
first compiles taxonomy information from input videos and then aggregates these
taxonomy priors into instance queries before the transformer decoder. We
conduct extensive experimental evaluations on four popular and challenging
benchmarks, including YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and UVO. Our
model shows significant improvement over the baseline solutions, and sets new
state-of-the-art records on all benchmarks. These appealing and encouraging
results demonstrate the effectiveness and generality of our approach. The code
is available at
https://github.com/rkzheng99/TMT-VIS(https://github.com/rkzheng99/TMT-VIS)
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06632" title="Abstract">arXiv:2312.06632</a> [<a href="/pdf/2312.06632" title="Download PDF">pdf</a>, <a href="/format/2312.06632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Risk for Potential Misuse of Artificial Intelligence in Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiyan He</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Weitao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Y">Yaosen Min</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kunsheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenbo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuxin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The expanding application of Artificial Intelligence (AI) in scientific
fields presents unprecedented opportunities for discovery and innovation.
However, this growth is not without risks. AI models in science, if misused,
can amplify risks like creation of harmful substances, or circumvention of
established regulations. In this study, we aim to raise awareness of the
dangers of AI misuse in science, and call for responsible AI development and
use in this domain. We first itemize the risks posed by AI in scientific
contexts, then demonstrate the risks by highlighting real-world examples of
misuse in chemical science. These instances underscore the need for effective
risk management strategies. In response, we propose a system called SciGuard to
control misuse risks for AI models in science. We also propose a red-teaming
benchmark SciMT-Safety to assess the safety of different systems. Our proposed
SciGuard shows the least harmful impact in the assessment without compromising
performance in benign tests. Finally, we highlight the need for a
multidisciplinary and collaborative effort to ensure the safe and ethical use
of AI models in science. We hope that our study can spark productive
discussions on using AI ethically in science among researchers, practitioners,
policymakers, and the public, to maximize benefits and minimize the risks of
misuse.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06633" title="Abstract">arXiv:2312.06633</a> [<a href="/pdf/2312.06633" title="Download PDF">pdf</a>, <a href="/ps/2312.06633" title="Download PostScript">ps</a>, <a href="/format/2312.06633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Effect of Implementation Factors on Deep Learning  Reproducibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coakley%2C+K">Kevin Coakley</a>, 
<a href="/search/cs?searchtype=author&query=Kirkpatrick%2C+C+R">Christine R. Kirkpatrick</a>, 
<a href="/search/cs?searchtype=author&query=Gundersen%2C+O+E">Odd Erik Gundersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Reproducing published deep learning papers to validate their conclusions can
be difficult due to sources of irreproducibility. We investigate the impact
that implementation factors have on the results and how they affect
reproducibility of deep learning studies. Three deep learning experiments were
ran five times each on 13 different hardware environments and four different
software environments. The analysis of the 780 combined results showed that
there was a greater than 6% accuracy range on the same deterministic examples
introduced from hardware or software environment variations alone. To account
for these implementation factors, researchers should run their experiments
multiple times in different hardware and software environments to verify their
conclusions are not affected.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06634" title="Abstract">arXiv:2312.06634</a> [<a href="/pdf/2312.06634" title="Download PDF">pdf</a>, <a href="/format/2312.06634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Bifurcation Analysis via Learning of Homeomorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+W">Wentao Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, submitted to the 6th Annual Learning for Dynamics and Control (L4DC) Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">This work proposes a data-driven approach for bifurcation analysis in
nonlinear systems when the governing differential equations are not available.
Specifically, regularized regression with barrier terms is used to learn a
homeomorphism that transforms the underlying system to a reference linear
dynamics -- either an explicit reference model with desired qualitative
behavior, or Koopman eigenfunctions that are identified from some system data
under a reference parameter value. When such a homeomorphism fails to be
constructed with low error, bifurcation phenomenon is detected. A case study is
performed on a planar numerical example where a pitchfork bifurcation exists.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06635" title="Abstract">arXiv:2312.06635</a> [<a href="/pdf/2312.06635" title="Download PDF">pdf</a>, <a href="/format/2312.06635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gated Linear Attention Transformers with Hardware-Efficient Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+R">Rameswar Panda</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Transformers with linear attention allow for efficient parallel training but
can simultaneously be formulated as an RNN with 2D (matrix-valued) hidden
states, thus enjoying linear (with respect to output length) inference
complexity. Recent works such as RetNet (Sun et al., 2023) and TransNormerLLM
(Qin et al., 2023a) observe that adding a global decay term to the additive RNN
update rule greatly improves performance, sometimes outperforming standard
Transformers with softmax attention when trained at scale. In this work we show
that adding a data-dependent gating mechanism further improves performance. We
derive a parallel form of this gated linear attention layer that enables
efficient training. However, a straightforward, numerically stable
implementation of this parallel form requires generalized matrix
multiplications in log-space for numerical stability, and thus cannot take
advantage of tensor cores on modern GPUs which are optimized for standard
matrix multiplications. We develop a hardware-efficient version of the parallel
form that can still make use of tensor cores through block-parallel
computations over sequence chunks. Experiments on moderate-scale language
modeling (340M-parameter models trained on 15B tokens, 1.3B-parameter models
trained on 100B tokens) show that gated linear attention (GLA) Transformers
perform competitively against a strong LLaMA-architecture Transformer baseline
(Touvron et al., 2023) as well as Mamba (Gu &amp; Dao, 2023), a recently introduced
state-space model with a data-dependent state transition mechanism. For
training speed, our Triton-based implementation performs comparably to
CUDA-optimized FlashAttention-2 (Dao, 2023) under the regular 2048 training
length setting, while outperforming FlashAttention-2 when training on longer
sequences beyond 4096.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06638" title="Abstract">arXiv:2312.06638</a> [<a href="/pdf/2312.06638" title="Download PDF">pdf</a>, <a href="/format/2312.06638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SurvBeNIM: The Beran-Based Neural Importance Model for Explaining the  Survival Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Utkin%2C+L+V">Lev V. Utkin</a>, 
<a href="/search/cs?searchtype=author&query=Eremenko%2C+D+Y">Danila Y. Eremenko</a>, 
<a href="/search/cs?searchtype=author&query=Konstantinov%2C+A+V">Andrei V. Konstantinov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">A new method called the Survival Beran-based Neural Importance Model
(SurvBeNIM) is proposed. It aims to explain predictions of machine learning
survival models, which are in the form of survival or cumulative hazard
functions. The main idea behind SurvBeNIM is to extend the Beran estimator by
incorporating the importance functions into its kernels and by implementing
these importance functions as a set of neural networks which are jointly
trained in an end-to-end manner. Two strategies of using and training the whole
neural network implementing SurvBeNIM are proposed. The first one explains a
single instance, and the neural network is trained for each explained instance.
According to the second strategy, the neural network only learns once on all
instances from the dataset and on all generated instances. Then the neural
network is used to explain any instance in a dataset domain. Various numerical
experiments compare the method with different existing explanation methods. A
code implementing the proposed method is publicly available.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06639" title="Abstract">arXiv:2312.06639</a> [<a href="/pdf/2312.06639" title="Download PDF">pdf</a>, <a href="/format/2312.06639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic Mobile Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruihan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yejin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ehsani%2C+K">Kiana Ehsani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More results are on our project site: <a href="https://rchalyang.github.io/HarmonicMM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in robotics have enabled robots to navigate complex
scenes or manipulate diverse objects independently. However, robots are still
impotent in many household tasks requiring coordinated behaviors such as
opening doors. The factorization of navigation and manipulation, while
effective for some tasks, fails in scenarios requiring coordinated actions. To
address this challenge, we introduce, HarmonicMM, an end-to-end learning method
that optimizes both navigation and manipulation, showing notable improvement
over existing techniques in everyday tasks. This approach is validated in
simulated and real-world environments and adapts to novel unseen settings
without additional tuning. Our contributions include a new benchmark for mobile
manipulation and the successful deployment in a real unseen apartment,
demonstrating the potential for practical indoor robot deployment in daily
life. More results are on our project site:
https://rchalyang.github.io/HarmonicMM/
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06640" title="Abstract">arXiv:2312.06640</a> [<a href="/pdf/2312.06640" title="Download PDF">pdf</a>, <a href="/format/2312.06640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World  Video Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shangchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peiqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yihang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Equal contributions from first two authors. Project page: <a href="https://shangchenzhou.com/projects/upscale-a-video/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-based diffusion models have exhibited remarkable success in generation
and editing, showing great promise for enhancing visual content with their
generative prior. However, applying these models to video super-resolution
remains challenging due to the high demands for output fidelity and temporal
consistency, which is complicated by the inherent randomness in diffusion
models. Our study introduces Upscale-A-Video, a text-guided latent diffusion
framework for video upscaling. This framework ensures temporal coherence
through two key mechanisms: locally, it integrates temporal layers into U-Net
and VAE-Decoder, maintaining consistency within short sequences; globally,
without training, a flow-guided recurrent latent propagation module is
introduced to enhance overall video stability by propagating and fusing latent
across the entire sequences. Thanks to the diffusion paradigm, our model also
offers greater flexibility by allowing text prompts to guide texture creation
and adjustable noise levels to balance restoration and generation, enabling a
trade-off between fidelity and quality. Extensive experiments show that
Upscale-A-Video surpasses existing methods in both synthetic and real-world
benchmarks, as well as in AI-generated videos, showcasing impressive visual
realism and temporal consistency.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06641" title="Abstract">arXiv:2312.06641</a> [<a href="/pdf/2312.06641" title="Download PDF">pdf</a>, <a href="/format/2312.06641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Decision Making with History-Average Dependent Costs (Extended)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hebbar%2C+V">Vijeth Hebbar</a>, 
<a href="/search/cs?searchtype=author&query=Langbort%2C+C">Cedric Langbort</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to L4DC 2024. This is an extended version including proofs and experimental results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In many online sequential decision-making scenarios, a learner's choices
affect not just their current costs but also the future ones. In this work, we
look at one particular case of such a situation where the costs depend on the
time average of past decisions over a history horizon. We first recast this
problem with history dependent costs as a problem of decision making under
stage-wise constraints. To tackle this, we then propose the novel
Follow-The-Adaptively-Regularized-Leader (FTARL) algorithm. Our innovative
algorithm incorporates adaptive regularizers that depend explicitly on past
decisions, allowing us to enforce stage-wise constraints while simultaneously
enabling us to establish tight regret bounds. We also discuss the implications
of the length of history horizon on design of no-regret algorithms for our
problem and present impossibility results when it is the full learning horizon.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06642" title="Abstract">arXiv:2312.06642</a> [<a href="/pdf/2312.06642" title="Download PDF">pdf</a>, <a href="/format/2312.06642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CorresNeRF: Image Correspondence Priors for Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lao%2C+Y">Yixing Lao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have achieved impressive results in novel view
synthesis and surface reconstruction tasks. However, their performance suffers
under challenging scenarios with sparse input views. We present CorresNeRF, a
novel method that leverages image correspondence priors computed by
off-the-shelf methods to supervise NeRF training. We design adaptive processes
for augmentation and filtering to generate dense and high-quality
correspondences. The correspondences are then used to regularize NeRF training
via the correspondence pixel reprojection and depth loss terms. We evaluate our
methods on novel view synthesis and surface reconstruction tasks with
density-based and SDF-based NeRF models on different datasets. Our method
outperforms previous methods in both photometric and geometric metrics. We show
that this simple yet effective technique of using correspondence priors can be
applied as a plug-and-play module across different NeRF variants. The project
page is at https://yxlao.github.io/corres-nerf.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06643" title="Abstract">arXiv:2312.06643</a> [<a href="/pdf/2312.06643" title="Download PDF">pdf</a>, <a href="/format/2312.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaze Detection and Analysis for Initiating Joint Activity in Industrial  Human-Robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prajod%2C+P">Pooja Prajod</a>, 
<a href="/search/cs?searchtype=author&query=Nicora%2C+M+L">Matteo Lavit Nicora</a>, 
<a href="/search/cs?searchtype=author&query=Mondellini%2C+M">Marta Mondellini</a>, 
<a href="/search/cs?searchtype=author&query=Tauro%2C+G">Giovanni Tauro</a>, 
<a href="/search/cs?searchtype=author&query=Vertechy%2C+R">Rocco Vertechy</a>, 
<a href="/search/cs?searchtype=author&query=Malosio%2C+M">Matteo Malosio</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Collaborative robots (cobots) are widely used in industrial applications, yet
extensive research is still needed to enhance human-robot collaborations and
operator experience. A potential approach to improve the collaboration
experience involves adapting cobot behavior based on natural cues from the
operator. Inspired by the literature on human-human interactions, we conducted
a wizard-of-oz study to examine whether a gaze towards the cobot can serve as a
trigger for initiating joint activities in collaborative sessions. In this
study, 37 participants engaged in an assembly task while their gaze behavior
was analyzed. We employ a gaze-based attention recognition model to identify
when the participants look at the cobot. Our results indicate that in most
cases (84.88\%), the joint activity is preceded by a gaze towards the cobot.
Furthermore, during the entire assembly cycle, the participants tend to look at
the cobot around the time of the joint activity. To the best of our knowledge,
this is the first study to analyze the natural gaze behavior of participants
working on a joint activity with a robot during a collaborative assembly task.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06644" title="Abstract">arXiv:2312.06644</a> [<a href="/pdf/2312.06644" title="Download PDF">pdf</a>, <a href="/format/2312.06644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zehao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srinath Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Rao Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We introduce AnyHome, a framework that translates open-vocabulary
descriptions, ranging from simple labels to elaborate paragraphs, into
well-structured and textured 3D indoor scenes at a house-scale. Inspired by
cognition theories, AnyHome employs an amodal structured representation to
capture 3D spatial cues from textual narratives and then uses egocentric
inpainting to enrich these scenes. To this end, we begin by using specially
designed template prompts for Large Language Models (LLMs), which enable
precise control over the textual input. We then utilize intermediate
representations to maintain the spatial structure's consistency, ensuring that
the 3D scenes align closely with the textual description. Then, we apply a
Score Distillation Sampling process to refine the placement of objects. Lastly,
an egocentric inpainting process is incorporated to enhance the realism and
appearance of the scenes. AnyHome stands out due to its hierarchical structured
representation combined with the versatility of open-vocabulary text
interpretation. This allows for extensive customization of indoor scenes at
various levels of granularity. We demonstrate that AnyHome can reliably
generate a range of diverse indoor scenes, characterized by their detailed
spatial structures and textures, all corresponding to the free-form textual
inputs.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06645" title="Abstract">arXiv:2312.06645</a> [<a href="/pdf/2312.06645" title="Download PDF">pdf</a>, <a href="/format/2312.06645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Classification: Definition and Density-based Estimation of  Calibration in Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popordanoska%2C+T">Teodora Popordanoska</a>, 
<a href="/search/cs?searchtype=author&query=Tiulpin%2C+A">Aleksei Tiulpin</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M+B">Matthew B. Blaschko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite their impressive predictive performance in various computer vision
tasks, deep neural networks (DNNs) tend to make overly confident predictions,
which hinders their widespread use in safety-critical applications. While there
have been recent attempts to calibrate DNNs, most of these efforts have
primarily been focused on classification tasks, thus neglecting DNN-based
object detectors. Although several recent works addressed calibration for
object detection and proposed differentiable penalties, none of them are
consistent estimators of established concepts in calibration. In this work, we
tackle the challenge of defining and estimating calibration error specifically
for this task. In particular, we adapt the definition of classification
calibration error to handle the nuances associated with object detection, and
predictions in structured output spaces more generally. Furthermore, we propose
a consistent and differentiable estimator of the detection calibration error,
utilizing kernel density estimation. Our experiments demonstrate the
effectiveness of our estimator against competing train-time and post-hoc
calibration methods, while maintaining similar detection performance.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06646" title="Abstract">arXiv:2312.06646</a> [<a href="/pdf/2312.06646" title="Download PDF">pdf</a>, <a href="/format/2312.06646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Copyright: Towards A Royalty Model for AI Music Generation  Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Junwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The advancement of generative AI has given rise to pressing copyright
challenges, particularly in music industry. This paper focuses on the economic
aspects of these challenges, emphasizing that the economic impact constitutes a
central issue in the copyright arena. The complexity of the black-box
generative AI technologies not only suggests but necessitates algorithmic
solutions. However, such solutions have been largely missing, leading to
regulatory challenges in this landscape. We aim to bridge the gap in current
approaches by proposing potential royalty models for revenue sharing on AI
music generation platforms. Our methodology involves a detailed analysis of
existing royalty models in platforms like Spotify and YouTube, and adapting
these to the unique context of AI-generated music. A significant challenge we
address is the attribution of AI-generated music to influential copyrighted
content in the training data. To this end, we present algorithmic solutions
employing data attribution techniques. Our experimental results verify the
effectiveness of these solutions. This research represents a pioneering effort
in integrating technical advancements with economic and legal considerations in
the field of generative AI, offering a computational copyright solution for the
challenges posed by the opaque nature of AI technologies.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06647" title="Abstract">arXiv:2312.06647</a> [<a href="/pdf/2312.06647" title="Download PDF">pdf</a>, <a href="/format/2312.06647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4M: Massively Multimodal Masked Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mizrahi%2C+D">David Mizrahi</a>, 
<a href="/search/cs?searchtype=author&query=Bachmann%2C+R">Roman Bachmann</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+O+F">O&#x11f;uzhan Fatih Kar</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+T">Teresa Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingfei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dehghan%2C+A">Afshin Dehghan</a>, 
<a href="/search/cs?searchtype=author&query=Zamir%2C+A">Amir Zamir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight. Project page at <a href="https://4m.epfl.ch/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Current machine learning models for vision are often highly specialized and
limited to a single modality and task. In contrast, recent large language
models exhibit a wide range of capabilities, hinting at a possibility for
similarly versatile models in computer vision. In this paper, we take a step in
this direction and propose a multimodal training scheme called 4M. It consists
of training a single unified Transformer encoder-decoder using a masked
modeling objective across a wide range of input/output modalities - including
text, images, geometric, and semantic modalities, as well as neural network
feature maps. 4M achieves scalability by unifying the representation space of
all modalities through mapping them into discrete tokens and performing
multimodal masked modeling on a small randomized subset of tokens.
<br />4M leads to models that exhibit several key capabilities: (1) they can
perform a diverse set of vision tasks out of the box, (2) they excel when
fine-tuned for unseen downstream tasks or new input modalities, and (3) they
can function as a generative model that can be conditioned on arbitrary
modalities, enabling a wide variety of expressive multimodal editing
capabilities with remarkable flexibility.
<br />Through experimental analyses, we demonstrate the potential of 4M for
training versatile and scalable foundation models for vision tasks, setting the
stage for further exploration in multimodal learning for vision and other
domains.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06648" title="Abstract">arXiv:2312.06648</a> [<a href="/pdf/2312.06648" title="Download PDF">pdf</a>, <a href="/format/2312.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense X Retrieval: What Retrieval Granularity Should We Use?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Dense retrieval has become a prominent method to obtain relevant context or
world knowledge in open-domain NLP tasks. When we use a learned dense retriever
on a retrieval corpus at inference time, an often-overlooked design choice is
the retrieval unit in which the corpus is indexed, e.g. document, passage, or
sentence. We discover that the retrieval unit choice significantly impacts the
performance of both retrieval and downstream tasks. Distinct from the typical
approach of using passages or sentences, we introduce a novel retrieval unit,
proposition, for dense retrieval. Propositions are defined as atomic
expressions within text, each encapsulating a distinct factoid and presented in
a concise, self-contained natural language format. We conduct an empirical
comparison of different retrieval granularity. Our results reveal that
proposition-based retrieval significantly outperforms traditional passage or
sentence-based methods in dense retrieval. Moreover, retrieval by proposition
also enhances the performance of downstream QA tasks, since the retrieved texts
are more condensed with question-relevant information, reducing the need for
lengthy input tokens and minimizing the inclusion of extraneous, irrelevant
information.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06652" title="Abstract">arXiv:2312.06652</a> [<a href="/pdf/2312.06652" title="Download PDF">pdf</a>, <a href="/format/2312.06652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Domain-Specific LLMs Faithful To The Islamic Worldview: Mirage  or Technical Possibility?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shabaz Patel</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+H">Hassan Kane</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Rayhan Patel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Muslims in ML workshop at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable performance across
numerous natural language understanding use cases. However, this impressive
performance comes with inherent limitations, such as the tendency to perpetuate
stereotypical biases or fabricate non-existent facts. In the context of Islam
and its representation, accurate and factual representation of its beliefs and
teachings rooted in the Quran and Sunnah is key. This work focuses on the
challenge of building domain-specific LLMs faithful to the Islamic worldview
and proposes ways to build and evaluate such systems. Firstly, we define this
open-ended goal as a technical problem and propose various solutions.
Subsequently, we critically examine known challenges inherent to each approach
and highlight evaluation methodologies that can be used to assess such systems.
This work highlights the need for high-quality datasets, evaluations, and
interdisciplinary work blending machine learning with Islamic scholarship.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06653" title="Abstract">arXiv:2312.06653</a> [<a href="/pdf/2312.06653" title="Download PDF">pdf</a>, <a href="/format/2312.06653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Human Trajectory Prediction via Latent Corridors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+N">Neerja Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Mangalam%2C+K">Karttikeya Mangalam</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website can be found at <a href="https://neerja.me/atp_latent_corridors/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human trajectory prediction is typically posed as a zero-shot generalization
problem: a predictor is learnt on a dataset of human motion in training scenes,
and then deployed on unseen test scenes. While this paradigm has yielded
tremendous progress, it fundamentally assumes that trends in human behavior
within the deployment scene are constant over time. As such, current prediction
models are unable to adapt to scene-specific transient human behaviors, such as
crowds temporarily gathering to see buskers, pedestrians hurrying through the
rain and avoiding puddles, or a protest breaking out. We formalize the problem
of scene-specific adaptive trajectory prediction and propose a new adaptation
approach inspired by prompt tuning called latent corridors. By augmenting the
input of any pre-trained human trajectory predictor with learnable image
prompts, the predictor can improve in the deployment scene by inferring trends
from extremely small amounts of new data (e.g., 2 humans observed for 30
seconds). With less than 0.1% additional model parameters, we see up to 23.9%
ADE improvement in MOTSynth simulated data and 16.4% ADE in MOT and Wildtrack
real pedestrian data. Qualitatively, we observe that latent corridors imbue
predictors with an awareness of scene geometry and scene-specific human
behaviors that non-adaptive predictors struggle to capture. The project website
can be found at https://neerja.me/atp_latent_corridors/.
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06654" title="Abstract">arXiv:2312.06654</a> [<a href="/pdf/2312.06654" title="Download PDF">pdf</a>, <a href="/format/2312.06654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightSim: Neural Lighting Simulation for Urban Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pun%2C+A">Ava Pun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gary Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Manivasagam%2C+S">Sivabalan Manivasagam</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei-Chiu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page: <a href="https://waabi.ai/lightsim/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Different outdoor illumination conditions drastically alter the appearance of
urban scenes, and they can harm the performance of image-based robot perception
systems if not seen during training. Camera simulation provides a
cost-effective solution to create a large dataset of images captured under
different lighting conditions. Towards this goal, we propose LightSim, a neural
lighting camera simulation system that enables diverse, realistic, and
controllable data generation. LightSim automatically builds lighting-aware
digital twins at scale from collected raw sensor data and decomposes the scene
into dynamic actors and static background with accurate geometry, appearance,
and estimated scene lighting. These digital twins enable actor insertion,
modification, removal, and rendering from a new viewpoint, all in a
lighting-aware manner. LightSim then combines physically-based and learnable
deferred rendering to perform realistic relighting of modified scenes, such as
altering the sun location and modifying the shadows or changing the sun
brightness, producing spatially- and temporally-consistent camera videos. Our
experiments show that LightSim generates more realistic relighting results than
prior work. Importantly, training perception models on data generated by
LightSim can significantly improve their performance.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06655" title="Abstract">arXiv:2312.06655</a> [<a href="/pdf/2312.06655" title="Download PDF">pdf</a>, <a href="/format/2312.06655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D  Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangfu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Diankun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Y">Yongming Rao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yueqi Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://liuff19.github.io/Sherpa3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, 3D content creation from text prompts has demonstrated remarkable
progress by utilizing 2D and 3D diffusion models. While 3D diffusion models
ensure great multi-view consistency, their ability to generate high-quality and
diverse 3D assets is hindered by the limited 3D data. In contrast, 2D diffusion
models find a distillation approach that achieves excellent generalization and
rich details without any 3D data. However, 2D lifting methods suffer from
inherent view-agnostic ambiguity thereby leading to serious multi-face Janus
issues, where text prompts fail to provide sufficient guidance to learn
coherent 3D results. Instead of retraining a costly viewpoint-aware model, we
study how to fully exploit easily accessible coarse 3D knowledge to enhance the
prompts and guide 2D lifting optimization for refinement. In this paper, we
propose Sherpa3D, a new text-to-3D framework that achieves high-fidelity,
generalizability, and geometric consistency simultaneously. Specifically, we
design a pair of guiding strategies derived from the coarse 3D prior generated
by the 3D diffusion model: a structural guidance for geometric fidelity and a
semantic guidance for 3D coherence. Employing the two types of guidance, the 2D
diffusion model enriches the 3D content with diversified and high-quality
results. Extensive experiments show the superiority of our Sherpa3D over the
state-of-the-art text-to-3D methods in terms of quality and 3D consistency.
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06657" title="Abstract">arXiv:2312.06657</a> [<a href="/pdf/2312.06657" title="Download PDF">pdf</a>, <a href="/format/2312.06657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Naturally Aggregated Appearance for Efficient 3D Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K+L">Ka Leong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiuyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zifan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+H">Hao Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Webpage: <a href="https://felixcheng97.github.io/AGAP/">this https URL</a>, Code: <a href="https://github.com/felixcheng97/AGAP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields, which represent a 3D scene as a color field and a
density field, have demonstrated great progress in novel view synthesis yet are
unfavorable for editing due to the implicitness. In view of such a deficiency,
we propose to replace the color field with an explicit 2D appearance
aggregation, also called canonical image, with which users can easily customize
their 3D editing via 2D image processing. To avoid the distortion effect and
facilitate convenient editing, we complement the canonical image with a
projection field that maps 3D points onto 2D pixels for texture lookup. This
field is carefully initialized with a pseudo canonical camera model and
optimized with offset regularity to ensure naturalness of the aggregated
appearance. Extensive experimental results on three datasets suggest that our
representation, dubbed AGAP, well supports various ways of 3D editing (e.g.,
stylization, interactive drawing, and content extraction) with no need of
re-optimization for each case, demonstrating its generalizability and
efficiency. Project page is available at https://felixcheng97.github.io/AGAP/.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06658" title="Abstract">arXiv:2312.06658</a> [<a href="/pdf/2312.06658" title="Download PDF">pdf</a>, <a href="/format/2312.06658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean estimation in the add-remove model of differential privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulesza%2C+A">Alex Kulesza</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+A+T">Ananda Theertha Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">Differential privacy is often studied under two different models of
neighboring datasets: the add-remove model and the swap model. While the swap
model is used extensively in the academic literature, many practical libraries
use the more conservative add-remove model. However, analysis under the
add-remove model can be cumbersome, and obtaining results with tight constants
requires some additional work. Here, we study the problem of one-dimensional
mean estimation under the add-remove model of differential privacy. We propose
a new algorithm and show that it is min-max optimal, that it has the correct
constant in the leading term of the mean squared error, and that this constant
is the same as the optimal algorithm in the swap model. Our results show that,
for mean estimation, the add-remove and swap model give nearly identical error
even though the add-remove model cannot treat the size of the dataset as public
information. In addition, we demonstrate empirically that our proposed
algorithm yields a factor of two improvement in mean squared error over
algorithms often used in practice.
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06660" title="Abstract">arXiv:2312.06660</a> [<a href="/pdf/2312.06660" title="Download PDF">pdf</a>, <a href="/format/2312.06660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgeSAM: Prompt-In-the-Loop Distillation for On-Device Deployment of SAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://mmlab-ntu.github.io/project/edgesam/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents EdgeSAM, an accelerated variant of the Segment Anything
Model (SAM), optimized for efficient execution on edge devices with minimal
compromise in performance. Our approach involves distilling the original
ViT-based SAM image encoder into a purely CNN-based architecture, better suited
for edge devices. We carefully benchmark various distillation strategies and
demonstrate that task-agnostic encoder distillation fails to capture the full
knowledge embodied in SAM. To overcome this bottleneck, we include both the
prompt encoder and mask decoder in the distillation process, with box and point
prompts in the loop, so that the distilled model can accurately capture the
intricate dynamics between user input and mask generation. To mitigate dataset
bias issues stemming from point prompt distillation, we incorporate a
lightweight module within the encoder. EdgeSAM achieves a 40-fold speed
increase compared to the original SAM, and it also outperforms MobileSAM, being
14 times as fast when deployed on edge devices while enhancing the mIoUs on
COCO and LVIS by 2.3 and 3.2 respectively. It is also the first SAM variant
that can run at over 30 FPS on an iPhone 14. Code and models are available at
https://github.com/chongzhou96/EdgeSAM.
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06661" title="Abstract">arXiv:2312.06661</a> [<a href="/pdf/2312.06661" title="Download PDF">pdf</a>, <a href="/format/2312.06661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UpFusion: Novel View Diffusion from Unposed Sparse View Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kani%2C+B+R+N">Bharath Raj Nagoor Kani</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Tulsiani%2C+S">Shubham Tulsiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://upfusion3d.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose UpFusion, a system that can perform novel view synthesis and infer
3D representations for an object given a sparse set of reference images without
corresponding pose information. Current sparse-view 3D inference methods
typically rely on camera poses to geometrically aggregate information from
input views, but are not robust in-the-wild when such information is
unavailable/inaccurate. In contrast, UpFusion sidesteps this requirement by
learning to implicitly leverage the available images as context in a
conditional generative model for synthesizing novel views. We incorporate two
complementary forms of conditioning into diffusion models for leveraging the
input views: a) via inferring query-view aligned features using a scene-level
transformer, b) via intermediate attentional layers that can directly observe
the input image tokens. We show that this mechanism allows generating
high-fidelity novel views while improving the synthesis quality given
additional (unposed) images. We evaluate our approach on the Co3Dv2 and Google
Scanned Objects datasets and demonstrate the benefits of our method over
pose-reliant sparse-view methods as well as single-view methods that cannot
leverage additional views. Finally, we also show that our learned model can
generalize beyond the training categories and even allow reconstruction from
self-captured images of generic objects in-the-wild.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06662" title="Abstract">arXiv:2312.06662</a> [<a href="/pdf/2312.06662" title="Download PDF">pdf</a>, <a href="/format/2312.06662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photorealistic Video Generation with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Agrim Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lijun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+K">Kihyuk Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiuye Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+M">Meera Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Essa%2C+I">Irfan Essa</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lezama%2C+J">Jos&#xe9; Lezama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website <a href="https://walt-video-diffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present W.A.L.T, a transformer-based approach for photorealistic video
generation via diffusion modeling. Our approach has two key design decisions.
First, we use a causal encoder to jointly compress images and videos within a
unified latent space, enabling training and generation across modalities.
Second, for memory and training efficiency, we use a window attention
architecture tailored for joint spatial and spatiotemporal generative modeling.
Taken together these design decisions enable us to achieve state-of-the-art
performance on established video (UCF-101 and Kinetics-600) and image
(ImageNet) generation benchmarks without using classifier free guidance.
Finally, we also train a cascade of three models for the task of text-to-video
generation consisting of a base latent video diffusion model, and two video
super-resolution diffusion models to generate videos of $512 \times 896$
resolution at $8$ frames per second.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06663" title="Abstract">arXiv:2312.06663</a> [<a href="/pdf/2312.06663" title="Download PDF">pdf</a>, <a href="/format/2312.06663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAD: Photorealistic 3D Generation via Adversarial Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidou%2C+D">Despoina Paschalidou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+I">Ian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bokui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xiaoyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="http://raywzy.com/CAD/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The increased demand for 3D data in AR/VR, robotics and gaming applications,
gave rise to powerful generative pipelines capable of synthesizing high-quality
3D objects. Most of these models rely on the Score Distillation Sampling (SDS)
algorithm to optimize a 3D representation such that the rendered image
maintains a high likelihood as evaluated by a pre-trained diffusion model.
However, finding a correct mode in the high-dimensional distribution produced
by the diffusion model is challenging and often leads to issues such as
over-saturation, over-smoothing, and Janus-like artifacts. In this paper, we
propose a novel learning paradigm for 3D synthesis that utilizes pre-trained
diffusion models. Instead of focusing on mode-seeking, our method directly
models the distribution discrepancy between multi-view renderings and diffusion
priors in an adversarial manner, which unlocks the generation of high-fidelity
and photorealistic 3D content, conditioned on a single image and prompt.
Moreover, by harnessing the latent space of GANs and expressive diffusion model
priors, our method facilitates a wide variety of 3D applications including
single-view reconstruction, high diversity generation and continuous 3D
interpolation in the open domain. The experiments demonstrate the superiority
of our pipeline compared to previous works in terms of generation quality and
diversity.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 12 Dec 23</h3>
<dl>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04967" title="Abstract">arXiv:2305.04967</a> (cross-list from q-fin.RM) [<a href="/pdf/2305.04967" title="Download PDF">pdf</a>, <a href="/format/2305.04967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UQ for Credit Risk Management: A deep evidence regression approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Dhiman%2C+A">Ashish Dhiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, plus references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine Learning has invariantly found its way into various Credit Risk
applications. Due to the intrinsic nature of Credit Risk, quantifying the
uncertainty of the predicted risk metrics is essential, and applying
uncertainty-aware deep learning models to credit risk settings can be very
helpful. In this work, we have explored the application of a scalable UQ-aware
deep learning technique, Deep Evidence Regression and applied it to predicting
Loss Given Default. We contribute to the literature by extending the Deep
Evidence Regression methodology to learning target variables generated by a
Weibull process and provide the relevant learning framework. We demonstrate the
application of our approach to both simulated and real-world data.
</p>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05256" title="Abstract">arXiv:2312.05256</a> (cross-list from eess.IV) [<a href="/pdf/2312.05256" title="Download PDF">pdf</a>, <a href="/format/2312.05256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Evaluation of GPT-4V for Biomedical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Hanqi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+T">Tianyang Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+C">Chong Ma</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xiaowei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yutong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Yi Pan</a>, 
<a href="/search/eess?searchtype=author&query=Shu%2C+P">Peng Shu</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+Y">Yanjun Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Junjie Yao</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+P">Peixin Dong</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+C">Chao Cao</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Z">Zhenxiang Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+S">Shaochen Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+Y">Yaonai Wei</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingyuan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+H">Haixing Dai</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Peilong Wang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zewei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yiheng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+L">Liheng Yan</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/eess?searchtype=author&query=Qiang%2C+N">Ning Qiang</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+B">Bao Ge</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+X">Xiaoyan Cai</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Shijie Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xintao Hu</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+X">Xi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tuo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Quanzheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+D">Dajiang Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+T">Tianming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present a large-scale evaluation probing GPT-4V's
capabilities and limitations for biomedical image analysis. GPT-4V represents a
breakthrough in artificial general intelligence (AGI) for computer vision, with
applications in the biomedical domain. We assess GPT-4V's performance across 16
medical imaging categories, including radiology, oncology, ophthalmology,
pathology, and more. Tasks include modality recognition, anatomy localization,
disease diagnosis, report generation, and lesion detection. The extensive
experiments provide insights into GPT-4V's strengths and weaknesses. Results
show GPT-4V's proficiency in modality and anatomy recognition but difficulty
with disease diagnosis and localization. GPT-4V excels at diagnostic report
generation, indicating strong image captioning skills. While promising for
biomedical imaging AI, GPT-4V requires further enhancement and validation
before clinical deployment. We emphasize responsible development and testing
for trustworthy integration of biomedical AGI. This rigorous evaluation of
GPT-4V on diverse medical images advances understanding of multimodal large
language models (LLMs) and guides future work toward impactful healthcare
applications.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05258" title="Abstract">arXiv:2312.05258</a> (cross-list from eess.IV) [<a href="/pdf/2312.05258" title="Download PDF">pdf</a>, <a href="/format/2312.05258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Small Kidney Cancer Detection in Non-Contrast Computed  Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=McGough%2C+W">William McGough</a>, 
<a href="/search/eess?searchtype=author&query=Buddenkotte%2C+T">Thomas Buddenkotte</a>, 
<a href="/search/eess?searchtype=author&query=Ursprung%2C+S">Stephan Ursprung</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Z">Zeyu Gao</a>, 
<a href="/search/eess?searchtype=author&query=Stewart%2C+G">Grant Stewart</a>, 
<a href="/search/eess?searchtype=author&query=Crispin-Ortuzar%2C+M">Mireia Crispin-Ortuzar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">This study introduces an automated pipeline for renal cancer (RC) detection
in non-contrast computed tomography (NCCT). In the development of our pipeline,
we test three detections models: a shape model, a 2D-, and a 3D axial-sample
model. Training (n=1348) and testing (n=64) data were gathered from open
sources (KiTS23, Abdomen1k, CT-ORG) and Cambridge University Hospital (CUH).
Results from cross-validation and testing revealed that the 2D axial sample
model had the highest small ($\leq$40mm diameter) RC detection area under the
curve (AUC) of 0.804. Our pipeline achieves 61.9\% sensitivity and 92.7\%
specificity for small kidney cancers on unseen test data. Our results are much
more accurate than previous attempts to automatically detect small renal
cancers in NCCT, the most likely imaging modality for RC screening. This
pipeline offers a promising advance that may enable screening for kidney
cancers.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05273" title="Abstract">arXiv:2312.05273</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.05273" title="Download PDF">pdf</a>, <a href="/format/2312.05273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Zero-Shot Scoring for In Vitro Antibody Binding Prediction  with Experimental Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Nori%2C+D">Divya Nori</a>, 
<a href="/search/q-bio?searchtype=author&query=Mathis%2C+S+V">Simon V. Mathis</a>, 
<a href="/search/q-bio?searchtype=author&query=Shanehsazzadeh%2C+A">Amir Shanehsazzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The success of therapeutic antibodies relies on their ability to selectively
bind antigens. AI-based antibody design protocols have shown promise in
generating epitope-specific designs. Many of these protocols use an inverse
folding step to generate diverse sequences given a backbone structure. Due to
prohibitive screening costs, it is key to identify candidate sequences likely
to bind in vitro. Here, we compare the efficacy of 8 common scoring paradigms
based on open-source models to classify antibody designs as binders or
non-binders. We evaluate these approaches on a novel surface plasmon resonance
(SPR) dataset, spanning 5 antigens. Our results show that existing methods
struggle to detect binders, and performance is highly variable across antigens.
We find that metrics computed on flexibly docked antibody-antigen complexes are
more robust, and ensembles scores are more consistent than individual metrics.
We provide experimental insight to analyze current scoring techniques,
highlighting that the development of robust, zero-shot filters is an important
research gap.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05279" title="Abstract">arXiv:2312.05279</a> (cross-list from eess.IV) [<a href="/pdf/2312.05279" title="Download PDF">pdf</a>, <a href="/ps/2312.05279" title="Download PostScript">ps</a>, <a href="/format/2312.05279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative perfusion maps using a novelty spatiotemporal convolutional  neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+A">Anbo Cao</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+P">Pin-Yu Le</a>, 
<a href="/search/eess?searchtype=author&query=Qie%2C+Z">Zhonghui Qie</a>, 
<a href="/search/eess?searchtype=author&query=Hassan%2C+H">Haseeb Hassan</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yingwei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Zaman%2C+A">Asim Zaman</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jiaxi Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+X">Xueqiang Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Huihui Yang</a>, 
<a href="/search/eess?searchtype=author&query=Miao%2C+X">Xiaoqiang Miao</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+T">Taiyu Han</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+G">Guangtao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jia Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Dynamic susceptibility contrast magnetic resonance imaging (DSC-MRI) is
widely used to evaluate acute ischemic stroke to distinguish salvageable tissue
and infarct core. For this purpose, traditional methods employ deconvolution
techniques, like singular value decomposition, which are known to be vulnerable
to noise, potentially distorting the derived perfusion parameters. However,
deep learning technology could leverage it, which can accurately estimate
clinical perfusion parameters compared to traditional clinical approaches.
Therefore, this study presents a perfusion parameters estimation network that
considers spatial and temporal information, the Spatiotemporal Network
(ST-Net), for the first time. The proposed network comprises a designed
physical loss function to enhance model performance further. The results
indicate that the network can accurately estimate perfusion parameters,
including cerebral blood volume (CBV), cerebral blood flow (CBF), and time to
maximum of the residual function (Tmax). The structural similarity index (SSIM)
mean values for CBV, CBF, and Tmax parameters were 0.952, 0.943, and 0.863,
respectively. The DICE score for the hypo-perfused region reached 0.859,
demonstrating high consistency. The proposed model also maintains time
efficiency, closely approaching the performance of commercial gold-standard
software.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05320" title="Abstract">arXiv:2312.05320</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2312.05320" title="Download PDF">pdf</a>, <a href="/format/2312.05320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Surrogate Models for Airfoil Flow Simulations with  Denoising Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Thuerey%2C+N">Nils Thuerey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Leveraging neural networks as surrogate models for turbulence simulation is a
topic of growing interest. At the same time, embodying the inherent uncertainty
of simulations in the predictions of surrogate models remains very challenging.
The present study makes a first attempt to use denoising diffusion
probabilistic models (DDPMs) to train an uncertainty-aware surrogate model for
turbulence simulations. Due to its prevalence, the simulation of flows around
airfoils with various shapes, Reynolds numbers, and angles of attack is chosen
as the learning objective. Our results show that DDPMs can successfully capture
the whole distribution of solutions and, as a consequence, accurately estimate
the uncertainty of the simulations. The performance of DDPMs is also compared
with varying baselines in the form of Bayesian neural networks and
heteroscedastic models. Experiments demonstrate that DDPMs outperform the other
methods regarding a variety of accuracy metrics. Besides, it offers the
advantage of providing access to the complete distributions of uncertainties
rather than providing a set of parameters. As such, it can yield realistic and
detailed samples from the distribution of solutions. All source codes and
datasets utilized in this study are publicly available.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05334" title="Abstract">arXiv:2312.05334</a> (cross-list from eess.IV) [<a href="/pdf/2312.05334" title="Download PDF">pdf</a>, <a href="/format/2312.05334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProsDectNet: Bridging the Gap in Prostate Cancer Detection via  Transrectal B-mode Ultrasound Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vesal%2C+S">Sulaiman Vesal</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+I">Indrani Bhattacharya</a>, 
<a href="/search/eess?searchtype=author&query=Jahanandish%2C+H">Hassan Jahanandish</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinran Li</a>, 
<a href="/search/eess?searchtype=author&query=Kornberg%2C+Z">Zachary Kornberg</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+R">Steve Ran Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Sommer%2C+E+R">Elijah Richard Sommer</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+M+H">Moon Hyung Choi</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+R+E">Richard E. Fan</a>, 
<a href="/search/eess?searchtype=author&query=Sonn%2C+G+A">Geoffrey A. Sonn</a>, 
<a href="/search/eess?searchtype=author&query=Rusu%2C+M">Mirabela Rusu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023 (Medical Imaging meets NeurIPS Workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Interpreting traditional B-mode ultrasound images can be challenging due to
image artifacts (e.g., shadowing, speckle), leading to low sensitivity and
limited diagnostic accuracy. While Magnetic Resonance Imaging (MRI) has been
proposed as a solution, it is expensive and not widely available. Furthermore,
most biopsies are guided by Transrectal Ultrasound (TRUS) alone and can miss up
to 52% cancers, highlighting the need for improved targeting. To address this
issue, we propose ProsDectNet, a multi-task deep learning approach that
localizes prostate cancer on B-mode ultrasound. Our model is pre-trained using
radiologist-labeled data and fine-tuned using biopsy-confirmed labels.
ProsDectNet includes a lesion detection and patch classification head, with
uncertainty minimization using entropy to improve model performance and reduce
false positive predictions. We trained and validated ProsDectNet using a cohort
of 289 patients who underwent MRI-TRUS fusion targeted biopsy. We then tested
our approach on a group of 41 patients and found that ProsDectNet outperformed
the average expert clinician in detecting prostate cancer on B-mode ultrasound
images, achieving a patient-level ROC-AUC of 82%, a sensitivity of 74%, and a
specificity of 67%. Our results demonstrate that ProsDectNet has the potential
to be used as a computer-aided diagnosis system to improve targeted biopsy and
treatment planning.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05340" title="Abstract">arXiv:2312.05340</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.05340" title="Download PDF">pdf</a>, <a href="/format/2312.05340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transition Path Sampling with Boltzmann Generator-based MCMC Moves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Plainer%2C+M">Michael Plainer</a>, 
<a href="/search/q-bio?searchtype=author&query=St%C3%A4rk%2C+H">Hannes St&#xe4;rk</a>, 
<a href="/search/q-bio?searchtype=author&query=Bunne%2C+C">Charlotte Bunne</a>, 
<a href="/search/q-bio?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight at NeurIPS 2023 Generative AI and Biology Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sampling all possible transition paths between two 3D states of a molecular
system has various applications ranging from catalyst design to drug discovery.
Current approaches to sample transition paths use Markov chain Monte Carlo and
rely on time-intensive molecular dynamics simulations to find new paths. Our
approach operates in the latent space of a normalizing flow that maps from the
molecule's Boltzmann distribution to a Gaussian, where we propose new paths
without requiring molecular simulations. Using alanine dipeptide, we explore
Metropolis-Hastings acceptance criteria in the latent space for exact sampling
and investigate different latent proposal mechanisms.
</p>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05357" title="Abstract">arXiv:2312.05357</a> (cross-list from eess.IV) [<a href="/pdf/2312.05357" title="Download PDF">pdf</a>, <a href="/format/2312.05357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filtering Pixel Latent Variables for Unmixing Volumetric Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bouchard%2C+C">Catherine Bouchard</a>, 
<a href="/search/eess?searchtype=author&query=Boulanger%2C+V">Vincent Boulanger</a>, 
<a href="/search/eess?searchtype=author&query=Lavoie-Cardinal%2C+F">Flavie Lavoie-Cardinal</a>, 
<a href="/search/eess?searchtype=author&query=Gagn%C3%A9%2C+C">Christian Gagn&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures (main paper) + 5 pages, 8 figures (supplementary material)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Measurements of different overlapping components require robust unmixing
algorithms to convert the raw multi-dimensional measurements to useful unmixed
images. Such algorithms perform reliable separation of the components when the
raw signal is fully resolved and contains enough information to fit curves on
the raw distributions. In experimental physics, measurements are often noisy,
undersampled, or unresolved spatially or spectrally. We propose a novel method
where bandpass filters are applied to the latent space of a multi-dimensional
convolutional neural network to separate the overlapping signal components and
extract each of their relative contributions. Simultaneously processing all
dimensions with multi-dimensional convolution kernels empowers the network to
combine the information from adjacent pixels and time- or spectral-bins,
facilitating component separation in instances where individual pixels lack
well-resolved information. We demonstrate the applicability of the method to
real experimental physics problems using fluorescence lifetime microscopy and
mode decomposition in optical fibers as test cases. The successful application
of our approach to these two distinct experimental cases, characterized by
different measured distributions, highlights the versatility of our approach in
addressing a wide array of imaging tasks.
</p>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05376" title="Abstract">arXiv:2312.05376</a> (cross-list from math.GT) [<a href="/pdf/2312.05376" title="Download PDF">pdf</a>, <a href="/format/2312.05376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realizing abstract simplicial complexes with specified edge lengths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ellison%2C+M">Matthew Ellison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Computational Geometry (cs.CG); Combinatorics (math.CO)

</div>
<p class="mathjax">For finite abstract simplicial complex $\Sigma$, initial realization $\alpha$
in $\mathbb{E}^d$, and desired edge lengths $L$, we give practical sufficient
conditions for the existence of a non-self-intersecting perturbation of
$\alpha$ realizing the lengths $L$. We provide software to verify these
conditions by computer and optionally assist in the creation of an initial
realization from abstract simplicial data. Applications include proving the
existence of a planar embedding of a graph with specified edge lengths or
proving the existence of polyhedra (or higher-dimensional polytopes) with
specified edge lengths.
</p>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05388" title="Abstract">arXiv:2312.05388</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.05388" title="Download PDF">pdf</a>, <a href="/format/2312.05388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Equivariant Neural Networks for Charge Density Prediction  in Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Koker%2C+T">Teddy Koker</a>, 
<a href="/search/physics?searchtype=author&query=Quigley%2C+K">Keegan Quigley</a>, 
<a href="/search/physics?searchtype=author&query=Taw%2C+E">Eric Taw</a>, 
<a href="/search/physics?searchtype=author&query=Tibbetts%2C+K">Kevin Tibbetts</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+L">Lin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
<p class="mathjax">The calculation of electron density distribution using density functional
theory (DFT) in materials and molecules is central to the study of their
quantum and macro-scale properties, yet accurate and efficient calculation
remains a long-standing challenge in the field of material science. This work
introduces ChargE3Net, an E(3)-equivariant graph neural network for predicting
electron density in atomic systems. ChargE3Net achieves equivariance through
the use of higher-order tensor representations, and directly predicts the
charge density at any arbitrary point in the system. We show that our method
achieves greater performance than prior work on large and diverse sets of
molecules and materials, and scales to larger systems than what is feasible to
compute with DFT. Using predicted electron densities as an initialization, we
show that fewer self-consistent iterations are required to converge DFT over
the default initialization. In addition, we show that non-self-consistent
calculations using the predicted electron densities can predict electronic and
thermodynamic properties of materials at near-DFT accuracy.
</p>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05460" title="Abstract">arXiv:2312.05460</a> (cross-list from stat.ML) [<a href="/pdf/2312.05460" title="Download PDF">pdf</a>, <a href="/format/2312.05460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-source domain adaptation for regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yujie Wu</a>, 
<a href="/search/stat?searchtype=author&query=Parmigiani%2C+G">Giovanni Parmigiani</a>, 
<a href="/search/stat?searchtype=author&query=Ren%2C+B">Boyu Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-source domain adaptation (DA) aims at leveraging information from more
than one source domain to make predictions in a target domain, where different
domains may have different data distributions. Most existing methods for
multi-source DA focus on classification problems while there is only limited
investigation in the regression settings. In this paper, we fill in this gap
through a two-step procedure. First, we extend a flexible single-source DA
algorithm for classification through outcome-coarsening to enable its
application to regression problems. We then augment our single-source DA
algorithm for regression with ensemble learning to achieve multi-source DA. We
consider three learning paradigms in the ensemble algorithm, which combines
linearly the target-adapted learners trained with each source domain: (i) a
multi-source stacking algorithm to obtain the ensemble weights; (ii) a
similarity-based weighting where the weights reflect the quality of DA of each
target-adapted learner; and (iii) a combination of the stacking and similarity
weights. We illustrate the performance of our algorithms with simulations and a
data application where the goal is to predict High-density lipoprotein (HDL)
cholesterol levels using gut microbiome. We observe a consistent improvement in
prediction performance of our multi-source DA algorithm over the routinely used
methods in all these scenarios.
</p>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05472" title="Abstract">arXiv:2312.05472</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.05472" title="Download PDF">pdf</a>, <a href="/format/2312.05472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectroscopy-Guided Discovery of Three-Dimensional Structures of  Disordered Materials with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Kwon%2C+H">Hyuna Kwon</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hsu%2C+T">Tim Hsu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+W">Wenyu Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Jeong%2C+W">Wonseok Jeong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Aydin%2C+F">Fikret Aydin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chapman%2C+J">James Chapman</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+X">Xiao Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Carbone%2C+M+R">Matthew R. Carbone</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+D">Deyu Lu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhou%2C+F">Fei Zhou</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pham%2C+T+A">Tuan Anh Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The ability to rapidly develop materials with desired properties has a
transformative impact on a broad range of emerging technologies. In this work,
we introduce a new framework based on the diffusion model, a recent generative
machine learning method to predict 3D structures of disordered materials from a
target property. For demonstration, we apply the model to identify the atomic
structures of amorphous carbons ($a$-C) as a representative material system
from the target X-ray absorption near edge structure (XANES) spectra--a common
experimental technique to probe atomic structures of materials. We show that
conditional generation guided by XANES spectra reproduces key features of the
target structures. Furthermore, we show that our model can steer the generative
process to tailor atomic arrangements for a specific XANES spectrum. Finally,
our generative model exhibits a remarkable scale-agnostic property, thereby
enabling generation of realistic, large-scale structures through learning from
a small-scale dataset (i.e., with small unit cells). Our work represents a
significant stride in bridging the gap between materials characterization and
atomic structure determination; in addition, it can be leveraged for materials
discovery in exploring various material properties as targeted.
</p>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05528" title="Abstract">arXiv:2312.05528</a> (cross-list from eess.IV) [<a href="/pdf/2312.05528" title="Download PDF">pdf</a>, <a href="/format/2312.05528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring 3D U-Net Training Configurations and Post-Processing  Strategies for the MICCAI 2023 Kidney and Tumor Segmentation Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Uhm%2C+K">Kwang-Hyun Uhm</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+H">Hyunjun Cho</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhixin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lim%2C+S">Seohoon Lim</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+S">Seung-Won Jung</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+S">Sung-Hoo Hong</a>, 
<a href="/search/eess?searchtype=author&query=Ko%2C+S">Sung-Jea Ko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023, KITS 2023 challenge 2nd place
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In 2023, it is estimated that 81,800 kidney cancer cases will be newly
diagnosed, and 14,890 people will die from this cancer in the United States.
Preoperative dynamic contrast-enhanced abdominal computed tomography (CT) is
often used for detecting lesions. However, there exists inter-observer
variability due to subtle differences in the imaging features of kidney and
kidney tumors. In this paper, we explore various 3D U-Net training
configurations and effective post-processing strategies for accurate
segmentation of kidneys, cysts, and kidney tumors in CT images. We validated
our model on the dataset of the 2023 Kidney and Kidney Tumor Segmentation
(KiTS23) challenge. Our method took second place in the final ranking of the
KiTS23 challenge on unseen test data with an average Dice score of 0.820 and an
average Surface Dice of 0.712.
</p>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05548" title="Abstract">arXiv:2312.05548</a> (cross-list from eess.IV) [<a href="/pdf/2312.05548" title="Download PDF">pdf</a>, <a href="/format/2312.05548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Multi-Phase CT Synthesis and Classification Framework for  Kidney Cancer Diagnosis with Incomplete Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Uhm%2C+K">Kwang-Hyun Uhm</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+S">Seung-Won Jung</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+M+H">Moon Hyung Choi</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+S">Sung-Hoo Hong</a>, 
<a href="/search/eess?searchtype=author&query=Ko%2C+S">Sung-Jea Ko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in IEEE Journal of Biomedical and Health Informatics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JBHI, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-phase CT is widely adopted for the diagnosis of kidney cancer due to
the complementary information among phases. However, the complete set of
multi-phase CT is often not available in practical clinical applications. In
recent years, there have been some studies to generate the missing modality
image from the available data. Nevertheless, the generated images are not
guaranteed to be effective for the diagnosis task. In this paper, we propose a
unified framework for kidney cancer diagnosis with incomplete multi-phase CT,
which simultaneously recovers missing CT images and classifies cancer subtypes
using the completed set of images. The advantage of our framework is that it
encourages a synthesis model to explicitly learn to generate missing CT phases
that are helpful for classifying cancer subtypes. We further incorporate lesion
segmentation network into our framework to exploit lesion-level features for
effective cancer classification in the whole CT volumes. The proposed framework
is based on fully 3D convolutional neural networks to jointly optimize both
synthesis and classification of 3D CT volumes. Extensive experiments on both
in-house and external datasets demonstrate the effectiveness of our framework
for the diagnosis with incomplete data compared with state-of-the-art
baselines. In particular, cancer subtype classification using the completed CT
data by our method achieves higher performance than the classification using
the given incomplete data.
</p>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05552" title="Abstract">arXiv:2312.05552</a> (cross-list from quant-ph) [<a href="/pdf/2312.05552" title="Download PDF">pdf</a>, <a href="/format/2312.05552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Parameter Training for VQEs by Sequential Hamiltonian Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roshani%2C+N">Navid Roshani</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zorn%2C+M">Maximilian Zorn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A central challenge in quantum machine learning is the design and training of
parameterized quantum circuits (PQCs). Similar to deep learning, vanishing
gradients pose immense problems in the trainability of PQCs, which have been
shown to arise from a multitude of sources. One such cause are non-local loss
functions, that demand the measurement of a large subset of involved qubits. To
facilitate the parameter training for quantum applications using global loss
functions, we propose a Sequential Hamiltonian Assembly, which iteratively
approximates the loss function using local components. Aiming for a prove of
principle, we evaluate our approach using Graph Coloring problem with a
Varational Quantum Eigensolver (VQE). Simulation results show, that our
approach outperforms conventional parameter training by 29.99% and the
empirical state of the art, Layerwise Learning, by 5.12% in the mean accuracy.
This paves the way towards locality-aware learning techniques, allowing to
evade vanishing gradients for a large class of practically relevant problems.
</p>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05573" title="Abstract">arXiv:2312.05573</a> (cross-list from stat.ML) [<a href="/pdf/2312.05573" title="Download PDF">pdf</a>, <a href="/format/2312.05573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting RIP guarantees for sketching operators on mixture models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Belhadji%2C+A">Ayoub Belhadji</a>, 
<a href="/search/stat?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the context of sketching for compressive mixture modeling, we revisit
existing proofs of the Restricted Isometry Property of sketching operators with
respect to certain mixtures models. After examining the shortcomings of
existing guarantees, we propose an alternative analysis that circumvents the
need to assume importance sampling when drawing random Fourier features to
build random sketching operators. Our analysis is based on new deterministic
bounds on the restricted isometry constant that depend solely on the set of
frequencies used to define the sketching operator; then we leverage these
bounds to establish concentration inequalities for random sketching operators
that lead to the desired RIP guarantees. Our analysis also opens the door to
theoretical guarantees for structured sketching with frequencies associated to
fast random linear operators.
</p>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05579" title="Abstract">arXiv:2312.05579</a> (cross-list from stat.ML) [<a href="/pdf/2312.05579" title="Download PDF">pdf</a>, <a href="/format/2312.05579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Stochastic Interpolation for Generative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+D">Ding Huang</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+J">Jian Huang</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+T">Ting Li</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+G">Guohao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a conditional stochastic interpolation (CSI) approach to learning
conditional distributions. CSI learns probability flow equations or stochastic
differential equations that transport a reference distribution to the target
conditional distribution. This is achieved by first learning the drift function
and the conditional score function based on conditional stochastic
interpolation, which are then used to construct a deterministic process
governed by an ordinary differential equation or a diffusion process for
conditional sampling. In our proposed CSI model, we incorporate an adaptive
diffusion term to address the instability issues arising during the training
process. We provide explicit forms of the conditional score function and the
drift function in terms of conditional expectations under mild conditions,
which naturally lead to an nonparametric regression approach to estimating
these functions. Furthermore, we establish non-asymptotic error bounds for
learning the target conditional distribution via conditional stochastic
interpolation in terms of KL divergence, taking into account the neural network
approximation error. We illustrate the application of CSI on image generation
using a benchmark image dataset.
</p>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05606" title="Abstract">arXiv:2312.05606</a> (cross-list from math.AP) [<a href="/pdf/2312.05606" title="Download PDF">pdf</a>, <a href="/format/2312.05606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional Dissipative PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Achleitner%2C+F">Franz Achleitner</a>, 
<a href="/search/math?searchtype=author&query=Akagi%2C+G">Goro Akagi</a>, 
<a href="/search/math?searchtype=author&query=Kuehn%2C+C">Christian Kuehn</a>, 
<a href="/search/math?searchtype=author&query=Melenk%2C+J+M">Jens Markus Melenk</a>, 
<a href="/search/math?searchtype=author&query=Rademacher%2C+J+D+M">Jens D.M. Rademacher</a>, 
<a href="/search/math?searchtype=author&query=Soresina%2C+C">Cinzia Soresina</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Jichen Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> book chapter
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA); Pattern Formation and Solitons (nlin.PS)

</div>
<p class="mathjax">In this chapter we provide an introduction to fractional dissipative partial
differential equations (PDEs) with a focus on trying to understand their
dynamics. The class of PDEs we focus on are reaction-diffusion equations but we
also provide an outlook on closely related classes of PDEs. To simplify the
exposition, we only discuss the cases of fractional time derivatives and
fractional space derivatives in the PDE separately. As our main tools, we
describe analytical as well as numerical methods, which are generically
necessary to study nonlinear dynamics. We start with the analytical study of
steady states and local linear stability for fractional time derivatives. Then
we extend this view to a global perspective and consider time-fractional PDEs
and gradient flows. Next, we continue to steady states, linear stability
analysis and bifurcations for space-fractional PDEs. As a final analytical
consideration we discuss existence and stability of traveling waves for
space-fractional PDEs. In the last parts, we provide numerical discretization
schemes for fractional (dissipative) PDEs and we utilize these techniques
within numerical continuation in applied examples of fractional
reaction-diffusion PDEs. We conclude with a brief summary and outlook on open
questions in the field.
</p>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05609" title="Abstract">arXiv:2312.05609</a> (cross-list from quant-ph) [<a href="/pdf/2312.05609" title="Download PDF">pdf</a>, <a href="/format/2312.05609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Analysis of BB84, A Quantum Key Distribution Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=M%2C+S+R">SujayKumar Reddy M</a>, 
<a href="/search/quant-ph?searchtype=author&query=B%2C+C+M">Chandra Mohan B</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY); Emerging Technologies (cs.ET); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Quantum Key Distribution (QKD) is a technique that enables secure
communication between two parties by sharing a secret key. One of the most
well-known QKD protocols is the BB84 protocol, proposed by Charles Bennett and
Gilles Brassard in 1984. In this protocol, Alice and Bob use a quantum channel
to exchange qubits, allowing them to generate a shared key that is resistant to
eavesdropping. This paper presents a comparative study of existing QKD schemes,
including the BB84 protocol, and highlights the advancements made in the BB84
protocol over the years. The study aims to provide a comprehensive overview of
the different QKD schemes and their strengths and weaknesses and demonstrate
QKDs working principles through existing simulations and implementations.
Through this study, we show that the BB84 protocol is a highly secure QKD
scheme that has been extensively studied and implemented in various settings.
Furthermore, we discuss the improvements made to the BB84 protocol to enhance
its security and practicality, including the use of decoy states and advanced
error correction techniques. Overall, this paper provides a comprehensive
analysis of QKD schemes, focusing on the BB84 protocol in secure communication
technologies.
</p>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05645" title="Abstract">arXiv:2312.05645</a> (cross-list from stat.ML) [<a href="/pdf/2312.05645" title="Download PDF">pdf</a>, <a href="/format/2312.05645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-Optimal Locally Private Hypothesis Selection and the Provable  Benefits of Interactivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pour%2C+A+F">Alireza F. Pour</a>, 
<a href="/search/stat?searchtype=author&query=Ashtiani%2C+H">Hassan Ashtiani</a>, 
<a href="/search/stat?searchtype=author&query=Asoodeh%2C+S">Shahab Asoodeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the problem of hypothesis selection under the constraint of local
differential privacy. Given a class $\mathcal{F}$ of $k$ distributions and a
set of i.i.d. samples from an unknown distribution $h$, the goal of hypothesis
selection is to pick a distribution $\hat{f}$ whose total variation distance to
$h$ is comparable with the best distribution in $\mathcal{F}$ (with high
probability). We devise an $\varepsilon$-locally-differentially-private
($\varepsilon$-LDP) algorithm that uses $\Theta\left(\frac{k}{\alpha^2\min
\{\varepsilon^2,1\}}\right)$ samples to guarantee that $d_{TV}(h,\hat{f})\leq
\alpha + 9 \min_{f\in \mathcal{F}}d_{TV}(h,f)$ with high probability. This
sample complexity is optimal for $\varepsilon&lt;1$, matching the lower bound of
Gopi et al. (2020). All previously known algorithms for this problem required
$\Omega\left(\frac{k\log k}{\alpha^2\min \{ \varepsilon^2 ,1\}} \right)$
samples to work.
<br />Moreover, our result demonstrates the power of interaction for
$\varepsilon$-LDP hypothesis selection. Namely, it breaks the known lower bound
of $\Omega\left(\frac{k\log k}{\alpha^2\min \{ \varepsilon^2 ,1\}} \right)$ for
the sample complexity of non-interactive hypothesis selection. Our algorithm
breaks this barrier using only $\Theta(\log \log k)$ rounds of interaction.
<br />To prove our results, we define the notion of \emph{critical queries} for a
Statistical Query Algorithm (SQA) which may be of independent interest.
Informally, an SQA is said to use a small number of critical queries if its
success relies on the accuracy of only a small number of queries it asks. We
then design an LDP algorithm that uses a smaller number of critical queries.
</p>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05647" title="Abstract">arXiv:2312.05647</a> (cross-list from physics.chem-ph) [<a href="/pdf/2312.05647" title="Download PDF">pdf</a>, <a href="/format/2312.05647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Avoiding matrix exponentials for large transition rate matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pessoa%2C+P">Pedro Pessoa</a>, 
<a href="/search/physics?searchtype=author&query=Schweiger%2C+M">Max Schweiger</a>, 
<a href="/search/physics?searchtype=author&query=Presse%2C+S">Steve Presse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Numerical Analysis (math.NA); Computation (stat.CO)

</div>
<p class="mathjax">Exact methods for exponentiation of matrices of dimension $N$ can be
computationally expensive in terms of execution time ($N^{3}$) and memory
requirements ($N^{2}$) not to mention numerical precision issues. A type of
matrix often exponentiated in the sciences is the rate matrix. Here we explore
five methods to exponentiate rate matrices some of which apply even more
broadly to other matrix types. Three of the methods leverage a mathematical
analogy between computing matrix elements of a matrix exponential and computing
transition probabilities of a dynamical processes (technically a Markov jump
process, MJP, typically simulated using Gillespie). In doing so, we identify a
novel MJP-based method relying on restricting the number of ``trajectory" jumps
based on the magnitude of the matrix elements with favorable computational
scaling. We then discuss this method's downstream implications on mixing
properties of Monte Carlo posterior samplers. We also benchmark two other
methods of matrix exponentiation valid for any matrix (beyond rate matrices
and, more generally, positive definite matrices) related to solving
differential equations: Runge-Kutta integrators and Krylov subspace methods.
Under conditions where both the largest matrix element and the number of
non-vanishing elements scale linearly with $N$ -- reasonable conditions for
rate matrices often exponentiated -- computational time scaling with the most
competitive methods (Krylov and one of the MJP-based methods) reduces to $N^2$
with total memory requirements of $N$.
</p>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05651" title="Abstract">arXiv:2312.05651</a> (cross-list from math.PR) [<a href="/pdf/2312.05651" title="Download PDF">pdf</a>, <a href="/format/2312.05651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set-valued recursions arising from vantage-point trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+C">Congzao Dong</a>, 
<a href="/search/math?searchtype=author&query=Marynych%2C+A">Alexander Marynych</a>, 
<a href="/search/math?searchtype=author&query=Molchanov%2C+I">Ilya Molchanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study vantage-point trees constructed using an independent sample from the
uniform distribution on a fixed convex body $K$ in $(\mathbb{R}^d,\|\cdot\|)$,
where $\|\cdot\|$ is an arbitrary homogeneous norm on $\mathbb{R}^d$. We prove
that a sequence of sets, associated with the left boundary of a vantage-point
tree, forms a recurrent Harris chain on the space of convex bodies in
$(\mathbb{R}^d,\|\cdot\|)$. The limiting object is a ball polyhedron, that is,
an a.s.~finite intersection of closed balls in $(\mathbb{R}^d,\|\cdot\|)$ of
possibly different radii. As a consequence, we derive a limit theorem for the
length of the leftmost path of a vantage-point tree.
</p>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05687" title="Abstract">arXiv:2312.05687</a> (cross-list from astro-ph.SR) [<a href="/pdf/2312.05687" title="Download PDF">pdf</a>, <a href="/format/2312.05687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stellar Spectra Fitting with Amortized Neural Posterior Estimation and  nbi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Zhang%2C+K">Keming Zhang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jayasinghe%2C+T">Tharindu Jayasinghe</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bloom%2C+J+S">Joshua S. Bloom</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICML 2023 Workshop on Machine Learning for Astrophysics. 7 pages 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern surveys often deliver hundreds of thousands of stellar spectra at
once, which are fit to spectral models to derive stellar parameters/labels.
Therefore, the technique of Amortized Neural Posterior Estimation (ANPE) stands
out as a suitable approach, which enables the inference of large number of
targets as sub-linear/constant computational costs. Leveraging our new nbi
software package, we train an ANPE model for the APOGEE survey and demonstrate
its efficacy on both mock and real APOGEE stellar spectra. Unique to the nbi
package is its out-of-the-box functionality on astronomical inverse problems
with sequential data. As such, we have been able to acquire the trained model
with minimal effort. We introduce an effective approach to handling the
measurement noise properties inherent in spectral data, which utilizes the
actual uncertainties in the observed data. This allows training data to
resemble observed data, an aspect that is crucial for ANPE applications. Given
the association of spectral data properties with the observing instrument, we
discuss the utility of an ANPE "model zoo," where models are trained for
specific instruments and distributed under the nbi framework to facilitate
real-time stellar parameter inference.
</p>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05692" title="Abstract">arXiv:2312.05692</a> (cross-list from math.FA) [<a href="/pdf/2312.05692" title="Download PDF">pdf</a>, <a href="/ps/2312.05692" title="Download PostScript">ps</a>, <a href="/format/2312.05692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decay estimates for Cayley transforms and inverses of semigroup  generators via the $\mathcal{B}$-calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wakaiki%2C+M">Masashi Wakaiki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Let $-A$ be the generator of a bounded $C_0$-semigroup $(e^{-tA})_{t \geq 0}$
on a Hilbert space. First we study the long-time asymptotic behavior of the
Cayley transform $V_{\omega}(A) := (A-\omega I) (A+\omega I)^{-1}$ with $\omega
&gt;0$. We give a decay estimate for $\|V_{\omega}(A)^nA^{-1}\|$ when
$(e^{-tA})_{t \geq 0}$ is polynomially stable. Considering the case where the
parameter $\omega$ varies, we estimate $\|\prod_{k=1}^n
(V_{\omega_k}(A))A^{-1}\|$ for exponentially stable $C_0$-semigroups
$(e^{-tA})_{t \geq 0}$. Next we show that if the generator $-A$ of the bounded
$C_0$-semigroup has a bounded inverse, then $\sup_{t \geq 0} \|e^{-tA^{-1}}
A^{-\alpha} \| &lt; \infty$ for all $\alpha &gt;0$. We also present an estimate for
the rate of decay of $\|e^{-tA^{-1}} A^{-1} \|$, assuming that $(e^{-tA})_{t
\geq 0}$ is polynomially stable. To obtain these results, we use operator norm
estimates offered by a functional calculus called the $\mathcal{B}$-calculus.
</p>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05707" title="Abstract">arXiv:2312.05707</a> (cross-list from eess.IV) [<a href="/pdf/2312.05707" title="Download PDF">pdf</a>, <a href="/format/2312.05707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Cartesian Self-Supervised Physics-Driven Deep Learning  Reconstruction for Highly-Accelerated Multi-Echo Spiral fMRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gu%2C+H">Hongyi Gu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zidan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Rettenmeier%2C+C">Christoph Rettenmeier</a>, 
<a href="/search/eess?searchtype=author&query=Stenger%2C+V+A">V. Andrew Stenger</a>, 
<a href="/search/eess?searchtype=author&query=Ak%C3%A7akaya%2C+M">Mehmet Ak&#xe7;akaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 ISBI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Functional MRI (fMRI) is an important tool for non-invasive studies of brain
function. Over the past decade, multi-echo fMRI methods that sample multiple
echo times has become popular with potential to improve quantification. While
these acquisitions are typically performed with Cartesian trajectories,
non-Cartesian trajectories, in particular spiral acquisitions, hold promise for
denser sampling of echo times. However, such acquisitions require very high
acceleration rates for sufficient spatiotemporal resolutions. In this work, we
propose to use a physics-driven deep learning (PD-DL) reconstruction to
accelerate multi-echo spiral fMRI by 10-fold. We modify a self-supervised
learning algorithm for optimized training with non-Cartesian trajectories and
use it to train the PD-DL network. Results show that the proposed
self-supervised PD-DL reconstruction achieves high spatio-temporal resolution
with meaningful BOLD analysis.
</p>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05734" title="Abstract">arXiv:2312.05734</a> (cross-list from math.FA) [<a href="/pdf/2312.05734" title="Download PDF">pdf</a>, <a href="/ps/2312.05734" title="Download PostScript">ps</a>, <a href="/format/2312.05734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Duality Approach to Regularized Learning Problems in Banach Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+R">Raymond Cheng</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Y">Yuesheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Learning methods in Banach spaces are often formulated as regularization
problems which minimize the sum of a data fidelity term in a Banach norm and a
regularization term in another Banach norm. Due to the infinite dimensional
nature of the space, solving such regularization problems is challenging. We
construct a direct sum space based on the Banach spaces for the data fidelity
term and the regularization term, and then recast the objective function as the
norm of a suitable quotient space of the direct sum space. In this way, we
express the original regularized problem as an unregularized problem on the
direct sum space, which is in turn reformulated as a dual optimization problem
in the dual space of the direct sum space. The dual problem is to find the
maximum of a linear function on a convex polytope, which may be solved by
linear programming. A solution of the original problem is then obtained by
using related extremal properties of norming functionals from a solution of the
dual problem. Numerical experiments are included to demonstrate that the
proposed duality approach leads to an implementable numerical method for
solving the regularization learning problems.
</p>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05774" title="Abstract">arXiv:2312.05774</a> (cross-list from quant-ph) [<a href="/pdf/2312.05774" title="Download PDF">pdf</a>, <a href="/format/2312.05774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secured Quantum Identity Authentication Protocol for Quantum Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shaban%2C+M">Mohamed Shaban</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ismail%2C+M">Muhammad Ismail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Quantum Internet signifies a remarkable advancement in communication
technology, harnessing the principles of quantum entanglement and superposition
to facilitate unparalleled levels of security and efficient computations.
Quantum communication can be achieved through the utilization of quantum
entanglement. Through the exchange of entangled pairs between two entities,
quantum communication becomes feasible, enabled by the process of quantum
teleportation. Given the lossy nature of the channels and the exponential
decoherence of the transmitted photons, a set of intermediate nodes can serve
as quantum repeaters to perform entanglement swapping and directly entangle two
distant nodes. Such quantum repeaters may be malicious and by setting up
malicious entanglements, intermediate nodes can jeopardize the confidentiality
of the quantum information exchanged between the two communication nodes.
Hence, this paper proposes a quantum identity authentication protocol that
protects quantum networks from malicious entanglements. Unlike the existing
protocols, the proposed quantum authentication protocol does not require
periodic refreshments of the shared secret keys. Simulation results demonstrate
that the proposed protocol can detect malicious entanglements with a 100%
probability after an average of 4 authentication rounds.
</p>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05775" title="Abstract">arXiv:2312.05775</a> (cross-list from quant-ph) [<a href="/pdf/2312.05775" title="Download PDF">pdf</a>, <a href="/format/2312.05775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Efficient Entanglement Distribution Protocol for Near-Term  Quantum Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Skjellum%2C+N">Nicholas Skjellum</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shaban%2C+M">Mohamed Shaban</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ismail%2C+M">Muhammad Ismail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Quantum information technology has the potential to revolutionize computing,
communications, and security. To fully realize its potential, quantum
processors with millions of qubits are needed, which is still far from being
accomplished. Thus, it is important to establish quantum networks to enable
distributed quantum computing to leverage existing and near-term quantum
processors into more powerful resources. This paper introduces a protocol to
distribute entanglements among quantum devices within classical-quantum
networks with limited quantum links, enabling more efficient quantum
teleportation in near-term hybrid networks. The proposed protocol uses
entanglement swapping to distribute entanglements efficiently in a butterfly
network, then classical network coding is applied to enable quantum
teleportation while overcoming network bottlenecks and minimizing qubit
requirements for individual nodes. Experimental results show that the proposed
protocol requires quantum resources that scale linearly with network size, with
individual nodes only requiring a fixed number of qubits. For small network
sizes of up to three transceiver pairs, the proposed protocol outperforms the
benchmark by using 17% fewer qubit resources, achieving 8.8% higher accuracy,
and with a 35% faster simulation time. The percentage improvement increases
significantly for large network sizes. We also propose a protocol for securing
entanglement distribution against malicious entanglements using quantum state
encoding through rotation. Our analysis shows that this method requires no
communication overhead and reduces the chance of a malicious node retrieving a
quantum state to 7.2%. The achieved results point toward a protocol that
enables a highly scalable, efficient, and secure near-term quantum Internet.
</p>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05786" title="Abstract">arXiv:2312.05786</a> (cross-list from eess.SP) [<a href="/pdf/2312.05786" title="Download PDF">pdf</a>, <a href="/format/2312.05786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Joint Design of Pilot, Channel Feedback, and Hybrid  Beamforming in FDD Massive MIMO-OFDM Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Junyi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+W">Weifeng Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+S">Shu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofeng Li</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+X">Xingqin Lin</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+M">Meixia Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, acccpted by IEEE Communication Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This letter considers the transceiver design in frequency division duplex
(FDD) massive multiple-input multiple-output (MIMO) orthogonal frequency
division multiplexing (OFDM) systems for high-quality data transmission. We
propose a novel deep learning based framework where the procedures of pilot
design, channel feedback, and hybrid beamforming are realized by carefully
crafted deep neural networks. All the considered modules are jointly learned in
an end-to-end manner, and a graph neural network is adopted to effectively
capture interactions between beamformers based on the built graphical
representation. Numerical results validate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05791" title="Abstract">arXiv:2312.05791</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.05791" title="Download PDF">pdf</a>, <a href="/ps/2312.05791" title="Download PostScript">ps</a>, <a href="/format/2312.05791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gluing GAP to RAS Mutants: A New Approach to an Old Problem in Cancer  Drug Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ran%C4%91elovi%C4%87%2C+I">Ivan Ran&#x111;elovi&#x107;</a>, 
<a href="/search/q-bio?searchtype=author&query=Ny%C3%ADri%2C+K">Kinga Ny&#xed;ri</a>, 
<a href="/search/q-bio?searchtype=author&query=Kopp%C3%A1ny%2C+G">Gergely Kopp&#xe1;ny</a>, 
<a href="/search/q-bio?searchtype=author&query=Baranyi%2C+M">Marcel Baranyi</a>, 
<a href="/search/q-bio?searchtype=author&query=T%C3%B3v%C3%A1ri%2C+J">J&#xf3;zsef T&#xf3;v&#xe1;ri</a>, 
<a href="/search/q-bio?searchtype=author&query=Kigy%C3%B3s%2C+A">Attila Kigy&#xf3;s</a>, 
<a href="/search/q-bio?searchtype=author&query=Tim%C3%A1r%2C+J">J&#xf3;zsef Tim&#xe1;r</a>, 
<a href="/search/q-bio?searchtype=author&query=V%C3%A9rtessy%2C+B+G">Be&#xe1;ta G. V&#xe9;rtessy</a>, 
<a href="/search/q-bio?searchtype=author&query=Grolmusz%2C+V">Vince Grolmusz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Mutated genes may lead to cancer development in numerous tissues. While more
than 600 cancer-causing genes are known today, some of the most widespread
mutations are connected to the RAS gene: RAS mutations are found in
approximately 25% of all human tumors. Specifically, KRAS mutations are
involved in the three most lethal cancers in U.S.: pancreatic ductal
adenocarcinoma, colorectal adenocarcinoma, and lung adenocarcinoma. These
cancers are among the most difficult to treat, and they are frequently excluded
from chemotherapeutic attacks as hopeless cases. The mutated KRAS proteins have
specific 3-dimensional conformations, which perturb functional interaction with
the GAP protein on the GAP:RAS complex surface leading to a signaling cascade
and uncontrolled cell growth. Here we describe a gluing docking method for
finding small molecules that bind to both the GAP and the mutated KRAS
molecules. These small molecules glue together the GAP and the mutated KRAS
molecules and may serve as new cancer drugs for the most lethal, most
difficult-to-treat carcinomas. As a proof of concept, we identify two new,
drug-like small molecules with the new method: these compounds specifically
inhibit the growth of PANC-1 cell line with KRAS mutation G12D in vitro and in
vivo. Importantly, the two new compounds show significantly lower IC50 and
higher specificity against the G12D KRAS mutant as compared to the recently
described MRTX-1133 inhibitor against the G12D KRAS mutant.
</p>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05793" title="Abstract">arXiv:2312.05793</a> (cross-list from stat.ML) [<a href="/pdf/2312.05793" title="Download PDF">pdf</a>, <a href="/format/2312.05793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Spatially Inhomogeneous Diffusion Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ren%2C+Y">Yinuo Ren</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Y">Yiping Lu</a>, 
<a href="/search/stat?searchtype=author&query=Ying%2C+L">Lexing Ying</a>, 
<a href="/search/stat?searchtype=author&query=Rotskoff%2C+G+M">Grant M. Rotskoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Statistics Theory (math.ST)

</div>
<p class="mathjax">Inferring a diffusion equation from discretely-observed measurements is a
statistical challenge of significant importance in a variety of fields, from
single-molecule tracking in biophysical systems to modeling financial
instruments. Assuming that the underlying dynamical process obeys a
$d$-dimensional stochastic differential equation of the form
$$\mathrm{d}\boldsymbol{x}_t=\boldsymbol{b}(\boldsymbol{x}_t)\mathrm{d}
t+\Sigma(\boldsymbol{x}_t)\mathrm{d}\boldsymbol{w}_t,$$ we propose neural
network-based estimators of both the drift $\boldsymbol{b}$ and the
spatially-inhomogeneous diffusion tensor $D = \Sigma\Sigma^{T}$ and provide
statistical convergence guarantees when $\boldsymbol{b}$ and $D$ are
$s$-H\"older continuous. Notably, our bound aligns with the minimax optimal
rate $N^{-\frac{2s}{2s+d}}$ for nonparametric function estimation even in the
presence of correlation within observational data, which necessitates careful
handling when establishing fast-rate generalization bounds. Our theoretical
results are bolstered by numerical experiments demonstrating accurate inference
of spatially-inhomogeneous diffusion tensors.
</p>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05794" title="Abstract">arXiv:2312.05794</a> (cross-list from math.ST) [<a href="/pdf/2312.05794" title="Download PDF">pdf</a>, <a href="/ps/2312.05794" title="Download PostScript">ps</a>, <a href="/format/2312.05794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Statistics of the Sample Covariance Matrix for High Dimensional  Linear Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Naeem%2C+M+A">Muhammad Abdullah Naeem</a>, 
<a href="/search/math?searchtype=author&query=Pajic%2C+M">Miroslav Pajic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.10523">arXiv:2310.10523</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Performance of ordinary least squares(OLS) method for the \emph{estimation of
high dimensional stable state transition matrix} $A$(i.e., spectral radius
$\rho(A)&lt;1$) from a single noisy observed trajectory of the linear time
invariant(LTI)\footnote{Linear Gaussian (LG) in Markov chain literature} system
$X_{-}:(x_0,x_1, \ldots,x_{N-1})$ satisfying \begin{equation}
<br />x_{t+1}=Ax_{t}+w_{t}, \hspace{10pt} \text{ where } w_{t} \thicksim
N(0,I_{n}), \end{equation}
<br />heavily rely on negative moments of the sample covariance matrix:
$(X_{-}X_{-}^{*})=\sum_{i=0}^{N-1}x_{i}x_{i}^{*}$ and singular values of
$EX_{-}^{*}$, where $E$ is a rectangular Gaussian ensemble $E=[w_0, \ldots,
w_{N-1}]$. Negative moments requires sharp estimates on all the eigenvalues
$\lambda_{1}\big(X_{-}X_{-}^{*}\big) \geq \ldots \geq
\lambda_{n}\big(X_{-}X_{-}^{*}\big) \geq 0$. Leveraging upon recent results on
spectral theorem for non-Hermitian operators in \cite{naeem2023spectral}, along
with concentration of measure phenomenon and perturbation theory(Gershgorins'
and Cauchys' interlacing theorem) we show that only when $A=A^{*}$, typical
order of $\lambda_{j}\big(X_{-}X_{-}^{*}\big) \in \big[N-n\sqrt{N},
N+n\sqrt{N}\big]$ for all $j \in [n]$. However, in \emph{high dimensions} when
$A$ has only one distinct eigenvalue $\lambda$ with geometric multiplicity of
one, then as soon as eigenvalue leaves \emph{complex half unit disc}, largest
eigenvalue suffers from curse of dimensionality:
$\lambda_{1}\big(X_{-}X_{-}^{*}\big)=\Omega\big( \lfloor\frac{N}{n}\rfloor
e^{\alpha_{\lambda}n} \big)$, while smallest eigenvalue
$\lambda_{n}\big(X_{-}X_{-}^{*}\big) \in (0, N+\sqrt{N}]$. Consequently, OLS
estimator incurs a \emph{phase transition} and becomes \emph{transient:
increasing iteration only worsens estimation error}, all of this happening when
the dynamics are generated from stable systems.
</p>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05827" title="Abstract">arXiv:2312.05827</a> (cross-list from q-fin.TR) [<a href="/pdf/2312.05827" title="Download PDF">pdf</a>, <a href="/format/2312.05827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Toxic Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Cartea%2C+%C3%81">&#xc1;lvaro Cartea</a>, 
<a href="/search/q-fin?searchtype=author&query=Duran-Martin%2C+G">Gerardo Duran-Martin</a>, 
<a href="/search/q-fin?searchtype=author&query=S%C3%A1nchez-Betancourt%2C+L">Leandro S&#xe1;nchez-Betancourt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper develops a framework to predict toxic trades that a broker
receives from her clients. Toxic trades are predicted with a novel online
Bayesian method which we call the projection-based unification of last-layer
and subspace estimation (PULSE). PULSE is a fast and statistically-efficient
online procedure to train a Bayesian neural network sequentially. We employ a
proprietary dataset of foreign exchange transactions to test our methodology.
PULSE outperforms standard machine learning and statistical methods when
predicting if a trade will be toxic; the benchmark methods are logistic
regression, random forests, and a recursively-updated maximum-likelihood
estimator. We devise a strategy for the broker who uses toxicity predictions to
internalise or to externalise each trade received from her clients. Our
methodology can be implemented in real-time because it takes less than one
millisecond to update parameters and make a prediction. Compared with the
benchmarks, PULSE attains the highest PnL and the largest avoided loss for the
horizons we consider.
</p>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05837" title="Abstract">arXiv:2312.05837</a> (cross-list from quant-ph) [<a href="/pdf/2312.05837" title="Download PDF">pdf</a>, <a href="/format/2312.05837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast Numerical Solver of Quantum-inspired Ising Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+L">Langyu Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+Y">Yu Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum annealers, coherent Ising machines and digital Ising machines for
solving quantum-inspired optimization problems have been developing rapidly due
to their near-term applications. The numerical solvers of the digital Ising
machines are based on traditional computing devices. In this work, we propose a
fast and efficient solver for the Ising optimization problems. The algorithm
consists of a pruning method that exploits the graph information of the Ising
model to reduce the computational complexity, and a domain selection method
which introduces significant acceleration by relaxing the discrete feasible
domain into a continuous one to incorporate the efficient gradient descent
method. The experiment results show that our solver can be an order of
magnitude faster than the classical solver, and at least two times faster than
the quantum-inspired annealers including the simulated quantum annealing on the
benchmark problems. With more relaxed requirements on hardware and lower cost
than quantum annealing, the proposed solver has the potential for near-term
application in solving challenging optimization problems as well as serving as
a benchmark for evaluating the advantage of quantum devices.
</p>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05878" title="Abstract">arXiv:2312.05878</a> (cross-list from stat.ML) [<a href="/pdf/2312.05878" title="Download PDF">pdf</a>, <a href="/format/2312.05878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skew Probabilistic Neural Networks for Learning from Imbalanced Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Naik%2C+S+M">Shraddha M. Naik</a>, 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+T">Tanujit Chakraborty</a>, 
<a href="/search/stat?searchtype=author&query=Hadid%2C+A">Abdenour Hadid</a>, 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+B">Bibhas Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-world datasets often exhibit imbalanced data distribution, where certain
class levels are severely underrepresented. In such cases, traditional pattern
classifiers have shown a bias towards the majority class, impeding accurate
predictions for the minority class. This paper introduces an imbalanced
data-oriented approach using probabilistic neural networks (PNNs) with a skew
normal probability kernel to address this major challenge. PNNs are known for
providing probabilistic outputs, enabling quantification of prediction
confidence and uncertainty handling. By leveraging the skew normal
distribution, which offers increased flexibility, particularly for imbalanced
and non-symmetric data, our proposed Skew Probabilistic Neural Networks
(SkewPNNs) can better represent underlying class densities. To optimize the
performance of the proposed approach on imbalanced datasets, hyperparameter
fine-tuning is imperative. To this end, we employ a population-based heuristic
algorithm, Bat optimization algorithms, for effectively exploring the
hyperparameter space. We also prove the statistical consistency of the density
estimates which suggests that the true distribution will be approached smoothly
as the sample size increases. Experimental simulations have been conducted on
different synthetic datasets, comparing various benchmark-imbalanced learners.
Our real-data analysis shows that SkewPNNs substantially outperform
state-of-the-art machine learning methods for both balanced and imbalanced
datasets in most experimental settings.
</p>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05883" title="Abstract">arXiv:2312.05883</a> (cross-list from physics.ins-det) [<a href="/pdf/2312.05883" title="Download PDF">pdf</a>, <a href="/format/2312.05883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using deep neural networks to improve the precision of fast-sampled  particle timing detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kocot%2C+M">Mateusz Kocot</a>, 
<a href="/search/physics?searchtype=author&query=Misan%2C+K">Krzysztof Misan</a>, 
<a href="/search/physics?searchtype=author&query=Avati%2C+V">Valentina Avati</a>, 
<a href="/search/physics?searchtype=author&query=Bossini%2C+E">Edoardo Bossini</a>, 
<a href="/search/physics?searchtype=author&query=Grzanka%2C+L">Leszek Grzanka</a>, 
<a href="/search/physics?searchtype=author&query=Minafra%2C+N">Nicola Minafra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted for publication in Computer Science journal: <a href="http://journals.agh.edu.pl/csci">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Measurements from particle timing detectors are often affected by the time
walk effect caused by statistical fluctuations in the charge deposited by
passing particles. The constant fraction discriminator (CFD) algorithm is
frequently used to mitigate this effect both in test setups and in running
experiments, such as the CMS-PPS system at the CERN's LHC. The CFD is simple
and effective but does not leverage all voltage samples in a time series. Its
performance could be enhanced with deep neural networks, which are commonly
used for time series analysis, including computing the particle arrival time.
We evaluated various neural network architectures using data acquired at the
test beam facility in the DESY-II synchrotron, where a precise MCP
(MicroChannel Plate) detector was installed in addition to PPS diamond timing
detectors. MCP measurements were used as a reference to train the networks and
compare the results with the standard CFD method. Ultimately, we improved the
timing precision by 8% to 23%, depending on the detector's readout channel. The
best results were obtained using a UNet-based model, which outperformed
classical convolutional networks and the multilayer perceptron.
</p>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05911" title="Abstract">arXiv:2312.05911</a> (cross-list from math.ST) [<a href="/pdf/2312.05911" title="Download PDF">pdf</a>, <a href="/ps/2312.05911" title="Download PostScript">ps</a>, <a href="/format/2312.05911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A leave-one-out approach to approximate message passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bao%2C+Z">Zhigang Bao</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+Q">Qiyang Han</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xiaocong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
<p class="mathjax">Approximate message passing (AMP) has emerged both as a popular class of
iterative algorithms and as a powerful analytic tool in a wide range of
statistical estimation problems and statistical physics models. A well
established line of AMP theory proves Gaussian approximations for the empirical
distributions of the AMP iterate in the high dimensional limit, under the GOE
random matrix model and its variants, via the celebrated conditioning
technique.
<br />This paper provides a leave-one-out representation for the AMP iterate that
holds under a broad class of Gaussian random matrix models with general
variance profiles. In contrast to the existing AMP theory that describes the
empirical distributions of the AMP iterate via a low dimensional state
evolution, our leave-one-out representation yields an intrinsically high
dimensional state evolution formula which characterizes the possibly
heterogeneous, entrywise behavior of the AMP iterate under the prescribed
random matrix models.
<br />To exemplify some distinct features of our AMP theory in applications, we
analyze, in the context of regularized linear estimation, the precise
stochastic behavior of the Ridge estimator for independent and non-identically
distributed observations whose covariates exhibit general variance profiles. We
find that its distribution is characterized via a weighted Ridge estimator in a
heterogeneous Gaussian sequence model. Notably, in contrast to the i.i.d.
sampling scenario, the effective noise and regularization are now full
dimensional vectors determined via a high dimensional system of equations.
<br />Our method of proof differs significantly from the master conditioning
approach, and relies on an inductive method that sheds light into the intricate
cancellation scheme for the trace functional of certain random matrix recursion
associated with the AMP.
</p>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05916" title="Abstract">arXiv:2312.05916</a> (cross-list from math.OC) [<a href="/pdf/2312.05916" title="Download PDF">pdf</a>, <a href="/ps/2312.05916" title="Download PostScript">ps</a>, <a href="/format/2312.05916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Switching Frequency Limitation with Finite Control Set Model Predictive  Control via Slack Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hartmann%2C+L+M">Luca M. Hartmann</a>, 
<a href="/search/math?searchtype=author&query=Karaca%2C+O">Orcun Karaca</a>, 
<a href="/search/math?searchtype=author&query=Dorfling%2C+T">Tinus Dorfling</a>, 
<a href="/search/math?searchtype=author&query=Geyer%2C+T">Tobias Geyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Past work proposed an extension to finite control set model predictive
control to track both a current reference and a switching frequency reference,
simultaneously. Such an objective can jeopardize the current tracking
performance, and this can potentially be alleviated by instead limiting the
switching frequency. To this end, we propose to limit the switching frequency
in finite control set model predictive control. The switching frequency is
captured with an infinite impulse response filter and bounded by an inequality
constraint; its corresponding slack variable is penalized in the cost function.
To solve the resulting problem efficiently, a sphere decoder with a
computational speed-up is presented.
</p>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05929" title="Abstract">arXiv:2312.05929</a> (cross-list from math.LO) [<a href="/pdf/2312.05929" title="Download PDF">pdf</a>, <a href="/ps/2312.05929" title="Download PostScript">ps</a>, <a href="/format/2312.05929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A non-uniform view of Craig interpolation in modal logics with linear  frames
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kurucz%2C+A">Agi Kurucz</a>, 
<a href="/search/math?searchtype=author&query=Wolter%2C+F">Frank Wolter</a>, 
<a href="/search/math?searchtype=author&query=Zakharyaschev%2C+M">Michael Zakharyaschev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Normal modal logics extending the logic K4.3 of linear transitive frames are
known to lack the Craig interpolation property, except some logics of bounded
depth such as S5. We turn this `negative' fact into a research question and
pursue a non-uniform approach to Craig interpolation by investigating the
following interpolant existence problem: decide whether there exists a Craig
interpolant between two given formulas in any fixed logic above K4.3. Using a
bisimulation-based characterisation of interpolant existence for descriptive
frames, we show that this problem is decidable and coNP-complete for all
finitely axiomatisable normal modal logics containing K4.3. It is thus not
harder than entailment in these logics, which is in sharp contrast to other
recent non-uniform interpolation results. We also extend our approach to
Priorean temporal logics (with both past and future modalities) over the
standard time flows-the integers, rationals, reals, and finite strict linear
orders-none of which is blessed with the Craig interpolation property.
</p>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05930" title="Abstract">arXiv:2312.05930</a> (cross-list from eess.IV) [<a href="/pdf/2312.05930" title="Download PDF">pdf</a>, <a href="/format/2312.05930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Dataset and Automated Pipeline for Nailfold Capillary  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+L">Linxi Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+J">Jiankai Tang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+D">Dongyu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Guangyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset, code, pretrained models: <a href="https://github.com/THU-CS-PI-LAB/ANFC-Automated-Nailfold-Capillary">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Nailfold capillaroscopy is a well-established method for assessing health
conditions, but the untapped potential of automated medical image analysis
using machine learning remains despite recent advancements. In this
groundbreaking study, we present a pioneering effort in constructing a
comprehensive dataset-321 images, 219 videos, 68 clinic reports, with expert
annotations-that serves as a crucial resource for training deep-learning
models. Leveraging this dataset, we propose an end-to-end nailfold capillary
analysis pipeline capable of automatically detecting and measuring diverse
morphological and dynamic features. Experimental results demonstrate sub-pixel
measurement accuracy and 90% accuracy in predicting abnormality portions,
highlighting its potential for advancing quantitative medical research and
enabling pervasive computing in healthcare. We've shared our open-source codes
and data (available at
https://github.com/THU-CS-PI-LAB/ANFC-Automated-Nailfold-Capillary) to
contribute to transformative progress in computational medical image analysis.
</p>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05945" title="Abstract">arXiv:2312.05945</a> (cross-list from math.CO) [<a href="/pdf/2312.05945" title="Download PDF">pdf</a>, <a href="/format/2312.05945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4-Chromatic Graphs Have At Least 4 Cycles of Length $0 \bmod 3$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+S">Sean Kim</a>, 
<a href="/search/math?searchtype=author&query=Picollelli%2C+M+E">Michael E. Picollelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A 2018 conjecture of Brewster, McGuinness, Moore, and Noel asserts that for
$k \ge 3$, if a graph has chromatic number greater than $k$, then it contains
at least as many cycles of length $0 \bmod k$ as the complete graph on $k+1$
vertices. Our main result confirms this in the $k=3$ case by showing every
$4$-critical graph contains at least $4$ cycles of length $0 \bmod 3$, and that
$K_4$ is the unique such graph achieving the minimum.
<br />We make progress on the general conjecture as well, showing that
$(k+1)$-critical graphs with minimum degree $k$ have at least as many cycles of
length $0\bmod r$ as $K_{k+1}$, provided $k+1 \ne 0 \bmod r$. We also show that
$K_{k+1}$ uniquely minimizes the number of cycles of length $1\bmod k$ among
all $(k+1)$-critical graphs, strengthening a recent result of Moore and West
and extending it to the $k=3$ case.
</p>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05953" title="Abstract">arXiv:2312.05953</a> (cross-list from eess.IV) [<a href="/pdf/2312.05953" title="Download PDF">pdf</a>, <a href="/ps/2312.05953" title="Download PostScript">ps</a>, <a href="/format/2312.05953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadImageGAN -- A Multi-modal Dataset-Scale Generative AI for Medical  Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zelong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+A">Alexander Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+A">Arnold Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yilmaz%2C+A">Alara Yilmaz</a>, 
<a href="/search/eess?searchtype=author&query=Yoo%2C+M">Maxwell Yoo</a>, 
<a href="/search/eess?searchtype=author&query=Sullivan%2C+M">Mikey Sullivan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Catherine Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Grant%2C+J">James Grant</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Daiqing Li</a>, 
<a href="/search/eess?searchtype=author&query=Fayad%2C+Z+A">Zahi A. Fayad</a>, 
<a href="/search/eess?searchtype=author&query=Huver%2C+S">Sean Huver</a>, 
<a href="/search/eess?searchtype=author&query=Deyer%2C+T">Timothy Deyer</a>, 
<a href="/search/eess?searchtype=author&query=Mei%2C+X">Xueyan Mei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning in medical imaging often requires large-scale, high-quality
data or initiation with suitably pre-trained weights. However, medical datasets
are limited by data availability, domain-specific knowledge, and privacy
concerns, and the creation of large and diverse radiologic databases like
RadImageNet is highly resource-intensive. To address these limitations, we
introduce RadImageGAN, the first multi-modal radiologic data generator, which
was developed by training StyleGAN-XL on the real RadImageNet dataset of
102,774 patients. RadImageGAN can generate high-resolution synthetic medical
imaging datasets across 12 anatomical regions and 130 pathological classes in 3
modalities. Furthermore, we demonstrate that RadImageGAN generators can be
utilized with BigDatasetGAN to generate multi-class pixel-wise annotated paired
synthetic images and masks for diverse downstream segmentation tasks with
minimal manual annotation. We showed that using synthetic auto-labeled data
from RadImageGAN can significantly improve performance on four diverse
downstream segmentation datasets by augmenting real training data and/or
developing pre-trained weights for fine-tuning. This shows that RadImageGAN
combined with BigDatasetGAN can improve model performance and address data
scarcity while reducing the resources needed for annotations for segmentation
tasks.
</p>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05980" title="Abstract">arXiv:2312.05980</a> (cross-list from math.OC) [<a href="/pdf/2312.05980" title="Download PDF">pdf</a>, <a href="/format/2312.05980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum flow-based formulation for the optimal location of electric  vehicle charging stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Parent%2C+P">Pierre-Luc Parent</a>, 
<a href="/search/math?searchtype=author&query=Carvalho%2C+M">Margarida Carvalho</a>, 
<a href="/search/math?searchtype=author&query=Anjos%2C+M+F">Miguel F. Anjos</a>, 
<a href="/search/math?searchtype=author&query=Atallah%2C+R">Ribal Atallah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the increasing effects of climate change, the urgency to step away from
fossil fuels is greater than ever before. Electric vehicles (EVs) are one way
to diminish these effects, but their widespread adoption is often limited by
the insufficient availability of charging stations. In this work, our goal is
to expand the infrastructure of EV charging stations, in order to provide a
better quality of service in terms of user satisfaction (and availability of
charging stations). Specifically, our focus is directed towards urban areas. We
first propose a model for the assignment of EV charging demand to stations,
framing it as a maximum flow problem. This model is the basis for the
evaluation of user satisfaction with a given charging infrastructure. Secondly,
we incorporate the maximum flow model into a mixed-integer linear program,
where decisions on the opening of new stations and on the expansion of their
capacity through additional outlets is accounted for. We showcase our
methodology for the city of Montreal, demonstrating the scalability of our
approach to handle real-world scenarios. We conclude that considering both
spacial and temporal variations in charging demand is meaningful when solving
realistic instances.
</p>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05986" title="Abstract">arXiv:2312.05986</a> (cross-list from eess.IV) [<a href="/pdf/2312.05986" title="Download PDF">pdf</a>, <a href="/format/2312.05986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of Cortical Surfaces with Spherical Topology from Infant  Brain MRI via Recurrent Deformation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaoyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Junjie Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Siyuan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ahmad%2C+S">Sahar Ahmad</a>, 
<a href="/search/eess?searchtype=author&query=Yap%2C+P">Pew-Thian Yap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cortical surface reconstruction (CSR) from MRI is key to investigating brain
structure and function. While recent deep learning approaches have
significantly improved the speed of CSR, a substantial amount of runtime is
still needed to map the cortex to a topologically-correct spherical manifold to
facilitate downstream geometric analyses. Moreover, this mapping is possible
only if the topology of the surface mesh is homotopic to a sphere. Here, we
present a method for simultaneous CSR and spherical mapping efficiently within
seconds. Our approach seamlessly connects two sub-networks for white and pial
surface generation. Residual diffeomorphic deformations are learned iteratively
to gradually warp a spherical template mesh to the white and pial surfaces
while preserving mesh topology and uniformity. The one-to-one vertex
correspondence between the template sphere and the cortical surfaces allows
easy and direct mapping of geometric features like convexity and curvature to
the sphere for visualization and downstream processing. We demonstrate the
efficacy of our approach on infant brain MRI, which poses significant
challenges to CSR due to tissue contrast changes associated with rapid brain
development during the first postnatal year. Performance evaluation based on a
dataset of infants from 0 to 12 months demonstrates that our method
substantially enhances mesh regularity and reduces geometric errors,
outperforming state-of-the-art deep learning approaches, all while maintaining
high computational efficiency.
</p>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06015" title="Abstract">arXiv:2312.06015</a> (cross-list from astro-ph.GA) [<a href="/pdf/2312.06015" title="Download PDF">pdf</a>, <a href="/format/2312.06015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up astrochemical reaction networks with autoencoders and neural  ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Sulzer%2C+I">Immanuel Sulzer</a>, 
<a href="/search/astro-ph?searchtype=author&query=Buck%2C+T">Tobias Buck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the "Machine Learning and the Physical Sciences" Workshop at Neurips, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In astrophysics, solving complex chemical reaction networks is essential but
computationally demanding due to the high dimensionality and stiffness of the
ODE systems. Traditional approaches for reducing computational load are often
specialized to specific chemical networks and require expert knowledge. This
paper introduces a machine learning-based solution employing autoencoders for
dimensionality reduction and a latent space neural ODE solver to accelerate
astrochemical reaction network computations. Additionally, we propose a
cost-effective latent space linear function solver as an alternative to neural
ODEs. These methods are assessed on a dataset comprising 29 chemical species
and 224 reactions. Our findings demonstrate that the neural ODE achieves a 55x
speedup over the baseline model while maintaining significantly higher accuracy
by up to two orders of magnitude reduction in relative error. Furthermore, the
linear latent model enhances accuracy and achieves a speedup of up to 4000x
compared to standard methods.
</p>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06025" title="Abstract">arXiv:2312.06025</a> (cross-list from eess.SP) [<a href="/pdf/2312.06025" title="Download PDF">pdf</a>, <a href="/format/2312.06025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stress Management Using Virtual Reality-Based Attention Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mahmoud%2C+R">Rojaina Mahmoud</a>, 
<a href="/search/eess?searchtype=author&query=Mamdouh%2C+M">Mona Mamdouh</a>, 
<a href="/search/eess?searchtype=author&query=Attallah%2C+O">Omneya Attallah</a>, 
<a href="/search/eess?searchtype=author&query=Al-Kabbany%2C+A">Ahmad Al-Kabbany</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this research, we are concerned with the applicability of virtual
reality-based attention training as a tool for stress management. Mental stress
is a worldwide challenge that is still far from being fully managed. This has
maintained a remarkable research attention on developing and validating tools
for detecting and managing stress. Technology-based tools have been at the
heart of these endeavors, including virtual reality (VR) technology.
Nevertheless, the potential of VR lies, to a large part, in the nature of the
content being consumed through such technology. In this study, we investigate
the impact of a special type of content, namely, attention training, on the
feasibility of using VR for stress management. On a group of fourteen
undergraduate engineering students, we conducted a study in which the
participants got exposed twice to a stress inducer while their EEG signals were
being recorded. The first iteration involved VR-based attention training before
starting the stress task while the second time did not. Using multiple features
and various machine learning models, we show that VR-based attention training
has consistently resulted in reducing the number of recognized stress instances
in the recorded EEG signals. This research gives preliminary insights on
adopting VR-based attention training for managing stress, and future studies
are required to replicate the results in larger samples.
</p>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06065" title="Abstract">arXiv:2312.06065</a> (cross-list from eess.AS) [<a href="/pdf/2312.06065" title="Download PDF">pdf</a>, <a href="/format/2312.06065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEND-DEMUX: End-to-End Neural Speaker Diarization via Demultiplexed  Speaker Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mun%2C+S+H">Sung Hwan Mun</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+M+H">Min Hyun Han</a>, 
<a href="/search/eess?searchtype=author&query=Moon%2C+C">Canyeong Moon</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+N+S">Nam Soo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Signal Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In recent years, there have been studies to further improve the end-to-end
neural speaker diarization (EEND) systems. This letter proposes the EEND-DEMUX
model, a novel framework utilizing demultiplexed speaker embeddings. In this
work, we focus on disentangling speaker-relevant information in the latent
space and then transform each separated latent variable into its corresponding
speech activity. EEND-DEMUX can directly obtain separated speaker embeddings
through the demultiplexing operation in the inference phase without an external
speaker diarization system, an embedding extractor, or a heuristic decoding
technique. Furthermore, we employ a multi-head cross-attention mechanism to
capture the correlation between mixture and separated speaker embeddings
effectively. We formulate three loss functions based on matching,
orthogonality, and sparsity constraints to learn robust demultiplexed speaker
embeddings. The experimental results on the LibriMix dataset show consistently
improved performance in both a fixed and flexible number of speakers scenarios.
</p>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06101" title="Abstract">arXiv:2312.06101</a> (cross-list from eess.IV) [<a href="/pdf/2312.06101" title="Download PDF">pdf</a>, <a href="/format/2312.06101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hundred-Kilobyte Lookup Tables for Efficient Single-Image  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+B">Binxiao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J+C+L">Jason Chun Lok Li</a>, 
<a href="/search/eess?searchtype=author&query=Ran%2C+J">Jie Ran</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jiajun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+D">Dahai Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+N">Ngai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Conventional super-resolution (SR) schemes make heavy use of convolutional
neural networks (CNNs), which involve intensive multiply-accumulate (MAC)
operations, and require specialized hardware such as graphics processing units.
This contradicts the regime of edge AI that often runs on devices strained by
power, computing, and storage resources. Such a challenge has motivated a
series of lookup table (LUT)-based SR schemes that employ simple LUT readout
and largely elude CNN computation. Nonetheless, the multi-megabyte LUTs in
existing methods still prohibit on-chip storage and necessitate off-chip memory
transport. This work tackles this storage hurdle and innovates hundred-kilobyte
LUT (HKLUT) models amenable to on-chip cache. Utilizing an asymmetric
two-branch multistage network coupled with a suite of specialized kernel
patterns, HKLUT demonstrates an uncompromising performance and superior
hardware efficiency over existing LUT schemes.
</p>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06152" title="Abstract">arXiv:2312.06152</a> (cross-list from hep-ph) [<a href="/pdf/2312.06152" title="Download PDF">pdf</a>, <a href="/format/2312.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the performance of weak supervision searches using transfer  and meta-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Beauchesne%2C+H">Hugues Beauchesne</a>, 
<a href="/search/hep-ph?searchtype=author&query=Chen%2C+Z">Zong-En Chen</a>, 
<a href="/search/hep-ph?searchtype=author&query=Chiang%2C+C">Cheng-Wei Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Weak supervision searches have in principle the advantages of both being able
to train on experimental data and being able to learn distinctive signal
properties. However, the practical applicability of such searches is limited by
the fact that successfully training a neural network via weak supervision can
require a large amount of signal. In this work, we seek to create neural
networks that can learn from less experimental signal by using transfer and
meta-learning. The general idea is to first train a neural network on
simulations, thereby learning concepts that can be reused or becoming a more
efficient learner. The neural network would then be trained on experimental
data and should require less signal because of its previous training. We find
that transfer and meta-learning can substantially improve the performance of
weak supervision searches.
</p>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06176" title="Abstract">arXiv:2312.06176</a> (cross-list from quant-ph) [<a href="/pdf/2312.06176" title="Download PDF">pdf</a>, <a href="/format/2312.06176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvement in Variational Quantum Algorithms by Measurement  Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hahm%2C+J">Jaehoon Hahm</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kim%2C+H">Hayeon Kim</a>, 
<a href="/search/quant-ph?searchtype=author&query=Park%2C+Y+J">Young June Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Variational Quantum Algorithms (VQAs) are expected to be promising algorithms
with quantum advantages that can be run at quantum computers in the close
future. In this work, we review simple rules in basic quantum circuits, and
propose a simplification method, Measurement Simplification, that simplifies
the expression for the measurement of quantum circuit. By the Measurement
Simplification, we simplified the specific result expression of VQAs and
obtained large improvements in calculation time and required memory size. Here
we applied Measurement Simplification to Variational Quantum Linear Solver
(VQLS), Variational Quantum Eigensolver (VQE) and other Quantum Machine
Learning Algorithms to show an example of speedup in the calculation time and
required memory size.
</p>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06187" title="Abstract">arXiv:2312.06187</a> (cross-list from eess.IV) [<a href="/pdf/2312.06187" title="Download PDF">pdf</a>, <a href="/format/2312.06187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SP-DiffDose: A Conditional Diffusion Model for Radiation Dose Prediction  Based on Multi-Scale Fusion of Anatomical Structures, Guided by  SwinTransformer and Projector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fu%2C+L">Linjie Fu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xia Li</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+X">Xiuding Cai</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yingkai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xueyao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+Y">Yu Yao</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+Y">Yali Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Radiation therapy serves as an effective and standard method for cancer
treatment. Excellent radiation therapy plans always rely on high-quality dose
distribution maps obtained through repeated trial and error by experienced
experts. However, due to individual differences and complex clinical
situations, even seasoned expert teams may need help to achieve the best
treatment plan every time quickly. Many automatic dose distribution prediction
methods have been proposed recently to accelerate the radiation therapy
planning process and have achieved good results. However, these results suffer
from over-smoothing issues, with the obtained dose distribution maps needing
more high-frequency details, limiting their clinical application. To address
these limitations, we propose a dose prediction diffusion model based on
SwinTransformer and a projector, SP-DiffDose. To capture the direct correlation
between anatomical structure and dose distribution maps, SP-DiffDose uses a
structural encoder to extract features from anatomical images, then employs a
conditional diffusion process to blend noise and anatomical images at multiple
scales and gradually map them to dose distribution maps. To enhance the dose
prediction distribution for organs at risk, SP-DiffDose utilizes
SwinTransformer in the deeper layers of the network to capture features at
different scales in the image. To learn good representations from the fused
features, SP-DiffDose passes the fused features through a designed projector,
improving dose prediction accuracy. Finally, we evaluate SP-DiffDose on an
internal dataset. The results show that SP-DiffDose outperforms existing
methods on multiple evaluation metrics, demonstrating the superiority and
generalizability of our method.
</p>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06190" title="Abstract">arXiv:2312.06190</a> (cross-list from math.ST) [<a href="/pdf/2312.06190" title="Download PDF">pdf</a>, <a href="/format/2312.06190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Phase Retrieval via Nonlinear Least Absolute Deviation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+S">Song Li</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Numerical Analysis (math.NA); Probability (math.PR)

</div>
<p class="mathjax">We investigate the phase retrieval problem perturbed by dense bounded noise
and sparse outliers that can change an adversarially chosen $s$-fraction of the
measurement vector. The adversarial sparse outliers may exhibit dependence on
both the observation and the measurement. We demonstrate that the nonlinear
least absolute deviation based on amplitude measurement can tolerate
adversarial outliers at a fraction of $s^{*,1}\approx0.2043$, while the
intensity-based model can tolerate a fraction of $s^{*,2}\approx0.1185$.
Furthermore, we construct adaptive counterexamples to show that the thresholds
are theoretically sharp, thereby showing the presentation of phase transition
in the adversarial phase retrieval problem when the corruption fraction exceeds
the sharp thresholds. This implies that the amplitude-based model exhibits
superior adversarial robustness in comparison with the intensity-based model.
Corresponding experimental results are presented to further illustrate our
theoretical findings. To the best of our knowledge, our results provide the
first theoretical examination of the distinction in robustness performance
between amplitude and intensity measurement. A crucial point of our analysis is
that we explore the exact distribution of some combination of two
non-independent Gaussian random variables and present the novel probability
density functions to derive the sharp thresholds.
</p>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06270" title="Abstract">arXiv:2312.06270</a> (cross-list from eess.AS) [<a href="/pdf/2312.06270" title="Download PDF">pdf</a>, <a href="/format/2312.06270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Speech Emotion Recognition Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Derington%2C+A">Anna Derington</a>, 
<a href="/search/eess?searchtype=author&query=Wierstorf%2C+H">Hagen Wierstorf</a>, 
<a href="/search/eess?searchtype=author&query=%C3%96zkil%2C+A">Ali &#xd6;zkil</a>, 
<a href="/search/eess?searchtype=author&query=Eyben%2C+F">Florian Eyben</a>, 
<a href="/search/eess?searchtype=author&query=Burkhardt%2C+F">Felix Burkhardt</a>, 
<a href="/search/eess?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Machine learning models for speech emotion recognition (SER) can be trained
for different tasks and are usually evaluated on the basis of a few available
datasets per task. Tasks could include arousal, valence, dominance, emotional
categories, or tone of voice. Those models are mainly evaluated in terms of
correlation or recall, and always show some errors in their predictions. The
errors manifest themselves in model behaviour, which can be very different
along different dimensions even if the same recall or correlation is achieved
by the model. This paper investigates behavior of speech emotion recognition
models with a testing framework which requires models to fulfill conditions in
terms of correctness, fairness, and robustness.
</p>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06378" title="Abstract">arXiv:2312.06378</a> (cross-list from math.OC) [<a href="/pdf/2312.06378" title="Download PDF">pdf</a>, <a href="/format/2312.06378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density-based isogeometric topology optimization of shell structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pan%2C+Q">Qiong Pan</a>, 
<a href="/search/math?searchtype=author&query=Zhai%2C+X">Xiaoya Zhai</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+F">Falai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 71 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Geometry (cs.CG); Graphics (cs.GR)

</div>
<p class="mathjax">Shell structures with a high stiffness-to-weight ratio are desirable in
various engineering applications. In such scenarios, topology optimization
serves as a popular and effective tool for shell structures design. Among the
topology optimization methods, solid isotropic material with penalization
method(SIMP) is often chosen due to its simplicity and convenience. However,
SIMP method is typically integrated with conventional finite element
analysis(FEA) which has limitations in computational accuracy. Achieving high
accuracy with FEA needs a substantial number of elements, leading to
computational burdens. In addition, the discrete representation of the material
distribution may result in rough boundaries and checkerboard structures. To
overcome these challenges, this paper proposes an isogeometric analysis(IGA)
based SIMP method for optimizing the topology of shell structures based on
Reissner-Mindlin theory. We use NURBS to represent both the shell structure and
the material distribution function with the same basis functions, allowing for
higher accuracy and smoother boundaries. The optimization model takes
compliance as the objective function with a volume fraction constraint and the
coefficients of the density function as design variables. The Method of Moving
Asymptotes is employed to solve the optimization problem, resulting in an
optimized shell structure defined by the material distribution function. To
obtain fairing boundaries in the optimized shell structure, further process is
conducted by fitting the boundaries with fair B-spline curves automatically.
Furthermore, the IGA-SIMP framework is applied to generate porous shell
structures by imposing different local volume fraction constraints. Numerical
examples are provided to demonstrate the feasibility and efficiency of the
IGA-SIMP method, showing that it outperforms the FEA-SIMP method and produces
smoother boundaries.
</p>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06403" title="Abstract">arXiv:2312.06403</a> (cross-list from stat.ML) [<a href="/pdf/2312.06403" title="Download PDF">pdf</a>, <a href="/format/2312.06403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiased Machine Learning and Network Cohesion for Doubly-Robust  Differential Reward Models in Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huch%2C+E+K">Easton K. Huch</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+J">Jieru Shi</a>, 
<a href="/search/stat?searchtype=author&query=Abbott%2C+M+R">Madeline R. Abbott</a>, 
<a href="/search/stat?searchtype=author&query=Golbus%2C+J+R">Jessica R. Golbus</a>, 
<a href="/search/stat?searchtype=author&query=Moreno%2C+A">Alexander Moreno</a>, 
<a href="/search/stat?searchtype=author&query=Dempsey%2C+W+H">Walter H. Dempsey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A common approach to learning mobile health (mHealth) intervention policies
is linear Thompson sampling. Two desirable mHealth policy features are (1)
pooling information across individuals and time and (2) incorporating a
time-varying baseline reward. Previous approaches pooled information across
individuals but not time, failing to capture trends in treatment effects over
time. In addition, these approaches did not explicitly model the baseline
reward, which limited the ability to precisely estimate the parameters in the
differential reward model. In this paper, we propose a novel Thompson sampling
algorithm, termed ''DML-TS-NNR'' that leverages (1) nearest-neighbors to
efficiently pool information on the differential reward function across users
and time and (2) the Double Machine Learning (DML) framework to explicitly
model baseline rewards and stay agnostic to the supervised learning algorithms
used. By explicitly modeling baseline rewards, we obtain smaller confidence
sets for the differential reward parameters. We offer theoretical guarantees on
the pseudo-regret, which are supported by empirical results. Importantly, the
DML-TS-NNR algorithm demonstrates robustness to potential misspecifications in
the baseline reward model.
</p>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06454" title="Abstract">arXiv:2312.06454</a> (cross-list from eess.IV) [<a href="/pdf/2312.06454" title="Download PDF">pdf</a>, <a href="/format/2312.06454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Transformer with Federated Learning for Predicting Breast Cancer  HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bao Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Shao%2C+L">Lizhi Shao</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+B">Bensheng Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Bu%2C+H">Hong Bu</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+J">Jie Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Directly predicting human epidermal growth factor receptor 2 (HER2) status
from widely available hematoxylin and eosin (HE)-stained whole slide images
(WSIs) can reduce technical costs and expedite treatment selection. Accurately
predicting HER2 requires large collections of multi-site WSIs. Federated
learning enables collaborative training of these WSIs without gigabyte-size
WSIs transportation and data privacy concerns. However, federated learning
encounters challenges in addressing label imbalance in multi-site WSIs from the
real world. Moreover, existing WSI classification methods cannot simultaneously
exploit local context information and long-range dependencies in the site-end
feature representation of federated learning. To address these issues, we
present a point transformer with federated learning for multi-site HER2 status
prediction from HE-stained WSIs. Our approach incorporates two novel designs.
We propose a dynamic label distribution strategy and an auxiliary classifier,
which helps to establish a well-initialized model and mitigate label
distribution variations across sites. Additionally, we propose a farthest
cosine sampling based on cosine distance. It can sample the most distinctive
features and capture the long-range dependencies. Extensive experiments and
analysis show that our method achieves state-of-the-art performance at four
sites with a total of 2687 WSIs. Furthermore, we demonstrate that our model can
generalize to two unseen sites with 229 WSIs.
</p>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06461" title="Abstract">arXiv:2312.06461</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2312.06461" title="Download PDF">pdf</a>, <a href="/format/2312.06461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Auto-Encoder Based Deep Learning Technique For Filling Gaps  in Reacting PIV Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yellapantula%2C+S">Shashank Yellapantula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Proceedings of the Combustion Institute
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, a deep learning based conditional density estimation technique
known as conditional variational auto-encoder (CVAE) is used to fill gaps
typically observed in particle image velocimetry (PIV) measurements in
combustion systems. The proposed CVAE technique is trained using time resolved
gappy PIV fields, typically observed in industrially relevant combustors.
Stereo-PIV (SPIV) data from a swirl combustor with very a high vector yield is
used to showcase the accuracy of the proposed CVAE technique. Various error
metrics evaluated on the reconstructed velocity field in the gaps are presented
from data sets corresponding to three sets of combustor operating conditions.
In addition to accurate data reproduction, the proposed CVAE technique offers
data compression by reducing the latent space dimension, enabling the efficient
processing of large-scale PIV data.
</p>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06508" title="Abstract">arXiv:2312.06508</a> (cross-list from math.OC) [<a href="/pdf/2312.06508" title="Download PDF">pdf</a>, <a href="/ps/2312.06508" title="Download PostScript">ps</a>, <a href="/format/2312.06508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Distributed Optimization with Delay-free Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+X">Xuyang Wu</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+C">Changxin Liu</a>, 
<a href="/search/math?searchtype=author&query=Magnusson%2C+S">Sindri Magnusson</a>, 
<a href="/search/math?searchtype=author&query=Johansson%2C+M">Mikael Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. arXiv admin note: text overlap with <a href="/abs/2303.18034">arXiv:2303.18034</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Existing asynchronous distributed optimization algorithms often use
diminishing step-sizes that cause slow practical convergence, or use fixed
step-sizes that depend on and decrease with an upper bound of the delays. Not
only are such delay bounds hard to obtain in advance, but they also tend to be
large and rarely attained, resulting in unnecessarily slow convergence. This
paper develops asynchronous versions of two distributed algorithms, Prox-DGD
and DGD-ATC, for solving consensus optimization problems over undirected
networks. In contrast to alternatives, our algorithms can converge to the fixed
point set of their synchronous counterparts using step-sizes that are
independent of the delays. We establish convergence guarantees for strongly and
weakly convex problems under both partial and total asynchrony. We also show
that the convergence speed of the two asynchronous methods adapts to the actual
level of asynchrony rather than being constrained by the worst-case. Numerical
experiments demonstrate a strong practical performance of our asynchronous
algorithms.
</p>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06531" title="Abstract">arXiv:2312.06531</a> (cross-list from stat.ML) [<a href="/pdf/2312.06531" title="Download PDF">pdf</a>, <a href="/format/2312.06531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification in automated valuation models with locally  weighted conformal prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hjort%2C+A">Anders Hjort</a>, 
<a href="/search/stat?searchtype=author&query=Hermansen%2C+G+H">Gudmund Horn Hermansen</a>, 
<a href="/search/stat?searchtype=author&query=Pensar%2C+J">Johan Pensar</a>, 
<a href="/search/stat?searchtype=author&query=Williams%2C+J+P">Jonathan P. Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Non-parametric machine learning models, such as random forests and gradient
boosted trees, are frequently used to estimate house prices due to their
predictive accuracy, but such methods are often limited in their ability to
quantify prediction uncertainty. Conformal Prediction (CP) is a model-agnostic
framework for constructing confidence sets around machine learning prediction
models with minimal assumptions. However, due to the spatial dependencies
observed in house prices, direct application of CP leads to confidence sets
that are not calibrated everywhere, i.e., too large of confidence sets in
certain geographical regions and too small in others. We survey various
approaches to adjust the CP confidence set to account for this and demonstrate
their performance on a data set from the housing market in Oslo, Norway. Our
findings indicate that calibrating the confidence sets on a \textit{locally
weighted} version of the non-conformity scores makes the coverage more
consistently calibrated in different geographical regions. We also perform a
simulation study on synthetically generated sale prices to empirically explore
the performance of CP on housing market data under idealized conditions with
known data-generating mechanisms.
</p>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06547" title="Abstract">arXiv:2312.06547</a> (cross-list from stat.ME) [<a href="/pdf/2312.06547" title="Download PDF">pdf</a>, <a href="/format/2312.06547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KF-PLS: Optimizing Kernel Partial Least-Squares (K-PLS) with Kernel  Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Duma%2C+Z">Zina-Sabrina Duma</a>, 
<a href="/search/stat?searchtype=author&query=Susiluoto%2C+J">Jouni Susiluoto</a>, 
<a href="/search/stat?searchtype=author&query=Lamminp%C3%A4%C3%A4%2C+O">Otto Lamminp&#xe4;&#xe4;</a>, 
<a href="/search/stat?searchtype=author&query=Sihvonen%2C+T">Tuomas Sihvonen</a>, 
<a href="/search/stat?searchtype=author&query=Reinikainen%2C+S">Satu-Pia Reinikainen</a>, 
<a href="/search/stat?searchtype=author&query=Haario%2C+H">Heikki Haario</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Partial Least-Squares (PLS) Regression is a widely used tool in chemometrics
for performing multivariate regression. PLS is a bi-linear method that has a
limited capacity of modelling non-linear relations between the predictor
variables and the response. Kernel PLS (K-PLS) has been introduced for
modelling non-linear predictor-response relations. In K-PLS, the input data is
mapped via a kernel function to a Reproducing Kernel Hilbert space (RKH), where
the dependencies between the response and the input matrix are assumed to be
linear. K-PLS is performed in the RKH space between the kernel matrix and the
dependent variable. Most available studies use fixed kernel parameters. Only a
few studies have been conducted on optimizing the kernel parameters for K-PLS.
In this article, we propose a methodology for the kernel function optimization
based on Kernel Flows (KF), a technique developed for Gaussian process
regression (GPR). The results are illustrated with four case studies. The case
studies represent both numerical examples and real data used in classification
and regression tasks. K-PLS optimized with KF, called KF-PLS in this study, is
shown to yield good results in all illustrated scenarios. The paper presents
cross-validation studies and hyperparameter analysis of the KF methodology when
applied to K-PLS.
</p>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06555" title="Abstract">arXiv:2312.06555</a> (cross-list from eess.SP) [<a href="/pdf/2312.06555" title="Download PDF">pdf</a>, <a href="/format/2312.06555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of CDL and TDL Augmentation for RF Fingerprinting under  Impaired Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gul%2C+O+M">Omer Melih Gul</a>, 
<a href="/search/eess?searchtype=author&query=Kulhandjian%2C+M">Michel Kulhandjian</a>, 
<a href="/search/eess?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>, 
<a href="/search/eess?searchtype=author&query=D%27Amours%2C+C">Claude D&#x27;Amours</a>, 
<a href="/search/eess?searchtype=author&query=Touazi%2C+A">Azzedine Touazi</a>, 
<a href="/search/eess?searchtype=author&query=Ellement%2C+C">Cliff Ellement</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 Figures, "Wireless World Research and Trends" Magazine. Initial version was presented in 48th Wireless World Research Forum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Cryptography and Security (cs.CR); Systems and Control (eess.SY)

</div>
<p class="mathjax">Cyber-physical systems have recently been used in several areas (such as
connected and autonomous vehicles) due to their high maneuverability. On the
other hand, they are susceptible to cyber-attacks. Radio frequency (RF)
fingerprinting emerges as a promising approach. This work aims to analyze the
impact of decoupling tapped delay line and clustered delay line (TDL+CDL)
augmentation-driven deep learning (DL) on transmitter-specific fingerprints to
discriminate malicious users from legitimate ones. This work also considers
5G-only-CDL, WiFi-only-TDL augmentation approaches. RF fingerprinting models
are sensitive to changing channels and environmental conditions. For this
reason, they should be considered during the deployment of a DL model. Data
acquisition can be another option. Nonetheless, gathering samples under various
conditions for a train set formation may be quite hard. Consequently, data
acquisition may not be feasible. This work uses a dataset that includes 5G, 4G,
and WiFi samples, and it empowers a CDL+TDL-based augmentation technique in
order to boost the learning performance of the DL model. Numerical results show
that CDL+TDL, 5G-only-CDL, and WiFi-only-TDL augmentation approaches achieve
87.59%, 81.63%, 79.21% accuracy on unobserved data while TDL/CDL augmentation
technique and no augmentation approach result in 77.81% and 74.84% accuracy on
unobserved data, respectively.
</p>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06579" title="Abstract">arXiv:2312.06579</a> (cross-list from math.OC) [<a href="/pdf/2312.06579" title="Download PDF">pdf</a>, <a href="/format/2312.06579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amazon Locker Capacity Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sethuraman%2C+S">Samyukta Sethuraman</a>, 
<a href="/search/math?searchtype=author&query=Bansal%2C+A">Ankur Bansal</a>, 
<a href="/search/math?searchtype=author&query=Mardan%2C+S">Setareh Mardan</a>, 
<a href="/search/math?searchtype=author&query=Resende%2C+M+G+C">Mauricio G.C. Resende</a>, 
<a href="/search/math?searchtype=author&query=Jacobs%2C+T+L">Timothy L. Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Amazon Locker is a self-service delivery or pickup location where customers
can pick up packages and drop off returns. A basic first-come-first-served
policy for accepting package delivery requests to lockers results in lockers
becoming full with standard shipping speed (3-5 day shipping) packages, and
leaving no space left for expedited packages which are mostly Next-Day or
Two-Day shipping. This paper proposes a solution to the problem of determining
how much locker capacity to reserve for different ship-option packages. Yield
management is a much researched field with popular applications in the airline,
car rental, and hotel industries. However, Amazon Locker poses a unique
challenge in this field since the number of days a package will wait in a
locker (package dwell time) is, in general, unknown. The proposed solution
combines machine learning techniques to predict locker demand and package dwell
time, and linear programming to maximize throughput in lockers. The decision
variables from this optimization provide optimal capacity reservation values
for different ship options. This resulted in a year-over-year increase of 9% in
Locker throughput worldwide during holiday season of 2018, impacting millions
of customers.
</p>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06587" title="Abstract">arXiv:2312.06587</a> (cross-list from eess.IV) [<a href="/pdf/2312.06587" title="Download PDF">pdf</a>, <a href="/format/2312.06587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuickQuakeBuildings: Post-earthquake SAR-Optical Dataset for Quick  Damaged-building Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Eineder%2C+M">Michael Eineder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Quick and automated earthquake-damaged building detection from post-event
satellite imagery is crucial, yet it is challenging due to the scarcity of
training data required to develop robust algorithms. This letter presents the
first dataset dedicated to detecting earthquake-damaged buildings from
post-event very high resolution (VHR) Synthetic Aperture Radar (SAR) and
optical imagery. Utilizing open satellite imagery and annotations acquired
after the 2023 Turkey-Syria earthquakes, we deliver a dataset of coregistered
building footprints and satellite image patches of both SAR and optical data,
encompassing more than four thousand buildings. The task of damaged building
detection is formulated as a binary image classification problem, that can also
be treated as an anomaly detection problem due to extreme class imbalance. We
provide baseline methods and results to serve as references for comparison.
Researchers can utilize this dataset to expedite algorithm development,
facilitating the rapid detection of damaged buildings in response to future
events. The dataset and codes together with detailed explanations are made
publicly available at
\url{https://github.com/ya0-sun/PostEQ-SARopt-BuildingDamage}.
</p>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06591" title="Abstract">arXiv:2312.06591</a> (cross-list from stat.ML) [<a href="/pdf/2312.06591" title="Download PDF">pdf</a>, <a href="/format/2312.06591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concurrent Density Estimation with Wasserstein Autoencoders: Some  Statistical Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chakrabarty%2C+A">Anish Chakrabarty</a>, 
<a href="/search/stat?searchtype=author&query=Basu%2C+A">Arkaprabha Basu</a>, 
<a href="/search/stat?searchtype=author&query=Das%2C+S">Swagatam Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Variational Autoencoders (VAEs) have been a pioneering force in the realm of
deep generative models. Amongst its legions of progenies, Wasserstein
Autoencoders (WAEs) stand out in particular due to the dual offering of
heightened generative quality and a strong theoretical backbone. WAEs consist
of an encoding and a decoding network forming a bottleneck with the prime
objective of generating new samples resembling the ones it was catered to. In
the process, they aim to achieve a target latent representation of the encoded
data. Our work is an attempt to offer a theoretical understanding of the
machinery behind WAEs. From a statistical viewpoint, we pose the problem as
concurrent density estimation tasks based on neural network-induced
transformations. This allows us to establish deterministic upper bounds on the
realized errors WAEs commit. We also analyze the propagation of these
stochastic errors in the presence of adversaries. As a result, both the large
sample properties of the reconstructed distribution and the resilience of WAE
models are explored.
</p>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06608" title="Abstract">arXiv:2312.06608</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2312.06608" title="Download PDF">pdf</a>, <a href="/format/2312.06608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information theory for model reduction in stochastic dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Schmitt%2C+M+S">Matthew S. Schmitt</a>, 
<a href="/search/cond-mat?searchtype=author&query=Koch-Janusz%2C+M">Maciej Koch-Janusz</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fruchart%2C+M">Michel Fruchart</a>, 
<a href="/search/cond-mat?searchtype=author&query=Seara%2C+D+S">Daniel S. Seara</a>, 
<a href="/search/cond-mat?searchtype=author&query=Vitelli%2C+V">Vincenzo Vitelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Model reduction is the construction of simple yet predictive descriptions of
the dynamics of many-body systems in terms of a few relevant variables. A
prerequisite to model reduction is the identification of these relevant
variables, a task for which no general method exists. Here, we develop a
systematic approach based on the information bottleneck to identify the
relevant variables, defined as those most predictive of the future. We
elucidate analytically the relation between these relevant variables and the
eigenfunctions of the transfer operator describing the dynamics. Further, we
show that in the limit of high compression, the relevant variables are directly
determined by the slowest-decaying eigenfunctions. Our information-based
approach indicates when to optimally stop increasing the complexity of the
reduced model. Further, it provides a firm foundation to construct
interpretable deep learning tools that perform model reduction. We illustrate
how these tools work on benchmark dynamical systems and deploy them on
uncurated datasets, such as satellite movies of atmospheric flows downloaded
directly from YouTube.
</p>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06619" title="Abstract">arXiv:2312.06619</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.06619" title="Download PDF">pdf</a>, <a href="/format/2312.06619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Scale-Free Networks in Social Interactions among Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=De+Marzo%2C+G">Giordano De Marzo</a>, 
<a href="/search/physics?searchtype=author&query=Pietronero%2C+L">Luciano Pietronero</a>, 
<a href="/search/physics?searchtype=author&query=Garcia%2C+D">David Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Scale-free networks are one of the most famous examples of emergent behavior
and are ubiquitous in social systems, especially online social media in which
users can follow each other. By analyzing the interactions of multiple
generative agents using GPT3.5-turbo as a language model, we demonstrate their
ability to not only mimic individual human linguistic behavior but also exhibit
collective phenomena intrinsic to human societies, in particular the emergence
of scale-free networks. We discovered that this process is disrupted by a
skewed token prior distribution of GPT3.5-turbo, which can lead to networks
with extreme centralization as a kind of alignment. We show how renaming agents
removes these token priors and allows the model to generate a range of networks
from random networks to more realistic scale-free networks.
</p>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06623" title="Abstract">arXiv:2312.06623</a> (cross-list from math.OC) [<a href="/pdf/2312.06623" title="Download PDF">pdf</a>, <a href="/ps/2312.06623" title="Download PostScript">ps</a>, <a href="/format/2312.06623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model selection for risk analysis of wastewater networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dunton%2C+A">Aaron Dunton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we test various models of wastewater infrastructure for risk
analysis and compare their performance. While many representations are
available, existing studies do not consider selection of the appropriate model
for risk analysis. In this paper, we define two characteristics of wastewater
models: the network granularity and the fidelity of the governing equations. We
consider different combinations of these characteristics to determine 6 network
representations that could be used as the foundation for risk analysis. We test
the performance of each model as compared to predictions from the most detailed
model, the full network with dynamic wave flow equations. We demonstrate the
model selection for Seaside, Oregon. We conclude that the full network
granularity is needed as compared to a coarse network representation. For the
fidelity of the governing equations, connectivity analysis is reasonable if the
primary goal is to determine the spatial distribution of hazard impact. To more
accurately predict nodal performance measures, the dynamic wave equations are
needed as they capture important physical phenomena.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 12 Dec 23</h3>
<dl>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1110.2324" title="Abstract">arXiv:1110.2324</a> (replaced) [<a href="/pdf/1110.2324" title="Download PDF">pdf</a>, <a href="/ps/1110.2324" title="Download PostScript">ps</a>, <a href="/format/1110.2324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative Error Control in Bivariate Interpolatory Cubature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prentice%2C+J+S+C">Justin Steven Calder Prentice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For the 1-D version of this algorithm, available open access at J. Math. Res., consult reference [10]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1605.06409" title="Abstract">arXiv:1605.06409</a> (replaced) [<a href="/pdf/1605.06409" title="Download PDF">pdf</a>, <a href="/format/1605.06409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R-FCN: Object Detection via Region-based Fully Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kaiming He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.09413" title="Abstract">arXiv:1902.09413</a> (replaced) [<a href="/pdf/1902.09413" title="Download PDF">pdf</a>, <a href="/format/1902.09413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Approximate Incentive Compatibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balcan%2C+M">Maria-Florina Balcan</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>, 
<a href="/search/cs?searchtype=author&query=Vitercik%2C+E">Ellen Vitercik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.13463" title="Abstract">arXiv:1907.13463</a> (replaced) [<a href="/pdf/1907.13463" title="Download PDF">pdf</a>, <a href="/format/1907.13463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonconvex Zeroth-Order Stochastic ADMM Methods with Lower Function Query  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+F">Feihu Huang</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+S">Shangqian Gao</a>, 
<a href="/search/math?searchtype=author&query=Pei%2C+J">Jian Pei</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+H">Heng Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.00326" title="Abstract">arXiv:2009.00326</a> (replaced) [<a href="/pdf/2009.00326" title="Download PDF">pdf</a>, <a href="/format/2009.00326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyCSP3: Modeling Combinatorial Constrained Problems in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lecoutre%2C+C">Christophe Lecoutre</a>, 
<a href="/search/cs?searchtype=author&query=Szczepanski%2C+N">Nicolas Szczepanski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.00137" title="Abstract">arXiv:2010.00137</a> (replaced) [<a href="/pdf/2010.00137" title="Download PDF">pdf</a>, <a href="/ps/2010.00137" title="Download PostScript">ps</a>, <a href="/format/2010.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient sampling from the Bingham distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+R">Rong Ge</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Holden Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Risteski%2C+A">Andrej Risteski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected factor: $(1-x^2)^{(d-3)/2}$
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Algorithmic Learning Theory. PMLR, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.03170" title="Abstract">arXiv:2012.03170</a> (replaced) [<a href="/e-print/2012.03170" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Food Classification with Convolutional Neural Networks and Multi-Class  Linear Discernment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ball%2C+J">Joshua Ball</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I dont like the paper, its not a good rep of me anymore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.05706" title="Abstract">arXiv:2103.05706</a> (replaced) [<a href="/pdf/2103.05706" title="Download PDF">pdf</a>, <a href="/format/2103.05706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A sampling criterion for constrained Bayesian optimization with  uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Amri%2C+R+E">Reda El Amri</a>, 
<a href="/search/stat?searchtype=author&query=Riche%2C+R+L">Rodolphe Le Riche</a>, 
<a href="/search/stat?searchtype=author&query=Helbert%2C+C">C&#xe9;line Helbert</a>, 
<a href="/search/stat?searchtype=author&query=Blanchet-Scalliet%2C+C">Christophette Blanchet-Scalliet</a>, 
<a href="/search/stat?searchtype=author&query=Da+Veiga%2C+S">S&#xe9;bastien Da Veiga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in SMAI Journal of Computational Mathematics, Vol.9, pp. 285-309
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.09373" title="Abstract">arXiv:2103.09373</a> (replaced) [<a href="/pdf/2103.09373" title="Download PDF">pdf</a>, <a href="/ps/2103.09373" title="Download PostScript">ps</a>, <a href="/format/2103.09373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variable-Length Sparse Feedback Codes for Point-to-Point, Multiple  Access, and Random Access Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yavas%2C+R+C">Recep Can Yavas</a>, 
<a href="/search/cs?searchtype=author&query=Kostina%2C+V">Victoria Kostina</a>, 
<a href="/search/cs?searchtype=author&query=Effros%2C+M">Michelle Effros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 Pages. Presented at ISIT 2021. Accepted for publication at IEEE Transactions on Information Theory Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.06809" title="Abstract">arXiv:2104.06809</a> (replaced) [<a href="/pdf/2104.06809" title="Download PDF">pdf</a>, <a href="/ps/2104.06809" title="Download PostScript">ps</a>, <a href="/format/2104.06809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smaller Keys for the McEliece Cryptosystem: A Convolutional Variant with  GRS Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+P">Paulo Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Beltr%C3%A1%2C+M">Miguel Beltr&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Napp%2C+D">Diego Napp</a>, 
<a href="/search/cs?searchtype=author&query=Sebasti%C3%A3o%2C+C">Cl&#xe1;udia Sebasti&#xe3;o</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. arXiv admin note: text overlap with <a href="/abs/1804.08955">arXiv:1804.08955</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.04088" title="Abstract">arXiv:2106.04088</a> (replaced) [<a href="/pdf/2106.04088" title="Download PDF">pdf</a>, <a href="/format/2106.04088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight and Gradient-Stable Neural Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yueyao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13720" title="Abstract">arXiv:2108.13720</a> (replaced) [<a href="/pdf/2108.13720" title="Download PDF">pdf</a>, <a href="/format/2108.13720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Optimization for Distance-Geometric Inverse Kinematics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mari%C4%87%2C+F">Filip Mari&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Giamou%2C+M">Matthew Giamou</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+A+W">Adam W. Hall</a>, 
<a href="/search/cs?searchtype=author&query=Khoubyarian%2C+S">Soroush Khoubyarian</a>, 
<a href="/search/cs?searchtype=author&query=Petrovi%C4%87%2C+I">Ivan Petrovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics (T-RO), Vol. 38, No. 3, pp.
  1703-1722, Jun. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08642" title="Abstract">arXiv:2109.08642</a> (replaced) [<a href="/pdf/2109.08642" title="Download PDF">pdf</a>, <a href="/format/2109.08642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> POAR: Efficient Policy Optimization via Online Abstract State  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaorun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Liang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Binhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Te Sun</a>, 
<a href="/search/cs?searchtype=author&query=Filliat%2C+D">David Filliat</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Rodr%C3%ADguez%2C+N">Natalia D&#xed;az-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08644" title="Abstract">arXiv:2109.08644</a> (replaced) [<a href="/pdf/2109.08644" title="Download PDF">pdf</a>, <a href="/format/2109.08644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Allocating Indivisible Goods to Strategic Agents: Pure Nash Equilibria  and Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amanatidis%2C+G">Georgios Amanatidis</a>, 
<a href="/search/cs?searchtype=author&query=Birmpas%2C+G">Georgios Birmpas</a>, 
<a href="/search/cs?searchtype=author&query=Fusco%2C+F">Federico Fusco</a>, 
<a href="/search/cs?searchtype=author&query=Lazos%2C+P">Philip Lazos</a>, 
<a href="/search/cs?searchtype=author&query=Leonardi%2C+S">Stefano Leonardi</a>, 
<a href="/search/cs?searchtype=author&query=Reiffenh%C3%A4user%2C+R">Rebecca Reiffenh&#xe4;user</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The conference version of this work was presented at the 17th Conference on Web and Internet Economics (WINE 2021). The journal version has been accepted to Mathematics of Operations Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04698" title="Abstract">arXiv:2110.04698</a> (replaced) [<a href="/pdf/2110.04698" title="Download PDF">pdf</a>, <a href="/format/2110.04698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at Advantage-Filtered Behavioral Cloning in High-Noise  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+J">Jake Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanjun Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11486" title="Abstract">arXiv:2110.11486</a> (replaced) [<a href="/pdf/2110.11486" title="Download PDF">pdf</a>, <a href="/format/2110.11486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Federated Learning in Resource-Constrained Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boukhari%2C+M+Y">Mohamed Yassine Boukhari</a>, 
<a href="/search/cs?searchtype=author&query=Dhasade%2C+A">Akash Dhasade</a>, 
<a href="/search/cs?searchtype=author&query=Kermarrec%2C+A">Anne-Marie Kermarrec</a>, 
<a href="/search/cs?searchtype=author&query=Pires%2C+R">Rafael Pires</a>, 
<a href="/search/cs?searchtype=author&query=Safsafi%2C+O">Othmane Safsafi</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rishi Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08564" title="Abstract">arXiv:2111.08564</a> (replaced) [<a href="/pdf/2111.08564" title="Download PDF">pdf</a>, <a href="/ps/2111.08564" title="Download PostScript">ps</a>, <a href="/format/2111.08564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Doxastic &#x141;ukasiewicz Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dastgheib%2C+D">Doratossadat Dastgheib</a>, 
<a href="/search/cs?searchtype=author&query=Farahani%2C+H">Hadi Farahani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.05997" title="Abstract">arXiv:2112.05997</a> (replaced) [<a href="/e-print/2112.05997" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Sequential Squaring Verifiable Delay Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sur%2C+S">Souvik Sur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The proofs are insufficient
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.03810" title="Abstract">arXiv:2201.03810</a> (replaced) [<a href="/pdf/2201.03810" title="Download PDF">pdf</a>, <a href="/format/2201.03810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ancestral Instrument Method for Causal Inference without Complete  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Debo Cheng</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiuyong Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiji Zhang</a> (2), 
<a href="/search/cs?searchtype=author&query=Le%2C+T+d">Thuc duy Le</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jixue Liu</a> (1) ((1) STEM, University of South Australia, Adelaide, SA, Australia, (2) Department of Religion and Philosophy, Hong Kong Baptist University, Hong Kong, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07063" title="Abstract">arXiv:2201.07063</a> (replaced) [<a href="/pdf/2201.07063" title="Download PDF">pdf</a>, <a href="/format/2201.07063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Backdoor HyperNetwork in Personalized Federated Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+P">Phung Lai</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+N">NhatHai Phan</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+I">Issa Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Khreishah%2C+A">Abdallah Khreishah</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01217" title="Abstract">arXiv:2203.01217</a> (replaced) [<a href="/pdf/2203.01217" title="Download PDF">pdf</a>, <a href="/format/2203.01217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Tracker with Pixel and Instance for Video Panoptic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Weicai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xinyue Lan</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+G">Ge Su</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Hujun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhaopeng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.05097" title="Abstract">arXiv:2203.05097</a> (replaced) [<a href="/pdf/2203.05097" title="Download PDF">pdf</a>, <a href="/ps/2203.05097" title="Download PostScript">ps</a>, <a href="/format/2203.05097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for the Interoperability of Cloud Platforms: Towards FAIR  Data in SAFE Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grossman%2C+R+L">Robert L. Grossman</a>, 
<a href="/search/cs?searchtype=author&query=Boyles%2C+R+R">Rebecca R. Boyles</a>, 
<a href="/search/cs?searchtype=author&query=Davis-Dusenbery%2C+B+N">Brandi N. Davis-Dusenbery</a>, 
<a href="/search/cs?searchtype=author&query=Haddock%2C+A">Amanda Haddock</a>, 
<a href="/search/cs?searchtype=author&query=Heath%2C+A+P">Allison P. Heath</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+B+D">Brian D. O&#x27;Connor</a>, 
<a href="/search/cs?searchtype=author&query=Resnick%2C+A+C">Adam C. Resnick</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+D+M">Deanne M. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Ahalt%2C+S">Stan Ahalt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages with 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07490" title="Abstract">arXiv:2203.07490</a> (replaced) [<a href="/pdf/2203.07490" title="Download PDF">pdf</a>, <a href="/format/2203.07490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repairing Regressors for Fair Binary Classification at Any Decision  Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwegyir-Aggrey%2C+K">Kweku Kwegyir-Aggrey</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jessica Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dickerson%2C+J">John Dickerson</a>, 
<a href="/search/cs?searchtype=author&query=Hines%2C+K">Keegan Hines</a>, 
<a href="/search/cs?searchtype=author&query=Venkatasubramanian%2C+S">Suresh Venkatasubramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11795" title="Abstract">arXiv:2203.11795</a> (replaced) [<a href="/pdf/2203.11795" title="Download PDF">pdf</a>, <a href="/ps/2203.11795" title="Download PostScript">ps</a>, <a href="/format/2203.11795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing communication in the multidimensional FFT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koopman%2C+T">Thomas Koopman</a>, 
<a href="/search/cs?searchtype=author&query=Bisseling%2C+R+H">Rob H. Bisseling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figures. The new version has mainly added results in section 4.2 for the package heFFT, following referee comments. Furthermore, small linguistic changes have been made to render the arXiv version identical in text to the final published journal version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM Journal on Scientific Computing, Volume 45, Number 6, pp.
  C330-C347 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13086" title="Abstract">arXiv:2203.13086</a> (replaced) [<a href="/pdf/2203.13086" title="Download PDF">pdf</a>, <a href="/format/2203.13086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiFi++: a Unified Framework for Bandwidth Extension and Speech  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andreev%2C+P">Pavel Andreev</a>, 
<a href="/search/cs?searchtype=author&query=Alanov%2C+A">Aibek Alanov</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+O">Oleg Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.03343" title="Abstract">arXiv:2204.03343</a> (replaced) [<a href="/pdf/2204.03343" title="Download PDF">pdf</a>, <a href="/format/2204.03343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary Spatial Random Field Reconstruction from Non-Gaussian  Inhomogeneous Time-series Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sheng%2C+S">Shunan Sheng</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Q">Qikun Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Nevat%2C+I">Ido Nevat</a>, 
<a href="/search/eess?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08563" title="Abstract">arXiv:2204.08563</a> (replaced) [<a href="/pdf/2204.08563" title="Download PDF">pdf</a>, <a href="/format/2204.08563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cylin-Painting: Seamless {360\textdegree} Panoramic Image Outpainting  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+K">Kang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wenqi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06006" title="Abstract">arXiv:2205.06006</a> (replaced) [<a href="/pdf/2205.06006" title="Download PDF">pdf</a>, <a href="/format/2205.06006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Predictability of Stochastic Dynamical Systems: Metric,  Optimality and Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tao Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianping He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yushan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01818" title="Abstract">arXiv:2206.01818</a> (replaced) [<a href="/pdf/2206.01818" title="Download PDF">pdf</a>, <a href="/format/2206.01818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAGCN: Answering Multi-Relation Questions via Single-Step Implicit  Reasoning over Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rossetto%2C+L">Luca Rossetto</a>, 
<a href="/search/cs?searchtype=author&query=Cochez%2C+M">Michael Cochez</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+A">Abraham Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09098" title="Abstract">arXiv:2206.09098</a> (replaced) [<a href="/pdf/2206.09098" title="Download PDF">pdf</a>, <a href="/ps/2206.09098" title="Download PostScript">ps</a>, <a href="/format/2206.09098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frank%2C+N+S">Natalie S. Frank</a>, 
<a href="/search/cs?searchtype=author&query=Niles-Weed%2C+J">Jonathan Niles-Weed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages. version 2: corrects several errors and employs a significantly different proof technique. version 3: modifies the arXiv author list but has no other changes. version 4: improved exposition and fixed typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10177" title="Abstract">arXiv:2206.10177</a> (replaced) [<a href="/pdf/2206.10177" title="Download PDF">pdf</a>, <a href="/format/2206.10177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui-Jie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qihang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianjing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haoyu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yule Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Malu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Liang-Jian Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13489" title="Abstract">arXiv:2206.13489</a> (replaced) [<a href="/pdf/2206.13489" title="Download PDF">pdf</a>, <a href="/format/2206.13489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supply-Side Equilibria in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jagadeesan%2C+M">Meena Jagadeesan</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+N">Nikhil Garg</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared at NeurIPS 2023; this is the full version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00259" title="Abstract">arXiv:2207.00259</a> (replaced) [<a href="/pdf/2207.00259" title="Download PDF">pdf</a>, <a href="/ps/2207.00259" title="Download PostScript">ps</a>, <a href="/format/2207.00259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 Detection Using Transfer Learning Approach from Computed  Tomography Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morani%2C+K">Kenan Morani</a>, 
<a href="/search/eess?searchtype=author&query=Ayana%2C+E+K">Esra Kaya Ayana</a>, 
<a href="/search/eess?searchtype=author&query=Unay%2C+D">Devrim Unay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03584" title="Abstract">arXiv:2207.03584</a> (replaced) [<a href="/pdf/2207.03584" title="Download PDF">pdf</a>, <a href="/format/2207.03584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization Guarantee of Training Graph Convolutional Networks with  Graph Topology Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongkang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jinjun Xiong</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICML 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05751" title="Abstract">arXiv:2207.05751</a> (replaced) [<a href="/pdf/2207.05751" title="Download PDF">pdf</a>, <a href="/format/2207.05751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Synergistic Compilation Workflow for Tackling Crosstalk in Quantum  Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hua%2C+F">Fei Hua</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jin%2C+Y">Yuwei Jin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+C">Chenxu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yanhao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hayes%2C+A">Ari Hayes</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+S">Samuel Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Guo%2C+M">Minghao Guo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+Y">Yipeng Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+E+Z">Eddy Z. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06465" title="Abstract">arXiv:2207.06465</a> (replaced) [<a href="/pdf/2207.06465" title="Download PDF">pdf</a>, <a href="/format/2207.06465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaging through the Atmosphere using Turbulence Mitigation Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xingguang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+Z">Zhiyuan Mao</a>, 
<a href="/search/eess?searchtype=author&query=Chimitt%2C+N">Nicholas Chimitt</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+S+H">Stanley H. Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Computational Imaging; project page: <a href="https://xg416.github.io/TMT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11005" title="Abstract">arXiv:2207.11005</a> (replaced) [<a href="/pdf/2207.11005" title="Download PDF">pdf</a>, <a href="/format/2207.11005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaptCL: Adaptive Continual Learning for Tackling Heterogeneity in  Sequential Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+D">Divya Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiannong Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted by TNNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09705" title="Abstract">arXiv:2208.09705</a> (replaced) [<a href="/pdf/2208.09705" title="Download PDF">pdf</a>, <a href="/format/2208.09705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gBuilder: A Scalable Knowledge Graph Construction System for  Unstructured Corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanzeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L">Lei Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10443" title="Abstract">arXiv:2208.10443</a> (replaced) [<a href="/pdf/2208.10443" title="Download PDF">pdf</a>, <a href="/format/2208.10443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid evaluation of Newtonian potentials on planar domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shen%2C+Z">Zewen Shen</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 tables, 11 figures. Accepted by SIAM J. Sci. Comput
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10715" title="Abstract">arXiv:2208.10715</a> (replaced) [<a href="/pdf/2208.10715" title="Download PDF">pdf</a>, <a href="/format/2208.10715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GANs and Closures: Micro-Macro Consistency in Multiscale Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crabtree%2C+E+R">Ellis R. Crabtree</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Rivas%2C+J+M">Juan M. Bello-Rivas</a>, 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+A+L">Andrew L. Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 14 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11435" title="Abstract">arXiv:2208.11435</a> (replaced) [<a href="/pdf/2208.11435" title="Download PDF">pdf</a>, <a href="/format/2208.11435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional Contrastive Split Learning for Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+H">Hideya Ochiai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00917" title="Abstract">arXiv:2209.00917</a> (replaced) [<a href="/pdf/2209.00917" title="Download PDF">pdf</a>, <a href="/format/2209.00917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the 2022 XCSP3 Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Audemard%2C+G">Gilles Audemard</a>, 
<a href="/search/cs?searchtype=author&query=Lecoutre%2C+C">Christophe Lecoutre</a>, 
<a href="/search/cs?searchtype=author&query=Lonca%2C+E">Emmanuel Lonca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1901.01830">arXiv:1901.01830</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03300" title="Abstract">arXiv:2209.03300</a> (replaced) [<a href="/pdf/2209.03300" title="Download PDF">pdf</a>, <a href="/ps/2209.03300" title="Download PostScript">ps</a>, <a href="/format/2209.03300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spach Transformer: Spatial and Channel-wise Transformer Based on Local  and Global Self-attentions for PET Image Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jang%2C+S">Se-In Jang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+T">Tinsu Pan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Ye Li</a>, 
<a href="/search/eess?searchtype=author&query=Heidari%2C+P">Pedram Heidari</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Junyu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Quanzheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Gong%2C+K">Kuang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05580" title="Abstract">arXiv:2209.05580</a> (replaced) [<a href="/pdf/2209.05580" title="Download PDF">pdf</a>, <a href="/format/2209.05580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-aware Meta-level Decision Making for Exploration Under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ott%2C+J">Joshua Ott</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sung-Kyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bouman%2C+A">Amanda Bouman</a>, 
<a href="/search/cs?searchtype=author&query=Peltzer%2C+O">Oriana Peltzer</a>, 
<a href="/search/cs?searchtype=author&query=Sobue%2C+M">Mamoru Sobue</a>, 
<a href="/search/cs?searchtype=author&query=Delecki%2C+H">Harrison Delecki</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>, 
<a href="/search/cs?searchtype=author&query=Burdick%2C+J">Joel Burdick</a>, 
<a href="/search/cs?searchtype=author&query=Agha-mohammadi%2C+A">Ali-akbar Agha-mohammadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08728" title="Abstract">arXiv:2209.08728</a> (replaced) [<a href="/pdf/2209.08728" title="Download PDF">pdf</a>, <a href="/format/2209.08728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Barrier Functions for Stochastic Systems With Quantitative  Evaluation of Probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nishimura%2C+Y">Yuki Nishimura</a>, 
<a href="/search/math?searchtype=author&query=Hoshino%2C+K">Kenta Hoshino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08860" title="Abstract">arXiv:2209.08860</a> (replaced) [<a href="/pdf/2209.08860" title="Download PDF">pdf</a>, <a href="/format/2209.08860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Deep Causal Models and Their Industrial Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Z">Zongyu Li</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+X">Xiaobo Guo</a>, 
<a href="/search/stat?searchtype=author&query=Qiang%2C+S">Siwei Qiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Artificial Intelligence Review 5648ba1c-880e-4496-94da-d497be02a167|v.2.0 <a href="https://www.researchsquare.com/article/rs-2689686/v1">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15320" title="Abstract">arXiv:2209.15320</a> (replaced) [<a href="/pdf/2209.15320" title="Download PDF">pdf</a>, <a href="/format/2209.15320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded Robustness in Reinforcement Learning via Lexicographic  Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ornia%2C+D+J">Daniel Jarne Ornia</a>, 
<a href="/search/cs?searchtype=author&query=Romao%2C+L">Licio Romao</a>, 
<a href="/search/cs?searchtype=author&query=Hammond%2C+L">Lewis Hammond</a>, 
<a href="/search/cs?searchtype=author&query=Mazo%2C+M">Manuel Mazo Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01620" title="Abstract">arXiv:2210.01620</a> (replaced) [<a href="/pdf/2210.01620" title="Download PDF">pdf</a>, <a href="/format/2210.01620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM as an Optimal Relaxation of Bayes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%B6llenhoff%2C+T">Thomas M&#xf6;llenhoff</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+E">Mohammad Emtiyaz Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2023. Changes: Link to source code (<a href="https://github.com/team-approx-bayes/bayesian-sam">this https URL</a>), fix a typo in Appendix D
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04232" title="Abstract">arXiv:2210.04232</a> (replaced) [<a href="/pdf/2210.04232" title="Download PDF">pdf</a>, <a href="/ps/2210.04232" title="Download PostScript">ps</a>, <a href="/format/2210.04232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing Patient-Reported Experiences in Healthcare from Social Media  using the DAPMAV Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murray%2C+C">Curtis Murray</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+L">Lewis Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Tuke%2C+J">Jonathan Tuke</a>, 
<a href="/search/cs?searchtype=author&query=Mackay%2C+M">Mark Mackay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08964" title="Abstract">arXiv:2210.08964</a> (replaced) [<a href="/pdf/2210.08964" title="Download PDF">pdf</a>, <a href="/format/2210.08964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptCast: A New Prompt-based Learning Paradigm for Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xue%2C+H">Hao Xue</a>, 
<a href="/search/stat?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TKDE Accepted Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16694" title="Abstract">arXiv:2210.16694</a> (replaced) [<a href="/pdf/2210.16694" title="Download PDF">pdf</a>, <a href="/format/2210.16694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Programs with Conjunctive Database Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capelli%2C+F">Florent Capelli</a>, 
<a href="/search/cs?searchtype=author&query=Crosetti%2C+N">Nicolas Crosetti</a>, 
<a href="/search/cs?searchtype=author&query=Niehren%2C+J">Joachim Niehren</a>, 
<a href="/search/cs?searchtype=author&query=Ramon%2C+J">Jan Ramon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01595" title="Abstract">arXiv:2211.01595</a> (replaced) [<a href="/pdf/2211.01595" title="Download PDF">pdf</a>, <a href="/format/2211.01595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning in Non-Markovian Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chandak%2C+S">Siddharth Chandak</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+P">Pratik Shah</a>, 
<a href="/search/eess?searchtype=author&query=Borkar%2C+V+S">Vivek S Borkar</a>, 
<a href="/search/eess?searchtype=author&query=Dodhia%2C+P">Parth Dodhia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, submitted to Systems and Control Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01871" title="Abstract">arXiv:2211.01871</a> (replaced) [<a href="/pdf/2211.01871" title="Download PDF">pdf</a>, <a href="/format/2211.01871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Calibration of 3D Millimetre-Wavelength Radar-Camera  Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wise%2C+E">Emmett Wise</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qilong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics (T-RO), Vol. 39, No. 6, pp.
  4552-4566, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05523" title="Abstract">arXiv:2211.05523</a> (replaced) [<a href="/pdf/2211.05523" title="Download PDF">pdf</a>, <a href="/format/2211.05523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Adversarial Training on Robustness and Generalizability of  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altinisik%2C+E">Enes Altinisik</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+H">Hassan Sajjad</a>, 
<a href="/search/cs?searchtype=author&query=Sencar%2C+H+T">Husrev Taha Sencar</a>, 
<a href="/search/cs?searchtype=author&query=Messaoud%2C+S">Safa Messaoud</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+S">Sanjay Chawla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08162" title="Abstract">arXiv:2211.08162</a> (replaced) [<a href="/pdf/2211.08162" title="Download PDF">pdf</a>, <a href="/format/2211.08162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Squaring Verifiable Delay Function from Time-lock Puzzle in the  Group of Known Order
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sur%2C+S">Souvik Sur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.05997">arXiv:2112.05997</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10916" title="Abstract">arXiv:2211.10916</a> (replaced) [<a href="/pdf/2211.10916" title="Download PDF">pdf</a>, <a href="/format/2211.10916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECM-OPCC: Efficient Context Model for Octree-based Point Cloud  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yiqi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Ziyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tongda Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuhuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13436" title="Abstract">arXiv:2211.13436</a> (replaced) [<a href="/pdf/2211.13436" title="Download PDF">pdf</a>, <a href="/ps/2211.13436" title="Download PostScript">ps</a>, <a href="/format/2211.13436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Bilevel Knapsack Problem using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S">Sunhyeon Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hwayong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sungsoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13715" title="Abstract">arXiv:2211.13715</a> (replaced) [<a href="/pdf/2211.13715" title="Download PDF">pdf</a>, <a href="/format/2211.13715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Olko%2C+M">Mateusz Olko</a>, 
<a href="/search/stat?searchtype=author&query=Zaj%C4%85c%2C+M">Micha&#x142; Zaj&#x105;c</a>, 
<a href="/search/stat?searchtype=author&query=Nowak%2C+A">Aleksandra Nowak</a>, 
<a href="/search/stat?searchtype=author&query=Scherrer%2C+N">Nino Scherrer</a>, 
<a href="/search/stat?searchtype=author&query=Annadani%2C+Y">Yashas Annadani</a>, 
<a href="/search/stat?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/stat?searchtype=author&query=Kuci%C5%84ski%2C+%C5%81">&#x141;ukasz Kuci&#x144;ski</a>, 
<a href="/search/stat?searchtype=author&query=Mi%C5%82o%C5%9B%2C+P">Piotr Mi&#x142;o&#x15b;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13993" title="Abstract">arXiv:2211.13993</a> (replaced) [<a href="/pdf/2211.13993" title="Download PDF">pdf</a>, <a href="/format/2211.13993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating noisy labels in object detection datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chachu%C5%82a%2C+K">Krystian Chachu&#x142;a</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81yskawa%2C+J">Jakub &#x141;yskawa</a>, 
<a href="/search/cs?searchtype=author&query=Olber%2C+B">Bart&#x142;omiej Olber</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C4%85tczak%2C+P">Piotr Fr&#x105;tczak</a>, 
<a href="/search/cs?searchtype=author&query=Popowicz%2C+A">Adam Popowicz</a>, 
<a href="/search/cs?searchtype=author&query=Radlak%2C+K">Krystian Radlak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures, submitted to ICDE 2024 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.17074" title="Abstract">arXiv:2211.17074</a> (replaced) [<a href="/pdf/2211.17074" title="Download PDF">pdf</a>, <a href="/format/2211.17074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Data-Driven Stochastic Output-Feedback Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+G">Guanru Pan</a>, 
<a href="/search/eess?searchtype=author&query=Ou%2C+R">Ruchuan Ou</a>, 
<a href="/search/eess?searchtype=author&query=Faulwasser%2C+T">Timm Faulwasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01593" title="Abstract">arXiv:2212.01593</a> (replaced) [<a href="/pdf/2212.01593" title="Download PDF">pdf</a>, <a href="/format/2212.01593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make RepVGG Greater Again: A Quantization-aware Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04098" title="Abstract">arXiv:2212.04098</a> (replaced) [<a href="/pdf/2212.04098" title="Download PDF">pdf</a>, <a href="/format/2212.04098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPCL: Frozen CLIP Transformer is An Efficient Point Cloud Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+W">Wentao Qu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yifan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05225" title="Abstract">arXiv:2212.05225</a> (replaced) [<a href="/pdf/2212.05225" title="Download PDF">pdf</a>, <a href="/format/2212.05225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEAD: Liberal Feature-based Distillation for Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+A">Anlei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jingwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+R">Rangan Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06512" title="Abstract">arXiv:2212.06512</a> (replaced) [<a href="/pdf/2212.06512" title="Download PDF">pdf</a>, <a href="/format/2212.06512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DifFace: Blind Face Restoration with Diffused Error Contraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zongsheng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended to Face Inpainting. Project page: <a href="https://github.com/zsyOAOA/DifFace">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07679" title="Abstract">arXiv:2212.07679</a> (replaced) [<a href="/pdf/2212.07679" title="Download PDF">pdf</a>, <a href="/format/2212.07679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and exact fixed-radius neighbor search based on sorting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinye Chen</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCttel%2C+S">Stefan G&#xfc;ttel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.01456">arXiv:2202.01456</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10519" title="Abstract">arXiv:2212.10519</a> (replaced) [<a href="/pdf/2212.10519" title="Download PDF">pdf</a>, <a href="/format/2212.10519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On polynomial interpolation in the monomial basis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shen%2C+Z">Zewen Shen</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13001" title="Abstract">arXiv:2212.13001</a> (replaced) [<a href="/pdf/2212.13001" title="Download PDF">pdf</a>, <a href="/format/2212.13001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stochastic preconditioned Douglas-Rachford splitting method for  saddle-point problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+Y">Yakun Dong</a>, 
<a href="/search/math?searchtype=author&query=Bredies%2C+K">Kristian Bredies</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+H">Hongpeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14260" title="Abstract">arXiv:2212.14260</a> (replaced) [<a href="/pdf/2212.14260" title="Download PDF">pdf</a>, <a href="/format/2212.14260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Strategy Synthesis for Switched Stochastic  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gracia%2C+I">Ibon Gracia</a>, 
<a href="/search/eess?searchtype=author&query=Boskos%2C+D">Dimitris Boskos</a>, 
<a href="/search/eess?searchtype=author&query=Lahijanian%2C+M">Morteza Lahijanian</a>, 
<a href="/search/eess?searchtype=author&query=Laurenti%2C+L">Luca Laurenti</a>, 
<a href="/search/eess?searchtype=author&query=Mazo%2C+M">Manuel Mazo Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The updated version includes a computationally efficient reformulation of the dynamic programming algorithm for strategy synthesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14274" title="Abstract">arXiv:2212.14274</a> (replaced) [<a href="/pdf/2212.14274" title="Download PDF">pdf</a>, <a href="/format/2212.14274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Path Based Attentional Graph Learning Model for Vulnerability  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xin-Cheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiaxin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhihong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TSE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00524" title="Abstract">arXiv:2301.00524</a> (replaced) [<a href="/pdf/2301.00524" title="Download PDF">pdf</a>, <a href="/format/2301.00524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Confident Classifiers in the Presence of Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashmi%2C+A+A">Asma Ahmed Hashmi</a>, 
<a href="/search/cs?searchtype=author&query=Zhumabayeva%2C+A">Aigerim Zhumabayeva</a>, 
<a href="/search/cs?searchtype=author&query=Kotelevskii%2C+N">Nikita Kotelevskii</a>, 
<a href="/search/cs?searchtype=author&query=Agafonov%2C+A">Artem Agafonov</a>, 
<a href="/search/cs?searchtype=author&query=Yaqub%2C+M">Mohammad Yaqub</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+M">Maxim Panov</a>, 
<a href="/search/cs?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02876" title="Abstract">arXiv:2301.02876</a> (replaced) [<a href="/pdf/2301.02876" title="Download PDF">pdf</a>, <a href="/format/2301.02876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assigning Agents to Increase Network-Based Neighborhood Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zirou Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+A">Andrew Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M+V">Madhav V. Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S+S">S. S. Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Rosenkrantz%2C+D+J">Daniel J. Rosenkrantz</a>, 
<a href="/search/cs?searchtype=author&query=Stearns%2C+R+E">Richard E. Stearns</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A">Anil Vullikanti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted: AAMAS-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02889" title="Abstract">arXiv:2301.02889</a> (replaced) [<a href="/pdf/2301.02889" title="Download PDF">pdf</a>, <a href="/format/2301.02889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Networked Anti-Coordination Games Meet Graphical Dynamical Systems:  Equilibria and Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zirou Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M+V">Madhav V. Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S+S">S. S. Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Rosenkrantz%2C+D+J">Daniel J. Rosenkrantz</a>, 
<a href="/search/cs?searchtype=author&query=Stearns%2C+R+E">Richard E. Stearns</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A">Anil Vullikanti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04090" title="Abstract">arXiv:2301.04090</a> (replaced) [<a href="/pdf/2301.04090" title="Download PDF">pdf</a>, <a href="/format/2301.04090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Nontrivial Minimum Fixed Points in Discrete Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zirou Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M+V">Madhav V. Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S+S">S. S. Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Rosenkrantz%2C+D+J">Daniel J. Rosenkrantz</a>, 
<a href="/search/cs?searchtype=author&query=Stearns%2C+R+E">Richard E. Stearns</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A">Anil Vullikanti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04745" title="Abstract">arXiv:2301.04745</a> (replaced) [<a href="/pdf/2301.04745" title="Download PDF">pdf</a>, <a href="/format/2301.04745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Persistent Homology Computation for Functions on $\mathbb{R}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glisse%2C+M">Marc Glisse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Algebraic Topology (math.AT)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06246" title="Abstract">arXiv:2301.06246</a> (replaced) [<a href="/pdf/2301.06246" title="Download PDF">pdf</a>, <a href="/format/2301.06246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobility Data in Operations: The Facility Location Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Candogan%2C+O">Ozan Candogan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yiding Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07629" title="Abstract">arXiv:2301.07629</a> (replaced) [<a href="/pdf/2301.07629" title="Download PDF">pdf</a>, <a href="/format/2301.07629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalisation Through Negation and Predicate Invention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerna%2C+D+M">David M. Cerna</a>, 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08482" title="Abstract">arXiv:2301.08482</a> (replaced) [<a href="/pdf/2301.08482" title="Download PDF">pdf</a>, <a href="/format/2301.08482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Algorithm for Consistent Query Answering under Primary Keys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Figueira%2C+D">Diego Figueira</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabha%2C+A">Anantha Padmanabha</a>, 
<a href="/search/cs?searchtype=author&query=Segoufin%2C+L">Luc Segoufin</a>, 
<a href="/search/cs?searchtype=author&query=Sirangelo%2C+C">Cristina Sirangelo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10343" title="Abstract">arXiv:2301.10343</a> (replaced) [<a href="/pdf/2301.10343" title="Download PDF">pdf</a>, <a href="/format/2301.10343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClimaX: A foundation model for weather and climate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+A">Ashish Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J+K">Jayesh K. Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Machine Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10403" title="Abstract">arXiv:2301.10403</a> (replaced) [<a href="/pdf/2301.10403" title="Download PDF">pdf</a>, <a href="/format/2301.10403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact and rapid linear clustering of networks with dynamic programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patania%2C+A">Alice Patania</a>, 
<a href="/search/cs?searchtype=author&query=Allard%2C+A">Antoine Allard</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+J">Jean-Gabriel Young</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11930" title="Abstract">arXiv:2301.11930</a> (replaced) [<a href="/pdf/2301.11930" title="Download PDF">pdf</a>, <a href="/format/2301.11930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Quantum Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Choukroun%2C+Y">Yoni Choukroun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12473" title="Abstract">arXiv:2301.12473</a> (replaced) [<a href="/pdf/2301.12473" title="Download PDF">pdf</a>, <a href="/format/2301.12473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Biomedical Knowledge Graph Construction:  Information extraction from EMR notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arsenyan%2C+V">Vahan Arsenyan</a>, 
<a href="/search/cs?searchtype=author&query=Bughdaryan%2C+S">Spartak Bughdaryan</a>, 
<a href="/search/cs?searchtype=author&query=Shaya%2C+F">Fadi Shaya</a>, 
<a href="/search/cs?searchtype=author&query=Small%2C+K">Kent Small</a>, 
<a href="/search/cs?searchtype=author&query=Shahnazaryan%2C+D">Davit Shahnazaryan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13058" title="Abstract">arXiv:2301.13058</a> (replaced) [<a href="/pdf/2301.13058" title="Download PDF">pdf</a>, <a href="/ps/2301.13058" title="Download PostScript">ps</a>, <a href="/format/2301.13058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilinear optimal control for the fractional Laplacian: analysis and  discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bersetche%2C+F">Francisco Bersetche</a>, 
<a href="/search/math?searchtype=author&query=Fuica%2C+F">Francisco Fuica</a>, 
<a href="/search/math?searchtype=author&query=Otarola%2C+E">Enrique Otarola</a>, 
<a href="/search/math?searchtype=author&query=Quero%2C+D">Daniel Quero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13589" title="Abstract">arXiv:2301.13589</a> (replaced) [<a href="/pdf/2301.13589" title="Download PDF">pdf</a>, <a href="/ps/2301.13589" title="Download PostScript">ps</a>, <a href="/format/2301.13589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Gradient for Rectangular Robust Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Navdeep Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Derman%2C+E">Esther Derman</a>, 
<a href="/search/cs?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+K">Kfir Levy</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00735" title="Abstract">arXiv:2302.00735</a> (replaced) [<a href="/pdf/2302.00735" title="Download PDF">pdf</a>, <a href="/format/2302.00735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTP-GO: Graph-Based Probabilistic Multi-Agent Trajectory Prediction with  Neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westny%2C+T">Theodor Westny</a>, 
<a href="/search/cs?searchtype=author&query=Oskarsson%2C+J">Joel Oskarsson</a>, 
<a href="/search/cs?searchtype=author&query=Olofsson%2C+B">Bj&#xf6;rn Olofsson</a>, 
<a href="/search/cs?searchtype=author&query=Frisk%2C+E">Erik Frisk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/westny/mtp-go">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03629" title="Abstract">arXiv:2302.03629</a> (replaced) [<a href="/pdf/2302.03629" title="Download PDF">pdf</a>, <a href="/ps/2302.03629" title="Download PostScript">ps</a>, <a href="/format/2302.03629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethical Considerations for Responsible Data Curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andrews%2C+J+T+A">Jerone T. A. Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dora Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Thong%2C+W">William Thong</a>, 
<a href="/search/cs?searchtype=author&query=Modas%2C+A">Apostolos Modas</a>, 
<a href="/search/cs?searchtype=author&query=Papakyriakopoulos%2C+O">Orestis Papakyriakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+A">Alice Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Track on Datasets and Benchmarks (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05583" title="Abstract">arXiv:2302.05583</a> (replaced) [<a href="/pdf/2302.05583" title="Download PDF">pdf</a>, <a href="/format/2302.05583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Procedural generation of meta-reinforcement learning tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miconi%2C+T">Thomas Miconi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Agent Learning in Open-Endedness (ALOE) Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05906" title="Abstract">arXiv:2302.05906</a> (replaced) [<a href="/pdf/2302.05906" title="Download PDF">pdf</a>, <a href="/format/2302.05906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Comparing Fair Classifiers under Data Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mohit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Amit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+R">Rajiv Ratn Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a Spotlight Presentation at Algorithmic Fairness through the Lens of Time, Neurips 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06527" title="Abstract">arXiv:2302.06527</a> (replaced) [<a href="/pdf/2302.06527" title="Download PDF">pdf</a>, <a href="/format/2302.06527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Using Large Language Models for Automated  Unit Test Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+M">Max Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Nadi%2C+S">Sarah Nadi</a>, 
<a href="/search/cs?searchtype=author&query=Eghbali%2C+A">Aryaz Eghbali</a>, 
<a href="/search/cs?searchtype=author&query=Tip%2C+F">Frank Tip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08015" title="Abstract">arXiv:2302.08015</a> (replaced) [<a href="/pdf/2302.08015" title="Download PDF">pdf</a>, <a href="/format/2302.08015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individual Fairness under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juyong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Cheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Oommen%2C+T">Thomas Oommen</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+J">Jeremy Weiss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08719" title="Abstract">arXiv:2302.08719</a> (replaced) [<a href="/pdf/2302.08719" title="Download PDF">pdf</a>, <a href="/format/2302.08719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morley finite element analysis for fourth-order elliptic equations under  a semi-regular mesh condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishizaka%2C+H">Hiroki Ishizaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10963" title="Abstract">arXiv:2302.10963</a> (replaced) [<a href="/pdf/2302.10963" title="Download PDF">pdf</a>, <a href="/format/2302.10963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Learning Be Explained By Local Optimality In Low-rank Matrix  Recovery?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianhao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fattahi%2C+S">Salar Fattahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12247" title="Abstract">arXiv:2302.12247</a> (replaced) [<a href="/pdf/2302.12247" title="Download PDF">pdf</a>, <a href="/format/2302.12247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying &amp; Modeling Multimodal Interactions: An Information  Decomposition Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yun Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+K">Chun Kai Ling</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+S">Suzanne Nie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Richard Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zihao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+N">Nicholas Allen</a>, 
<a href="/search/cs?searchtype=author&query=Auerbach%2C+R">Randy Auerbach</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+F">Faisal Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Morency%2C+L">Louis-Philippe Morency</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code available at: <a href="https://github.com/pliang279/PID">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00994" title="Abstract">arXiv:2303.00994</a> (replaced) [<a href="/pdf/2303.00994" title="Download PDF">pdf</a>, <a href="/format/2303.00994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Randomized Subspace System Identification for Large I/O Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kedia%2C+V">Vatsal Kedia</a>, 
<a href="/search/eess?searchtype=author&query=Chakraborty%2C+D">Debraj Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Transactions on Automatic Control (TAC) - Under review, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01007" title="Abstract">arXiv:2303.01007</a> (replaced) [<a href="/pdf/2303.01007" title="Download PDF">pdf</a>, <a href="/format/2303.01007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical cycle-tree packing model for $K$-core attack problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zhou%2C+J">Jianwen Zhou</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhou%2C+H">Hai-Jun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02574" title="Abstract">arXiv:2303.02574</a> (replaced) [<a href="/pdf/2303.02574" title="Download PDF">pdf</a>, <a href="/format/2303.02574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim2Real Neural Controllers for Physics-based Robotic Deployment of  Deformable Linear Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+D">Dezhong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+A">Andrew Choi</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Longhui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weicheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+J">Jungseock Joo</a>, 
<a href="/search/cs?searchtype=author&query=Jawed%2C+M+K">M. Khalid Jawed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> YouTube video: <a href="https://youtu.be/OSD6dhOgyMA?feature=shared">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06121" title="Abstract">arXiv:2303.06121</a> (replaced) [<a href="/pdf/2303.06121" title="Download PDF">pdf</a>, <a href="/format/2303.06121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ignorance is Bliss: Robust Control via Information Gating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomar%2C+M">Manan Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+R">Riashat Islam</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+M+E">Matthew E. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Bachman%2C+P">Philip Bachman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09375" title="Abstract">arXiv:2303.09375</a> (replaced) [<a href="/pdf/2303.09375" title="Download PDF">pdf</a>, <a href="/format/2303.09375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svitov%2C+D">David Svitov</a>, 
<a href="/search/cs?searchtype=author&query=Gudkov%2C+D">Dmitrii Gudkov</a>, 
<a href="/search/cs?searchtype=author&query=Bashirov%2C+R">Renat Bashirov</a>, 
<a href="/search/cs?searchtype=author&query=Lempitsky%2C+V">Victor Lempitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09508" title="Abstract">arXiv:2303.09508</a> (replaced) [<a href="/pdf/2303.09508" title="Download PDF">pdf</a>, <a href="/format/2303.09508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDMVFI: Video Frame Interpolation with Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Danier%2C+D">Duolikun Danier</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09635" title="Abstract">arXiv:2303.09635</a> (replaced) [<a href="/pdf/2303.09635" title="Download PDF">pdf</a>, <a href="/format/2303.09635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universality and Control of Fat Tails
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chertkov%2C+M">Michael Chertkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, L-CSS/CDC 2023 (+ corrected missprints)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Control Systems Letters, v. 7, p. 1718-1723, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Statistical Mechanics (cond-mat.stat-mech); Chaotic Dynamics (nlin.CD); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09728" title="Abstract">arXiv:2303.09728</a> (replaced) [<a href="/pdf/2303.09728" title="Download PDF">pdf</a>, <a href="/format/2303.09728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cascaded Forward Algorithm for Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Gongpei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yidong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+C">Congyan Lang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haibin Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10275" title="Abstract">arXiv:2303.10275</a> (replaced) [<a href="/pdf/2303.10275" title="Download PDF">pdf</a>, <a href="/format/2303.10275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoRF: Mobile Realistic Fullbody Avatars from a Monocular Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bashirov%2C+R">Renat Bashirov</a>, 
<a href="/search/cs?searchtype=author&query=Larionov%2C+A">Alexey Larionov</a>, 
<a href="/search/cs?searchtype=author&query=Ustinova%2C+E">Evgeniya Ustinova</a>, 
<a href="/search/cs?searchtype=author&query=Sidorenko%2C+M">Mikhail Sidorenko</a>, 
<a href="/search/cs?searchtype=author&query=Svitov%2C+D">David Svitov</a>, 
<a href="/search/cs?searchtype=author&query=Zakharkin%2C+I">Ilya Zakharkin</a>, 
<a href="/search/cs?searchtype=author&query=Lempitsky%2C+V">Victor Lempitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10467" title="Abstract">arXiv:2303.10467</a> (replaced) [<a href="/pdf/2303.10467" title="Download PDF">pdf</a>, <a href="/format/2303.10467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSR Codes with Linear Field Size and Smallest Sub-packetization for Any  Number of Helper Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sihuang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Min Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is reorganized to make it more readable. The lower bounds in Lemma 6 and Lemma 9 are improved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11287" title="Abstract">arXiv:2303.11287</a> (replaced) [<a href="/pdf/2303.11287" title="Download PDF">pdf</a>, <a href="/format/2303.11287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Color Computer Generated Holography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Markley%2C+E">Eric Markley</a>, 
<a href="/search/physics?searchtype=author&query=Matsuda%2C+N">Nathan Matsuda</a>, 
<a href="/search/physics?searchtype=author&query=Schiffers%2C+F">Florian Schiffers</a>, 
<a href="/search/physics?searchtype=author&query=Cossairt%2C+O">Oliver Cossairt</a>, 
<a href="/search/physics?searchtype=author&query=Kuo%2C+G">Grace Kuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12928" title="Abstract">arXiv:2303.12928</a> (replaced) [<a href="/pdf/2303.12928" title="Download PDF">pdf</a>, <a href="/format/2303.12928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Multi-time Hamilton-Jacobi PDEs for Certain Scientific  Machine Learning Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Paula Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tingwei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zongren Zou</a>, 
<a href="/search/cs?searchtype=author&query=Darbon%2C+J">J&#xe9;r&#xf4;me Darbon</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13318" title="Abstract">arXiv:2303.13318</a> (replaced) [<a href="/pdf/2303.13318" title="Download PDF">pdf</a>, <a href="/format/2303.13318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Active Flux methods for linear advection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barsukow%2C+W">Wasilij Barsukow</a>, 
<a href="/search/math?searchtype=author&query=Borsche%2C+R">Raul Borsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14178" title="Abstract">arXiv:2303.14178</a> (replaced) [<a href="/pdf/2303.14178" title="Download PDF">pdf</a>, <a href="/ps/2303.14178" title="Download PostScript">ps</a>, <a href="/format/2303.14178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Protocol to Rule Them All? On Securing Interoperable Messaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blessing%2C+J">Jenny Blessing</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Ross Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16078" title="Abstract">arXiv:2303.16078</a> (replaced) [<a href="/pdf/2303.16078" title="Download PDF">pdf</a>, <a href="/format/2303.16078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative pose of three calibrated and partially calibrated cameras from  four points using virtual correspondences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tzamos%2C+C">Charalambos Tzamos</a>, 
<a href="/search/cs?searchtype=author&query=Barath%2C+D">Daniel Barath</a>, 
<a href="/search/cs?searchtype=author&query=Sattler%2C+T">Torsten Sattler</a>, 
<a href="/search/cs?searchtype=author&query=Kukelova%2C+Z">Zuzana Kukelova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17879" title="Abstract">arXiv:2303.17879</a> (replaced) [<a href="/pdf/2303.17879" title="Download PDF">pdf</a>, <a href="/format/2303.17879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSMo: a Framework to Instantiate Conditioned Process Simulation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oyamada%2C+R+S">Rafael S. Oyamada</a>, 
<a href="/search/cs?searchtype=author&query=Tavares%2C+G+M">Gabriel M. Tavares</a>, 
<a href="/search/cs?searchtype=author&query=Ceravolo%2C+P">Paolo Ceravolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00192" title="Abstract">arXiv:2304.00192</a> (replaced) [<a href="/e-print/2304.00192" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Neo4j and deep learning for traffic congestion simulation &amp;  optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Shyam Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+A">Arshad Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Souissi%2C+R">Riad Souissi</a>, 
<a href="/search/cs?searchtype=author&query=Yusuf%2C+S+A">Syed Adnan Yusuf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper was rejected by a journal publisher and we have advanced the research so need to re-write and re-publish in light of reviewers' comments and revised scope of research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00784" title="Abstract">arXiv:2304.00784</a> (replaced) [<a href="/pdf/2304.00784" title="Download PDF">pdf</a>, <a href="/format/2304.00784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Pre-training for Image Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanda Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zilong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbo Jiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024 as Oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01844" title="Abstract">arXiv:2304.01844</a> (replaced) [<a href="/pdf/2304.01844" title="Download PDF">pdf</a>, <a href="/format/2304.01844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grid-SD2E: A General Grid-Feedback in a System for Cognitive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jingyi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures, 8 formulas
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03548" title="Abstract">arXiv:2304.03548</a> (replaced) [<a href="/pdf/2304.03548" title="Download PDF">pdf</a>, <a href="/format/2304.03548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GEMINI: Controlling the Sentence-level Writing Style for Abstractive  Text Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+G">Guangsheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Z">Zebin Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023 camera-ready version. 8 pages, 5 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03671" title="Abstract">arXiv:2304.03671</a> (replaced) [<a href="/pdf/2304.03671" title="Download PDF">pdf</a>, <a href="/format/2304.03671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contraction-Guided Adaptive Partitioning for Reachability Analysis of  Neural Network Controlled Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Harapanahalli%2C+A">Akash Harapanahalli</a>, 
<a href="/search/eess?searchtype=author&query=Jafarpour%2C+S">Saber Jafarpour</a>, 
<a href="/search/eess?searchtype=author&query=Coogan%2C+S">Samuel Coogan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04364" title="Abstract">arXiv:2304.04364</a> (replaced) [<a href="/pdf/2304.04364" title="Download PDF">pdf</a>, <a href="/format/2304.04364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ITportrait: Image-Text Coupled 3D Portrait Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiangwen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuanhao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05655" title="Abstract">arXiv:2304.05655</a> (replaced) [<a href="/pdf/2304.05655" title="Download PDF">pdf</a>, <a href="/ps/2304.05655" title="Download PostScript">ps</a>, <a href="/format/2304.05655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localisation of Regularised and Multiview Support Vector Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gheondea%2C+A">Aurelian Gheondea</a>, 
<a href="/search/math?searchtype=author&query=Tilki%2C+C">Cankat Tilki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07460" title="Abstract">arXiv:2304.07460</a> (replaced) [<a href="/pdf/2304.07460" title="Download PDF">pdf</a>, <a href="/format/2304.07460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication and Energy Efficient Wireless Federated Learning with  Intrinsic Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanxiong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yanmin Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, Accepted for publication in IEEE Transactions on Dependable and Secure Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09595" title="Abstract">arXiv:2304.09595</a> (replaced) [<a href="/pdf/2304.09595" title="Download PDF">pdf</a>, <a href="/format/2304.09595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdapterGNN: Parameter-Efficient Fine-Tuning Improves Generalization in  GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xueting Han</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jing Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10351" title="Abstract">arXiv:2304.10351</a> (replaced) [<a href="/pdf/2304.10351" title="Download PDF">pdf</a>, <a href="/format/2304.10351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inducing Stackelberg Equilibrium through Spatio-Temporal Sequential  Decision-Making in Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guoliang Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper to the 32nd International Joint Conference on Artificial Intelligence (IJCAI-23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10356" title="Abstract">arXiv:2304.10356</a> (replaced) [<a href="/pdf/2304.10356" title="Download PDF">pdf</a>, <a href="/ps/2304.10356" title="Download PostScript">ps</a>, <a href="/format/2304.10356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive minimax optimality in statistical inverse problems via SOLIT --  Sharp Optimal Lepskii-Inspired Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Housen Li</a>, 
<a href="/search/math?searchtype=author&query=Werner%2C+F">Frank Werner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some technical parts are polished, and a comparison with classical Lepskii is included in the simulation section
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11171" title="Abstract">arXiv:2304.11171</a> (replaced) [<a href="/pdf/2304.11171" title="Download PDF">pdf</a>, <a href="/format/2304.11171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Granular-ball computing: an efficient, robust, and interpretable  adaptive multi-granularity representation and computation method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shuyin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiaoyu Lian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12180" title="Abstract">arXiv:2304.12180</a> (replaced) [<a href="/pdf/2304.12180" title="Download PDF">pdf</a>, <a href="/format/2304.12180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variance-Reduced Gradient Estimation via Noise-Reuse in Online Evolution  Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+O">Oscar Li</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+J">James Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-Dickstein%2C+J">Jascha Sohl-Dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>, 
<a href="/search/cs?searchtype=author&query=Metz%2C+L">Luke Metz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. 41 pages. Code available at <a href="https://github.com/OscarcarLi/Noise-Reuse-Evolution-Strategies">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13445" title="Abstract">arXiv:2304.13445</a> (replaced) [<a href="/pdf/2304.13445" title="Download PDF">pdf</a>, <a href="/format/2304.13445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-PBIR Reconstruction of Shape, Material, and Illumination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guangyan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+C">Carl Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project page at <a href="https://neural-pbir.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14385" title="Abstract">arXiv:2304.14385</a> (replaced) [<a href="/pdf/2304.14385" title="Download PDF">pdf</a>, <a href="/ps/2304.14385" title="Download PostScript">ps</a>, <a href="/format/2304.14385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Pricing and Learning with Bayesian Persuasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Shipra Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yiding Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference version appeared in NeurIPS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00199" title="Abstract">arXiv:2305.00199</a> (replaced) [<a href="/pdf/2305.00199" title="Download PDF">pdf</a>, <a href="/ps/2305.00199" title="Download PostScript">ps</a>, <a href="/format/2305.00199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Scale Assessment of Labour Market Dynamics in China during the  COVID-19 Pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01154" title="Abstract">arXiv:2305.01154</a> (replaced) [<a href="/pdf/2305.01154" title="Download PDF">pdf</a>, <a href="/format/2305.01154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedAVO: Improving Communication Efficiency in Federated Learning with  African Vultures Optimizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+Z">Md Zarif Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Imteaj%2C+A">Ahmed Imteaj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02105" title="Abstract">arXiv:2305.02105</a> (replaced) [<a href="/pdf/2305.02105" title="Download PDF">pdf</a>, <a href="/format/2305.02105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-RE: In-context Learning for Relation Extraction using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Fei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhuoyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qianying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Haiyue Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Kurohashi%2C+S">Sadao Kurohashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 Main Conference (long paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02177" title="Abstract">arXiv:2305.02177</a> (replaced) [<a href="/pdf/2305.02177" title="Download PDF">pdf</a>, <a href="/format/2305.02177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforming Visual Scene Graphs to Image Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiawei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Songfang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhangzikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, has been accepted by ACL 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03520" title="Abstract">arXiv:2305.03520</a> (replaced) [<a href="/pdf/2305.03520" title="Download PDF">pdf</a>, <a href="/ps/2305.03520" title="Download PostScript">ps</a>, <a href="/format/2305.03520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Semantic Similarity Measurement for Unsupervised Word  Sense Disambiguation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinez-Gil%2C+J">Jorge Martinez-Gil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04388" title="Abstract">arXiv:2305.04388</a> (replaced) [<a href="/pdf/2305.04388" title="Download PDF">pdf</a>, <a href="/format/2305.04388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models Don&#x27;t Always Say What They Think: Unfaithful  Explanations in Chain-of-Thought Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turpin%2C+M">Miles Turpin</a>, 
<a href="/search/cs?searchtype=author&query=Michael%2C+J">Julian Michael</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+E">Ethan Perez</a>, 
<a href="/search/cs?searchtype=author&query=Bowman%2C+S+R">Samuel R. Bowman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05463" title="Abstract">arXiv:2305.05463</a> (replaced) [<a href="/pdf/2305.05463" title="Download PDF">pdf</a>, <a href="/ps/2305.05463" title="Download PostScript">ps</a>, <a href="/format/2305.05463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Tier Hierarchical Federated Learning-assisted NTN for Intelligent  IoT Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farajzadeh%2C+A">Amin Farajzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Animesh Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05983" title="Abstract">arXiv:2305.05983</a> (replaced) [<a href="/pdf/2305.05983" title="Download PDF">pdf</a>, <a href="/format/2305.05983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Access and Backhaul in 5G with Aerial Distributed Unit using  OpenAirInterface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mundlamuri%2C+R">Rakesh Mundlamuri</a>, 
<a href="/search/cs?searchtype=author&query=Esrafilian%2C+O">Omid Esrafilian</a>, 
<a href="/search/cs?searchtype=author&query=Gangula%2C+R">Rajeev Gangula</a>, 
<a href="/search/cs?searchtype=author&query=Kharade%2C+R">Rohan Kharade</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+C">Cedric Roux</a>, 
<a href="/search/cs?searchtype=author&query=Kaltenberger%2C+F">Florian Kaltenberger</a>, 
<a href="/search/cs?searchtype=author&query=Knopp%2C+R">Raymond Knopp</a>, 
<a href="/search/cs?searchtype=author&query=Gesbert%2C+D">David Gesbert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06225" title="Abstract">arXiv:2305.06225</a> (replaced) [<a href="/pdf/2305.06225" title="Download PDF">pdf</a>, <a href="/format/2305.06225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head  Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Fa-Ting Hong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TPAMI; CVPR 2022 extension
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06324" title="Abstract">arXiv:2305.06324</a> (replaced) [<a href="/pdf/2305.06324" title="Download PDF">pdf</a>, <a href="/format/2305.06324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternating Gradient Descent and Mixture-of-Experts for Integrated  Multimodal Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akbari%2C+H">Hassan Akbari</a>, 
<a href="/search/cs?searchtype=author&query=Kondratyuk%2C+D">Dan Kondratyuk</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Hornung%2C+R">Rachel Hornung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+H">Hartwig Adam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07372" title="Abstract">arXiv:2305.07372</a> (replaced) [<a href="/pdf/2305.07372" title="Download PDF">pdf</a>, <a href="/format/2305.07372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Text-to-SQL Generation via Editable Step-by-Step  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zheng Ning</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Kummerfeld%2C+J+K">Jonathan K. Kummerfeld</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ARR AE score of 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08361" title="Abstract">arXiv:2305.08361</a> (replaced) [<a href="/pdf/2305.08361" title="Download PDF">pdf</a>, <a href="/ps/2305.08361" title="Download PostScript">ps</a>, <a href="/format/2305.08361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal harvesting policy for biological resources with uncertain  heterogeneity for application in fisheries management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yoshioka%2C+H">Hidekazu Yoshioka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under second review in some journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09009" title="Abstract">arXiv:2305.09009</a> (replaced) [<a href="/pdf/2305.09009" title="Download PDF">pdf</a>, <a href="/format/2305.09009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Geometric Trajectory Tracking using Lie Algebraic MPC for  Autonomous Marine Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Junwoo Jang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+S">Sangli Teng</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robot. Automat. Lett., vol 6, no. 2 (2023) 8374 - 8381
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09029" title="Abstract">arXiv:2305.09029</a> (replaced) [<a href="/pdf/2305.09029" title="Download PDF">pdf</a>, <a href="/ps/2305.09029" title="Download PostScript">ps</a>, <a href="/format/2305.09029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log-concavity and log-convexity of series containing multiple Pochhammer  symbols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karp%2C+D">Dmitrii Karp</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages; no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09792" title="Abstract">arXiv:2305.09792</a> (replaced) [<a href="/pdf/2305.09792" title="Download PDF">pdf</a>, <a href="/format/2305.09792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score Operator Newton transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chandramoorthy%2C+N">Nisha Chandramoorthy</a>, 
<a href="/search/math?searchtype=author&query=Schaefer%2C+F">Florian Schaefer</a>, 
<a href="/search/math?searchtype=author&query=Marzouk%2C+Y">Youssef Marzouk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages; Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10133" title="Abstract">arXiv:2305.10133</a> (replaced) [<a href="/pdf/2305.10133" title="Download PDF">pdf</a>, <a href="/format/2305.10133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of 3D Molecules in Pockets via Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lvwei Wang</a> (1), 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zaiyun Lin</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanhao Zhu</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a> (1), 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianqiang Dong</a> (1), 
<a href="/search/cs?searchtype=author&query=Bai%2C+R">Rong Bai</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huting Wang</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jielong Zhou</a> (1), 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a> (2), 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenbiao Zhou</a> (1) ((1) Beijing StoneWise Technology Co Ltd (2) Innovation Center for Pathogen Research Guangzhou Laboratory)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10506" title="Abstract">arXiv:2305.10506</a> (replaced) [<a href="/e-print/2305.10506" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Recovery for System Identification with More Corrupt Data than  Clean Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yalcin%2C+B">Baturalp Yalcin</a>, 
<a href="/search/cs?searchtype=author&query=Lavaei%2C+J">Javad Lavaei</a>, 
<a href="/search/cs?searchtype=author&query=Arcak%2C+M">Murat Arcak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We will make major updates to the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12032" title="Abstract">arXiv:2305.12032</a> (replaced) [<a href="/pdf/2305.12032" title="Download PDF">pdf</a>, <a href="/format/2305.12032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Waymo Open Sim Agents Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montali%2C+N">Nico Montali</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+J">John Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Mougin%2C+P">Paul Mougin</a>, 
<a href="/search/cs?searchtype=author&query=Kuefler%2C+A">Alex Kuefler</a>, 
<a href="/search/cs?searchtype=author&query=Rhinehart%2C+N">Nick Rhinehart</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Michelle Li</a>, 
<a href="/search/cs?searchtype=author&query=Gulino%2C+C">Cole Gulino</a>, 
<a href="/search/cs?searchtype=author&query=Emrich%2C+T">Tristan Emrich</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zoey Yang</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+B">Brandyn White</a>, 
<a href="/search/cs?searchtype=author&query=Anguelov%2C+D">Dragomir Anguelov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, Track on Datasets and Benchmarks. Public leaderboard available at <a href="https://waymo.com/open/challenges/2023/sim-agents/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12464" title="Abstract">arXiv:2305.12464</a> (replaced) [<a href="/pdf/2305.12464" title="Download PDF">pdf</a>, <a href="/format/2305.12464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Predictive Coding Models Encode Speaker and Phonetic  Information in Orthogonal Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+O">Oli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Goldwater%2C+S">Sharon Goldwater</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12530" title="Abstract">arXiv:2305.12530</a> (replaced) [<a href="/pdf/2305.12530" title="Download PDF">pdf</a>, <a href="/format/2305.12530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Family-Infant Audio Analysis Based on Unsupervised  Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jialu Li</a>, 
<a href="/search/eess?searchtype=author&query=Hasegawa-Johnson%2C+M">Mark Hasegawa-Johnson</a>, 
<a href="/search/eess?searchtype=author&query=McElwain%2C+N+L">Nancy L. McElwain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of Interspeech 2023; v4 version updates: correction of W2V2-base pretrained on 960-hour of LibriSpeech and number of families participated for LENA home recordings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12534" title="Abstract">arXiv:2305.12534</a> (replaced) [<a href="/pdf/2305.12534" title="Download PDF">pdf</a>, <a href="/format/2305.12534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BertRLFuzzer: A BERT and Reinforcement Learning Based Fuzzer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Piyush Jha</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+J">Joseph Scott</a>, 
<a href="/search/cs?searchtype=author&query=Ganeshna%2C+J+S">Jaya Sriram Ganeshna</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mudit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+V">Vijay Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12878" title="Abstract">arXiv:2305.12878</a> (replaced) [<a href="/pdf/2305.12878" title="Download PDF">pdf</a>, <a href="/format/2305.12878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Autoregressive Document-Level Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+G">Guangsheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhiyang Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jianhao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023 Findings camera-ready version. Review soundness 443 and excitement 443
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12975" title="Abstract">arXiv:2305.12975</a> (replaced) [<a href="/pdf/2305.12975" title="Download PDF">pdf</a>, <a href="/ps/2305.12975" title="Download PostScript">ps</a>, <a href="/format/2305.12975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphical Proof Theory I: Sequent Calculi operating on Undirected Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acclavio%2C+M">Matteo Acclavio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13014" title="Abstract">arXiv:2305.13014</a> (replaced) [<a href="/pdf/2305.13014" title="Download PDF">pdf</a>, <a href="/ps/2305.13014" title="Download PostScript">ps</a>, <a href="/format/2305.13014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models emulate an inductive Thematic Analysis of  semi-structured interviews? An exploration and provocation on the limits of  the approach and the model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Paoli%2C+S">Stefano De Paoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13048" title="Abstract">arXiv:2305.13048</a> (replaced) [<a href="/pdf/2305.13048" title="Download PDF">pdf</a>, <a href="/format/2305.13048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RWKV: Reinventing RNNs for the Transformer Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Alcaide%2C+E">Eric Alcaide</a>, 
<a href="/search/cs?searchtype=author&query=Anthony%2C+Q">Quentin Anthony</a>, 
<a href="/search/cs?searchtype=author&query=Albalak%2C+A">Alon Albalak</a>, 
<a href="/search/cs?searchtype=author&query=Arcadinho%2C+S">Samuel Arcadinho</a>, 
<a href="/search/cs?searchtype=author&query=Biderman%2C+S">Stella Biderman</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Huanqi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+M">Michael Chung</a>, 
<a href="/search/cs?searchtype=author&query=Grella%2C+M">Matteo Grella</a>, 
<a href="/search/cs?searchtype=author&query=GV%2C+K+K">Kranthi Kiran GV</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuzheng He</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+H">Haowen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiaju Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kazienko%2C+P">Przemyslaw Kazienko</a>, 
<a href="/search/cs?searchtype=author&query=Kocon%2C+J">Jan Kocon</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+J">Jiaming Kong</a>, 
<a href="/search/cs?searchtype=author&query=Koptyra%2C+B">Bartlomiej Koptyra</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+H">Hayden Lau</a>, 
<a href="/search/cs?searchtype=author&query=Mantri%2C+K+S+I">Krishna Sri Ipsit Mantri</a>, 
<a href="/search/cs?searchtype=author&query=Mom%2C+F">Ferdinand Mom</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+A">Atsushi Saito</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guangyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bolun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wind%2C+J+S">Johan S. Wind</a>, 
<a href="/search/cs?searchtype=author&query=Wozniak%2C+S">Stanislaw Wozniak</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruichong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qihang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qinghua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui-Jie Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15184" title="Abstract">arXiv:2305.15184</a> (replaced) [<a href="/pdf/2305.15184" title="Download PDF">pdf</a>, <a href="/format/2305.15184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6G Enabled Advanced Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Meng Hua</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+K">Ke Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Leyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+T">Tianqi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jamalipour%2C+A">Abbas Jamalipour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Intelligent Transportation Systems (T-ITS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15265" title="Abstract">arXiv:2305.15265</a> (replaced) [<a href="/pdf/2305.15265" title="Download PDF">pdf</a>, <a href="/format/2305.15265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanchu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shaochen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhaozhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhimeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+V">Vipin Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15769" title="Abstract">arXiv:2305.15769</a> (replaced) [<a href="/pdf/2305.15769" title="Download PDF">pdf</a>, <a href="/format/2305.15769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MERGE: Fast Private Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pinghui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+L">Lifeng Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15990" title="Abstract">arXiv:2305.15990</a> (replaced) [<a href="/pdf/2305.15990" title="Download PDF">pdf</a>, <a href="/format/2305.15990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINNslope: seismic data interpolation and local slope estimation with  physics informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Brandolin%2C+F">Francesco Brandolin</a>, 
<a href="/search/physics?searchtype=author&query=Ravasi%2C+M">Matteo Ravasi</a>, 
<a href="/search/physics?searchtype=author&query=Alkhalifah%2C+T">Tariq Alkhalifah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16771" title="Abstract">arXiv:2305.16771</a> (replaced) [<a href="/pdf/2305.16771" title="Download PDF">pdf</a>, <a href="/format/2305.16771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Nonparametric Regression under Poisoning Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+P">Puning Zhao</a>, 
<a href="/search/math?searchtype=author&query=Wan%2C+Z">Zhiguo Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16941" title="Abstract">arXiv:2305.16941</a> (replaced) [<a href="/pdf/2305.16941" title="Download PDF">pdf</a>, <a href="/format/2305.16941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milli%2C+S">Smitha Milli</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+M">Micah Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yike Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S">Sashrika Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sebastian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A+D">Anca D. Dragan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17581" title="Abstract">arXiv:2305.17581</a> (replaced) [<a href="/pdf/2305.17581" title="Download PDF">pdf</a>, <a href="/format/2305.17581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation Performs Partial Variance Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safaryan%2C+M">Mher Safaryan</a>, 
<a href="/search/cs?searchtype=author&query=Peste%2C+A">Alexandra Peste</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15+22 pages, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18772" title="Abstract">arXiv:2305.18772</a> (replaced) [<a href="/pdf/2305.18772" title="Download PDF">pdf</a>, <a href="/ps/2305.18772" title="Download PostScript">ps</a>, <a href="/format/2305.18772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Remarks on Yablo Like Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schlechta%2C+K">Karl Schlechta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00196" title="Abstract">arXiv:2306.00196</a> (replaced) [<a href="/pdf/2306.00196" title="Download PDF">pdf</a>, <a href="/format/2306.00196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restless Bandits with Average Reward: Breaking the Uniform Global  Attractor Assumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yige Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weina Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. 38 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00393" title="Abstract">arXiv:2306.00393</a> (replaced) [<a href="/pdf/2306.00393" title="Download PDF">pdf</a>, <a href="/format/2306.00393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teacher Agent: A Knowledge Distillation-Free Framework for  Rehearsal-based Video Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shengqin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yaoyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haokui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuankai Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00723" title="Abstract">arXiv:2306.00723</a> (replaced) [<a href="/pdf/2306.00723" title="Download PDF">pdf</a>, <a href="/ps/2306.00723" title="Download PostScript">ps</a>, <a href="/format/2306.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Mood-While-Eating with Smartphone Sensing and Community-Based  Model Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bangamuarachchi%2C+W">Wageesha Bangamuarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Chamantha%2C+A">Anju Chamantha</a>, 
<a href="/search/cs?searchtype=author&query=Meegahapola%2C+L">Lakmal Meegahapola</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Haeeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz-Correa%2C+S">Salvador Ruiz-Correa</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+I">Indika Perera</a>, 
<a href="/search/cs?searchtype=author&query=Gatica-Perez%2C+D">Daniel Gatica-Perez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01804" title="Abstract">arXiv:2306.01804</a> (replaced) [<a href="/pdf/2306.01804" title="Download PDF">pdf</a>, <a href="/format/2306.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Reward Functions from Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nuti%2C+F">Felipe Nuti</a>, 
<a href="/search/cs?searchtype=author&query=Franzmeyer%2C+T">Tim Franzmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+J+F">Jo&#xe3;o F. Henriques</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02316" title="Abstract">arXiv:2306.02316</a> (replaced) [<a href="/pdf/2306.02316" title="Download PDF">pdf</a>, <a href="/format/2306.02316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Dynamic Quantization for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=So%2C+J">Junhyuk So</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+D">Daehyun Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunhyeok Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02320" title="Abstract">arXiv:2306.02320</a> (replaced) [<a href="/pdf/2306.02320" title="Download PDF">pdf</a>, <a href="/format/2306.02320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Model Scaling on Parameter-Efficient Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yusheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chi-Min Chan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiali Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengding Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zonghan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xingzhi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guotong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02822" title="Abstract">arXiv:2306.02822</a> (replaced) [<a href="/pdf/2306.02822" title="Download PDF">pdf</a>, <a href="/format/2306.02822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Dynamic Causal Space for DAG Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangfu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenchang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">An Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yueqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by KDD 2023. Our codes are available at <a href="https://github.com/liuff19/CASPER">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02956" title="Abstract">arXiv:2306.02956</a> (replaced) [<a href="/pdf/2306.02956" title="Download PDF">pdf</a>, <a href="/format/2306.02956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+T">Thomas Walker</a>, 
<a href="/search/cs?searchtype=author&query=Mariotti%2C+O">Octave Mariotti</a>, 
<a href="/search/cs?searchtype=author&query=Vaxman%2C+A">Amir Vaxman</a>, 
<a href="/search/cs?searchtype=author&query=Bilen%2C+H">Hakan Bilen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03161" title="Abstract">arXiv:2306.03161</a> (replaced) [<a href="/pdf/2306.03161" title="Download PDF">pdf</a>, <a href="/ps/2306.03161" title="Download PostScript">ps</a>, <a href="/format/2306.03161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Entanglement and Statistics in Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Arunachalam%2C+S">Srinivasan Arunachalam</a>, 
<a href="/search/quant-ph?searchtype=author&query=Havlicek%2C+V">Vojtech Havlicek</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schatzki%2C+L">Louis Schatzki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 4 pages of appendix Update: typos fixed and minor edits to proofs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04300" title="Abstract">arXiv:2306.04300</a> (replaced) [<a href="/pdf/2306.04300" title="Download PDF">pdf</a>, <a href="/format/2306.04300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CorrMatch: Label Propagation via Correlation Matching for  Semi-Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Boyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04998" title="Abstract">arXiv:2306.04998</a> (replaced) [<a href="/pdf/2306.04998" title="Download PDF">pdf</a>, <a href="/format/2306.04998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Unsupervised Anomaly Detection with Quantum Boltzmann Machines  in Fraud Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schuman%2C+D">Dani&#xeb;lle Schuman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Benkard%2C+M">Magdalena Benkard</a>, 
<a href="/search/quant-ph?searchtype=author&query=Holger%2C+T">Thomas Holger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sajko%2C+W">Wanja Sajko</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=N%C3%BC%C3%9Flein%2C+J">Jonas N&#xfc;&#xdf;lein</a>, 
<a href="/search/quant-ph?searchtype=author&query=S%C3%BCnkel%2C+L">Leo S&#xfc;nkel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Salomon%2C+O">Olivier Salomon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05042" title="Abstract">arXiv:2306.05042</a> (replaced) [<a href="/pdf/2306.05042" title="Download PDF">pdf</a>, <a href="/ps/2306.05042" title="Download PostScript">ps</a>, <a href="/format/2306.05042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Quantum Surrogate Models on Scarce and Noisy Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Poppel%2C+M">Michael Poppel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Adamczyk%2C+P">Philip Adamczyk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fabry%2C+R">Ramona Fabry</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+Z">Zixin Wu</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=N%C3%BC%C3%9Flein%2C+J">Jonas N&#xfc;&#xdf;lein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schuman%2C+D">Dani&#xeb;lle Schuman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ehmer%2C+T">Thomas Ehmer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Narasimhan%2C+V">Vijay Narasimhan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05911" title="Abstract">arXiv:2306.05911</a> (replaced) [<a href="/pdf/2306.05911" title="Download PDF">pdf</a>, <a href="/format/2306.05911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch2Stress: Sketching with Structural Stress Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Deng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chufeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+M">Manfred Lau</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongbo Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Visualization and Computer Graphics (IEEE TVCG)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06070" title="Abstract">arXiv:2306.06070</a> (replaced) [<a href="/pdf/2306.06070" title="Download PDF">pdf</a>, <a href="/format/2306.06070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind2Web: Towards a Generalist Agent for the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Boyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boshi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://osu-nlp-group.github.io/Mind2Web.">this https URL</a> Updated with supplementary material. NeurIPS'23 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06689" title="Abstract">arXiv:2306.06689</a> (replaced) [<a href="/pdf/2306.06689" title="Download PDF">pdf</a>, <a href="/ps/2306.06689" title="Download PostScript">ps</a>, <a href="/format/2306.06689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order-One Convergence of the Backward Euler Method for Random Periodic  Solutions of Semilinear SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+Y">Yujia Guo</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yue Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07042" title="Abstract">arXiv:2306.07042</a> (replaced) [<a href="/pdf/2306.07042" title="Download PDF">pdf</a>, <a href="/format/2306.07042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers learn through gradual rank increase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boix-Adsera%2C+E">Enric Boix-Adsera</a>, 
<a href="/search/cs?searchtype=author&query=Littwin%2C+E">Etai Littwin</a>, 
<a href="/search/cs?searchtype=author&query=Abbe%2C+E">Emmanuel Abbe</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+S">Samy Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J">Joshua Susskind</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, to appear in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07547" title="Abstract">arXiv:2306.07547</a> (replaced) [<a href="/pdf/2306.07547" title="Download PDF">pdf</a>, <a href="/format/2306.07547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniCATS: A Unified Context-Aware Text-to-Speech Framework with  Contextual VQ-Diffusion and Vocoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Feiyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07894" title="Abstract">arXiv:2306.07894</a> (replaced) [<a href="/pdf/2306.07894" title="Download PDF">pdf</a>, <a href="/format/2306.07894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iSLAM: Imperative SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Taimeng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shaoshu Su</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yiren Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09344" title="Abstract">arXiv:2306.09344</a> (replaced) [<a href="/pdf/2306.09344" title="Download PDF">pdf</a>, <a href="/format/2306.09344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamSim: Learning New Dimensions of Human Visual Similarity using  Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Stephanie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Tamir%2C+N">Netanel Tamir</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+S">Shobhita Sundaram</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+L">Lucy Chai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dekel%2C+T">Tali Dekel</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://dreamsim-nights.github.io/">this https URL</a> Code: <a href="https://github.com/ssundaram21/dreamsim">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09364" title="Abstract">arXiv:2306.09364</a> (replaced) [<a href="/pdf/2306.09364" title="Download PDF">pdf</a>, <a href="/format/2306.09364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ekambaram%2C+V">Vijay Ekambaram</a>, 
<a href="/search/cs?searchtype=author&query=Jati%2C+A">Arindam Jati</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nam Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Sinthong%2C+P">Phanwadee Sinthong</a>, 
<a href="/search/cs?searchtype=author&query=Kalagnanam%2C+J">Jayant Kalagnanam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 23), Research Track. Delayed release in arXiv to comply with the conference policies on the double-blind review process. This paper has been submitted to the KDD peer-review process on Feb 02, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09444" title="Abstract">arXiv:2306.09444</a> (replaced) [<a href="/pdf/2306.09444" title="Download PDF">pdf</a>, <a href="/format/2306.09444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Scale Quantum Separability Through a Reproducible Machine Learning  Lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Casal%C3%A9%2C+B">Balthazar Casal&#xe9;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Di+Molfetta%2C+G">Giuseppe Di Molfetta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Anthoine%2C+S">Sandrine Anthoine</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kadri%2C+H">Hachem Kadri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09803" title="Abstract">arXiv:2306.09803</a> (replaced) [<a href="/pdf/2306.09803" title="Download PDF">pdf</a>, <a href="/format/2306.09803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Framework and Benchmarks for Combinatorial and Mixed-variable Bayesian  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dreczkowski%2C+K">Kamil Dreczkowski</a>, 
<a href="/search/cs?searchtype=author&query=Grosnit%2C+A">Antoine Grosnit</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+H+B">Haitham Bou Ammar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09910" title="Abstract">arXiv:2306.09910</a> (replaced) [<a href="/pdf/2306.09910" title="Download PDF">pdf</a>, <a href="/format/2306.09910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LabelBench: A Comprehensive Framework for Benchmarking Adaptive  Label-Efficient Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Canal%2C+G">Gregory Canal</a>, 
<a href="/search/cs?searchtype=author&query=Mussmann%2C+S">Stephen Mussmann</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav M. Das</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yinglun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon Shaolei Du</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R+D">Robert D Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10619" title="Abstract">arXiv:2306.10619</a> (replaced) [<a href="/pdf/2306.10619" title="Download PDF">pdf</a>, <a href="/format/2306.10619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Stability of Autoregressive Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCabe%2C+M">Michael McCabe</a>, 
<a href="/search/cs?searchtype=author&query=Harrington%2C+P">Peter Harrington</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S">Shashank Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+J">Jed Brown</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research. November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11698" title="Abstract">arXiv:2306.11698</a> (replaced) [<a href="/pdf/2306.11698" title="Download PDF">pdf</a>, <a href="/format/2306.11698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+H">Hengzhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mintong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chejian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zidi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+R">Ritik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+R">Rylan Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+S+T">Sang T. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Simran Arora</a>, 
<a href="/search/cs?searchtype=author&query=Mazeika%2C+M">Mantas Mazeika</a>, 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Oral Presentation in NeurIPS 2023 (Datasets and Benchmarks Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11920" title="Abstract">arXiv:2306.11920</a> (replaced) [<a href="/pdf/2306.11920" title="Download PDF">pdf</a>, <a href="/format/2306.11920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NILUT: Conditional Neural Implicit 3D Lookup Tables for Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conde%2C+M+V">Marcos V. Conde</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez-Corral%2C+J">Javier Vazquez-Corral</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+M+S">Michael S. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 - The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12461" title="Abstract">arXiv:2306.12461</a> (replaced) [<a href="/pdf/2306.12461" title="Download PDF">pdf</a>, <a href="/format/2306.12461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-orbit model training for satellite imagery with label proportions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramos-Poll%C3%A1n%2C+R">Ra&#xfa;l Ramos-Poll&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+F+A">Fabio A. Gonz&#xe1;lez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12562" title="Abstract">arXiv:2306.12562</a> (replaced) [<a href="/pdf/2306.12562" title="Download PDF">pdf</a>, <a href="/format/2306.12562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Spectro-polarimetric Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wonjoon Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14870" title="Abstract">arXiv:2306.14870</a> (replaced) [<a href="/pdf/2306.14870" title="Download PDF">pdf</a>, <a href="/format/2306.14870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composing Parameter-Efficient Modules with Arithmetic Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junteng Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code is available at <a href="https://github.com/SJTU-LIT/PEM_composition">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15319" title="Abstract">arXiv:2306.15319</a> (replaced) [<a href="/pdf/2306.15319" title="Download PDF">pdf</a>, <a href="/ps/2306.15319" title="Download PostScript">ps</a>, <a href="/format/2306.15319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nano1D: An accurate Computer Vision software for analysis and  segmentation of low-dimensional nanostructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Moradpur-Tari%2C+E">Ehsan Moradpur-Tari</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Vlassov%2C+S">Sergei Vlassov</a> (1,2), 
<a href="/search/cond-mat?searchtype=author&query=Oras%2C+S">Sven Oras</a> (1,2), 
<a href="/search/cond-mat?searchtype=author&query=Ernits%2C+M">Mart Ernits</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Damerchi%2C+E">Elyad Damerchi</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Polyakovc%2C+B">Boris Polyakovc</a> (3), 
<a href="/search/cond-mat?searchtype=author&query=Kyritsakis%2C+A">Andreas Kyritsakis</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Zadin%2C+V">Veronika Zadin</a> (1) ((1) Institute of Technology, University of Tartu, Nooruse 1, 50411 Tartu, Estonia (2) Institute of Physics, University of Tartu, W. Ostwaldi 1, 50411 Tartu, Estonia (3) Institute of Solid State Physics, University of Latvia, Kengaraga street 8, LV-1063 Riga, Latvia)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15381" title="Abstract">arXiv:2306.15381</a> (replaced) [<a href="/pdf/2306.15381" title="Download PDF">pdf</a>, <a href="/format/2306.15381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic-Preserving Neural Networks for Multiscale Kinetic Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+K">Keke Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16022" title="Abstract">arXiv:2306.16022</a> (replaced) [<a href="/pdf/2306.16022" title="Download PDF">pdf</a>, <a href="/format/2306.16022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enrollment-stage Backdoor Attacks on Speaker Recognition Systems via  Adversarial Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+J">Junning Ze</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yushi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Internet of Things Journal (IoT-J)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17594" title="Abstract">arXiv:2306.17594</a> (replaced) [<a href="/pdf/2306.17594" title="Download PDF">pdf</a>, <a href="/format/2306.17594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On numerical realizations of Shannon&#x27;s sampling theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kircheis%2C+M">Melanie Kircheis</a>, 
<a href="/search/math?searchtype=author&query=Potts%2C+D">Daniel Potts</a>, 
<a href="/search/math?searchtype=author&query=Tasche%2C+M">Manfred Tasche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17759" title="Abstract">arXiv:2306.17759</a> (replaced) [<a href="/pdf/2306.17759" title="Download PDF">pdf</a>, <a href="/format/2306.17759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Shaped Transformer: Attention Models in the Infinite Depth-and-Width  Limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Noci%2C+L">Lorenzo Noci</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+C">Chuning Li</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+M+B">Mufan Bill Li</a>, 
<a href="/search/stat?searchtype=author&query=He%2C+B">Bobby He</a>, 
<a href="/search/stat?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>, 
<a href="/search/stat?searchtype=author&query=Maddison%2C+C">Chris Maddison</a>, 
<a href="/search/stat?searchtype=author&query=Roy%2C+D+M">Daniel M. Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00371" title="Abstract">arXiv:2307.00371</a> (replaced) [<a href="/pdf/2307.00371" title="Download PDF">pdf</a>, <a href="/format/2307.00371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Content-enhanced Mask Transformer for Domain Generalized  Urban-Scene Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+Q">Qi Bi</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shaodi You</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures. Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00553" title="Abstract">arXiv:2307.00553</a> (replaced) [<a href="/pdf/2307.00553" title="Download PDF">pdf</a>, <a href="/format/2307.00553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial-label Learning with Mixed Closed-set and Open-set  Out-of-candidate Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shuo He</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guowu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01343" title="Abstract">arXiv:2307.01343</a> (replaced) [<a href="/pdf/2307.01343" title="Download PDF">pdf</a>, <a href="/format/2307.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HPC-driven computational reproducibility in numerical relativity codes:  A use case study with IllinoisGRMHD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/gr-qc?searchtype=author&query=Luo%2C+Y">Yufeng Luo</a>, 
<a href="/search/gr-qc?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/gr-qc?searchtype=author&query=Haas%2C+R">Roland Haas</a>, 
<a href="/search/gr-qc?searchtype=author&query=Etienne%2C+Z+B">Zachariah B. Etienne</a>, 
<a href="/search/gr-qc?searchtype=author&query=Allen%2C+G">Gabrielle Allen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, accepted to Classical and Quantum Gravity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Relativity and Quantum Cosmology (gr-qc)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02028" title="Abstract">arXiv:2307.02028</a> (replaced) [<a href="/pdf/2307.02028" title="Download PDF">pdf</a>, <a href="/format/2307.02028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wornow%2C+M">Michael Wornow</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+R">Rahul Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Steinberg%2C+E">Ethan Steinberg</a>, 
<a href="/search/cs?searchtype=author&query=Fries%2C+J+A">Jason A. Fries</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N+H">Nigam H. Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03503" title="Abstract">arXiv:2307.03503</a> (replaced) [<a href="/pdf/2307.03503" title="Download PDF">pdf</a>, <a href="/format/2307.03503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A variant of the Raviart-Thomas method to handle smooth domains with  straight-edged triangles. Part I -- Well-posedness results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertrand%2C+F">Fleurianne Bertrand</a>, 
<a href="/search/math?searchtype=author&query=Ruas%2C+V">Vitoriano Ruas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, two figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04057" title="Abstract">arXiv:2307.04057</a> (replaced) [<a href="/pdf/2307.04057" title="Download PDF">pdf</a>, <a href="/format/2307.04057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional Attention as a Mixture of Continuous Word Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wibisono%2C+K+C">Kevin Christian Wibisono</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages. Published in UAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05695" title="Abstract">arXiv:2307.05695</a> (replaced) [<a href="/pdf/2307.05695" title="Download PDF">pdf</a>, <a href="/format/2307.05695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLoRA: High-Rank Training Through Low-Rank Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lialin%2C+V">Vladislav Lialin</a>, 
<a href="/search/cs?searchtype=author&query=Shivagunde%2C+N">Namrata Shivagunde</a>, 
<a href="/search/cs?searchtype=author&query=Muckatira%2C+S">Sherin Muckatira</a>, 
<a href="/search/cs?searchtype=author&query=Rumshisky%2C+A">Anna Rumshisky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06483" title="Abstract">arXiv:2307.06483</a> (replaced) [<a href="/pdf/2307.06483" title="Download PDF">pdf</a>, <a href="/format/2307.06483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misclassification in Automated Content Analysis Causes Bias in  Regression. Can We Fix It? Yes We Can!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=TeBlunthuis%2C+N">Nathan TeBlunthuis</a>, 
<a href="/search/cs?searchtype=author&query=Hase%2C+V">Valerie Hase</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chung-Hong Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 66 page, 43 Figures. Accepted for publication in Communication Methods &amp; Measures. Top Paper Award from the 2023 Annual Meeting of The International Communication Association Computational Methods Division
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06751" title="Abstract">arXiv:2307.06751</a> (replaced) [<a href="/pdf/2307.06751" title="Download PDF">pdf</a>, <a href="/format/2307.06751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watch Where You Head: A View-biased Domain Gap in Gait Recognition and  Unsupervised Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habib%2C+G">Gavriel Habib</a>, 
<a href="/search/cs?searchtype=author&query=Barzilay%2C+N">Noa Barzilay</a>, 
<a href="/search/cs?searchtype=author&query=Shimshi%2C+O">Or Shimshi</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Ari%2C+R">Rami Ben-Ari</a>, 
<a href="/search/cs?searchtype=author&query=Darshan%2C+N">Nir Darshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07085" title="Abstract">arXiv:2307.07085</a> (replaced) [<a href="/pdf/2307.07085" title="Download PDF">pdf</a>, <a href="/ps/2307.07085" title="Download PostScript">ps</a>, <a href="/format/2307.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-learned molecular mechanics force field for the simulation of  protein-ligand systems and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Takaba%2C+K">Kenichiro Takaba</a>, 
<a href="/search/physics?searchtype=author&query=Pulido%2C+I">Iv&#xe1;n Pulido</a>, 
<a href="/search/physics?searchtype=author&query=Behara%2C+P+K">Pavan Kumar Behara</a>, 
<a href="/search/physics?searchtype=author&query=Cavender%2C+C+E">Chapin E. Cavender</a>, 
<a href="/search/physics?searchtype=author&query=Friedman%2C+A+J">Anika J. Friedman</a>, 
<a href="/search/physics?searchtype=author&query=Henry%2C+M+M">Michael M. Henry</a>, 
<a href="/search/physics?searchtype=author&query=Opeskin%2C+H+M">Hugo MacDermott Opeskin</a>, 
<a href="/search/physics?searchtype=author&query=Iacovella%2C+C+R">Christopher R. Iacovella</a>, 
<a href="/search/physics?searchtype=author&query=Nagle%2C+A+M">Arnav M. Nagle</a>, 
<a href="/search/physics?searchtype=author&query=Payne%2C+A+M">Alexander Matthew Payne</a>, 
<a href="/search/physics?searchtype=author&query=Shirts%2C+M+R">Michael R. Shirts</a>, 
<a href="/search/physics?searchtype=author&query=Mobley%2C+D+L">David L. Mobley</a>, 
<a href="/search/physics?searchtype=author&query=Chodera%2C+J+D">John D. Chodera</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuanqing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07976" title="Abstract">arXiv:2307.07976</a> (replaced) [<a href="/pdf/2307.07976" title="Download PDF">pdf</a>, <a href="/format/2307.07976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HRHD-HK: A benchmark dataset of high-rise and high-density urban scenes  for 3D semantic segmentation of photogrammetric point clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Maosu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yijie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+A+G+O">Anthony G.O. Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+F">Fan Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been published in the Proceedings of 2023 IEEE International Conference on Image Processing Challenges and Workshops
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 2023 IEEE International Conference on Image
  Processing Challenges and Workshops, 3714-3718. IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08863" title="Abstract">arXiv:2307.08863</a> (replaced) [<a href="/pdf/2307.08863" title="Download PDF">pdf</a>, <a href="/format/2307.08863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Value Learning: a General Framework for Learning with Learning  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooijmans%2C+T">Tim Cooijmans</a>, 
<a href="/search/cs?searchtype=author&query=Aghajohari%2C+M">Milad Aghajohari</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08875" title="Abstract">arXiv:2307.08875</a> (replaced) [<a href="/pdf/2307.08875" title="Download PDF">pdf</a>, <a href="/format/2307.08875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Actor-Critic for Robust Reinforcement Learning with Function  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruida Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Min Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kalathil%2C+D">Dileep Kalathil</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P+R">P. R. Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chao Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08939" title="Abstract">arXiv:2307.08939</a> (replaced) [<a href="/pdf/2307.08939" title="Download PDF">pdf</a>, <a href="/format/2307.08939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runtime Stealthy Perception Attacks against DNN-based Adaptive Cruise  Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xugui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kouzel%2C+M">Maxfield Kouzel</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haotian Ren</a>, 
<a href="/search/cs?searchtype=author&query=McCarty%2C+M">Morgan McCarty</a>, 
<a href="/search/cs?searchtype=author&query=Nita-Rotaru%2C+C">Cristina Nita-Rotaru</a>, 
<a href="/search/cs?searchtype=author&query=Alemzadeh%2C+H">Homa Alemzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 21 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09007" title="Abstract">arXiv:2307.09007</a> (replaced) [<a href="/pdf/2307.09007" title="Download PDF">pdf</a>, <a href="/format/2307.09007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the (In)Effectiveness of Large Language Models for Chinese Text  Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haojing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shirong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qingyu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09072" title="Abstract">arXiv:2307.09072</a> (replaced) [<a href="/pdf/2307.09072" title="Download PDF">pdf</a>, <a href="/format/2307.09072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Inference and Extrapolation via a Diffusion-inspired Temporal  Transformer Operator (DiTTO)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ovadia%2C+O">Oded Ovadia</a>, 
<a href="/search/cs?searchtype=author&query=Oommen%2C+V">Vivek Oommen</a>, 
<a href="/search/cs?searchtype=author&query=Kahana%2C+A">Adar Kahana</a>, 
<a href="/search/cs?searchtype=author&query=Peyvan%2C+A">Ahmad Peyvan</a>, 
<a href="/search/cs?searchtype=author&query=Turkel%2C+E">Eli Turkel</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09368" title="Abstract">arXiv:2307.09368</a> (replaced) [<a href="/pdf/2307.09368" title="Download PDF">pdf</a>, <a href="/format/2307.09368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-driven Talking Face Generation by Overcoming Unintended  Information Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yaman%2C+D">Dogucan Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Eyiokur%2C+F+I">Fevziye Irem Eyiokur</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4rmann%2C+L">Leonard B&#xe4;rmann</a>, 
<a href="/search/cs?searchtype=author&query=Ekenel%2C+H+K">Hazim Kemal Ekenel</a>, 
<a href="/search/cs?searchtype=author&query=Waibel%2C+A">Alexander Waibel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10907" title="Abstract">arXiv:2307.10907</a> (replaced) [<a href="/pdf/2307.10907" title="Download PDF">pdf</a>, <a href="/format/2307.10907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Entropy and Reconstruction in Multi-View Self-Supervised  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-G%C3%A1lvez%2C+B">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, 
<a href="/search/cs?searchtype=author&query=Blaas%2C+A">Arno Blaas</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+P">Pau Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Goli%C5%84ski%2C+A">Adam Goli&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Suau%2C+X">Xavier Suau</a>, 
<a href="/search/cs?searchtype=author&query=Ramapuram%2C+J">Jason Ramapuram</a>, 
<a href="/search/cs?searchtype=author&query=Busbridge%2C+D">Dan Busbridge</a>, 
<a href="/search/cs?searchtype=author&query=Zappella%2C+L">Luca Zappella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages: 9 of main text, 2 of references, and 7 of supplementary material [Updated typo in page 6 (Section 3.2)]. Appears in the proceedings of ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11730" title="Abstract">arXiv:2307.11730</a> (replaced) [<a href="/pdf/2307.11730" title="Download PDF">pdf</a>, <a href="/format/2307.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Communications Threats in Decentralized Federated Learning  through Moving Target Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beltr%C3%A1n%2C+E+T+M">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+P+M+S">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/cs?searchtype=author&query=Bovet%2C+G">G&#xe9;r&#xf4;me Bovet</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+M+G">Manuel Gil P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12267" title="Abstract">arXiv:2307.12267</a> (replaced) [<a href="/pdf/2307.12267" title="Download PDF">pdf</a>, <a href="/format/2307.12267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid  Essay in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zijie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+L">Lele Sha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanliang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an AAAI 2024 full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14217" title="Abstract">arXiv:2307.14217</a> (replaced) [<a href="/pdf/2307.14217" title="Download PDF">pdf</a>, <a href="/ps/2307.14217" title="Download PostScript">ps</a>, <a href="/format/2307.14217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimates for finite element discretizations of the instationary  Navier-Stokes equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vexler%2C+B">Boris Vexler</a>, 
<a href="/search/math?searchtype=author&query=Wagner%2C+J">Jakob Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> revised version; added some detail to proofs; reordered some results for better readability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15967" title="Abstract">arXiv:2307.15967</a> (replaced) [<a href="/pdf/2307.15967" title="Download PDF">pdf</a>, <a href="/format/2307.15967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Condensation for Inductive Node Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yilong Zang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE 40th International Conference on Data Engineering (ICDE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16230" title="Abstract">arXiv:2307.16230</a> (replaced) [<a href="/pdf/2307.16230" title="Download PDF">pdf</a>, <a href="/format/2307.16230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Unforgeable Publicly Verifiable Watermark for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shu&#x27;ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00428" title="Abstract">arXiv:2308.00428</a> (replaced) [<a href="/pdf/2308.00428" title="Download PDF">pdf</a>, <a href="/format/2308.00428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Feature Learning Using Co-Tuplet Loss for Offline Handwritten  Signature Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fu-Hsien Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hsin-Min Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01654" title="Abstract">arXiv:2308.01654</a> (replaced) [<a href="/pdf/2308.01654" title="Download PDF">pdf</a>, <a href="/format/2308.01654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Safe Real-Time Motion Planning Framework for Autonomous  Driving Systems: An MPPI Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Testouri%2C+M">Mehdi Testouri</a>, 
<a href="/search/cs?searchtype=author&query=Elghazaly%2C+G">Gamal Elghazaly</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+R">Raphael Frank</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01672" title="Abstract">arXiv:2308.01672</a> (replaced) [<a href="/pdf/2308.01672" title="Download PDF">pdf</a>, <a href="/format/2308.01672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Floorplet: Performance-aware Floorplan Framework for Chiplet Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Su Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sangiovanni-Vincentelli%2C+A+L">Alberto L. Sangiovanni-Vincentelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by TCAD, 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02080" title="Abstract">arXiv:2308.02080</a> (replaced) [<a href="/pdf/2308.02080" title="Download PDF">pdf</a>, <a href="/format/2308.02080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality Guided Disentanglement for Cross-Platform Hate Speech  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheth%2C+P">Paras Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Kumarage%2C+T">Tharindu Kumarage</a>, 
<a href="/search/cs?searchtype=author&query=Moraffah%2C+R">Raha Moraffah</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WSDM'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02910" title="Abstract">arXiv:2308.02910</a> (replaced) [<a href="/pdf/2308.02910" title="Download PDF">pdf</a>, <a href="/ps/2308.02910" title="Download PostScript">ps</a>, <a href="/format/2308.02910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 5G Quality of Service in Bangkok and Metropolitan Areas: Revisiting BTS  Skytrain Station Areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daengsi%2C+T">Therdpong Daengsi</a>, 
<a href="/search/cs?searchtype=author&query=Sriamorntrakul%2C+P">Pakkasit Sriamorntrakul</a>, 
<a href="/search/cs?searchtype=author&query=Chatchalermpun%2C+S">Surachai Chatchalermpun</a>, 
<a href="/search/cs?searchtype=author&query=Phanrattanachai%2C+K">Kritphon Phanrattanachai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03230" title="Abstract">arXiv:2308.03230</a> (replaced) [<a href="/pdf/2308.03230" title="Download PDF">pdf</a>, <a href="/ps/2308.03230" title="Download PostScript">ps</a>, <a href="/format/2308.03230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tractability of approximation by general shallow networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mhaskar%2C+H">Hrushikesh Mhaskar</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+T">Tong Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03658" title="Abstract">arXiv:2308.03658</a> (replaced) [<a href="/pdf/2308.03658" title="Download PDF">pdf</a>, <a href="/format/2308.03658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-Oriented Deep Space Communications For Unmanned Space  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+X">Xinran Fang</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yunfei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+N">Ning Ge</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+G">Gan Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04080" title="Abstract">arXiv:2308.04080</a> (replaced) [<a href="/pdf/2308.04080" title="Download PDF">pdf</a>, <a href="/format/2308.04080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gorilla: Safe Permissionless Byzantine Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Youer Pu</a> (1), 
<a href="/search/cs?searchtype=author&query=Farahbakhsh%2C+A">Ali Farahbakhsh</a> (1), 
<a href="/search/cs?searchtype=author&query=Alvisi%2C+L">Lorenzo Alvisi</a> (1), 
<a href="/search/cs?searchtype=author&query=Eyal%2C+I">Ittay Eyal</a> (2) ((1) Cornell University, (2) The Technion)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 3 figures, published in the International Symposium on Distributed Computing (DISC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04887" title="Abstract">arXiv:2308.04887</a> (replaced) [<a href="/pdf/2308.04887" title="Download PDF">pdf</a>, <a href="/format/2308.04887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted and Troublesome: Tracking and Advertising on Children&#x27;s  Websites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moti%2C+Z">Zahra Moti</a>, 
<a href="/search/cs?searchtype=author&query=Senol%2C+A">Asuman Senol</a>, 
<a href="/search/cs?searchtype=author&query=Bostani%2C+H">Hamid Bostani</a>, 
<a href="/search/cs?searchtype=author&query=Borgesius%2C+F+Z">Frederik Zuiderveen Borgesius</a>, 
<a href="/search/cs?searchtype=author&query=Moonsamy%2C+V">Veelasha Moonsamy</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+A">Arunesh Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Acar%2C+G">Gunes Acar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at 45th IEEE Symposium on Security and Privacy, May 20-23 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06399" title="Abstract">arXiv:2308.06399</a> (replaced) [<a href="/pdf/2308.06399" title="Download PDF">pdf</a>, <a href="/format/2308.06399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via  Mixed-Effect Models and Hierarchical Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Valleggi%2C+L">Lorenzo Valleggi</a>, 
<a href="/search/stat?searchtype=author&query=Scutari%2C+M">Marco Scutari</a>, 
<a href="/search/stat?searchtype=author&query=Stefanini%2C+F+M">Federico Mattia Stefanini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06838" title="Abstract">arXiv:2308.06838</a> (replaced) [<a href="/pdf/2308.06838" title="Download PDF">pdf</a>, <a href="/format/2308.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weisfeiler and Lehman Go Paths: Learning Topological Features via Path  Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+Q">Quang Truong</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+P">Peter Chin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07779" title="Abstract">arXiv:2308.07779</a> (replaced) [<a href="/pdf/2308.07779" title="Download PDF">pdf</a>, <a href="/format/2308.07779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do We Fully Understand Students&#x27; Knowledge States? Identifying and  Mitigating Answer Bias in Knowledge Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Chaoran Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hebo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yumo Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Meng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuling Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08479" title="Abstract">arXiv:2308.08479</a> (replaced) [<a href="/pdf/2308.08479" title="Download PDF">pdf</a>, <a href="/format/2308.08479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeDoDe: Detect, Don&#x27;t Describe -- Describe, Don&#x27;t Detect for Local  Feature Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edstedt%2C+J">Johan Edstedt</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 3DV 2024 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09300" title="Abstract">arXiv:2308.09300</a> (replaced) [<a href="/pdf/2308.09300" title="Download PDF">pdf</a>, <a href="/format/2308.09300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by  Connecting Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pascual%2C+S">Santiago Pascual</a>, 
<a href="/search/cs?searchtype=author&query=Cartwright%2C+R">Richard Cartwright</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. Demo page: <a href="https://v2a-mapper.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09895" title="Abstract">arXiv:2308.09895</a> (replaced) [<a href="/pdf/2308.09895" title="Download PDF">pdf</a>, <a href="/format/2308.09895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Gouwar%2C+J">John Gouwar</a>, 
<a href="/search/cs?searchtype=author&query=Lucchetti%2C+F">Francesca Lucchetti</a>, 
<a href="/search/cs?searchtype=author&query=Schlesinger%2C+C">Claire Schlesinger</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+M">Michael Greenberg</a>, 
<a href="/search/cs?searchtype=author&query=Jangda%2C+A">Abhinav Jangda</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11070" title="Abstract">arXiv:2308.11070</a> (replaced) [<a href="/pdf/2308.11070" title="Download PDF">pdf</a>, <a href="/format/2308.11070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal-Distributed Backdoor Attack Against Video Based Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Songhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ruiquan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gowda%2C+M">Mahanth Gowda</a>, 
<a href="/search/cs?searchtype=author&query=Kesidis%2C+G">George Kesidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12050" title="Abstract">arXiv:2308.12050</a> (replaced) [<a href="/pdf/2308.12050" title="Download PDF">pdf</a>, <a href="/format/2308.12050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Language Models with Offline Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Li Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">June Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chandler Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12060" title="Abstract">arXiv:2308.12060</a> (replaced) [<a href="/pdf/2308.12060" title="Download PDF">pdf</a>, <a href="/format/2308.12060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Sunqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhichao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bowen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24 in December 2023; Knowledge Base Question Answering; Large Language Model; Data Generation; Few-Shot &amp; Zero-Shot
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12609" title="Abstract">arXiv:2308.12609</a> (replaced) [<a href="/pdf/2308.12609" title="Download PDF">pdf</a>, <a href="/format/2308.12609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Video Contextual Knowledge Exploration and Exploitation for  Ambiguity Reduction in Weakly Supervised Temporal Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songchun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chunhui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TCSVT. 14 pages and 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13466" title="Abstract">arXiv:2308.13466</a> (replaced) [<a href="/pdf/2308.13466" title="Download PDF">pdf</a>, <a href="/format/2308.13466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Staleness-Alleviated Distributed GNN Training via Online  Dynamic-Embedding Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Z">Zheng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Do not distribute
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13794" title="Abstract">arXiv:2308.13794</a> (replaced) [<a href="/pdf/2308.13794" title="Download PDF">pdf</a>, <a href="/format/2308.13794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOGDet: Semantic-Occupancy Guided Multi-view 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jinming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+H">Hanchao Leng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yifang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Kun%2C+Y">Yu Kun</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13839" title="Abstract">arXiv:2308.13839</a> (replaced) [<a href="/pdf/2308.13839" title="Download PDF">pdf</a>, <a href="/format/2308.13839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Conflict Resolution Dataset Derived from Argoverse-2: Analysis of the  Safety and Efficiency Impacts of Autonomous Vehicles at Intersections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yiru Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Calvert%2C+S+C">Simeon C. Calvert</a>, 
<a href="/search/cs?searchtype=author&query=van+Lint%2C+J+W+C">J.W.C. van Lint</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14411" title="Abstract">arXiv:2308.14411</a> (replaced) [<a href="/pdf/2308.14411" title="Download PDF">pdf</a>, <a href="/ps/2308.14411" title="Download PostScript">ps</a>, <a href="/format/2308.14411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Community College Articulation Agreement Websites: Students&#x27; Suggestions  for New Academic Advising Software Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+V">David V. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Doroudi%2C+S">Shayan Doroudi</a>, 
<a href="/search/cs?searchtype=author&query=Epstein%2C+D+A">Daniel A. Epstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16139" title="Abstract">arXiv:2308.16139</a> (replaced) [<a href="/pdf/2308.16139" title="Download PDF">pdf</a>, <a href="/format/2308.16139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedShapeNet -- A Large-Scale Dataset of 3D Medical Shapes for Computer  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zongwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiancheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pepe%2C+A">Antonio Pepe</a>, 
<a href="/search/cs?searchtype=author&query=Gsaxner%2C+C">Christina Gsaxner</a>, 
<a href="/search/cs?searchtype=author&query=Luijten%2C+G">Gijs Luijten</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chongyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiezheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wodzinski%2C+M">Marek Wodzinski</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+P">Paul Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kangxian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yuan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ambigapathy%2C+N">Narmada Ambigapathy</a>, 
<a href="/search/cs?searchtype=author&query=Nasca%2C+E">Enrico Nasca</a>, 
<a href="/search/cs?searchtype=author&query=Solak%2C+N">Naida Solak</a>, 
<a href="/search/cs?searchtype=author&query=Melito%2C+G+M">Gian Marco Melito</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+D">Viet Duc Vu</a>, 
<a href="/search/cs?searchtype=author&query=Memon%2C+A+R">Afaque R. Memon</a>, 
<a href="/search/cs?searchtype=author&query=Schlachta%2C+C">Christopher Schlachta</a>, 
<a href="/search/cs?searchtype=author&query=De+Ribaupierre%2C+S">Sandrine De Ribaupierre</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Rajnikant Patel</a>, 
<a href="/search/cs?searchtype=author&query=Eagleson%2C+R">Roy Eagleson</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4chler%2C+H">Heinrich M&#xe4;chler</a>, 
<a href="/search/cs?searchtype=author&query=Kirschke%2C+J+S">Jan Stefan Kirschke</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Rosa%2C+E">Ezequiel de la Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Christ%2C+P+F">Patrick Ferdinand Christ</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H+B">Hongwei Bran Li</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+D+G">David G. Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Aizenberg%2C+M+R">Michele R. Aizenberg</a>, 
<a href="/search/cs?searchtype=author&query=Gatidis%2C+S">Sergios Gatidis</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCstner%2C+T">Thomas K&#xfc;stner</a>, 
<a href="/search/cs?searchtype=author&query=Shusharina%2C+N">Nadya Shusharina</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+N">Nicholas Heller</a>, 
<a href="/search/cs?searchtype=author&query=Andrearczyk%2C+V">Vincent Andrearczyk</a>, 
<a href="/search/cs?searchtype=author&query=Depeursinge%2C+A">Adrien Depeursinge</a>, 
<a href="/search/cs?searchtype=author&query=Hatt%2C+M">Mathieu Hatt</a>, 
<a href="/search/cs?searchtype=author&query=Sekuboyina%2C+A">Anjany Sekuboyina</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6ffler%2C+M">Maximilian L&#xf6;ffler</a>, 
<a href="/search/cs?searchtype=author&query=Liebl%2C+H">Hans Liebl</a>, 
<a href="/search/cs?searchtype=author&query=Dorent%2C+R">Reuben Dorent</a>, 
<a href="/search/cs?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/cs?searchtype=author&query=Shapey%2C+J">Jonathan Shapey</a>, 
<a href="/search/cs?searchtype=author&query=Kujawa%2C+A">Aaron Kujawa</a>, 
<a href="/search/cs?searchtype=author&query=Cornelissen%2C+S">Stefan Cornelissen</a>,  et al. (110 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16910" title="Abstract">arXiv:2308.16910</a> (replaced) [<a href="/pdf/2308.16910" title="Download PDF">pdf</a>, <a href="/format/2308.16910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Variational Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rojas%2C+S">Sergio Rojas</a>, 
<a href="/search/math?searchtype=author&query=Maczuga%2C+P">Pawe&#x142; Maczuga</a>, 
<a href="/search/math?searchtype=author&query=Mu%C3%B1oz-Matute%2C+J">Judit Mu&#xf1;oz-Matute</a>, 
<a href="/search/math?searchtype=author&query=Pardo%2C+D">David Pardo</a>, 
<a href="/search/math?searchtype=author&query=Paszynski%2C+M">Maciej Paszynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01627" title="Abstract">arXiv:2309.01627</a> (replaced) [<a href="/pdf/2309.01627" title="Download PDF">pdf</a>, <a href="/format/2309.01627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Consistent Deep Unfolding Network for Adaptive All-In-One Video  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuanshuo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingwen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yecong Wan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yuanjian Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01994" title="Abstract">arXiv:2309.01994</a> (replaced) [<a href="/pdf/2309.01994" title="Download PDF">pdf</a>, <a href="/format/2309.01994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud Control of Connected Vehicle under Bi-directional Time-varying  delay: An Application of Predictor-observer Structured Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+J">Ji-An Pan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Q">Qing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+K">Keqiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chunying Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02340" title="Abstract">arXiv:2309.02340</a> (replaced) [<a href="/pdf/2309.02340" title="Download PDF">pdf</a>, <a href="/format/2309.02340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Infinite-Size Textures using GANs with Patch-by-Patch  Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdellatif%2C+A">Alhasan Abdellatif</a>, 
<a href="/search/cs?searchtype=author&query=Elsheikh%2C+A+H">Ahmed H. Elsheikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02356" title="Abstract">arXiv:2309.02356</a> (replaced) [<a href="/pdf/2309.02356" title="Download PDF">pdf</a>, <a href="/format/2309.02356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEP -- Towards Structured Scene-Text Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Bordils%2C+S">Sergi Garcia-Bordils</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>, 
<a href="/search/cs?searchtype=author&query=Rusi%C3%B1ol%2C+M">Mar&#xe7;al Rusi&#xf1;ol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02464" title="Abstract">arXiv:2309.02464</a> (replaced) [<a href="/pdf/2309.02464" title="Download PDF">pdf</a>, <a href="/format/2309.02464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deployment of Real-Time Network Traffic Analysis using GraphBLAS  Hypersparse Matrices and D4M Associative Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Michael Jones</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>, 
<a href="/search/cs?searchtype=author&query=Prout%2C+A">Andrew Prout</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+T">Timothy Davis</a>, 
<a href="/search/cs?searchtype=author&query=Arcand%2C+W">William Arcand</a>, 
<a href="/search/cs?searchtype=author&query=Bestor%2C+D">David Bestor</a>, 
<a href="/search/cs?searchtype=author&query=Bergeron%2C+W">William Bergeron</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+C">Chansup Byun</a>, 
<a href="/search/cs?searchtype=author&query=Gadepally%2C+V">Vijay Gadepally</a>, 
<a href="/search/cs?searchtype=author&query=Houle%2C+M">Micheal Houle</a>, 
<a href="/search/cs?searchtype=author&query=Hubbell%2C+M">Matthew Hubbell</a>, 
<a href="/search/cs?searchtype=author&query=Jananthan%2C+H">Hayden Jananthan</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+A">Anna Klein</a>, 
<a href="/search/cs?searchtype=author&query=Milechin%2C+L">Lauren Milechin</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+G">Guillermo Morales</a>, 
<a href="/search/cs?searchtype=author&query=Mullen%2C+J">Julie Mullen</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Ritesh Patel</a>, 
<a href="/search/cs?searchtype=author&query=Pisharody%2C+S">Sandeep Pisharody</a>, 
<a href="/search/cs?searchtype=author&query=Reuther%2C+A">Albert Reuther</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+A">Antonio Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Samsi%2C+S">Siddharth Samsi</a>, 
<a href="/search/cs?searchtype=author&query=Yee%2C+C">Charles Yee</a>, 
<a href="/search/cs?searchtype=author&query=Michaleas%2C+P">Peter Michaleas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE HPEC, 8 pages, 8 figures, 1 table, 69 references. arXiv admin note: text overlap with <a href="/abs/2203.13934">arXiv:2203.13934</a>. text overlap with <a href="/abs/2309.01806">arXiv:2309.01806</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02521" title="Abstract">arXiv:2309.02521</a> (replaced) [<a href="/pdf/2309.02521" title="Download PDF">pdf</a>, <a href="/format/2309.02521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of CPU and GPU Profiling for Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gyawali%2C+D">Dipesh Gyawali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03038" title="Abstract">arXiv:2309.03038</a> (replaced) [<a href="/pdf/2309.03038" title="Download PDF">pdf</a>, <a href="/format/2309.03038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cellular Wireless Networks in the Upper Mid-Band
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seongjoon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mezzavilla%2C+M">Marco Mezzavilla</a>, 
<a href="/search/cs?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>, 
<a href="/search/cs?searchtype=author&query=Madanayake%2C+A">Arjuna Madanayake</a>, 
<a href="/search/cs?searchtype=author&query=Venkatakrishnan%2C+S+B">Satheesh Bojja Venkatakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Hellbourg%2C+G">Gregory Hellbourg</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+M">Monisha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hamed Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Dhananjay%2C+A">Aditya Dhananjay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03407" title="Abstract">arXiv:2309.03407</a> (replaced) [<a href="/pdf/2309.03407" title="Download PDF">pdf</a>, <a href="/format/2309.03407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Josephson Parametric Oscillator-Based Ising Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Razmkhah%2C+S">Sasan Razmkhah</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kamal%2C+M">Mehdi Kamal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yoshikawa%2C+N">Nobuyuki Yoshikawa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pedram%2C+M">Massoud Pedram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures, 31 references. Accepted by PRB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Superconductivity (cond-mat.supr-con); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05961" title="Abstract">arXiv:2309.05961</a> (replaced) [<a href="/pdf/2309.05961" title="Download PDF">pdf</a>, <a href="/format/2309.05961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering  Trends across Diverse Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Agnik Saha</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07544" title="Abstract">arXiv:2309.07544</a> (replaced) [<a href="/pdf/2309.07544" title="Download PDF">pdf</a>, <a href="/format/2309.07544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VerilogEval: Evaluating Large Language Models for Verilog Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pinckney%2C+N">Nathaniel Pinckney</a>, 
<a href="/search/cs?searchtype=author&query=Khailany%2C+B">Brucek Khailany</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoxing Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCAD 2023 Invited Paper. Prior version contained errors in the numbers reported for gpt-4 in Table II
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08788" title="Abstract">arXiv:2309.08788</a> (replaced) [<a href="/pdf/2309.08788" title="Download PDF">pdf</a>, <a href="/ps/2309.08788" title="Download PostScript">ps</a>, <a href="/format/2309.08788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioinspiredLLM: Conversational Large Language Model for the Mechanics of  Biological and Bio-inspired Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Luu%2C+R+K">Rachel K. Luu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Buehler%2C+M+J">Markus J. Buehler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Soft Condensed Matter (cond-mat.soft); Machine Learning (cs.LG); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08836" title="Abstract">arXiv:2309.08836</a> (replaced) [<a href="/pdf/2309.08836" title="Download PDF">pdf</a>, <a href="/format/2309.08836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias and Fairness in Chatbots: An Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jintang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun-Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chengwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jonghye Woo</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+C+-+J">C.-C. Jay Kuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09043" title="Abstract">arXiv:2309.09043</a> (replaced) [<a href="/pdf/2309.09043" title="Download PDF">pdf</a>, <a href="/format/2309.09043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward Invariance in Neural Network Controlled Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Harapanahalli%2C+A">Akash Harapanahalli</a>, 
<a href="/search/eess?searchtype=author&query=Jafarpour%2C+S">Saber Jafarpour</a>, 
<a href="/search/eess?searchtype=author&query=Coogan%2C+S">Samuel Coogan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09431" title="Abstract">arXiv:2309.09431</a> (replaced) [<a href="/pdf/2309.09431" title="Download PDF">pdf</a>, <a href="/format/2309.09431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised  Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Shaheer Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Haghighat%2C+M">Maryam Haghighat</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+T">Tharindu Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+S">Sridha Sridharan</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Geoscience and Remote Sensing in December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12056" title="Abstract">arXiv:2309.12056</a> (replaced) [<a href="/e-print/2309.12056" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BELT:Bootstrapping Electroencephalography-to-Language Decoding and  Zero-Shot Sentiment Classification by Natural Language Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinzhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yu-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We decided to redraw the manuscript because of the multi-error in the paper due to poor writing and inspection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13230" title="Abstract">arXiv:2309.13230</a> (replaced) [<a href="/pdf/2309.13230" title="Download PDF">pdf</a>, <a href="/format/2309.13230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unify word-level and span-level tasks: NJUNLP&#x27;s Participation for the  WMT2023 Quality Estimation Shared Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhejian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shimin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WMT2023 System Paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> https://aclanthology.org/2023.wmt-1.71
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13237" title="Abstract">arXiv:2309.13237</a> (replaced) [<a href="/pdf/2309.13237" title="Download PDF">pdf</a>, <a href="/format/2309.13237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+T">Tao Pu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hefeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yongyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at T-IP, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13550" title="Abstract">arXiv:2309.13550</a> (replaced) [<a href="/pdf/2309.13550" title="Download PDF">pdf</a>, <a href="/format/2309.13550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-AI: A Controllable &amp; Interpretable AI System for Decoding  Radiologists&#x27; Intense Focus for Accurate CXR Diagnoses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T+T">Trong Thang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Brecheisen%2C+J">Jacob Brecheisen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13775" title="Abstract">arXiv:2309.13775</a> (replaced) [<a href="/pdf/2309.13775" title="Download PDF">pdf</a>, <a href="/format/2309.13775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rashomon Importance Distribution: Getting RID of Unstable, Single  Model-based Variable Importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donnelly%2C+J">Jon Donnelly</a>, 
<a href="/search/cs?searchtype=author&query=Katta%2C+S">Srikar Katta</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Browne%2C+E+P">Edward P. Browne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023 as a spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14293" title="Abstract">arXiv:2309.14293</a> (replaced) [<a href="/pdf/2309.14293" title="Download PDF">pdf</a>, <a href="/format/2309.14293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAS-NeRF: Generative Neural Architecture Search for Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+S">Saeejith Nair</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shafiee%2C+M+J">Mohammad Javad Shafiee</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14405" title="Abstract">arXiv:2309.14405</a> (replaced) [<a href="/pdf/2309.14405" title="Download PDF">pdf</a>, <a href="/format/2309.14405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Audio and Speech Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A+H">Alexander H. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hongyin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Karlinsky%2C+L">Leonid Karlinsky</a>, 
<a href="/search/cs?searchtype=author&query=Glass%2C+J">James Glass</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU 2023. Code, dataset, and pretrained models are at <a href="https://github.com/yuangongnd/ltu.">this https URL</a> Interactive demo at <a href="https://huggingface.co/spaces/yuangongfdu/ltu-2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14482" title="Abstract">arXiv:2309.14482</a> (replaced) [<a href="/pdf/2309.14482" title="Download PDF">pdf</a>, <a href="/format/2309.14482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogGPT: Log Anomaly Detection via GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuhan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Trabelsi%2C+M">Mohamed Trabelsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15127" title="Abstract">arXiv:2309.15127</a> (replaced) [<a href="/pdf/2309.15127" title="Download PDF">pdf</a>, <a href="/format/2309.15127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grad DFT: a software library for machine learning enhanced density  functional theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Casares%2C+P+A+M">Pablo A. M. Casares</a>, 
<a href="/search/physics?searchtype=author&query=Baker%2C+J+S">Jack S. Baker</a>, 
<a href="/search/physics?searchtype=author&query=Medvidovic%2C+M">Matija Medvidovic</a>, 
<a href="/search/physics?searchtype=author&query=Reis%2C+R+d">Roberto dos Reis</a>, 
<a href="/search/physics?searchtype=author&query=Arrazola%2C+J+M">Juan Miguel Arrazola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures. The following article has been submitted to the Journal of Chemical Physics. After it is published, it will be found at <a href="https://publishing.aip.org/resources/librarians/products/journals/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15214" title="Abstract">arXiv:2309.15214</a> (replaced) [<a href="/pdf/2309.15214" title="Download PDF">pdf</a>, <a href="/format/2309.15214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Diffusion Modeling for Km-scale Atmospheric Downscaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mardani%2C+M">Morteza Mardani</a>, 
<a href="/search/cs?searchtype=author&query=Brenowitz%2C+N">Noah Brenowitz</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+Y">Yair Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+J">Jaideep Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chieh-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Chin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/cs?searchtype=author&query=Kashinath%2C+K">Karthik Kashinath</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Pritchard%2C+M">Mike Pritchard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15269" title="Abstract">arXiv:2309.15269</a> (replaced) [<a href="/pdf/2309.15269" title="Download PDF">pdf</a>, <a href="/ps/2309.15269" title="Download PostScript">ps</a>, <a href="/format/2309.15269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Foundations of Community Rating by a Private Monopolist  Insurer: Framework, Regulation, and Numerical Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Braouezec%2C+Y">Yann Braouezec</a>, 
<a href="/search/econ?searchtype=author&query=Cagnol%2C+J">John Cagnol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The key findings haven't undergone any modifications. A handful of typos have been corrected, and the presentation has been enhanced for improved clarity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15593" title="Abstract">arXiv:2309.15593</a> (replaced) [<a href="/pdf/2309.15593" title="Download PDF">pdf</a>, <a href="/format/2309.15593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exciton-Polariton Condensates: A Fourier Neural Operator Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sathujoda%2C+S+T">Surya T. Sathujoda</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gandhi%2C+K">Kanishk Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Gases (cond-mat.quant-gas)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15654" title="Abstract">arXiv:2309.15654</a> (replaced) [<a href="/pdf/2309.15654" title="Download PDF">pdf</a>, <a href="/ps/2309.15654" title="Download PostScript">ps</a>, <a href="/format/2309.15654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Resilience Problems via Valued Constraint Satisfaction  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bodirsky%2C+M">Manuel Bodirsky</a>, 
<a href="/search/math?searchtype=author&query=Semani%C5%A1inov%C3%A1%2C+%C5%BD">&#x17d;aneta Semani&#x161;inov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Lutz%2C+C">Carsten Lutz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Computational Complexity (cs.CC); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15726" title="Abstract">arXiv:2309.15726</a> (replaced) [<a href="/pdf/2309.15726" title="Download PDF">pdf</a>, <a href="/format/2309.15726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factorized Diffusion Architectures for Unsupervised Image Generation and  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Maire%2C+M">Michael Maire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16066" title="Abstract">arXiv:2309.16066</a> (replaced) [<a href="/pdf/2309.16066" title="Download PDF">pdf</a>, <a href="/format/2309.16066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Augmentation Method for Medical Landmark Detection in Hip  Radiograph Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y">Yehyun Suh</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+P">Peter Chan</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J+R">J.Ryan Martin</a>, 
<a href="/search/cs?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00428" title="Abstract">arXiv:2310.00428</a> (replaced) [<a href="/pdf/2310.00428" title="Download PDF">pdf</a>, <a href="/ps/2310.00428" title="Download PostScript">ps</a>, <a href="/format/2310.00428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First Principles of Big Memory Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yu Hua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00704" title="Abstract">arXiv:2310.00704</a> (replaced) [<a href="/pdf/2310.00704" title="Download PDF">pdf</a>, <a href="/format/2310.00704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniAudio: An Audio Foundation Model Toward Universal Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00752" title="Abstract">arXiv:2310.00752</a> (replaced) [<a href="/pdf/2310.00752" title="Download PDF">pdf</a>, <a href="/format/2310.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIGERScore: Towards Building Explainable Metric for All Text Generation  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yishan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01770" title="Abstract">arXiv:2310.01770</a> (replaced) [<a href="/pdf/2310.01770" title="Download PDF">pdf</a>, <a href="/format/2310.01770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple connection from loss flatness to compressed representations in  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Recanatesi%2C+S">Stefano Recanatesi</a>, 
<a href="/search/cs?searchtype=author&query=Shea-Brown%2C+E">Eric Shea-Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02003" title="Abstract">arXiv:2310.02003</a> (replaced) [<a href="/pdf/2310.02003" title="Download PDF">pdf</a>, <a href="/format/2310.02003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L2MAC: Large Language Model Automatic Computer for Unbounded Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holt%2C+S">Samuel Holt</a>, 
<a href="/search/cs?searchtype=author&query=Luyten%2C+M+R">Max Ruiz Luyten</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright 2023 by the author(s)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02854" title="Abstract">arXiv:2310.02854</a> (replaced) [<a href="/pdf/2310.02854" title="Download PDF">pdf</a>, <a href="/format/2310.02854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Domain Causal Representation Learning via Weak Distributional  Invariances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+K">Kartik Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Mansouri%2C+A">Amin Mansouri</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03374" title="Abstract">arXiv:2310.03374</a> (replaced) [<a href="/pdf/2310.03374" title="Download PDF">pdf</a>, <a href="/format/2310.03374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Optimizer for Planar Soft-Growing Robot Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stroppa%2C+F">Fabio Stroppa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 15 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> F. Stroppa. Design Optimizer for Planar Soft-Growing Robot
  Manipulators. In Elsevier Engineering Applications of Artificial
  Intelligence, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03494" title="Abstract">arXiv:2310.03494</a> (replaced) [<a href="/pdf/2310.03494" title="Download PDF">pdf</a>, <a href="/format/2310.03494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How the level sampling process impacts zero-shot generalisation in deep  reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcin%2C+S">Samuel Garcin</a>, 
<a href="/search/cs?searchtype=author&query=Doran%2C+J">James Doran</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shangmin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+C+G">Christopher G. Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+S+V">Stefano V. Albrecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review, 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03668" title="Abstract">arXiv:2310.03668</a> (replaced) [<a href="/pdf/2310.03668" title="Download PDF">pdf</a>, <a href="/format/2310.03668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sainz%2C+O">Oscar Sainz</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Ferrero%2C+I">Iker Garc&#xed;a-Ferrero</a>, 
<a href="/search/cs?searchtype=author&query=Agerri%2C+R">Rodrigo Agerri</a>, 
<a href="/search/cs?searchtype=author&query=de+Lacalle%2C+O+L">Oier Lopez de Lacalle</a>, 
<a href="/search/cs?searchtype=author&query=Rigau%2C+G">German Rigau</a>, 
<a href="/search/cs?searchtype=author&query=Agirre%2C+E">Eneko Agirre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04353" title="Abstract">arXiv:2310.04353</a> (replaced) [<a href="/pdf/2310.04353" title="Download PDF">pdf</a>, <a href="/format/2310.04353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language-Agent Approach to Formal Theorem-Proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+A">Amitayush Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yeming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05056" title="Abstract">arXiv:2310.05056</a> (replaced) [<a href="/pdf/2310.05056" title="Download PDF">pdf</a>, <a href="/format/2310.05056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Vocabulary Animal Keypoint Detection with Semantic-feature Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lumin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+S">Shenqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaipeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05365" title="Abstract">arXiv:2310.05365</a> (replaced) [<a href="/pdf/2310.05365" title="Download PDF">pdf</a>, <a href="/format/2310.05365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular De Novo Design through Transformer-based Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Pengcheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tianfan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Laghuvarapu%2C+S">Siddhartha Laghuvarapu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05742" title="Abstract">arXiv:2310.05742</a> (replaced) [<a href="/pdf/2310.05742" title="Download PDF">pdf</a>, <a href="/format/2310.05742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Shape Distances on Neural Representations with Limited  Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pospisil%2C+D+A">Dean A. Pospisil</a>, 
<a href="/search/stat?searchtype=author&query=Larsen%2C+B+W">Brett W. Larsen</a>, 
<a href="/search/stat?searchtype=author&query=Harvey%2C+S+E">Sarah E. Harvey</a>, 
<a href="/search/stat?searchtype=author&query=Williams%2C+A+H">Alex H. Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06141" title="Abstract">arXiv:2310.06141</a> (replaced) [<a href="/pdf/2310.06141" title="Download PDF">pdf</a>, <a href="/format/2310.06141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delay-Optimal Service Chain Forwarding and Offloading in Collaborative  Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinkun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+E">Edmund Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06579" title="Abstract">arXiv:2310.06579</a> (replaced) [<a href="/pdf/2310.06579" title="Download PDF">pdf</a>, <a href="/format/2310.06579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Non-Stationary Channel Measurement and Analysis for MaMIMO-UAV  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colpaert%2C+A">Achiel Colpaert</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhuangzhuang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Vinogradov%2C+E">Evgenii Vinogradov</a>, 
<a href="/search/cs?searchtype=author&query=Pollin%2C+S">Sofie Pollin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06648" title="Abstract">arXiv:2310.06648</a> (replaced) [<a href="/pdf/2310.06648" title="Download PDF">pdf</a>, <a href="/format/2310.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ren-Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+K">Ke Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yutong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06824" title="Abstract">arXiv:2310.06824</a> (replaced) [<a href="/pdf/2310.06824" title="Download PDF">pdf</a>, <a href="/format/2310.06824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Geometry of Truth: Emergent Linear Structure in Large Language Model  Representations of True/False Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marks%2C+S">Samuel Marks</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07206" title="Abstract">arXiv:2310.07206</a> (replaced) [<a href="/pdf/2310.07206" title="Download PDF">pdf</a>, <a href="/format/2310.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSimHO: Stable Pose Estimation for Hand-Object Interaction via  Physics Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07427" title="Abstract">arXiv:2310.07427</a> (replaced) [<a href="/pdf/2310.07427" title="Download PDF">pdf</a>, <a href="/format/2310.07427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field  and CNNs for Stock Return Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengmeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaotong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanli Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07867" title="Abstract">arXiv:2310.07867</a> (replaced) [<a href="/pdf/2310.07867" title="Download PDF">pdf</a>, <a href="/format/2310.07867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cheap Talking Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Condorelli%2C+D">Daniele Condorelli</a>, 
<a href="/search/econ?searchtype=author&query=Furlan%2C+M">Massimiliano Furlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07916" title="Abstract">arXiv:2310.07916</a> (replaced) [<a href="/pdf/2310.07916" title="Download PDF">pdf</a>, <a href="/format/2310.07916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Appearance Particle Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+A">Ancheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08008" title="Abstract">arXiv:2310.08008</a> (replaced) [<a href="/pdf/2310.08008" title="Download PDF">pdf</a>, <a href="/format/2310.08008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Human Adversarial and Affable Samples on BERT Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elangovan%2C+A">Aparna Elangovan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayuan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Verspoor%2C+K">Karin Verspoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09025" title="Abstract">arXiv:2310.09025</a> (replaced) [<a href="/pdf/2310.09025" title="Download PDF">pdf</a>, <a href="/format/2310.09025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Near-Space Information Networks: Channel Modeling, Networking,  and Transmission Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xianbin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiaoning Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10214" title="Abstract">arXiv:2310.10214</a> (replaced) [<a href="/pdf/2310.10214" title="Download PDF">pdf</a>, <a href="/format/2310.10214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-SMPC: Koopman Operator-Based Stochastic Model Predictive Control for  Enhanced Lateral Control of Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+J+S">Jin Sung Kim</a>, 
<a href="/search/eess?searchtype=author&query=Quan%2C+Y+S">Ying Shuai Quan</a>, 
<a href="/search/eess?searchtype=author&query=Chung%2C+C+C">Chung Choo Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10619" title="Abstract">arXiv:2310.10619</a> (replaced) [<a href="/pdf/2310.10619" title="Download PDF">pdf</a>, <a href="/format/2310.10619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest-path recovery from signature with an optimal control approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rauscher%2C+M">Marco Rauscher</a>, 
<a href="/search/math?searchtype=author&query=Scagliotti%2C+A">Alessandro Scagliotti</a>, 
<a href="/search/math?searchtype=author&query=Pagginelli%2C+F">Felipe Pagginelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10981" title="Abstract">arXiv:2310.10981</a> (replaced) [<a href="/pdf/2310.10981" title="Download PDF">pdf</a>, <a href="/format/2310.10981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instructive Dialogue Summarization with Query Aggregations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference - Summarization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12214" title="Abstract">arXiv:2310.12214</a> (replaced) [<a href="/pdf/2310.12214" title="Download PDF">pdf</a>, <a href="/format/2310.12214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InferDPT: Privacy-Preserving Inference for Black-box Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meng Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12609" title="Abstract">arXiv:2310.12609</a> (replaced) [<a href="/pdf/2310.12609" title="Download PDF">pdf</a>, <a href="/ps/2310.12609" title="Download PostScript">ps</a>, <a href="/format/2310.12609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Heat-inspired Diffusion with Insulators for Collision Free  Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Junwoo Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+H">Hyunwoo Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Soochul Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongeun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Joohwan Seo</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+N">Nikhil Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Horowitz%2C+R">Roberto Horowitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Workshop on Diffusion Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13140" title="Abstract">arXiv:2310.13140</a> (replaced) [<a href="/pdf/2310.13140" title="Download PDF">pdf</a>, <a href="/format/2310.13140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Evaluation Framework for Fully Homomorphic Encryption and  Privacy-Preserving Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hunjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+C">Corey Clark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> changes made from previous version include change in the name of the title and restructuring/re-organization of the original paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13164" title="Abstract">arXiv:2310.13164</a> (replaced) [<a href="/pdf/2310.13164" title="Download PDF">pdf</a>, <a href="/format/2310.13164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Equivariance via Lie Algebra Convolutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McNeela%2C+D">Daniel McNeela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13191" title="Abstract">arXiv:2310.13191</a> (replaced) [<a href="/pdf/2310.13191" title="Download PDF">pdf</a>, <a href="/format/2310.13191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy  for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13413" title="Abstract">arXiv:2310.13413</a> (replaced) [<a href="/pdf/2310.13413" title="Download PDF">pdf</a>, <a href="/ps/2310.13413" title="Download PostScript">ps</a>, <a href="/format/2310.13413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scoped and Typed Staging by Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allais%2C+G">Guillaume Allais</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> As accepted for PEPM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14076" title="Abstract">arXiv:2310.14076</a> (replaced) [<a href="/pdf/2310.14076" title="Download PDF">pdf</a>, <a href="/format/2310.14076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Relationship Between Relevance and Conflict in Online Social Link  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14729" title="Abstract">arXiv:2310.14729</a> (replaced) [<a href="/pdf/2310.14729" title="Download PDF">pdf</a>, <a href="/format/2310.14729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAS: Multi-view Ancestral Sampling for 3D motion generation using 2D  diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapon%2C+R">Roy Kapon</a>, 
<a href="/search/cs?searchtype=author&query=Tevet%2C+G">Guy Tevet</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Bermano%2C+A+H">Amit H. Bermano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15074" title="Abstract">arXiv:2310.15074</a> (replaced) [<a href="/pdf/2310.15074" title="Download PDF">pdf</a>, <a href="/format/2310.15074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGAS: Multi-Granularity Architecture Search for Trade-Off Between Model  Effectiveness and Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+D">Divya Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiannong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+P">Penghui Ruan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16676" title="Abstract">arXiv:2310.16676</a> (replaced) [<a href="/pdf/2310.16676" title="Download PDF">pdf</a>, <a href="/format/2310.16676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning  Framework for Emotion Recognition in Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaoyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xinyi Tong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shao-Lun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17793" title="Abstract">arXiv:2310.17793</a> (replaced) [<a href="/pdf/2310.17793" title="Download PDF">pdf</a>, <a href="/format/2310.17793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;You Are An Expert Linguistic Annotator&quot;: Limits of LLMs as Analyzers of  Abstract Meaning Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ettinger%2C+A">Allyson Ettinger</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+D">Jena D. Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings (short)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19614" title="Abstract">arXiv:2310.19614</a> (replaced) [<a href="/pdf/2310.19614" title="Download PDF">pdf</a>, <a href="/format/2310.19614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dis-inhibitory neuronal circuits can control the sign of synaptic  plasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rossbroich%2C+J">Julian Rossbroich</a>, 
<a href="/search/q-bio?searchtype=author&query=Zenke%2C+F">Friedemann Zenke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023; fixed error in Figure S2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20187" title="Abstract">arXiv:2310.20187</a> (replaced) [<a href="/pdf/2310.20187" title="Download PDF">pdf</a>, <a href="/format/2310.20187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Pre-Training for Precipitation Post-Processor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+S">Sojung An</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jiyeon Jang</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+I">Inchae Na</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+W">Wooyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Sujeong You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00286" title="Abstract">arXiv:2311.00286</a> (replaced) [<a href="/pdf/2311.00286" title="Download PDF">pdf</a>, <a href="/format/2311.00286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JADE: A Linguistics-based Safety Evaluation Platform for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xudong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preprint work. Benchmark link: <a href="https://github.com/whitzard-ai/jade-db.">this https URL</a> Website link: <a href="https://whitzard-ai.github.io/jade.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00693" title="Abstract">arXiv:2311.00693</a> (replaced) [<a href="/pdf/2311.00693" title="Download PDF">pdf</a>, <a href="/format/2311.00693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Task-personalized Multimodal Few-shot Learning for Visually-rich  Document Entity Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hanjun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper published at Findings of the Association for Computational Linguistics: EMNLP, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01223" title="Abstract">arXiv:2311.01223</a> (replaced) [<a href="/pdf/2311.01223" title="Download PDF">pdf</a>, <a href="/format/2311.01223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Reinforcement Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhengbang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanye Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoran He</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yichao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01766" title="Abstract">arXiv:2311.01766</a> (replaced) [<a href="/pdf/2311.01766" title="Download PDF">pdf</a>, <a href="/format/2311.01766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Support or Refute: Analyzing the Stance of Evidence to Detect  Out-of-Context Mis- and Disinformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weidong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and published by EMNLP 2023. Details can be found in <a href="https://aclanthology.org/2023.emnlp-main.259">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing, pages 4268-4280, Singapore. Association for
  Computational Linguistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02869" title="Abstract">arXiv:2311.02869</a> (replaced) [<a href="/pdf/2311.02869" title="Download PDF">pdf</a>, <a href="/format/2311.02869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight equivariant interaction graph neural network for accurate  and efficient interatomic potential and force predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziduo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qiujie Lv</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+Y">Calvin Yu-Chian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lei Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04651" title="Abstract">arXiv:2311.04651</a> (replaced) [<a href="/pdf/2311.04651" title="Download PDF">pdf</a>, <a href="/ps/2311.04651" title="Download PostScript">ps</a>, <a href="/format/2311.04651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Bayesian Networks, Exactly (Extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faggian%2C+C">Claudia Faggian</a>, 
<a href="/search/cs?searchtype=author&query=Pautasso%2C+D">Daniele Pautasso</a>, 
<a href="/search/cs?searchtype=author&query=Vanoni%2C+G">Gabriele Vanoni</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Program. Lang. 8, POPL, Article 84 (January 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04673" title="Abstract">arXiv:2311.04673</a> (replaced) [<a href="/pdf/2311.04673" title="Download PDF">pdf</a>, <a href="/format/2311.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressive Recovery of Sparse Precision Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vayer%2C+T">Titouan Vayer</a>, 
<a href="/search/stat?searchtype=author&query=Lasalle%2C+E">Etienne Lasalle</a>, 
<a href="/search/stat?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a>, 
<a href="/search/stat?searchtype=author&query=Gon%C3%A7alves%2C+P">Paulo Gon&#xe7;alves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04811" title="Abstract">arXiv:2311.04811</a> (replaced) [<a href="/pdf/2311.04811" title="Download PDF">pdf</a>, <a href="/format/2311.04811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-Based Virtual Try-On: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanpu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Juan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+R">Ruofeng Tong</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An-An Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04916" title="Abstract">arXiv:2311.04916</a> (replaced) [<a href="/pdf/2311.04916" title="Download PDF">pdf</a>, <a href="/format/2311.04916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Identification of Hate Speech towards Islam using Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasi%2C+A+T">Azmine Toushik Wasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures; NeurIPS 2023 Workshop Muslims in ML. Openreview forum: <a href="https://openreview.net/forum?id=jG3Y7bA94N">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05112" title="Abstract">arXiv:2311.05112</a> (replaced) [<a href="/pdf/2311.05112" title="Download PDF">pdf</a>, <a href="/format/2311.05112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Large Language Models in Medicine: Principles, Applications,  and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongjian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fenglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Boyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xinyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinfa Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinge Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiru Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S+S">Sam S. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yining Hua</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengfeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+L">Lei Clifton</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Version 2. 53 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05135" title="Abstract">arXiv:2311.05135</a> (replaced) [<a href="/pdf/2311.05135" title="Download PDF">pdf</a>, <a href="/format/2311.05135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Computational Efficiency for Powered Descent Guidance via  Transformer-based Tight Constraint Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Briden%2C+J">Julia Briden</a>, 
<a href="/search/math?searchtype=author&query=Gurga%2C+T">Trey Gurga</a>, 
<a href="/search/math?searchtype=author&query=Johnson%2C+B">Breanna Johnson</a>, 
<a href="/search/math?searchtype=author&query=Cauligi%2C+A">Abhishek Cauligi</a>, 
<a href="/search/math?searchtype=author&query=Linares%2C+R">Richard Linares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AIAA SciTech 2024 on 25-Aug-2023. Full manuscript submitted to AIAA SciTech 2024 on 25-May-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05610" title="Abstract">arXiv:2311.05610</a> (replaced) [<a href="/pdf/2311.05610" title="Download PDF">pdf</a>, <a href="/format/2311.05610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Parallelization Layouts for Large-Scale Distributed Model  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagemann%2C+J">Johannes Hagemann</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>, 
<a href="/search/cs?searchtype=author&query=Dobler%2C+K">Konstantin Dobler</a>, 
<a href="/search/cs?searchtype=author&query=Schall%2C+M">Maximilian Schall</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+G">Gerard de Melo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version for the Workshop on Advancing Neural Network Training at 37th Conference on Neural Information Processing Systems (WANT@NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06396" title="Abstract">arXiv:2311.06396</a> (replaced) [<a href="/pdf/2311.06396" title="Download PDF">pdf</a>, <a href="/format/2311.06396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive analysis of concept drift locality in data streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aguiar%2C+G+J">Gabriel J. Aguiar</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+A">Alberto Cano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07461" title="Abstract">arXiv:2311.07461</a> (replaced) [<a href="/pdf/2311.07461" title="Download PDF">pdf</a>, <a href="/format/2311.07461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Self-Supervised Dynamic Incremental Regularised Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghobrial%2C+A">Abanoub Ghobrial</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+K">Kerstin Eder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07947" title="Abstract">arXiv:2311.07947</a> (replaced) [<a href="/pdf/2311.07947" title="Download PDF">pdf</a>, <a href="/ps/2311.07947" title="Download PostScript">ps</a>, <a href="/format/2311.07947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Technical Debt for Recommender System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreschini%2C+S">Sergio Moreschini</a>, 
<a href="/search/cs?searchtype=author&query=Coba%2C+L">Ludovik Coba</a>, 
<a href="/search/cs?searchtype=author&query=Lenarduzzi%2C+V">Valentina Lenarduzzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07995" title="Abstract">arXiv:2311.07995</a> (replaced) [<a href="/pdf/2311.07995" title="Download PDF">pdf</a>, <a href="/ps/2311.07995" title="Download PostScript">ps</a>, <a href="/format/2311.07995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPPA numbers of graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bradley-Williams%2C+D">David Bradley-Williams</a>, 
<a href="/search/math?searchtype=author&query=Cameron%2C+P+J">Peter J. Cameron</a>, 
<a href="/search/math?searchtype=author&query=Hubi%C4%8Dka%2C+J">Jan Hubi&#x10d;ka</a>, 
<a href="/search/math?searchtype=author&query=Kone%C4%8Dn%C3%BD%2C+M">Mat&#x11b;j Kone&#x10d;n&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08811" title="Abstract">arXiv:2311.08811</a> (replaced) [<a href="/pdf/2311.08811" title="Download PDF">pdf</a>, <a href="/format/2311.08811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlation-aware active learning for surgery video segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Marquez-Neila%2C+P">Pablo Marquez-Neila</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mingyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Rafii-Tari%2C+H">Hedyeh Rafii-Tari</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024, 8 pages, 7 supplementary pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08999" title="Abstract">arXiv:2311.08999</a> (replaced) [<a href="/pdf/2311.08999" title="Download PDF">pdf</a>, <a href="/ps/2311.08999" title="Download PostScript">ps</a>, <a href="/format/2311.08999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging AI for Natural Disaster Management : Takeaways From The  Moroccan Earthquake
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hackathon%2C+M+S">Morocco Solidarity Hackathon</a> (Organizers, Speakers, Mentors and Participant teams)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09178" title="Abstract">arXiv:2311.09178</a> (replaced) [<a href="/pdf/2311.09178" title="Download PDF">pdf</a>, <a href="/format/2311.09178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulaiman%2C+M">Marwah Sulaiman</a>, 
<a href="/search/cs?searchtype=author&query=Shehabeldin%2C+Z">Zahraa Shehabeldin</a>, 
<a href="/search/cs?searchtype=author&query=Fahmy%2C+I">Israa Fahmy</a>, 
<a href="/search/cs?searchtype=author&query=Barakat%2C+M">Mohammed Barakat</a>, 
<a href="/search/cs?searchtype=author&query=El-Naggar%2C+M">Mohammed El-Naggar</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+D">Dareen Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Youssef%2C+M">Moustafa Youssef</a>, 
<a href="/search/cs?searchtype=author&query=Eraqi%2C+H+M">Hesham M. Eraqi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10533" title="Abstract">arXiv:2311.10533</a> (replaced) [<a href="/pdf/2311.10533" title="Download PDF">pdf</a>, <a href="/format/2311.10533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parsing Millions of URLs per Second
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nizipli%2C+Y">Yagiz Nizipli</a>, 
<a href="/search/cs?searchtype=author&query=Lemire%2C+D">Daniel Lemire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10792" title="Abstract">arXiv:2311.10792</a> (replaced) [<a href="/pdf/2311.10792" title="Download PDF">pdf</a>, <a href="/ps/2311.10792" title="Download PostScript">ps</a>, <a href="/format/2311.10792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Mechanism for Lithium-Ion Battery Lifespan Prediction:  Temporal and Cyclic Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+S">Seongmin Heo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jay H. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10931" title="Abstract">arXiv:2311.10931</a> (replaced) [<a href="/pdf/2311.10931" title="Download PDF">pdf</a>, <a href="/format/2311.10931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLORIDA: Fake-looking Real Images Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borji%2C+A">Ali Borji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12397" title="Abstract">arXiv:2311.12397</a> (replaced) [<a href="/pdf/2311.12397" title="Download PDF">pdf</a>, <a href="/format/2311.12397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rich and Poor Texture Contrast: A Simple yet Effective Approach for  AI-generated Image Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+N">Nan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our project: <a href="https://fdmas.github.io/AIGCDetect/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12424" title="Abstract">arXiv:2311.12424</a> (replaced) [<a href="/pdf/2311.12424" title="Download PDF">pdf</a>, <a href="/format/2311.12424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looped Transformers are Better at Learning Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kangwook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R">Robert Nowak</a>, 
<a href="/search/cs?searchtype=author&query=Papailiopoulos%2C+D">Dimitris Papailiopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13812" title="Abstract">arXiv:2311.13812</a> (replaced) [<a href="/pdf/2311.13812" title="Download PDF">pdf</a>, <a href="/format/2311.13812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanical Characterization and Inverse Design of Stochastic Architected  Metamaterials Using Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Jin%2C+H">Hanxun Jin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+E">Enrui Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+B">Boyu Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Krishnaswamy%2C+S">Sridhar Krishnaswamy</a>, 
<a href="/search/cond-mat?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cond-mat?searchtype=author&query=Espinosa%2C+H+D">Horacio D. Espinosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13884" title="Abstract">arXiv:2311.13884</a> (replaced) [<a href="/pdf/2311.13884" title="Download PDF">pdf</a>, <a href="/format/2311.13884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Large Language Model-based Agents for Large-Scale  Decision-Making: An Actor-Critic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jingqing Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guoliang Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1071">[1071]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14168" title="Abstract">arXiv:2311.14168</a> (replaced) [<a href="/pdf/2311.14168" title="Download PDF">pdf</a>, <a href="/format/2311.14168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Policy Learning for Linear Quadratic Control with Entropy  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+R">Renyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1072">[1072]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14262" title="Abstract">arXiv:2311.14262</a> (replaced) [<a href="/pdf/2311.14262" title="Download PDF">pdf</a>, <a href="/format/2311.14262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroPS: High-quality Cross-modal Knowledge Transfer for Zero-Shot 3D  Part Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yuheng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nenglun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenyun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures; references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1073">[1073]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14616" title="Abstract">arXiv:2311.14616</a> (replaced) [<a href="/pdf/2311.14616" title="Download PDF">pdf</a>, <a href="/format/2311.14616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using MultiPrecisonArrays.jl: Iterative Refinement in Julia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kelley%2C+C+T">C. T. Kelley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1074">[1074]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15626" title="Abstract">arXiv:2311.15626</a> (replaced) [<a href="/pdf/2311.15626" title="Download PDF">pdf</a>, <a href="/format/2311.15626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The WebCrow French Crossword Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelini%2C+G">Giovanni Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Ernandes%2C+M">Marco Ernandes</a>, 
<a href="/search/cs?searchtype=author&query=laquinta%2C+T">Tommaso laquinta</a>, 
<a href="/search/cs?searchtype=author&query=Stehl%C3%A9%2C+C">Caroline Stehl&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+F">Fanny Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Zugarini%2C+A">Andrea Zugarini</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper for EAI Intetain 2023 - 14th EAI International Conference on Intelligent Technologies for Interactive Entertainment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1075">[1075]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15643" title="Abstract">arXiv:2311.15643</a> (replaced) [<a href="/pdf/2311.15643" title="Download PDF">pdf</a>, <a href="/format/2311.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Monocular Re-Localization: From the Perspective of Scene Map  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Jinyu Miao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+T">Tuopu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Peijing Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhongyang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhihua Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diange Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 108 pages, 9 tables, 17 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1076">[1076]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15962" title="Abstract">arXiv:2311.15962</a> (replaced) [<a href="/pdf/2311.15962" title="Download PDF">pdf</a>, <a href="/format/2311.15962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification of Set-Membership Estimation in Control and  Perception: Revisiting the Minimum Enclosing Ellipsoid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+Y">Yukai Tang</a>, 
<a href="/search/math?searchtype=author&query=Lasserre%2C+J">Jean-Bernard Lasserre</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+H">Heng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 6th Learning for Dynamics and Control (L4DC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1077">[1077]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16378" title="Abstract">arXiv:2311.16378</a> (replaced) [<a href="/pdf/2311.16378" title="Download PDF">pdf</a>, <a href="/format/2311.16378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Formulations for Graph Spectral Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leone%2C+S">Sam Leone</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xingzhi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Perlmutter%2C+M">Michael Perlmutter</a>, 
<a href="/search/cs?searchtype=author&query=Krishnaswamy%2C+S">Smita Krishnaswamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1078">[1078]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16588" title="Abstract">arXiv:2311.16588</a> (replaced) [<a href="/pdf/2311.16588" title="Download PDF">pdf</a>, <a href="/ps/2311.16588" title="Download PostScript">ps</a>, <a href="/format/2311.16588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ascle: A Python Natural Language Processing Toolkit for Medical Text  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Q">Qingcheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+K">Keen You</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yujie Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lucas Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Chia-Chun Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Rosand%2C+B">Benjamin Rosand</a>, 
<a href="/search/cs?searchtype=author&query=Goldwasser%2C+J">Jeremy Goldwasser</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A+D">Amisha D Dave</a>, 
<a href="/search/cs?searchtype=author&query=Keenan%2C+T+D+L">Tiarnan D.L. Keenan</a>, 
<a href="/search/cs?searchtype=author&query=Chew%2C+E+Y">Emily Y Chew</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+D">Dragomir Radev</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1079">[1079]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16663" title="Abstract">arXiv:2311.16663</a> (replaced) [<a href="/pdf/2311.16663" title="Download PDF">pdf</a>, <a href="/ps/2311.16663" title="Download PostScript">ps</a>, <a href="/format/2311.16663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unclonable Cryptography in the Plain Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chevalier%2C+C">C&#xe9;line Chevalier</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hermouet%2C+P">Paul Hermouet</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vu%2C+Q">Quoc-Huy Vu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> added erratum describing an error in the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1080">[1080]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16945" title="Abstract">arXiv:2311.16945</a> (replaced) [<a href="/pdf/2311.16945" title="Download PDF">pdf</a>, <a href="/format/2311.16945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UC-NeRF: Neural Radiance Field for Under-Calibrated Multi-view Cameras  in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kai Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaozhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuejin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See the project page for code, data: <a href="https://kcheng1021.github.io/ucnerf.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1081">[1081]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17431" title="Abstract">arXiv:2311.17431</a> (replaced) [<a href="/pdf/2311.17431" title="Download PDF">pdf</a>, <a href="/format/2311.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Foundation Models through Federated Transfer Learning: A  General Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress. fixed some typos, errors, and revised the text a little bit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1082">[1082]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18054" title="Abstract">arXiv:2311.18054</a> (replaced) [<a href="/pdf/2311.18054" title="Download PDF">pdf</a>, <a href="/format/2311.18054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Know You Did Not Write That! A Sampling Based Watermarking Method for  Identifying Machine Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kele%C5%9F%2C+K+E">Kaan Efe Kele&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrb%C3%BCz%2C+%C3%96+K">&#xd6;mer Kaan G&#xfc;rb&#xfc;z</a>, 
<a href="/search/cs?searchtype=author&query=Kutlu%2C+M">Mucahid Kutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1083">[1083]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18188" title="Abstract">arXiv:2311.18188</a> (replaced) [<a href="/pdf/2311.18188" title="Download PDF">pdf</a>, <a href="/format/2311.18188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging cache to enable SLU on tiny devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Benazir%2C+A">Afsara Benazir</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhiming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a> (University of Virginia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1084">[1084]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18760" title="Abstract">arXiv:2311.18760</a> (replaced) [<a href="/pdf/2311.18760" title="Download PDF">pdf</a>, <a href="/format/2311.18760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaskBench: Benchmarking Large Language Models for Task Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yongliang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Siyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weiming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1085">[1085]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00377" title="Abstract">arXiv:2312.00377</a> (replaced) [<a href="/pdf/2312.00377" title="Download PDF">pdf</a>, <a href="/format/2312.00377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynFundus: A synthetic fundus images dataset with millions of samples  and multi-disease annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+F">Fangxin Shang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yehui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1086">[1086]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00516" title="Abstract">arXiv:2312.00516</a> (replaced) [<a href="/pdf/2312.00516" title="Download PDF">pdf</a>, <a href="/format/2312.00516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal-Decoupled Masked Pre-training: Benchmarked on Traffic  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haotian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Renhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jinliang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1087">[1087]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00534" title="Abstract">arXiv:2312.00534</a> (replaced) [<a href="/pdf/2312.00534" title="Download PDF">pdf</a>, <a href="/format/2312.00534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-based curb detection for ground truth annotation in automated  driving validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apell%C3%A1niz%2C+J+L">Jose Luis Apell&#xe1;niz</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+M">Mikel Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Aranjuelo%2C+N">Nerea Aranjuelo</a>, 
<a href="/search/cs?searchtype=author&query=Barandiar%C3%A1n%2C+J">Javier Barandiar&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+M">Marcos Nieto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1088">[1088]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00655" title="Abstract">arXiv:2312.00655</a> (replaced) [<a href="/pdf/2312.00655" title="Download PDF">pdf</a>, <a href="/ps/2312.00655" title="Download PostScript">ps</a>, <a href="/format/2312.00655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning for Health symposium 2023 -- Findings track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hegselmann%2C+S">Stefan Hegselmann</a>, 
<a href="/search/cs?searchtype=author&query=Parziale%2C+A">Antonio Parziale</a>, 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+D">Divya Shanmugam</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shengpu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Asiedu%2C+M+N">Mercy Nyamewaa Asiedu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Serina Chang</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Thomas Hartvigsen</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Harvineet Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1089">[1089]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00790" title="Abstract">arXiv:2312.00790</a> (replaced) [<a href="/pdf/2312.00790" title="Download PDF">pdf</a>, <a href="/format/2312.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Rank Solution Operator for Forced Linearized Dynamics with Unsteady  Base Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Amiri-Margavi%2C+A">Alireza Amiri-Margavi</a>, 
<a href="/search/physics?searchtype=author&query=Babaee%2C+H">Hessam Babaee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item1090">[1090]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01027" title="Abstract">arXiv:2312.01027</a> (replaced) [<a href="/pdf/2312.01027" title="Download PDF">pdf</a>, <a href="/format/2312.01027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Latent Diffusion Models to See in the Dark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qiang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yazhou Xing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1091">[1091]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01150" title="Abstract">arXiv:2312.01150</a> (replaced) [<a href="/pdf/2312.01150" title="Download PDF">pdf</a>, <a href="/format/2312.01150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pointer Networks Trained Better via Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Muyao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> None
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item1092">[1092]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01219" title="Abstract">arXiv:2312.01219</a> (replaced) [<a href="/pdf/2312.01219" title="Download PDF">pdf</a>, <a href="/ps/2312.01219" title="Download PostScript">ps</a>, <a href="/format/2312.01219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Security Events Correlation Model for Real-time Cyber  Threat Detection and Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maosa%2C+H">Herbert Maosa</a>, 
<a href="/search/cs?searchtype=author&query=Ouazzane%2C+K">Karim Ouazzane</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M+C">Mohamed Chahine Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version 2.4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1093">[1093]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01339" title="Abstract">arXiv:2312.01339</a> (replaced) [<a href="/pdf/2312.01339" title="Download PDF">pdf</a>, <a href="/format/2312.01339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+M+Z">Mohamed Zaky Saad</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper for ArabicNLP 2023 - The First Arabic Natural Language Processing Conference - Co-located with EMNLP 2023 in Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1094">[1094]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01544" title="Abstract">arXiv:2312.01544</a> (replaced) [<a href="/pdf/2312.01544" title="Download PDF">pdf</a>, <a href="/format/2312.01544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KEEC: Embed to Control on An Equivariant Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiaoyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yukun Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1095">[1095]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01598" title="Abstract">arXiv:2312.01598</a> (replaced) [<a href="/pdf/2312.01598" title="Download PDF">pdf</a>, <a href="/format/2312.01598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Good Questions Help Zero-Shot Image Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaiwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xinmei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiubo Geng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1096">[1096]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01648" title="Abstract">arXiv:2312.01648</a> (replaced) [<a href="/pdf/2312.01648" title="Download PDF">pdf</a>, <a href="/format/2312.01648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Large Language Model Geometry Solves Toxicity Detection  and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balestriero%2C+R">Randall Balestriero</a>, 
<a href="/search/cs?searchtype=author&query=Cosentino%2C+R">Romain Cosentino</a>, 
<a href="/search/cs?searchtype=author&query=Shekkizhar%2C+S">Sarath Shekkizhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1097">[1097]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01711" title="Abstract">arXiv:2312.01711</a> (replaced) [<a href="/pdf/2312.01711" title="Download PDF">pdf</a>, <a href="/format/2312.01711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regressor-Segmenter Mutual Prompt Learning for Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhaoyi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Binghui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qixiang Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> mPrompt defines a way of mutual information maximization from prompt learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1098">[1098]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01826" title="Abstract">arXiv:2312.01826</a> (replaced) [<a href="/pdf/2312.01826" title="Download PDF">pdf</a>, <a href="/format/2312.01826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain-based Coverage Manifold Estimation: Machine Learning, Stochastic  Geometry, or Simulation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+W+U">Washim Uddin Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item1099">[1099]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01853" title="Abstract">arXiv:2312.01853</a> (replaced) [<a href="/pdf/2312.01853" title="Download PDF">pdf</a>, <a href="/format/2312.01853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Synesthesia: In-Hand Manipulation with Visuotactile Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ying Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+H">Haichuan Che</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binghao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhao-Heng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-Won Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Soo-Chul Lim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yingyuan0414.github.io/visuotactile/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1100">[1100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01878" title="Abstract">arXiv:2312.01878</a> (replaced) [<a href="/pdf/2312.01878" title="Download PDF">pdf</a>, <a href="/format/2312.01878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot  Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1101">[1101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02021" title="Abstract">arXiv:2312.02021</a> (replaced) [<a href="/pdf/2312.02021" title="Download PDF">pdf</a>, <a href="/format/2312.02021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations  for Domain Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%BCmmer%2C+C">Christoph H&#xfc;mmer</a>, 
<a href="/search/cs?searchtype=author&query=Schwonberg%2C+M">Manuel Schwonberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Liangwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Gottschalk%2C+H">Hanno Gottschalk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1102">[1102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02338" title="Abstract">arXiv:2312.02338</a> (replaced) [<a href="/pdf/2312.02338" title="Download PDF">pdf</a>, <a href="/format/2312.02338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contrastive Compositional Benchmark for Text-to-Image Synthesis: A  Study with Unified Text-to-Image Fidelity Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Penglei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1103">[1103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02396" title="Abstract">arXiv:2312.02396</a> (replaced) [<a href="/pdf/2312.02396" title="Download PDF">pdf</a>, <a href="/format/2312.02396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Change Detection for Space Habitats Using 3D Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+J">Jamie Santos</a>, 
<a href="/search/cs?searchtype=author&query=Dinkel%2C+H">Holly Dinkel</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>, 
<a href="/search/cs?searchtype=author&query=Borges%2C+P+V+K">Paulo V.K. Borges</a>, 
<a href="/search/cs?searchtype=author&query=Moreira%2C+M">Marina Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+O">Oleg Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Coltin%2C+B">Brian Coltin</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+T">Trey Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, Manuscript will be presented at the AIAA SciTech Forum in Orlando, FL, USA, 8 - 12 January 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1104">[1104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02406" title="Abstract">arXiv:2312.02406</a> (replaced) [<a href="/pdf/2312.02406" title="Download PDF">pdf</a>, <a href="/format/2312.02406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Online Data Mixing For Language Model Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albalak%2C+A">Alon Albalak</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1105">[1105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02725" title="Abstract">arXiv:2312.02725</a> (replaced) [<a href="/pdf/2312.02725" title="Download PDF">pdf</a>, <a href="/format/2312.02725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R3D-SWIN:Use Shifted Window Attention for Single-View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meihua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=li%2C+z">zehuan li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Shanshan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mengxi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages,3 figures,5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1106">[1106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02762" title="Abstract">arXiv:2312.02762</a> (replaced) [<a href="/pdf/2312.02762" title="Download PDF">pdf</a>, <a href="/format/2312.02762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Cortical Anomaly through Masked Encoding for Unsupervised  Heterogeneity Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hao-Chun Yang</a>, 
<a href="/search/eess?searchtype=author&query=Andreassen%2C+O">Ole Andreassen</a>, 
<a href="/search/eess?searchtype=author&query=Westlye%2C+L+T">Lars Tjelta Westlye</a>, 
<a href="/search/eess?searchtype=author&query=Marquand%2C+A+F">Andre F. Marquand</a>, 
<a href="/search/eess?searchtype=author&query=Beckmann%2C+C+F">Christian F. Beckmann</a>, 
<a href="/search/eess?searchtype=author&query=Wolfers%2C+T">Thomas Wolfers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, LaTeX; typos corrected, introduction refined
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1107">[1107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02957" title="Abstract">arXiv:2312.02957</a> (replaced) [<a href="/pdf/2312.02957" title="Download PDF">pdf</a>, <a href="/format/2312.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification for everyone : Building geography agnostic models for  fairer recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jindal%2C+A">Akshat Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shreya Singh</a>, 
<a href="/search/cs?searchtype=author&query=Gadgil%2C+S">Soham Gadgil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Stanford CS 231n Course Project
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1108">[1108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03018" title="Abstract">arXiv:2312.03018</a> (replaced) [<a href="/pdf/2312.03018" title="Download PDF">pdf</a>, <a href="/format/2312.03018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention  and Text Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaxi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Panwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1109">[1109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03097" title="Abstract">arXiv:2312.03097</a> (replaced) [<a href="/pdf/2312.03097" title="Download PDF">pdf</a>, <a href="/format/2312.03097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State of Health Estimation for Battery Modules with Parallel-Connected  Cells Under Cell-to-Cell Variations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Q">Qinan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Anderson%2C+D">Dyche Anderson</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Jing Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added the initialization of Phi in Algorithm 2, which the author forgot to type at the previous submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1110">[1110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03196" title="Abstract">arXiv:2312.03196</a> (replaced) [<a href="/pdf/2312.03196" title="Download PDF">pdf</a>, <a href="/format/2312.03196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Invariant Representation Learning and Sleep Dynamics Modeling for  Automatic Sleep Staging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thai-Hoang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1111">[1111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03325" title="Abstract">arXiv:2312.03325</a> (replaced) [<a href="/pdf/2312.03325" title="Download PDF">pdf</a>, <a href="/format/2312.03325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCFA:Geodesic Curve Feature Augmentation in the Pre-Shape Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuexing Han</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Guanxin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1112">[1112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03430" title="Abstract">arXiv:2312.03430</a> (replaced) [<a href="/pdf/2312.03430" title="Download PDF">pdf</a>, <a href="/format/2312.03430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShareCMP: Polarization-Aware RGB-P Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chenyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1113">[1113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03441" title="Abstract">arXiv:2312.03441</a> (replaced) [<a href="/pdf/2312.03441" title="Download PDF">pdf</a>, <a href="/format/2312.03441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFineBench: Towards Text-based Person Retrieval with Ultra-fine  Granularity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jialong Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Ying Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1114">[1114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03511" title="Abstract">arXiv:2312.03511</a> (replaced) [<a href="/pdf/2312.03511" title="Download PDF">pdf</a>, <a href="/format/2312.03511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kandinsky 3.0 Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arkhipkin%2C+V">Vladimir Arkhipkin</a>, 
<a href="/search/cs?searchtype=author&query=Filatov%2C+A">Andrei Filatov</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+V">Viacheslav Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Maltseva%2C+A">Anastasia Maltseva</a>, 
<a href="/search/cs?searchtype=author&query=Azizov%2C+S">Said Azizov</a>, 
<a href="/search/cs?searchtype=author&query=Pavlov%2C+I">Igor Pavlov</a>, 
<a href="/search/cs?searchtype=author&query=Agafonova%2C+J">Julia Agafonova</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+A">Andrey Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ai-forever.github.io/Kandinsky-3">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1115">[1115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03549" title="Abstract">arXiv:2312.03549</a> (replaced) [<a href="/pdf/2312.03549" title="Download PDF">pdf</a>, <a href="/format/2312.03549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holmes: Towards Distributed Training Across Clusters with Heterogeneous  NIC Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shuang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+N">Ning Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Ke Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Aimin Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1116">[1116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03585" title="Abstract">arXiv:2312.03585</a> (replaced) [<a href="/pdf/2312.03585" title="Download PDF">pdf</a>, <a href="/format/2312.03585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model Assisted Weakly Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaobo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xiaojin Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1117">[1117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03730" title="Abstract">arXiv:2312.03730</a> (replaced) [<a href="/pdf/2312.03730" title="Download PDF">pdf</a>, <a href="/format/2312.03730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News  for Credible US Elections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+T">Tahniat Khan</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mizanur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Chatrath%2C+V">Veronica Chatrath</a>, 
<a href="/search/cs?searchtype=author&query=Bamgbose%2C+O">Oluwanifemi Bamgbose</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1118">[1118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03763" title="Abstract">arXiv:2312.03763</a> (replaced) [<a href="/pdf/2312.03763" title="Download PDF">pdf</a>, <a href="/format/2312.03763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yushi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+D">Di Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiangeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Genova%2C+K">Kyle Genova</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fanello%2C+S">Sean Fanello</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Funkhouser%2C+T">Thomas Funkhouser</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project webpage: <a href="https://nirvanalan.github.io/projects/gaussian3diff/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1119">[1119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03815" title="Abstract">arXiv:2312.03815</a> (replaced) [<a href="/pdf/2312.03815" title="Download PDF">pdf</a>, <a href="/format/2312.03815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent  Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yingqiang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yujie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Juntao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1120">[1120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03927" title="Abstract">arXiv:2312.03927</a> (replaced) [<a href="/pdf/2312.03927" title="Download PDF">pdf</a>, <a href="/format/2312.03927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fast numerical algorithm for finding all real solutions to a system of  N nonlinear equations in a finite domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chueca-Diez%2C+F">Fernando Chueca-Diez</a>, 
<a href="/search/eess?searchtype=author&query=Ganan-Calvo%2C+A+M">Alfonso M. Ganan-Calvo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1121">[1121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03996" title="Abstract">arXiv:2312.03996</a> (replaced) [<a href="/pdf/2312.03996" title="Download PDF">pdf</a>, <a href="/ps/2312.03996" title="Download PostScript">ps</a>, <a href="/format/2312.03996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable diffusion for Data Augmentation in COCO and Weed Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Boyang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1122">[1122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04004" title="Abstract">arXiv:2312.04004</a> (replaced) [<a href="/pdf/2312.04004" title="Download PDF">pdf</a>, <a href="/format/2312.04004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occlusion-based Detection of Trojan-triggering Inputs in Large Language  Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aftab Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+T">Toufique Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M+A">Mohammad Amin Alipour</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1123">[1123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04008" title="Abstract">arXiv:2312.04008</a> (replaced) [<a href="/pdf/2312.04008" title="Download PDF">pdf</a>, <a href="/format/2312.04008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural-language-driven Simulation Benchmark and Copilot for Efficient  Production of Object Interactions in Virtual Road Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kairui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zihao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Gengjie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haotian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+D">Die Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jibin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhecheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fupeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Ziyun Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1124">[1124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04021" title="Abstract">arXiv:2312.04021</a> (replaced) [<a href="/pdf/2312.04021" title="Download PDF">pdf</a>, <a href="/format/2312.04021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on the Calibration of In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi-Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yaodong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Madeka%2C+D">Dhruv Madeka</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+D">Dean Foster</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Hima Lakkaraju</a>, 
<a href="/search/cs?searchtype=author&query=Kakade%2C+S">Sham Kakade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight Talk at NeurIPS 2023 Workshop on Failure Modes in the Age of Foundation Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1125">[1125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04025" title="Abstract">arXiv:2312.04025</a> (replaced) [<a href="/e-print/2312.04025" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moirai: Towards Optimal Placement for Distributed Inference on  Heterogeneous Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beibei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhihui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S+X">Sean Xiaoyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Temprarily withdraw to amend experimental results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1126">[1126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04055" title="Abstract">arXiv:2312.04055</a> (replaced) [<a href="/pdf/2312.04055" title="Download PDF">pdf</a>, <a href="/ps/2312.04055" title="Download PostScript">ps</a>, <a href="/format/2312.04055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly spatial-temporal representation learning for individual  trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jianrong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yang Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 tables, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1127">[1127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04066" title="Abstract">arXiv:2312.04066</a> (replaced) [<a href="/pdf/2312.04066" title="Download PDF">pdf</a>, <a href="/format/2312.04066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining inherent knowledge of vision-language models with unsupervised  domain adaptation through self-knowledge distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westfechtel%2C+T">Thomas Westfechtel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dexuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1128">[1128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04091" title="Abstract">arXiv:2312.04091</a> (replaced) [<a href="/pdf/2312.04091" title="Download PDF">pdf</a>, <a href="/ps/2312.04091" title="Download PostScript">ps</a>, <a href="/format/2312.04091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperarithmetical Complexity of Infinitary Action Logic with  Multiplexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pshenitsyn%2C+T">Tikhon Pshenitsyn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1129">[1129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04191" title="Abstract">arXiv:2312.04191</a> (replaced) [<a href="/pdf/2312.04191" title="Download PDF">pdf</a>, <a href="/ps/2312.04191" title="Download PostScript">ps</a>, <a href="/format/2312.04191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subsets of groups with context-free preimages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Levine%2C+A">Alex Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures. Corrected statement of Theorem 6.4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item1130">[1130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04223" title="Abstract">arXiv:2312.04223</a> (replaced) [<a href="/pdf/2312.04223" title="Download PDF">pdf</a>, <a href="/format/2312.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysioCHI: Towards Best Practices for Integrating Physiological Signals  in HCI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiossi%2C+F">Francesco Chiossi</a>, 
<a href="/search/cs?searchtype=author&query=Stepanova%2C+E+R">Ekaterina R. Stepanova</a>, 
<a href="/search/cs?searchtype=author&query=Tag%2C+B">Benjamin Tag</a>, 
<a href="/search/cs?searchtype=author&query=Perusquia-Hernandez%2C+M">Monica Perusquia-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Kitson%2C+A">Alexandra Kitson</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A">Arindam Dey</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+S">Sven Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+E">Abdallah El Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1131">[1131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04417" title="Abstract">arXiv:2312.04417</a> (replaced) [<a href="/pdf/2312.04417" title="Download PDF">pdf</a>, <a href="/ps/2312.04417" title="Download PostScript">ps</a>, <a href="/format/2312.04417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Fairness in Multiwinner Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkind%2C+E">Edith Elkind</a>, 
<a href="/search/cs?searchtype=author&query=Obraztsova%2C+S">Svetlana Obraztsova</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+N">Nicholas Teh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item1132">[1132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04512" title="Abstract">arXiv:2312.04512</a> (replaced) [<a href="/pdf/2312.04512" title="Download PDF">pdf</a>, <a href="/format/2312.04512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuFuzz: Sequence-Aware Mutation and Seed Mask Guidance for Blockchain  Smart Contract Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+P">Peng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zeren Du</a>, 
<a href="/search/cs?searchtype=author&query=Vural%2C+T">Turan Vural</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+D">Dazhong Rong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qinming He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1133">[1133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04519" title="Abstract">arXiv:2312.04519</a> (replaced) [<a href="/pdf/2312.04519" title="Download PDF">pdf</a>, <a href="/format/2312.04519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Autonomous Radars with Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yiduo Hao</a>, 
<a href="/search/cs?searchtype=author&query=Madani%2C+S">Sohrab Madani</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Junfeng Guan</a>, 
<a href="/search/cs?searchtype=author&query=Alloulah%2C+M">Mohammed Alloulah</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saurabh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hassanieh%2C+H">Haitham Hassanieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1134">[1134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04584" title="Abstract">arXiv:2312.04584</a> (replaced) [<a href="/pdf/2312.04584" title="Download PDF">pdf</a>, <a href="/format/2312.04584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Sample-specific Backdoor Attack with Clean Labels via Attribute  Trigger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingyan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junfeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1135">[1135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04876" title="Abstract">arXiv:2312.04876</a> (replaced) [<a href="/pdf/2312.04876" title="Download PDF">pdf</a>, <a href="/format/2312.04876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVE-Louvain: Fast Louvain Algorithm for Community Detection in Shared  Memory Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item1136">[1136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04920" title="Abstract">arXiv:2312.04920</a> (replaced) [<a href="/pdf/2312.04920" title="Download PDF">pdf</a>, <a href="/format/2312.04920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Secure Aggregation in FL: Partial Vector Freezing for  Cost Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1137">[1137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04937" title="Abstract">arXiv:2312.04937</a> (replaced) [<a href="/pdf/2312.04937" title="Download PDF">pdf</a>, <a href="/format/2312.04937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AHSecAgg and TSKG: Lightweight Secure Aggregation for Federated Learning  Without Compromise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1138">[1138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04956" title="Abstract">arXiv:2312.04956</a> (replaced) [<a href="/pdf/2312.04956" title="Download PDF">pdf</a>, <a href="/format/2312.04956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stacked ensemble learning IDS model for Software-defined VANET
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+S+I">Shakil Ibne Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=Legg%2C+P">Phil Legg</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S+M+I">S M Iftekharul Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1139">[1139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05107" title="Abstract">arXiv:2312.05107</a> (replaced) [<a href="/pdf/2312.05107" title="Download PDF">pdf</a>, <a href="/format/2312.05107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreaMoving: A Human Video Generation Framework based on Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Z">Zheng Hui</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiefan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianhui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haolan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Biwen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Miaomiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Peiran Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, Tech. Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item671">Cross-lists</a></li>
<li><a href="#item739">Replacements</a></li>
</ul>
<small>[ total of 1139 entries:  <b>1-1139</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
