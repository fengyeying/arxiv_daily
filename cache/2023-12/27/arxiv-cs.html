<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 22 Dec 23  to  Tue 26 Dec 23, announced Wed, 27 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item550">Cross-lists</a></li>
<li><a href="#item616">Replacements</a></li>
</ul>
<small>[ total of 1023 entries:  <b>1-1023</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 27 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14930" title="Abstract">arXiv:2312.14930</a> [<a href="/pdf/2312.14930" title="Download PDF">pdf</a>, <a href="/ps/2312.14930" title="Download PostScript">ps</a>, <a href="/format/2312.14930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Digital Twin Network Architecture in the Industrial  Internet of Things (IIoT) Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isah%2C+A">Abubakar Isah</a> (1), 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hyeju Shin</a> (1), 
<a href="/search/cs?searchtype=author&query=Aliyu%2C+I">Ibrahim Aliyu</a> (1), 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sangwon Oh</a> (1), 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangjoon Lee</a> (2), 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehyung Park</a> (1), 
<a href="/search/cs?searchtype=author&query=Hahn%2C+M">Minsoo Hahn</a> (3), 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinsul Kim</a> ((1) Department of ICT Convergence System Engineering, Chonnam National University, Gwangju, Korea. (2) Interdisciplinary Program of Digital Future Convergence Service, Chonnam National University, Gwangju, Korea. (3) Astana IT University, Astana, Kazakhstan)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">A new network named the "Digital Twin Network" (DTN) uses the "Digital Twin"
(DT) technology to produce virtual twins of real things. The network load and
size continue to grow as a result of the development of 5G, the Internet of
Things, and cloud computing technology as well as the advent of new network
services. As a result, network operation and maintenance are becoming more
difficult. A digital twin connects the real and digital worlds, exchanging data
in both directions and revealing information about the progression of a network
process. The framework of the Industrial Internet of Things, data processing,
and digital twin network is taken into consideration in this article as a key
aspect. This paper proposed a data-driven digital twin network architecture,
that comprises the physical network layer (PNL), the digital twin layer(DTL),
the application layer (AL), and what those layers encompass and beyond. Also,
we presented DTN data types and protocols to be used for data integration.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14931" title="Abstract">arXiv:2312.14931</a> [<a href="/pdf/2312.14931" title="Download PDF">pdf</a>, <a href="/ps/2312.14931" title="Download PostScript">ps</a>, <a href="/format/2312.14931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parallel IFC Normalization Algorithm for Incremental Storage and  Version Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+M">Ming Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in: 30th International Workshop on Intelligent Computing in Engineering (EG-ICE), 2023: 511-520
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Industry Foundation Classes (IFC) files are commonly used for data exchange
of Building Information Models (BIMs). Due to the equivalent transformations in
the graph structure of IFC data, it is a challenge to perform version
comparison and incremental storage on IFC files. In this paper, an IFC
normalization method is proposed, which can reduce the influence of the
equivalent transformations, so that the normalized IFC file can be directly
used in Git-like tools for version comparison and incremental storage. The
algorithm is also designed for getting stable results when running on
multi-threads. Experiments show the efficiency of the algorithm and its
potential in Common Data Environment (CDE) applications.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14934" title="Abstract">arXiv:2312.14934</a> [<a href="/pdf/2312.14934" title="Download PDF">pdf</a>, <a href="/ps/2312.14934" title="Download PostScript">ps</a>, <a href="/format/2312.14934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> aoip.ai: An Open-Source P2P SDK
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konan%2C+J">Joseph Konan</a>, 
<a href="/search/cs?searchtype=author&query=Agnihotri%2C+S">Shikhar Agnihotri</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Chia-Chun Hsieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This white paper introduces aoip.ai, a groundbreaking open-source SDK
incorporating peer-to-peer technology and advanced AI integration to transform
VoIP and IoT applications. It addresses key market challenges by enhancing data
security, elevating communication quality, and providing greater flexibility
for developers and users. Developed in collaboration with Carnegie Mellon
University, aoip.ai sets a new standard for decentralized and democratized
communication solutions.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14935" title="Abstract">arXiv:2312.14935</a> [<a href="/pdf/2312.14935" title="Download PDF">pdf</a>, <a href="/ps/2312.14935" title="Download PostScript">ps</a>, <a href="/format/2312.14935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AS-XAI: Self-supervised Automatic Semantic Interpretation for CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongxiao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainable artificial intelligence (XAI) aims to develop transparent
explanatory approaches for "black-box" deep learning models. However,it remains
difficult for existing methods to achieve the trade-off of the three key
criteria in interpretability, namely, reliability, causality, and usability,
which hinder their practical applications. In this paper, we propose a
self-supervised automatic semantic interpretable explainable artificial
intelligence (AS-XAI) framework, which utilizes transparent orthogonal
embedding semantic extraction spaces and row-centered principal component
analysis (PCA) for global semantic interpretation of model decisions in the
absence of human interference, without additional computational costs. In
addition, the invariance of filter feature high-rank decomposition is used to
evaluate model sensitivity to different semantic concepts. Extensive
experiments demonstrate that robust and orthogonal semantic spaces can be
automatically extracted by AS-XAI, providing more effective global
interpretability for convolutional neural networks (CNNs) and generating
human-comprehensible explanations. The proposed approach offers broad
fine-grained extensible practical applications, including shared semantic
interpretation under out-of-distribution (OOD) categories, auxiliary
explanations for species that are challenging to distinguish, and
classification explanations from various perspectives.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14937" title="Abstract">arXiv:2312.14937</a> [<a href="/pdf/2312.14937" title="Download PDF">pdf</a>, <a href="/format/2312.14937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi-Hua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang-Tian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xiaoyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Novel view synthesis for dynamic scenes is still a challenging problem in
computer vision and graphics. Recently, Gaussian splatting has emerged as a
robust technique to represent static scenes and enable high-quality and
real-time novel view synthesis. Building upon this technique, we propose a new
representation that explicitly decomposes the motion and appearance of dynamic
scenes into sparse control points and dense Gaussians, respectively. Our key
idea is to use sparse control points, significantly fewer in number than the
Gaussians, to learn compact 6 DoF transformation bases, which can be locally
interpolated through learned interpolation weights to yield the motion field of
3D Gaussians. We employ a deformation MLP to predict time-varying 6 DoF
transformations for each control point, which reduces learning complexities,
enhances learning abilities, and facilitates obtaining temporal and spatial
coherent motion patterns. Then, we jointly learn the 3D Gaussians, the
canonical space locations of control points, and the deformation MLP to
reconstruct the appearance, geometry, and dynamics of 3D scenes. During
learning, the location and number of control points are adaptively adjusted to
accommodate varying motion complexities in different regions, and an ARAP loss
following the principle of as rigid as possible is developed to enforce spatial
continuity and local rigidity of learned motions. Finally, thanks to the
explicit sparse motion representation and its decomposition from appearance,
our method can enable user-controlled motion editing while retaining
high-fidelity appearances. Extensive experiments demonstrate that our approach
outperforms existing approaches on novel view synthesis with a high rendering
speed and enables novel appearance-preserved motion editing applications.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14941" title="Abstract">arXiv:2312.14941</a> [<a href="/pdf/2312.14941" title="Download PDF">pdf</a>, <a href="/format/2312.14941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Criteria Client Selection and Scheduling with Fairness Guarantee  for Federated Learning Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meiying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ebron%2C+S">Sheldon Ebron</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruitao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) enables multiple clients to train machine learning
models collaboratively without sharing the raw training data. However, for a
given FL task, how to select a group of appropriate clients fairly becomes a
challenging problem due to budget restrictions and client heterogeneity. In
this paper, we propose a multi-criteria client selection and scheduling scheme
with a fairness guarantee, comprising two stages: 1) preliminary client pool
selection, and 2) per-round client scheduling. Specifically, we first define a
client selection metric informed by several criteria, such as client resources,
data quality, and client behaviors. Then, we formulate the initial client pool
selection problem into an optimization problem that aims to maximize the
overall scores of selected clients within a given budget and propose a greedy
algorithm to solve it. To guarantee fairness, we further formulate the
per-round client scheduling problem and propose a heuristic algorithm to divide
the client pool into several subsets such that every client is selected at
least once while guaranteeing that the `integrated' dataset in a subset is
close to an independent and identical distribution (iid). Our experimental
results show that our scheme can improve the model quality especially when data
are non-iid.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14942" title="Abstract">arXiv:2312.14942</a> [<a href="/pdf/2312.14942" title="Download PDF">pdf</a>, <a href="/ps/2312.14942" title="Download PostScript">ps</a>, <a href="/format/2312.14942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liquid State Genetic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oltean%2C+M">Mihai Oltean</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, ICANNGA 2007, Lecture Notes in Computer Science, pp 220-229, vol 4431. Springer. arXiv admin note: text overlap with <a href="/abs/2110.02014">arXiv:2110.02014</a>, <a href="/abs/2111.14790">arXiv:2111.14790</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Beliczynski, B., Dzielinski, A., Iwanowski, M., Ribeiro, B.
  (eds) Adaptive and Natural Computing Algorithms. ICANNGA 2007. Lecture Notes
  in Computer Science, vol 4431. Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A new Genetic Programming variant called Liquid State Genetic Programming
(LSGP) is proposed in this paper. LSGP is a hybrid method combining a dynamic
memory for storing the inputs (the liquid) and a Genetic Programming technique
used for the problem solving part. Several numerical experiments with LSGP are
performed by using several benchmarking problems. Numerical experiments show
that LSGP performs similarly and sometimes even better than standard Genetic
Programming for the considered test problems.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14943" title="Abstract">arXiv:2312.14943</a> [<a href="/pdf/2312.14943" title="Download PDF">pdf</a>, <a href="/format/2312.14943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flood Event Extraction from News Media to Support Satellite-Based Flood  Insurance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pabari%2C+T">Tejit Pabari</a>, 
<a href="/search/cs?searchtype=author&query=Tellman%2C+B">Beth Tellman</a>, 
<a href="/search/cs?searchtype=author&query=Karamanolakis%2C+G">Giannis Karamanolakis</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+M">Mitchell Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Mauerman%2C+M">Max Mauerman</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+E">Eugene Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lall%2C+U">Upmanu Lall</a>, 
<a href="/search/cs?searchtype=author&query=Tedesco%2C+M">Marco Tedesco</a>, 
<a href="/search/cs?searchtype=author&query=Steckler%2C+M+S">Michael S Steckler</a>, 
<a href="/search/cs?searchtype=author&query=Colosio%2C+P">Paolo Colosio</a>, 
<a href="/search/cs?searchtype=author&query=Osgood%2C+D+E">Daniel E Osgood</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+M">Melody Braun</a>, 
<a href="/search/cs?searchtype=author&query=de+Bruijn%2C+J">Jens de Bruijn</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+S">Shammun Islam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Floods cause large losses to property, life, and livelihoods across the world
every year, hindering sustainable development. Safety nets to help absorb
financial shocks in disasters, such as insurance, are often unavailable in
regions of the world most vulnerable to floods, like Bangladesh. Index-based
insurance has emerged as an affordable solution, which considers weather data
or information from satellites to create a "flood index" that should correlate
with the damage insured. However, existing flood event databases are often
incomplete, and satellite sensors are not reliable under extreme weather
conditions (e.g., because of clouds), which limits the spatial and temporal
resolution of current approaches for index-based insurance.
<br />In this work, we explore a novel approach for supporting satellite-based
flood index insurance by extracting high-resolution spatio-temporal information
from news media. First, we publish a dataset consisting of 40,000 news articles
covering flood events in Bangladesh by 10 prominent news sources, and inundated
area estimates for each division in Bangladesh collected from a satellite radar
sensor. Second, we show that keyword-based models are not adequate for this
novel application, while context-based classifiers cover complex and implicit
flood related patterns. Third, we show that time series extracted from news
media have substantial correlation Spearman's rho$=0.70 with satellite
estimates of inundated area. Our work demonstrates that news media is a
promising source for improving the temporal resolution and expanding the
spatial coverage of the available flood damage data.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14945" title="Abstract">arXiv:2312.14945</a> [<a href="/pdf/2312.14945" title="Download PDF">pdf</a>, <a href="/ps/2312.14945" title="Download PostScript">ps</a>, <a href="/format/2312.14945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering ChatGPT-Like Large-Scale Language Models with Local Knowledge  Base for Industrial Prognostics and Health Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan-Fu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Min Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Prognostics and health management (PHM) is essential for industrial operation
and maintenance, focusing on predicting, diagnosing, and managing the health
status of industrial systems. The emergence of the ChatGPT-Like large-scale
language model (LLM) has begun to lead a new round of innovation in the AI
field. It has extensively promoted the level of intelligence in various fields.
Therefore, it is also expected further to change the application paradigm in
industrial PHM and promote PHM to become intelligent. Although ChatGPT-Like
LLMs have rich knowledge reserves and powerful language understanding and
generation capabilities, they lack domain-specific expertise, significantly
limiting their practicability in PHM applications. To this end, this study
explores the ChatGPT-Like LLM empowered by the local knowledge base (LKB) in
industrial PHM to solve the above limitations. In addition, we introduce the
method and steps of combining the LKB with LLMs, including LKB preparation, LKB
vectorization, prompt engineering, etc. Experimental analysis of real cases
shows that combining the LKB with ChatGPT-Like LLM can significantly improve
its performance and make ChatGPT-Like LLMs more accurate, relevant, and able to
provide more insightful information. This can promote the development of
ChatGPT-Like LLMs in industrial PHM and promote their efficiency and quality.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14947" title="Abstract">arXiv:2312.14947</a> [<a href="/pdf/2312.14947" title="Download PDF">pdf</a>, <a href="/ps/2312.14947" title="Download PostScript">ps</a>, <a href="/format/2312.14947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radio-Enabled Low Power IoT Devices for TinyML Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonneau%2C+A">Antoine Bonneau</a> (DYNAMID, EE), 
<a href="/search/cs?searchtype=author&query=Mieyeville%2C+F">Fabien Mieyeville</a> (INL, EE), 
<a href="/search/cs?searchtype=author&query=Mou%C3%ABl%2C+F+L">Fr&#xe9;d&#xe9;ric Le Mou&#xeb;l</a> (DYNAMID), 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+R">Regis Rousseau</a> (SOCRATE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The proliferation of Internet of Things (IoT) devices has intensified the
demand for energyefficient solutions supporting ondevice and distributed
learning applications. This re search presents a circumscribed comparative
analysis of radioenabled ultralow power IoT devices, specifically focusing on
their suitability for computationheavy use cases. Our analysis centers on
middleend IoT devices that serve as a vital interface between the Electronics
and Machine Learn ing communities. The evaluation encompasses a diverse range
of IoT hardware equipped with inte grated radios. We established functional
datasheetbased criteria completed with accessibility and communitywise criteria
to study and offer valuable insights into each selected node's performance
tradeoffs, strengths, and weaknesses. This study provides crucial guidance for
TinyML practitioners seeking to make informed device selections for their
applications.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14948" title="Abstract">arXiv:2312.14948</a> [<a href="/pdf/2312.14948" title="Download PDF">pdf</a>, <a href="/format/2312.14948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evolving Population Approach to Data-Stream Classification with  Extreme Verification Latency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahy%2C+C">Conor Fahy</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shengxiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recognising and reacting to change in non-stationary data-streams is a
challenging task. The majority of research in this area assumes that the true
class label of incoming points are available, either at each time step or
intermittently with some latency. In the worse case this latency approaches
infinity and we can assume that no labels are available beyond the initial
training set. When change is expected and no further training labels are
provided the challenge of maintaining a high classification accuracy is very
great. The challenge is to propagate the original training information through
several timesteps, possibly indefinitely, while adapting to underlying change
in the data-stream. In this paper we conduct an initial study into the
effectiveness of using an evolving, population-based approach as the mechanism
for adapting to change. An ensemble of one-class-classifiers is maintained for
each class. Each classifier is considered as an agent in the sub-population and
is subject to selection pressure to find interesting areas of the feature
space. This selection pressure forces the ensemble to adapt to the underlying
change in the data-stream.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14949" title="Abstract">arXiv:2312.14949</a> [<a href="/pdf/2312.14949" title="Download PDF">pdf</a>, <a href="/format/2312.14949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Interactive Optimization of Open Source Python Libraries -- Case  Studies and Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Florath%2C+A">Andreas Florath</a>, 
<a href="/search/cs?searchtype=author&query=Kiraly%2C+F">Franz Kiraly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Performance (cs.PF)

</div>
<p class="mathjax">With the advent of large language models (LLMs) like GPT-3, a natural
question is the extent to which these models can be utilized for source code
optimization. This paper presents methodologically stringent case studies
applied to well-known open source python libraries pillow and numpy. We find
that contemporary LLM ChatGPT-4 (state September and October 2023) is
surprisingly adept at optimizing energy and compute efficiency. However, this
is only the case in interactive use, with a human expert in the loop. Aware of
experimenter bias, we document our qualitative approach in detail, and provide
transcript and source code. We start by providing a detailed description of our
approach in conversing with the LLM to optimize the _getextrema function in the
pillow library, and a quantitative evaluation of the performance improvement.
To demonstrate qualitative replicability, we report further attempts on another
locus in the pillow library, and one code locus in the numpy library, to
demonstrate generalization within and beyond a library. In all attempts, the
performance improvement is significant (factor up to 38). We have also not
omitted reporting of failed attempts (there were none). We conclude that LLMs
are a promising tool for code optimization in open source libraries, but that
the human expert in the loop is essential for success. Nonetheless, we were
surprised by how few iterations were required to achieve substantial
performance improvements that were not obvious to the expert in the loop. We
would like bring attention to the qualitative nature of this study, more robust
quantitative studies would need to introduce a layer of selecting experts in a
representative sample -- we invite the community to collaborate.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14950" title="Abstract">arXiv:2312.14950</a> [<a href="/pdf/2312.14950" title="Download PDF">pdf</a>, <a href="/format/2312.14950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TypeFly: Flying Drones with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaojing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lin Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Commanding a drone with a natural language is not only user-friendly but also
opens the door for emerging language agents to control the drone. Emerging
large language models (LLMs) provide a previously impossible opportunity to
automatically translate a task description in a natural language to a program
that can be executed by the drone. However, powerful LLMs and their vision
counterparts are limited in three important ways. First, they are only
available as cloud-based services. Sending images to the cloud raises privacy
concerns. Second, they are expensive, costing proportionally to the request
size. Finally, without expensive fine-tuning, existing LLMs are quite limited
in their capability of writing a program for specialized systems like drones.
<br />In this paper, we present a system called TypeFly that tackles the above
three problems using a combination of edge-based vision intelligence, novel
programming language design, and prompt engineering. Instead of the familiar
Python, TypeFly gets a cloud-based LLM service to write a program in a small,
custom language called MiniSpec, based on task and scene descriptions in
English. Such MiniSpec programs are not only succinct (and therefore efficient)
but also able to consult the LLM during their execution using a special skill
called query. Using a set of increasingly challenging drone tasks, we show that
design choices made by TypeFly can reduce both the cost of LLM service and the
task execution time by more than 2x. More importantly, query and prompt
engineering techniques contributed by TypeFly significantly improve the chance
of success of complex tasks.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14952" title="Abstract">arXiv:2312.14952</a> [<a href="/pdf/2312.14952" title="Download PDF">pdf</a>, <a href="/format/2312.14952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cascaded Neural Network System For Rating Student Performance In  Surgical Knot Tying Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yunzhe Xue</a>, 
<a href="/search/cs?searchtype=author&query=Eletta%2C+O">Olanrewaju Eletta</a>, 
<a href="/search/cs?searchtype=author&query=Ady%2C+J+W">Justin W. Ady</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+N+M">Nell M. Patel</a>, 
<a href="/search/cs?searchtype=author&query=Bongu%2C+A">Advaith Bongu</a>, 
<a href="/search/cs?searchtype=author&query=Roshan%2C+U">Usman Roshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in proceedings of 11th IEEE International Conference on Healthcare Informatics (ICHI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">As part of their training all medical students and residents have to pass
basic surgical tasks such as knot tying, needle-passing, and suturing. Their
assessment is typically performed in the operating room by surgical faculty
where mistakes and failure by the student increases the operation time and
cost. This evaluation is quantitative and has a low margin of error. Simulation
has emerged as a cost effective option but it lacks assessment or requires
additional expensive hardware for evaluation. Apps that provide training videos
on surgical knot trying are available to students but none have evaluation. We
propose a cascaded neural network architecture that evaluates a student's
performance just from a video of themselves simulating a surgical knot tying
task. Our model converts video frame images into feature vectors with a
pre-trained deep convolutional network and then models the sequence of frames
with a temporal network. We obtained videos of medical students and residents
from the Robert Wood Johnson Hospital performing knot tying on a standardized
simulation kit. We manually annotated each video and proceeded to do a
five-fold cross-validation study on them. Our model achieves a median
precision, recall, and F1-score of 0.71, 0.66, and 0.65 respectively in
determining the level of knot related tasks of tying and pushing the knot. Our
mean precision score averaged across different probability thresholds is 0.8.
Both our F1-score and mean precision score are 8% and 30% higher than that of a
recently published study for the same problem. We expect the accuracy of our
model to further increase as we add more training videos to the model thus
making it a practical solution that students can use to evaluate themselves.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14954" title="Abstract">arXiv:2312.14954</a> [<a href="/pdf/2312.14954" title="Download PDF">pdf</a>, <a href="/format/2312.14954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Co-Design as a Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vineyard%2C+C+M">Craig M. Vineyard</a>, 
<a href="/search/cs?searchtype=author&query=Severa%2C+W+M">William M. Severa</a>, 
<a href="/search/cs?searchtype=author&query=Aimone%2C+J+B">James B. Aimone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, accepted to First Workshop on Machine Learning with New Compute Paradigms at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Co-design is a prominent topic presently in computing, speaking to the mutual
benefit of coordinating design choices of several layers in the technology
stack. For example, this may be designing algorithms which can most efficiently
take advantage of the acceleration properties of a given architecture, while
simultaneously designing the hardware to support the structural needs of a
class of computation. The implications of these design decisions are
influential enough to be deemed a lottery, enabling an idea to win out over
others irrespective of the individual merits. Coordination is a well studied
topic in the mathematics of game theory, where in many cases without a
coordination mechanism the outcome is sub-optimal. Here we consider what
insights game theoretic analysis can offer for computer architecture co-design.
In particular, we consider the interplay between algorithm and architecture
advances in the field of neuromorphic computing. Analyzing developments of
spiking neural network algorithms and neuromorphic hardware as a co-design game
we use the Stag Hunt model to illustrate challenges for spiking algorithms or
architectures to advance the field independently and advocate for a strategic
pursuit to advance neuromorphic computing.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14957" title="Abstract">arXiv:2312.14957</a> [<a href="/pdf/2312.14957" title="Download PDF">pdf</a>, <a href="/format/2312.14957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Session-Based Recommendation by Exploiting Substitutable and  Complementary Relationships from Multi-behavior Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huizi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+C">Cong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hui Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Session-based recommendation (SR) aims to dynamically recommend items to a
user based on a sequence of the most recent user-item interactions. Most
existing studies on SR adopt advanced deep learning methods. However, the
majority only consider a special behavior type (e.g., click), while those few
considering multi-typed behaviors ignore to take full advantage of the
relationships between products (items). In this case, the paper proposes a
novel approach, called Substitutable and Complementary Relationships from
Multi-behavior Data (denoted as SCRM) to better explore the relationships
between products for effective recommendation. Specifically, we firstly
construct substitutable and complementary graphs based on a user's sequential
behaviors in every session by jointly considering `click' and `purchase'
behaviors. We then design a denoising network to remove false relationships,
and further consider constraints on the two relationships via a particularly
designed loss function. Extensive experiments on two e-commerce datasets
demonstrate the superiority of our model over state-of-the-art methods, and the
effectiveness of every component in SCRM.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14958" title="Abstract">arXiv:2312.14958</a> [<a href="/pdf/2312.14958" title="Download PDF">pdf</a>, <a href="/format/2312.14958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Network-Based Bandwidth Allocation for Secure Wireless  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yeoh%2C+P+L">Phee Lep Yeoh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+C">Changyang She</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+B">Branka Vucetic</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper designs a graph neural network (GNN) to improve bandwidth
allocations for multiple legitimate wireless users transmitting to a base
station in the presence of an eavesdropper. To improve the privacy and prevent
eavesdropping attacks, we propose a user scheduling algorithm to schedule users
satisfying an instantaneous minimum secrecy rate constraint. Based on this, we
optimize the bandwidth allocations with three algorithms namely iterative
search (IvS), GNN-based supervised learning (GNN-SL), and GNN-based
unsupervised learning (GNN-USL). We present a computational complexity analysis
which shows that GNN-SL and GNN-USL can be more efficient compared to IvS which
is limited by the bandwidth block size. Numerical simulation results highlight
that our proposed GNN-based resource allocations can achieve a comparable sum
secrecy rate compared to IvS with significantly lower computational complexity.
Furthermore, we observe that the GNN approach is more robust to uncertainties
in the eavesdropper's channel state information, especially compared with the
best channel allocation scheme.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14963" title="Abstract">arXiv:2312.14963</a> [<a href="/pdf/2312.14963" title="Download PDF">pdf</a>, <a href="/format/2312.14963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Mario Adventures in a Constrained Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sanyam Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This project proposes and compares a new way to optimise Super Mario Bros.
(SMB) environment where the control is in hand of two approaches, namely,
Genetic Algorithm (MarioGA) and NeuroEvolution (MarioNE). Not only we learn
playing SMB using these techniques, but also optimise it with constrains of
collection of coins and finishing levels. Firstly, we formalise the SMB agent
to maximize the total value of collected coins (reward) and maximising the
total distance traveled (reward) in order to finish the level faster (time
penalty) for both the algorithms. Secondly, we study MarioGA and its evaluation
function (fitness criteria) including its representation methods, crossover
used, mutation operator formalism, selection method used, MarioGA loop, and few
other parameters. Thirdly, MarioNE is applied on SMB where a population of ANNs
with random weights is generated, and these networks control Marios actions in
the game. Fourth, SMB is further constrained to complete the task within the
specified time, rebirths (deaths) within the limit, and performs actions or
moves within the maximum allowed moves, while seeking to maximize the total
coin value collected. This ensures an efficient way of finishing SMB levels.
Finally, we provide a fivefold comparative analysis by plotting fitness plots,
ability to finish different levels of world 1, and domain adaptation (transfer
learning) of the trained models.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14964" title="Abstract">arXiv:2312.14964</a> [<a href="/pdf/2312.14964" title="Download PDF">pdf</a>, <a href="/format/2312.14964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effectful Semantics in 2-Dimensional Categories: Premonoidal and Freyd  Bicategories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paquet%2C+H">Hugo Paquet</a> (LIPN, Universit&#xe9; Sorbonne Paris Nord), 
<a href="/search/cs?searchtype=author&query=Saville%2C+P">Philip Saville</a> (University of Oxford)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 190-209
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Premonoidal categories and Freyd categories provide an encompassing framework
for the semantics of call-by-value programming languages. Premonoidal
categories are a weakening of monoidal categories in which the interchange law
for the tensor product may not hold, modelling the fact that effectful programs
cannot generally be re-ordered. A Freyd category is a pair of categories with
the same objects: a premonoidal category of general programs, and a monoidal
category of 'effect-free' programs which do admit re-ordering.
<br />Certain recent innovations in semantics, however, have produced models which
are not categories but bicategories. Here we develop the theory to capture such
examples by introducing premonoidal and Freyd structure in a bicategorical
setting. The second dimension introduces new subtleties, so we verify our
definitions with several examples and a correspondence theorem (between Freyd
bicategories and certain actions of monoidal bicategories) which parallels the
categorical framework.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14965" title="Abstract">arXiv:2312.14965</a> [<a href="/pdf/2312.14965" title="Download PDF">pdf</a>, <a href="/format/2312.14965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Temporal Dynamics of the Unet in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+V">Vidya Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Zhu-Tian%2C+C">Chen Zhu-Tian</a>, 
<a href="/search/cs?searchtype=author&query=Vilanova%2C+A">Anna Vilanova</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+H">Hanspeter Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Pezzotti%2C+N">Nicola Pezzotti</a>, 
<a href="/search/cs?searchtype=author&query=Strobelt%2C+H">Hendrik Strobelt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have garnered significant attention since they can
effectively learn complex multivariate Gaussian distributions, resulting in
diverse, high-quality outcomes. They introduce Gaussian noise into training
data and reconstruct the original data iteratively. Central to this iterative
process is a single Unet, adapting across time steps to facilitate generation.
Recent work revealed the presence of composition and denoising phases in this
generation process, raising questions about the Unets' varying roles. Our study
dives into the dynamic behavior of Unets within denoising diffusion
probabilistic models (DDPM), focusing on (de)convolutional blocks and skip
connections across time steps. We propose an analytical method to
systematically assess the impact of time steps and core Unet components on the
final output. This method eliminates components to study causal relations and
investigate their influence on output changes. The main purpose is to
understand the temporal dynamics and identify potential shortcuts during
inference. Our findings provide valuable insights into the various generation
phases during inference and shed light on the Unets' usage patterns across
these phases. Leveraging these insights, we identify redundancies in GLIDE (an
improved DDPM) and improve inference time by ~27% with minimal degradation in
output quality. Our ultimate goal is to guide more informed optimization
strategies for inference and influence new model designs.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14966" title="Abstract">arXiv:2312.14966</a> [<a href="/pdf/2312.14966" title="Download PDF">pdf</a>, <a href="/ps/2312.14966" title="Download PostScript">ps</a>, <a href="/format/2312.14966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Syntax Mapping: A New Approach to Unsupervised Syntax Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gohsh%2C+B">Buvarp Gohsh</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+W">Woods Ali</a>, 
<a href="/search/cs?searchtype=author&query=Michael%2C+A">Anders Michael</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The intricate hierarchical structure of syntax is fundamental to the
intricate and systematic nature of human language. This study investigates the
premise that language models, specifically their attention distributions, can
encapsulate syntactic dependencies. We introduce Dynamic Syntax Mapping (DSM),
an innovative approach for the agnostic induction of these structures. Our
method diverges from traditional syntax models which rely on predefined
annotation schemata. Instead, we focus on a core characteristic inherent in
dependency relations: syntactic substitutability. This concept refers to the
interchangeability of words within the same syntactic category at either end of
a dependency. By leveraging this property, we generate a collection of
syntactically invariant sentences, which serve as the foundation for our
parsing framework. Our findings reveal that the use of an increasing array of
substitutions notably enhances parsing precision on natural language data.
Specifically, in the context of long-distance subject-verb agreement, DSM
exhibits a remarkable advancement over prior methodologies. Furthermore, DSM's
adaptability is demonstrated through its successful application in varied
parsing scenarios, underscoring its broad applicability.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14967" title="Abstract">arXiv:2312.14967</a> [<a href="/pdf/2312.14967" title="Download PDF">pdf</a>, <a href="/ps/2312.14967" title="Download PostScript">ps</a>, <a href="/format/2312.14967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Armed Bandit Learning for Content Provisioning in Network of UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhuyan%2C+A+K">Amit Kumar Bhuyan</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+H">Hrishikesh Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Subir Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table and 1 Algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes an unmanned aerial vehicle (UAV) aided content management
system in communication-challenged disaster scenarios. Without cellular
infrastructure in such scenarios, community of stranded users can be provided
access to situation-critical contents using a hybrid network of static and
traveling UAVs. A set of relatively static anchor UAVs can download content
from central servers and provide content access to its local users. A set of
ferrying UAVs with wider mobility can provision content to users by shuffling
them across different anchor UAVs while visiting different communities of
users. The objective is to design a content dissemination system that
on-the-fly learns content caching policies for maximizing content availability
to the stranded users. This paper proposes a decentralized Top-k Multi-Armed
Bandit Learning model for UAV-caching decision-making that takes geo-temporal
differences in content popularity and heterogeneity in content demands into
consideration. The proposed paradigm is able to combine the expected reward
maximization attribute and a proposed multi-dimensional reward structure of
Top-k Multi-Armed Bandit, for caching decision at the UAVs. This study is done
for different user-specified tolerable access delay, heterogeneous popularity
distributions, and inter-community geographical characteristics. Functional
verification and performance evaluation of the proposed caching framework is
done for a wide range of network size, UAV distribution, and content
popularity.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14969" title="Abstract">arXiv:2312.14969</a> [<a href="/pdf/2312.14969" title="Download PDF">pdf</a>, <a href="/format/2312.14969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Opportunities of Moderating Usage of Large Language  Models in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krupp%2C+L">Lars Krupp</a>, 
<a href="/search/cs?searchtype=author&query=Steinert%2C+S">Steffen Steinert</a>, 
<a href="/search/cs?searchtype=author&query=Kiefer-Emmanouilidis%2C+M">Maximilian Kiefer-Emmanouilidis</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+K+E">Karina E. Avila</a>, 
<a href="/search/cs?searchtype=author&query=Lukowicz%2C+P">Paul Lukowicz</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+J">Jochen Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCchemann%2C+S">Stefan K&#xfc;chemann</a>, 
<a href="/search/cs?searchtype=author&query=Karolus%2C+J">Jakob Karolus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper consists of 13 pages 6 figures; supplementary material 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The increased presence of large language models (LLMs) in educational
settings has ignited debates concerning negative repercussions, including
overreliance and inadequate task reflection. Our work advocates moderated usage
of such models, designed in a way that supports students and encourages
critical thinking. We developed two moderated interaction methods with ChatGPT:
hint-based assistance and presenting multiple answer choices. In a study with
students (N=40) answering physics questions, we compared the effects of our
moderated models against two baseline settings: unmoderated ChatGPT access and
internet searches. We analyzed the interaction strategies and found that the
moderated versions exhibited less unreflected usage (e.g., copy \&amp; paste)
compared to the unmoderated condition. However, neither ChatGPT-supported
condition could match the ratio of reflected usage present in internet
searches. Our research highlights the potential benefits of moderating language
models, showing a research direction toward designing effective AI-supported
educational strategies.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14972" title="Abstract">arXiv:2312.14972</a> [<a href="/pdf/2312.14972" title="Download PDF">pdf</a>, <a href="/format/2312.14972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Down to Scale Up: A Cost-Benefit Analysis of Replacing OpenAI&#x27;s  GPT-4 with Self-Hosted Open Source SLMs in Production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irugalbandara%2C+C">Chandra Irugalbandara</a>, 
<a href="/search/cs?searchtype=author&query=Mahendra%2C+A">Ashish Mahendra</a>, 
<a href="/search/cs?searchtype=author&query=Daynauth%2C+R">Roland Daynauth</a>, 
<a href="/search/cs?searchtype=author&query=Arachchige%2C+T+K">Tharuka Kasthuri Arachchige</a>, 
<a href="/search/cs?searchtype=author&query=Flautner%2C+K">Krisztian Flautner</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lingjia Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yiping Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mars%2C+J">Jason Mars</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Many companies rely on APIs of managed AI models such as OpenAI's GPT-4 to
create AI-enabled experiences in their products. Along with the benefits of
ease of use and shortened time to production, this reliance on proprietary APIs
has downsides in terms of model control, performance reliability, up-time
predictability, and cost. At the same time, there has been a flurry of open
source small language models (SLMs) that have been made available for
commercial use. However, their readiness to replace existing capabilities
remains unclear, and a systematic approach to test these models is not readily
available. In this paper, we present a systematic evaluation methodology for,
and characterization of, modern open source SLMs and their trade-offs when
replacing a proprietary LLM APIs for a real-world product feature. We have
designed SLaM, an automated analysis tool that enables the quantitative and
qualitative testing of product features utilizing arbitrary SLMs. Using SLaM,
we examine both the quality and the performance characteristics of modern SLMs
relative to an existing customer-facing OpenAI-based implementation. We find
that across 9 SLMs and 29 variants, we observe competitive quality-of-results
for our use case, significant performance consistency improvement, and a cost
reduction of 5x-29x when compared to OpenAI GPT-4.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14973" title="Abstract">arXiv:2312.14973</a> [<a href="/pdf/2312.14973" title="Download PDF">pdf</a>, <a href="/format/2312.14973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Visualization of Time-Varying Flow Fields Using Particle  Tracing Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mengjiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jixian Li</a>, 
<a href="/search/cs?searchtype=author&query=Sane%2C+S">Sudhanshu Sane</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shubham Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Petruzza%2C+S">Steve Petruzza</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+C+R">Chris R. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this paper, we present a comprehensive evaluation to establish a robust
and efficient framework for Lagrangian-based particle tracing using deep neural
networks (DNNs). Han et al. (2021) first proposed a DNN-based approach to learn
Lagrangian representations and demonstrated accurate particle tracing for an
analytic 2D flow field. In this paper, we extend and build upon this prior work
in significant ways. First, we evaluate the performance of DNN models to
accurately trace particles in various settings, including 2D and 3D
time-varying flow fields, flow fields from multiple applications, flow fields
with varying complexity, as well as structured and unstructured input data.
Second, we conduct an empirical study to inform best practices with respect to
particle tracing model architectures, activation functions, and training data
structures. Third, we conduct a comparative evaluation against prior techniques
that employ flow maps as input for exploratory flow visualization.
Specifically, we compare our extended model against its predecessor by Han et
al. (2021), as well as the conventional approach that uses triangulation and
Barycentric coordinate interpolation. Finally, we consider the integration and
adaptation of our particle tracing model with different viewers. We provide an
interactive web-based visualization interface by leveraging the efficiencies of
our framework, and perform high-fidelity interactive visualization by
integrating it with an OSPRay-based viewer. Overall, our experiments
demonstrate that using a trained DNN model to predict new particle trajectories
requires a low memory footprint and results in rapid inference. Following the
best practices for large 3D datasets, our deep learning approach is shown to
require approximately 46 times less memory while being more than 400 times
faster than the conventional methods.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14976" title="Abstract">arXiv:2312.14976</a> [<a href="/pdf/2312.14976" title="Download PDF">pdf</a>, <a href="/format/2312.14976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Harmony: Attaining Fairness in Diffusion-based Face Generation  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+B">Basudha Pal</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+A">Arunkumar Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Kathirvel%2C+R+P">Ram Prabhakar Kathirvel</a>, 
<a href="/search/cs?searchtype=author&query=O%27Toole%2C+A+J">Alice J. O&#x27;Toole</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Diffusion models have achieved great progress in face generation. However,
these models amplify the bias in the generation process, leading to an
imbalance in distribution of sensitive attributes such as age, gender and race.
This paper proposes a novel solution to this problem by balancing the facial
attributes of the generated images. We mitigate the bias by localizing the
means of the facial attributes in the latent space of the diffusion model using
Gaussian mixture models (GMM). Our motivation for choosing GMMs over other
clustering frameworks comes from the flexible latent structure of diffusion
model. Since each sampling step in diffusion models follows a Gaussian
distribution, we show that fitting a GMM model helps us to localize the
subspace responsible for generating a specific attribute. Furthermore, our
method does not require retraining, we instead localize the subspace on-the-fly
and mitigate the bias for generating a fair dataset. We evaluate our approach
on multiple face attribute datasets to demonstrate the effectiveness of our
approach. Our results demonstrate that our approach leads to a more fair data
generation in terms of representational fairness while preserving the quality
of generated samples.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14977" title="Abstract">arXiv:2312.14977</a> [<a href="/pdf/2312.14977" title="Download PDF">pdf</a>, <a href="/format/2312.14977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Generative Artificial Intelligence: An Introduction  for Applied Mathematicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higham%2C+C+F">Catherine F. Higham</a>, 
<a href="/search/cs?searchtype=author&query=Higham%2C+D+J">Desmond J. Higham</a>, 
<a href="/search/cs?searchtype=author&query=Grindrod%2C+P">Peter Grindrod</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative artificial intelligence (AI) refers to algorithms that create
synthetic but realistic output. Diffusion models currently offer state of the
art performance in generative AI for images. They also form a key component in
more general tools, including text-to-image generators and large language
models. Diffusion models work by adding noise to the available training data
and then learning how to reverse the process. The reverse operation may then be
applied to new random data in order to produce new outputs. We provide a brief
introduction to diffusion models for applied mathematicians and statisticians.
Our key aims are (a) to present illustrative computational examples, (b) to
give a careful derivation of the underlying mathematical formulas involved, and
(c) to draw a connection with partial differential equation (PDE) diffusion
models. We provide code for the computational experiments. We hope that this
topic will be of interest to advanced undergraduate students and postgraduate
students. Portions of the material may also provide useful motivational
examples for those who teach courses in stochastic processes, inference,
machine learning, PDEs or scientific computing.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14978" title="Abstract">arXiv:2312.14978</a> [<a href="/pdf/2312.14978" title="Download PDF">pdf</a>, <a href="/ps/2312.14978" title="Download PostScript">ps</a>, <a href="/format/2312.14978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Quantifying Sentiments of Financial News -- Are We Doing the Right  Things?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nath%2C+G">Gourab Nath</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+A">Arav Sood</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+A">Aanchal Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+S">Savi Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Manot%2C+K">Karan Manot</a>, 
<a href="/search/cs?searchtype=author&query=Durbaka%2C+S+K">Sree Kavya Durbaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to the 56th Annual Convention of ORSI and 10th International Conference on Business Analytics and Intelligence held at the Indian Institute of Science (IISc) during 18-20 December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Typical investors start off the day by going through the daily news to get an
intuition about the performance of the market. The speculations based on the
tone of the news ultimately shape their responses towards the market. Today,
computers are being trained to compute the news sentiment so that it can be
used as a variable to predict stock market movements and returns. Some
researchers have even developed news-based market indices to forecast stock
market returns. Majority of the research in the field of news sentiment
analysis has focussed on using libraries like Vader, Loughran-McDonald (LM),
Harvard IV and Pattern. However, are the popular approaches for measuring
financial news sentiment really approaching the problem of sentiment analysis
correctly? Our experiments suggest that measuring sentiments using these
libraries, especially for financial news, fails to depict the true picture and
hence may not be very reliable. Therefore, the question remains: What is the
most effective and accurate approach to measure financial news sentiment? Our
paper explores these questions and attempts to answer them through SENTInews: a
one-of-its-kind financial news sentiment analyzer customized to the Indian
context
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14979" title="Abstract">arXiv:2312.14979</a> [<a href="/pdf/2312.14979" title="Download PDF">pdf</a>, <a href="/format/2312.14979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stacked tensorial neural networks for reduced-order modeling of a  parametric partial differential equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+C+G">Caleb G. Wagner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Tensorial neural networks (TNNs) combine the successes of multilinear algebra
with those of deep learning to enable extremely efficient reduced-order models
of high-dimensional problems. Here, I describe a deep neural network
architecture that fuses multiple TNNs into a larger network, intended to solve
a broader class of problems than a single TNN. I evaluate this architecture,
referred to as a "stacked tensorial neural network" (STNN), on a parametric PDE
with three independent variables and three parameters. The three parameters
correspond to one PDE coefficient and two quantities describing the domain
geometry. The STNN provides an accurate reduced-order description of the
solution manifold over a wide range of parameters. There is also evidence of
meaningful generalization to parameter values outside its training data.
Finally, while the STNN architecture is relatively simple and problem agnostic,
it can be regularized to incorporate problem-specific features like symmetries
and physical modeling assumptions.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14980" title="Abstract">arXiv:2312.14980</a> [<a href="/pdf/2312.14980" title="Download PDF">pdf</a>, <a href="/format/2312.14980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPTNet: A Data-Driven Temperature Prediction Model Based on Turbulent  Potential Temperature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jun Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changhoon Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">A data-driven model for predicting the surface temperature using neural
networks was proposed to alleviate the computational burden of numerical
weather prediction (NWP). Our model, named TPTNet uses only 2m temperature
measured at the weather stations of the South Korean Peninsula as input to
predict the local temperature at finite forecast hours. The turbulent
fluctuation component of the temperature was extracted from the station
measurements by separating the climatology component accounting for the yearly
and daily variations. The effect of station altitude was then compensated by
introducing a potential temperature. The resulting turbulent potential
temperature data at irregularly distributed stations were used as input for
predicting the turbulent potential temperature at forecast hours through three
trained networks based on convolutional neural network (CNN), Swin Transformer,
and a graphic neural network (GNN). The prediction performance of our network
was compared with that of persistence and NWP, confirming that our model
outperformed NWP for up to 12 forecast hours.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14985" title="Abstract">arXiv:2312.14985</a> [<a href="/pdf/2312.14985" title="Download PDF">pdf</a>, <a href="/format/2312.14985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniHuman: A Unified Model for Editing Human Images in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nannan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K+K">Krishna Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhe Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human image editing includes tasks like changing a person's pose, their
clothing, or editing the image according to a text prompt. However, prior work
often tackles these tasks separately, overlooking the benefit of mutual
reinforcement from learning them jointly. In this paper, we propose UniHuman, a
unified model that addresses multiple facets of human image editing in
real-world settings. To enhance the model's generation quality and
generalization capacity, we leverage guidance from human visual encoders and
introduce a lightweight pose-warping module that can exploit different pose
representations, accommodating unseen textures and patterns. Furthermore, to
bridge the disparity between existing human editing benchmarks with real-world
data, we curated 400K high-quality human image-text pairs for training and
collected 2K human images for out-of-domain testing, both encompassing diverse
clothing styles, backgrounds, and age groups. Experiments on both in-domain and
out-of-domain test sets demonstrate that UniHuman outperforms task-specific
models by a significant margin. In user studies, UniHuman is preferred by the
users in an average of 77% of cases.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14988" title="Abstract">arXiv:2312.14988</a> [<a href="/pdf/2312.14988" title="Download PDF">pdf</a>, <a href="/format/2312.14988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emage: Non-Autoregressive Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhangyin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Runyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liangxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Duyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autoregressive and diffusion models drive the recent breakthroughs on
text-to-image generation. Despite their huge success of generating
high-realistic images, a common shortcoming of these models is their high
inference latency - autoregressive models run more than a thousand times
successively to produce image tokens and diffusion models convert Gaussian
noise into images with many hundreds of denoising steps. In this work, we
explore non-autoregressive text-to-image models that efficiently generate
hundreds of image tokens in parallel. We develop many model variations with
different learning and inference strategies, initialized text encoders, etc.
Compared with autoregressive baselines that needs to run one thousand times,
our model only runs 16 times to generate images of competitive quality with an
order of magnitude lower inference latency. Our non-autoregressive model with
346M parameters generates an image of 256$\times$256 with about one second on
one V100 GPU.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14990" title="Abstract">arXiv:2312.14990</a> [<a href="/pdf/2312.14990" title="Download PDF">pdf</a>, <a href="/format/2312.14990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Prompt Knowledge Transfer for Open-World Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the proceeding of AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper studies the problem of continual learning in an open-world
scenario, referred to as Open-world Continual Learning (OwCL). OwCL is
increasingly rising while it is highly challenging in two-fold: i) learning a
sequence of tasks without forgetting knowns in the past, and ii) identifying
unknowns (novel objects/classes) in the future. Existing OwCL methods suffer
from the adaptability of task-aware boundaries between knowns and unknowns, and
do not consider the mechanism of knowledge transfer. In this work, we propose
Pro-KT, a novel prompt-enhanced knowledge transfer model for OwCL. Pro-KT
includes two key components: (1) a prompt bank to encode and transfer both
task-generic and task-specific knowledge, and (2) a task-aware open-set
boundary to identify unknowns in the new tasks. Experimental results using two
real-world datasets demonstrate that the proposed Pro-KT outperforms the
state-of-the-art counterparts in both the detection of unknowns and the
classification of knowns markedly.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14991" title="Abstract">arXiv:2312.14991</a> [<a href="/pdf/2312.14991" title="Download PDF">pdf</a>, <a href="/format/2312.14991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoodLMM: A Versatile Food Assistant using Large Multi-modal Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuehao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Huiyan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+C">Chong-Wah Ngo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large Multi-modal Models (LMMs) have made impressive progress in many
vision-language tasks. Nevertheless, the performance of general LMMs in
specific domains is still far from satisfactory. This paper proposes FoodLMM, a
versatile food assistant based on LMMs with various capabilities, including
food recognition, ingredient recognition, recipe generation, nutrition
estimation, food segmentation and multi-round conversation. To facilitate
FoodLMM to deal with tasks beyond pure text output, we introduce a series of
novel task-specific tokens and heads, enabling the model to predict food
nutritional values and multiple segmentation masks. We adopt a two-stage
training strategy. In the first stage, we utilize multiple public food
benchmarks for multi-task learning by leveraging instruct-following paradigm.
In the second stage, we construct a multi-round conversation and a reasoning
segmentation datasets to fine-tune the model, enabling it to conduct
professional dialogues and generate segmentation masks based on complex
reasoning in food domain. Our fine-tuned FoodLMM achieves state-of-the-art
results across several food benchmarks. We will make our code, models and
datasets publicly available.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14996" title="Abstract">arXiv:2312.14996</a> [<a href="/pdf/2312.14996" title="Download PDF">pdf</a>, <a href="/ps/2312.14996" title="Download PostScript">ps</a>, <a href="/format/2312.14996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging AI and Clinical Practice: Integrating Automated Sleep Scoring  Algorithm with Uncertainty-Guided Physician Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bechny%2C+M">Michal Bechny</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Monachino%2C+G">Giuliana Monachino</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Fiorillo%2C+L">Luigi Fiorillo</a> (2), 
<a href="/search/cs?searchtype=author&query=van+der+Meer%2C+J">Julia van der Meer</a> (3), 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M+H">Markus H. Schmidt</a> (3 and 4), 
<a href="/search/cs?searchtype=author&query=Bassetti%2C+C+L+A">Claudio L. A. Bassetti</a> (3), 
<a href="/search/cs?searchtype=author&query=Tzovara%2C+A">Athina Tzovara</a> (1 and 5), 
<a href="/search/cs?searchtype=author&query=Faraci%2C+F+D">Francesca D. Faraci</a> (2) ((1) Institute of Computer Science, University of Bern, Bern, Switzerland (2) Institute of Digital Technologies for Personalized Healthcare (MeDiTech), University of Applied Sciences and Arts of Southern Switzerland, Lugano, Switzerland (3) Department of Neurology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland (4) Ohio Sleep Medicine Institute, Dublin, United States (5) Center for Experimental Neurology, Department of Neurology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Purpose: This study aims to enhance the clinical use of automated
sleep-scoring algorithms by incorporating an uncertainty estimation approach to
efficiently assist clinicians in the manual review of predicted hypnograms, a
necessity due to the notable inter-scorer variability inherent in
polysomnography (PSG) databases. Our efforts target the extent of review
required to achieve predefined agreement levels, examining both in-domain and
out-of-domain data, and considering subjects diagnoses. Patients and methods:
Total of 19578 PSGs from 13 open-access databases were used to train U-Sleep, a
state-of-the-art sleep-scoring algorithm. We leveraged a comprehensive clinical
database of additional 8832 PSGs, covering a full spectrum of ages and
sleep-disorders, to refine the U-Sleep, and to evaluate different
uncertainty-quantification approaches, including our novel confidence network.
The ID data consisted of PSGs scored by over 50 physicians, and the two OOD
sets comprised recordings each scored by a unique senior physician. Results:
U-Sleep demonstrated robust performance, with Cohen's kappa (K) at 76.2% on ID
and 73.8-78.8% on OOD data. The confidence network excelled at identifying
uncertain predictions, achieving AUROC scores of 85.7% on ID and 82.5-85.6% on
OOD data. Independently of sleep-disorder status, statistical evaluations
revealed significant differences in confidence scores between aligning vs
discording predictions, and significant correlations of confidence scores with
classification performance metrics. To achieve K of at least 90% with physician
intervention, examining less than 29.0% of uncertain epochs was required,
substantially reducing physicians workload, and facilitating near-perfect
agreement.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14998" title="Abstract">arXiv:2312.14998</a> [<a href="/pdf/2312.14998" title="Download PDF">pdf</a>, <a href="/format/2312.14998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic images aid the recognition of human-made art forgeries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ostmeyer%2C+J">Johann Ostmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Schaerf%2C+L">Ludovica Schaerf</a>, 
<a href="/search/cs?searchtype=author&query=Buividovich%2C+P">Pavel Buividovich</a>, 
<a href="/search/cs?searchtype=author&query=Charles%2C+T">Tessa Charles</a>, 
<a href="/search/cs?searchtype=author&query=Postma%2C+E">Eric Postma</a>, 
<a href="/search/cs?searchtype=author&query=Popovici%2C+C">Carina Popovici</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 + 10 pages, 9 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Previous research has shown that Artificial Intelligence is capable of
distinguishing between authentic paintings by a given artist and human-made
forgeries with remarkable accuracy, provided sufficient training. However, with
the limited amount of existing known forgeries, augmentation methods for
forgery detection are highly desirable. In this work, we examine the potential
of incorporating synthetic artworks into training datasets to enhance the
performance of forgery detection. Our investigation focuses on paintings by
Vincent van Gogh, for which we release the first dataset specialized for
forgery detection. To reinforce our results, we conduct the same analyses on
the artists Amedeo Modigliani and Raphael. We train a classifier to distinguish
original artworks from forgeries. For this, we use human-made forgeries and
imitations in the style of well-known artists and augment our training sets
with images in a similar style generated by Stable Diffusion and StyleGAN. We
find that the additional synthetic forgeries consistently improve the detection
of human-made forgeries. In addition, we find that, in line with previous
research, the inclusion of synthetic forgeries in the training also enables the
detection of AI-generated forgeries, especially if created using a similar
generator.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14999" title="Abstract">arXiv:2312.14999</a> [<a href="/pdf/2312.14999" title="Download PDF">pdf</a>, <a href="/format/2312.14999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Habitat Information for Fine-grained Bird Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tin Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional bird classifiers mostly rely on the visual characteristics of
birds. Some prior works even train classifiers to be invariant to the
background, completely discarding the living environment of birds. Instead, we
are the first to explore integrating habitat information, one of the four major
cues for identifying birds by ornithologists, into modern bird classifiers. We
focus on two leading model types: (1) CNNs and ViTs trained on the downstream
bird datasets; and (2) original, multi-modal CLIP. Training CNNs and ViTs with
habitat-augmented data results in an improvement of up to +0.83 and +0.23
points on NABirds and CUB-200, respectively. Similarly, adding habitat
descriptors to the prompts for CLIP yields a substantial accuracy boost of up
to +0.99 and +1.1 points on NABirds and CUB-200, respectively. We find
consistent accuracy improvement after integrating habitat features into the
image augmentation process and into the textual descriptors of vision-language
CLIP classifiers. Code is available at:
https://anonymous.4open.science/r/reasoning-8B7E/.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15000" title="Abstract">arXiv:2312.15000</a> [<a href="/pdf/2312.15000" title="Download PDF">pdf</a>, <a href="/format/2312.15000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Cloaking Digital Footprints on User Privacy and  Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goethals%2C+S">Sofie Goethals</a>, 
<a href="/search/cs?searchtype=author&query=Matz%2C+S">Sandra Matz</a>, 
<a href="/search/cs?searchtype=author&query=Provost%2C+F">Foster Provost</a>, 
<a href="/search/cs?searchtype=author&query=Ramon%2C+Y">Yanou Ramon</a>, 
<a href="/search/cs?searchtype=author&query=Martens%2C+D">David Martens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Our online lives generate a wealth of behavioral records -'digital
footprints'- which are stored and leveraged by technology platforms. This data
can be used to create value for users by personalizing services. At the same
time, however, it also poses a threat to people's privacy by offering a highly
intimate window into their private traits (e.g., their personality, political
ideology, sexual orientation). Prior work has proposed a potential remedy: The
cloaking of users' footprints. That is, platforms could allow users to hide
portions of their digital footprints from predictive algorithms to avoid
undesired inferences. While such an approach has been shown to offer privacy
protection in the moment, there are two open questions. First, it remains
unclear how well cloaking performs over time. As people constantly leave new
digital footprints, the algorithm might regain the ability to predict
previously cloaked traits. Second, cloaking digital footprints to avoid one
undesirable inference may degrade the performance of models for other,
desirable inferences (e.g., those driving desired personalized content). In the
light of these research gaps, our contributions are twofold: 1) We propose a
novel cloaking strategy that conceals 'metafeatures' (automatically generated
higher-level categories) and compares its effectiveness against existing
cloaking approaches, and 2) we test the spill-over effects of cloaking one
trait on the accuracy of inferences on other traits. A key finding is that the
effectiveness of cloaking degrades over times, but the rate at which it
degrades is significantly smaller when cloaking metafeatures rather than
individual footprints. In addition, our findings reveal the expected trade-off
between privacy and personalization: Cloaking an undesired trait also partially
conceals other desirable traits.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15001" title="Abstract">arXiv:2312.15001</a> [<a href="/pdf/2312.15001" title="Download PDF">pdf</a>, <a href="/format/2312.15001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering modular solutions that generalize compositionally
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schug%2C+S">Simon Schug</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+S">Seijin Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+Y">Yassir Akram</a>, 
<a href="/search/cs?searchtype=author&query=Wo%C5%82czyk%2C+M">Maciej Wo&#x142;czyk</a>, 
<a href="/search/cs?searchtype=author&query=Proca%2C+A">Alexandra Proca</a>, 
<a href="/search/cs?searchtype=author&query=von+Oswald%2C+J">Johannes von Oswald</a>, 
<a href="/search/cs?searchtype=author&query=Pascanu%2C+R">Razvan Pascanu</a>, 
<a href="/search/cs?searchtype=author&query=Sacramento%2C+J">Jo&#xe3;o Sacramento</a>, 
<a href="/search/cs?searchtype=author&query=Steger%2C+A">Angelika Steger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/smonsays/modular-hyperteacher">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Many complex tasks and environments can be decomposed into simpler,
independent parts. Discovering such underlying compositional structure has the
potential to expedite adaptation and enable compositional generalization.
Despite progress, our most powerful systems struggle to compose flexibly. While
most of these systems are monolithic, modularity promises to allow capturing
the compositional nature of many tasks. However, it is unclear under which
circumstances modular systems discover this hidden compositional structure. To
shed light on this question, we study a teacher-student setting with a modular
teacher where we have full control over the composition of ground truth
modules. This allows us to relate the problem of compositional generalization
to that of identification of the underlying modules. We show theoretically that
identification up to linear transformation purely from demonstrations is
possible in hypernetworks without having to learn an exponential number of
module combinations. While our theory assumes the infinite data limit, in an
extensive empirical study we demonstrate how meta-learning from finite data can
discover modular solutions that generalize compositionally in modular but not
monolithic architectures. We further show that our insights translate outside
the teacher-student setting and demonstrate that in tasks with compositional
preferences and tasks with compositional goals hypernetworks can discover
modular policies that compositionally generalize.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15002" title="Abstract">arXiv:2312.15002</a> [<a href="/pdf/2312.15002" title="Download PDF">pdf</a>, <a href="/format/2312.15002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C2FAR: Coarse-to-Fine Autoregressive Networks for Precise Probabilistic  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergsma%2C+S">Shane Bergsma</a>, 
<a href="/search/cs?searchtype=author&query=Zeyl%2C+T">Timothy Zeyl</a>, 
<a href="/search/cs?searchtype=author&query=Anaraki%2C+J+R">Javad Rahimipour Anaraki</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lei Guo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 36th Conference on Neural Information
  Processing Systems (NeurIPS 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present coarse-to-fine autoregressive networks (C2FAR), a method for
modeling the probability distribution of univariate, numeric random variables.
C2FAR generates a hierarchical, coarse-to-fine discretization of a variable
autoregressively; progressively finer intervals of support are generated from a
sequence of binned distributions, where each distribution is conditioned on
previously-generated coarser intervals. Unlike prior (flat) binned
distributions, C2FAR can represent values with exponentially higher precision,
for only a linear increase in complexity. We use C2FAR for probabilistic
forecasting via a recurrent neural network, thus modeling time series
autoregressively in both space and time. C2FAR is the first method to
simultaneously handle discrete and continuous series of arbitrary scale and
distribution shape. This flexibility enables a variety of time series use
cases, including anomaly detection, interpolation, and compression. C2FAR
achieves improvements over the state-of-the-art on several benchmark
forecasting datasets.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15003" title="Abstract">arXiv:2312.15003</a> [<a href="/pdf/2312.15003" title="Download PDF">pdf</a>, <a href="/format/2312.15003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benefits of Advanced Air Mobility for Society and Environment: A Case  Study of Ohio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dulia%2C+E+F">Esrat F. Dulia</a>, 
<a href="/search/math?searchtype=author&query=Sabuj%2C+M+S">Mir S. Sabuj</a>, 
<a href="/search/math?searchtype=author&query=Shihab%2C+S+A+M">Syed A. M. Shihab</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Sciences, 12(1), 207 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Advanced Air Mobility (AAM) is an emerging transportation system that will
enable the safe and efficient low altitude operations and applications of
unmanned aircraft (e.g., passenger transportation and cargo delivery) in the
national airspace. This system is currently under active research and
development by NASA in collaboration with FAA, other federal partner agencies,
industry, and academia to develop its infrastructure, information architecture,
software functions, concepts of operation, operations management tools and
other functional components. Existing studies have, however, not thoroughly
analyzed the net positive impact of AAM on society and environment to justify
investments in its infrastructure and implementation. In this work, we fill
this gap by evaluating the non-monetary social impact of AAM in the state of
Ohio for passengers, patients, farmers, logistics companies and their customers
and bridge inspection entities, as well as its environmental impact, by
conducting a thorough data-driven quantitative cost-benefit analysis of AAM
from the perspective of the state government. To this end, the most relevant
and significant benefit and cost factors are identified, monetized, and
estimated. Existing ground transportation for the movement of passengers and
goods within and across urban areas is considered as the base case. The
findings demonstrate that AAM's benefits are large and varied, far outweighing
its costs. Insights on these benefits can help gain community acceptance of
AAM, which is critical for successful implementation of AAM. The findings
support decision-making for policymakers and provide justification for
investments in AAM infrastructure by the government and private sector.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15004" title="Abstract">arXiv:2312.15004</a> [<a href="/pdf/2312.15004" title="Download PDF">pdf</a>, <a href="/format/2312.15004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FineMoGen: Fine-Grained Spatio-Temporal Motion Generation and Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huirong Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-driven motion generation has achieved substantial progress with the
emergence of diffusion models. However, existing methods still struggle to
generate complex motion sequences that correspond to fine-grained descriptions,
depicting detailed and accurate spatio-temporal actions. This lack of fine
controllability limits the usage of motion generation to a larger audience. To
tackle these challenges, we present FineMoGen, a diffusion-based motion
generation and editing framework that can synthesize fine-grained motions, with
spatial-temporal composition to the user instructions. Specifically, FineMoGen
builds upon diffusion model with a novel transformer architecture dubbed
Spatio-Temporal Mixture Attention (SAMI). SAMI optimizes the generation of the
global attention template from two perspectives: 1) explicitly modeling the
constraints of spatio-temporal composition; and 2) utilizing sparsely-activated
mixture-of-experts to adaptively extract fine-grained features. To facilitate a
large-scale study on this new fine-grained motion generation task, we
contribute the HuMMan-MoGen dataset, which consists of 2,968 videos and 102,336
fine-grained spatio-temporal descriptions. Extensive experiments validate that
FineMoGen exhibits superior motion generation quality over state-of-the-art
methods. Notably, FineMoGen further enables zero-shot motion editing
capabilities with the aid of modern large language models (LLM), which
faithfully manipulates motion sequences with fine-grained instructions. Project
Page: https://mingyuan-zhang.github.io/projects/FineMoGen.html
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15006" title="Abstract">arXiv:2312.15006</a> [<a href="/pdf/2312.15006" title="Download PDF">pdf</a>, <a href="/format/2312.15006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Impact of Prompting, Persona, and Chain of Thought Methods  on ChatGPT&#x27;s Arithmetic Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Chloe Wong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Aguenza%2C+J">Juan Aguenza</a>, 
<a href="/search/cs?searchtype=author&query=Bhujangari%2C+S">Sai Bhujangari</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+B">Benthan Vu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xun Lei</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+A">Amisha Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Fluss%2C+M">Manny Fluss</a>, 
<a href="/search/cs?searchtype=author&query=Phuong%2C+E">Eric Phuong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J">James Davis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study critically evaluates the mathematical proficiency of OpenAI's
language model, ChatGPT, by juxtaposing its default computational capabilities
against the efficiency of three prescriptive methods: strategic prompting,
persona implementation, and the Chain of Thought approach. The evaluation
harnessed the diverse and extensive problem sets from the MATH, GSM8K, and MMLU
data-sets, which encompassing a broad spectrum of mathematical conundrums and
levels of complexity. A sophisticated grading script was designed to determine
the efficacy of these interventions in enhancing the model's mathematical
precision. Contrary to expectations, our empirical analysis revealed that none
of the trialed methods substantially improved ChatGPT's baseline performance.
In some cases, these interventions inadvertently disrupted the model's response
generation. This investigation concluded that while the pursuit of innovative
strategies for augmenting language model performance remains crucial, the
specific methods examined within this study did not induce significant
improvements in ChatGPT's computational aptitude. These findings underscore the
importance of further comprehensive research and exploration of novel
techniques to enhance the precision and dependability of such models across
diverse domains.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15010" title="Abstract">arXiv:2312.15010</a> [<a href="/pdf/2312.15010" title="Download PDF">pdf</a>, <a href="/format/2312.15010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SI-MIL: Taming Deep MIL for Self-Interpretability in Gigapixel  Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapse%2C+S">Saarthak Kapse</a>, 
<a href="/search/cs?searchtype=author&query=Pati%2C+P">Pushpak Pati</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srijan Das</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vakalopoulou%2C+M">Maria Vakalopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Saltz%2C+J">Joel Saltz</a>, 
<a href="/search/cs?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R+R">Rajarsi R. Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+P">Prateek Prasanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Introducing interpretability and reasoning into Multiple Instance Learning
(MIL) methods for Whole Slide Image (WSI) analysis is challenging, given the
complexity of gigapixel slides. Traditionally, MIL interpretability is limited
to identifying salient regions deemed pertinent for downstream tasks, offering
little insight to the end-user (pathologist) regarding the rationale behind
these selections. To address this, we propose Self-Interpretable MIL (SI-MIL),
a method intrinsically designed for interpretability from the very outset.
SI-MIL employs a deep MIL framework to guide an interpretable branch grounded
on handcrafted pathological features, facilitating linear predictions. Beyond
identifying salient regions, SI-MIL uniquely provides feature-level
interpretations rooted in pathological insights for WSIs. Notably, SI-MIL, with
its linear prediction constraints, challenges the prevalent myth of an
inevitable trade-off between model interpretability and performance,
demonstrating competitive results compared to state-of-the-art methods on
WSI-level prediction tasks across three cancer types. In addition, we
thoroughly benchmark the local- and global-interpretability of SI-MIL in terms
of statistical analysis, a domain expert study, and desiderata of
interpretability, namely, user-friendliness and faithfulness.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15011" title="Abstract">arXiv:2312.15011</a> [<a href="/pdf/2312.15011" title="Download PDF">pdf</a>, <a href="/format/2312.15011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gemini vs GPT-4V: A Preliminary Comparison and Combination of  Vision-Language Models Through Qualitative Cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhangyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Ye Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://github.com/Qi-Zhangyang/Gemini-vs-GPT4V.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2309.17421">arXiv:2309.17421</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The rapidly evolving sector of Multi-modal Large Language Models (MLLMs) is
at the forefront of integrating linguistic and visual processing in artificial
intelligence. This paper presents an in-depth comparative study of two
pioneering models: Google's Gemini and OpenAI's GPT-4V(ision). Our study
involves a multi-faceted evaluation of both models across key dimensions such
as Vision-Language Capability, Interaction with Humans, Temporal Understanding,
and assessments in both Intelligence and Emotional Quotients. The core of our
analysis delves into the distinct visual comprehension abilities of each model.
We conducted a series of structured experiments to evaluate their performance
in various industrial application scenarios, offering a comprehensive
perspective on their practical utility. We not only involve direct performance
comparisons but also include adjustments in prompts and scenarios to ensure a
balanced and fair analysis. Our findings illuminate the unique strengths and
niches of both models. GPT-4V distinguishes itself with its precision and
succinctness in responses, while Gemini excels in providing detailed, expansive
answers accompanied by relevant imagery and links. These understandings not
only shed light on the comparative merits of Gemini and GPT-4V but also
underscore the evolving landscape of multimodal foundation models, paving the
way for future advancements in this area. After the comparison, we attempted to
achieve better results by combining the two models. Finally, We would like to
express our profound gratitude to the teams behind GPT-4V and Gemini for their
pioneering contributions to the field. Our acknowledgments are also extended to
the comprehensive qualitative analysis presented in 'Dawn' by Yang et al. This
work, with its extensive collection of image samples, prompts, and
GPT-4V-related results, provided a foundational basis for our analysis.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15020" title="Abstract">arXiv:2312.15020</a> [<a href="/pdf/2312.15020" title="Download PDF">pdf</a>, <a href="/format/2312.15020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Technical Debt Using Natural Language Processing Approaches --  A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sutoyo%2C+E">Edi Sutoyo</a>, 
<a href="/search/cs?searchtype=author&query=Capiluppi%2C+A">Andrea Capiluppi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Context: Technical debt (TD) is a well-known metaphor for the long-term
effects of architectural decisions in software development and the trade-off
between producing high-quality, effective, and efficient code and meeting a
release schedule. Thus, the code degrades and needs refactoring. A lack of
resources, time, knowledge, or experience on the development team might cause
TD in any software development project. Objective: In the context of TD
detection, NLP has been utilized to identify the presence of TD automatically
and even recognize specific types of TD. However, the enormous variety of
feature extraction approaches and ML/DL algorithms employed in the literature
often hinders researchers from trying to improve their performance. Method: In
light of this, this SLR proposes a taxonomy of feature extraction techniques
and algorithms used in technical debt detection: its objective is to compare
and benchmark their performance in the examined studies. Results: We selected
55 articles that passed the quality evaluation of this SLR. We then
investigated which feature extractions and algorithms were employed to identify
TD in each SDLC phase. All approaches proposed in the analyzed studies were
grouped into NLP, NLP+ML, and NLP+DL. This allows us to discuss the performance
in three different ways. Conclusion: Overall, the NLP+DL group consistently
outperforms in precision and F1-score for all projects, and in all but one
project for the recall metric. Regarding the feature extraction techniques, the
PTWE consistently achieves higher precision, recall, and F1-score for each
project analyzed. Furthermore, TD types have been mapped, when possible, to
SDLC phases: this served to determine the best-performing feature extractions
and algorithms for each SDLC phase. Finally, based on the SLR results, we also
identify implications that could be of concern to researchers and
practitioners.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15021" title="Abstract">arXiv:2312.15021</a> [<a href="/pdf/2312.15021" title="Download PDF">pdf</a>, <a href="/format/2312.15021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Multimodal Reasoning Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arun%2C+A">Abhinav Arun</a>, 
<a href="/search/cs?searchtype=author&query=Mal%2C+D+S">Dipendra Singh Mal</a>, 
<a href="/search/cs?searchtype=author&query=Soni%2C+M">Mehul Soni</a>, 
<a href="/search/cs?searchtype=author&query=Sawada%2C+T">Tomohiro Sawada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in deep learning have led to the development of powerful
language models (LMs) that excel in various tasks. Despite these achievements,
there is still room for improvement, particularly in enhancing reasoning
abilities and incorporating multimodal data. This report investigates the
potential impact of combining Chain-of-Thought (CoT) reasoning and Visual
Question Answering (VQA) techniques to improve LM's accuracy in solving
multiple-choice questions. By employing TextVQA and ScienceQA datasets, we
assessed the effectiveness of three text embedding methods and three visual
embedding approaches. Our experiments aimed to fill the gap in current research
by investigating the combined impact of CoT and VQA, contributing to the
understanding of how these techniques can improve the reasoning capabilities of
state-of-the-art models like GPT-4. Results from our experiments demonstrated
the potential of these approaches in enhancing LM's reasoning and
question-answering capabilities, providing insights for further research and
development in the field, and paving the way for more accurate and reliable AI
systems that can handle complex reasoning tasks across multiple modalities.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15022" title="Abstract">arXiv:2312.15022</a> [<a href="/pdf/2312.15022" title="Download PDF">pdf</a>, <a href="/format/2312.15022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Elman&#x27;s Bound for GMRES
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Embree%2C+M">Mark Embree</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">If the numerical range of a matrix is contained in the right half-plane, the
GMRES algorithm for solving linear systems will make progress at every
iteration. In his Ph.D. dissertation, Howard Elman derived a bound that
guarantees convergence. When all eigenvalues are in the right half-plane but
the numerical range contains the origin, GMRES need not make progress at every
step, and Elman's bound does not apply. By solving a Lyapunov equation, one can
construct an inner product in which the numerical range is contained in the
right half-plane. One can bound GMRES (run in the standard Euclidean norm) by
applying Elman's bound in this new inner product, at the cost of a
multiplicative constant that characterizes the distortion caused by the change
of inner product. Using Lyapunov inverse iteration, one can build a family of
suitable inner products, trading off the location of the numerical range with
the size of constant. This approach complements techniques recently proposed by
Greenbaum and colleagues for eliminating the origin from the numerical range
for GMRES convergence analysis.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15023" title="Abstract">arXiv:2312.15023</a> [<a href="/pdf/2312.15023" title="Download PDF">pdf</a>, <a href="/format/2312.15023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Q-Learning: Linear Regret Speedup with Low Communication Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fengyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lingzhou Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we consider federated reinforcement learning for tabular
episodic Markov Decision Processes (MDP) where, under the coordination of a
central server, multiple agents collaboratively explore the environment and
learn an optimal policy without sharing their raw data. While linear speedup in
the number of agents has been achieved for some metrics, such as convergence
rate and sample complexity, in similar settings, it is unclear whether it is
possible to design a model-free algorithm to achieve linear regret speedup with
low communication cost. We propose two federated Q-Learning algorithms termed
as FedQ-Hoeffding and FedQ-Bernstein, respectively, and show that the
corresponding total regrets achieve a linear speedup compared with their
single-agent counterparts when the time horizon is sufficiently large, while
the communication cost scales logarithmically in the total number of time steps
$T$. Those results rely on an event-triggered synchronization mechanism between
the agents and the server, a novel step size selection when the server
aggregates the local estimates of the state-action values to form the global
estimates, and a set of new concentration inequalities to bound the sum of
non-martingale differences. This is the first work showing that linear regret
speedup and logarithmic communication cost can be achieved by model-free
algorithms in federated reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15024" title="Abstract">arXiv:2312.15024</a> [<a href="/pdf/2312.15024" title="Download PDF">pdf</a>, <a href="/format/2312.15024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coded Caching for Hierarchical Two-Layer Networks with Coded Placement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rajlaxmi Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Rajput%2C+C">Charul Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+B+S">B. Sundar Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages and 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider two layered hierarchical coded caching problem introduced in
Hierarchical coded caching, IEEE Trans. Inf. Theory, 2016, in which a server is
connected to $K_1$ mirrors, and each mirror is connected to $K_2$ users. The
mirrors and the users are equipped with the cache of size $M_1$ and $M_2$,
respectively. We propose a hierarchical coded caching scheme with coded
placements that perform better than the existing schemes. In order to ensure a
fair comparison with existing schemes, we introduce the notion of composite
rate, defined as $\overline{R}=R_1+K_1R_2$, which consists of the rate from
server to mirrors $R_1$ and the rate from mirror to users $R_2$. The composite
rate has not been discussed before in literature and it represents the total
consumed bandwidth in the system. Therefore, it is more appropriate to consider
the composite rate along with $R_1$ and $R_2$. For the proposed scheme, we show
a trade-off between the global memory $\overline{M}=K_1M_1+K_1K_2M_2$ of the
system and the composite rate. We compare the proposed scheme with the existing
hierarchical coded caching schemes using the proposed parameter composite rate.
Finally, we propose another scheme for the specific case of a single mirror,
which performs better for this case.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15033" title="Abstract">arXiv:2312.15033</a> [<a href="/pdf/2312.15033" title="Download PDF">pdf</a>, <a href="/format/2312.15033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity-Guided Holistic Explanation for LLMs with Interpretable  Inference-Time Intervention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have achieved unprecedented breakthroughs in
various natural language processing domains. However, the enigmatic
``black-box'' nature of LLMs remains a significant challenge for
interpretability, hampering transparent and accountable applications. While
past approaches, such as attention visualization, pivotal subnetwork
extraction, and concept-based analyses, offer some insight, they often focus on
either local or global explanations within a single dimension, occasionally
falling short in providing comprehensive clarity. In response, we propose a
novel methodology anchored in sparsity-guided techniques, aiming to provide a
holistic interpretation of LLMs. Our framework, termed SparseCBM, innovatively
integrates sparsity to elucidate three intertwined layers of interpretation:
input, subnetwork, and concept levels. In addition, the newly introduced
dimension of interpretable inference-time intervention facilitates dynamic
adjustments to the model during deployment. Through rigorous empirical
evaluations on real-world datasets, we demonstrate that SparseCBM delivers a
profound understanding of LLM behaviors, setting it apart in both interpreting
and ameliorating model inaccuracies. Codes are provided in supplements.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15035" title="Abstract">arXiv:2312.15035</a> [<a href="/pdf/2312.15035" title="Download PDF">pdf</a>, <a href="/format/2312.15035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardcaml: An OCaml Hardware Domain-Specific Language for Efficient and  Robust Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Andy Ray</a>, 
<a href="/search/cs?searchtype=author&query=Devlin%2C+B">Benjamin Devlin</a>, 
<a href="/search/cs?searchtype=author&query=Quah%2C+F+Y">Fu Yong Quah</a>, 
<a href="/search/cs?searchtype=author&query=Yesantharao%2C+R">Rahul Yesantharao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">This paper introduces Hardcaml, an embedded hardware design domain specific
language (DSL) implemented in the OCaml programming language. Unlike high level
synthesis (HLS), Hardcaml allows for low level control of the underlying
hardware for maximum productivity, while abstracting away many of the tedious
aspects of traditional hardware definition languages (HDLs) such as Verilog or
VHDL. The richness of OCaml's type system combined with Hardcaml's fast circuit
elaboration checks reduces the chance of user-introduced bugs and erroneous
connections with features like custom type defining, type-safe parameterized
modules and elaboration-time bit-width inference and validation. Hardcaml
tooling emphasizes fast feedback through simulation, testing, and verification.
It includes both a native OCaml cycle-accurate and an event-driven simulator.
Unit tests can live in the source code and include digital ASCII waveforms
representing the simulator's output. Hardcaml also provides tools for SAT
proving and formal verification. Hardcaml is industrially proven, and has been
used at Jane Street internally for many large FPGA designs. As a case study we
highlight several aspects of our recent Hardcaml submission to the 2022 ZPrize
cryptography competition which won 1st place in the FPGA track.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15036" title="Abstract">arXiv:2312.15036</a> [<a href="/pdf/2312.15036" title="Download PDF">pdf</a>, <a href="/format/2312.15036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SODA: Protecting Proprietary Information in On-Device Machine Learning  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atrey%2C+A">Akanksha Atrey</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+R">Ritwik Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Saayan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Prashant Shenoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The growth of low-end hardware has led to a proliferation of machine
learning-based services in edge applications. These applications gather
contextual information about users and provide some services, such as
personalized offers, through a machine learning (ML) model. A growing practice
has been to deploy such ML models on the user's device to reduce latency,
maintain user privacy, and minimize continuous reliance on a centralized
source. However, deploying ML models on the user's edge device can leak
proprietary information about the service provider. In this work, we
investigate on-device ML models that are used to provide mobile services and
demonstrate how simple attacks can leak proprietary information of the service
provider. We show that different adversaries can easily exploit such models to
maximize their profit and accomplish content theft. Motivated by the need to
thwart such attacks, we present an end-to-end framework, SODA, for deploying
and serving on edge devices while defending against adversarial usage. Our
results demonstrate that SODA can detect adversarial usage with 89% accuracy in
less than 50 queries with minimal impact on service performance, latency, and
storage.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15037" title="Abstract">arXiv:2312.15037</a> [<a href="/pdf/2312.15037" title="Download PDF">pdf</a>, <a href="/format/2312.15037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latents2Semantics: Leveraging the Latent Space of Generative Models for  Localized Style Manipulation of Face Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomar%2C+S+S">Snehal Singh Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+A+N">A.N. Rajagopalan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an oral paper at the AAAI-24 Workshop on AI for Digital Human
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the metaverse slowly becoming a reality and given the rapid pace of
developments toward the creation of digital humans, the need for a principled
style editing pipeline for human faces is bound to increase manifold. We cater
to this need by introducing the Latents2Semantics Autoencoder (L2SAE), a
Generative Autoencoder model that facilitates highly localized editing of style
attributes of several Regions of Interest (ROIs) in face images. The L2SAE
learns separate latent representations for encoded images' structure and style
information. Thus, allowing for structure-preserving style editing of the
chosen ROIs. The encoded structure representation is a multichannel 2D tensor
with reduced spatial dimensions, which captures both local and global structure
properties. The style representation is a 1D tensor that captures global style
attributes. In our framework, we slice the structure representation to build
strong and disentangled correspondences with different ROIs. Consequentially,
style editing of the chosen ROIs amounts to a simple combination of (a) the
ROI-mask generated from the sliced structure representation and (b) the decoded
image with global style changes, generated from the manipulated (using Gaussian
noise) global style and unchanged structure tensor. Style editing sans
additional human supervision is a significant win over SOTA style editing
pipelines because most existing works require additional human effort
(supervision) post-training for attributing semantic meaning to style edits. We
also do away with iterative-optimization-based inversion or determining
controllable latent directions post-training, which requires additional
computationally expensive operations. We provide qualitative and quantitative
results for the same over multiple applications, such as selective style
editing and swapping using test images sampled from several datasets.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15040" title="Abstract">arXiv:2312.15040</a> [<a href="/pdf/2312.15040" title="Download PDF">pdf</a>, <a href="/format/2312.15040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Detecting Cascades of Biased Medical Claims on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiderman%2C+L">Libby Tiderman</a>, 
<a href="/search/cs?searchtype=author&query=Mercedes%2C+J+S">Juan Sanchez Mercedes</a>, 
<a href="/search/cs?searchtype=author&query=Romanoschi%2C+F">Fiona Romanoschi</a>, 
<a href="/search/cs?searchtype=author&query=Murai%2C+F">Fabricio Murai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2023 MIT Undergraduate Research Technology Conference (URTC'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Social media may disseminate medical claims that highlight misleading
correlations between social identifiers and diseases due to not accounting for
structural determinants of health. Our research aims to identify biased medical
claims on Twitter and measure their spread. We propose a machine learning
framework that uses two models in tandem: RoBERTa to detect medical claims and
DistilBERT to classify bias. After identifying original biased medical claims,
we conducted a retweet cascade analysis, computing their individual reach and
rate of spread. Tweets containing biased claims were found to circulate faster
and further than unbiased claims.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15041" title="Abstract">arXiv:2312.15041</a> [<a href="/pdf/2312.15041" title="Download PDF">pdf</a>, <a href="/format/2312.15041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> W4-Groups: Modeling the Who, What, When and Where of Group Behavior via  Mobility Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atrey%2C+A">Akanksha Atrey</a>, 
<a href="/search/cs?searchtype=author&query=Zakaria%2C+C">Camellia Zakaria</a>, 
<a href="/search/cs?searchtype=author&query=Balan%2C+R">Rajesh Balan</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Prashant Shenoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Human social interactions occur in group settings of varying sizes and
locations, depending on the type of social activity. The ability to distinguish
group formations based on their purposes transforms how group detection
mechanisms function. Not only should such tools support the effective detection
of serendipitous encounters, but they can derive categories of relation types
among users. Determining who is involved, what activity is performed, and when
and where the activity occurs are critical to understanding group processes in
greater depth, including supporting goal-oriented applications (e.g.,
performance, productivity, and mental health) that require sensing social
factors. In this work, we propose W4-Groups that captures the functional
perspective of variability and repeatability when automatically constructing
short-term and long-term groups via multiple data sources (e.g., WiFi and
location check-in data). We design and implement W4-Groups to detect and
extract all four group features who-what-when-where from the user's daily
mobility patterns. We empirically evaluate the framework using two real-world
WiFi datasets and a location check-in dataset, yielding an average of 92%
overall accuracy, 96% precision, and 94% recall. Further, we supplement two
case studies to demonstrate the application of W4-Groups for next-group
activity prediction and analyzing changes in group behavior at a longitudinal
scale, exemplifying short-term and long-term occurrences.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15042" title="Abstract">arXiv:2312.15042</a> [<a href="/pdf/2312.15042" title="Download PDF">pdf</a>, <a href="/ps/2312.15042" title="Download PostScript">ps</a>, <a href="/format/2312.15042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Have Learning Analytics Dashboards Lived Up to the Hype? A Systematic  Review of Impact on Students&#x27; Achievement, Motivation, Participation and  Attitude
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaliisa%2C+R">Rogers Kaliisa</a>, 
<a href="/search/cs?searchtype=author&query=Misiejuk%2C+K">Kamila Misiejuk</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Pernas%2C+S">Sonsoles L&#xf3;pez-Pernas</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+M">Mohammad Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Saqr%2C+M">Mohammed Saqr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">While learning analytics dashboards (LADs) are the most common form of LA
intervention, there is limited evidence regarding their impact on students
learning outcomes. This systematic review synthesizes the findings of 38
research studies to investigate the impact of LADs on students' learning
outcomes, encompassing achievement, participation, motivation, and attitudes.
As we currently stand, there is no evidence to support the conclusion that LADs
have lived up to the promise of improving academic achievement. Most studies
reported negligible or small effects, with limited evidence from well-powered
controlled experiments. Many studies merely compared users and non-users of
LADs, confounding the dashboard effect with student engagement levels.
Similarly, the impact of LADs on motivation and attitudes appeared modest, with
only a few exceptions demonstrating significant effects. Small sample sizes in
these studies highlight the need for larger-scale investigations to validate
these findings. Notably, LADs showed a relatively substantial impact on student
participation. Several studies reported medium to large effect sizes,
suggesting that LADs can promote engagement and interaction in online learning
environments. However, methodological shortcomings, such as reliance on
traditional evaluation methods, self-selection bias, the assumption that access
equates to usage, and a lack of standardized assessment tools, emerged as
recurring issues. To advance the research line for LADs, researchers should use
rigorous assessment methods and establish clear standards for evaluating
learning constructs. Such efforts will advance our understanding of the
potential of LADs to enhance learning outcomes and provide valuable insights
for educators and researchers alike.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15043" title="Abstract">arXiv:2312.15043</a> [<a href="/pdf/2312.15043" title="Download PDF">pdf</a>, <a href="/format/2312.15043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GroundVLP: Harnessing Zero-shot Visual Grounding from Vision-Language  Pre-training and Open-Vocabulary Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haozhan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiancheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianwei Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual grounding, a crucial vision-language task involving the understanding
of the visual context based on the query expression, necessitates the model to
capture the interactions between objects, as well as various spatial and
attribute information. However, the annotation data of visual grounding task is
limited due to its time-consuming and labor-intensive annotation process,
resulting in the trained models being constrained from generalizing its
capability to a broader domain. To address this challenge, we propose
GroundVLP, a simple yet effective zero-shot method that harnesses visual
grounding ability from the existing models trained from image-text pairs and
pure object detection data, both of which are more conveniently obtainable and
offer a broader domain compared to visual grounding annotation data. GroundVLP
proposes a fusion mechanism that combines the heatmap from GradCAM and the
object proposals of open-vocabulary detectors. We demonstrate that the proposed
method significantly outperforms other zero-shot methods on RefCOCO/+/g
datasets, surpassing prior zero-shot state-of-the-art by approximately 28\% on
the test split of RefCOCO and RefCOCO+. Furthermore, GroundVLP performs
comparably to or even better than some non-VLP-based supervised models on the
Flickr30k entities dataset. Our code is available at
https://github.com/om-ai-lab/GroundVLP.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15045" title="Abstract">arXiv:2312.15045</a> [<a href="/pdf/2312.15045" title="Download PDF">pdf</a>, <a href="/format/2312.15045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Modeling for Sequences of Sets in Continuous-Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yuxin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+A">Alex Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Smyth%2C+P">Padhraic Smyth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural marked temporal point processes have been a valuable addition to the
existing toolbox of statistical parametric models for continuous-time event
data. These models are useful for sequences where each event is associated with
a single item (a single type of event or a "mark") -- but such models are not
suited for the practical situation where each event is associated with a set of
items. In this work, we develop a general framework for modeling set-valued
data in continuous-time, compatible with any intensity-based recurrent neural
point process model. In addition, we develop inference methods that can use
such models to answer probabilistic queries such as "the probability of item
$A$ being observed before item $B$," conditioned on sequence history. Computing
exact answers for such queries is generally intractable for neural models due
to both the continuous-time nature of the problem setting and the
combinatorially-large space of potential outcomes for each event. To address
this, we develop a class of importance sampling methods for querying with
set-based sequences and demonstrate orders-of-magnitude improvements in
efficiency over direct sampling via systematic experiments with four real-world
datasets. We also illustrate how to use this framework to perform model
selection using likelihoods that do not involve one-step-ahead prediction.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15046" title="Abstract">arXiv:2312.15046</a> [<a href="/pdf/2312.15046" title="Download PDF">pdf</a>, <a href="/format/2312.15046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-seeking polynomial NARX model-predictive control through  expected free energy minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kouw%2C+W+M">Wouter M. Kouw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose an adaptive model-predictive controller that balances driving the
system to a goal state and seeking system observations that are informative
with respect to the parameters of a nonlinear autoregressive exogenous model.
The controller's objective function is derived from an expected free energy
functional and contains information-theoretic terms expressing uncertainty over
model parameters and output predictions. Experiments illustrate how parameter
uncertainty affects the control objective and evaluate the proposed controller
for a pendulum swing-up task.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15058" title="Abstract">arXiv:2312.15058</a> [<a href="/pdf/2312.15058" title="Download PDF">pdf</a>, <a href="/format/2312.15058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The State of Documentation Practices of Third-party Machine Learning  Models and Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oreamuno%2C+E+L">Ernesto Lang Oreamuno</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+R+F">Rohan Faiyaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Bangash%2C+A+A">Abdul Ali Bangash</a>, 
<a href="/search/cs?searchtype=author&query=Stinson%2C+C">Catherine Stinson</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+B">Bram Adams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, IEEESoftware format
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Model stores offer third-party ML models and datasets for easy project
integration, minimizing coding efforts. One might hope to find detailed
specifications of these models and datasets in the documentation, leveraging
documentation standards such as model and dataset cards. In this study, we use
statistical analysis and hybrid card sorting to assess the state of the
practice of documenting model cards and dataset cards in one of the largest
model stores in use today--Hugging Face (HF). Our findings show that only
21,902 models (39.62\%) and 1,925 datasets (28.48\%) have documentation.
Furthermore, we observe inconsistency in ethics and transparency-related
documentation for ML models and datasets.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15059" title="Abstract">arXiv:2312.15059</a> [<a href="/pdf/2312.15059" title="Download PDF">pdf</a>, <a href="/format/2312.15059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable 3D Gaussian Splatting for Animatable Human Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">HyunJun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Brasch%2C+N">Nikolas Brasch</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jifei Song</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Pellitero%2C+E">Eduardo Perez-Pellitero</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in neural radiance fields enable novel view synthesis of
photo-realistic images in dynamic settings, which can be applied to scenarios
with human animation. Commonly used implicit backbones to establish accurate
models, however, require many input views and additional annotations such as
human masks, UV maps and depth maps. In this work, we propose ParDy-Human
(Parameterized Dynamic Human Avatar), a fully explicit approach to construct a
digital avatar from as little as a single monocular sequence. ParDy-Human
introduces parameter-driven dynamics into 3D Gaussian Splatting where 3D
Gaussians are deformed by a human pose model to animate the avatar. Our method
is composed of two parts: A first module that deforms canonical 3D Gaussians
according to SMPL vertices and a consecutive module that further takes their
designed joint encodings and predicts per Gaussian deformations to deal with
dynamics beyond SMPL vertex deformations. Images are then synthesized by a
rasterizer. ParDy-Human constitutes an explicit model for realistic dynamic
human avatars which requires significantly fewer training views and images. Our
avatars learning is free of additional annotations such as masks and can be
trained with variable backgrounds while inferring full-resolution images
efficiently even on consumer hardware. We provide experimental evidence to show
that ParDy-Human outperforms state-of-the-art methods on ZJU-MoCap and
THUman4.0 datasets both quantitatively and visually.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15063" title="Abstract">arXiv:2312.15063</a> [<a href="/pdf/2312.15063" title="Download PDF">pdf</a>, <a href="/format/2312.15063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A universal approximation theorem for nonlinear resistive networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scellier%2C+B">Benjamin Scellier</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
<p class="mathjax">Resistor networks have recently had a surge of interest as substrates for
energy-efficient self-learning machines. This work studies the computational
capabilities of these resistor networks. We show that electrical networks
composed of voltage sources, linear resistors, diodes and voltage-controlled
voltage sources (VCVS) can implement any continuous functions. To prove it, we
assume that the circuit elements are ideal and that the conductances of
variable resistors and the amplification factors of the VCVS's can take
arbitrary values -- arbitrarily small or arbitrarily large. The constructive
nature of our proof could also inform the design of such self-learning
electrical networks.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15067" title="Abstract">arXiv:2312.15067</a> [<a href="/pdf/2312.15067" title="Download PDF">pdf</a>, <a href="/format/2312.15067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electromagnetic Transient Model of Cryptocurrency Mining Loads for  Low-Voltage Ride Through Assessment in Transmission Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Samanta%2C+A">Anindita Samanta</a>, 
<a href="/search/eess?searchtype=author&query=Majumder%2C+S">Subir Majumder</a>, 
<a href="/search/eess?searchtype=author&query=Ibrahim%2C+H">Hasan Ibrahim</a>, 
<a href="/search/eess?searchtype=author&query=Enjeti%2C+P">Prasad Enjeti</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Le Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 10 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we developed an Electromagnetic Transient (EMT) model tailored
for large cryptocurrency mining loads to understand the cross-interaction of
these loads with the electric grid. The load model has been built using
Electromagnetic Transients Program (EMTP) software. We have cross-validated the
performance of the EMT model of the load with commercial application-specific
integrated circuit miners, typically used by large-scale mining facilities, by
comparing their low-voltage ride-through (LVRT) capabilities. Subsequently,
LVRT capabilities of the large-scale miners have been tested against various
fault scenarios both within the miner's remote facility as well as at one of
the distant buses of the interconnected grid. The significance of this model
lies in its scalability to accommodate larger blocks of mining loads and its
seamless integration into a larger electric grid.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15068" title="Abstract">arXiv:2312.15068</a> [<a href="/pdf/2312.15068" title="Download PDF">pdf</a>, <a href="/format/2312.15068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining GPT-3 Embeddings with a Siamese Structure for Technical Post  Duplicate Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yoshioka%2C+N">Nobukazu Yoshioka</a>, 
<a href="/search/cs?searchtype=author&query=Washizaki%2C+H">Hironori Washizaki</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SANER 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">One goal of technical online communities is to help developers find the right
answer in one place. A single question can be asked in different ways with
different wordings, leading to the existence of duplicate posts on technical
forums. The question of how to discover and link duplicate posts has garnered
the attention of both developer communities and researchers. For example, Stack
Overflow adopts a voting-based mechanism to mark and close duplicate posts.
However, addressing these constantly emerging duplicate posts in a timely
manner continues to pose challenges. Therefore, various approaches have been
proposed to detect duplicate posts on technical forum posts automatically. The
existing methods suffer from limitations either due to their reliance on
handcrafted similarity metrics which can not sufficiently capture the semantics
of posts, or their lack of supervision to improve the performance.
Additionally, the efficiency of these methods is hindered by their dependence
on pair-wise feature generation, which can be impractical for large amount of
data. In this work, we attempt to employ and refine the GPT-3 embeddings for
the duplicate detection task. We assume that the GPT-3 embeddings can
accurately represent the semantics of the posts. In addition, by training a
Siamese-based network based on the GPT-3 embeddings, we obtain a latent
embedding that accurately captures the duplicate relation in technical forum
posts. Our experiment on a benchmark dataset confirms the effectiveness of our
approach and demonstrates superior performance compared to baseline methods.
When applied to the dataset we constructed with a recent Stack Overflow dump,
our approach attains a Top-1, Top-5, and Top-30 accuracy of 23.1%, 43.9%, and
68.9%, respectively. With a manual study, we confirm our approach's potential
of finding unlabelled duplicates on technical forums.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15071" title="Abstract">arXiv:2312.15071</a> [<a href="/pdf/2312.15071" title="Download PDF">pdf</a>, <a href="/format/2312.15071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Independence in the Home: A Wearable Interface for a Person with  Quadriplegia to Teleoperate a Mobile Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padmanabha%2C+A">Akhil Padmanabha</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J">Janavi Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jehan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+D+J">Douglas J. Weber</a>, 
<a href="/search/cs?searchtype=author&query=Majidi%2C+C">Carmel Majidi</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Teleoperation of mobile manipulators within a home environment can
significantly enhance the independence of individuals with severe motor
impairments, allowing them to regain the ability to perform self-care and
household tasks. There is a critical need for novel teleoperation interfaces to
offer effective alternatives for individuals with impairments who may encounter
challenges in using existing interfaces due to physical limitations. In this
work, we iterate on one such interface, HAT (Head-Worn Assistive
Teleoperation), an inertial-based wearable integrated into any head-worn
garment. We evaluate HAT through a 7-day in-home study with Henry Evans, a
non-speaking individual with quadriplegia who has participated extensively in
assistive robotics studies. We additionally evaluate HAT with a proposed shared
control method for mobile manipulators termed Driver Assistance and demonstrate
how the interface generalizes to other physical devices and contexts. Our
results show that HAT is a strong teleoperation interface across key metrics
including efficiency, errors, learning curve, and workload. Code and videos are
located on our project website.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15073" title="Abstract">arXiv:2312.15073</a> [<a href="/pdf/2312.15073" title="Download PDF">pdf</a>, <a href="/format/2312.15073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Volume Visualization for Big Scientific Data Modeled by  Functional Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lenz%2C+D">David Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Peterka%2C+T">Tom Peterka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Considering the challenges posed by the space and time complexities in
handling extensive scientific volumetric data, various data representations
have been developed for the analysis of large-scale scientific data.
Multivariate functional approximation (MFA) is an innovative data model
designed to tackle substantial challenges in scientific data analysis. It
computes values and derivatives with high-order accuracy throughout the spatial
domain, mitigating artifacts associated with zero- or first-order
interpolation. However, the slow query time through MFA makes it less suitable
for interactively visualizing a large MFA model. In this work, we develop the
first scalable interactive volume visualization pipeline, MFA-DVV, for the MFA
model encoded from large-scale datasets. Our method achieves low input latency
through distributed architecture, and its performance can be further enhanced
by utilizing a compressed MFA model while still maintaining a high-quality
rendering result for scientific datasets. We conduct comprehensive experiments
to show that MFA-DVV can decrease the input latency and achieve superior
visualization results for big scientific data compared with existing
approaches.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15081" title="Abstract">arXiv:2312.15081</a> [<a href="/pdf/2312.15081" title="Download PDF">pdf</a>, <a href="/format/2312.15081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Rich Rankings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seshadri%2C+A">Arjun Seshadri</a>, 
<a href="/search/cs?searchtype=author&query=Ragain%2C+S">Stephen Ragain</a>, 
<a href="/search/cs?searchtype=author&query=Ugander%2C+J">Johan Ugander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Although the foundations of ranking are well established, the ranking
literature has primarily been focused on simple, unimodal models, e.g. the
Mallows and Plackett-Luce models, that define distributions centered around a
single total ordering. Explicit mixture models have provided some tools for
modelling multimodal ranking data, though learning such models from data is
often difficult. In this work, we contribute a contextual repeated selection
(CRS) model that leverages recent advances in choice modeling to bring a
natural multimodality and richness to the rankings space. We provide rigorous
theoretical guarantees for maximum likelihood estimation under the model
through structure-dependent tail risk and expected risk bounds. As a
by-product, we also furnish the first tight bounds on the expected risk of
maximum likelihood estimators for the multinomial logit (MNL) choice model and
the Plackett-Luce (PL) ranking model, as well as the first tail risk bound on
the PL ranking model. The CRS model significantly outperforms existing methods
for modeling real world ranking data in a variety of settings, from racing to
rank choice voting.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15084" title="Abstract">arXiv:2312.15084</a> [<a href="/pdf/2312.15084" title="Download PDF">pdf</a>, <a href="/format/2312.15084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated forest inventory: analysis of high-density airborne LiDAR  point clouds with 3D deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+B">Binbin Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Wielgosz%2C+M">Maciej Wielgosz</a>, 
<a href="/search/cs?searchtype=author&query=Kontogianni%2C+T">Theodora Kontogianni</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+T">Torben Peters</a>, 
<a href="/search/cs?searchtype=author&query=Puliti%2C+S">Stefano Puliti</a>, 
<a href="/search/cs?searchtype=author&query=Astrup%2C+R">Rasmus Astrup</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detailed forest inventories are critical for sustainable and flexible
management of forest resources, to conserve various ecosystem services. Modern
airborne laser scanners deliver high-density point clouds with great potential
for fine-scale forest inventory and analysis, but automatically partitioning
those point clouds into meaningful entities like individual trees or tree
components remains a challenge. The present study aims to fill this gap and
introduces a deep learning framework that is able to perform such a
segmentation across diverse forest types and geographic regions. From the
segmented data, we then derive relevant biophysical parameters of individual
trees as well as stands. The system has been tested on FOR-Instance, a dataset
of point clouds that have been acquired in five different countries using
surveying drones. The segmentation back-end achieves over 85% F-score for
individual trees, respectively over 73% mean IoU across five semantic
categories: ground, low vegetation, stems, live branches and dead branches.
Building on the segmentation results our pipeline then densely calculates
biophysical features of each individual tree (height, crown diameter, crown
volume, DBH, and location) and properties per stand (digital terrain model and
stand density). Especially crown-related features are in most cases retrieved
with high accuracy, whereas the estimates for DBH and location are less
reliable, due to the airborne scanning setup.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15086" title="Abstract">arXiv:2312.15086</a> [<a href="/pdf/2312.15086" title="Download PDF">pdf</a>, <a href="/format/2312.15086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperMix: Out-of-Distribution Detection and Classification in Few-Shot  Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+N">Nikhil Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K+J">Kevin J Liang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+F">Fu-Jen Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Li Yin</a>, 
<a href="/search/cs?searchtype=author&query=Hassner%2C+T">Tal Hassner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection is an important topic for real-world
machine learning systems, but settings with limited in-distribution samples
have been underexplored. Such few-shot OOD settings are challenging, as models
have scarce opportunities to learn the data distribution before being tasked
with identifying OOD samples. Indeed, we demonstrate that recent
state-of-the-art OOD methods fail to outperform simple baselines in the
few-shot setting. We thus propose a hypernetwork framework called HyperMix,
using Mixup on the generated classifier parameters, as well as a natural
out-of-episode outlier exposure technique that does not require an additional
outlier dataset. We conduct experiments on CIFAR-FS and MiniImageNet,
significantly outperforming other OOD methods in the few-shot regime.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15087" title="Abstract">arXiv:2312.15087</a> [<a href="/pdf/2312.15087" title="Download PDF">pdf</a>, <a href="/format/2312.15087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Seedless Condensers: Exploring the Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+E">Eshan Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Gurumukhani%2C+M">Mohit Gurumukhani</a>, 
<a href="/search/cs?searchtype=author&query=Ringach%2C+N">Noam Ringach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We prove several new results for seedless condensers in the context of three
related classes of sources: NOSF sources, SHELA sources as defined by [AORSV,
EUROCRYPT'20], and almost CG sources as defined by [DMOZ, STOC'23]. We will
think of these sources as a sequence of random variables
$\mathbf{X}=\mathbf{X}_1,\dots,\mathbf{X}_\ell$ on $\ell$ symbols where at
least $g$ symbols are "good" (i.e., uniformly random), denoted as a
$(g,\ell)$-source, and the remaining "bad" $\ell-g$ symbols may adversarially
depend on these $g$ good blocks. The difference between each of these sources
is realized by restrictions on the power of the adversary, with the adversary
in NOSF sources having no restrictions.
<br />Prior to our work, the only known seedless condenser upper or lower bound in
these settings is due to [DMOZ, STOC'23] which explicitly constructs a seedless
condenser for a restricted subset of $(g,\ell)$-almost CG sources. The
following are our main results concerning seedless condensers for each of these
three sources.
<br />1. When $g\leq \frac{\ell}{2}$, we prove for all three classes of sources
that condensing with error 0.99 above rate $\frac{1}{\lfloor \ell/g \rfloor}$
is impossible.
<br />2. We show that condensing from (2, 3) NOSF sources above rate $\frac{2}{3}$
is impossible.
<br />3. Quite surprisingly, we show the existence of excellent condensers for
uniform $(2,3)$-SHELA and uniform almost CG sources, thus proving a separation
from NOSF sources. Further, we explicitly construct a condenser that outputs $m
= \frac{n}{16}$ bits and condenses any uniform $(2,3)$-SHELA source to entropy
$m - O(\log(m / \varepsilon))$ (with error $\varepsilon$). Our construction is
based on a new type of seeded extractor that we call output-light, which could
be of independent interest. In contrast, we show that it is impossible to
extract from uniform $(2,3)$-SHELA sources.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15088" title="Abstract">arXiv:2312.15088</a> [<a href="/pdf/2312.15088" title="Download PDF">pdf</a>, <a href="/ps/2312.15088" title="Download PostScript">ps</a>, <a href="/format/2312.15088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Domain Inference Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuechun Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keke Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">As deep neural networks are increasingly deployed in sensitive application
domains, such as healthcare and security, it's necessary to understand what
kind of sensitive information can be inferred from these models. Existing
model-targeted attacks all assume the attacker has known the application domain
or training data distribution, which plays an essential role in successful
attacks. Can removing the domain information from model APIs protect models
from these attacks? This paper studies this critical problem. Unfortunately,
even with minimal knowledge, i.e., accessing the model as an unnamed function
without leaking the meaning of input and output, the proposed adaptive domain
inference attack (ADI) can still successfully estimate relevant subsets of
training data. We show that the extracted relevant data can significantly
improve, for instance, the performance of model-inversion attacks.
Specifically, the ADI method utilizes a concept hierarchy built on top of a
large collection of available public and private datasets and a novel algorithm
to adaptively tune the likelihood of leaf concepts showing up in the unseen
training data. The ADI attack not only extracts partial training data at the
concept level, but also converges fast and requires much fewer target-model
accesses than another domain inference attack, GDI.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15091" title="Abstract">arXiv:2312.15091</a> [<a href="/pdf/2312.15091" title="Download PDF">pdf</a>, <a href="/ps/2312.15091" title="Download PostScript">ps</a>, <a href="/format/2312.15091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Stability in Asynchronous Stochastic Approximation without  Communication Delays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huizhen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+R+S">Richard S. Sutton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we study asynchronous stochastic approximation algorithms
without communication delays. Our main contribution is a stability proof for
these algorithms that extends a method of Borkar and Meyn by accommodating more
general noise conditions. We also derive convergence results from this
stability result and discuss their application in important average-reward
reinforcement learning problems.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15094" title="Abstract">arXiv:2312.15094</a> [<a href="/pdf/2312.15094" title="Download PDF">pdf</a>, <a href="/format/2312.15094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Steps Forward and One Step Back: The Right to Opt-out of Sale under  CPRA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charatan%2C+J">Jan Charatan</a>, 
<a href="/search/cs?searchtype=author&query=Birrell%2C+E">Eleanor Birrell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The California Privacy Rights Act (CPRA) was a ballot initiative that revised
the California Consumer Privacy Act (CCPA). Although often framed as expanding
and enhancing privacy rights, a close analysis of textual revisions -- both
changes from the earlier law and changes from earlier drafts of the CPRA
guidelines -- suggest that the reality might be more nuanced. In this work, we
identify three textual revisions that have potential to negatively impact the
right to opt-out of sale under CPRA and evaluate the effect of these textual
revisions using (1) a large-scale longitudinal measurement study of 25,000
websites over twelve months and (2) an experimental user study with 775
participants recruited through Prolific. We find that all revisions negatively
impacted the usability, scope, and visibility of the right to opt-out of sale.
Our results provide the first comprehensive evaluation of the impact of CPRA on
Internet privacy. They also emphasize the importance of continued evaluation of
legal requirements as guidelines and case law evolve after a law goes into
effect.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15096" title="Abstract">arXiv:2312.15096</a> [<a href="/pdf/2312.15096" title="Download PDF">pdf</a>, <a href="/format/2312.15096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal In-Place Compaction of Sliding Cubes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostitsyna%2C+I">Irina Kostitsyna</a>, 
<a href="/search/cs?searchtype=author&query=Ophelders%2C+T">Tim Ophelders</a>, 
<a href="/search/cs?searchtype=author&query=Parada%2C+I">Irene Parada</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+T">Tom Peters</a>, 
<a href="/search/cs?searchtype=author&query=Sonke%2C+W">Willem Sonke</a>, 
<a href="/search/cs?searchtype=author&query=Speckmann%2C+B">Bettina Speckmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The sliding cubes model is a well-established theoretical framework that
supports the analysis of reconfiguration algorithms for modular robots
consisting of face-connected cubes. The best algorithm currently known for the
reconfiguration problem, by Abel and Kominers [arXiv, 2011], uses O(n3) moves
to transform any n-cube configuration into any other n-cube configuration. As
is common in the literature, this algorithm reconfigures the input into an
intermediate canonical shape. In this paper we present an in-place algorithm
that reconfigures any n-cube configuration into a compact canonical shape using
a number of moves proportional to the sum of coordinates of the input cubes.
This result is asymptotically optimal. Furthermore, our algorithm directly
extends to dimensions higher than three.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15097" title="Abstract">arXiv:2312.15097</a> [<a href="/pdf/2312.15097" title="Download PDF">pdf</a>, <a href="/format/2312.15097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recourse under Model Multiplicity via Argumentative Ensembling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Rago%2C+A">Antonio Rago</a>, 
<a href="/search/cs?searchtype=author&query=Leofante%2C+F">Francesco Leofante</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Model Multiplicity (MM) arises when multiple, equally performing machine
learning models can be trained to solve the same prediction task. Recent
studies show that models obtained under MM may produce inconsistent predictions
for the same input. When this occurs, it becomes challenging to provide
counterfactual explanations (CEs), a common means for offering recourse
recommendations to individuals negatively affected by models' predictions. In
this paper, we formalise this problem, which we name recourse-aware ensembling,
and identify several desirable properties which methods for solving it should
satisfy. We show that existing ensembling methods, naturally extended in
different ways to provide CEs, fail to satisfy these properties. We then
introduce argumentative ensembling, deploying computational argumentation to
guarantee robustness of CEs to MM, while also accommodating customisable user
preferences. We show theoretically and experimentally that argumentative
ensembling satisfies properties which the existing methods lack, and that the
trade-offs are minimal wrt accuracy.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15098" title="Abstract">arXiv:2312.15098</a> [<a href="/pdf/2312.15098" title="Download PDF">pdf</a>, <a href="/format/2312.15098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Auditory and Semantic Entrainment Models with Deep Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kejriwal%2C+J">Jay Kejriwal</a>, 
<a href="/search/cs?searchtype=author&query=Benus%2C+S">Stefan Benus</a>, 
<a href="/search/cs?searchtype=author&query=Rojas-Barahona%2C+L+M">Lina M. Rojas-Barahona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speakers tend to engage in adaptive behavior, known as entrainment, when they
become similar to their interlocutor in various aspects of speaking. We present
an unsupervised deep learning framework that derives meaningful representation
from textual features for developing semantic entrainment. We investigate the
model's performance by extracting features using different variations of the
BERT model (DistilBERT and XLM-RoBERTa) and Google's universal sentence encoder
(USE) embeddings on two human-human (HH) corpora (The Fisher Corpus English
Part 1, Columbia games corpus) and one human-machine (HM) corpus (Voice
Assistant Conversation Corpus (VACC)). In addition to semantic features we also
trained DNN-based models utilizing two auditory embeddings (TRIpLet Loss
network (TRILL) vectors, Low-level descriptors (LLD) features) and two units of
analysis (Inter pausal unit and Turn). The results show that semantic
entrainment can be assessed with our model, that models can distinguish between
HH and HM interactions and that the two units of analysis for extracting
acoustic features provide comparable findings.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15099" title="Abstract">arXiv:2312.15099</a> [<a href="/pdf/2312.15099" title="Download PDF">pdf</a>, <a href="/format/2312.15099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishwamitra%2C+N">Nishant Vishwamitra</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Keyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Romit%2C+F+T">Farhan Tajwar Romit</a>, 
<a href="/search/cs?searchtype=author&query=Ondracek%2C+I">Isabelle Ondracek</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Long Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongxin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the 45th IEEE Symposium on Security and Privacy, May 20-23, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Online hate is an escalating problem that negatively impacts the lives of
Internet users, and is also subject to rapid changes due to evolving events,
resulting in new waves of online hate that pose a critical threat. Detecting
and mitigating these new waves present two key challenges: it demands
reasoning-based complex decision-making to determine the presence of hateful
content, and the limited availability of training samples hinders updating the
detection model. To address this critical issue, we present a novel framework
called HATEGUARD for effectively moderating new waves of online hate. HATEGUARD
employs a reasoning-based approach that leverages the recently introduced
chain-of-thought (CoT) prompting technique, harnessing the capabilities of
large language models (LLMs). HATEGUARD further achieves prompt-based zero-shot
detection by automatically generating and updating detection prompts with new
derogatory terms and targets in new wave samples to effectively address new
waves of online hate. To demonstrate the effectiveness of our approach, we
compile a new dataset consisting of tweets related to three recently witnessed
new waves: the 2022 Russian invasion of Ukraine, the 2021 insurrection of the
US Capitol, and the COVID-19 pandemic. Our studies reveal crucial longitudinal
patterns in these new waves concerning the evolution of events and the pressing
need for techniques to rapidly update existing moderation tools to counteract
them. Comparative evaluations against state-of-the-art tools illustrate the
superiority of our framework, showcasing a substantial 22.22% to 83.33%
improvement in detecting the three new waves of online hate. Our work
highlights the severe threat posed by the emergence of new waves of online hate
and represents a paradigm shift in addressing this threat practically.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15101" title="Abstract">arXiv:2312.15101</a> [<a href="/pdf/2312.15101" title="Download PDF">pdf</a>, <a href="/format/2312.15101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fix-Con: Automatic Fault Localization and Repair of Deep Learning Model  Conversions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louloudakis%2C+N">Nikolaos Louloudakis</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+P">Perry Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+J">Jos&#xe9; Cano</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+A">Ajitha Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 4 tables, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Converting deep learning models between frameworks is a common step to
maximize model compatibility across devices and leverage optimization features
that may be exclusively provided in one deep learning framework. However, this
conversion process may be riddled with bugs, making the converted models either
undeployable or problematic, considerably degrading their prediction
correctness.
<br />We propose an automated approach for fault localization and repair, Fix-Con,
during model conversion between deep learning frameworks. Fix-Con is capable of
detecting and fixing faults introduced in model input, parameters,
hyperparameters, and the model graph during conversion.
<br />Fix-Con uses a set of fault types mined from surveying conversion issues
raised to localize potential conversion faults in the converted target model,
and then repairs them appropriately, e.g. replacing the parameters of the
target model with those from the source model. This is done iteratively for
every image in the dataset with output label differences between the source
model and the converted target model until all differences are resolved. We
evaluate the effectiveness of Fix-Con in fixing model conversion bugs of three
widely used image recognition models converted across four different deep
learning frameworks. Overall, Fix-Con was able to either completely repair, or
significantly improve the performance of 14 out of the 15 erroneous conversion
cases.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15102" title="Abstract">arXiv:2312.15102</a> [<a href="/pdf/2312.15102" title="Download PDF">pdf</a>, <a href="/format/2312.15102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Sclera Segmentation for Skin-tone Agnostic Face Image Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabbani%2C+W">Wassim Kabbani</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+K">Kiran Raja</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> BIOSIG 2023. Gesellschaft f\"ur Informatik e.V. ISSN: 1617-5468.
  ISBN: 978-3-88579-733-3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Face image quality assessment (FIQA) is crucial for obtaining good face
recognition performance. FIQA algorithms should be robust and insensitive to
demographic factors. The eye sclera has a consistent whitish color in all
humans regardless of their age, ethnicity and skin-tone. This work proposes a
robust sclera segmentation method that is suitable for face images in the
enrolment and the border control face recognition scenarios. It shows how the
statistical analysis of the sclera pixels produces features that are invariant
to skin-tone, age and ethnicity and thus can be incorporated into FIQA
algorithms to make them agnostic to demographic factors.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15103" title="Abstract">arXiv:2312.15103</a> [<a href="/pdf/2312.15103" title="Download PDF">pdf</a>, <a href="/format/2312.15103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based learning algorithms for analog computing: a comparative  study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scellier%2C+B">Benjamin Scellier</a>, 
<a href="/search/cs?searchtype=author&query=Ernoult%2C+M">Maxence Ernoult</a>, 
<a href="/search/cs?searchtype=author&query=Kendall%2C+J">Jack Kendall</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Suhas Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Energy-based learning algorithms have recently gained a surge of interest due
to their compatibility with analog (post-digital) hardware. Existing algorithms
include contrastive learning (CL), equilibrium propagation (EP) and coupled
learning (CpL), all consisting in contrasting two states, and differing in the
type of perturbation used to obtain the second state from the first one.
However, these algorithms have never been explicitly compared on equal footing
with same models and datasets, making it difficult to assess their scalability
and decide which one to select in practice. In this work, we carry out a
comparison of seven learning algorithms, namely CL and different variants of EP
and CpL depending on the signs of the perturbations. Specifically, using these
learning algorithms, we train deep convolutional Hopfield networks (DCHNs) on
five vision tasks (MNIST, F-MNIST, SVHN, CIFAR-10 and CIFAR-100). We find that,
while all algorithms yield comparable performance on MNIST, important
differences in performance arise as the difficulty of the task increases. Our
key findings reveal that negative perturbations are better than positive ones,
and highlight the centered variant of EP (which uses two perturbations of
opposite sign) as the best-performing algorithm. We also endorse these findings
with theoretical arguments. Additionally, we establish new SOTA results with
DCHNs on all five datasets, both in performance and speed. In particular, our
DCHN simulations are 13.5 times faster with respect to Laborieux et al. (2021),
which we achieve thanks to the use of a novel energy minimisation algorithm
based on asynchronous updates, combined with reduced precision (16 bits).
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15106" title="Abstract">arXiv:2312.15106</a> [<a href="/pdf/2312.15106" title="Download PDF">pdf</a>, <a href="/format/2312.15106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI and the History of Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ploennigs%2C+J">Joern Ploennigs</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+M">Markus Berger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> chapter to appear in Decoding Cultural Heritage with AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Recent generative AI platforms are able to create texts or impressive images
from simple text prompts. This makes them powerful tools for summarizing
knowledge about architectural history or deriving new creative work in early
design tasks like ideation, sketching and modelling. But, how good is the
understanding of the generative AI models of the history of architecture? Has
it learned to properly distinguish styles, or is it hallucinating information?
In this chapter, we investigate this question for generative AI platforms for
text and image generation for different architectural styles, to understand the
capabilities and boundaries of knowledge of those tools. We also analyze how
they are already being used by analyzing a data set of 101 million Midjourney
queries to see if and how practitioners are already querying for specific
architectural concepts.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15108" title="Abstract">arXiv:2312.15108</a> [<a href="/pdf/2312.15108" title="Download PDF">pdf</a>, <a href="/format/2312.15108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roaming Performance Analysis and Comparison between Wi-Fi and Private  Cellular Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sathya%2C+V">Vanlin Sathya</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+A">Aasawaree Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+M">Mohit Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+M">Mehmet Yavuz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE ICNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Private network deployment is gaining momentum in warehouses, retail,
automation, health care, and many such use cases to guarantee mission-critical
services with less latency. Guaranteeing the delay-sensitive application in
Wi-Fi is always challenging due to the nature of unlicensed spectrum. As the
device ecosystem keeps growing and expanding, all the current and future
devices can support both Wi-Fi and Private Cellular Network (CBRS is the
primary spectrum in the US for private network deployment). However, due to the
existing infrastructure and huge investment in the dense Wi-Fi network,
consumers prefer two deployment models. The first scenario is deploying the
private network outdoors and using the existing Wi-Fi indoors. The second
scenario is to use the existing Wi-Fi network as a backup for offloading the
traffic indoors and parallely utilizes the private network deployment for less
latency applications. Hence, we expect, in both scenarios, a roaming between
two technologies \emph{i.e.,} Wi-Fi and Private Cellular Network. In this work,
we would like to quantify the roaming performance or service interruption time
when the device moves from Wi-Fi to Private Network (CBRS) and vice-versa.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15109" title="Abstract">arXiv:2312.15109</a> [<a href="/pdf/2312.15109" title="Download PDF">pdf</a>, <a href="/ps/2312.15109" title="Download PostScript">ps</a>, <a href="/format/2312.15109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAS-based Automated Structural Inspection Path Planning via Visual Data  Analytics and Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Benhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M">Mohamad Alipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unmanned Aerial Systems (UAS) have gained significant traction for their
application in infrastructure inspections. However, considering the enormous
scale and complex nature of infrastructure, automation is essential for
improving the efficiency and quality of inspection operations. One of the core
problems in this regard is electing an optimal automated flight path that can
achieve the mission objectives while minimizing flight time. This paper
presents an effective formulation for the path planning problem in the context
of structural inspections. Coverage is guaranteed as a constraint to ensure
damage detectability and path length is minimized as an objective, thus
maximizing efficiency while ensuring inspection quality. A two-stage algorithm
is then devised to solve the path planning problem, composed of a genetic
algorithm for determining the positions of viewpoints and a greedy algorithm
for calculating the poses. A comprehensive sensitivity analysis is conducted to
demonstrate the proposed algorithm's effectiveness and range of applicability.
Applied examples of the algorithm, including partial space inspection with
no-fly zones and focused inspection, are also presented, demonstrating the
flexibility of the proposed method to meet real-world structural inspection
requirements. In conclusion, the results of this study highlight the
feasibility of the proposed approach and establish the groundwork for
incorporating automation into UAS-based structural inspection mission planning.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15112" title="Abstract">arXiv:2312.15112</a> [<a href="/pdf/2312.15112" title="Download PDF">pdf</a>, <a href="/format/2312.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haolun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Knowledge distillation aims to train a compact student network using soft
supervision from a larger teacher network and hard supervision from ground
truths. However, determining an optimal knowledge fusion ratio that balances
these supervisory signals remains challenging. Prior methods generally resort
to a constant or heuristic-based fusion ratio, which often falls short of a
proper balance. In this study, we introduce a novel adaptive method for
learning a sample-wise knowledge fusion ratio, exploiting both the correctness
of teacher and student, as well as how well the student mimics the teacher on
each sample. Our method naturally leads to the intra-sample trilateral
geometric relations among the student prediction ($S$), teacher prediction
($T$), and ground truth ($G$). To counterbalance the impact of outliers, we
further extend to the inter-sample relations, incorporating the teacher's
global average prediction $\bar{T}$ for samples within the same class. A simple
neural network then learns the implicit mapping from the intra- and
inter-sample relations to an adaptive, sample-wise knowledge fusion ratio in a
bilevel-optimization manner. Our approach provides a simple, practical, and
adaptable solution for knowledge distillation that can be employed across
various architectures and model sizes. Extensive experiments demonstrate
consistent improvements over other loss re-weighting methods on image
classification, attack detection, and click-through rate prediction.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15113" title="Abstract">arXiv:2312.15113</a> [<a href="/pdf/2312.15113" title="Download PDF">pdf</a>, <a href="/format/2312.15113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding driver-pedestrian interactions to predict driver yielding:  naturalistic open-source dataset collected in Minnesota
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Klavins%2C+J">Joshua Klavins</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Te Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zafri%2C+N+M">Niaz Mahmud Zafri</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+R">Raphael Stern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Many factors influence the yielding result of a driver-pedestrian
interaction, including traffic volume, vehicle speed, roadway characteristics,
etc. While individual aspects of these interactions have been explored,
comprehensive, naturalistic studies, particularly those considering the built
environment's influence on driver-yielding behavior, are lacking. To address
this gap, our study introduces an extensive open-source dataset, compiled from
video data at 18 unsignalized intersections across Minnesota. Documenting more
than 3000 interactions, this dataset provides a detailed view of
driver-pedestrian interactions and over 50 distinct contextual variables. The
data, which covers individual driver-pedestrian interactions and contextual
factors, is made publicly available at
https://github.com/tianyi17/pedestrian_yielding_data_MN.
<br />Using logistic regression, we developed a classification model that predicts
driver yielding based on the identified variables. Our analysis indicates that
vehicle speed, the presence of parking lots, proximity to parks or schools, and
the width of major road crossings significantly influence driver yielding at
unsignalized intersections. This study contributes to one of the most
comprehensive driver-pedestrian datasets in the US, offering valuable insights
for traffic safety improvements. By making this information available, our
study will support communities across Minnesota and the United States in their
ongoing efforts to improve road safety for pedestrians.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15116" title="Abstract">arXiv:2312.15116</a> [<a href="/pdf/2312.15116" title="Download PDF">pdf</a>, <a href="/format/2312.15116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGAIN: Extended GAn INversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabbani%2C+W">Wassim Kabbani</a>, 
<a href="/search/cs?searchtype=author&query=Grimmer%2C+M">Marcel Grimmer</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 10th European Workshop on Visual Information Processing
  (EUVIP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have witnessed significant advances in
recent years, generating increasingly higher quality images, which are
non-distinguishable from real ones. Recent GANs have proven to encode features
in a disentangled latent space, enabling precise control over various semantic
attributes of the generated facial images such as pose, illumination, or
gender. GAN inversion, which is projecting images into the latent space of a
GAN, opens the door for the manipulation of facial semantics of real face
images. This is useful for numerous applications such as evaluating the
performance of face recognition systems. In this work, EGAIN, an architecture
for constructing GAN inversion models, is presented. This architecture
explicitly addresses some of the shortcomings in previous GAN inversion models.
A specific model with the same name, egain, based on this architecture is also
proposed, demonstrating superior reconstruction quality over state-of-the-art
models, and illustrating the validity of the EGAIN architecture.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15122" title="Abstract">arXiv:2312.15122</a> [<a href="/pdf/2312.15122" title="Download PDF">pdf</a>, <a href="/format/2312.15122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Is All You Need: Training Strong Policies for Autonomous Driving  with JAX-Accelerated Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harmel%2C+M">Moritz Harmel</a>, 
<a href="/search/cs?searchtype=author&query=Paras%2C+A">Anubhav Paras</a>, 
<a href="/search/cs?searchtype=author&query=Pasternak%2C+A">Andreas Pasternak</a>, 
<a href="/search/cs?searchtype=author&query=Linscott%2C+G">Gary Linscott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Reinforcement learning has been used to train policies that outperform even
the best human players in various games. However, a large amount of data is
needed to achieve good performance, which in turn requires building large-scale
frameworks and simulators. In this paper, we study how large-scale
reinforcement learning can be applied to autonomous driving, analyze how the
resulting policies perform as the experiment size is scaled, and what the most
important factors contributing to policy performance are. To do this, we first
introduce a hardware-accelerated autonomous driving simulator, which allows us
to efficiently collect experience from billions of agent steps. This simulator
is paired with a large-scale, multi-GPU reinforcement learning framework. We
demonstrate that simultaneous scaling of dataset size, model size, and agent
steps trained provides increasingly strong driving policies in regard to
collision, traffic rule violations, and progress. In particular, our best
policy reduces the failure rate by 57% while improving progress by 23% compared
to the current state-of-the-art machine learning policies for autonomous
driving.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15123" title="Abstract">arXiv:2312.15123</a> [<a href="/pdf/2312.15123" title="Download PDF">pdf</a>, <a href="/format/2312.15123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Admission Control with Response Time Objectives for Low-latency Online  Data Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Colmenares%2C+J+A">Juan A. Colmenares</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">To provide quick responses to users, Internet companies rely on online data
systems able to answer queries in milliseconds. These systems employ
complementary overload management techniques to ensure they provide a
continued, acceptable service through-out traffic surges, where 'acceptable'
partly means that serviced queries meet or track closely their response time
objectives. Thus, in this paper we present Bouncer, an admission control policy
aimed to keep admitted queries under or near their service level objectives
(SLOs) on percentile response times. It computes inexpensive estimates of
percentile response times for every incoming query and compares the estimates
against the objective values to decide whether to accept or reject the query.
Bouncer allows assigning separate SLOs to different classes of queries in the
workload, implements early rejections to let clients react promptly and to help
data systems avoid doing useless work, and complements other load shedding
policies that guard systems from exceeding their capacity. Moreover, we propose
two starvation avoidance strategies that supplement Bouncer's basic formulation
and prevent query types from receiving no service (starving).
<br />We evaluate Bouncer and its starvation-avoiding variants against other
policies in simulation and on a production-grade in-memory distributed graph
database. Our results show that Bouncer and its variants allow admitted queries
to meet or stay close to the SLOs when the other policies do not. They also
report fewer overall rejections, a small overhead, and with the given latency
SLOs, they let the system reach high utilization. In addition, we observe that
the proposed strategies can stop query starvation, but at the expense of a
modest increase in overall rejections and causing SLO violations for serviced
requests.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15127" title="Abstract">arXiv:2312.15127</a> [<a href="/pdf/2312.15127" title="Download PDF">pdf</a>, <a href="/format/2312.15127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Shaping for Multi-Constraint Safe Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yihang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cen%2C+Z">Zhepeng Cen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peide Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingnan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Online safe reinforcement learning (RL) involves training a policy that
maximizes task efficiency while satisfying constraints via interacting with the
environments. In this paper, our focus lies in addressing the complex
challenges associated with solving multi-constraint (MC) safe RL problems. We
approach the safe RL problem from the perspective of Multi-Objective
Optimization (MOO) and propose a unified framework designed for MC safe RL
algorithms. This framework highlights the manipulation of gradients derived
from constraints. Leveraging insights from this framework and recognizing the
significance of \textit{redundant} and \textit{conflicting} constraint
conditions, we introduce the Gradient Shaping (GradS) method for general
Lagrangian-based safe RL algorithms to improve the training efficiency in terms
of both reward and constraint satisfaction. Our extensive experimentation
demonstrates the effectiveness of our proposed method in encouraging
exploration and learning a policy that improves both safety and reward
performance across various challenging MC safe RL tasks as well as good
scalability to the number of constraints.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15130" title="Abstract">arXiv:2312.15130</a> [<a href="/pdf/2312.15130" title="Download PDF">pdf</a>, <a href="/format/2312.15130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PACE: Pose Annotations in Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Kai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhening Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhengxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruoxi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhou Fang</a>, 
<a href="/search/cs?searchtype=author&query=Harley%2C+A+W">Adam W. Harley</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pose estimation is a crucial task in computer vision, enabling tracking and
manipulating objects in images or videos. While several datasets exist for pose
estimation, there is a lack of large-scale datasets specifically focusing on
cluttered scenes with occlusions. This limitation is a bottleneck in the
development and evaluation of pose estimation methods, particularly toward the
goal of real-world application in environments where occlusions are common.
Addressing this, we introduce PACE (Pose Annotations in Cluttered
Environments), a large-scale benchmark designed to advance the development and
evaluation of pose estimation methods in cluttered scenarios. PACE encompasses
54,945 frames with 257,673 annotations across 300 videos, covering 576 objects
from 44 categories and featuring a mix of rigid and articulated items in
cluttered scenes. To annotate the real-world data efficiently, we developed an
innovative annotation system utilizing a calibrated 3-camera setup. We test
state-of-the-art algorithms in PACE along two tracks: pose estimation, and
object pose tracking, revealing the benchmark's challenges and research
opportunities. We plan to release PACE as a public evaluation benchmark, along
the annotations tools we developed, to stimulate further advancements in the
field. Our code and data is available on https://github.com/qq456cvb/PACE.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15133" title="Abstract">arXiv:2312.15133</a> [<a href="/pdf/2312.15133" title="Download PDF">pdf</a>, <a href="/format/2312.15133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Continuous Implicit Field with Local Distance Indicator for  Arbitrary-Scale Point Cloud Upsampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junsheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Baorui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Shen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhizhong Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Project page: <a href="https://lisj575.github.io/APU-LDI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud upsampling aims to generate dense and uniformly distributed point
sets from a sparse point cloud, which plays a critical role in 3D computer
vision. Previous methods typically split a sparse point cloud into several
local patches, upsample patch points, and merge all upsampled patches. However,
these methods often produce holes, outliers or nonuniformity due to the
splitting and merging process which does not maintain consistency among local
patches. To address these issues, we propose a novel approach that learns an
unsigned distance field guided by local priors for point cloud upsampling.
Specifically, we train a local distance indicator (LDI) that predicts the
unsigned distance from a query point to a local implicit surface. Utilizing the
learned LDI, we learn an unsigned distance field to represent the sparse point
cloud with patch consistency. At inference time, we randomly sample queries
around the sparse point cloud, and project these query points onto the
zero-level set of the learned implicit field to generate a dense point cloud.
We justify that the implicit field is naturally continuous, which inherently
enables the application of arbitrary-scale upsampling without necessarily
retraining for various scales. We conduct comprehensive experiments on both
synthetic data and real scans, and report state-of-the-art results under widely
used benchmarks.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15138" title="Abstract">arXiv:2312.15138</a> [<a href="/pdf/2312.15138" title="Download PDF">pdf</a>, <a href="/format/2312.15138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An FPGA-Based Accelerator for Graph Embedding using Sequential Training  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sunaga%2C+K">Kazuki Sunaga</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Keisuke Sugiura</a>, 
<a href="/search/cs?searchtype=author&query=Matsutani%2C+H">Hiroki Matsutani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A graph embedding is an emerging approach that can represent a graph
structure with a fixed-length low-dimensional vector. node2vec is a well-known
algorithm to obtain such a graph embedding by sampling neighboring nodes on a
given graph with a random walk technique. However, the original node2vec
algorithm typically relies on a batch training of graph structures; thus, it is
not suited for applications in which the graph structure changes after the
deployment. In this paper, we focus on node2vec applications for IoT (Internet
of Things) environments. To handle the changes of graph structures after the
IoT devices have been deployed in edge environments, in this paper we propose
to combine an online sequential training algorithm with node2vec. The proposed
sequentially-trainable model is implemented on a resource-limited FPGA
(Field-Programmable Gate Array) device to demonstrate the benefits of our
approach. The proposed FPGA implementation achieves up to 205.25 times speedup
compared to the original model on CPU. Evaluation results using dynamic graphs
show that although the original model decreases the accuracy, the proposed
sequential model can obtain better graph embedding that can increase the
accuracy even when the graph structure is changed.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15139" title="Abstract">arXiv:2312.15139</a> [<a href="/pdf/2312.15139" title="Download PDF">pdf</a>, <a href="/format/2312.15139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Tooth Arrangement with Joint Features of Point and Mesh  Representations via Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Changsong Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Mengfei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaqian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Ran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuhui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongjin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Tooth arrangement is a crucial step in orthodontics treatment, in which
aligning teeth could improve overall well-being, enhance facial aesthetics, and
boost self-confidence. To improve the efficiency of tooth arrangement and
minimize errors associated with unreasonable designs by inexperienced
practitioners, some deep learning-based tooth arrangement methods have been
proposed. Currently, most existing approaches employ MLPs to model the
nonlinear relationship between tooth features and transformation matrices to
achieve tooth arrangement automatically. However, the limited datasets (which
to our knowledge, have not been made public) collected from clinical practice
constrain the applicability of existing methods, making them inadequate for
addressing diverse malocclusion issues. To address this challenge, we propose a
general tooth arrangement neural network based on the diffusion probabilistic
model. Conditioned on the features extracted from the dental model, the
diffusion probabilistic model can learn the distribution of teeth
transformation matrices from malocclusion to normal occlusion by gradually
denoising from a random variable, thus more adeptly managing real orthodontic
data. To take full advantage of effective features, we exploit both mesh and
point cloud representations by designing different encoding networks to extract
the tooth (local) and jaw (global) features, respectively. In addition to
traditional metrics ADD, PA-ADD, CSA, and ME_{rot}, we propose a new evaluation
metric based on dental arch curves to judge whether the generated teeth meet
the individual normal occlusion. Experimental results demonstrate that our
proposed method achieves state-of-the-art tooth alignment results and
satisfactory occlusal relationships between dental arches. We will publish the
code and dataset.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15140" title="Abstract">arXiv:2312.15140</a> [<a href="/pdf/2312.15140" title="Download PDF">pdf</a>, <a href="/format/2312.15140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Majority-based Preference Diffusion on Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zehmakan%2C+A+N">Ahad N. Zehmakan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAMAS-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Structures and Algorithms (cs.DS); Multiagent Systems (cs.MA); Combinatorics (math.CO); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We study a majority based preference diffusion model in which the members of
a social network update their preferences based on those of their connections.
Consider an undirected graph where each node has a strict linear order over a
set of $\alpha$ alternatives. At each round, a node randomly selects two
adjacent alternatives and updates their relative order with the majority view
of its neighbors. We bound the convergence time of the process in terms of the
number of nodes/edges and $\alpha$. Furthermore, we study the minimum cost to
ensure that a desired alternative will ``win'' the process, where occupying
each position in a preference order of a node has a cost. We prove tight bounds
on the minimum cost for general graphs and graphs with strong expansion
properties. Furthermore, we investigate a more light-weight process where each
node chooses one of its neighbors uniformly at random and copies its order
fully with some fixed probability and remains unchanged otherwise. We
characterize the convergence properties of this process, namely convergence
time and stable states, using Martingale and reversible Markov chain analysis.
Finally, we present the outcomes of our experiments conducted on different
synthetic random graph models and graph data from online social platforms.
These experiments not only support our theoretical findings, but also shed some
light on some other fundamental problems, such as designing powerful
countermeasures.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15141" title="Abstract">arXiv:2312.15141</a> [<a href="/pdf/2312.15141" title="Download PDF">pdf</a>, <a href="/format/2312.15141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Performance of Echo State Networks Through Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehlers%2C+P+J">Peter J. Ehlers</a>, 
<a href="/search/cs?searchtype=author&query=Nurdin%2C+H+I">Hendra I. Nurdin</a>, 
<a href="/search/cs?searchtype=author&query=Soh%2C+D">Daniel Soh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Adaptation and Self-Organizing Systems (nlin.AO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Reservoir computing, using nonlinear dynamical systems, offers a
cost-effective alternative to neural networks for complex tasks involving
processing of sequential data, time series modeling, and system identification.
Echo state networks (ESNs), a type of reservoir computer, mirror neural
networks but simplify training. They apply fixed, random linear transformations
to the internal state, followed by nonlinear changes. This process, guided by
input signals and linear regression, adapts the system to match target
characteristics, reducing computational demands. A potential drawback of ESNs
is that the fixed reservoir may not offer the complexity needed for specific
problems. While directly altering (training) the internal ESN would reintroduce
the computational burden, an indirect modification can be achieved by
redirecting some output as input. This feedback can influence the internal
reservoir state, yielding ESNs with enhanced complexity suitable for broader
challenges. In this paper, we demonstrate that by feeding some component of the
reservoir state back into the network through the input, we can drastically
improve upon the performance of a given ESN. We rigorously prove that, for any
given ESN, feedback will almost always improve the accuracy of the output. For
a set of three tasks, each representing different problem classes, we find that
with feedback the average error measures are reduced by $30\%-60\%$.
Remarkably, feedback provides at least an equivalent performance boost to
doubling the initial number of computational nodes, a computationally expensive
and technologically challenging alternative. These results demonstrate the
broad applicability and substantial usefulness of this feedback scheme.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15144" title="Abstract">arXiv:2312.15144</a> [<a href="/pdf/2312.15144" title="Download PDF">pdf</a>, <a href="/format/2312.15144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Decoupling Contrastive Learning for Skeleton-based  Human Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yonghao Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Skeleton-based action recognition is a central task of human-computer
interaction. Current methods apply the modeling paradigm of image recognition
to it directly. However, the skeleton sequences abstracted from the human body
is a sparse representation. The features extracted from the skeleton encoder
are spatiotemporal decoupled, which may confuse the semantics. To reduce the
coupling and improve the semantics of the global features, we propose a
framework (STD-CL) for skeleton-based action recognition. We first decouple the
spatial-specific and temporal-specific features from the spatiotemporal
features. Then we apply the attentive features to contrastive learning, which
pulls together the features from the positive pairs and pushes away the feature
embedding from the negative pairs. Moreover, the proposed training strategy
STD-CL can be incorporated into current methods. Without additional compute
consumption in the testing phase, our STD-CL with four various backbones (HCN,
2S-AGCN, CTR-GCN, and Hyperformer) achieves improvement on NTU60, NTU120, and
NW-UCLA benchmarks. We will release our code at:
https://github.com/BUPTSJZhang/STD-CL.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15145" title="Abstract">arXiv:2312.15145</a> [<a href="/pdf/2312.15145" title="Download PDF">pdf</a>, <a href="/format/2312.15145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routing on Heavy Path WSPD Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+P">Prosenjit Bose</a>, 
<a href="/search/cs?searchtype=author&query=Tuttle%2C+T">Tyler Tuttle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">In this article, we present a construction of a spanner on a set of $n$
points in $\mathbf{R}^d$ that we call a heavy path WSPD spanner. The
construction is parameterized by a constant $s &gt; 2$ called the separation
ratio. The size of the graph is $O(s^dn)$ and the spanning ratio is at most $1
+ 2/s + 2/(s - 1)$. We also show that this graph has a hop spanning ratio of at
most $2\lg n + 1$.
<br />We present a memoryless local routing algorithm for heavy path WSPD spanners.
The routing algorithm requires a vertex $v$ of the graph to store
$O(\mathrm{deg}(v)\log n)$ bits of information, where $\mathrm{deg}(v)$ is the
degree of $v$. The routing ratio is at most $1 + 4/s + 1/(s - 1)$ and at least
$1 + 4/s$ in the worst case. The number of edges on the routing path is bounded
by $2\lg n + 1$.
<br />We then show that the heavy path WSPD spanner can be constructed in metric
spaces of bounded doubling dimension. These metric spaces have been studied in
computational geometry as a generalization of Euclidean space. We show that, in
a metric space with doubling dimension $\lambda$, the heavy path WSPD spanner
has size $O(s^\lambda n)$ where $s$ is the separation ratio. The spanning ratio
and hop spanning ratio are the same as in the Euclidean case.
<br />Finally, we show that the local routing algorithm works in the bounded
doubling dimension case. The vertices require the same amount of storage, but
the routing ratio becomes at most $1 + (2 + \frac{\tau}{\tau-1})/s + 1/(s - 1)$
in the worst case, where $\tau \ge 11$ is a constant related to the doubling
dimension.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15148" title="Abstract">arXiv:2312.15148</a> [<a href="/pdf/2312.15148" title="Download PDF">pdf</a>, <a href="/format/2312.15148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Federated Learning with Attention-based Client Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cong Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Personalized Federated Learning (PFL) relies on collective data knowledge to
build customized models. However, non-IID data between clients poses
significant challenges, as collaborating with clients who have diverse data
distributions can harm local model performance, especially with limited
training data. To address this issue, we propose FedACS, a new PFL algorithm
with an Attention-based Client Selection mechanism. FedACS integrates an
attention mechanism to enhance collaboration among clients with similar data
distributions and mitigate the data scarcity issue. It prioritizes and
allocates resources based on data similarity. We further establish the
theoretical convergence behavior of FedACS. Experiments on CIFAR10 and FMNIST
validate FedACS's superiority, showcasing its potential to advance personalized
federated learning. By tackling non-IID data challenges and data scarcity,
FedACS offers promising advances in the field of personalized federated
learning.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15150" title="Abstract">arXiv:2312.15150</a> [<a href="/pdf/2312.15150" title="Download PDF">pdf</a>, <a href="/ps/2312.15150" title="Download PostScript">ps</a>, <a href="/format/2312.15150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Inner Workings of Windows Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulshrestha%2C+A+A">Ashvini A Kulshrestha</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanqun Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The year 2022 saw a significant increase in Microsoft vulnerabilities,
reaching an all-time high in the past decade. With new vulnerabilities
constantly emerging, there is an urgent need for proactive approaches to harden
systems and protect them from potential cyber threats. This project aims to
investigate the vulnerabilities of the Windows Operating System and explore the
effectiveness of key security features such as BitLocker, Microsoft Defender,
and Windows Firewall in addressing these threats. To achieve this, various
security threats are simulated in controlled environments using coded examples,
allowing for a thorough evaluation of the security solutions' effectiveness.
Based on the results, this study will provide recommendations for mitigation
strategies to enhance system security and strengthen the protection provided by
Windows security features. By identifying potential weaknesses and areas of
improvement in the Windows security infrastructure, this project will
contribute to the development of more robust and resilient security solutions
that can better safeguard systems against emerging cyber threats.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15152" title="Abstract">arXiv:2312.15152</a> [<a href="/pdf/2312.15152" title="Download PDF">pdf</a>, <a href="/ps/2312.15152" title="Download PostScript">ps</a>, <a href="/format/2312.15152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Classification With Multiprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dixit%2C+A">Anuja Dixit</a>, 
<a href="/search/cs?searchtype=author&query=Byreddy%2C+S">Shreya Byreddy</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanqun Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Classification is one of the most important tasks in Machine Learning (ML)
and with recent advancements in artificial intelligence (AI) it is important to
find efficient ways to implement it. Generally, the choice of classification
algorithm depends on the data it is dealing with, and accuracy of the algorithm
depends on the hyperparameters it is tuned with. One way is to check the
accuracy of the algorithms by executing it with different hyperparameters
serially and then selecting the parameters that give the highest accuracy to
predict the final output. This paper proposes another way where the algorithm
is parallelly trained with different hyperparameters to reduce the execution
time. In the end, results from all the trained variations of the algorithms are
ensembled to exploit the parallelism and improve the accuracy of prediction.
Python multiprocessing is used to test this hypothesis with different
classification algorithms such as K-Nearest Neighbors (KNN), Support Vector
Machines (SVM), random forest and decision tree and reviews factors affecting
parallelism. Ensembled output considers the predictions from all processes and
final class is the one predicted by maximum number of processes. Doing this
increases the reliability of predictions. We conclude that ensembling improves
accuracy and multiprocessing reduces execution time for selected algorithms.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15153" title="Abstract">arXiv:2312.15153</a> [<a href="/pdf/2312.15153" title="Download PDF">pdf</a>, <a href="/ps/2312.15153" title="Download PostScript">ps</a>, <a href="/format/2312.15153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Implementation Considerations for a Virtual File System Using  an Inode Data Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qin Sun</a>, 
<a href="/search/cs?searchtype=author&query=McKenzie%2C+G">Grace McKenzie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanqun Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Cryptography and Security (cs.CR); Systems and Control (eess.SY)

</div>
<p class="mathjax">Virtual file systems are a tool to centralize and mobilize a file system that
could otherwise be complex and consist of multiple hierarchies, hard disks, and
more. In this paper, we discuss the design of Unix-based file systems and how
this type of file system layout using inode data structures and a disk emulator
can be implemented as a single-file virtual file system in Linux. We explore
the ways that virtual file systems are vulnerable to security attacks and
introduce straightforward solutions that can be implemented to help prevent or
mitigate the consequences of such attacks.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15156" title="Abstract">arXiv:2312.15156</a> [<a href="/pdf/2312.15156" title="Download PDF">pdf</a>, <a href="/format/2312.15156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Zero-Shot Keyphrase Extractor: A Preliminary  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xuelian Geng</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Songfang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shilong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liping Jing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report, 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Zero-shot keyphrase extraction aims to build a keyphrase extractor without
training by human-annotated data, which is challenging due to the limited human
intervention involved. Challenging but worthwhile, zero-shot setting
efficiently reduces the time and effort that data labeling takes. Recent
efforts on pre-trained large language models (e.g., ChatGPT and ChatGLM) show
promising performance on zero-shot settings, thus inspiring us to explore
prompt-based methods. In this paper, we ask whether strong keyphrase extraction
models can be constructed by directly prompting the large language model
ChatGPT. Through experimental results, it is found that ChatGPT still has a lot
of room for improvement in the keyphrase extraction task compared to existing
state-of-the-art unsupervised and supervised models.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15157" title="Abstract">arXiv:2312.15157</a> [<a href="/pdf/2312.15157" title="Download PDF">pdf</a>, <a href="/format/2312.15157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeScholar: Growing Idiomatic Code Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetty%2C+M">Manish Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+K">Koushik Sen</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">Programmers often search for usage examples for API methods. A tool that
could generate realistic, idiomatic, and contextual usage examples for one or
more APIs would be immensely beneficial to developers. Such a tool would
relieve the need for a deep understanding of the API landscape, augment
existing documentation, and help discover interactions among APIs. We present
CodeScholar, a tool that generates idiomatic code examples demonstrating the
common usage of API methods. It includes a novel neural-guided search technique
over graphs that grows the query APIs into idiomatic code examples. Our user
study demonstrates that in 70% of cases, developers prefer CodeScholar
generated examples over state-of-the-art large language models (LLM) like
GPT3.5. We quantitatively evaluate 60 single and 25 multi-API queries from 6
popular Python libraries and show that across-the-board CodeScholar generates
more realistic, diverse, and concise examples. In addition, we show that
CodeScholar not only helps developers but also LLM-powered programming
assistants generate correct code in a program synthesis setting.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15158" title="Abstract">arXiv:2312.15158</a> [<a href="/pdf/2312.15158" title="Download PDF">pdf</a>, <a href="/format/2312.15158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Map-Reduce for Multiprocessing Large Data and Multi-threading for Data  Scraping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Qiu%2C+Z">Zefeng Qiu</a>, 
<a href="/search/math?searchtype=author&query=Umapathy%2C+P">Prashanth Umapathy</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qingquan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+G">Guanqun Song</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This document is the final project report for our advanced operating system
class. During this project, we mainly focused on applying multiprocessing and
multi-threading technology to our whole project and utilized the map-reduce
algorithm in our data cleaning and data analysis process. In general, our
project can be divided into two components: data scraping and data processing,
where the previous part was almost web wrangling with employing potential
multiprocessing or multi-threading technology to speed up the whole process.
And after we collect and scrape a large amount value of data as mentioned
above, we can use them as input to implement data cleaning and data analysis,
during this period, we take advantage of the map-reduce algorithm to increase
efficiency.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15159" title="Abstract">arXiv:2312.15159</a> [<a href="/pdf/2312.15159" title="Download PDF">pdf</a>, <a href="/format/2312.15159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Potential of FPGA-Based Spatial Acceleration for Large  Language Model Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongzheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yixiao Du</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Shaojie Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zichao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Niansong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yaohui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) boasting billions of
parameters have generated a significant demand for efficient deployment in
inference workloads. The majority of existing approaches rely on temporal
architectures that reuse hardware units for different network layers and
operators. However, these methods often encounter challenges in achieving low
latency due to considerable memory access overhead. This paper investigates the
feasibility and potential of model-specific spatial acceleration for LLM
inference on FPGAs. Our approach involves the specialization of distinct
hardware units for specific operators or layers, facilitating direct
communication between them through a dataflow architecture while minimizing
off-chip memory accesses. We introduce a comprehensive analytical model for
estimating the performance of a spatial LLM accelerator, taking into account
the on-chip compute and memory resources available on an FPGA. Through our
analysis, we can determine the scenarios in which FPGA-based spatial
acceleration can outperform its GPU-based counterpart. To enable more
productive implementations of an LLM model on FPGAs, we further provide a
library of high-level synthesis (HLS) kernels that are composable and reusable.
This library will be made available as open-source. To validate the
effectiveness of both our analytical model and HLS library, we have implemented
BERT and GPT2 on an AMD Alveo U280 FPGA device. Experimental results
demonstrate our approach can achieve up to 16.1x speedup when compared to
previous FPGA-based accelerators for the BERT model. For GPT generative
inference, we attain a 2.2x speedup compared to DFX, an FPGA overlay, in the
prefill stage, while achieving a 1.9x speedup and a 5.7x improvement in energy
efficiency compared to the NVIDIA A100 GPU in the decode stage.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15160" title="Abstract">arXiv:2312.15160</a> [<a href="/pdf/2312.15160" title="Download PDF">pdf</a>, <a href="/format/2312.15160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-AI Collaboration in Real-World Complex Environment with  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Saiful Islam</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srijita Das</a>, 
<a href="/search/cs?searchtype=author&query=Gottipati%2C+S+K">Sai Krishna Gottipati</a>, 
<a href="/search/cs?searchtype=author&query=Duguay%2C+W">William Duguay</a>, 
<a href="/search/cs?searchtype=author&query=Mars%2C+C">Clod&#xe9;ric Mars</a>, 
<a href="/search/cs?searchtype=author&query=Arabneydi%2C+J">Jalal Arabneydi</a>, 
<a href="/search/cs?searchtype=author&query=Fagette%2C+A">Antoine Fagette</a>, 
<a href="/search/cs?searchtype=author&query=Guzdial%2C+M">Matthew Guzdial</a>, 
<a href="/search/cs?searchtype=author&query=Matthew-E-Taylor">Matthew-E-Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Neural Computing and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Recent advances in reinforcement learning (RL) and Human-in-the-Loop (HitL)
learning have made human-AI collaboration easier for humans to team with AI
agents. Leveraging human expertise and experience with AI in intelligent
systems can be efficient and beneficial. Still, it is unclear to what extent
human-AI collaboration will be successful, and how such teaming performs
compared to humans or AI agents only. In this work, we show that learning from
humans is effective and that human-AI collaboration outperforms
human-controlled and fully autonomous AI agents in a complex simulation
environment. In addition, we have developed a new simulator for critical
infrastructure protection, focusing on a scenario where AI-powered drones and
human teams collaborate to defend an airport against enemy drone attacks. We
develop a user interface to allow humans to assist AI agents effectively. We
demonstrated that agents learn faster while learning from policy correction
compared to learning from humans or agents. Furthermore, human-AI collaboration
requires lower mental and temporal demands, reduces human effort, and yields
higher performance than if humans directly controlled all agents. In
conclusion, we show that humans can provide helpful advice to the RL agents,
allowing them to improve learning in a multi-agent setting.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15161" title="Abstract">arXiv:2312.15161</a> [<a href="/pdf/2312.15161" title="Download PDF">pdf</a>, <a href="/ps/2312.15161" title="Download PostScript">ps</a>, <a href="/format/2312.15161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Networks of Classical Conditioning Gates and Their Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azuma%2C+S">Shun-ichi Azuma</a>, 
<a href="/search/cs?searchtype=author&query=Takakura%2C+D">Dai Takakura</a>, 
<a href="/search/cs?searchtype=author&query=Ariizumi%2C+R">Ryo Ariizumi</a>, 
<a href="/search/cs?searchtype=author&query=Asai%2C+T">Toru Asai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to New Generation Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Chemical AI is chemically synthesized artificial intelligence that has the
ability of learning in addition to information processing. A research project
on chemical AI, called the Molecular Cybernetics Project, was launched in Japan
in 2021 with the goal of creating a molecular machine that can learn a type of
conditioned reflex through the process called classical conditioning. If the
project succeeds in developing such a molecular machine, the next step would be
to configure a network of such machines to realize more complex functions. With
this motivation, this paper develops a method for learning a desired function
in the network of nodes each of which can implement classical conditioning.
First, we present a model of classical conditioning, which is called here a
classical conditioning gate. We then propose a learning algorithm for the
network of classical conditioning gates.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15162" title="Abstract">arXiv:2312.15162</a> [<a href="/pdf/2312.15162" title="Download PDF">pdf</a>, <a href="/format/2312.15162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cycle-Consistency Learning for Captioning and Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiajun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mingbo Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present that visual grounding and image captioning, which perform as two
mutually inverse processes, can be bridged together for collaborative training
by careful designs. By consolidating this idea, we introduce CyCo, a
cyclic-consistent learning framework to ameliorate the independent training
pipelines of visual grounding and image captioning. The proposed framework (1)
allows the semi-weakly supervised training of visual grounding; (2) improves
the performance of fully supervised visual grounding; (3) yields a general
captioning model that can describe arbitrary image regions. Extensive
experiments show that our fully supervised grounding model achieves
state-of-the-art performance, and the semi-weakly supervised one also exhibits
competitive performance compared to the fully supervised counterparts. Our
image captioning model has the capability to freely describe image regions and
meanwhile shows impressive performance on prevalent captioning benchmarks.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15163" title="Abstract">arXiv:2312.15163</a> [<a href="/pdf/2312.15163" title="Download PDF">pdf</a>, <a href="/format/2312.15163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Safe Occupancy Strategies in Educational  Spaces during an Epidemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ondula%2C+E+A">Elizabeth Akinyi Ondula</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Epidemic modeling, encompassing deterministic and stochastic approaches, is
vital for understanding infectious diseases and informing public health
strategies. This research adopts a prescriptive approach, focusing on
reinforcement learning (RL) to develop strategies that balance minimizing
infections with maximizing in-person interactions in educational settings. We
introduce SafeCampus , a novel tool that simulates infection spread and
facilitates the exploration of various RL algorithms in response to epidemic
challenges. SafeCampus incorporates a custom RL environment, informed by
stochastic epidemic models, to realistically represent university campus
dynamics during epidemics. We evaluate Q-learning for a discretized state space
which resulted in a policy matrix that not only guides occupancy decisions
under varying epidemic conditions but also illustrates the inherent trade-off
in epidemic management. This trade-off is characterized by the dilemma between
stricter measures, which may effectively reduce infections but impose less
educational benefit (more in-person interactions), and more lenient policies,
which could lead to higher infection rates.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15166" title="Abstract">arXiv:2312.15166</a> [<a href="/pdf/2312.15166" title="Download PDF">pdf</a>, <a href="/format/2312.15166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective  Depth Up-Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dahyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonsung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wonho Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yungi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyeonju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+C">Changbae Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Seonghoon Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sukyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunbyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Gim%2C+G">Gyoungjin Gim</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+M">Mikyoung Cha</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hwalsuk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunghun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce depth up-scaling (DUS), a novel technique to up-scale base LLMs
efficiently and effectively in a simple manner. In contrast to
mixture-of-experts (MoE), DUS does not require complex changes to train and
inference. Using DUS, we build SOLAR 10.7B, a large language model (LLM) with
10.7 billion parameters, demonstrating superior performance in various natural
language processing (NLP) tasks. Comparative evaluations show that SOLAR 10.7B
outperforms existing open-source pretrained LLMs, such as Llama 2 and Mistral
7B. We additionally present SOLAR 10.7B-Instruct, a variant fine-tuned for
instruction-following capabilities, surpassing Mixtral-8x7B. SOLAR 10.7B is
publicly available under the Apache 2.0 license, promoting broad access and
application in the LLM field.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15167" title="Abstract">arXiv:2312.15167</a> [<a href="/pdf/2312.15167" title="Download PDF">pdf</a>, <a href="/format/2312.15167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of One-Bit Quantized Linear Precoding Schemes in Multi-Cell  Massive MIMO Downlink
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+Q">Qurrat-Ul-Ain Nadeem</a>, 
<a href="/search/cs?searchtype=author&query=Chaaban%2C+A">Anas Chaaban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This work studies a multi-cell one-bit massive multiple-input multiple-output
(MIMO) system that employs one-bit analog-to-digital converters (ADCs) and
digital-to-analog converters (DACs) at each base station (BS). We utilize
Bussgang decomposition to derive downlink
signal-to-quantization-plus-interference-plus-noise ratio (SQINR) and ergodic
achievable rate expressions under one-bit quantized maximum ratio transmission
(MRT) and zero-forcing (ZF) precoding schemes considering scenarios with and
without pilot contamination (PC) in the derived channel estimates. The results
are also simplified for the mixed architecture that employs full resolution
(FR) ADCs and one-bit DACs, and the conventional architecture that employs FR
ADCs and DACs. The SQINR is shown to decrease by a factor of $2/\pi$ and
$4/\pi^2$ in the one-bit setting compared to that achieved in the mixed setting
and conventional setting respectively under MRT precoding without PC.
Interestingly, the decrease in SQINR is less when we consider PC, which is
shown to adversely impact the conventional system more than the one-bit system.
Similar insights are obtained under ZF precoding with the decrease in the SQINR
with the use of one-bit ADCs and DACs being more pronounced. We utilize the
derived expressions to yield performance insights related to power efficiency,
the numbers of antennas needed by the three architectures to achieve the same
sum-rate, and energy efficiency.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15172" title="Abstract">arXiv:2312.15172</a> [<a href="/pdf/2312.15172" title="Download PDF">pdf</a>, <a href="/format/2312.15172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Trojan Attacks for Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aishan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yisong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuguang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiakai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianglong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-trained vision models (PVMs) have become a dominant component due to
their exceptional performance when fine-tuned for downstream tasks. However,
the presence of backdoors within PVMs poses significant threats. Unfortunately,
existing studies primarily focus on backdooring PVMs for the classification
task, neglecting potential inherited backdoors in downstream tasks such as
detection and segmentation. In this paper, we propose the Pre-trained Trojan
attack, which embeds backdoors into a PVM, enabling attacks across various
downstream vision tasks. We highlight the challenges posed by cross-task
activation and shortcut connections in successful backdoor attacks. To achieve
effective trigger activation in diverse tasks, we stylize the backdoor trigger
patterns with class-specific textures, enhancing the recognition of
task-irrelevant low-level features associated with the target class in the
trigger pattern. Moreover, we address the issue of shortcut connections by
introducing a context-free learning pipeline for poison training. In this
approach, triggers without contextual backgrounds are directly utilized as
training data, diverging from the conventional use of clean images.
Consequently, we establish a direct shortcut from the trigger to the target
class, mitigating the shortcut connection issue. We conducted extensive
experiments to thoroughly validate the effectiveness of our attacks on
downstream detection and segmentation tasks. Additionally, we showcase the
potential of our approach in more practical scenarios, including large vision
models and 3D object detection in autonomous driving. This paper aims to raise
awareness of the potential threats associated with applying PVMs in practical
scenarios. Our codes will be available upon paper publication.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15174" title="Abstract">arXiv:2312.15174</a> [<a href="/pdf/2312.15174" title="Download PDF">pdf</a>, <a href="/ps/2312.15174" title="Download PostScript">ps</a>, <a href="/format/2312.15174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Bridge Toward 6G: 5G-Advanced Evolution in 3GPP Release 19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xingqin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The 3rd generation partnership project (3GPP) initiated 5G-Advanced in
Release 18, laying a solid foundation for the further evolution of 5G-Advanced.
Release 19-the next wave of 5G-Advanced-will primarily focus on commercial
deployment needs while serving as a bridge toward 6G. In this article, we
provide an in-depth overview of the 5G-Advanced evolution in 3GPP Release 19.
We not only delve into the key technology components and their corresponding
use cases in 5G-Advanced evolution but also shed light on initial 3GPP studies
toward 6G.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15175" title="Abstract">arXiv:2312.15175</a> [<a href="/pdf/2312.15175" title="Download PDF">pdf</a>, <a href="/format/2312.15175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed neural network for modeling dynamic linear elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kag%2C+V">Vijay Kag</a>, 
<a href="/search/cs?searchtype=author&query=Gopinath%2C+V">Venkatesh Gopinath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">In this work, we present the physics-informed neural network (PINN) model
applied particularly to dynamic problems in solid mechanics. We focus on
forward and inverse problems. Particularly, we show how a PINN model can be
used efficiently for material identification in a dynamic setting. In this
work, we assume linear continuum elasticity. We show results for
two-dimensional (2D) plane strain problem and then we proceed to apply the same
techniques for a three-dimensional (3D) problem. As for the training data we
use the solution based on the finite element method. We rigorously show that
PINN models are accurate, robust and computationally efficient, especially as a
surrogate model for material identification problems. Also, we employ
state-of-the-art techniques from the PINN literature which are an improvement
to the vanilla implementation of PINN. Based on our results, we believe that
the framework we have developed can be readily adapted to computational
platforms for solving multiple dynamic problems in solid mechanics.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15177" title="Abstract">arXiv:2312.15177</a> [<a href="/pdf/2312.15177" title="Download PDF">pdf</a>, <a href="/format/2312.15177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Data-Driven Predictive Control with Equivalence to Stochastic  MPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ruiqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Simpson-Porco%2C+J+W">John W. Simpson-Porco</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+S+L">Stephen L. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures. The extended version of a submission to IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We propose a data-driven receding-horizon control method dealing with the
chance-constrained output-tracking problem of unknown stochastic linear
time-invariant (LTI) systems with partial state observation. The proposed
method takes into account the statistics of the process noise, the measurement
noise and the uncertain initial condition, following an analogous framework to
Stochastic Model Predictive Control (SMPC), but does not rely on the use of a
parametric system model. As such, our receding-horizon algorithm produces a
sequence of closed-loop control policies for predicted time steps, as opposed
to a sequence of open-loop control actions. Under certain conditions, we
establish that our proposed data-driven control method produces identical
control inputs as that produced by the associated model-based SMPC. Simulation
results on a grid-connected power converter are provided to illustrate the
performance benefits of our methodology.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15181" title="Abstract">arXiv:2312.15181</a> [<a href="/pdf/2312.15181" title="Download PDF">pdf</a>, <a href="/format/2312.15181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Bias Detection and Mitigation for Indian Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maity%2C+A">Ankita Maity</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Anubhav Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Dhar%2C+R">Rudra Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Abhishek%2C+T">Tushar Abhishek</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Manish Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+V">Vasudeva Varma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Lack of diverse perspectives causes neutrality bias in Wikipedia content
leading to millions of worldwide readers getting exposed by potentially
inaccurate information. Hence, neutrality bias detection and mitigation is a
critical problem. Although previous studies have proposed effective solutions
for English, no work exists for Indian languages. First, we contribute two
large datasets, mWikiBias and mWNC, covering 8 languages, for the bias
detection and mitigation tasks respectively. Next, we investigate the
effectiveness of popular multilingual Transformer-based models for the two
tasks by modeling detection as a binary classification problem and mitigation
as a style transfer problem. We make the code and data publicly available.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15184" title="Abstract">arXiv:2312.15184</a> [<a href="/pdf/2312.15184" title="Download PDF">pdf</a>, <a href="/format/2312.15184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZO-AdaMU Optimizer: Adapting Perturbation by the Momentum and  Uncertainty in Zeroth-order Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuoran Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingcai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Youchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yukang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangping Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuanyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaobao Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Lowering the memory requirement in full-parameter training on large models
has become a hot research area. MeZO fine-tunes the large language models
(LLMs) by just forward passes in a zeroth-order SGD optimizer (ZO-SGD),
demonstrating excellent performance with the same GPU memory usage as
inference. However, the simulated perturbation stochastic approximation for
gradient estimate in MeZO leads to severe oscillations and incurs a substantial
time overhead. Moreover, without momentum regularization, MeZO shows severe
over-fitting problems. Lastly, the perturbation-irrelevant momentum on ZO-SGD
does not improve the convergence rate. This study proposes ZO-AdaMU to resolve
the above problems by adapting the simulated perturbation with momentum in its
stochastic approximation. Unlike existing adaptive momentum methods, we
relocate momentum on simulated perturbation in stochastic gradient
approximation. Our convergence analysis and experiments prove this is a better
way to improve convergence stability and rate in ZO-SGD. Extensive experiments
demonstrate that ZO-AdaMU yields better generalization for LLMs fine-tuning
across various NLP tasks than MeZO and its momentum variants.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15185" title="Abstract">arXiv:2312.15185</a> [<a href="/pdf/2312.15185" title="Download PDF">pdf</a>, <a href="/format/2312.15185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> emotion2vec: Self-Supervised Pre-Training for Speech Emotion  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhisheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiaxin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhifu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code, checkpoints, and extracted features are available at <a href="https://github.com/ddlBoJack/emotion2vec">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose emotion2vec, a universal speech emotion representation model.
emotion2vec is pre-trained on open-source unlabeled emotion data through
self-supervised online distillation, combining utterance-level loss and
frame-level loss during pre-training. emotion2vec outperforms state-of-the-art
pre-trained universal models and emotion specialist models by only training
linear layers for the speech emotion recognition task on the mainstream IEMOCAP
dataset. In addition, emotion2vec shows consistent improvements among 10
different languages of speech emotion recognition datasets. emotion2vec also
shows excellent results on other emotion tasks, such as song emotion
recognition, emotion prediction in conversation, and sentiment analysis.
Comparison experiments, ablation experiments, and visualization comprehensively
demonstrate the universal capability of the proposed emotion2vec. To the best
of our knowledge, emotion2vec is the first universal representation model in
various emotion-related tasks, filling a gap in the field.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15186" title="Abstract">arXiv:2312.15186</a> [<a href="/pdf/2312.15186" title="Download PDF">pdf</a>, <a href="/format/2312.15186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Asynchronous Federated Learning with Sparsification and  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Juncheng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chendi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mianxiong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+D">Dejing Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Concurrency and Computation: Practice and Experience (CCPE), 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While data is distributed in multiple edge devices, Federated Learning (FL)
is attracting more and more attention to collaboratively train a machine
learning model without transferring raw data. FL generally exploits a parameter
server and a large number of edge devices during the whole process of the model
training, while several devices are selected in each round. However, straggler
devices may slow down the training process or even make the system crash during
training. Meanwhile, other idle edge devices remain unused. As the bandwidth
between the devices and the server is relatively low, the communication of
intermediate data becomes a bottleneck. In this paper, we propose
Time-Efficient Asynchronous federated learning with Sparsification and
Quantization, i.e., TEASQ-Fed. TEASQ-Fed can fully exploit edge devices to
asynchronously participate in the training process by actively applying for
tasks. We utilize control parameters to choose an appropriate number of
parallel edge devices, which simultaneously execute the training tasks. In
addition, we introduce a caching mechanism and weighted averaging with respect
to model staleness to further improve the accuracy. Furthermore, we propose a
sparsification and quantitation approach to compress the intermediate data to
accelerate the training. The experimental results reveal that TEASQ-Fed
improves the accuracy (up to 16.67% higher) while accelerating the convergence
of model training (up to twice faster).
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15187" title="Abstract">arXiv:2312.15187</a> [<a href="/pdf/2312.15187" title="Download PDF">pdf</a>, <a href="/format/2312.15187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRG: Generating Synthetic Relational Databases using GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y+C">Y.C. Tay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There is an overgrowing demand for data sharing in academia and industry.
However, such sharing has issues with personal privacy and data
confidentiality. One option is to share only synthetically-generated versions
of the real data. Generative Adversarial Network (GAN) is a recently-popular
technique that can be used for this purpose.
<br />Relational databases usually have multiple tables that are related to each
other. So far, the use of GANs has essentially focused on generating single
tables. This paper presents Incremental Relational Generator (IRG), which uses
GANs to synthetically generate interrelated tables. Given an empirical
relational database, IRG can generate a synthetic version that can be safely
shared.
<br />IRG generates the tables in some sequential order. The key idea is to
construct a context, based on the tables generated so far, when using a GAN to
generate the next table. Experiments with public datasets and private student
data show that IRG outperforms state-of-the-art in terms of statistical
properties and query results.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15188" title="Abstract">arXiv:2312.15188</a> [<a href="/pdf/2312.15188" title="Download PDF">pdf</a>, <a href="/format/2312.15188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSI Measurements and Initial Results for Massive MIMO to UAV  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+Z">Zhuangzhuang Cui</a>, 
<a href="/search/eess?searchtype=author&query=Colpaert%2C+A">Achiel Colpaert</a>, 
<a href="/search/eess?searchtype=author&query=Pollin%2C+S">Sofie Pollin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceeding of Asilomar 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Non-Terrestrial Network (NTN) has been envisioned as a key component of the
sixth-generation (6G) mobile communication system. Meanwhile, unmanned aerial
vehicles (UAVs) play an important role in enabling and deploying NTNs. In this
paper, we focus on massive multi-input multi-output (MaMIMO) supported UAV
communications, where channel state information (CSI) was measured considering
different heights and trajectories of a rotary-wing drone. To characterize the
propagation channel for this air-to-ground link, some initial results were
analyzed, such as stationary distance. To investigate the impact of channels on
communication performance, we analyzed spectral efficiency (SE) by using
Maximum Ratio Combining (MRC). This study shows that the presented
space-time-frequency channel dataset facilitates channel correlation analysis
and supports performance evaluation for MaMIMO-UAV communications.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15190" title="Abstract">arXiv:2312.15190</a> [<a href="/pdf/2312.15190" title="Download PDF">pdf</a>, <a href="/format/2312.15190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAIC: Integration of Speech Anonymization and Identity Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+X">Xingjian Diao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shitong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenjun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech anonymization and de-identification have garnered significant
attention recently, especially in the healthcare area including telehealth
consultations, patient voiceprint matching, and patient real-time monitoring.
Speaker identity classification tasks, which involve recognizing specific
speakers from audio to learn identity features, are crucial for
de-identification. Since rare studies have effectively combined speech
anonymization with identity classification, we propose SAIC - an innovative
pipeline for integrating Speech Anonymization and Identity Classification. SAIC
demonstrates remarkable performance and reaches state-of-the-art in the speaker
identity classification task on the Voxceleb1 dataset, with a top-1 accuracy of
96.1%. Although SAIC is not trained or evaluated specifically on clinical data,
the result strongly proves the model's effectiveness and the possibility to
generalize into the healthcare area, providing insightful guidance for future
work.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15191" title="Abstract">arXiv:2312.15191</a> [<a href="/pdf/2312.15191" title="Download PDF">pdf</a>, <a href="/format/2312.15191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Federated Learning with Contextual Modulation and  Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vettoruzzo%2C+A">Anna Vettoruzzo</a>, 
<a href="/search/cs?searchtype=author&query=Bouguelia%2C+M">Mohamed-Rafik Bouguelia</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6gnvaldsson%2C+T">Thorsteinn R&#xf6;gnvaldsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning has emerged as a promising approach for training machine
learning models on decentralized data sources while preserving data privacy.
However, challenges such as communication bottlenecks, heterogeneity of client
devices, and non-i.i.d. data distribution pose significant obstacles to
achieving optimal model performance. We propose a novel framework that combines
federated learning with meta-learning techniques to enhance both efficiency and
generalization capabilities. Our approach introduces a federated modulator that
learns contextual information from data batches and uses this knowledge to
generate modulation parameters. These parameters dynamically adjust the
activations of a base model, which operates using a MAML-based approach for
model personalization. Experimental results across diverse datasets highlight
the improvements in convergence speed and model performance compared to
existing federated learning approaches. These findings highlight the potential
of incorporating contextual information and meta-learning techniques into
federated learning, paving the way for advancements in distributed machine
learning paradigms.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15194" title="Abstract">arXiv:2312.15194</a> [<a href="/pdf/2312.15194" title="Download PDF">pdf</a>, <a href="/format/2312.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PokeMQA: Programmable knowledge editing for Multi-hop Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hengrui Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruobing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at <a href="https://github.com/Hengrui-Gu/PokeMQA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-hop question answering (MQA) is one of the challenging tasks to
evaluate machine's comprehension and reasoning abilities, where large language
models (LLMs) have widely achieved the human-comparable performance. Due to the
dynamics of knowledge facts in real world, knowledge editing has been explored
to update model with the up-to-date facts while avoiding expensive re-training
or fine-tuning. Starting from the edited fact, the updated model needs to
provide cascading changes in the chain of MQA. The previous art simply adopts a
mix-up prompt to instruct LLMs conducting multiple reasoning tasks
sequentially, including question decomposition, answer generation, and conflict
checking via comparing with edited facts. However, the coupling of these
functionally-diverse reasoning tasks inhibits LLMs' advantages in comprehending
and answering questions while disturbing them with the unskilled task of
conflict checking. We thus propose a framework, Programmable knowledge editing
for Multi-hop Question Answering (PokeMQA), to decouple the jobs. Specifically,
we prompt LLMs to decompose knowledge-augmented multi-hop question, while
interacting with a detached trainable scope detector to modulate LLMs behavior
depending on external conflict signal. The experiments on three LLM backbones
and two benchmark datasets validate our superiority in knowledge editing of
MQA, outperforming all competitors by a large margin in almost all settings and
consistently producing reliable reasoning process.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15195" title="Abstract">arXiv:2312.15195</a> [<a href="/pdf/2312.15195" title="Download PDF">pdf</a>, <a href="/format/2312.15195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Information as Intrinsic Reward of Reinforcement Learning Agents  for On-demand Ride Pooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiahao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yifei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">The emergence of on-demand ride pooling services allows each vehicle to serve
multiple passengers at a time, thus increasing drivers' income and enabling
passengers to travel at lower prices than taxi/car on-demand services (only one
passenger can be assigned to a car at a time like UberX and Lyft). Although
on-demand ride pooling services can bring so many benefits, ride pooling
services need a well-defined matching strategy to maximize the benefits for all
parties (passengers, drivers, aggregation companies and environment), in which
the regional dispatching of vehicles has a significant impact on the matching
and revenue. Existing algorithms often only consider revenue maximization,
which makes it difficult for requests with unusual distribution to get a ride.
How to increase revenue while ensuring a reasonable assignment of requests
brings a challenge to ride pooling service companies (aggregation companies).
In this paper, we propose a framework for vehicle dispatching for ride pooling
tasks, which splits the city into discrete dispatching regions and uses the
reinforcement learning (RL) algorithm to dispatch vehicles in these regions. We
also consider the mutual information (MI) between vehicle and order
distribution as the intrinsic reward of the RL algorithm to improve the
correlation between their distributions, thus ensuring the possibility of
getting a ride for unusually distributed requests. In experimental results on a
real-world taxi dataset, we demonstrate that our framework can significantly
increase revenue up to an average of 3\% over the existing best on-demand ride
pooling method.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15197" title="Abstract">arXiv:2312.15197</a> [<a href="/pdf/2312.15197" title="Download PDF">pdf</a>, <a href="/format/2312.15197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xize Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Tao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+A">Aoxiong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xinyu Duan</a>, 
<a href="/search/cs?searchtype=author&query=yang%2C+c">changpeng yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Direct speech-to-speech translation achieves high-quality results through the
introduction of discrete units obtained from self-supervised learning. This
approach circumvents delays and cascading errors associated with model
cascading. However, talking head translation, converting audio-visual speech
(i.e., talking head video) from one language into another, still confronts
several challenges compared to audio speech: (1) Existing methods invariably
rely on cascading, synthesizing via both audio and text, resulting in delays
and cascading errors. (2) Talking head translation has a limited set of
reference frames. If the generated translation exceeds the length of the
original speech, the video sequence needs to be supplemented by repeating
frames, leading to jarring video transitions. In this work, we propose a model
for talking head translation, \textbf{TransFace}, which can directly translate
audio-visual speech into audio-visual speech in other languages. It consists of
a speech-to-unit translation model to convert audio speech into discrete units
and a unit-based audio-visual speech synthesizer, Unit2Lip, to re-synthesize
synchronized audio-visual speech from discrete units in parallel. Furthermore,
we introduce a Bounded Duration Predictor, ensuring isometric talking head
translation and preventing duplicate reference frames. Experiments demonstrate
that our proposed Unit2Lip model significantly improves synchronization (1.601
and 0.982 on LSE-C for the original and generated audio speech, respectively)
and boosts inference speed by a factor of 4.35 on LRS2. Additionally, TransFace
achieves impressive BLEU scores of 61.93 and 47.55 for Es-En and Fr-En on
LRS3-T and 100% isochronous translations.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15198" title="Abstract">arXiv:2312.15198</a> [<a href="/pdf/2312.15198" title="Download PDF">pdf</a>, <a href="/format/2312.15198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLM Agents Exhibit Social Behavior?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+Y">Yan Leng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Social and Information Networks (cs.SI); General Economics (econ.GN)

</div>
<p class="mathjax">The advances of Large Language Models (LLMs) are expanding their utility in
both academic research and practical applications. Recent social science
research has explored the use of these "black-box" LLM agents for simulating
complex social systems and potentially substituting human subjects in
experiments. Our study delves into this emerging domain, investigating the
extent to which LLMs exhibit key social interaction principles, such as social
learning, social preference, and cooperative behavior, in their interactions
with humans and other agents. We develop a novel framework for our study,
wherein classical laboratory experiments involving human subjects are adapted
to use LLM agents. This approach involves step-by-step reasoning that mirrors
human cognitive processes and zero-shot learning to assess the innate
preferences of LLMs. Our analysis of LLM agents' behavior includes both the
primary effects and an in-depth examination of the underlying mechanisms.
Focusing on GPT-4, the state-of-the-art LLM, our analyses suggest that LLM
agents appear to exhibit a range of human-like social behaviors such as
distributional and reciprocity preferences, responsiveness to group identity
cues, engagement in indirect reciprocity, and social learning capabilities.
However, our analysis also reveals notable differences: LLMs demonstrate a
pronounced fairness preference, weaker positive reciprocity, and a more
calculating approach in social learning compared to humans. These insights
indicate that while LLMs hold great promise for applications in social science
research, such as in laboratory experiments and agent-based modeling, the
subtle behavioral differences between LLM agents and humans warrant further
investigation. Careful examination and development of protocols in evaluating
the social behaviors of LLMs are necessary before directly applying these
models to emulate human behavior.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15199" title="Abstract">arXiv:2312.15199</a> [<a href="/pdf/2312.15199" title="Download PDF">pdf</a>, <a href="/ps/2312.15199" title="Download PostScript">ps</a>, <a href="/format/2312.15199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing Shadows: Low-Light Image Enhancement Using Self-Calibrated  Illumination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koohestani%2C+F">Farzaneh Koohestani</a>, 
<a href="/search/cs?searchtype=author&query=Karimi%2C+N">Nader Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Samavi%2C+S">Shadrokh Samavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In digital imaging, enhancing visual content in poorly lit environments is a
significant challenge, as images often suffer from inadequate brightness,
hidden details, and an overall reduction in quality. This issue is especially
critical in applications like nighttime surveillance, astrophotography, and
low-light videography, where clear and detailed visual information is crucial.
Our research addresses this problem by enhancing the illumination aspect of
dark images. We have advanced past techniques by using varied color spaces to
extract the illumination component, enhance it, and then recombine it with the
other components of the image. By employing the Self-Calibrated Illumination
(SCI) method, a strategy initially developed for RGB images, we effectively
intensify and clarify details that are typically lost in low-light conditions.
This method of selective illumination enhancement leaves the color information
intact, thus preserving the color integrity of the image. Crucially, our method
eliminates the need for paired images, making it suitable for situations where
they are unavailable. Implementing the modified SCI technique represents a
substantial shift from traditional methods, providing a refined and potent
solution for low-light image enhancement. Our approach sets the stage for more
complex image processing techniques and extends the range of possible
real-world applications where accurate color representation and improved
visibility are essential.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15202" title="Abstract">arXiv:2312.15202</a> [<a href="/pdf/2312.15202" title="Download PDF">pdf</a>, <a href="/format/2312.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Code Intelligence Tasks with ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xinjun Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tanghaoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yihao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaoguang Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Pre-trained code models have emerged as crucial tools in various code
intelligence tasks. However, their effectiveness depends on the quality of the
pre-training dataset, particularly the human reference comments, which serve as
a bridge between the programming language and natural language. One significant
challenge is that such comments can become inconsistent with the corresponding
code as the software evolves. This discrepancy can lead to suboptimal training
of the models, decreasing their performances. LLMs have demonstrated superior
capabilities in generating high-quality code comments. In light of that, we try
to tackle the quality issue of the dataset by harnessing the power of LLMs.
Specifically, we raise the question: Can we rebuild the pre-training dataset by
substituting the original comments with LLM-generated ones for more effective
pre-trained code models? To answer the question, we first conduct a
comprehensive evaluation to compare ChatGPT-generated comments with human
reference comments. As existing reference-based metrics treat the reference
comments as gold standards, we introduce two auxiliary tasks as novel
reference-free metrics to assess the quality of comments, i.e., code-comment
inconsistency detection and code search. Experimental results show that
ChatGPT-generated comments demonstrate superior semantic consistency with the
code compared to human references, indicating the potential of utilizing
ChatGPT to enhance the quality of the pre-training dataset. We rebuilt the
widely used dataset, CodeSearchNet, with ChatGPT-generated comments. Subsequent
experiments involve re-pre-training the CodeT5 with our refined
dataset.Evaluation results on four generation tasks and one understanding code
intelligence tasks show that the model pre-trained by ChatGPT-enhanced data
outperforms its counterpart on code summarization, code generation, and code
translation tasks.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15204" title="Abstract">arXiv:2312.15204</a> [<a href="/pdf/2312.15204" title="Download PDF">pdf</a>, <a href="/ps/2312.15204" title="Download PostScript">ps</a>, <a href="/format/2312.15204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DexDLO: Learning Goal-Conditioned Dexterous Policy for Dynamic  Manipulation of Deformable Linear Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhaole%2C+S">Sun Zhaole</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+R+B">Robert B. Fisher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deformable linear object (DLO) manipulation is needed in many fields.
Previous research on deformable linear object (DLO) manipulation has primarily
involved parallel jaw gripper manipulation with fixed grasping positions.
However, the potential for dexterous manipulation of DLOs using an
anthropomorphic hand is under-explored. We present DexDLO, a model-free
framework that learns dexterous dynamic manipulation policies for deformable
linear objects with a fixed-base dexterous hand in an end-to-end way. By
abstracting several common DLO manipulation tasks into goal-conditioned tasks,
our DexDLO can perform these tasks, such as DLO grabbing, DLO pulling, DLO
end-tip position controlling, etc. Using the Mujoco physics simulator, we
demonstrate that our framework can efficiently and effectively learn five
different DLO manipulation tasks with the same framework parameters. We further
provide a thorough analysis of learned policies, reward functions, and reduced
observations for a comprehensive understanding of the framework.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15209" title="Abstract">arXiv:2312.15209</a> [<a href="/pdf/2312.15209" title="Download PDF">pdf</a>, <a href="/ps/2312.15209" title="Download PostScript">ps</a>, <a href="/format/2312.15209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A dynamic approach to ceteris paribus counterfactuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delkos%2C+A">Avgerinos Delkos</a>, 
<a href="/search/cs?searchtype=author&query=Girlando%2C+M">Marianna Girlando</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint - working document
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Counterfactuals are conditional statements describing consequences of states
of affairs that might not have occurred. Ceteris paribus counterfactuals take
into account specific conditions which hold at the actual state of affairs, and
which ought to be kept unchanged throughout the evaluation. Inspired by the
approach of Girard and Triplett, we define ceteris paribus conditionals as
dynamic operators over (weakly) centered sphere models. We introduce three ways
of evaluating the operators, by updating sphere models based on ceteris paribus
sets of formulas. Our approach features two main novelties: on the one hand, we
define our ceteris paribus conditionals as proper dynamic operators, thus
allowing for iterated evaluations. On the other hand, when updating the worlds
within a system of sphere we additionally take into account a notion of
'significance' of the formulas that ought to be kept unchanged. We discuss the
relations of our model updates with other prioritisations introduced in the
literature, and show completeness of the set of valid formulas in the updated
centered (resp. weakly centered) sphere models with respect to Lewis'
axiomatization of the conditional logic VC (resp. VW).
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15212" title="Abstract">arXiv:2312.15212</a> [<a href="/pdf/2312.15212" title="Download PDF">pdf</a>, <a href="/format/2312.15212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic models of memristive behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gora%2C+P+F">P. F. Gora</a>, 
<a href="/search/cs?searchtype=author&query=Gudowska-Nowak%2C+E">Ewa Gudowska-Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Classical Physics (physics.class-ph)

</div>
<p class="mathjax">Under normal operations, memristive devices undergo variability in time and
space and have internal dynamics. Interplay of memory and stochastic signal
processing in memristive devices makes them candidates for performing
bio-inspired tasks of information transduction and transformation, where
intrinsic random behavior can be harnessed for high performance of circuits
built up of individual memory storing elements. The paper discusses models of
single memristive devices exhibiting both - dynamic hysteresis and Stochastic
Resonance, addressing also the cooperative effect of correlated noises acting
on the system and occurrence of dirty hysteretic rounding.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15215" title="Abstract">arXiv:2312.15215</a> [<a href="/pdf/2312.15215" title="Download PDF">pdf</a>, <a href="/format/2312.15215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptualising an Anti-Digital Forensics Kill Chain for Smart Homes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raciti%2C+M">Mario Raciti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 10th International Conference on Information Systems Security and Privacy (ICISSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The widespread integration of Internet of Things (IoT) devices in households
generates extensive digital footprints, notably within Smart Home ecosystems.
These IoT devices, brimming with data about residents, inadvertently offer
insights into human activities, potentially embodying even criminal acts, such
as a murder. As technology advances, so does the concern for criminals seeking
to exploit various techniques to conceal evidence and evade investigations.
This paper delineates the application of Anti-Digital Forensics (ADF) in Smart
Home scenarios and recognises its potential to disrupt (digital)
investigations. It does so by elucidating the current challenges and gaps and
by arguing, in response, the conceptualisation of an ADF Kill Chain tailored to
Smart Home ecosystems. While seemingly arming criminals, the Kill Chain will
allow a better understanding of the distinctive peculiarities of Anti-Digital
Forensics in Smart Home scenario. This understanding is essential for
fortifying the Digital Forensics process and, in turn, developing robust
countermeasures against malicious activities.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15219" title="Abstract">arXiv:2312.15219</a> [<a href="/pdf/2312.15219" title="Download PDF">pdf</a>, <a href="/format/2312.15219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale Optimization Using Evolutionary Reinforcement Learning for Object  Detection on Drone Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoying Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wentao He</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jianfeng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Titian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+R">Ruibin Bai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangjian He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection in aerial imagery presents a significant challenge due to
large scale variations among objects. This paper proposes an evolutionary
reinforcement learning agent, integrated within a coarse-to-fine object
detection framework, to optimize the scale for more effective detection of
objects in such images. Specifically, a set of patches potentially containing
objects are first generated. A set of rewards measuring the localization
accuracy, the accuracy of predicted labels, and the scale consistency among
nearby patches are designed in the agent to guide the scale optimization. The
proposed scale-consistency reward ensures similar scales for neighboring
objects of the same category. Furthermore, a spatial-semantic attention
mechanism is designed to exploit the spatial semantic relations between
patches. The agent employs the proximal policy optimization strategy in
conjunction with the evolutionary strategy, effectively utilizing both the
current patch status and historical experience embedded in the agent. The
proposed model is compared with state-of-the-art methods on two benchmark
datasets for object detection on drone imagery. It significantly outperforms
all the compared methods.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15220" title="Abstract">arXiv:2312.15220</a> [<a href="/pdf/2312.15220" title="Download PDF">pdf</a>, <a href="/format/2312.15220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look-ahead Search on Top of Policy Networks in Imperfect Information  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kubicek%2C+O">Ondrej Kubicek</a>, 
<a href="/search/cs?searchtype=author&query=Burch%2C+N">Neil Burch</a>, 
<a href="/search/cs?searchtype=author&query=Lisy%2C+V">Viliam Lisy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Conducting additional search during test time is often used to improve the
performance of reinforcement learning algorithms. Performing search in
adversarial games with imperfect information is notoriously difficult and often
requires a complicated training process. We present an algorithm that uses an
arbitrary policy-gradient algorithm that learns from sampled trajectories in
the setting of fully adversarial two-player games with imperfect information.
Alongside the training of the policy network, the algorithm trains an
additional critic network, which provides multiple expected values if both
players follow one of a fixed set of transformations of the policy given by the
policy network. These values are then used for depth-limited search. We show
how the values from this critic can create a value function for imperfect
information games. Moreover, they can be used to compute the summary statistics
necessary to start the search from an arbitrary decision point in the game. The
presented algorithm is scalable to very large games since it does not require
any search in the training time. Furthermore, given sufficient computational
resources, our algorithm may choose whether to use search or play the strategy
according to the trained policy network anywhere in the game. We evaluate the
algorithm's performance when trained alongside Regularized Nash Dynamics, and
we compare the performance of using the search against the policy network in
the standard benchmark game of Leduc hold'em, multiple variants of imperfect
information Goofspiel, and in a game of Battleships.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15223" title="Abstract">arXiv:2312.15223</a> [<a href="/pdf/2312.15223" title="Download PDF">pdf</a>, <a href="/format/2312.15223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Large Language Models for Software Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shengcheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software Engineering (SE) is the systematic design, development, and
maintenance of software applications, underpinning the digital infrastructure
of our modern mainworld. Very recently, the SE community has seen a rapidly
increasing number of techniques employing Large Language Models (LLMs) to
automate a broad range of SE tasks. Nevertheless, existing information of the
applications, effects, and possible limitations of LLMs within SE is still not
well-studied.
<br />In this paper, we provide a systematic survey to summarize the current
state-of-the-art research in the LLM-based SE community. We summarize 30
representative LLMs of Source Code across three model architectures, 15
pre-training objectives across four categories, and 16 downstream tasks across
five categories. We then present a detailed summarization of the recent SE
studies for which LLMs are commonly utilized, including 155 studies for 43
specific code-related tasks across four crucial phases within the SE workflow.
Besides, we summarize existing attempts to empirically evaluate LLMs in SE,
such as benchmarks, empirical studies, and exploration of SE education. We also
discuss several critical aspects of optimization and applications of LLMs in
SE, such as security attacks, model tuning, and model compression. Finally, we
highlight several challenges and potential opportunities on applying LLMs for
future SE studies, such as exploring domain LLMs and constructing clean
evaluation datasets. Overall, our work can help researchers gain a
comprehensive understanding about the achievements of the existing LLM-based SE
studies and promote the practical application of these techniques. Our
artifacts are publicly available and will continuously updated at the living
repository: \url{https://github.com/iSEngLab/AwesomeLLM4SE}.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15224" title="Abstract">arXiv:2312.15224</a> [<a href="/pdf/2312.15224" title="Download PDF">pdf</a>, <a href="/format/2312.15224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Powered Hierarchical Language Agent for Real-time Human-AI  Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaxuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuqing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qingmin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accpeted by AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">AI agents powered by Large Language Models (LLMs) have made significant
advances, enabling them to assist humans in diverse complex tasks and leading
to a revolution in human-AI coordination. LLM-powered agents typically require
invoking LLM APIs and employing artificially designed complex prompts, which
results in high inference latency. While this paradigm works well in scenarios
with minimal interactive demands, such as code generation, it is unsuitable for
highly interactive and real-time applications, such as gaming. Traditional
gaming AI often employs small models or reactive policies, enabling fast
inference but offering limited task completion and interaction abilities. In
this work, we consider Overcooked as our testbed where players could
communicate with natural language and cooperate to serve orders. We propose a
Hierarchical Language Agent (HLA) for human-AI coordination that provides both
strong reasoning abilities while keeping real-time execution. In particular,
HLA adopts a hierarchical framework and comprises three modules: a proficient
LLM, referred to as Slow Mind, for intention reasoning and language
interaction, a lightweight LLM, referred to as Fast Mind, for generating macro
actions, and a reactive policy, referred to as Executor, for transforming macro
actions into atomic actions. Human studies show that HLA outperforms other
baseline agents, including slow-mind-only agents and fast-mind-only agents,
with stronger cooperation abilities, faster responses, and more consistent
language communications.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15225" title="Abstract">arXiv:2312.15225</a> [<a href="/pdf/2312.15225" title="Download PDF">pdf</a>, <a href="/ps/2312.15225" title="Download PostScript">ps</a>, <a href="/format/2312.15225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Inference with Limited Memory: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berg%2C+T">Tomer Berg</a>, 
<a href="/search/cs?searchtype=author&query=Ordentlich%2C+O">Or Ordentlich</a>, 
<a href="/search/cs?searchtype=author&query=Shayevitz%2C+O">Ofer Shayevitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JSAIT Special Issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">The problem of statistical inference in its various forms has been the
subject of decades-long extensive research. Most of the effort has been focused
on characterizing the behavior as a function of the number of available
samples, with far less attention given to the effect of memory limitations on
performance. Recently, this latter topic has drawn much interest in the
engineering and computer science literature. In this survey paper, we attempt
to review the state-of-the-art of statistical inference under memory
constraints in several canonical problems, including hypothesis testing,
parameter estimation, and distribution property testing/estimation. We discuss
the main results in this developing field, and by identifying recurrent themes,
we extract some fundamental building blocks for algorithmic construction, as
well as useful techniques for lower bound derivations.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15228" title="Abstract">arXiv:2312.15228</a> [<a href="/pdf/2312.15228" title="Download PDF">pdf</a>, <a href="/format/2312.15228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Data Poisoning for Fake News Detection: How to Make a Model  Misclassify a Target News without Modifying It
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siciliano%2C+F">Federico Siciliano</a>, 
<a href="/search/cs?searchtype=author&query=Maiano%2C+L">Luca Maiano</a>, 
<a href="/search/cs?searchtype=author&query=Papa%2C+L">Lorenzo Papa</a>, 
<a href="/search/cs?searchtype=author&query=Baccin%2C+F">Federica Baccin</a>, 
<a href="/search/cs?searchtype=author&query=Amerini%2C+I">Irene Amerini</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Fake news detection models are critical to countering disinformation but can
be manipulated through adversarial attacks. In this position paper, we analyze
how an attacker can compromise the performance of an online learning detector
on specific news content without being able to manipulate the original target
news. In some contexts, such as social networks, where the attacker cannot
exert complete control over all the information, this scenario can indeed be
quite plausible. Therefore, we show how an attacker could potentially introduce
poisoning data into the training data to manipulate the behavior of an online
learning method. Our initial findings reveal varying susceptibility of logistic
regression models based on complexity and attack type.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15229" title="Abstract">arXiv:2312.15229</a> [<a href="/pdf/2312.15229" title="Download PDF">pdf</a>, <a href="/ps/2312.15229" title="Download PostScript">ps</a>, <a href="/format/2312.15229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized PolyKervNets: Optimizing Expressiveness and Efficiency for  Private Inference in Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aremu%2C+T">Toluwani Aremu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report on experimental findings published in the IACR Cryptology ePrint Archive (<a href="https://ia.cr/2023/1917">this https URL</a>). The report spans 7 pages and includes 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Private computation of nonlinear functions, such as Rectified Linear Units
(ReLUs) and max-pooling operations, in deep neural networks (DNNs) poses
significant challenges in terms of storage, bandwidth, and time consumption. To
address these challenges, there has been a growing interest in utilizing
privacy-preserving techniques that leverage polynomial activation functions and
kernelized convolutions as alternatives to traditional ReLUs. However, these
alternative approaches often suffer from a trade-off between achieving faster
private inference (PI) and sacrificing model accuracy. In particular, when
applied to much deeper networks, these methods encounter training
instabilities, leading to issues like exploding gradients (resulting in NaNs)
or suboptimal approximations. In this study, we focus on PolyKervNets, a
technique known for offering improved dynamic approximations in smaller
networks but still facing instabilities in larger and more complex networks.
Our primary objective is to empirically explore optimization-based training
recipes to enhance the performance of PolyKervNets in larger networks. By doing
so, we aim to potentially eliminate the need for traditional nonlinear
activation functions, thereby advancing the state-of-the-art in
privacy-preserving deep neural network architectures. Code can be found on
GitHub at: \url{https://github.com/tolusophy/PolyKervNets/}
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15230" title="Abstract">arXiv:2312.15230</a> [<a href="/pdf/2312.15230" title="Download PDF">pdf</a>, <a href="/format/2312.15230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PERP: Rethinking the Prune-Retrain Paradigm in the Era of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Max Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Andoni%2C+M">Megi Andoni</a>, 
<a href="/search/cs?searchtype=author&query=Spiegel%2C+C">Christoph Spiegel</a>, 
<a href="/search/cs?searchtype=author&query=Pokutta%2C+S">Sebastian Pokutta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural Networks can be efficiently compressed through pruning, significantly
reducing storage and computational demands while maintaining predictive
performance. Simple yet effective methods like Iterative Magnitude Pruning
(IMP, Han et al., 2015) remove less important parameters and require a costly
retraining procedure to recover performance after pruning. However, with the
rise of Large Language Models (LLMs), full retraining has become infeasible due
to memory and compute constraints. In this study, we challenge the practice of
retraining all parameters by demonstrating that updating only a small subset of
highly expressive parameters is often sufficient to recover or even improve
performance compared to full retraining. Surprisingly, retraining as little as
0.27%-0.35% of the parameters of GPT-architectures (OPT-2.7B/6.7B/13B/30B)
achieves comparable performance to One Shot IMP across various sparsity levels.
Our method, Parameter-Efficient Retraining after Pruning (PERP), drastically
reduces compute and memory demands, enabling pruning and retraining of up to 30
billion parameter models on a single NVIDIA A100 GPU within minutes. Despite
magnitude pruning being considered as unsuited for pruning LLMs, our findings
show that PERP positions it as a strong contender against state-of-the-art
retraining-free approaches such as Wanda (Sun et al., 2023) and SparseGPT
(Frantar &amp; Alistarh, 2023), opening up a promising alternative to avoiding
retraining.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15231" title="Abstract">arXiv:2312.15231</a> [<a href="/pdf/2312.15231" title="Download PDF">pdf</a>, <a href="/ps/2312.15231" title="Download PostScript">ps</a>, <a href="/format/2312.15231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensing-Enhanced Secure Communication: Joint Time Allocation and  Beamforming Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongfang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shenghui Song</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The integration of sensing and communication enables wireless communication
systems to serve environment-aware applications. In this paper, we propose to
leverage sensing to enhance physical layer security (PLS) in multiuser
communication systems in the presence of a suspicious target. To this end, we
develop a two-phase framework to first estimate the location of the potential
eavesdropper by sensing and then utilize the estimated information to enhance
PLS for communication. In particular, in the first phase, a dual-functional
radar and communication (DFRC) base station (BS) exploits a sensing signal to
mitigate the sensing information uncertainty of the potential eavesdropper.
Then, in the second phase, to facilitate joint sensing and secure
communication, the DFRC BS employs beamforming and artificial noise to enhance
secure communication. The design objective is to maximize the system sum rate
while alleviating the information leakage by jointly optimizing the time
allocation and beamforming policy. Capitalizing on monotonic optimization
theory, we develop a two-layer globally optimal algorithm to reveal the
performance upper bound of the considered system. Simulation results show that
the proposed scheme achieves a significant sum rate gain over two baseline
schemes that adopt existing techniques. Moreover, our results unveil that ISAC
is a promising paradigm for enhancing secure communication in wireless
networks.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15234" title="Abstract">arXiv:2312.15234</a> [<a href="/pdf/2312.15234" title="Download PDF">pdf</a>, <a href="/format/2312.15234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Generative Large Language Model Serving: A Survey from  Algorithms to Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Oliaro%2C+G">Gabriele Oliaro</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongyi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">In the rapidly evolving landscape of artificial intelligence (AI), generative
large language models (LLMs) stand at the forefront, revolutionizing how we
interact with our data. However, the computational intensity and memory
consumption of deploying these models present substantial challenges in terms
of serving efficiency, particularly in scenarios demanding low latency and high
throughput. This survey addresses the imperative need for efficient LLM serving
methodologies from a machine learning system (MLSys) research perspective,
standing at the crux of advanced AI innovations and practical system
optimizations. We provide in-depth analysis, covering a spectrum of solutions,
ranging from cutting-edge algorithmic modifications to groundbreaking changes
in system designs. The survey aims to provide a comprehensive understanding of
the current state and future directions in efficient LLM serving, offering
valuable insights for researchers and practitioners in overcoming the barriers
of effective LLM deployment, thereby reshaping the future of AI.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15235" title="Abstract">arXiv:2312.15235</a> [<a href="/pdf/2312.15235" title="Download PDF">pdf</a>, <a href="/format/2312.15235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASTER: Market-Guided Stock Transformer for Stock Price Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yanyan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Stock price forecasting has remained an extremely challenging problem for
many decades due to the high volatility of the stock market. Recent efforts
have been devoted to modeling complex stock correlations toward joint stock
price forecasting. Existing works share a common neural architecture that
learns temporal patterns from individual stock series and then mixes up
temporal representations to establish stock correlations. However, they only
consider time-aligned stock correlations stemming from all the input stock
features, which suffer from two limitations. First, stock correlations often
occur momentarily and in a cross-time manner. Second, the feature effectiveness
is dynamic with market variation, which affects both the stock sequential
patterns and their correlations. To address the limitations, this paper
introduces MASTER, a MArkert-Guided Stock TransformER, which models the
momentary and cross-time stock correlation and leverages market information for
automatic feature selection. MASTER elegantly tackles the complex stock
correlation by alternatively engaging in intra-stock and inter-stock
information aggregation. Experiments show the superiority of MASTER compared
with previous works and visualize the captured realistic stock correlation to
provide valuable insights.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15236" title="Abstract">arXiv:2312.15236</a> [<a href="/pdf/2312.15236" title="Download PDF">pdf</a>, <a href="/format/2312.15236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifying Soccer Ball-on-Goal Position Through Kicker Shooting Action
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tor%C3%B3n-Artiles%2C+J">Javier Tor&#xf3;n-Artiles</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Sosa%2C+D">Daniel Hern&#xe1;ndez-Sosa</a>, 
<a href="/search/cs?searchtype=author&query=Santana%2C+O+J">Oliverio J. Santana</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzo-Navarro%2C+J">Javier Lorenzo-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Freire-Obreg%C3%B3n%2C+D">David Freire-Obreg&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 13th International Conference on Pattern Recognition Applications (ICPRAM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research addresses whether the ball's direction after a soccer free-kick
can be accurately predicted solely by observing the shooter's kicking
technique. To investigate this, we meticulously curated a dataset of soccer
players executing free kicks and conducted manual temporal segmentation to
identify the moment of the kick precisely. Our approach involves utilizing
neural networks to develop a model that integrates Human Action Recognition
(HAR) embeddings with contextual information, predicting the ball-on-goal
position (BoGP) based on two temporal states: the kicker's run-up and the
instant of the kick. The study encompasses a performance evaluation for eleven
distinct HAR backbones, shedding light on their effectiveness in BoGP
estimation during free-kick situations. An extra tabular metadata input is
introduced, leading to an interesting model enhancement without introducing
bias. The promising results reveal 69.1% accuracy when considering two primary
BoGP classes: right and left. This underscores the model's proficiency in
predicting the ball's destination towards the goal with high accuracy, offering
promising implications for understanding free-kick dynamics in soccer.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15237" title="Abstract">arXiv:2312.15237</a> [<a href="/pdf/2312.15237" title="Download PDF">pdf</a>, <a href="/format/2312.15237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fine-Grained Explainability for Heterogeneous Graph Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiale Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yanyan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Luyu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C+C">Caleb Chen Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Heterogeneous graph neural networks (HGNs) are prominent approaches to node
classification tasks on heterogeneous graphs. Despite the superior performance,
insights about the predictions made from HGNs are obscure to humans. Existing
explainability techniques are mainly proposed for GNNs on homogeneous graphs.
They focus on highlighting salient graph objects to the predictions whereas the
problem of how these objects affect the predictions remains unsolved. Given
heterogeneous graphs with complex structures and rich semantics, it is
imperative that salient objects can be accompanied with their influence paths
to the predictions, unveiling the reasoning process of HGNs. In this paper, we
develop xPath, a new framework that provides fine-grained explanations for
black-box HGNs specifying a cause node with its influence path to the target
node. In xPath, we differentiate the influence of a node on the prediction
w.r.t. every individual influence path, and measure the influence by perturbing
graph structure via a novel graph rewiring algorithm. Furthermore, we introduce
a greedy search algorithm to find the most influential fine-grained
explanations efficiently. Empirical results on various HGNs and heterogeneous
graphs show that xPath yields faithful explanations efficiently, outperforming
the adaptations of advanced GNN explanation approaches.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15238" title="Abstract">arXiv:2312.15238</a> [<a href="/pdf/2312.15238" title="Download PDF">pdf</a>, <a href="/format/2312.15238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoPose-NeuS: Jointly Optimizing Camera Poses with Neural Implicit  Surfaces for Multi-view Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabae%2C+M+S">Mohamed Shawky Sabae</a>, 
<a href="/search/cs?searchtype=author&query=Baraka%2C+H+A">Hoda Anis Baraka</a>, 
<a href="/search/cs?searchtype=author&query=Hadhoud%2C+M+M">Mayada Mansour Hadhoud</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> UniReps: the First Workshop on Unifying Representations in Neural
  Models (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Learning neural implicit surfaces from volume rendering has become popular
for multi-view reconstruction. Neural surface reconstruction approaches can
recover complex 3D geometry that are difficult for classical Multi-view Stereo
(MVS) approaches, such as non-Lambertian surfaces and thin structures. However,
one key assumption for these methods is knowing accurate camera parameters for
the input multi-view images, which are not always available. In this paper, we
present NoPose-NeuS, a neural implicit surface reconstruction method that
extends NeuS to jointly optimize camera poses with the geometry and color
networks. We encode the camera poses as a multi-layer perceptron (MLP) and
introduce two additional losses, which are multi-view feature consistency and
rendered depth losses, to constrain the learned geometry for better estimated
camera poses and scene surfaces. Extensive experiments on the DTU dataset show
that the proposed method can estimate relatively accurate camera poses, while
maintaining a high surface reconstruction quality with 0.89 mean Chamfer
distance.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15239" title="Abstract">arXiv:2312.15239</a> [<a href="/pdf/2312.15239" title="Download PDF">pdf</a>, <a href="/ps/2312.15239" title="Download PostScript">ps</a>, <a href="/format/2312.15239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QoE modeling for Voice over IP: Simplified E-model Enhancement Utilizing  the Subjective MOS Prediction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daengsi%2C+T">Therdpong Daengsi</a>, 
<a href="/search/cs?searchtype=author&query=Wuttidittachotti%2C+P">Pongpisit Wuttidittachotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">This research proposes an enhanced measurement method for VoIP quality
assessment which provides an improvement to accuracy and reliability. To
improve the objective measurement tool called the simplified E-model for the
selected codec, G.729, it has been enhanced by utilizing a subjective MOS
prediction model based on native Thai users, who use the Thai-tonal language.
Then, the different results from the simplified E-model and subjective MOS
prediction model were used to create the Bias function, before adding to the
simplified E-model. Finally, it has been found that the outputs from the
enhanced simplified E-model for the G.729 codec shows better accuracy when
compared to the original simplified E-model, specially, after the enhanced
model has been evaluated with 4 test sets. The major contribution of this
enhancement is that errors are reduced by 58.87 % when compared to the generic
simplified E-model. That means the enhanced simplified E-model as proposed in
this study can provide improvement beyond the original simplified one
significantly.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15241" title="Abstract">arXiv:2312.15241</a> [<a href="/pdf/2312.15241" title="Download PDF">pdf</a>, <a href="/ps/2312.15241" title="Download PostScript">ps</a>, <a href="/format/2312.15241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Value Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2110.09240">arXiv:2110.09240</a> by other authors
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 MP2 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">As artificial intelligence (AI) systems become increasingly integrated into
various domains, ensuring that they align with human values becomes critical.
This paper introduces a novel formalism to quantify the alignment between AI
systems and human values, using Markov Decision Processes (MDPs) as the
foundational model. We delve into the concept of values as desirable goals tied
to actions and norms as behavioral guidelines, aiming to shed light on how they
can be used to guide AI decisions. This framework offers a mechanism to
evaluate the degree of alignment between norms and values by assessing
preference changes across state transitions in a normative world. By utilizing
this formalism, AI developers and ethicists can better design and evaluate AI
systems to ensure they operate in harmony with human values. The proposed
methodology holds potential for a wide range of applications, from
recommendation systems emphasizing well-being to autonomous vehicles
prioritizing safety.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15242" title="Abstract">arXiv:2312.15242</a> [<a href="/pdf/2312.15242" title="Download PDF">pdf</a>, <a href="/format/2312.15242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaLDiff: Camera Localization in NeRF via Pose Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+R">Rashik Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Koju%2C+B">Bishad Koju</a>, 
<a href="/search/cs?searchtype=author&query=Bhusal%2C+A">Abhigyan Bhusal</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Rameau%2C+F">Fran&#xe7;ois Rameau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the widespread use of NeRF-based implicit 3D representation, the need
for camera localization in the same representation becomes manifestly apparent.
Doing so not only simplifies the localization process -- by avoiding an
outside-the-NeRF-based localization -- but also has the potential to offer the
benefit of enhanced localization. This paper studies the problem of localizing
cameras in NeRF using a diffusion model for camera pose adjustment. More
specifically, given a pre-trained NeRF model, we train a diffusion model that
iteratively updates randomly initialized camera poses, conditioned upon the
image to be localized. At test time, a new camera is localized in two steps:
first, coarse localization using the proposed pose diffusion process, followed
by local refinement steps of a pose inversion process in NeRF. In fact, the
proposed camera localization by pose diffusion (CaLDiff) method also integrates
the pose inversion steps within the diffusion process. Such integration offers
significantly better localization, thanks to our downstream refinement-aware
diffusion process. Our exhaustive experiments on challenging real-world data
validate our method by providing significantly better results than the compared
methods and the established baselines. Our source code will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15244" title="Abstract">arXiv:2312.15244</a> [<a href="/pdf/2312.15244" title="Download PDF">pdf</a>, <a href="/ps/2312.15244" title="Download PostScript">ps</a>, <a href="/format/2312.15244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fluid Antenna Array Enhanced Over-the-Air Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Sicong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Over-the-air computation (AirComp) has emerged as a promising technology for
fast wireless data aggregation by harnessing the superposition property of
wireless multiple-access channels. This paper investigates a fluid antenna (FA)
array-enhanced AirComp system, employing the new degrees of freedom achieved by
antenna movements. Specifically, we jointly optimize the transceiver design and
antenna position vector (APV) to minimize the mean squared error (MSE) between
target and estimated function values. To tackle the resulting highly non-convex
problem, we adopt an alternating optimization technique to decompose it into
three subproblems. These subproblems are then iteratively solved until
convergence, leading to a locally optimal solution. Numerical results show that
FA arrays with the proposed transceiver and APV design significantly outperform
the traditional fixed-position antenna arrays in terms of MSE.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15246" title="Abstract">arXiv:2312.15246</a> [<a href="/pdf/2312.15246" title="Download PDF">pdf</a>, <a href="/format/2312.15246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Non-Acyclic Generative Flow Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brunswic%2C+L+M">Leo Maxime Brunswic</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinchuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yushun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jui%2C+S">Shangling Jui</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 1 table, AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Probability (math.PR)

</div>
<p class="mathjax">GFlowNets is a novel flow-based method for learning a stochastic policy to
generate objects via a sequence of actions and with probability proportional to
a given positive reward. We contribute to relaxing hypotheses limiting the
application range of GFlowNets, in particular: acyclicity (or lack thereof). To
this end, we extend the theory of GFlowNets on measurable spaces which includes
continuous state spaces without cycle restrictions, and provide a
generalization of cycles in this generalized context. We show that losses used
so far push flows to get stuck into cycles and we define a family of losses
solving this issue. Experiments on graphs and continuous tasks validate those
principles.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15247" title="Abstract">arXiv:2312.15247</a> [<a href="/pdf/2312.15247" title="Download PDF">pdf</a>, <a href="/format/2312.15247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-Propose-Verify: A Reliable Hand-Object-Interaction Data  Generation Framework using Foundational Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Juneja%2C+G">Gurusha Juneja</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sukrit Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International Workshop on AI for Digital Human in AAAI Conference on Articial Intelligence (AAAI, 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models when conditioned on text prompts, generate realistic-looking
images with intricate details. But most of these pre-trained models fail to
generate accurate images when it comes to human features like hands, teeth,
etc. We hypothesize that this inability of diffusion models can be overcome
through well-annotated good-quality data. In this paper, we look specifically
into improving the hand-object-interaction image generation using diffusion
models. We collect a well annotated hand-object interaction synthetic dataset
curated using Prompt-Propose-Verify framework and finetune a stable diffusion
model on it. We evaluate the image-text dataset on qualitative and quantitative
metrics like CLIPScore, ImageReward, Fedility, and alignment and show
considerably better performance over the current state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15249" title="Abstract">arXiv:2312.15249</a> [<a href="/pdf/2312.15249" title="Download PDF">pdf</a>, <a href="/ps/2312.15249" title="Download PostScript">ps</a>, <a href="/format/2312.15249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QoE Modeling Associated with QoS Impairment Parameters in 5G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daengsi%2C+T">Therdpong Daengsi</a>, 
<a href="/search/cs?searchtype=author&query=Sirawongphatsara%2C+P">Patsita Sirawongphatsara</a>, 
<a href="/search/cs?searchtype=author&query=Pornpongtechavanich%2C+P">Phisit Pornpongtechavanich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper aims to propose the quality of experience (QoE) models based on
the expectation and/or the perception of 5G users to evaluate for mean opinion
score (MOS) for real-time or interactive services/applications with high
reliability. Therefore, Based on the fundamental QoE concept, the analytic
hierarchy process (AHP) decision making technique has been applied.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15250" title="Abstract">arXiv:2312.15250</a> [<a href="/pdf/2312.15250" title="Download PDF">pdf</a>, <a href="/ps/2312.15250" title="Download PostScript">ps</a>, <a href="/format/2312.15250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Security Enhanced Authentication Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vankayalapati%2C+S+S">Sai Sreekar Vankayalapati</a>, 
<a href="/search/cs?searchtype=author&query=Mookherji%2C+S">Srijanee Mookherji</a>, 
<a href="/search/cs?searchtype=author&query=Odelu%2C+V">Vanga Odelu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Internet of Things (IoT) have gained popularity in recent times. With an
increase in the number of IoT devices, security and privacy vulnerabilities are
also increasing. For sensitive domains like healthcare and industrial sectors,
such vulnerabilities can cause havoc. Thus, authentication is an important
aspect for establishing a secure communication between various participants. In
this paper, we study the two recent authentication and key exchange protocols.
We prove that these protocols are vulnerable to replay attack and modification
attack, and also suffer from technical correctness. We then present the
possible improvements to overcome the discussed vulnerabilities. The
enhancement preserves performance of the original protocols.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15251" title="Abstract">arXiv:2312.15251</a> [<a href="/pdf/2312.15251" title="Download PDF">pdf</a>, <a href="/format/2312.15251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A forced Boussinesq model with a sponge layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Martins%2C+L+G">L. G. Martins</a>, 
<a href="/search/math?searchtype=author&query=Flamarion%2C+M+V">M. V. Flamarion</a>, 
<a href="/search/math?searchtype=author&query=R.">R. Ribeiro-Jr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">The movement of water waves is a topic of interest to researchers from
different areas. While their propagation is described by Euler equations, there
are instances where simplified models can also provide accurate approximations.
A well-known reduced model employed to study the wave dynamics is the
Boussinesq model. Despite being extensively studied, to our knowledge, there is
no research available on a Boussinesq model featuring a sponge layer.
Therefore, in this work, we present a Boussinesq model with a sponge layer.
Furthermore, we carry out a numerical investigation to explore the advantages
and limitations of the proposed model. For this purpose, we compare the
numerical solutions of the model with and without the sponge in three different
scenarios. The numerical solutions are computed by a pseudospectral method. Our
results show that the Boussinesq model with a sponge layer is numerically
stable and advantageous because it is able to absorb low-amplitude waves,
allowing it to run the numerical simulations for long periods of time without
requiring a large spatial domain, but it is not able to absorb high-amplitude
waves.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15253" title="Abstract">arXiv:2312.15253</a> [<a href="/pdf/2312.15253" title="Download PDF">pdf</a>, <a href="/format/2312.15253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deformable Tissue Reconstruction via Orthogonal Neural Plane
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuehao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Intraoperative imaging techniques for reconstructing deformable tissues in
vivo are pivotal for advanced surgical systems. Existing methods either
compromise on rendering quality or are excessively computationally intensive,
often demanding dozens of hours to perform, which significantly hinders their
practical application. In this paper, we introduce Fast Orthogonal Plane
(Forplane), a novel, efficient framework based on neural radiance fields (NeRF)
for the reconstruction of deformable tissues. We conceptualize surgical
procedures as 4D volumes, and break them down into static and dynamic fields
comprised of orthogonal neural planes. This factorization iscretizes the
four-dimensional space, leading to a decreased memory usage and faster
optimization. A spatiotemporal importance sampling scheme is introduced to
improve performance in regions with tool occlusion as well as large motions and
accelerate training. An efficient ray marching method is applied to skip
sampling among empty regions, significantly improving inference speed. Forplane
accommodates both binocular and monocular endoscopy videos, demonstrating its
extensive applicability and flexibility. Our experiments, carried out on two in
vivo datasets, the EndoNeRF and Hamlyn datasets, demonstrate the effectiveness
of our framework. In all cases, Forplane substantially accelerates both the
optimization process (by over 100 times) and the inference process (by over 15
times) while maintaining or even improving the quality across a variety of
non-rigid deformations. This significant performance improvement promises to be
a valuable asset for future intraoperative surgical applications. The code of
our project is now available at https://github.com/Loping151/ForPlane.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15258" title="Abstract">arXiv:2312.15258</a> [<a href="/pdf/2312.15258" title="Download PDF">pdf</a>, <a href="/format/2312.15258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human101: Training 100+FPS Human Gaussians in 100s from 1 View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jiachen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://github.com/longxiang-ai/Human101">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing the human body from single-view videos plays a pivotal role in
the virtual reality domain. One prevalent application scenario necessitates the
rapid reconstruction of high-fidelity 3D digital humans while simultaneously
ensuring real-time rendering and interaction. Existing methods often struggle
to fulfill both requirements. In this paper, we introduce Human101, a novel
framework adept at producing high-fidelity dynamic 3D human reconstructions
from 1-view videos by training 3D Gaussians in 100 seconds and rendering in
100+ FPS. Our method leverages the strengths of 3D Gaussian Splatting, which
provides an explicit and efficient representation of 3D humans. Standing apart
from prior NeRF-based pipelines, Human101 ingeniously applies a Human-centric
Forward Gaussian Animation method to deform the parameters of 3D Gaussians,
thereby enhancing rendering speed (i.e., rendering 1024-resolution images at an
impressive 60+ FPS and rendering 512-resolution images at 100+ FPS).
Experimental results indicate that our approach substantially eclipses current
methods, clocking up to a 10 times surge in frames per second and delivering
comparable or superior rendering quality. Code and demos will be released at
https://github.com/longxiang-ai/Human101.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15263" title="Abstract">arXiv:2312.15263</a> [<a href="/pdf/2312.15263" title="Download PDF">pdf</a>, <a href="/format/2312.15263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Depth Completion Guided by 3D Perception and Geometry  Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tianyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shi-Sheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hua Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth completion, aiming to predict dense depth maps from sparse depth
measurements, plays a crucial role in many computer vision related
applications. Deep learning approaches have demonstrated overwhelming success
in this task. However, high-precision depth completion without relying on the
ground-truth data, which are usually costly, still remains challenging. The
reason lies on the ignorance of 3D structural information in most previous
unsupervised solutions, causing inaccurate spatial propagation and mixed-depth
problems. To alleviate the above challenges, this paper explores the
utilization of 3D perceptual features and multi-view geometry consistency to
devise a high-precision self-supervised depth completion method. Firstly, a 3D
perceptual spatial propagation algorithm is constructed with a point cloud
representation and an attention weighting mechanism to capture more reasonable
and favorable neighboring features during the iterative depth propagation
process. Secondly, the multi-view geometric constraints between adjacent views
are explicitly incorporated to guide the optimization of the whole depth
completion model in a self-supervised manner. Extensive experiments on
benchmark datasets of NYU-Depthv2 and VOID demonstrate that the proposed model
achieves the state-of-the-art depth completion performance compared with other
unsupervised methods, and competitive performance compared with previous
supervised methods.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15265" title="Abstract">arXiv:2312.15265</a> [<a href="/pdf/2312.15265" title="Download PDF">pdf</a>, <a href="/format/2312.15265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring the Evolution of Behavioural Embeddings in Social Media  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saket%2C+S">Srijan Saket</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Short video applications pose unique challenges for recommender systems due
to the constant influx of new content and the absence of historical user
interactions for quality assessment of uploaded content. This research
characterizes the evolution of embeddings in short video recommendation
systems, comparing batch and real-time updates to content embeddings. The
analysis investigates embedding maturity, the learning peak during view
accumulation, popularity bias, l2-norm distribution of learned embeddings, and
their impact on user engagement metrics. The study unveils the contrast in the
number of interactions needed to achieve mature embeddings in both learning
modes, identifies the ideal learning point, and explores the distribution of
l2-norm across various update methods. Utilizing a production system deployed
on a large-scale short video app with over 180 million users, the findings
offer insights into designing effective recommendation systems and enhancing
user satisfaction and engagement in short video applications.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15268" title="Abstract">arXiv:2312.15268</a> [<a href="/pdf/2312.15268" title="Download PDF">pdf</a>, <a href="/format/2312.15268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGDepth: Motion-Guided Cost Volume For Self-Supervised Monocular Depth  In Dynamic Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jia-Xing Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jia-Wang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jian-Qing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite advancements in self-supervised monocular depth estimation,
challenges persist in dynamic scenarios due to the dependence on assumptions
about a static world. In this paper, we present MGDepth, a Motion-Guided Cost
Volume Depth Net, to achieve precise depth estimation for both dynamic objects
and static backgrounds, all while maintaining computational efficiency. To
tackle the challenges posed by dynamic content, we incorporate optical flow and
coarse monocular depth to create a novel static reference frame. This frame is
then utilized to build a motion-guided cost volume in collaboration with the
target frame. Additionally, to enhance the accuracy and resilience of the
network structure, we introduce an attention-based depth net architecture to
effectively integrate information from feature maps with varying resolutions.
Compared to methods with similar computational costs, MGDepth achieves a
significant reduction of approximately seven percent in root-mean-square error
for self-supervised monocular depth estimation on the KITTI-2015 dataset.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15271" title="Abstract">arXiv:2312.15271</a> [<a href="/pdf/2312.15271" title="Download PDF">pdf</a>, <a href="/format/2312.15271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSFlowNet: Semi-supervised Scene Flow Estimation On Point Clouds With  Pseudo Label
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Junfeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qiqin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Rongzhou Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the domain of supervised scene flow estimation, the process of manual
labeling is both time-intensive and financially demanding. This paper
introduces SSFlowNet, a semi-supervised approach for scene flow estimation,
that utilizes a blend of labeled and unlabeled data, optimizing the balance
between the cost of labeling and the precision of model training. SSFlowNet
stands out through its innovative use of pseudo-labels, mainly reducing the
dependency on extensively labeled datasets while maintaining high model
accuracy. The core of our model is its emphasis on the intricate geometric
structures of point clouds, both locally and globally, coupled with a novel
spatial memory feature. This feature is adept at learning the geometric
relationships between points over sequential time frames. By identifying
similarities between labeled and unlabeled points, SSFlowNet dynamically
constructs a correlation matrix to evaluate scene flow dependencies at
individual point level. Furthermore, the integration of a flow consistency
module within SSFlowNet enhances its capability to consistently estimate flow,
an essential aspect for analyzing dynamic scenes. Empirical results demonstrate
that SSFlowNet surpasses existing methods in pseudo-label generation and shows
adaptability across varying data volumes. Moreover, our semi-supervised
training technique yields promising outcomes even with different smaller ratio
labeled data, marking a substantial advancement in the field of scene flow
estimation.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15272" title="Abstract">arXiv:2312.15272</a> [<a href="/pdf/2312.15272" title="Download PDF">pdf</a>, <a href="/format/2312.15272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting anxiety from short clips of free-form speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P">Prabhat Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+A">Akshat Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shreya Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Barriers to accessing mental health assessments including cost and stigma
continues to be an impediment in mental health diagnosis and treatment. Machine
learning approaches based on speech samples could help in this direction. In
this work, we develop machine learning solutions to diagnose anxiety disorders
from audio journals of patients. We work on a novel anxiety dataset (provided
through collaboration with Kintsugi Mindful Wellness Inc.) and experiment with
several models of varying complexity utilizing audio, text and a combination of
multiple modalities. We show that the multi-modal and audio embeddings based
approaches achieve good performance in the task achieving an AUC ROC score of
0.68-0.69.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15273" title="Abstract">arXiv:2312.15273</a> [<a href="/pdf/2312.15273" title="Download PDF">pdf</a>, <a href="/format/2312.15273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benefit from public unlabeled data: A Frangi filtering-based pretraining  network for 3D cerebrovascular segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Gen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+H">Hui Hui</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jie Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The precise cerebrovascular segmentation in time-of-flight magnetic resonance
angiography (TOF-MRA) data is crucial for clinically computer-aided diagnosis.
However, the sparse distribution of cerebrovascular structures in TOF-MRA
results in an exceedingly high cost for manual data labeling. The use of
unlabeled TOF-MRA data holds the potential to enhance model performance
significantly. In this study, we construct the largest preprocessed unlabeled
TOF-MRA datasets (1510 subjects) to date. We also provide three additional
labeled datasets totaling 113 subjects. Furthermore, we propose a simple yet
effective pertraining strategy based on Frangi filtering, known for enhancing
vessel-like structures, to fully leverage the unlabeled data for 3D
cerebrovascular segmentation. Specifically, we develop a Frangi filtering-based
preprocessing workflow to handle the large-scale unlabeled dataset, and a
multi-task pretraining strategy is proposed to effectively utilize the
preprocessed data. By employing this approach, we maximize the knowledge gained
from the unlabeled data. The pretrained model is evaluated on four
cerebrovascular segmentation datasets. The results have demonstrated the
superior performance of our model, with an improvement of approximately 3\%
compared to state-of-the-art semi- and self-supervised methods. Furthermore,
the ablation studies also demonstrate the generalizability and effectiveness of
the pretraining method regarding the backbone structures. The code and data
have been open source at: \url{https://github.com/shigen-StoneRoot/FFPN}.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15275" title="Abstract">arXiv:2312.15275</a> [<a href="/pdf/2312.15275" title="Download PDF">pdf</a>, <a href="/format/2312.15275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARS: Multi-Scale Adaptive Robotics Vision for Underwater Object  Detection and Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saoud%2C+L+S">Lyes Saad Saoud</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+L">Lakmal Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Underwater robotic vision encounters significant challenges, necessitating
advanced solutions to enhance performance and adaptability. This paper presents
MARS (Multi-Scale Adaptive Robotics Vision), a novel approach to underwater
object detection tailored for diverse underwater scenarios. MARS integrates
Residual Attention YOLOv3 with Domain-Adaptive Multi-Scale Attention (DAMSA) to
enhance detection accuracy and adapt to different domains. During training,
DAMSA introduces domain class-based attention, enabling the model to emphasize
domain-specific features. Our comprehensive evaluation across various
underwater datasets demonstrates MARS's performance. On the original dataset,
MARS achieves a mean Average Precision (mAP) of 58.57\%, showcasing its
proficiency in detecting critical underwater objects like echinus, starfish,
holothurian, scallop, and waterweeds. This capability holds promise for
applications in marine robotics, marine biology research, and environmental
monitoring. Furthermore, MARS excels at mitigating domain shifts. On the
augmented dataset, which incorporates all enhancements (+Domain
+Residual+Channel Attention+Multi-Scale Attention), MARS achieves an mAP of
36.16\%. This result underscores its robustness and adaptability in recognizing
objects and performing well across a range of underwater conditions. The source
code for MARS is publicly available on GitHub at
https://github.com/LyesSaadSaoud/MARS-Object-Detection/
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15276" title="Abstract">arXiv:2312.15276</a> [<a href="/pdf/2312.15276" title="Download PDF">pdf</a>, <a href="/format/2312.15276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIOLET: Visual Analytics for Explainable Quantum Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+S">Shaolun Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhiding Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Q">Qiang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+P">Paul Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xiaolin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yanna Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">With the rapid development of Quantum Machine Learning, quantum neural
networks (QNN) have experienced great advancement in the past few years,
harnessing the advantages of quantum computing to significantly speed up
classical machine learning tasks. Despite their increasing popularity, the
quantum neural network is quite counter-intuitive and difficult to understand,
due to their unique quantum-specific layers (e.g., data encoding and
measurement) in their architecture. It prevents QNN users and researchers from
effectively understanding its inner workings and exploring the model training
status. To fill the research gap, we propose VIOLET, a novel visual analytics
approach to improve the explainability of quantum neural networks. Guided by
the design requirements distilled from the interviews with domain experts and
the literature survey, we developed three visualization views: the Encoder View
unveils the process of converting classical input data into quantum states, the
Ansatz View reveals the temporal evolution of quantum states in the training
process, and the Feature View displays the features a QNN has learned after the
training process. Two novel visual designs, i.e., satellite chart and augmented
heatmap, are proposed to visually explain the variational parameters and
quantum circuit measurements respectively. We evaluate VIOLET through two case
studies and in-depth interviews with 12 domain experts. The results demonstrate
the effectiveness and usability of VIOLET in helping QNN users and developers
intuitively understand and explore quantum neural networks
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15280" title="Abstract">arXiv:2312.15280</a> [<a href="/pdf/2312.15280" title="Download PDF">pdf</a>, <a href="/ps/2312.15280" title="Download PostScript">ps</a>, <a href="/format/2312.15280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Image Encryption Scheme based on Chaos and a DPA-Resistant Sbox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholamzadeh%2C+M">Mohammad Gholamzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Khadem%2C+B">Behrooz Khadem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, in Persian language, 13 tables, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Image encryption is one of the most common and effective methods to secure
digital images. Recently, Khalid M. Hosny presented an image encryption scheme
based on 6D hyper chaotic mapping and Q-Fibonacci matrix, which, despite its
remarkable theoretical and practical properties, has several weaknesses,
including inaccuracy of black image encryption, inappropriate white image
encryption (improper entropy parameters, correlation, chi-square test,
histogram, UACI, and NPCR), weak keys, inappropriate key usage. In this paper,
based on Khaled Hosny's design, a new effective design is presented that has
improved encryption security and efficiency. In addition, in the proposed
design, a secure key and a substitution box with a high degree of transparency
order, which is resistant to DPA attacks, have been added. Also, a method to
improve transferring chaos parameters is also proposed. The test results show
the improvement of the resistance of the proposed design against the common
attacks of image encryption schemes and improvement in bandwidth consumption.
Also it has been shown that the proposed scheme has produced better results in
terms of both security and efficiency compared to other similar new schemes.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15281" title="Abstract">arXiv:2312.15281</a> [<a href="/pdf/2312.15281" title="Download PDF">pdf</a>, <a href="/format/2312.15281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra Reliable Low Latency Routing in LEO Satellite Constellations: A  Stochastic Geometry Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In recent years, LEO satellite constellations have become envisioned as a
core component of the next-generation wireless communication networks. The
successive establishment of mega satellite constellations has triggered further
demands for satellite communication advanced features: high reliability and low
latency. In this article, we first establish a multi-objective optimization
problem that simultaneously maximizes reliability and minimizes latency, then
we solve it by two methods. According to the optimal solution, ideal upper
bounds for reliability and latency performance of LEO satellite routing can be
derived. Next, we design an algorithm for relay satellite subset selection,
which can approach the ideal upper bounds in terms of performance. Furthermore,
we derive analytical expressions for satellite availability, coverage
probability, and latency under the stochastic geometry (SG) framework, and the
accuracy is verified by Monte Carlo simulation. In the numerical results, we
study the routing performance of three existing mega constellations and the
impact of different constellation parameter configurations on performance. By
comparing with existing routing strategies, we demonstrate the advantages of
our proposed routing strategy and extend the scope of our research.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15286" title="Abstract">arXiv:2312.15286</a> [<a href="/pdf/2312.15286" title="Download PDF">pdf</a>, <a href="/format/2312.15286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markdown Pricing Under an Unknown Parametric Demand Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Su Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Andrew Li</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+R">R. Ravi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Consider a single-product revenue-maximization problem where the seller
monotonically decreases the price in $n$ rounds with an unknown demand model
coming from a given family. Without monotonicity, the minimax regret is $\tilde
O(n^{2/3})$ for the Lipschitz demand family and $\tilde O(n^{1/2})$ for a
general class of parametric demand models. With monotonicity, the minimax
regret is $\tilde O(n^{3/4})$ if the revenue function is Lipschitz and
unimodal. However, the minimax regret for parametric families remained open. In
this work, we provide a complete settlement for this fundamental problem. We
introduce the crossing number to measure the complexity of a family of demand
functions. In particular, the family of degree-$k$ polynomials has a crossing
number $k$. Based on conservatism under uncertainty, we present (i) a policy
with an optimal $\Theta(\log^2 n)$ regret for families with crossing number
$k=0$, and (ii) another policy with an optimal $\tilde \Theta(n^{k/(k+1)})$
regret when $k\ge 1$. These bounds are asymptotically higher than the $\tilde
O(\log n)$ and $\tilde \Theta(\sqrt n)$ minimax regret for the same families
without the monotonicity constraint.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15288" title="Abstract">arXiv:2312.15288</a> [<a href="/pdf/2312.15288" title="Download PDF">pdf</a>, <a href="/format/2312.15288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding normalization in contrastive representation learning and  out-of-distribution detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le-Gia%2C+T">Tai Le-Gia</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Jaehyun Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Contrastive representation learning has emerged as an outstanding approach
for anomaly detection. In this work, we explore the $\ell_2$-norm of
contrastive features and its applications in out-of-distribution detection. We
propose a simple method based on contrastive learning, which incorporates
out-of-distribution data by discriminating against normal samples in the
contrastive layer space. Our approach can be applied flexibly as an outlier
exposure (OE) approach, where the out-of-distribution data is a huge collective
of random images, or as a fully self-supervised learning approach, where the
out-of-distribution data is self-generated by applying distribution-shifting
transformations. The ability to incorporate additional out-of-distribution
samples enables a feasible solution for datasets where AD methods based on
contrastive learning generally underperform, such as aerial images or
microscopy images. Furthermore, the high-quality features learned through
contrastive learning consistently enhance performance in OE scenarios, even
when the available out-of-distribution dataset is not diverse enough. Our
extensive experiments demonstrate the superiority of our proposed method under
various scenarios, including unimodal and multimodal settings, with various
image datasets.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15289" title="Abstract">arXiv:2312.15289</a> [<a href="/pdf/2312.15289" title="Download PDF">pdf</a>, <a href="/format/2312.15289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet Packet Power Spectrum Kullback-Leibler Divergence: A New Metric  for Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veeramacheneni%2C+L">Lokesh Veeramacheneni</a> (University of Bonn), 
<a href="/search/cs?searchtype=author&query=Wolter%2C+M">Moritz Wolter</a> (University of Bonn), 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a> (University of Bonn)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Current metrics for generative neural networks are biased towards low
frequencies, specific generators, objects from the ImageNet dataset, and value
texture more than shape. Many current quality metrics do not measure frequency
information directly. In response, we propose a new frequency band-based
quality metric, which opens a door into the frequency domain yet, at the same
time, preserves spatial aspects of the data. Our metric works well even if the
distributions we compare are far from ImageNet or have been produced by
differing generator architectures. We verify the quality of our metric by
sampling a broad selection of generative networks on a wide variety of data
sets. A user study ensures our metric aligns with human perception.
Furthermore, we show that frequency band guidance can improve the frequency
domain fidelity of a current generative network.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15291" title="Abstract">arXiv:2312.15291</a> [<a href="/pdf/2312.15291" title="Download PDF">pdf</a>, <a href="/format/2312.15291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reverse Multi-Choice Dialogue Commonsense Inference with  Graph-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Li Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bobo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lizi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Donghong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chong Teng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the proliferation of dialogic data across the Internet, the Dialogue
Commonsense Multi-choice Question Answering (DC-MCQ) task has emerged as a
response to the challenge of comprehending user queries and intentions.
Although prevailing methodologies exhibit effectiveness in addressing
single-choice questions, they encounter difficulties in handling multi-choice
queries due to the heightened intricacy and informational density. In this
paper, inspired by the human cognitive process of progressively excluding
options, we propose a three-step Reverse Exclusion Graph-of-Thought (ReX-GoT)
framework, including Option Exclusion, Error Analysis, and Combine Information.
Specifically, our ReX-GoT mimics human reasoning by gradually excluding
irrelevant options and learning the reasons for option errors to choose the
optimal path of the GoT and ultimately infer the correct answer. By
progressively integrating intricate clues, our method effectively reduces the
difficulty of multi-choice reasoning and provides a novel solution for DC-MCQ.
Extensive experiments on the CICERO and CICERO$_{v2}$ datasets validate the
significant improvement of our approach on DC-MCQ task. On zero-shot setting,
our model outperform the best baseline by 17.67\% in terms of F1 score for the
multi-choice task. Most strikingly, our GPT3.5-based ReX-GoT framework achieves
a remarkable 39.44\% increase in F1 score. Our code is available at:
\url{https://github.com/ZhengL00/ReX-GoT}.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15297" title="Abstract">arXiv:2312.15297</a> [<a href="/pdf/2312.15297" title="Download PDF">pdf</a>, <a href="/format/2312.15297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Me a BNN: A Simple Strategy for Estimating Bayesian Uncertainty  from Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franchi%2C+G">Gianni Franchi</a>, 
<a href="/search/cs?searchtype=author&query=Laurent%2C+O">Olivier Laurent</a>, 
<a href="/search/cs?searchtype=author&query=Legu%C3%A9ry%2C+M">Maxence Legu&#xe9;ry</a>, 
<a href="/search/cs?searchtype=author&query=Bursuc%2C+A">Andrei Bursuc</a>, 
<a href="/search/cs?searchtype=author&query=Pilzer%2C+A">Andrea Pilzer</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Angela Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are powerful tools for various computer vision
tasks, yet they often struggle with reliable uncertainty quantification - a
critical requirement for real-world applications. Bayesian Neural Networks
(BNN) are equipped for uncertainty estimation but cannot scale to large DNNs
that are highly unstable to train. To address this challenge, we introduce the
Adaptable Bayesian Neural Network (ABNN), a simple and scalable strategy to
seamlessly transform DNNs into BNNs in a post-hoc manner with minimal
computational and training overheads. ABNN preserves the main predictive
properties of DNNs while enhancing their uncertainty quantification abilities
through simple BNN adaptation layers (attached to normalization layers) and a
few fine-tuning steps on pre-trained models. We conduct extensive experiments
across multiple datasets for image classification and semantic segmentation
tasks, and our results demonstrate that ABNN achieves state-of-the-art
performance without the computational budget typically associated with ensemble
methods.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15300" title="Abstract">arXiv:2312.15300</a> [<a href="/pdf/2312.15300" title="Download PDF">pdf</a>, <a href="/format/2312.15300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Boost: On Visual Quality Assessment Ability of Low-level  Multi-Modality Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhongpeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fengyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jui%2C+S">Shangling Jui</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in Multi-modality Large Language Models (MLLMs) have
demonstrated remarkable capabilities in complex high-level vision tasks.
However, the exploration of MLLM potential in visual quality assessment, a
vital aspect of low-level vision, remains limited. To address this gap, we
introduce Q-Boost, a novel strategy designed to enhance low-level MLLMs in
image quality assessment (IQA) and video quality assessment (VQA) tasks, which
is structured around two pivotal components: 1) Triadic-Tone Integration:
Ordinary prompt design simply oscillates between the binary extremes of
$positive$ and $negative$. Q-Boost innovates by incorporating a `middle ground'
approach through $neutral$ prompts, allowing for a more balanced and detailed
assessment. 2) Multi-Prompt Ensemble: Multiple quality-centric prompts are used
to mitigate bias and acquire more accurate evaluation. The experimental results
show that the low-level MLLMs exhibit outstanding zeros-shot performance on the
IQA/VQA tasks equipped with the Q-Boost strategy.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15302" title="Abstract">arXiv:2312.15302</a> [<a href="/pdf/2312.15302" title="Download PDF">pdf</a>, <a href="/format/2312.15302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatically Generating Metamorphic Relations via Genetic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayerdi%2C+J">Jon Ayerdi</a>, 
<a href="/search/cs?searchtype=author&query=Terragni%2C+V">Valerio Terragni</a>, 
<a href="/search/cs?searchtype=author&query=Jahangirova%2C+G">Gunel Jahangirova</a>, 
<a href="/search/cs?searchtype=author&query=Arrieta%2C+A">Aitor Arrieta</a>, 
<a href="/search/cs?searchtype=author&query=Tonella%2C+P">Paolo Tonella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Metamorphic testing is a popular approach that aims to alleviate the oracle
problem in software testing. At the core of this approach are Metamorphic
Relations (MRs), specifying properties that hold among multiple test inputs and
corresponding outputs. Deriving MRs is mostly a manual activity, since their
automated generation is a challenging and largely unexplored problem.
<br />This paper presents GenMorph, a technique to automatically generate MRs for
Java methods that involve inputs and outputs that are boolean, numerical, or
ordered sequences. GenMorph uses an evolutionary algorithm to search for
effective test oracles, i.e., oracles that trigger no false alarms and expose
software faults in the method under test. The proposed search algorithm is
guided by two fitness functions that measure the number of false alarms and the
number of missed faults for the generated MRs.
<br />Our results show that GenMorph generates effective MRs for 18 out of 23
methods (mutation score &gt;20%). Furthermore, it can increase Randoop's fault
detection capability in 7 out of 23 methods, and Evosuite's in 14 out of 23
methods.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15304" title="Abstract">arXiv:2312.15304</a> [<a href="/pdf/2312.15304" title="Download PDF">pdf</a>, <a href="/format/2312.15304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Capability of ChatGPT on Ancient Chinese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siqing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+S">Shijing Si</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ChatGPT's proficiency in handling modern standard languages suggests
potential for its use in understanding ancient Chinese.
<br />This project explores ChatGPT's capabilities on ancient Chinese via two
tasks: translating ancient Chinese to modern Chinese and recognizing ancient
Chinese names. A comparison of ChatGPT's output with human translations serves
to evaluate its comprehension of ancient Chinese. The findings indicate that:
(1.)the proficiency of ancient Chinese by ChatGPT is yet to reach a
satisfactory level; (2.) ChatGPT performs the best on ancient-to-modern
translation when feeding with three context sentences. To help reproduce our
work, we display the python code snippets used in this study.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15306" title="Abstract">arXiv:2312.15306</a> [<a href="/pdf/2312.15306" title="Download PDF">pdf</a>, <a href="/format/2312.15306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing High-Dimensional Datasets From Their Bivariate  Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dugan%2C+E">Eli Dugan</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+K">Klaus Mueller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper deals with developing techniques for the reconstruction of
high-dimensional datasets given each bivariate projection, as would be found in
a matrix scatterplot. A graph-based solution is introduced, involving
clique-finding, providing a set of possible rows that might make up the
original dataset. Complications are discussed, including cases where phantom
cliques are found, as well as cases where an exact solution is impossible.
Additional methods are shown, with some dealing with fully deducing rows and
others dealing with having to creatively produce methods that find some
possibilities to be more likely than others. Results show that these methods
are highly successful in recreating a significant portion of the original
dataset in many cases - for randomly generated and real-world datasets - with
the factors leading to a greater rate of failure being lower dimension, higher
n, and lower interval.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15307" title="Abstract">arXiv:2312.15307</a> [<a href="/pdf/2312.15307" title="Download PDF">pdf</a>, <a href="/format/2312.15307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Algorithmic Bias on Facial Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amigo%2C+G">Glauco Amigo</a>, 
<a href="/search/cs?searchtype=author&query=Perea%2C+P+R">Pablo Rivas Perea</a>, 
<a href="/search/cs?searchtype=author&query=Marks%2C+R+J">Robert J. Marks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Biased datasets are ubiquitous and present a challenge for machine learning.
For a number of categories on a dataset that are equally important but some are
sparse and others are common, the learning algorithms will favor the ones with
more presence. The problem of biased datasets is especially sensitive when
dealing with minority people groups. How can we, from biased data, generate
algorithms that treat every person equally? This work explores one way to
mitigate bias using a debiasing variational autoencoder with experiments on
facial expression recognition.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15308" title="Abstract">arXiv:2312.15308</a> [<a href="/pdf/2312.15308" title="Download PDF">pdf</a>, <a href="/ps/2312.15308" title="Download PostScript">ps</a>, <a href="/format/2312.15308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The hull variation problem for projective Reed-Muller codes and quantum  error-correcting codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>, 
<a href="/search/cs?searchtype=author&query=San-Jos%C3%A9%2C+R">Rodrigo San-Jos&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Long quantum codes using projective Reed-Muller codes are constructed. We
obtain asymmetric and symmetric quantum codes by using the CSS construction and
the Hermitian construction, respectively. Quantum codes obtained from
projective Reed-Muller codes usually require entanglement assistance, but we
show that sometimes we can avoid this requirement by considering monomially
equivalent codes. Moreover, we also provide some constructions of quantum codes
from subfield subcodes of projective Reed-Muller codes.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15310" title="Abstract">arXiv:2312.15310</a> [<a href="/pdf/2312.15310" title="Download PDF">pdf</a>, <a href="/format/2312.15310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalization in Subitizing with Neuro-Symbolic Loss using  Holographic Reduced Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+M">Mohammad Mahmudul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Raff%2C+E">Edward Raff</a>, 
<a href="/search/cs?searchtype=author&query=Oates%2C+T">Tim Oates</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 38th Annual AAAI Workshop on Neuro-Symbolic Learning and Reasoning in the Era of Large Language Models (NuCLeaR), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">While deep learning has enjoyed significant success in computer vision tasks
over the past decade, many shortcomings still exist from a Cognitive Science
(CogSci) perspective. In particular, the ability to subitize, i.e., quickly and
accurately identify the small (less than 6) count of items, is not well learned
by current Convolutional Neural Networks (CNNs) or Vision Transformers (ViTs)
when using a standard cross-entropy (CE) loss. In this paper, we demonstrate
that adapting tools used in CogSci research can improve the subitizing
generalization of CNNs and ViTs by developing an alternative loss function
using Holographic Reduced Representations (HRRs). We investigate how this
neuro-symbolic approach to learning affects the subitizing capability of CNNs
and ViTs, and so we focus on specially crafted problems that isolate
generalization to specific aspects of subitizing. Via saliency maps and
out-of-distribution performance, we are able to empirically observe that the
proposed HRR loss improves subitizing generalization though it does not
completely solve the problem. In addition, we find that ViTs perform
considerably worse compared to CNNs in most respects on subitizing, except on
one axis where an HRR-based loss provides improvement.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15311" title="Abstract">arXiv:2312.15311</a> [<a href="/pdf/2312.15311" title="Download PDF">pdf</a>, <a href="/format/2312.15311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel-Level Change Detection Pseudo-Label Learning for Remote Sensing  Change Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zipeng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The existing methods for Remote Sensing Image Change Captioning (RSICC)
perform well in simple scenes but exhibit poorer performance in complex scenes.
This limitation is primarily attributed to the model's constrained visual
ability to distinguish and locate changes. Acknowledging the inherent
correlation between change detection (CD) and RSICC tasks, we believe
pixel-level CD is significant for describing the differences between images
through language. Regrettably, the current RSICC dataset lacks readily
available pixel-level CD labels. To address this deficiency, we leverage a
model trained on existing CD datasets to derive CD pseudo-labels. We propose an
innovative network with an auxiliary CD branch, supervised by pseudo-labels.
Furthermore, a semantic fusion augment (SFA) module is proposed to fuse the
feature information extracted by the CD branch, thereby facilitating the
nuanced description of changes. Experiments demonstrate that our method
achieves state-of-the-art performance and validate that learning pixel-level CD
pseudo-labels significantly contributes to change captioning. Our code will be
available at: https://github.com/Chen-Yang-Liu/Pix4Cap
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15313" title="Abstract">arXiv:2312.15313</a> [<a href="/pdf/2312.15313" title="Download PDF">pdf</a>, <a href="/format/2312.15313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centric Resource Allocation for the Metaverse With Multiaccess  Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijian Long</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haiwei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Internet of Things Journal, vol. 10, no. 22, pp. 19993-20005,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Multi-access edge computing (MEC) is a promising solution to the
computation-intensive, low-latency rendering tasks of the metaverse. However,
how to optimally allocate limited communication and computation resources at
the edge to a large number of users in the metaverse is quite challenging. In
this paper, we propose an adaptive edge resource allocation method based on
multi-agent soft actor-critic with graph convolutional networks (SAC-GCN).
Specifically, SAC-GCN models the multi-user metaverse environment as a graph
where each agent is denoted by a node. Each agent learns the interplay between
agents by graph convolutional networks with self-attention mechanism to further
determine the resource usage for one user in the metaverse. The effectiveness
of SAC-GCN is demonstrated through the analysis of user experience, balance of
resource allocation, and resource utilization rate by taking a virtual city
park metaverse as an example. Experimental results indicate that SAC-GCN
outperforms other resource allocation methods in improving overall user
experience, balancing resource allocation, and increasing resource utilization
rate by at least 27%, 11%, and 8%, respectively.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15316" title="Abstract">arXiv:2312.15316</a> [<a href="/pdf/2312.15316" title="Download PDF">pdf</a>, <a href="/format/2312.15316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guan-Ting Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shivakumar%2C+P+G">Prashanth Gurunath Shivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Gandhe%2C+A">Ankur Gandhe</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yile Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shalini Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Stolcke%2C+A">Andreas Stolcke</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bulyko%2C+I">Ivan Bulyko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated superior abilities in tasks
such as chatting, reasoning, and question-answering. However, standard LLMs may
ignore crucial paralinguistic information, such as sentiment, emotion, and
speaking style, which are essential for achieving natural, human-like spoken
conversation, especially when such information is conveyed by acoustic cues. We
therefore propose Paralinguistics-enhanced Generative Pretrained Transformer
(ParalinGPT), an LLM utilizes text and speech modality to better model the
linguistic content and paralinguistic attribute of spoken response. The model
takes the conversational context of text, speech embeddings, and paralinguistic
attributes as input prompts within a serialized multitasking multi-modal
framework. Specifically, our framework serializes tasks in the order of current
paralinguistic attribute prediction, response paralinguistic attribute
prediction, and response text generation with autoregressive conditioning. We
utilize the Switchboard-1 corpus, including its sentiment labels to be the
paralinguistic attribute, as our spoken dialogue dataset. Experimental results
indicate the proposed serialized multitasking method outperforms typical
sequence classification techniques on current and response sentiment
classification. Furthermore, leveraging conversational context and speech
embeddings significantly improves both response text generation and sentiment
prediction. Our proposed framework achieves relative improvements of 6.7%,
12.0%, and 3.5% in current sentiment accuracy, response sentiment accuracy, and
response text BLEU score, respectively.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15318" title="Abstract">arXiv:2312.15318</a> [<a href="/pdf/2312.15318" title="Download PDF">pdf</a>, <a href="/ps/2312.15318" title="Download PostScript">ps</a>, <a href="/format/2312.15318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Rapid Bug Resolution for Android Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+J">Junayed Mahmud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, to appear in the Proceedings of the 46th International Conference on Software Engineering (ICSE'24) - Doctoral Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Bug reports document unexpected behaviors in software, enabling developers to
understand, validate, and fix bugs. Unfortunately, a significant portion of bug
reports is of low quality, which poses challenges for developers in terms of
addressing these issues. Prior research has delved into the information needed
for documenting high-quality bug reports and expediting bug report management.
Furthermore, researchers have explored the challenges associated with bug
report management and proposed various automated techniques. Nevertheless,
these techniques exhibit several limitations, including a lexical gap between
developers and reporters, difficulties in bug reproduction, and identifying bug
locations. Therefore, there is a pressing need for additional efforts to
effectively manage bug reports and enhance the quality of both desktop and
mobile applications. In this paper, we describe the existing limitations of bug
reports and identify potential strategies for addressing them. Our vision
encompasses a future where the alleviation of these limitations and successful
execution of our proposed new research directions can benefit both reporters
and developers, ultimately making the entire software maintenance faster.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15319" title="Abstract">arXiv:2312.15319</a> [<a href="/pdf/2312.15319" title="Download PDF">pdf</a>, <a href="/format/2312.15319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMAP: A Threat Modeling and Attack Path Analysis Framework for  Industrial IoT Systems (A Case Study of IoM and IoP)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+K">Kumar Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Gajjala%2C+D">Deepak Gajjala</a>, 
<a href="/search/cs?searchtype=author&query=Kaipa%2C+K">Krishna Kaipa</a>, 
<a href="/search/cs?searchtype=author&query=Vyas%2C+R">Ranjana Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Vyas%2C+O+P">O.P. Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Khondoker%2C+R">Rahamatullah Khondoker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Industrial cyber-physical systems (ICPS) are gradually integrating
information technology and automating industrial processes, leading systems to
become more vulnerable to malicious actors. Thus, to deploy secure Industrial
Control and Production Systems (ICPS) in smart factories, cyber threats and
risks must be addressed. To identify all possible threats, Threat Modeling is a
promising solution. Despite the existence of numerous methodological solutions
for threat modeling in cyber-physical systems (CPS), current approaches are ad
hoc and inefficient in providing clear insights to researchers and
organizations involved in IIoT technologies. These approaches lack a
comprehensive analysis of cyber threats and fail to facilitate effective path
analysis across the ICPS lifecycle, incorporating smart manufacturing
technologies and tools. To address these gaps, a novel quantitative threat
modeling approach is proposed, aiming to identify probable attack vectors,
assess the path of attacks, and evaluate the magnitude of each vector. This
paper also explains the execution of the proposed approach with two case
studies, namely the industrial manufacturing line, i.e., the Internet of
Manufacturing (IoM), and the power and industry, i.e., the Internet of
Production (IoP).
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15321" title="Abstract">arXiv:2312.15321</a> [<a href="/pdf/2312.15321" title="Download PDF">pdf</a>, <a href="/format/2312.15321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy Grammar Induction with Indirect Negative Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potashnik%2C+J">Joseph Potashnik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages (including appendices and references), 2 png files. 5 anciliary files (dataset)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper offers a fresh look at the pumping lemma constant as an upper
bound for the finite structural information of a Context Free Grammar. An
objective function based on indirect negative evidence considers the
occurrences, and non-occurrences, of a finite number of trees, encountered
after a sufficiently long non-adversial input presentation. This objective
function has optimal substructure in the hypotheses space, giving rise to a
greedy search learner. With this learner, a range of classes of Context Free
Languages is shown to be learnable (identifiable in the limit) on an otherwise
intractable hypotheses space.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15322" title="Abstract">arXiv:2312.15322</a> [<a href="/pdf/2312.15322" title="Download PDF">pdf</a>, <a href="/format/2312.15322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware-Aware DNN Compression via Diverse Pruning and Mixed-Precision  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balaskas%2C+K">Konstantinos Balaskas</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+A">Andreas Karatzas</a>, 
<a href="/search/cs?searchtype=author&query=Sad%2C+C">Christos Sad</a>, 
<a href="/search/cs?searchtype=author&query=Siozios%2C+K">Kostas Siozios</a>, 
<a href="/search/cs?searchtype=author&query=Anagnostopoulos%2C+I">Iraklis Anagnostopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zervakis%2C+G">Georgios Zervakis</a>, 
<a href="/search/cs?searchtype=author&query=Henkel%2C+J">J&#xf6;rg Henkel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep Neural Networks (DNNs) have shown significant advantages in a wide
variety of domains. However, DNNs are becoming computationally intensive and
energy hungry at an exponential pace, while at the same time, there is a vast
demand for running sophisticated DNN-based services on resource constrained
embedded devices. In this paper, we target energy-efficient inference on
embedded DNN accelerators. To that end, we propose an automated framework to
compress DNNs in a hardware-aware manner by jointly employing pruning and
quantization. We explore, for the first time, per-layer fine- and
coarse-grained pruning, in the same DNN architecture, in addition to low
bit-width mixed-precision quantization for weights and activations.
Reinforcement Learning (RL) is used to explore the associated design space and
identify the pruning-quantization configuration so that the energy consumption
is minimized whilst the prediction accuracy loss is retained at acceptable
levels. Using our novel composite RL agent we are able to extract
energy-efficient solutions without requiring retraining and/or fine tuning. Our
extensive experimental evaluation over widely used DNNs and the CIFAR-10/100
and ImageNet datasets demonstrates that our framework achieves $39\%$ average
energy reduction for $1.7\%$ average accuracy loss and outperforms
significantly the state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15323" title="Abstract">arXiv:2312.15323</a> [<a href="/pdf/2312.15323" title="Download PDF">pdf</a>, <a href="/ps/2312.15323" title="Download PostScript">ps</a>, <a href="/format/2312.15323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Microservice-based Middleware for a Multi-hazard Early Warning  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akanbi%2C+A">A Akanbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Environmental hazards like water and air pollution, extreme weather, or
chemical exposures can affect human health in a number of ways, and it is a
persistent apprehension in communities surrounded by mining operations. The
application of modern technologies in the environmental monitoring of these
Human-made hazards is critical, because while not immediately
health-threatening may turn out detrimental with unwanted negative effects.
Enabling technologies needed to realise this concept is multifaceted and most
especially involves deploying interconnected Internet of Things (IoT) sensors,
existing legacy systems, enterprise networks, multi layered software
architecture (middleware), and event processing engines, amongst others.
Currently, the integration of several early warning systems has inherent
challenges, mostly due to the heterogeneity of components. This paper proposes
transversal microservice-based middleware aiming at increasing data
integration, interoperability, scalability, high availability, and reusability
of adopted systems using a container orchestration framework for a multi-hazard
early warning system. Devised within the scope of the ICMHEWS project, the
proposed platform aims at improving known challenges.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15337" title="Abstract">arXiv:2312.15337</a> [<a href="/pdf/2312.15337" title="Download PDF">pdf</a>, <a href="/ps/2312.15337" title="Download PostScript">ps</a>, <a href="/format/2312.15337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient Galerkin method for problems with physically realistic  boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Podvigina%2C+O">Olga Podvigina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JCP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Galerkin method is often employed for numerical integration of
evolutionary equations, such as the Navier-Stokes equation or the magnetic
induction equation. Application of the method requires solving an equation of
the form $P(Av-f)=0$ at each time step, where $v$ is an element of a
finite-dimensional space $V$ with a basis satisfying boundary conditions, $P$
is the orthogonal projection on this space and $A$ is a linear operator.
Usually the coefficients of $v$ expanded in the basis are found by calculating
the matrix of $PA$ acting on $V$ and solving the respective system of linear
equations. For physically realistic boundary conditions (such as the no-slip
boundary conditions for the velocity, or for a dielectric outside the fluid
volume for the magnetic field) the basis is often not orthogonal and solving
the problem can be computationally demanding. We propose an algorithm giving an
opportunity to reduce the computational cost for such a problem. Suppose there
exists a space $W$ that contains $V$, the difference between the dimensions of
$W$ and $V$ is small relative to the dimension of $V$, and solving the problem
$P(Aw-f)=0$, where $w$ is an element of $W$, requires less operations than
solving the original problem. The equation $P(Av-f)=0$ is then solved in two
steps: we solve the problem $P(Aw-f)=0$ in $W$, find a correction $h=v-w$ that
belongs to a complement to $V$ in $W$, and obtain the solution $w+h$. When the
dimension of the complement is small the proposed algorithm is more efficient
than the traditional one.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15338" title="Abstract">arXiv:2312.15338</a> [<a href="/pdf/2312.15338" title="Download PDF">pdf</a>, <a href="/ps/2312.15338" title="Download PostScript">ps</a>, <a href="/format/2312.15338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spigot-Algorithm for Square-Roots: Explained and Extended
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+M">Mayer Goldberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">This work presents and extends a known spigot-algorithm for computing
square-roots, digit-by-digit, that is suitable for calculation by hand or an
abacus, using only addition and subtraction. We offer an elementary proof of
correctness for the original algorithm, then present a corresponding
spigot-algorithm for computing cube-roots. Finally, we generalize the
algorithm, so as to find $r$-th roots, and show how to optimize the algorithm
for any $r$. The resulting algorithms require only integer addition and
subtraction.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15339" title="Abstract">arXiv:2312.15339</a> [<a href="/pdf/2312.15339" title="Download PDF">pdf</a>, <a href="/format/2312.15339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaDi: Learning to Mask Distractions for Generalization in Visual Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grooten%2C+B">Bram Grooten</a>, 
<a href="/search/cs?searchtype=author&query=Tomilin%2C+T">Tristan Tomilin</a>, 
<a href="/search/cs?searchtype=author&query=Vasan%2C+G">Gautham Vasan</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+M+E">Matthew E. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A+R">A. Rupam Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
<a href="/search/cs?searchtype=author&query=Mocanu%2C+D+C">Decebal Constantin Mocanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as full-paper (oral) at AAMAS 2024. Code is available at <a href="https://github.com/bramgrooten/mask-distractions">this https URL</a> and see our 40-second video at <a href="https://youtu.be/2oImF0h1k48">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">The visual world provides an abundance of information, but many input pixels
received by agents often contain distracting stimuli. Autonomous agents need
the ability to distinguish useful information from task-irrelevant perceptions,
enabling them to generalize to unseen environments with new distractions.
Existing works approach this problem using data augmentation or large auxiliary
networks with additional loss functions. We introduce MaDi, a novel algorithm
that learns to mask distractions by the reward signal only. In MaDi, the
conventional actor-critic structure of deep reinforcement learning agents is
complemented by a small third sibling, the Masker. This lightweight neural
network generates a mask to determine what the actor and critic will receive,
such that they can focus on learning the task. The masks are created
dynamically, depending on the current input. We run experiments on the DeepMind
Control Generalization Benchmark, the Distracting Control Suite, and a real UR5
Robotic Arm. Our algorithm improves the agent's focus with useful masks, while
its efficient Masker network only adds 0.2% more parameters to the original
structure, in contrast to previous work. MaDi consistently achieves
generalization results better than or competitive to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15340" title="Abstract">arXiv:2312.15340</a> [<a href="/pdf/2312.15340" title="Download PDF">pdf</a>, <a href="/format/2312.15340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learning-Based Adaptive Stability Certificates for Dynamical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jena%2C+A">Amit Jena</a>, 
<a href="/search/eess?searchtype=author&query=Kalathil%2C+D">Dileep Kalathil</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Le Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for AAAI-24 (The 38th Annual AAAI Conference on Artificial Intelligence)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper addresses the problem of Neural Network (NN) based adaptive
stability certification in a dynamical system. The state-of-the-art methods,
such as Neural Lyapunov Functions (NLFs), use NN-based formulations to assess
the stability of a non-linear dynamical system and compute a Region of
Attraction (ROA) in the state space. However, under parametric uncertainty, if
the values of system parameters vary over time, the NLF methods fail to adapt
to such changes and may lead to conservative stability assessment performance.
We circumvent this issue by integrating Model Agnostic Meta-learning (MAML)
with NLFs and propose meta-NLFs. In this process, we train a meta-function that
adapts to any parametric shifts and updates into an NLF for the system with new
test-time parameter values. We demonstrate the stability assessment performance
of meta-NLFs on some standard benchmark autonomous dynamical systems.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15342" title="Abstract">arXiv:2312.15342</a> [<a href="/pdf/2312.15342" title="Download PDF">pdf</a>, <a href="/format/2312.15342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High Order Geometry Conforming Immersed Finite Element for Elliptic  Interface Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adjerid%2C+S">Slimane Adjerid</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Tao Lin</a>, 
<a href="/search/math?searchtype=author&query=Meghaichi%2C+H">Haroun Meghaichi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a high order immersed finite element (IFE) method for solving the
elliptic interface problem with interface-independent meshes. The IFE functions
developed here satisfy the interface conditions exactly and they have optimal
approximation capabilities. The construction of this novel IFE space relies on
a nonlinear transformation based on the Frenet-Serret frame of the interface to
locally map it into a line segment, and this feature makes the process of
constructing the IFE functions cost-effective and robust for any degree. This
new class of immersed finite element functions is locally conforming with the
usual weak form of the interface problem so that they can be employed in the
standard interior penalty discontinuous Galerkin scheme without additional
penalties on the interface. Numerical examples are provided to showcase the
convergence properties of the method under $h$ and $p$ refinements.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15345" title="Abstract">arXiv:2312.15345</a> [<a href="/pdf/2312.15345" title="Download PDF">pdf</a>, <a href="/format/2312.15345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboFiSense: Attention-Based Robotic Arm Activity Recognition with WiFi  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zandi%2C+R">Rojin Zandi</a>, 
<a href="/search/cs?searchtype=author&query=Behzad%2C+K">Kian Behzad</a>, 
<a href="/search/cs?searchtype=author&query=Motamedi%2C+E">Elaheh Motamedi</a>, 
<a href="/search/cs?searchtype=author&query=Salehinejad%2C+H">Hojjat Salehinejad</a>, 
<a href="/search/cs?searchtype=author&query=Siami%2C+M">Milad Siami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Despite the current surge of interest in autonomous robotic systems, robot
activity recognition within restricted indoor environments remains a formidable
challenge. Conventional methods for detecting and recognizing robotic arms'
activities often rely on vision-based or light detection and ranging (LiDAR)
sensors, which require line-of-sight (LoS) access and may raise privacy
concerns, for example, in nursing facilities. This research pioneers an
innovative approach harnessing channel state information (CSI) measured from
WiFi signals, subtly influenced by the activity of robotic arms. We developed
an attention-based network to classify eight distinct activities performed by a
Franka Emika robotic arm in different situations. Our proposed bidirectional
vision transformer-concatenated (BiVTC) methodology aspires to predict robotic
arm activities accurately, even when trained on activities with different
velocities, all without dependency on external or internal sensors or visual
aids. Considering the high dependency of CSI data to the environment, motivated
us to study the problem of sniffer location selection, by systematically
changing the sniffer's location and collecting different sets of data. Finally,
this paper also marks the first publication of the CSI data of eight distinct
robotic arm activities, collectively referred to as RoboFiSense. This
initiative aims to provide a benchmark dataset and baselines to the research
community, fostering advancements in the field of robotics sensing.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15346" title="Abstract">arXiv:2312.15346</a> [<a href="/pdf/2312.15346" title="Download PDF">pdf</a>, <a href="/format/2312.15346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multi-Step Manipulation Tasks from A Single Human Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dingkun Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Learning from a single demonstration is promising given the difficulty in
collecting sizeable robot data. However, the challenge remains to develop a
robot system that matches human capabilities and data efficiency in learning
and generalizability, particularly in complex, unstructured real-world
scenarios. We propose a system that processes RGBD videos to translate human
actions to robot primitives and identifies task-relevant key poses of objects
using Grounded Segment Anything. We then address challenges for robots in
replicating human actions, considering the human-robot differences in
kinematics and collision geometry. To test the effectiveness of our system, we
conducted experiments focusing on manual dishwashing. With a single human
demonstration recorded in a mockup kitchen, the system achieved 50-100\%
success for each step and up to a 40\% success rate for the whole task with
different objects in a home kitchen. Videos are available at
https://robot-dishwashing.github.io
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15347" title="Abstract">arXiv:2312.15347</a> [<a href="/pdf/2312.15347" title="Download PDF">pdf</a>, <a href="/format/2312.15347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Safety and Liveness Filtering Using Hamilton-Jacobi Reachability  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borquez%2C+J">Javier Borquez</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+K">Kaustav Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Somil Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Hamilton-Jacobi (HJ) reachability-based filtering provides a powerful
framework to co-optimize performance and safety (or liveness) for autonomous
systems. Under this filtering scheme, a nominal controller is minimally
modified to ensure system safety or liveness. However, the resulting
controllers can exhibit abrupt switching and bang-bang behavior, which is not
suitable for applications of autonomous systems in the real world. This work
presents a novel, unifying framework to design safety and liveness filters
through reachability analysis. We explicitly characterize the maximal set of
control inputs that ensures safety (or liveness) at a given state. Different
safety filters can then be constructed using different subsets of this maximal
set along with a projection operator to modify the nominal controller. We use
the proposed framework to design three safety filters, each balancing
performance, computation time, and smoothness differently. The proposed filters
can easily handle dynamics uncertainties, disturbances, and bounded control
inputs. We highlight their relative strengths and limitations by applying these
filters to autonomous navigation and rocket landing scenarios and on a physical
robot testbed. We also discuss practical aspects associated with implementing
these filters on real-world autonomous systems. Our research advances the
understanding and potential application of reachability-based controllers on
real-world autonomous systems.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15350" title="Abstract">arXiv:2312.15350</a> [<a href="/pdf/2312.15350" title="Download PDF">pdf</a>, <a href="/format/2312.15350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Not Mitigate Vulnerabilities in Helm Charts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiahuei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+B">Bram Adams</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A+E">Ahmed E. Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">[Context]: Containerization ensures the resilience of distributed
applications by Kubernetes. Helm is a package manager for Kubernetes
applications. A Helm package, namely "Chart'', is a set of pre-configured
resources that one could quickly deploy a complex application. However, Helm
broadens the attack surface of the distributed applications.
<br />[Objective]: This study aims to investigate the prevalence of fixable
vulnerabilities, the factors related to the vulnerabilities, and current
mitigation strategies in Helm Charts.
<br />[Method]: We conduct a mixed-methods study on 11,035 Helm Charts affected by
10,982 fixable vulnerabilities. We analyze the complexity of Charts and compare
the distribution of vulnerabilities between official and unofficial Charts.
Subsequently, we investigate vulnerability mitigation strategies from the
Chart-associated repositories by a grounded theory.
<br />[Results]: Our findings highlight that the complexity of a Chart correlates
with the number of vulnerabilities, and the official Charts do not contain
fewer vulnerabilities compared to unofficial Charts. The 10,982 fixable
vulnerabilities are at a median of high severity and can be easily exploited.
In addition, we identify 11 vulnerability mitigation strategies in three
categories. Due to the complexity of Charts, maintainers are required to
investigate where a vulnerability impacts and how to mitigate it. The use of
automated strategies is low as automation has limited capability(e.g., a higher
number of false positives) in such complex Charts.
<br />[Conclusion]: There exists need for automation tools that assist maintainers
in mitigating vulnerabilities to reduce manual effort. In addition, Chart
maintainers lack incentives to mitigate vulnerabilities, given a lack of
guidelines for mitigation responsibilities. Adopting a shared responsibility
model in the Helm ecosystem would increase its security.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15353" title="Abstract">arXiv:2312.15353</a> [<a href="/pdf/2312.15353" title="Download PDF">pdf</a>, <a href="/format/2312.15353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Outcome-driven Higher-order Dependencies in Graphs of  Disease Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krieg%2C+S+J">Steven J. Krieg</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+K">Keith Feldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The widespread application of machine learning techniques to biomedical data
has produced many new insights into disease progression and improving clinical
care. Inspired by the flexibility and interpretability of graphs (networks), as
well as the potency of sequence models like transformers and higher-order
networks (HONs), we propose a method that identifies combinations of risk
factors for a given outcome and accurately encodes these higher-order
relationships in a graph. Using historical data from 913,475 type 2 diabetes
(T2D) patients, we found that, compared to other approaches, the proposed
networks encode significantly more information about the progression of T2D
toward a variety of outcomes. We additionally demonstrate how structural
information from the proposed graph can be used to augment the performance of
transformer-based models on predictive tasks, especially when the data are
noisy. By increasing the order, or memory, of the graph, we show how the
proposed method illuminates key risk factors while successfully ignoring noisy
elements, which facilitates analysis that is simultaneously accurate and
interpretable.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15354" title="Abstract">arXiv:2312.15354</a> [<a href="/pdf/2312.15354" title="Download PDF">pdf</a>, <a href="/format/2312.15354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scout-Net: Prospective Personalized Estimation of CT Organ Doses from  Scout Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imran%2C+A">Abdullah-Al-Zubaer Imran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+D">Debashish Pal</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Sandeep Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+B">Bhavik Patel</a>, 
<a href="/search/cs?searchtype=author&query=Zucker%2C+E">Evan Zucker</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Adam Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 11 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Purpose: Estimation of patient-specific organ doses is required for more
comprehensive dose metrics, such as effective dose. Currently, available
methods are performed retrospectively using the CT images themselves, which can
only be done after the scan. To optimize CT acquisitions before scanning, rapid
prediction of patient-specific organ dose is needed prospectively, using
available scout images. We, therefore, devise an end-to-end, fully-automated
deep learning solution to perform real-time, patient-specific, organ-level
dosimetric estimation of CT scans.
<br />Approach: We propose the Scout-Net model for CT dose prediction at six
different organs as well as for the overall patient body, leveraging the
routinely obtained frontal and lateral scout images of patients, before their
CT scans. To obtain reference values of the organ doses, we used Monte Carlo
simulation and 3D segmentation methods on the corresponding CT images of the
patients.
<br />Results: We validate our proposed Scout-Net model against real patient CT
data and demonstrate the effectiveness in estimating organ doses in real-time
(only 27 ms on average per scan). Additionally, we demonstrate the efficiency
(real-time execution), sufficiency (reasonable error rates), and robustness
(consistent across varying patient sizes) of the Scout-Net model.
<br />Conclusions: An effective, efficient, and robust Scout-Net model, once
incorporated into the CT acquisition plan, could potentially guide the
automatic exposure control for balanced image quality and radiation dose.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15356" title="Abstract">arXiv:2312.15356</a> [<a href="/pdf/2312.15356" title="Download PDF">pdf</a>, <a href="/format/2312.15356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short-lived High-volume Multi-A(rmed)/B(andits) Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Su Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Andrew Li</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+R">R. Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Oli%2C+N">Nishant Oli</a>, 
<a href="/search/cs?searchtype=author&query=Duff%2C+P">Paul Duff</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+I">Ian Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Modern platforms leverage randomized experiments to make informed decisions
from a given set of items (``treatments''). As a particularly challenging
scenario, these items may (i) arrive in high volume, with thousands of new
items being released per hour, and (ii) have short lifetime, say, due to the
item's transient nature or underlying non-stationarity that impels the platform
to perceive the same item as distinct copies over time. Thus motivated, we
study a Bayesian multiple-play bandit problem that encapsulates the key
features of the multivariate testing (or ``multi-A/B testing'') problem with a
high volume of short-lived arms. In each round, a set of $k$ arms arrive, each
available for $w$ rounds. Without knowing the mean reward for each arm, the
learner selects a multiset of $n$ arms and immediately observes their realized
rewards. We aim to minimize the loss due to not knowing the mean rewards,
averaged over instances generated from a given prior distribution. We show that
when $k = O(n^\rho)$ for some constant $\rho&gt;0$, our proposed policy has
$\tilde O(n^{-\min \{\rho, \frac 12 (1+\frac 1w)^{-1}\}})$ loss on a
sufficiently large class of prior distributions. We complement this result by
showing that every policy suffers $\Omega (n^{-\min \{\rho, \frac 12\}})$ loss
on the same class of distributions. We further validate the effectiveness of
our policy through a large-scale field experiment on {\em Glance}, a
content-card-serving platform that faces exactly the above challenge. A simple
variant of our policy outperforms the platform's current recommender by 4.32\%
in total duration and 7.48\% in total number of click-throughs.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15357" title="Abstract">arXiv:2312.15357</a> [<a href="/pdf/2312.15357" title="Download PDF">pdf</a>, <a href="/format/2312.15357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Decision Tree with Noisy Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Su Jia</a>, 
<a href="/search/cs?searchtype=author&query=Navidi%2C+F">Fatemeh Navidi</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+V">Viswanath Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+R">R. Ravi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In pool-based active learning, the learner is given an unlabeled data set and
aims to efficiently learn the unknown hypothesis by querying the labels of the
data points. This can be formulated as the classical Optimal Decision Tree
(ODT) problem: Given a set of tests, a set of hypotheses, and an outcome for
each pair of test and hypothesis, our objective is to find a low-cost testing
procedure (i.e., decision tree) that identifies the true hypothesis. This
optimization problem has been extensively studied under the assumption that
each test generates a deterministic outcome. However, in numerous applications,
for example, clinical trials, the outcomes may be uncertain, which renders the
ideas from the deterministic setting invalid. In this work, we study a
fundamental variant of the ODT problem in which some test outcomes are noisy,
even in the more general case where the noise is persistent, i.e., repeating a
test gives the same noisy output. Our approximation algorithms provide
guarantees that are nearly best possible and hold for the general case of a
large number of noisy outcomes per test or per hypothesis where the performance
degrades continuously with this number. We numerically evaluated our algorithms
for identifying toxic chemicals and learning linear classifiers, and observed
that our algorithms have costs very close to the information-theoretic minimum.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15359" title="Abstract">arXiv:2312.15359</a> [<a href="/pdf/2312.15359" title="Download PDF">pdf</a>, <a href="/format/2312.15359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LETA: Learning Transferable Attribution for Generic Vision Explainer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanchu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yu-Neng Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chia-Yuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shaochen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhaozhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xuanting Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Explainable machine learning significantly improves the transparency of deep
neural networks~(DNN). However, existing work is constrained to explaining the
behavior of individual model predictions, and lacks the ability to transfer the
explanation across various models and tasks. This limitation results in
explaining various tasks being time- and resource-consuming. To address this
problem, we develop a pre-trained, DNN-based, generic explainer on large-scale
image datasets, and leverage its transferability to explain various vision
models for downstream tasks. In particular, the pre-training of generic
explainer focuses on LEarning Transferable Attribution (LETA). The transferable
attribution takes advantage of the versatile output of the target backbone
encoders to comprehensively encode the essential attribution for explaining
various downstream tasks. LETA guides the pre-training of the generic explainer
towards the transferable attribution, and introduces a rule-based adaptation of
the transferable attribution for explaining downstream tasks, without the need
for additional training on downstream data. Theoretical analysis demonstrates
that the pre-training of LETA enables minimizing the explanation error bound
aligned with the conditional $\mathcal{V}$-information on downstream tasks.
Empirical studies involve explaining three different architectures of vision
models across three diverse downstream datasets. The experiment results
indicate LETA is effective in explaining these tasks without the need for
additional training on the data of downstream tasks.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15361" title="Abstract">arXiv:2312.15361</a> [<a href="/pdf/2312.15361" title="Download PDF">pdf</a>, <a href="/format/2312.15361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Federated Learning over Ground-to-Satellite Integrated  Networks: Joint Local Computation and Data Offloading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dong-Jun Han</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+D+J">David J. Love</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+M">Mung Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted for publication in IEEE Journal on Selected Areas in Communications (JSAC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While network coverage maps continue to expand, many devices located in
remote areas remain unconnected to terrestrial communication infrastructures,
preventing them from getting access to the associated data-driven services. In
this paper, we propose a ground-to-satellite cooperative federated learning
(FL) methodology to facilitate machine learning service management over remote
regions. Our methodology orchestrates satellite constellations to provide the
following key functions during FL: (i) processing data offloaded from ground
devices, (ii) aggregating models within device clusters, and (iii) relaying
models/data to other satellites via inter-satellite links (ISLs). Due to the
limited coverage time of each satellite over a particular remote area, we
facilitate satellite transmission of trained models and acquired data to
neighboring satellites via ISL, so that the incoming satellite can continue
conducting FL for the region. We theoretically analyze the convergence behavior
of our algorithm, and develop a training latency minimizer which optimizes over
satellite-specific network resources, including the amount of data to be
offloaded from ground devices to satellites and satellites' computation speeds.
Through experiments on three datasets, we show that our methodology can
significantly speed up the convergence of FL compared with terrestrial-only and
other satellite baseline approaches.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15363" title="Abstract">arXiv:2312.15363</a> [<a href="/pdf/2312.15363" title="Download PDF">pdf</a>, <a href="/format/2312.15363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEV-CV: Birds-Eye-View Transform for Cross-View Geo-Localisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shore%2C+T">Tavis Shore</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+S">Simon Hadfield</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+O">Oscar Mendez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cross-view image matching for geo-localisation is a challenging problem due
to the significant visual difference between aerial and ground-level
viewpoints. The method provides localisation capabilities from geo-referenced
images, eliminating the need for external devices or costly equipment. This
enhances the capacity of agents to autonomously determine their position,
navigate, and operate effectively in environments where GPS signals are
unavailable. Current research employs a variety of techniques to reduce the
domain gap such as applying polar transforms to aerial images or synthesising
between perspectives. However, these approaches generally rely on having a
360{\deg} field of view, limiting real-world feasibility. We propose BEV-CV, an
approach which introduces two key novelties. Firstly we bring ground-level
images into a semantic Birds-Eye-View before matching embeddings, allowing for
direct comparison with aerial segmentation representations. Secondly, we
introduce the use of a Normalised Temperature-scaled Cross Entropy Loss to the
sub-field, achieving faster convergence than with the standard triplet loss.
BEV-CV achieves state-of-the-art recall accuracies, improving feature
extraction Top-1 rates by more than 300%, and Top-1% rates by approximately
150% for 70{\deg} crops, and for orientation-aware application we achieve a 35%
Top-1 accuracy increase with 70{\deg} crops.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15364" title="Abstract">arXiv:2312.15364</a> [<a href="/pdf/2312.15364" title="Download PDF">pdf</a>, <a href="/format/2312.15364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WildScenes: A Benchmark for 2D and 3D Semantic Segmentation in  Large-scale Natural Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vidanapathirana%2C+K">Kavisha Vidanapathirana</a>, 
<a href="/search/cs?searchtype=author&query=Knights%2C+J">Joshua Knights</a>, 
<a href="/search/cs?searchtype=author&query=Hausler%2C+S">Stephen Hausler</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+M">Mark Cox</a>, 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Milad Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Jooste%2C+J">Jason Jooste</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+E">Ethan Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Shaheer Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+S">Sridha Sridharan</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. The first 3 authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent progress in semantic scene understanding has primarily been enabled by
the availability of semantically annotated bi-modal (camera and lidar) datasets
in urban environments. However, such annotated datasets are also needed for
natural, unstructured environments to enable semantic perception for
applications, including conservation, search and rescue, environment
monitoring, and agricultural automation. Therefore, we introduce WildScenes, a
bi-modal benchmark dataset consisting of multiple large-scale traversals in
natural environments, including semantic annotations in high-resolution 2D
images and dense 3D lidar point clouds, and accurate 6-DoF pose information.
The data is (1) trajectory-centric with accurate localization and globally
aligned point clouds, (2) calibrated and synchronized to support bi-modal
inference, and (3) containing different natural environments over 6 months to
support research on domain adaptation. Our 3D semantic labels are obtained via
an efficient automated process that transfers the human-annotated 2D labels
from multiple views into 3D point clouds, thus circumventing the need for
expensive and time-consuming human annotation in 3D. We introduce benchmarks on
2D and 3D semantic segmentation and evaluate a variety of recent deep-learning
techniques to demonstrate the challenges in semantic segmentation in natural
environments. We propose train-val-test splits for standard benchmarks as well
as domain adaptation benchmarks and utilize an automated split generation
technique to ensure the balance of class label distributions. The data,
evaluation scripts and pretrained models will be released upon acceptance at
https://csiro-robotics.github.io/WildScenes.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15366" title="Abstract">arXiv:2312.15366</a> [<a href="/pdf/2312.15366" title="Download PDF">pdf</a>, <a href="/format/2312.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed and asymptotic formulae for harmonic and quadratic harmonic sums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartoszek%2C+K">Krzysztof Bartoszek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Classical Analysis and ODEs (math.CA); Number Theory (math.NT)

</div>
<p class="mathjax">We present here a large collection of harmonic and quadratic harmonic sums,
that can be useful in applied questions, e.g., probabilistic ones. We find
closed-form formulae, that we were not able to locate in the literature.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15373" title="Abstract">arXiv:2312.15373</a> [<a href="/pdf/2312.15373" title="Download PDF">pdf</a>, <a href="/format/2312.15373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-day Needs-based Modeling Approach for Activity and Travel Demand  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Kexin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+J">Jinping Guan</a>, 
<a href="/search/eess?searchtype=author&query=Seshadri%2C+R">Ravi Seshadri</a>, 
<a href="/search/eess?searchtype=author&query=Pattabhiraman%2C+V">Varun Pattabhiraman</a>, 
<a href="/search/eess?searchtype=author&query=Aboutaleb%2C+Y+M">Youssef Medhat Aboutaleb</a>, 
<a href="/search/eess?searchtype=author&query=Shamshiripour%2C+A">Ali Shamshiripour</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaochun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ben-Akiva%2C+M">Moshe Ben-Akiva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">This paper proposes a multi-day needs-based model for activity and travel
demand analysis. The model captures the multi-day dynamics in activity
generation, which enables the modeling of activities with increased flexibility
in time and space (e.g., e-commerce and remote working). As an enhancement to
activity-based models, the proposed model captures the underlying
decision-making process of activity generation by accounting for psychological
needs as the drivers of activities. The level of need satisfaction is modeled
as a psychological inventory, whose utility is optimized via decisions on
activity participation, location, and duration. The utility includes both the
benefit in the inventory gained and the cost in time, monetary expense as well
as maintenance of safety stock. The model includes two sub-models, a
Deterministic Model that optimizes the utility of the inventory, and an
Empirical Model that accounts for heterogeneity and stochasticity. Numerical
experiments are conducted to demonstrate model scalability. A maximum
likelihood estimator is proposed, the properties of the log-likelihood function
are examined and the recovery of true parameters is tested. This research
contributes to the literature on transportation demand models in the following
three aspects. First, it is arguably better grounded in psychological theory
than traditional models and allows the generation of activity patterns to be
policy-sensitive (while avoiding the need for ad hoc utility definitions).
Second, it contributes to the development of needs-based models with a
non-myopic approach to model multi-day activity patterns. Third, it proposes a
tractable model formulation via problem reformulation and computational
enhancements, which allows for maximum likelihood parameter estimation.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15375" title="Abstract">arXiv:2312.15375</a> [<a href="/pdf/2312.15375" title="Download PDF">pdf</a>, <a href="/format/2312.15375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Efficiency and Privacy of Federated Learning  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahri%2C+S">Sofia Zahri</a>, 
<a href="/search/cs?searchtype=author&query=Bennouri%2C+H">Hajar Bennouri</a>, 
<a href="/search/cs?searchtype=author&query=Abdelmoniem%2C+A+M">Ahmed M. Abdelmoniem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In today's world, the rapid expansion of IoT networks and the proliferation
of smart devices in our daily lives, have resulted in the generation of
substantial amounts of heterogeneous data. These data forms a stream which
requires special handling. To handle this data effectively, advanced data
processing technologies are necessary to guarantee the preservation of both
privacy and efficiency. Federated learning emerged as a distributed learning
method that trains models locally and aggregates them on a server to preserve
data privacy. This paper showcases two illustrative scenarios that highlight
the potential of federated learning (FL) as a key to delivering efficient and
privacy-preserving machine learning within IoT networks. We first give the
mathematical foundations for key aggregation algorithms in federated learning,
i.e., FedAvg and FedProx. Then, we conduct simulations, using Flower Framework,
to show the \textit{efficiency} of these algorithms by training deep neural
networks on common datasets and show a comparison between the accuracy and loss
metrics of FedAvg and FedProx. Then, we present the results highlighting the
trade-off between maintaining privacy versus accuracy via simulations -
involving the implementation of the differential privacy (DP) method - in
Pytorch and Opacus ML frameworks on common FL datasets and data distributions
for both FedAvg and FedProx strategies.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15377" title="Abstract">arXiv:2312.15377</a> [<a href="/pdf/2312.15377" title="Download PDF">pdf</a>, <a href="/format/2312.15377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End 3D Object Detection using LiDAR Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raut%2C+G">Gaurav Raut</a>, 
<a href="/search/cs?searchtype=author&query=Patole%2C+A">Advait Patole</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">There has been significant progress made in the field of autonomous vehicles.
Object detection and tracking are the primary tasks for any autonomous vehicle.
The task of object detection in autonomous vehicles relies on a variety of
sensors like cameras, and LiDAR. Although image features are typically
preferred, numerous approaches take spatial data as input. Exploiting this
information we present an approach wherein, using a novel encoding of the LiDAR
point cloud we infer the location of different classes near the autonomous
vehicles. This approach does not implement a bird's eye view approach, which is
generally applied for this application and thus saves the extensive
pre-processing required. After studying the numerous networks and approaches
used to solve this approach, we have implemented a novel model with the
intention to inculcate their advantages and avoid their shortcomings. The
output is predictions about the location and orientation of objects in the
scene in form of 3D bounding boxes and labels of scene objects.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15379" title="Abstract">arXiv:2312.15379</a> [<a href="/pdf/2312.15379" title="Download PDF">pdf</a>, <a href="/ps/2312.15379" title="Download PostScript">ps</a>, <a href="/format/2312.15379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive modular verification of termination for busy-waiting programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fasse%2C+J">Justus Fasse</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+B">Bart Jacobs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Busy-waiting is an important, low-level synchronization pattern that is used
to implement higher-level abstractions for synchronization. Its termination
depends on cooperation by other threads as well as a fair thread scheduler.
<br />We present a general approach for modularly verifying busy-waiting concurrent
programs based on higher-order separation logic. The approach combines two
strands of prior work. First, the Jacobs and Piessens (2011)
higher-order-programming perspective for verifying concurrent modules. Second,
the Reinhard and Jacobs (2021) ghost signals approach to verify busy-waiting.
The latter uses classical specifications for synchronization constructs where
the module creates and discharges obligations. Such specifications, however,
fix particular client patterns and would in general require "obligation
transfer" to handle more intricate wait dependencies. This precludes clients
from performing lock handoffs, an important mechanism to control (un)fairness
in the design of locks. Our contribution -- inspired by D'Osualdo, Sutherland,
Farzan and Gardner (2021)'s TaDA Live -- is to require the client to create and
discharge obligations as necessary to satisfy the module's liveness
requirements. However, instead of building these liveness requirements into the
logic, we express them by having the module's operations take auxiliary code as
arguments whose job it is to generate the call permissions the module needs for
its busy-waiting.
<br />In the paper we present specifications and proofs in Iris. We validated our
approach by developing a (non-foundational) machine-checked proof of a cohort
lock -- to the best of our knowledge the first of its kind -- using an encoding
of our approach in the VeriFast program verifier for C and Java. This fair lock
is implemented on top of another fair lock module and involves lock handoff,
thus exercising the asserted contributions.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15380" title="Abstract">arXiv:2312.15380</a> [<a href="/pdf/2312.15380" title="Download PDF">pdf</a>, <a href="/format/2312.15380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Battery-Care Resource Allocation and Task Offloading in Multi-Agent  Post-Disaster MEC Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yiwei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hualong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wenhan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+G">Geyong Min</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhekai Duan</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yuchuan Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by wcnc2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Being an up-and-coming application scenario of mobile edge computing (MEC),
the post-disaster rescue suffers multitudinous computing-intensive tasks but
unstably guaranteed network connectivity. In rescue environments, quality of
service (QoS), such as task execution delay, energy consumption and battery
state of health (SoH), is of significant meaning. This paper studies a
multi-user post-disaster MEC environment with unstable 5G communication, where
device-to-device (D2D) link communication and dynamic voltage and frequency
scaling (DVFS) are adopted to balance each user's requirement for task delay
and energy consumption. A battery degradation evaluation approach to prolong
battery lifetime is also presented. The distributed optimization problem is
formulated into a mixed cooperative-competitive (MCC) multi-agent Markov
decision process (MAMDP) and is tackled with recurrent multi-agent Proximal
Policy Optimization (rMAPPO). Extensive simulations and comprehensive
comparisons with other representative algorithms clearly demonstrate the
effectiveness of the proposed rMAPPO-based offloading scheme.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15382" title="Abstract">arXiv:2312.15382</a> [<a href="/pdf/2312.15382" title="Download PDF">pdf</a>, <a href="/format/2312.15382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient simulation of mixed boundary value problems and conformal  mappings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+Q">Qiansheng Han</a>, 
<a href="/search/math?searchtype=author&query=Rasila%2C+A">Antti Rasila</a>, 
<a href="/search/math?searchtype=author&query=Sottinen%2C+T">Tommi Sottinen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Complex Variables (math.CV); Probability (math.PR)

</div>
<p class="mathjax">In this paper, we present a stochastic method for the simulation of Laplace's
equation with a mixed boundary condition in planar domains that are polygonal
or bounded by circular arcs. We call this method the Reflected Walk on Spheres
algorithm. The method combines a traditional Walk on Spheres algorithm with use
of reflections at the Neumann boundaries. We apply our algorithm to simulate
numerical conformal mappings from certain quadrilaterals to the corresponding
canonical domains, and to compute their conformal moduli. Finally, we give
examples of the method on three dimensional polyhedral domains, and use it to
simulate the heat flow on an L-shaped insulated polyhedron.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15383" title="Abstract">arXiv:2312.15383</a> [<a href="/pdf/2312.15383" title="Download PDF">pdf</a>, <a href="/ps/2312.15383" title="Download PostScript">ps</a>, <a href="/format/2312.15383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Technical Implementation and Human Impact of Internet Privacy  Regulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Birrell%2C+E">Eleanor Birrell</a>, 
<a href="/search/cs?searchtype=author&query=Rodolitz%2C+J">Jay Rodolitz</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+A">Angel Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jenna Lee</a>, 
<a href="/search/cs?searchtype=author&query=McReynolds%2C+E">Emily McReynolds</a>, 
<a href="/search/cs?searchtype=author&query=Hutson%2C+J">Jevan Hutson</a>, 
<a href="/search/cs?searchtype=author&query=Lerner%2C+A">Ada Lerner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Growing recognition of the potential for exploitation of personal data and of
the shortcomings of prior privacy regimes has led to the passage of a multitude
of new online privacy regulations. Some of these laws -- notably the European
Union's General Data Protection Regulation (GDPR) and the California Consumer
Privacy Act (CCPA) -- have been the focus of large bodies of research by the
computer science community, while others have received less attention. In this
work, we analyze a set of Internet privacy and data protection regulations
drawn from around the world -- both those that have frequently been studied by
computer scientists and those that have not -- and develop a taxonomy of rights
granted and obligations imposed by these laws. We then leverage this taxonomy
to systematize 270 technical research papers published in computer science
venues that investigate the impact of these laws and explore how technical
solutions can complement legal protections. Finally, we analyze the results in
this space through an interdisciplinary lens and make recommendations for
future work at the intersection of computer science and legal privacy.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15388" title="Abstract">arXiv:2312.15388</a> [<a href="/pdf/2312.15388" title="Download PDF">pdf</a>, <a href="/format/2312.15388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEAP: Design Space Exploration for DNN Accelerator Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+E">Ekansh Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X+S">Xiangyu Sam Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The boom in Large Language Models (LLMs) like GPT-4 and ChatGPT has marked a
significant advancement in artificial intelligence. These models are becoming
increasingly complex and powerful to train and serve. This growth in
capabilities comes with a substantial increase in computational requirements,
both in terms of hardware resources and energy consumption. The goal of this
paper is to showcase how hardware and software co-design can come together and
allow us to create customized hardware systems for specific LLM workloads. We
propose a simulation workflow that allows us to combine model parallelism
techniques with a multi-accelerator simulation framework for efficiency
metrics. We focus on inference workloads and report power, cycle, and latency
metrics upon performing a design space exploration search over multiple
software and hardware configurations.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15392" title="Abstract">arXiv:2312.15392</a> [<a href="/pdf/2312.15392" title="Download PDF">pdf</a>, <a href="/ps/2312.15392" title="Download PostScript">ps</a>, <a href="/format/2312.15392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain Smart Contract Threat Detection Technology Based on Symbolic  Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chang Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The security of smart contracts, which are an important part of blockchain
technology, has attracted much attention. In particular, reentrancy
vulnerability, which is hidden and complex, poses a great threat to smart
contracts. In order to improve the existing detection methods, which exhibit
low efficiency and accuracy, in this paper, we propose a smart contract threat
detection technology based on symbolic execution. In this method, first, the
recursive descent algorithm is used to recover the basic blocks of contract
code and control flow diagram, and static type inference is performed for
static single assignment (SSA) variables. Then, the control flow diagram is
encoded into constrained horn clause (CHC) constraints in combination with the
symbolic execution technology. Model checking is conducted for the generated
constraints using an automatic theorem prover based on the abstraction
refinement technique for fast static detection of common security threats in
smart contracts. Compared with existing detection methods, the method proposed
in this paper allows the detection of both the checks-effects-interactions
pattern and the vulnerability in relation to reentrant locks. It can simulate
the state changes of reentrant locks as well as other global variables in
multiple recursive transactions. The experimental results show that this method
significantly increases both detection efficiency and accuracy, improving the
security of smart contracts.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15393" title="Abstract">arXiv:2312.15393</a> [<a href="/pdf/2312.15393" title="Download PDF">pdf</a>, <a href="/format/2312.15393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiased Learning for Remote Sensing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Chun-Hsiao Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+C">Charles Hill</a>, 
<a href="/search/cs?searchtype=author&query=Steck%2C+Z">Zackery Steck</a>, 
<a href="/search/cs?searchtype=author&query=Kangas%2C+S">Scott Kangas</a>, 
<a href="/search/cs?searchtype=author&query=Reite%2C+A">Aaron Reite</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2023 MultiEarth Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning has had remarkable success at analyzing handheld imagery such
as consumer photos due to the availability of large-scale human annotations
(e.g., ImageNet). However, remote sensing data lacks such extensive annotation
and thus potential for supervised learning. To address this, we propose a
highly effective semi-supervised approach tailored specifically to remote
sensing data. Our approach encompasses two key contributions. First, we adapt
the FixMatch framework to remote sensing data by designing robust strong and
weak augmentations suitable for this domain. Second, we develop an effective
semi-supervised learning method by removing bias in imbalanced training data
resulting from both actual labels and pseudo-labels predicted by the model. Our
simple semi-supervised framework was validated by extensive experimentation.
Using 30\% of labeled annotations, it delivers a 7.1\% accuracy gain over the
supervised learning baseline and a 2.1\% gain over the supervised
state-of-the-art CDS method on the remote sensing xView dataset.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15395" title="Abstract">arXiv:2312.15395</a> [<a href="/pdf/2312.15395" title="Download PDF">pdf</a>, <a href="/format/2312.15395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Valuation Based on Shapley Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaokai Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haocheng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) excel on new tasks without additional training,
simply by providing natural language prompts that demonstrate how the task
should be performed. Prompt ensemble methods comprehensively harness the
knowledge of LLMs while mitigating individual biases and errors and further
enhancing performance. However, more prompts do not necessarily lead to better
results, and not all prompts are beneficial. A small number of high-quality
prompts often outperform many low-quality prompts. Currently, there is a lack
of a suitable method for evaluating the impact of prompts on the results. In
this paper, we utilize the Shapley value to fairly quantify the contributions
of prompts, helping to identify beneficial or detrimental prompts, and
potentially guiding prompt valuation in data markets. Through extensive
experiments employing various ensemble methods and utility functions on diverse
tasks, we validate the effectiveness of using the Shapley value method for
prompts as it effectively distinguishes and quantifies the contributions of
each prompt.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15398" title="Abstract">arXiv:2312.15398</a> [<a href="/pdf/2312.15398" title="Download PDF">pdf</a>, <a href="/format/2312.15398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness-Aware Structured Pruning in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zayed%2C+A">Abdelrahman Zayed</a>, 
<a href="/search/cs?searchtype=author&query=Mordido%2C+G">Goncalo Mordido</a>, 
<a href="/search/cs?searchtype=author&query=Shabanian%2C+S">Samira Shabanian</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+I">Ioana Baldini</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing size of large language models (LLMs) has introduced challenges
in their training and inference. Removing model components is perceived as a
solution to tackle the large model sizes, however, existing pruning methods
solely focus on performance, without considering an essential aspect for the
responsible use of LLMs: model fairness. It is crucial to address the fairness
of LLMs towards diverse groups, such as women, Black people, LGBTQ+, Jewish
communities, among others, as they are being deployed and available to a wide
audience. In this work, first, we investigate how attention heads impact
fairness and performance in pre-trained transformer-based language models. We
then propose a novel method to prune the attention heads that negatively impact
fairness while retaining the heads critical for performance, i.e. language
modeling capabilities. Our approach is practical in terms of time and
resources, as it does not require fine-tuning the final pruned, and fairer,
model. Our findings demonstrate a reduction in gender bias by 19%, 19.5%,
39.5%, 34.7%, 23%, and 8% for DistilGPT-2, GPT-2, GPT-Neo of two different
sizes, GPT-J, and Llama 2 models, respectively, in comparison to the biased
model, with only a slight decrease in performance.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15400" title="Abstract">arXiv:2312.15400</a> [<a href="/pdf/2312.15400" title="Download PDF">pdf</a>, <a href="/format/2312.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial music generation model with song structure graph analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Go%2C+S">Seonghyeon Go</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyogu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages(4 pages of paper and 1 references), 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this work, we propose a symbolic music generation model with the song
structure graph analysis network. We construct a graph that uses information
such as note sequence and instrument as node features, while the correlation
between note sequences acts as the edge feature. We trained a Graph Neural
Network to obtain node representation in the graph, then we use node
representation as input of Unet to generate CONLON pianoroll image latent. The
outcomes of our experimental results show that the proposed model can generate
a comprehensive form of music. Our approach represents a promising and
innovative method for symbolic music generation and holds potential
applications in various fields in Music Information Retreival, including music
composition, music classification, and music inpainting systems.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15402" title="Abstract">arXiv:2312.15402</a> [<a href="/pdf/2312.15402" title="Download PDF">pdf</a>, <a href="/format/2312.15402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Unfitted Interface Penalty DG--FE Method for Elliptic Interface  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+J">Juan Han</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+H">Haijun Wu</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+Y">Yuanming Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We design an unfitted interface penalty DG-FE method (UIPDG-FEM) for an
elliptic interface problem, which uses the interior penalty discontinuous
Galerkin methods locally along the interface together with additional penalty
terms on the interface (or the Nitsche's trick) to deal with the jump
conditions, and uses the finite element methods away from the interface.
Moreover, the trick of merging elements is used to keep the condition number of
the algebraic system not affected by the interface position. The proposed
UIPDG-FEM not only possesses flexibilities of the IPDG method, in particular,
simplifying the process of merging elements near a complex interface, but also
avoids its drawback of larger number of global degrees of freedom. The
convergence rates of the UIPDG-FEM solution are optimal and independent of the
interface position. Furthermore, a uniform estimate of the flux value is
established in terms of the discontinuous physical coefficients. A two
dimensional merging algorithm is also presented, which is guaranteed to succeed
under appropriate assumptions on the interface. Numerical examples are given to
verify the theoretical results.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15403" title="Abstract">arXiv:2312.15403</a> [<a href="/pdf/2312.15403" title="Download PDF">pdf</a>, <a href="/format/2312.15403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIRD: A Sender-Informed, Receiver-Driven Datacenter Transport Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasopoulos%2C+K">Konstantinos Prasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bugnion%2C+E">Edouard Bugnion</a>, 
<a href="/search/cs?searchtype=author&query=Kogias%2C+M">Marios Kogias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Datacenter switching hardware trends are delivering higher bisection
bandwidth but not proportionally larger SRAM packet buffer capacity. The lack
of buffer space challenges congestion control protocols to combine high link
utilization and minimal queuing. Additionally, protocols must ensure low
latency delivery, ease of deployment, and robust handling of congestion across
all possible bottlenecks.
<br />We present SIRD, a datacenter transport that fulfills all these requirements
by combining receiver-driven (RD) scheduling with a sender-informed (SI)
control loop that optimizes credit allocation. The combined approach, informed
overcommitment, achieves both high throughput and minimal buffering because it
allows receivers to efficiently allocate a very limited amount of credit. Since
little credit is used, receivers face little inbound traffic which minimizes
in-network buffering. As such, SIRD can deliver messages with low latency
without having to reserve Ethernet priorities. In addition to sender
information, SIRD integrates network feedback into scheduling decisions and
explicitly deals with core congestion, a typical limitation of end-to-end RD
protocols.
<br />We compare SIRD to two state-of-the-art receiver-driven protocols (Homa and
dcPIM) and two production-grade reactive protocols (Swift and DCTCP) and show
that SIRD is the only one that can consistently maximize link utilization,
minimize queuing, obtain near-optimal latency across a wide set of workloads
and traffic patterns, and never suffer from congestion collapse under high
load. SIRD causes 13% less peak buffering than Homa and achieves competitive
latency and utilization without requiring Ethernet priorities. Unlike dcPIM,
SIRD operates without latency-inducing message exchange rounds and outperforms
it in utilization, buffering, and tail latency by 9%, 44%, and 46%
respectively.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15405" title="Abstract">arXiv:2312.15405</a> [<a href="/pdf/2312.15405" title="Download PDF">pdf</a>, <a href="/format/2312.15405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Computation Pushdown for Cloud OLAP Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiangyao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Serafini%2C+M">Marco Serafini</a>, 
<a href="/search/cs?searchtype=author&query=Aboulnaga%2C+A">Ashraf Aboulnaga</a>, 
<a href="/search/cs?searchtype=author&query=Stonebraker%2C+M">Michael Stonebraker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Network is a major bottleneck in modern cloud databases that adopt a
storage-disaggregation architecture. Computation pushdown is a promising
solution to tackle this issue, which offloads some computation tasks to the
storage layer to reduce network traffic. Existing cloud OLAP systems statically
decide whether to push down computation during the query optimization phase and
do not consider the storage layer's computational capacity and load. Besides,
there is a lack of a general principle that determines which operators are
amenable for pushdown. Existing systems design and implement pushdown features
empirically, which ends up picking a limited set of pushdown operators
respectively.
<br />In this paper, we first design Adaptive pushdown as a new mechanism to avoid
throttling the storage-layer computation during pushdown, which pushes the
request back to the computation layer at runtime if the storage-layer
computational resource is insufficient. Moreover, we derive a general principle
to identify pushdown-amenable computational tasks, by summarizing common
patterns of pushdown capabilities in existing systems. We propose two new
pushdown operators, namely, selection bitmap and distributed data shuffle.
Evaluation results on TPC-H show that Adaptive pushdown can achieve up to 1.9x
speedup over both No pushdown and Eager pushdown baselines, and the new
pushdown operators can further accelerate query execution by up to 3.0x.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15406" title="Abstract">arXiv:2312.15406</a> [<a href="/pdf/2312.15406" title="Download PDF">pdf</a>, <a href="/format/2312.15406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A theory of volumetric representations for opaque solids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miller%2C+B">Bailey Miller</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+A">Alice Lai</a>, 
<a href="/search/cs?searchtype=author&query=Gkioulekas%2C+I">Ioannis Gkioulekas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://imaging.cs.cmu.edu/volumetric_opaque_solids">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We develop a theory for the representation of opaque solids as volumetric
models. Starting from a stochastic representation of opaque solids as random
indicator functions, we prove the conditions under which such solids can be
modeled using exponential volumetric transport. We also derive expressions for
the volumetric attenuation coefficient as a functional of the probability
distributions of the underlying indicator functions. We generalize our theory
to account for isotropic and anisotropic scattering at different parts of the
solid, and for representations of opaque solids as implicit surfaces. We derive
our volumetric representation from first principles, which ensures that it
satisfies physical constraints such as reciprocity and reversibility. We use
our theory to explain, compare, and correct previous volumetric
representations, as well as propose meaningful extensions that lead to improved
performance in 3D reconstruction tasks.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15407" title="Abstract">arXiv:2312.15407</a> [<a href="/pdf/2312.15407" title="Download PDF">pdf</a>, <a href="/format/2312.15407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Analysis of the Effectiveness of Large Language Models  as Automatic Dialogue Evaluators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=D%27Haro%2C+L+F">Luis Fernando D&#x27;Haro</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Malu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-2024, appendix included, 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic evaluation is an integral aspect of dialogue system research. The
traditional reference-based NLG metrics are generally found to be unsuitable
for dialogue assessment. Consequently, recent studies have suggested various
unique, reference-free neural metrics that better align with human evaluations.
Notably among them, large language models (LLMs), particularly the
instruction-tuned variants like ChatGPT, are shown to be promising substitutes
for human judges. Yet, existing works on utilizing LLMs for automatic dialogue
evaluation are limited in their scope in terms of the number of meta-evaluation
datasets, mode of evaluation, coverage of LLMs, etc. Hence, it remains
inconclusive how effective these LLMs are. To this end, we conduct a
comprehensive study on the application of LLMs for automatic dialogue
evaluation. Specifically, we analyze the multi-dimensional evaluation
capability of 30 recently emerged LLMs at both turn and dialogue levels, using
a comprehensive set of 12 meta-evaluation datasets. Additionally, we probe the
robustness of the LLMs in handling various adversarial perturbations at both
turn and dialogue levels. Finally, we explore how model-level and
dimension-level ensembles impact the evaluation performance. All resources are
available at https://github.com/e0397123/comp-analysis.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15412" title="Abstract">arXiv:2312.15412</a> [<a href="/pdf/2312.15412" title="Download PDF">pdf</a>, <a href="/format/2312.15412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARSS: Cooperative Attention-guided Reinforcement Subpath Synthesis for  Solving Traveling Salesman Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuchen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Congying Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tiande Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper introduces CARSS (Cooperative Attention-guided Reinforcement
Subpath Synthesis), a novel approach to address the Traveling Salesman Problem
(TSP) by leveraging cooperative Multi-Agent Reinforcement Learning (MARL).
CARSS decomposes the TSP solving process into two distinct yet synergistic
steps: "subpath generation" and "subpath merging." In the former, a cooperative
MARL framework is employed to iteratively generate subpaths using multiple
agents. In the latter, these subpaths are progressively merged to form a
complete cycle. The algorithm's primary objective is to enhance efficiency in
terms of training memory consumption, testing time, and scalability, through
the adoption of a multi-agent divide and conquer paradigm. Notably, attention
mechanisms play a pivotal role in feature embedding and parameterization
strategies within CARSS. The training of the model is facilitated by the
independent REINFORCE algorithm. Empirical experiments reveal CARSS's
superiority compared to single-agent alternatives: it demonstrates reduced GPU
memory utilization, accommodates training graphs nearly 2.5 times larger, and
exhibits the potential for scaling to even more extensive problem sizes.
Furthermore, CARSS substantially reduces testing time and optimization gaps by
approximately 50% for TSP instances of up to 1000 vertices, when compared to
standard decoding methods.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15416" title="Abstract">arXiv:2312.15416</a> [<a href="/pdf/2312.15416" title="Download PDF">pdf</a>, <a href="/format/2312.15416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing SDP-Based Barrier Certificate Synthesis to Unbounded  Domains by Dropping Archimedean Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+S">Shenghua Feng</a>, 
<a href="/search/eess?searchtype=author&query=Gan%2C+T">Ting Gan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+B">Bican Xia</a>, 
<a href="/search/eess?searchtype=author&query=Zhan%2C+N">Naijun Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Barrier certificates, which serve as differential invariants that witness
system safety, play a crucial role in the verification of cyber-physical
systems (CPS). Prevailing computational methods for synthesizing barrier
certificates are based on semidefinite programming (SDP) by exploiting Putinar
Positivstellensatz. Consequently, these approaches are limited by Archimedean
condition, which requires all variables to be bounded, i.e., systems are
defined over bounded domains. For the unbounded case, unfortunately, these
methods become conservative and even fail to identify potential barrier
certificates.
<br />In this paper, we address this limitation by presenting a new computational
method. The main technique we use is the homogenization approach, which was
proposed in optimization community recently, to transform an unbounded
optimization problem to a bounded one. Our method can be applied to various
definitions of barrier certificates, thus expanding the scope of barrier
certificate synthesis in the general sense. Experimental results demonstrate
that our approach is more effective while maintaining a comparable level of
efficiency.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15420" title="Abstract">arXiv:2312.15420</a> [<a href="/pdf/2312.15420" title="Download PDF">pdf</a>, <a href="/format/2312.15420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDMF: Privacy-Preserving User Attribute Prediction using Deep Matrix  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheung%2C+M">Ming Cheung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">User attribute prediction is a crucial task in various industries. However,
sharing user data across different organizations faces challenges due to
privacy concerns and legal requirements regarding personally identifiable
information. Regulations such as the General Data Protection Regulation (GDPR)
in the European Union and the Personal Information Protection Law of the
People's Republic of China impose restrictions on data sharing. To address the
need for utilizing features from multiple clients while adhering to legal
requirements, federated learning algorithms have been proposed. These
algorithms aim to predict user attributes without directly sharing the data.
However, existing approaches typically rely on matching users across companies,
which can result in dishonest partners discovering user lists or the inability
to utilize all available features. In this paper, we propose a novel algorithm
for predicting user attributes without requiring user matching. Our approach
involves training deep matrix factorization models on different clients and
sharing only the item vectors. This allows us to predict user attributes
without sharing the user vectors themselves. The algorithm is evaluated using
the publicly available MovieLens dataset and demonstrate that it achieves
similar performance to the FedAvg algorithm, reaching 96% of a single model's
accuracy. The proposed algorithm is particularly well-suited for improving
customer targeting and enhancing the overall customer experience. This paper
presents a valuable contribution to the field of user attribute prediction by
offering a novel algorithm that addresses some of the most pressing privacy
concerns in this area.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15424" title="Abstract">arXiv:2312.15424</a> [<a href="/pdf/2312.15424" title="Download PDF">pdf</a>, <a href="/format/2312.15424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Renewable Energy Sources as Reserve Providers: Modeling,  Pricing, and Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+W">Wenli Wu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Ye Guo</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Jiantao Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In pursuit of carbon neutrality, many countries have adopted renewable
portfolio standards to facilitate the integration of renewable energy. However,
increasing penetration of renewable energy resources will also pose higher
requirements on system flexibility. Allowing renewable themselves to
participate in the reserve market could be a viable solution. To this end, this
paper proposes an optimal dispatch model for joint energy-reserve procurement
that incorporates renewable portfolio standards and RES serve as reserve
providers. Potential generator outages and deviations in renewable and load
power are modelled through a given number of probability-weighted scenarios. In
particular, reserve resources are initially booked in the base case and then
activated in non-base scenarios through the re-dispatch process. Marginal
pricing is used to derive energy, reserve, and power deviation prices. Next, we
develop the associated settlement process and establish several market
properties. The proposed pricing scheme establishes equivalence between thermal
generators and renewable units by accounting for their uncertainties, including
thermal generator outages and renewable power deviations, and their
flexibility, namely reserve and re-dispatch. We have shown that for renewable
resources, supplying reserve according to the dispatch results compared to
generating as much as possible leads to better profits. Simulations validate
the effectiveness of the proposed method and properties established.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15425" title="Abstract">arXiv:2312.15425</a> [<a href="/pdf/2312.15425" title="Download PDF">pdf</a>, <a href="/format/2312.15425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Guided Semi-Supervised Learning for Quality Assessment of User  Generated Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Shankhanil Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Soundararajan%2C+R">Rajiv Soundararajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 38th AAAI conference on AI (AAAI 24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Perceptual quality assessment of user generated content (UGC) videos is
challenging due to the requirement of large scale human annotated videos for
training. In this work, we address this challenge by first designing a
self-supervised Spatio-Temporal Visual Quality Representation Learning
(ST-VQRL) framework to generate robust quality aware features for videos. Then,
we propose a dual-model based Semi Supervised Learning (SSL) method
specifically designed for the Video Quality Assessment (SSL-VQA) task, through
a novel knowledge transfer of quality predictions between the two models. Our
SSL-VQA method uses the ST-VQRL backbone to produce robust performances across
various VQA datasets including cross-database settings, despite being learned
with limited human annotated videos. Our model improves the state-of-the-art
performance when trained only with limited data by around 10%, and by around
15% when unlabelled data is also used in SSL. Source codes and checkpoints are
available at https://github.com/Shankhanil006/SSL-VQA.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15426" title="Abstract">arXiv:2312.15426</a> [<a href="/pdf/2312.15426" title="Download PDF">pdf</a>, <a href="/format/2312.15426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Group Access Bounds for Binary Search Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chalermsook%2C+P">Parinya Chalermsook</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Manoj Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jiamjitrak%2C+W">Wanchote Jiamjitrak</a>, 
<a href="/search/cs?searchtype=author&query=Pareek%2C+A">Akash Pareek</a>, 
<a href="/search/cs?searchtype=author&query=Yingchareonthawornchai%2C+S">Sorrachai Yingchareonthawornchai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The access lemma (Sleator and Tarjan, JACM 1985) is a property of binary
search trees that implies interesting consequences such as static optimality,
static finger, and working set property. However, there are known corollaries
of the dynamic optimality that cannot be derived via the access lemma, such as
the dynamic finger, and any $o(\log n)$-competitive ratio to the optimal BST
where $n$ is the number of keys.
<br />In this paper, we introduce the group access bound that can be defined with
respect to a reference group access tree. Group access bounds generalize the
access lemma and imply properties that are far stronger than those implied by
the access lemma. For each of the following results, there is a group access
tree whose group access bound
<br />Is $O(\sqrt{\log n})$-competitive to the optimal BST.
<br />Achieves the $k$-finger bound with an additive term of $O(m \log k \log \log
n)$ (randomized) when the reference tree is an almost complete binary tree.
<br />Satisfies the unified bound with an additive term of $O(m \log \log n)$.
<br />Matches the unified bound with a time window $k$ with an additive term of
$O(m \log k \log \log n)$ (randomized).
<br />Furthermore, we prove simulation theorem: For every group access tree, there
is an online BST algorithm that is $O(1)$-competitive with its group access
bound. In particular, any new group access bound will automatically imply a new
BST algorithm achieving the same bound. Thereby, we obtain an improved
$k$-finger bound (reference tree is an almost complete binary tree), an
improved unified bound with a time window $k$, and matching the best-known
bound for Unified bound in the BST model. Since any dynamically optimal BST
must achieve the group access bounds, we believe our results provide a new
direction towards proving $o(\log n)$-competitiveness of Splay tree and Greedy.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15427" title="Abstract">arXiv:2312.15427</a> [<a href="/pdf/2312.15427" title="Download PDF">pdf</a>, <a href="/format/2312.15427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Bandit Learning for Monotone Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Arpit Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ghuge%2C+R">Rohan Ghuge</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+V">Viswanath Nagarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Stochastic optimization is a widely used approach for optimization under
uncertainty, where uncertain input parameters are modeled by random variables.
Exact or approximation algorithms have been obtained for several fundamental
problems in this area. However, a significant limitation of this approach is
that it requires full knowledge of the underlying probability distributions.
Can we still get good (approximation) algorithms if these distributions are
unknown, and the algorithm needs to learn them through repeated interactions?
In this paper, we resolve this question for a large class of "monotone"
stochastic problems, by providing a generic online learning algorithm with
$\sqrt{T \log T}$ regret relative to the best approximation algorithm (under
known distributions). Importantly, our online algorithm works in a semi-bandit
setting, where in each period, the algorithm only observes samples from the
r.v.s that were actually probed. Our framework applies to several fundamental
problems in stochastic optimization such as prophet inequality, Pandora's box,
stochastic knapsack, stochastic matchings and stochastic submodular
optimization.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15429" title="Abstract">arXiv:2312.15429</a> [<a href="/pdf/2312.15429" title="Download PDF">pdf</a>, <a href="/format/2312.15429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-RIS Communication Systems: Asymptotic analysis of best RIS  selection for i.n.i.d. Random Variables using Extreme Value Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagar%2C+S">Srinivas Sagar</a>, 
<a href="/search/cs?searchtype=author&query=Kalyani%2C+S">Sheetal Kalyani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates the performance of multiple reconfigurable
intelligent surfaces (multi-RIS) communication systems where the RIS link with
the highest signal-to-noise-ratio (SNR) is selected at the destination. In
practice, all the RISs will not have the same number of reflecting elements.
Hence, selecting the RIS link with the highest SNR will involve characterizing
the distribution of the maximum of independent, non-identically distributed
(i.n.i.d.) SNR random variables (RVs). Using extreme value theory (EVT), we
derive the asymptotic distribution of the normalized maximum of i.n.i.d.
non-central chi-square (NCCS) distributed SNR RVs with one degree of freedom
(d.o.f) and then extend the results for k-th order statistics. Using these
asymptotic results, the outage capacity and average throughput expressions are
derived for the multi-RIS system. The results for independent and identically
distributed (i.i.d.) SNR RVs are then derived as a special case of i.n.i.d.
RVs. All the derivations are validated through extensive Monte Carlo
simulations, and their utility is discussed.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15430" title="Abstract">arXiv:2312.15430</a> [<a href="/pdf/2312.15430" title="Download PDF">pdf</a>, <a href="/format/2312.15430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make-A-Character: High Quality Text-to-3D Character Generation within  Minutes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jianqiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chao He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yutong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yafei Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianfang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tangli Xue</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siqi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kunkun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jianjing Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">There is a growing demand for customized and expressive 3D characters with
the emergence of AI agents and Metaverse, but creating 3D characters using
traditional computer graphics tools is a complex and time-consuming task. To
address these challenges, we propose a user-friendly framework named
Make-A-Character (Mach) to create lifelike 3D avatars from text descriptions.
The framework leverages the power of large language and vision models for
textual intention understanding and intermediate image generation, followed by
a series of human-oriented visual perception and 3D generation modules. Our
system offers an intuitive approach for users to craft controllable, realistic,
fully-realized 3D characters that meet their expectations within 2 minutes,
while also enabling easy integration with existing CG pipeline for dynamic
expressiveness. For more information, please visit the project page at
https://human3daigc.github.io/MACH/.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15432" title="Abstract">arXiv:2312.15432</a> [<a href="/pdf/2312.15432" title="Download PDF">pdf</a>, <a href="/ps/2312.15432" title="Download PostScript">ps</a>, <a href="/format/2312.15432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Guarantees for Power Scheduling Problems With  Sum-of-Squares Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Trung Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Elbassioni%2C+K">Khaled Elbassioni</a>, 
<a href="/search/cs?searchtype=author&query=Karapetyan%2C+A">Areg Karapetyan</a>, 
<a href="/search/cs?searchtype=author&query=Khonji%2C+M">Majid Khonji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study a class of combinatorial scheduling problems characterized by a
particular type of constraint often associated with electrical power or gas
energy. This constraint appears in several practical applications and is
expressed as a sum of squares of linear functions. Its nonlinear nature adds
complexity to the scheduling problem, rendering it notably challenging, even in
the case of a linear objective. In fact, exact polynomial time algorithms are
unlikely to exist, and thus, prior works have focused on designing
approximation algorithms with polynomial running time and provable guarantees
on the solution quality. In an effort to advance this line of research, we
present novel approximation algorithms yielding significant improvements over
the existing state-of-the-art results for these problems.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15433" title="Abstract">arXiv:2312.15433</a> [<a href="/pdf/2312.15433" title="Download PDF">pdf</a>, <a href="/ps/2312.15433" title="Download PostScript">ps</a>, <a href="/format/2312.15433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best-of-Both-Worlds Algorithms for Linear Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuroki%2C+Y">Yuko Kuroki</a>, 
<a href="/search/cs?searchtype=author&query=Rumi%2C+A">Alberto Rumi</a>, 
<a href="/search/cs?searchtype=author&query=Tsuchiya%2C+T">Taira Tsuchiya</a>, 
<a href="/search/cs?searchtype=author&query=Vitale%2C+F">Fabio Vitale</a>, 
<a href="/search/cs?searchtype=author&query=Cesa-Bianchi%2C+N">Nicol&#xf2; Cesa-Bianchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study best-of-both-worlds algorithms for $K$-armed linear contextual
bandits. Our algorithms deliver near-optimal regret bounds in both the
adversarial and stochastic regimes, without prior knowledge about the
environment. In the stochastic regime, we achieve the polylogarithmic rate
$\frac{(dK)^2\mathrm{poly}\log(dKT)}{\Delta_{\min}}$, where $\Delta_{\min}$ is
the minimum suboptimality gap over the $d$-dimensional context space. In the
adversarial regime, we obtain either the first-order
$\widetilde{O}(dK\sqrt{L^*})$ bound, or the second-order
$\widetilde{O}(dK\sqrt{\Lambda^*})$ bound, where $L^*$ is the cumulative loss
of the best action and $\Lambda^*$ is a notion of the cumulative second moment
for the losses incurred by the algorithm. Moreover, we develop an algorithm
based on FTRL with Shannon entropy regularizer that does not require the
knowledge of the inverse of the covariance matrix, and achieves a
polylogarithmic regret in the stochastic regime while obtaining
$\widetilde{O}\big(dK\sqrt{T}\big)$ regret bounds in the adversarial regime.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15444" title="Abstract">arXiv:2312.15444</a> [<a href="/pdf/2312.15444" title="Download PDF">pdf</a>, <a href="/format/2312.15444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variation-Resilient FeFET-Based In-Memory Computing Leveraging  Probabilistic Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manna%2C+B">Bibhas Manna</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Arnob Saha</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhouhang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+K">Kai Ni</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Abhronil Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Reliability issues stemming from device level non-idealities of non-volatile
emerging technologies like ferroelectric field-effect transistors (FeFET),
especially at scaled dimensions, cause substantial degradation in the accuracy
of In-Memory crossbar-based AI systems. In this work, we present a
variation-aware design technique to characterize the device level variations
and to mitigate their impact on hardware accuracy employing a Bayesian Neural
Network (BNN) approach. An effective conductance variation model is derived
from the experimental measurements of cycle-to-cycle (C2C) and device-to-device
(D2D) variations performed on FeFET devices fabricated using 28 nm high-$k$
metal gate technology. The variations were found to be a function of different
conductance states within the given programming range, which sharply contrasts
earlier efforts where a fixed variation dispersion was considered for all
conductance values. Such variation characteristics formulated for three
different device sizes at different read voltages were provided as prior
variation information to the BNN to yield a more exact and reliable inference.
Near-ideal accuracy for shallow networks (MLP5 and LeNet models) on the MNIST
dataset and limited accuracy decline by $\sim$3.8-16.1% for deeper AlexNet
models on CIFAR10 dataset under a wide range of variations corresponding to
different device sizes and read voltages, demonstrates the efficacy of our
proposed device-algorithm co-design technique.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15447" title="Abstract">arXiv:2312.15447</a> [<a href="/pdf/2312.15447" title="Download PDF">pdf</a>, <a href="/format/2312.15447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superpixel-based and Spatially-regularized Diffusion Learning for  Unsupervised Hyperspectral Image Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kangning Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruoning Li</a>, 
<a href="/search/cs?searchtype=author&query=Polk%2C+S+L">Sam L. Polk</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yinyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+J+M">James M. Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Plemmons%2C+R+J">Robert J. Plemmons</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R+H">Raymond H. Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 9 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Hyperspectral images (HSIs) provide exceptional spatial and spectral
resolution of a scene, crucial for various remote sensing applications.
However, the high dimensionality, presence of noise and outliers, and the need
for precise labels of HSIs present significant challenges to HSIs analysis,
motivating the development of performant HSI clustering algorithms. This paper
introduces a novel unsupervised HSI clustering algorithm, Superpixel-based and
Spatially-regularized Diffusion Learning (S2DL), which addresses these
challenges by incorporating rich spatial information encoded in HSIs into
diffusion geometry-based clustering. S2DL employs the Entropy Rate Superpixel
(ERS) segmentation technique to partition an image into superpixels, then
constructs a spatially-regularized diffusion graph using the most
representative high-density pixels. This approach reduces computational burden
while preserving accuracy. Cluster modes, serving as exemplars for underlying
cluster structure, are identified as the highest-density pixels farthest in
diffusion distance from other highest-density pixels. These modes guide the
labeling of the remaining representative pixels from ERS superpixels. Finally,
majority voting is applied to the labels assigned within each superpixel to
propagate labels to the rest of the image. This spatial-spectral approach
simultaneously simplifies graph construction, reduces computational cost, and
improves clustering performance. S2DL's performance is illustrated with
extensive experiments on three publicly available, real-world HSIs: Indian
Pines, Salinas, and Salinas A. Additionally, we apply S2DL to landscape-scale,
unsupervised mangrove species mapping in the Mai Po Nature Reserve, Hong Kong,
using a Gaofen-5 HSI. The success of S2DL in these diverse numerical
experiments indicates its efficacy on a wide range of important unsupervised
remote sensing analysis tasks.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15449" title="Abstract">arXiv:2312.15449</a> [<a href="/pdf/2312.15449" title="Download PDF">pdf</a>, <a href="/format/2312.15449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iDet3D: Towards Efficient Interactive Object Detection for LiDAR Point  Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dongmin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+W">Wonwoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kangyeol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurately annotating multiple 3D objects in LiDAR scenes is laborious and
challenging. While a few previous studies have attempted to leverage
semi-automatic methods for cost-effective bounding box annotation, such methods
have limitations in efficiently handling numerous multi-class objects. To
effectively accelerate 3D annotation pipelines, we propose iDet3D, an efficient
interactive 3D object detector. Supporting a user-friendly 2D interface, which
can ease the cognitive burden of exploring 3D space to provide click
interactions, iDet3D enables users to annotate the entire objects in each scene
with minimal interactions. Taking the sparse nature of 3D point clouds into
account, we design a negative click simulation (NCS) to improve accuracy by
reducing false-positive predictions. In addition, iDet3D incorporates two click
propagation techniques to take full advantage of user interactions: (1) dense
click guidance (DCG) for keeping user-provided information throughout the
network and (2) spatial click propagation (SCP) for detecting other instances
of the same class based on the user-specified objects. Through our extensive
experiments, we present that our method can construct precise annotations in a
few clicks, which shows the practicality as an efficient annotation tool for 3D
object detection.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15450" title="Abstract">arXiv:2312.15450</a> [<a href="/pdf/2312.15450" title="Download PDF">pdf</a>, <a href="/format/2312.15450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting  Using Multi-agent LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lixin Su</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Pengyue Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Suqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Search engines are crucial as they provide an efficient and easy way to
access vast amounts of information on the internet for diverse information
needs. User queries, even with a specific need, can differ significantly. Prior
research has explored the resilience of ranking models against typical query
variations like paraphrasing, misspellings, and order changes. Yet, these works
overlook how diverse demographics uniquely formulate identical queries. For
instance, older individuals tend to construct queries more naturally and in
varied order compared to other groups. This demographic diversity necessitates
enhancing the adaptability of ranking models to diverse query formulations. To
this end, in this paper, we propose a framework that integrates a novel
rewriting pipeline that rewrites queries from various demographic perspectives
and a novel framework to enhance ranking robustness. To be specific, we use
Chain of Thought (CoT) technology to utilize Large Language Models (LLMs) as
agents to emulate various demographic profiles, then use them for efficient
query rewriting, and we innovate a robust Multi-gate Mixture of Experts (MMoE)
architecture coupled with a hybrid loss function, collectively strengthening
the ranking models' robustness. Our extensive experimentation on both public
and industrial datasets assesses the efficacy of our query rewriting approach
and the enhanced accuracy and robustness of the ranking model. The findings
highlight the sophistication and effectiveness of our proposed model.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15454" title="Abstract">arXiv:2312.15454</a> [<a href="/pdf/2312.15454" title="Download PDF">pdf</a>, <a href="/format/2312.15454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Aware and Energy-Efficient AoI Optimization for Multi-Connectivity  WNCS with Short Packet Transmissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sumei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kurniawan%2C+E">Ernest Kurniawan</a>, 
<a href="/search/cs?searchtype=author&query=Amnart%2C+B">Boonkajay Amnart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Age of Information (AoI) has been proposed to quantify the freshness of
information for emerging real-time applications such as remote monitoring and
control in wireless networked control systems (WNCSs). Minimization of the
average AoI and its outage probability can ensure timely and stable
transmission. Energy efficiency (EE) also plays an important role in WNCSs, as
many devices are featured by low cost and limited battery. Multi-connectivity
over multiple links enables a decrease in AoI, at the cost of energy. We tackle
the unresolved problem of selecting the optimal number of connections that is
both AoI-optimal and energy-efficient, while avoiding risky states. To address
this issue, the average AoI and peak AoI (PAoI), as well as PAoI violation
probability are formulated as functions of the number of connections. Then the
EE-PAoI ratio is introduced to allow a tradeoff between AoI and energy, which
is maximized by the proposed risk-aware, AoI-optimal and energy-efficient
connectivity scheme. To obtain this, we analyze the property of the formulated
EE-PAoI ratio and prove the monotonicity of PAoI violation probability.
Interestingly, we reveal that the multi-connectivity scheme is not always
preferable, and the signal-to-noise ratio (SNR) threshold that determines the
selection of the multi-connectivity scheme is derived as a function of the
coding rate. Also, the optimal number of connections is obtained and shown to
be a decreasing function of the transmit power. Simulation results demonstrate
that the proposed scheme enables more than 15 folds of EE-PAoI gain at the low
SNR than the single-connectivity scheme.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15459" title="Abstract">arXiv:2312.15459</a> [<a href="/pdf/2312.15459" title="Download PDF">pdf</a>, <a href="/format/2312.15459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented mixed finite element methods for elliptic equations with  discontinuous coefficients: Robust A Priori and A Posteriori Error Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liang%2C+Y">Yuxiang Liang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, for the generalized Darcy problem (an elliptic equation with
discontinuous coefficients), we study a special Galerkin-Least-Squares method,
known as the augmented mixed finite element method, and its relationship to the
standard least-squares finite element method (LSFEM). Two versions of augmented
mixed finite element methods are proposed in the paper with robust a priori and
a posteriori error estimates. As partial least-squares methods, the augmented
mixed finite element methods are more flexible than the original least-squares
finite element methods. The a posteriori error estimators of the augmented
mixed finite element methods are the evaluations of the numerical solutions at
the corresponding least-squares functionals. As comparisons, we discuss the
non-robustness of the closely related least-squares finite element methods.
Numerical experiments are presented to verify our findings.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15460" title="Abstract">arXiv:2312.15460</a> [<a href="/pdf/2312.15460" title="Download PDF">pdf</a>, <a href="/format/2312.15460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Robin-type non-singular coupling scheme for solving the wave  scattering problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xiaojuan Liu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+M">Maojun Li</a>, 
<a href="/search/math?searchtype=author&query=Yin%2C+T">Tao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper studies a non-singular coupling scheme for solving the acoustic
and elastic wave scattering problems and its extension to the problems of
Laplace and Lam\'e equations and the problem with a compactly supported
inhomogeneity is also briefly discussed. Relying on the solution representation
of the wave scattering problem, a Robin-type artificial boundary condition in
terms of layer potentials whose kernels are non-singular, is introduced to
obtain a reduced problem on a bounded domain. The wellposedness of the reduced
problems and the a priori error estimates of the corresponding finite element
discretization are proved. Numerical examples are presented to demonstrate the
accuracy and efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15471" title="Abstract">arXiv:2312.15471</a> [<a href="/pdf/2312.15471" title="Download PDF">pdf</a>, <a href="/format/2312.15471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Learning for Image Point Descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+R">Rashik Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Kanakis%2C+M">Menelaos Kanakis</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Local image feature descriptors have had a tremendous impact on the
development and application of computer vision methods. It is therefore
unsurprising that significant efforts are being made for learning-based image
point descriptors. However, the advantage of learned methods over handcrafted
methods in real applications is subtle and more nuanced than expected.
Moreover, handcrafted descriptors such as SIFT and SURF still perform better
point localization in Structure-from-Motion (SfM) compared to many learned
counterparts. In this paper, we propose a very simple and effective approach to
learning local image descriptors by using a hand-crafted detector and
descriptor. Specifically, we choose to learn only the descriptors, supported by
handcrafted descriptors while discarding the point localization head. We
optimize the final descriptor by leveraging the knowledge already present in
the handcrafted descriptor. Such an approach of optimization allows us to
discard learning knowledge already present in non-differentiable functions such
as the hand-crafted descriptors and only learn the residual knowledge in the
main network branch. This offers 50X convergence speed compared to the standard
baseline architecture of SuperPoint while at inference the combined descriptor
provides superior performance over the learned and hand-crafted descriptors.
This is done with minor increase in the computations over the baseline learned
descriptor. Our approach has potential applications in ensemble learning and
learning with non-differentiable functions. We perform experiments in matching,
camera localization and Structure-from-Motion in order to showcase the
advantages of our approach.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15472" title="Abstract">arXiv:2312.15472</a> [<a href="/pdf/2312.15472" title="Download PDF">pdf</a>, <a href="/ps/2312.15472" title="Download PostScript">ps</a>, <a href="/format/2312.15472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Consistent Language Models Using Declarative Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+J">Jasmin Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Termehchy%2C+A">Arash Termehchy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models have shown unprecedented abilities in generating
linguistically coherent and syntactically correct natural language output.
However, they often return incorrect and inconsistent answers to input
questions. Due to the complexity and uninterpretability of the internally
learned representations, it is challenging to modify language models such that
they provide correct and consistent results. The data management community has
developed various methods and tools for providing consistent answers over
inconsistent datasets. In these methods, users specify the desired properties
of data in a domain in the form of high-level declarative constraints. This
approach has provided usable and scalable methods to delivering consistent
information from inconsistent datasets. We aim to build upon this success and
leverage these methods to modify language models such that they deliver
consistent and accurate results. We investigate the challenges of using these
ideas to obtain consistent and relevant answers from language models and report
some preliminary empirical studies.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15474" title="Abstract">arXiv:2312.15474</a> [<a href="/pdf/2312.15474" title="Download PDF">pdf</a>, <a href="/format/2312.15474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trust Region Approach for Few-Shot Sim-to-Real Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daoudi%2C+P">Paul Daoudi</a>, 
<a href="/search/cs?searchtype=author&query=Prieur%2C+C">Christophe Prieur</a>, 
<a href="/search/cs?searchtype=author&query=Robu%2C+B">Bogdan Robu</a>, 
<a href="/search/cs?searchtype=author&query=Barlier%2C+M">Merwan Barlier</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+L+D">Ludovic Dos Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Simulation-to-Reality Reinforcement Learning (Sim-to-Real RL) seeks to use
simulations to minimize the need for extensive real-world interactions.
Specifically, in the few-shot off-dynamics setting, the goal is to acquire a
simulator-based policy despite a dynamics mismatch that can be effectively
transferred to the real-world using only a handful of real-world transitions.
In this context, conventional RL agents tend to exploit simulation inaccuracies
resulting in policies that excel in the simulator but underperform in the real
environment. To address this challenge, we introduce a novel approach that
incorporates a penalty to constrain the trajectories induced by the
simulator-trained policy inspired by recent advances in Imitation Learning and
Trust Region based RL algorithms. We evaluate our method across various
environments representing diverse Sim-to-Real conditions, where access to the
real environment is extremely limited. These experiments include
high-dimensional systems relevant to real-world applications. Across most
tested scenarios, our proposed method demonstrates performance improvements
compared to existing baselines.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15475" title="Abstract">arXiv:2312.15475</a> [<a href="/pdf/2312.15475" title="Download PDF">pdf</a>, <a href="/format/2312.15475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Code Summarization Techniques: A New Metric and an Empirical  Characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mastropaolo%2C+A">Antonio Mastropaolo</a>, 
<a href="/search/cs?searchtype=author&query=Ciniselli%2C+M">Matteo Ciniselli</a>, 
<a href="/search/cs?searchtype=author&query=Di+Penta%2C+M">Massimiliano Di Penta</a>, 
<a href="/search/cs?searchtype=author&query=Bavota%2C+G">Gabriele Bavota</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Several code summarization techniques have been proposed in the literature to
automatically document a code snippet or a function. Ideally, software
developers should be involved in assessing the quality of the generated
summaries. However, in most cases, researchers rely on automatic evaluation
metrics such as BLEU, ROUGE, and METEOR. These metrics are all based on the
same assumption: The higher the textual similarity between the generated
summary and a reference summary written by developers, the higher its quality.
However, there are two reasons for which this assumption falls short: (i)
reference summaries, e.g., code comments collected by mining software
repositories, may be of low quality or even outdated; (ii) generated summaries,
while using a different wording than a reference one, could be semantically
equivalent to it, thus still being suitable to document the code snippet. In
this paper, we perform a thorough empirical investigation on the
complementarity of different types of metrics in capturing the quality of a
generated summary. Also, we propose to address the limitations of existing
metrics by considering a new dimension, capturing the extent to which the
generated summary aligns with the semantics of the documented code snippet,
independently from the reference summary. To this end, we present a new metric
based on contrastive learning to capture said aspect. We empirically show that
the inclusion of this novel dimension enables a more effective representation
of developers' evaluations regarding the quality of automatically generated
summaries.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15478" title="Abstract">arXiv:2312.15478</a> [<a href="/pdf/2312.15478" title="Download PDF">pdf</a>, <a href="/format/2312.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Group Fairness Lens for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+G">Guanqun Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuqiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tiangang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaodong He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The rapid advancement of large language models has revolutionized various
applications but also raised crucial concerns about their potential to
perpetuate biases and unfairness when deployed in social media contexts.
Evaluating LLMs' potential biases and fairness has become crucial, as existing
methods rely on limited prompts focusing on just a few groups, lacking a
comprehensive categorical perspective. In this paper, we propose evaluating LLM
biases from a group fairness lens using a novel hierarchical schema
characterizing diverse social groups. Specifically, we construct a dataset,
GFair, encapsulating target-attribute combinations across multiple dimensions.
In addition, we introduce statement organization, a new open-ended text
generation task, to uncover complex biases in LLMs. Extensive evaluations of
popular LLMs reveal inherent safety concerns. To mitigate the biases of LLM
from a group fairness perspective, we pioneer a novel chain-of-thought method
GF-Think to mitigate biases of LLMs from a group fairness perspective.
Experimental results demonstrate its efficacy in mitigating bias in LLMs to
achieve fairness.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15479" title="Abstract">arXiv:2312.15479</a> [<a href="/pdf/2312.15479" title="Download PDF">pdf</a>, <a href="/ps/2312.15479" title="Download PostScript">ps</a>, <a href="/format/2312.15479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Proportional Allocations of Indivisible Goods and Chores:  Insights via Matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nimbhorkar%2C+P">Prajakta Nimbhorkar</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+V+P+H">Vishwa Prakash H.V</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the fair allocation of indivisible goods and chores under ordinal
valuations for agents with unequal entitlements. We show the existence and
polynomial time computation of weighted necessarily proportional up to one item
(WSD-PROP1) allocations for both goods and chores, by reducing it to a problem
of finding perfect matchings in a bipartite graph. We give a complete
characterization of these allocations as corner points of a perfect matching
polytope. Using this polytope, we can optimize over all allocations to find a
min-cost WSD-PROP1 allocation of goods or most efficient WSD-PROP1 allocation
of chores. Additionally, we show the existence and computation of sequencible
(SEQ) WSD-PROP1 allocations by using rank-maximal perfect matching algorithms
and show incompatibility of Pareto optimality under all valuations and
WSD-PROP1.
<br />We also consider the Best-of-Both-Worlds (BoBW) fairness notion. By using our
characterization, we show the existence and polynomial time computation of
Ex-ante envy free (WSD-EF) and Ex-post WSD-PROP1 allocations under ordinal
valuations for both chores and goods.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15480" title="Abstract">arXiv:2312.15480</a> [<a href="/pdf/2312.15480" title="Download PDF">pdf</a>, <a href="/format/2312.15480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-stage Personalized Virtual Try-on Framework with Shape Control and  Texture Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shufang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+M">Minxue Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenxin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Diffusion model has a strong ability to generate wild images. However,
the model can just generate inaccurate images with the guidance of text, which
makes it very challenging to directly apply the text-guided generative model
for virtual try-on scenarios. Taking images as guiding conditions of the
diffusion model, this paper proposes a brand new personalized virtual try-on
model (PE-VITON), which uses the two stages (shape control and texture
guidance) to decouple the clothing attributes. Specifically, the proposed model
adaptively matches the clothing to human body parts through the Shape Control
Module (SCM) to mitigate the misalignment of the clothing and the human body
parts. The semantic information of the input clothing is parsed by the Texture
Guided Module (TGM), and the corresponding texture is generated by directional
guidance. Therefore, this model can effectively solve the problems of weak
reduction of clothing folds, poor generation effect under complex human
posture, blurred edges of clothing, and unclear texture styles in traditional
try-on methods. Meanwhile, the model can automatically enhance the generated
clothing folds and textures according to the human posture, and improve the
authenticity of virtual try-on. In this paper, qualitative and quantitative
experiments are carried out on high-resolution paired and unpaired datasets,
the results show that the proposed model outperforms the state-of-the-art
model.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15488" title="Abstract">arXiv:2312.15488</a> [<a href="/pdf/2312.15488" title="Download PDF">pdf</a>, <a href="/format/2312.15488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Zeta ($&#x3b6;$) Notation for Complex Asymptotes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Anurag Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Lakshmanan%2C+K">K. Lakshmanan</a>, 
<a href="/search/cs?searchtype=author&query=Harshith%2C+J">John Harshith</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthy%2C+A">A. Ramamoorthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Time Complexity is an important metric to compare algorithms based on their
cardinality. The commonly used, trivial notations to qualify the same are the
Big-Oh, Big-Omega, Big-Theta, Small-Oh, and Small-Omega Notations. All of them,
consider time a part of the real entity, i.e., Time coincides with the
horizontal axis in the argand plane. But what if the Time rather than
completely coinciding with the real axis of the argand plane, makes some angle
with it? We are trying to focus on the case when the Time Complexity will have
both real and imaginary components. For Instance, if $T\left(n\right)=\
n\log{n}$, the existing asymptomatic notations are capable of handling that in
real time But, if we come across a problem where, $T\left(n\right)=\
n\log{n}+i\cdot n^2$, where, $i=\sqrt[2]{-1}$, the existing asymptomatic
notations will not be able to catch up. To mitigate the same, in this research,
we would consider proposing the Zeta Notation ($\zeta$), which would qualify
Time in both the Real and Imaginary Axis, as per the Argand Plane.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15489" title="Abstract">arXiv:2312.15489</a> [<a href="/pdf/2312.15489" title="Download PDF">pdf</a>, <a href="/format/2312.15489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Browsing behavior exposes identities on the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+M">Marcos Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jonathan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+D">Daniel Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Bonnay%2C+D">Denis Bonnay</a>, 
<a href="/search/cs?searchtype=author&query=Kulshrestha%2C+J">Juhi Kulshrestha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph); Applications (stat.AP)

</div>
<p class="mathjax">How easy is it to uniquely identify a person based on their web browsing
behavior? Here we show that when people navigate the Web, their online traces
produce fingerprints that identify them. By merely knowing their most visited
web domains, four data points are enough to identify 95% of the individuals.
These digital fingerprints are stable and render high re-identifiability. We
demonstrate that we can re-identify 90% of the individuals in separate time
slices of data. Such a privacy threat persists even with limited information
about individuals' browsing behavior, reinforcing existing concerns around
online privacy.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15490" title="Abstract">arXiv:2312.15490</a> [<a href="/pdf/2312.15490" title="Download PDF">pdf</a>, <a href="/format/2312.15490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-EXR: Controllable Review Generation for Explainable  Recommendation via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaohua Li</a>, 
<a href="/search/cs?searchtype=author&query=Marantika%2C+W">Winda Marantika</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A+C">Alex C. Kot</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Huijing Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Denoising Diffusion Probabilistic Model (DDPM) has shown great competence in
image and audio generation tasks. However, there exist few attempts to employ
DDPM in the text generation, especially review generation under recommendation
systems. Fueled by the predicted reviews explainability that justifies
recommendations could assist users better understand the recommended items and
increase the transparency of recommendation system, we propose a Diffusion
Model-based Review Generation towards EXplainable Recommendation named
Diffusion-EXR. Diffusion-EXR corrupts the sequence of review embeddings by
incrementally introducing varied levels of Gaussian noise to the sequence of
word embeddings and learns to reconstruct the original word representations in
the reverse process. The nature of DDPM enables our lightweight Transformer
backbone to perform excellently in the recommendation review generation task.
Extensive experimental results have demonstrated that Diffusion-EXR can achieve
state-of-the-art review generation for recommendation on two publicly available
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15497" title="Abstract">arXiv:2312.15497</a> [<a href="/pdf/2312.15497" title="Download PDF">pdf</a>, <a href="/ps/2312.15497" title="Download PostScript">ps</a>, <a href="/format/2312.15497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Convolutional Neural Networks for Short-Term Multi-Energy Demand  Prediction of Integrated Energy Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arsene%2C+C">Corneliu Arsene</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 40 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Forecasting power consumptions of integrated electrical, heat or gas network
systems is essential in order to operate more efficiently the whole energy
network. Multi-energy systems are increasingly seen as a key component of
future energy systems, and a valuable source of flexibility, which can
significantly contribute to a cleaner and more sustainable whole energy system.
Therefore, there is a stringent need for developing novel and performant models
for forecasting multi-energy demand of integrated energy systems, which to
account for the different types of interacting energy vectors and of the
coupling between them. Previous efforts in demand forecasting focused mainly on
the single electrical power consumption or, more recently, on the single heat
or gas power consumptions. In order to address this gap, in this paper six
novel prediction models based on Convolutional Neural Networks (CNNs) are
developed, for either individual or joint prediction of multi-energy power
consumptions: the single input/single output CNN model with determining the
optimum number of epochs (CNN_1), the multiple input/single output CNN model
(CNN_2), the single input/ single output CNN model with
training/validation/testing datasets (CNN_3), the joint prediction CNN model
(CNN_4), the multiple-building input/output CNN model (CNN_5) and the federated
learning CNN model (CNN_6). All six novel CNN models are applied in a
comprehensive manner on a novel integrated electrical, heat and gas network
system, which only recently has started to be used for forecasting. The
forecast horizon is short-term (next half an hour) and all the predictions
results are evaluated in terms of the Signal to Noise Ratio (SNR) and the
Normalized Root Mean Square Error (NRMSE), while the Mean Absolute Percentage
Error (MAPE) is used for comparison purposes with other existent results from
literature.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15502" title="Abstract">arXiv:2312.15502</a> [<a href="/pdf/2312.15502" title="Download PDF">pdf</a>, <a href="/format/2312.15502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent based modelling for continuously varying supply chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haiyan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Sobey%2C+A+J">Adam J.Sobey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Problem definition: Supply chains are constantly evolving networks.
Reinforcement learning is increasingly proposed as a solution to provide
optimal control of these networks. Academic/practical: However, learning in
continuously varying environments remains a challenge in the reinforcement
learning literature.Methodology: This paper therefore seeks to address whether
agents can control varying supply chain problems, transferring learning between
environments that require different strategies and avoiding catastrophic
forgetting of tasks that have not been seen in a while. To evaluate this
approach, two state-of-the-art Reinforcement Learning (RL) algorithms are
compared: an actor-critic learner, Proximal Policy Optimisation(PPO), and a
Recurrent Proximal Policy Optimisation (RPPO), PPO with a Long Short-Term
Memory(LSTM) layer, which is showing popularity in online learning
environments. Results: First these methods are compared on six sets of
environments with varying degrees of stochasticity. The results show that more
lean strategies adopted in Batch environments are different from those adopted
in Stochastic environments with varying products. The methods are also compared
on various continuous supply chain scenarios, where the PPO agents are shown to
be able to adapt through continuous learning when the tasks are similar but
show more volatile performance when changing between the extreme tasks.
However, the RPPO, with an ability to remember histories, is able to overcome
this to some extent and takes on a more realistic strategy. Managerial
implications: Our results provide a new perspective on the continuously varying
supply chain, the cooperation and coordination of agents are crucial for
improving the overall performance in uncertain and semi-continuous
non-stationary supply chain environments without the need to retrain the
environment as the demand changes.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15503" title="Abstract">arXiv:2312.15503</a> [<a href="/pdf/2312.15503" title="Download PDF">pdf</a>, <a href="/format/2312.15503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Large Language Models A Better Foundation For Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Dense retrieval needs to learn discriminative text embeddings to represent
the semantic relationship between query and document. It may benefit from the
using of large language models (LLMs), given LLMs' strong capability on
semantic understanding. However, the LLMs are pre-trained by text generation
tasks, whose working pattern is completely different from representing texts as
embeddings. As a result, it is imperative to study how to adapt LLMs properly
so that they can be effectively initialized as the backbone encoder for dense
retrieval.
<br />In this paper, we propose a novel approach, called LLaRA (LLM adapted for
dense RetrievAl), which works as a post-hoc adaptation of LLM for the dense
retrieval application. LLaRA consists of two pretext tasks: EBAE
(Embedding-Based Auto-Encoding) and EBAR (Embedding-Based Auto-Regression),
where the text embeddings from LLM are used to reconstruct the tokens for the
input sentence and predict the tokens for the next sentence, respectively.
LLaRA turns out to be simple, lightweight, and highly effective. It is applied
to adapt LLaMA-2-7B (base) on the Wikipedia corpus, where it substantially
improves the model's fine-tuned performances on a variety of dense retrieval
benchmarks, like MSMARCO and BEIR. Our model and code will be made publicly
available at BGE repository.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15504" title="Abstract">arXiv:2312.15504</a> [<a href="/pdf/2312.15504" title="Download PDF">pdf</a>, <a href="/ps/2312.15504" title="Download PostScript">ps</a>, <a href="/format/2312.15504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Allocation and Beamforming Design for IRS-aided Secure Directional  Modulation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Rongen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With the aim of boosting the security of the conventional directional
modulation (DM) network, a secure DM network assisted by intelligent reflecting
surface (IRS) is investigated in this paper. To maximize the security rate
(SR), we jointly optimize the power allocation (PA) factor, confidential
message (CM) beamforming, artificial noise (AN) beamforming, and IRS reflected
beamforming. To tackle the formulated problem, a maximizing SR with
high-performance (Max-SR-HP) scheme is proposed, where the PA factor, CM
beamforming, AN beamforming, and IRS phase shift matrix are derived by the
derivative operation, generalized Rayleigh-Rize, generalized power iteration,
and semidefinite relaxation criteria, respectively. Given that the high
complexity of the above scheme, a maximizing SR with low-complexity (Max-SR-LC)
scheme is proposed, which employs the generalized leakage and successive convex
approximation algorithms to derive the variables. Simulation results show that
both the proposed schemes can significantly boost the SR performance, and are
better than the equal PA, no IRS and random phase shift IRS schemes.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15507" title="Abstract">arXiv:2312.15507</a> [<a href="/pdf/2312.15507" title="Download PDF">pdf</a>, <a href="/format/2312.15507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construct 3D Hand Skeleton with Commercial WiFi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Sijie Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuanqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mo Li</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM SenSys 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents HandFi, which constructs hand skeletons with practical
WiFi devices. Unlike previous WiFi hand sensing systems that primarily employ
predefined gestures for pattern matching, by constructing the hand skeleton,
HandFi can enable a variety of downstream WiFi-based hand sensing applications
in gaming, healthcare, and smart homes. Deriving the skeleton from WiFi signals
is challenging, especially because the palm is a dominant reflector compared
with fingers. HandFi develops a novel multi-task learning neural network with a
series of customized loss functions to capture the low-level hand information
from WiFi signals. During offline training, HandFi takes raw WiFi signals as
input and uses the leap motion to provide supervision. During online use, only
with commercial WiFi, HandFi is capable of producing 2D hand masks as well as
3D hand poses. We demonstrate that HandFi can serve as a foundation model to
enable developers to build various applications such as finger tracking and
sign language recognition, and outperform existing WiFi-based solutions.
Artifacts can be found: https://github.com/SIJIEJI/HandFi
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15514" title="Abstract">arXiv:2312.15514</a> [<a href="/pdf/2312.15514" title="Download PDF">pdf</a>, <a href="/format/2312.15514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reliable AI Model Deployments: Multiple Input Mixup for  Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dasol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Dongbin Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the AAAI 2024 Workshop on Deployable AI (DAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent remarkable success in the deep-learning industries has unprecedentedly
increased the need for reliable model deployment. For example, the model should
alert the user if the produced model outputs might not be reliable. Previous
studies have proposed various methods to solve the Out-of-Distribution (OOD)
detection problem, however, they generally require a burden of resources. In
this work, we propose a novel and simple method, Multiple Input Mixup (MIM).
Our method can help improve the OOD detection performance with only single
epoch fine-tuning. Our method does not require training the model from scratch
and can be attached to the classifier simply. Despite its simplicity, our MIM
shows competitive performance. Our method can be suitable for various
environments because our method only utilizes the In-Distribution (ID) samples
to generate the synthesized OOD data. With extensive experiments with CIFAR10
and CIFAR100 benchmarks that have been largely adopted in out-of-distribution
detection fields, we have demonstrated our MIM shows comprehensively superior
performance compared to the SOTA method. Especially, our method does not need
additional computation on the feature vectors compared to the previous studies.
All source codes are publicly available at
https://github.com/ndb796/MultipleInputMixup.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15516" title="Abstract">arXiv:2312.15516</a> [<a href="/pdf/2312.15516" title="Download PDF">pdf</a>, <a href="/format/2312.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-SDM: Accelerating Stable Diffusion through Redundancy Removal and  Performance Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaobing Tu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Siyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Stable Diffusion Model (SDM) is a popular and efficient text-to-image
(t2i) generation and image-to-image (i2i) generation model. Although there have
been some attempts to reduce sampling steps, model distillation, and network
quantization, these previous methods generally retain the original network
architecture. Billion scale parameters and high computing requirements make the
research of model architecture adjustment scarce. In this work, we first
explore the computational redundancy part of the network, and then prune the
redundancy blocks of the model and maintain the network performance through a
progressive incubation strategy. Secondly, in order to maintaining the model
performance, we add cross-layer multi-expert conditional convolution
(CLME-Condconv) to the block pruning part to inherit the original convolution
parameters. Thirdly, we propose a global-regional interactive (GRI) attention
to speed up the computationally intensive attention part. Finally, we use
semantic-aware supervision (SAS) to align the outputs of the teacher model and
student model at the semantic level. Experiments show that this method can
effectively train a lightweight model close to the performance of the original
SD model, and effectively improve the model speed under limited resources.
Experiments show that the proposed method can effectively train a light-weight
model close to the performance of the original SD model, and effectively
improve the model speed under limited resources. After acceleration, the UNet
part of the model is 22% faster and the overall speed is 19% faster.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15520" title="Abstract">arXiv:2312.15520</a> [<a href="/pdf/2312.15520" title="Download PDF">pdf</a>, <a href="/format/2312.15520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Coarsening via Convolution Matching for Scalable Graph Neural  Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dickens%2C+C">Charles Dickens</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+E">Eddie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Reganti%2C+A">Aishwarya Reganti</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Subbian%2C+K">Karthik Subbian</a>, 
<a href="/search/cs?searchtype=author&query=Koutra%2C+D">Danai Koutra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph summarization as a preprocessing step is an effective and complementary
technique for scalable graph neural network (GNN) training. In this work, we
propose the Coarsening Via Convolution Matching (CONVMATCH) algorithm and a
highly scalable variant, A-CONVMATCH, for creating summarized graphs that
preserve the output of graph convolution. We evaluate CONVMATCH on six
real-world link prediction and node classification graph datasets, and show it
is efficient and preserves prediction performance while significantly reducing
the graph size. Notably, CONVMATCH achieves up to 95% of the prediction
performance of GNNs on node classification while trained on graphs summarized
down to 1% the size of the original graph. Furthermore, on link prediction
tasks, CONVMATCH consistently outperforms all baselines, achieving up to a 2x
improvement.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15523" title="Abstract">arXiv:2312.15523</a> [<a href="/pdf/2312.15523" title="Download PDF">pdf</a>, <a href="/format/2312.15523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Persuasive Power of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breum%2C+S+M">Simon Martin Breum</a>, 
<a href="/search/cs?searchtype=author&query=Egdal%2C+D+V">Daniel V&#xe6;dele Egdal</a>, 
<a href="/search/cs?searchtype=author&query=Mortensen%2C+V+G">Victor Gram Mortensen</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B8ller%2C+A+G">Anders Giovanni M&#xf8;ller</a>, 
<a href="/search/cs?searchtype=author&query=Aiello%2C+L+M">Luca Maria Aiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, 3 tables, 1 page in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The increasing capability of Large Language Models to act as human-like
social agents raises two important questions in the area of opinion dynamics.
First, whether these agents can generate effective arguments that could be
injected into the online discourse to steer the public opinion. Second, whether
artificial agents can interact with each other to reproduce dynamics of
persuasion typical of human social systems, opening up opportunities for
studying synthetic social systems as faithful proxies for opinion dynamics in
human populations. To address these questions, we designed a synthetic
persuasion dialogue scenario on the topic of climate change, where a
'convincer' agent generates a persuasive argument for a 'skeptic' agent, who
subsequently assesses whether the argument changed its internal opinion state.
Different types of arguments were generated to incorporate different linguistic
dimensions underpinning psycho-linguistic theories of opinion change. We then
asked human judges to evaluate the persuasiveness of machine-generated
arguments. Arguments that included factual knowledge, markers of trust,
expressions of support, and conveyed status were deemed most effective
according to both humans and agents, with humans reporting a marked preference
for knowledge-based arguments. Our experimental framework lays the groundwork
for future in-silico studies of opinion dynamics, and our findings suggest that
artificial agents have the potential of playing an important role in collective
processes of opinion formation in online social media.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15524" title="Abstract">arXiv:2312.15524</a> [<a href="/pdf/2312.15524" title="Download PDF">pdf</a>, <a href="/format/2312.15524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Challenge of Using LLMs to Simulate Human Behavior: A Causal  Inference Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+G">George Gui</a>, 
<a href="/search/cs?searchtype=author&query=Toubia%2C+O">Olivier Toubia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR); Econometrics (econ.EM); Applications (stat.AP)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated impressive potential to
simulate human behavior. Using a causal inference framework, we empirically and
theoretically analyze the challenges of conducting LLM-simulated experiments,
and explore potential solutions. In the context of demand estimation, we show
that variations in the treatment included in the prompt (e.g., price of focal
product) can cause variations in unspecified confounding factors (e.g., price
of competitors, historical prices, outside temperature), introducing
endogeneity and yielding implausibly flat demand curves. We propose a
theoretical framework suggesting this endogeneity issue generalizes to other
contexts and won't be fully resolved by merely improving the training data.
Unlike real experiments where researchers assign pre-existing units across
conditions, LLMs simulate units based on the entire prompt, which includes the
description of the treatment. Therefore, due to associations in the training
data, the characteristics of individuals and environments simulated by the LLM
can be affected by the treatment assignment. We explore two potential
solutions. The first specifies all contextual variables that affect both
treatment and outcome, which we demonstrate to be challenging for a
general-purpose LLM. The second explicitly specifies the source of treatment
variation in the prompt given to the LLM (e.g., by informing the LLM that the
store is running an experiment). While this approach only allows the estimation
of a conditional average treatment effect that depends on the specific
experimental design, it provides valuable directional results for exploratory
analysis.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15526" title="Abstract">arXiv:2312.15526</a> [<a href="/pdf/2312.15526" title="Download PDF">pdf</a>, <a href="/ps/2312.15526" title="Download PostScript">ps</a>, <a href="/format/2312.15526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aspect category learning and sentimental analysis using weakly  supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subbaih%2C+K">Kalpa Subbaih</a>, 
<a href="/search/cs?searchtype=author&query=Bolla%2C+B+K">Bharath Kumar Bolla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The surge of e-commerce reviews has presented a challenge in manually
annotating the vast volume of reviews to comprehend their underlying aspects
and sentiments. This research focused on leveraging weakly supervised learning
to tackle aspect category learning and the sentiment classification of reviews.
Our approach involves the generation of labels for both aspects and sentiments,
employing the Snorkel framework of WSL, which incorporates aspect terms, review
sentiment scores, and review ratings as sources of weak signals. This
innovative strategy significantly reduces the laborious labeling efforts
required for processing such extensive datasets. In this study, we deployed
hybrid models, namely BiLSTM, CNN-BiLSTM, and CNN-LSTM, which harness multiple
inputs, including review text, aspect terms, and ratings. Our proposed model
employs two distinct loss functions: Binary Cross Entropy with Sigmoid
Activation for Multi-Label Classification, enabling us to learn aspect Labels
such as Quality, Usability, Service, Size, and Price, and Categorical Cross
Entropy with Softmax Activations for Multi-Class Classification. Subsequently,
we meticulously evaluate the performance metrics of these three implemented
models, including Macro F1 score and Macro Precision. CNN &amp; Bi-LSTM model
attained 0.78 and 0.79 F1 scores on aspect and sentiment identification,
respectively. The outcomes of this research are poised to make a substantial
contribution to e-commerce platforms, offering an efficient and automated means
to label and analyze vast troves of user reviews.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15527" title="Abstract">arXiv:2312.15527</a> [<a href="/pdf/2312.15527" title="Download PDF">pdf</a>, <a href="/ps/2312.15527" title="Download PostScript">ps</a>, <a href="/format/2312.15527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAMA: Commodity DRAM based Content Addressable Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yavits%2C+L">Leonid Yavits</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Fast parallel search capabilities on large datasets provided by content
addressable memories (CAM) are required across multiple application domains.
However compared to RAM, CAMs feature high area overhead and power consumption,
and as a result, they scale poorly. The proposed solution, DRAMA, enables CAM,
ternary CAM (TCAM) and approximate (similarity) search CAM functionalities in
unmodified commodity DRAM. DRAMA performs compare operation in a bit-serial
fashion, where the search pattern (query) is coded in DRAM addresses. A single
bit compare (XNOR) in DRAMA is identical to a regular DRAM read. AND and OR
operations required for NAND CAM and NOR CAM respectively are implemented using
nonstandard DRAM timing. We evaluate DRAMA on bacterial DNA classification and
show that DRAMA can achieve 3.6 times higher performance and 19.6 times lower
power consumption compared to state-of-the-art CMOS CAM based genome
classification accelerator.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15528" title="Abstract">arXiv:2312.15528</a> [<a href="/pdf/2312.15528" title="Download PDF">pdf</a>, <a href="/format/2312.15528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of Iterative Detection and Decoding with Log-Likelihood Ratio  Based Access Point Selection for Cell-Free Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Renna%2C+R+B">R. B. Di Renna</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures, 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes an iterative detection and decoding (IDD) scheme and an
approach to improve the selection of access points (APs) in uplink cell-free
massive multiple-antenna systems. A cost-effective scheme for selection of APs
based on local log-likelihood ratios (LLRs) is developed that provides
sufficient statistics to the central processing unit and selects which APs
should be considered for each user. {Numerical results show that the proposed
IDD scheme works very well and the proposed LLRs-based approach to select APs
outperforms the existing techniques in terms of bit error rate and spectral
efficiency while requiring a comparable fronthaul load.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15536" title="Abstract">arXiv:2312.15536</a> [<a href="/pdf/2312.15536" title="Download PDF">pdf</a>, <a href="/format/2312.15536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Pre-trained Generalist Agents for Software Engineering Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mindom%2C+P+S+N">Paulina Stevia Nouwou Mindom</a>, 
<a href="/search/cs?searchtype=author&query=Nikanjam%2C+A">Amin Nikanjam</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Nowadays, we are witnessing an increasing adoption of Artificial Intelligence
(AI) to develop techniques aimed at improving the reliability, effectiveness,
and overall quality of software systems. Deep reinforcement learning (DRL) has
recently been successfully used for automation in complex tasks such as game
testing and solving the job-shop scheduling problem. However, these specialized
DRL agents, trained from scratch on specific tasks, suffer from a lack of
generalizability to other tasks and they need substantial time to be developed
and re-trained effectively. Recently, DRL researchers have begun to develop
generalist agents, able to learn a policy from various environments and capable
of achieving performances similar to or better than specialist agents in new
tasks. In the Natural Language Processing or Computer Vision domain, these
generalist agents are showing promising adaptation capabilities to
never-before-seen tasks after a light fine-tuning phase and achieving high
performance. This paper investigates the potential of generalist agents for
solving SE tasks. Specifically, we conduct an empirical study aimed at
assessing the performance of two generalist agents on two important SE tasks:
the detection of bugs in games (for two games) and the minimization of makespan
in a scheduling task, to solve the job-shop scheduling problem (for two
instances). Our results show that the generalist agents outperform the
specialist agents with very little effort for fine-tuning, achieving a 20%
reduction of the makespan over specialized agent performance on task-based
scheduling. In the context of game testing, some generalist agent
configurations detect 85% more bugs than the specialist agents. Building on our
analysis, we provide recommendations for researchers and practitioners looking
to select generalist agents for SE tasks, to ensure that they perform
effectively.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15539" title="Abstract">arXiv:2312.15539</a> [<a href="/pdf/2312.15539" title="Download PDF">pdf</a>, <a href="/format/2312.15539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical approximation of variational problems with orthotropic growth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balci%2C+A+K">Anna Kh. Balci</a>, 
<a href="/search/math?searchtype=author&query=Diening%2C+L">Lars Diening</a>, 
<a href="/search/math?searchtype=author&query=Salgado%2C+A+J">Abner J. Salgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the numerical approximation of variational problems with
orthotropic growth, that is those where the integrand depends strongly on the
coordinate directions with possibly different growth in each direction. Under
realistic regularity assumptions we derive optimal error estimates. These
estimates depend on the existence of an orthotropically stable interpolation
operator. Over certain meshes we construct an orthotropically stable
interpolant that is also a projection. Numerical experiments illustrate and
explore the limits of our theory.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15540" title="Abstract">arXiv:2312.15540</a> [<a href="/pdf/2312.15540" title="Download PDF">pdf</a>, <a href="/format/2312.15540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amodal Completion via Progressive Mixed Context Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Katherine Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianbo Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our brain can effortlessly recognize objects even when partially hidden from
view. Seeing the visible of the hidden is called amodal completion; however,
this task remains a challenge for generative AI despite rapid progress. We
propose to sidestep many of the difficulties of existing approaches, which
typically involve a two-step process of predicting amodal masks and then
generating pixels. Our method involves thinking outside the box, literally! We
go outside the object bounding box to use its context to guide a pre-trained
diffusion inpainting model, and then progressively grow the occluded object and
trim the extra background. We overcome two technical challenges: 1) how to be
free of unwanted co-occurrence bias, which tends to regenerate similar
occluders, and 2) how to judge if an amodal completion has succeeded. Our
amodal completion method exhibits improved photorealistic completion results
compared to existing approaches in numerous successful completion cases. And
the best part? It doesn't require any special training or fine-tuning of
models.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15546" title="Abstract">arXiv:2312.15546</a> [<a href="/pdf/2312.15546" title="Download PDF">pdf</a>, <a href="/format/2312.15546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runge-Kutta methods are stable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tadmor%2C+E">Eitan Tadmor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">We prove that Runge-Kutta (RK) methods for numerical integration of
arbitrarily large systems of Ordinary Differential Equations are linearly
stable. Standard stability arguments -- based on spectral analysis, resolvent
condition or strong stability, fail to secure the stability of arbitrarily
large RK systems. We explain the failure of different approaches, offer a new
stability theory and demonstrate a few examples.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15547" title="Abstract">arXiv:2312.15547</a> [<a href="/pdf/2312.15547" title="Download PDF">pdf</a>, <a href="/format/2312.15547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guess What Quantum Computing Can Do for Test Case Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Arcaini%2C+P">Paolo Arcaini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the near term, quantum approximate optimization algorithms (QAOAs) hold
great potential to solve combinatorial optimization problems. These are hybrid
algorithms, i.e., a combination of quantum and classical algorithms. Several
proof-of-concept applications of QAOAs for solving combinatorial problems, such
as portfolio optimization, energy optimization in power systems, and job
scheduling, have been demonstrated. However, whether QAOAs can efficiently
solve optimization problems from classical software engineering, such as test
optimization, remains unstudied. To this end, we present the first effort to
formulate a software test case optimization problem as a QAOA problem and solve
it on quantum computer simulators. To solve bigger test optimization problems
that require many qubits, which are unavailable these days, we integrate a
problem decomposition strategy with the QAOA. We performed an empirical
evaluation with five test case optimization problems and four industrial
datasets from ABB, Google, and Orona to compare various configurations of our
approach, assess its decomposition strategy of handling large datasets, and
compare its performance with classical algorithms (i.e., Genetic Algorithm (GA)
and Random Search). Based on the evaluation results, we recommend the best
configuration of our approach for test case optimization problems. Also, we
demonstrate that our strategy can reach the same effectiveness as GA and
outperform GA in two out of five test case optimization problems we conducted.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15548" title="Abstract">arXiv:2312.15548</a> [<a href="/pdf/2312.15548" title="Download PDF">pdf</a>, <a href="/format/2312.15548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal  Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xinglin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minzheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wenji Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Daniel Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The difficulty of the information extraction task lies in dealing with the
task-specific label schemas and heterogeneous data structures. Recent work has
proposed methods based on large language models to uniformly model different
information extraction tasks. However, these existing methods are deficient in
their information extraction capabilities for Chinese languages other than
English. In this paper, we propose an end-to-end chat-enhanced instruction
tuning framework for universal information extraction (YAYI-UIE), which
supports both Chinese and English. Specifically, we utilize dialogue data and
information extraction data to enhance the information extraction performance
jointly. Experimental results show that our proposed framework achieves
state-of-the-art performance on Chinese datasets while also achieving
comparable performance on English datasets under both supervised settings and
zero-shot settings.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15549" title="Abstract">arXiv:2312.15549</a> [<a href="/pdf/2312.15549" title="Download PDF">pdf</a>, <a href="/format/2312.15549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-Time Frequentist Regret Bounds of Multi-Agent Thompson Sampling  on Sparse Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Tianyuan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+H">Hao-Lun Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">William Chang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Pan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures, 2 tables. To appear in the proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI'2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the multi-agent multi-armed bandit (MAMAB) problem, where $m$ agents
are factored into $\rho$ overlapping groups. Each group represents a hyperedge,
forming a hypergraph over the agents. At each round of interaction, the learner
pulls a joint arm (composed of individual arms for each agent) and receives a
reward according to the hypergraph structure. Specifically, we assume there is
a local reward for each hyperedge, and the reward of the joint arm is the sum
of these local rewards. Previous work introduced the multi-agent Thompson
sampling (MATS) algorithm \citep{verstraeten2020multiagent} and derived a
Bayesian regret bound. However, it remains an open problem how to derive a
frequentist regret bound for Thompson sampling in this multi-agent setting. To
address these issues, we propose an efficient variant of MATS, the
$\epsilon$-exploring Multi-Agent Thompson Sampling ($\epsilon$-MATS) algorithm,
which performs MATS exploration with probability $\epsilon$ while adopts a
greedy policy otherwise. We prove that $\epsilon$-MATS achieves a worst-case
frequentist regret bound that is sublinear in both the time horizon and the
local arm size. We also derive a lower bound for this setting, which implies
our frequentist regret upper bound is optimal up to constant and logarithm
terms, when the hypergraph is sufficiently sparse. Thorough experiments on
standard MAMAB problems demonstrate the superior performance and the improved
computational efficiency of $\epsilon$-MATS compared with existing algorithms
in the same setting.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15550" title="Abstract">arXiv:2312.15550</a> [<a href="/pdf/2312.15550" title="Download PDF">pdf</a>, <a href="/ps/2312.15550" title="Download PostScript">ps</a>, <a href="/format/2312.15550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level biomedical NER through multi-granularity embeddings and  enhanced labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahrokh%2C+F">Fahime Shahrokh</a>, 
<a href="/search/cs?searchtype=author&query=Ghadiri%2C+N">Nasser Ghadiri</a>, 
<a href="/search/cs?searchtype=author&query=Samani%2C+R">Rasoul Samani</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+M">Milad Moradi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Biomedical Named Entity Recognition (NER) is a fundamental task of Biomedical
Natural Language Processing for extracting relevant information from biomedical
texts, such as clinical records, scientific publications, and electronic health
records. The conventional approaches for biomedical NER mainly use traditional
machine learning techniques, such as Conditional Random Fields and Support
Vector Machines or deep learning-based models like Recurrent Neural Networks
and Convolutional Neural Networks. Recently, Transformer-based models,
including BERT, have been used in the domain of biomedical NER and have
demonstrated remarkable results. However, these models are often based on
word-level embeddings, limiting their ability to capture character-level
information, which is effective in biomedical NER due to the high variability
and complexity of biomedical texts. To address these limitations, this paper
proposes a hybrid approach that integrates the strengths of multiple models. In
this paper, we proposed an approach that leverages fine-tuned BERT to provide
contextualized word embeddings, a pre-trained multi-channel CNN for
character-level information capture, and following by a BiLSTM + CRF for
sequence labelling and modelling dependencies between the words in the text. In
addition, also we propose an enhanced labelling method as part of
pre-processing to enhance the identification of the entity's beginning word and
thus improve the identification of multi-word entities, a common challenge in
biomedical NER. By integrating these models and the pre-processing method, our
proposed model effectively captures both contextual information and detailed
character-level information. We evaluated our model on the benchmark i2b2/2010
dataset, achieving an F1-score of 90.11. These results illustrate the
proficiency of our proposed model in performing biomedical Named Entity
Recognition.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15551" title="Abstract">arXiv:2312.15551</a> [<a href="/pdf/2312.15551" title="Download PDF">pdf</a>, <a href="/format/2312.15551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Public Representations for Private Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thaker%2C+P">Pratiksha Thaker</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+A">Amrith Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Motivated by the recent empirical success of incorporating public data into
differentially private learning, we theoretically investigate how a shared
representation learned from public data can improve private learning. We
explore two common scenarios of transfer learning for linear regression, both
of which assume the public and private tasks (regression vectors) share a
low-rank subspace in a high-dimensional space. In the first single-task
transfer scenario, the goal is to learn a single model shared across all users,
each corresponding to a row in a dataset. We provide matching upper and lower
bounds showing that our algorithm achieves the optimal excess risk within a
natural class of algorithms that search for the linear model within the given
subspace estimate. In the second scenario of multitask model personalization,
we show that with sufficient public data, users can avoid private coordination,
as purely local learning within the given subspace achieves the same utility.
Taken together, our results help to characterize the benefits of public data
across common regimes of private transfer learning.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15554" title="Abstract">arXiv:2312.15554</a> [<a href="/pdf/2312.15554" title="Download PDF">pdf</a>, <a href="/format/2312.15554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Computational Micromechanics for Reactive Flow in Porous  Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karimi%2C+M">Mina Karimi</a>, 
<a href="/search/math?searchtype=author&query=Bhattacharya%2C+K">Kaushik Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Reactive transport in permeable porous media is relevant for a variety of
applications, but poses a significant challenge due to the range of length and
time scales. Multiscale methods that aim to link microstructure with the
macroscopic response of geo-materials have been developed, but require the
repeated solution of the small-scale problem and provide the motivation for
this work. We present an efficient computational method to study fluid flow and
solute transport problems in periodic porous media. Fluid flow is governed by
the Stokes equation, and the solute transport is governed by the
advection-diffusion equation. We follow the accelerated computational
micromechanics approach that leads to an iterative computational method where
each step is either local or the solution of a Poisson's equation. This enables
us to implement these methods on accelerators like graphics processing units
(GPUs) and exploit their massively parallel architecture. We verify the
approach by comparing the results against established computational methods and
then demonstrate the accuracy, efficacy, and performance by studying various
examples. This method efficiently calculates the effective transport properties
for complex pore geometries.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15555" title="Abstract">arXiv:2312.15555</a> [<a href="/pdf/2312.15555" title="Download PDF">pdf</a>, <a href="/format/2312.15555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConcaveQ: Non-Monotonic Value Function Factorization via Concave  Representations in Deep Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huiqun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanhan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yifei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongxiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Value function factorization has achieved great success in multi-agent
reinforcement learning by optimizing joint action-value functions through the
maximization of factorized per-agent utilities. To ensure
Individual-Global-Maximum property, existing works often focus on value
factorization using monotonic functions, which are known to result in
restricted representation expressiveness. In this paper, we analyze the
limitations of monotonic factorization and present ConcaveQ, a novel
non-monotonic value function factorization approach that goes beyond monotonic
mixing functions and employs neural network representations of concave mixing
functions. Leveraging the concave property in factorization, an iterative
action selection scheme is developed to obtain optimal joint actions during
training. It is used to update agents' local policy networks, enabling fully
decentralized execution. The effectiveness of the proposed ConcaveQ is
validated across scenarios involving multi-agent predator-prey environment and
StarCraft II micromanagement tasks. Empirical results exhibit significant
improvement of ConcaveQ over state-of-the-art multi-agent reinforcement
learning approaches.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15559" title="Abstract">arXiv:2312.15559</a> [<a href="/pdf/2312.15559" title="Download PDF">pdf</a>, <a href="/format/2312.15559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Dependent Solutions to the 2D Kuramoto-Sivashinsky Equation via  Pseudospectral Method on a Rectangular Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C5%BDigi%C4%87%2C+J">Jovan &#x17d;igi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 4 tables, 56 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This report provides an investigation into solving the Kuramoto-Sivashinsky
equation in two spatial dimensions (2DKS) using a pseudo-spectral method on
various rectangular periodic domains. The Kuramoto-Sivashinsky equation is a
fluid dynamics model that exhibits dynamical features that are highly dependent
on the length of the periodic domain. The goals of this report are to describe
the mathematical problem; explain the details of the chosen numerical method;
inspect solutions and dynamical features for varying grid sizes, step sizes,
and domains; and summarize the findings.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15561" title="Abstract">arXiv:2312.15561</a> [<a href="/pdf/2312.15561" title="Download PDF">pdf</a>, <a href="/format/2312.15561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> README: Bridging Medical Jargon and Lay Understanding for Patient  Education through Data-Centric NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Kantu%2C+N+S">Nandyala Siddharth Kantu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guanghao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H">Hieu Tran</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhangqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S">Sunjae Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=README+annotation+team">README annotation team</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advancement in healthcare has shifted focus toward patient-centric
approaches, particularly in self-care and patient education, facilitated by
access to Electronic Health Records (EHR). However, medical jargon in EHRs
poses significant challenges in patient comprehension. To address this, we
introduce a new task of automatically generating lay definitions, aiming to
simplify complex medical terms into patient-friendly lay language. We first
created the README dataset, an extensive collection of over 20,000 unique
medical terms and 300,000 mentions, each offering context-aware lay definitions
manually annotated by domain experts. We have also engineered a data-centric
Human-AI pipeline that synergizes data filtering, augmentation, and selection
to improve data quality. We then used README as the training data for models
and leveraged a Retrieval-Augmented Generation (RAG) method to reduce
hallucinations and improve the quality of model outputs. Our extensive
automatic and human evaluations demonstrate that open-source mobile-friendly
models, when fine-tuned with high-quality data, are capable of matching or even
surpassing the performance of state-of-the-art closed-source large language
models like ChatGPT. This research represents a significant stride in closing
the knowledge gap in patient education and advancing patient-centric healthcare
solutions
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15567" title="Abstract">arXiv:2312.15567</a> [<a href="/pdf/2312.15567" title="Download PDF">pdf</a>, <a href="/format/2312.15567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Co-Speech Gesture Generation via Modeling Dialog  Intention, Emotion, and Context with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haiwei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhensong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zonghong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,2 figures, Accepted for publication at the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Audio-driven co-speech human gesture generation has made remarkable
advancements recently. However, most previous works only focus on single person
audio-driven gesture generation. We aim at solving the problem of
conversational co-speech gesture generation that considers multiple
participants in a conversation, which is a novel and challenging task due to
the difficulty of simultaneously incorporating semantic information and other
relevant features from both the primary speaker and the interlocutor. To this
end, we propose CoDiffuseGesture, a diffusion model-based approach for
speech-driven interaction gesture generation via modeling bilateral
conversational intention, emotion, and semantic context. Our method synthesizes
appropriate interactive, speech-matched, high-quality gestures for
conversational motions through the intention perception module and emotion
reasoning module at the sentence level by a pretrained language model.
Experimental results demonstrate the promising performance of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15569" title="Abstract">arXiv:2312.15569</a> [<a href="/pdf/2312.15569" title="Download PDF">pdf</a>, <a href="/format/2312.15569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Globally Optimal Inverse Kinematics as a Quadratic Program
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Votroubek%2C+T">Tom&#xe1;&#x161; Votroubek</a>, 
<a href="/search/cs?searchtype=author&query=Kroupa%2C+T">Tom&#xe1;&#x161; Kroupa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We show how to compute globally optimal solutions to inverse kinematics (IK)
by formulating the problem as an indefinite quadratically constrained quadratic
program. Our approach makes it feasible to solve IK instances of generic
redundant manipulators. We demonstrate the performance on randomly generated
designs and on real-world robots with up to ten revolute joints. The same
technique can be used for manipulator design by introducing kinematic
parameters as variables.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15571" title="Abstract">arXiv:2312.15571</a> [<a href="/pdf/2312.15571" title="Download PDF">pdf</a>, <a href="/format/2312.15571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Open-Set Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiayin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiulei Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-set image recognition (OSR) aims to both classify known-class samples
and identify unknown-class samples in the testing set, which supports robust
classifiers in many realistic applications, such as autonomous driving, medical
diagnosis, security monitoring, etc. In recent years, open-set recognition
methods have achieved more and more attention, since it is usually difficult to
obtain holistic information about the open world for model training. In this
paper, we aim to summarize the up-to-date development of recent OSR methods,
considering their rapid development in recent two or three years. Specifically,
we firstly introduce a new taxonomy, under which we comprehensively review the
existing DNN-based OSR methods. Then, we compare the performances of some
typical and state-of-the-art OSR methods on both coarse-grained datasets and
fine-grained datasets under both standard-dataset setting and cross-dataset
setting, and further give the analysis of the comparison. Finally, we discuss
some open issues and possible future directions in this community.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15573" title="Abstract">arXiv:2312.15573</a> [<a href="/pdf/2312.15573" title="Download PDF">pdf</a>, <a href="/ps/2312.15573" title="Download PostScript">ps</a>, <a href="/format/2312.15573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges of Blockchain adoption in financial services in China&#x27;s  Greater Bay Area
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiongfei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+Y">Yain-Whar Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In China's Greater Bay Area (Guangdong-Hong Kong-Macao), the increasing use
of Blockchain technology in financial services has the potential to generate
benefits for many stakeholders. Blockchains are known for their distinctive
features, such as decentralized architecture, tamper-proof data structures, and
traceable transactions. These features make Blockchain a preferred choice of
platform for developing applications in financial service areas. Meanwhile,
some questions have been raised regarding Blockchain's suitability to compete
with or even replace existing financial systems. This paper provides insights
into the current progress of Blockchain applications in insurance, banking,
payments, asset trading, loans, remittances, the Internet of Things (IoT) for
the finance industry, financial inclusions, and enterprise-level interaction in
finance and governance. We review the barriers to widespread Blockchain
adoption, especially the risks when transaction fees dominate mining rewards.
By comparing the emerging Blockchain technologies and incentive issues related
to real-world applications, we hope that this paper can serve as a valuable
source of reference for Blockchain researchers and developers in financial
service areas.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15576" title="Abstract">arXiv:2312.15576</a> [<a href="/pdf/2312.15576" title="Download PDF">pdf</a>, <a href="/format/2312.15576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing LLM Hallucinations using Epistemic Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Shreyas Verma</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+K">Kien Tran</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+Y">Yusuf Ali</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+G">Guangyu Min</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Reducing and detecting hallucinations in large language models is an open
research problem. In this project, we attempt to leverage recent advances in
the field of uncertainty estimation to reduce hallucinations in frozen large
language models. Epistemic neural networks have recently been proposed to
improve output joint distributions for large pre-trained models. ENNs are small
networks attached to large, frozen models to improve the model's joint
distributions and uncertainty estimates. In this work, we train an epistemic
neural network on top of the Llama-2 7B model combined with a contrastive
decoding feature enhancement technique. We are the first to train an ENN for
the next token prediction task and explore the efficacy of this method in
reducing hallucinations on the TruthfulQA dataset. In essence, we provide a
method that leverages a pre-trained model's latent embeddings to reduce
hallucinations.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15577" title="Abstract">arXiv:2312.15577</a> [<a href="/pdf/2312.15577" title="Download PDF">pdf</a>, <a href="/format/2312.15577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Structure and Attention Aware Subspace Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shengjiang Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, accepted by PRCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Clustering is a fundamental unsupervised representation learning task with
wide application in computer vision and pattern recognition. Deep clustering
utilizes deep neural networks to learn latent representation, which is suitable
for clustering. However, previous deep clustering methods, especially image
clustering, focus on the features of the data itself and ignore the
relationship between the data, which is crucial for clustering. In this paper,
we propose a novel Deep Structure and Attention aware Subspace Clustering
(DSASC), which simultaneously considers data content and structure information.
We use a vision transformer to extract features, and the extracted features are
divided into two parts, structure features, and content features. The two
features are used to learn a more efficient subspace structure for spectral
clustering. Extensive experimental results demonstrate that our method
significantly outperforms state-of-the-art methods. Our code will be available
at https://github.com/cs-whh/DSASC
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15578" title="Abstract">arXiv:2312.15578</a> [<a href="/pdf/2312.15578" title="Download PDF">pdf</a>, <a href="/format/2312.15578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Subgoal Planning with Variational Autoencoders for Long-Horizon  Sparse Reward Robotic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+A">Anqing Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+S">Shengzeng Huo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+G">Guodong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenguang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Navarro-Alarcon%2C+D">David Navarro-Alarcon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The challenges inherent to long-horizon tasks in robotics persist due to the
typical inefficient exploration and sparse rewards in traditional reinforcement
learning approaches. To alleviate these challenges, we introduce a novel
algorithm, Variational Autoencoder-based Subgoal Inference (VAESI), to
accomplish long-horizon tasks through a divide-and-conquer manner. VAESI
consists of three components: a Variational Autoencoder (VAE)-based Subgoal
Generator, a Hindsight Sampler, and a Value Selector. The VAE-based Subgoal
Generator draws inspiration from the human capacity to infer subgoals and
reason about the final goal in the context of these subgoals. It is composed of
an explicit encoder model, engineered to generate subgoals, and an implicit
decoder model, designed to enhance the quality of the generated subgoals by
predicting the final goal. Additionally, the Hindsight Sampler selects valid
subgoals from an offline dataset to enhance the feasibility of the generated
subgoals. The Value Selector utilizes the value function in reinforcement
learning to filter the optimal subgoals from subgoal candidates. To validate
our method, we conduct several long-horizon tasks in both simulation and the
real world, including one locomotion task and three manipulation tasks. The
obtained quantitative and qualitative data indicate that our approach achieves
promising performance compared to other baseline methods. These experimental
results can be seen in the website
\url{https://sites.google.com/view/vaesi/home}.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15582" title="Abstract">arXiv:2312.15582</a> [<a href="/pdf/2312.15582" title="Download PDF">pdf</a>, <a href="/format/2312.15582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Fear: Exploring User Experiences in Virtual Reality Horror  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Christine Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinyi Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 7 tables, accepted by CHCHI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This preliminary study investigated user experiences in VR horror games,
highlighting fear-triggering and gender-based differences in perception. By
utilizing a scientifically validated and specially designed questionnaire, we
successfully collected questionnaire data from 23 subjects for an early
empirical study of fear induction in a virtual reality gaming environment. The
early findings suggest that visual restrictions and ambient sound-enhanced
realism may be more effective in intensifying the fear experience. Participants
exhibited a tendency to avoid playing alone or during nighttime, underscoring
the significant psychological impact of VR horror games. The study also
revealed a distinct gender difference in fear perception, with female
participants exhibiting a higher sensitivity to fear stimuli. However, the
preference for different types of horror games was not solely dominated by
males; it varied depending on factors such as the game's pace, its objectives,
and the nature of the fear stimulant.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15583" title="Abstract">arXiv:2312.15583</a> [<a href="/pdf/2312.15583" title="Download PDF">pdf</a>, <a href="/format/2312.15583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RMNAS: A Multimodal Neural Architecture Search Framework For Robust  Multimodal Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Licai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Multimodal sentiment analysis (MSA) finds extensive applications, but the
presence of missing modalities in real-world environments requires researchers
to enhance the robustness of models, often demanding significant efforts.
Multimodal neural architecture search (MNAS) is a more efficient approach.
However, current MNAS methods, while effective in integrating multi-level
information, are incapable of simultaneously searching for optimal operations
to extract modality-specific information. This weakens the robustness of the
model in addressing diverse scenarios. Moreover, these methods also fall short
in enhancing the capture of emotional cues. In this paper, we propose
robust-sentiment multimodal neural architecture search (RMNAS) framework.
Specifically, we utilize the Transformer as a unified architecture for various
modalities and incorporate a search for token mixers to enhance the encoding
capacity of individual modalities and improve robustness across diverse
scenarios. Subsequently, we leverage BM-NAS to integrate multi-level
information. Furthermore, we incorporate local sentiment variation trends to
guide the token mixers computation, enhancing the model's ability to capture
sentiment context. Experimental results demonstrate that our approach
outperforms or competitively matches existing state-of-the-art approaches in
incomplete multimodal learning, both in sentence-level and dialogue-level MSA
tasks, without the need for knowledge of incomplete learning.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15591" title="Abstract">arXiv:2312.15591</a> [<a href="/pdf/2312.15591" title="Download PDF">pdf</a>, <a href="/format/2312.15591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Neural Graph Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaxin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of big data and rapidly evolving information systems, efficient
and accurate data retrieval has become increasingly crucial. Neural graph
databases (NGDBs) have emerged as a powerful paradigm that combines the
strengths of graph databases (graph DBs) and neural networks to enable
efficient storage, retrieval, and analysis of graph-structured data. The usage
of neural embedding storage and complex neural logical query answering provides
NGDBs with generalization ability. When the graph is incomplete, by extracting
latent patterns and representations, neural graph databases can fill gaps in
the graph structure, revealing hidden relationships and enabling accurate query
answering. Nevertheless, this capability comes with inherent trade-offs, as it
introduces additional privacy risks to the database. Malicious attackers can
infer more sensitive information in the database using well-designed
combinatorial queries, such as by comparing the answer sets of where Turing
Award winners born before 1950 and after 1940 lived, the living places of
Turing Award winner Hinton are probably exposed, although the living places may
have been deleted in the training due to the privacy concerns. In this work,
inspired by the privacy protection in graph embeddings, we propose a
privacy-preserving neural graph database (P-NGDB) to alleviate the risks of
privacy leakage in NGDBs. We introduce adversarial training techniques in the
training stage to force the NGDBs to generate indistinguishable answers when
queried with private information, enhancing the difficulty of inferring
sensitive information through combinations of multiple innocuous queries.
Extensive experiment results on three datasets show that P-NGDB can effectively
protect private information in the graph database while delivering high-quality
public answers responses to queries.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15593" title="Abstract">arXiv:2312.15593</a> [<a href="/pdf/2312.15593" title="Download PDF">pdf</a>, <a href="/format/2312.15593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSNet: Disentangled Siamese Network with Neutral Calibration for Speech  Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chengxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">One persistent challenge in deep learning based speech emotion recognition
(SER) is the unconscious encoding of emotion-irrelevant factors (e.g., speaker
or phonetic variability), which limits the generalization of SER in practical
use. In this paper, we propose DSNet, a Disentangled Siamese Network with
neutral calibration, to meet the demand for a more robust and explainable SER
model. Specifically, we introduce an orthogonal feature disentanglement module
to explicitly project the high-level representation into two distinct
subspaces. Later, we propose a novel neutral calibration mechanism to encourage
one subspace to capture sufficient emotion-irrelevant information. In this way,
the other one can better isolate and emphasize the emotion-relevant information
within speech signals. Experimental results on two popular benchmark datasets
demonstrate the superiority of DSNet over various state-of-the-art methods for
speaker-independent SER.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15594" title="Abstract">arXiv:2312.15594</a> [<a href="/pdf/2312.15594" title="Download PDF">pdf</a>, <a href="/format/2312.15594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Approximate Optimal Diagonal Preconditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+W">Wenzhi Gao</a>, 
<a href="/search/math?searchtype=author&query=Qu%2C+Z">Zhaonan Qu</a>, 
<a href="/search/math?searchtype=author&query=Udell%2C+M">Madeleine Udell</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+Y">Yinyu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the problem of finding the optimal diagonal preconditioner for a
positive definite matrix. Although this problem has been shown to be solvable
and various methods have been proposed, none of the existing approaches are
scalable to matrices of large dimension, or when access is limited to black-box
matrix-vector products, thereby significantly limiting their practical
application. In view of these challenges, we propose practical algorithms
applicable to finding approximate optimal diagonal preconditioners of large
sparse systems. Our approach is based on the idea of dimension reduction, and
combines techniques from semi-definite programming (SDP), random projection,
semi-infinite programming (SIP), and column generation. Numerical experiments
demonstrate that our method scales to sparse matrices of size greater than
$10^7$. Notably, our approach is efficient and implementable using only
black-box matrix-vector product operations, making it highly practical for a
wide variety of applications.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15596" title="Abstract">arXiv:2312.15596</a> [<a href="/pdf/2312.15596" title="Download PDF">pdf</a>, <a href="/format/2312.15596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Domain-Based Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Si Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+P+W+L">Philip W. L. Fong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Protection domains are one of the most enduring concepts in Access Control.
Entities with identical access control characteristics are grouped under the
same protection domain, and domain-based policies assign access privileges to
the protection domain as a whole. With the advent of the Internet of Things
(IoT), devices play the roles of both subjects and objects. Domain-based
policies are particularly suited to support this symmetry of roles.
<br />This paper studies the mining of domain-based policies from incomplete access
logs. We began by building a theory of domain-based policies, resulting in a
polynomial-time algorithm that constructs the optimal domain-based policy out
of a given access control matrix. We then showed that the problem of
domain-based policy mining (DBPM) and the related problem of mining policies
for domain and type enforcement (DTEPM) are both NP-complete. Next, we looked
at the practical problem of using a MaxSAT solver to solve DBPM. We devised
sophisticated encodings for this purpose, and empirically evaluated their
relative performance. This paper thus lays the groundwork for future study of
DBPM.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15599" title="Abstract">arXiv:2312.15599</a> [<a href="/pdf/2312.15599" title="Download PDF">pdf</a>, <a href="/format/2312.15599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preliminary Study on Incremental Learning for Large Language Model-based  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tianhao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhijian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Adapting Large Language Models for recommendation (LLM4Rec)has garnered
substantial attention and demonstrated promising results. However, the
challenges of practically deploying LLM4Rec are largely unexplored, with the
need for incremental adaptation to evolving user preferences being a critical
concern. Nevertheless, the suitability of traditional incremental learning
within LLM4Rec remains ambiguous, given the unique characteristics of LLMs. In
this study, we empirically evaluate the commonly used incremental learning
strategies (full retraining and fine-tuning) for LLM4Rec. Surprisingly, neither
approach leads to evident improvements in LLM4Rec's performance. Rather than
directly dismissing the role of incremental learning, we ascribe this lack of
anticipated performance improvement to the mismatch between the
LLM4Recarchitecture and incremental learning: LLM4Rec employs a single
adaptation module for learning recommendation, hampering its ability to
simultaneously capture long-term and short-term user preferences in the
incremental learning context. To validate this speculation, we develop a Long-
and Short-term Adaptation-aware Tuning (LSAT) framework for LLM4Rec incremental
learning. Instead of relying on a single adaptation module, LSAT utilizes two
adaptation modules to separately learn long-term and short-term user
preferences. Empirical results demonstrate that LSAT could enhance performance,
validating our speculation.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15600" title="Abstract">arXiv:2312.15600</a> [<a href="/pdf/2312.15600" title="Download PDF">pdf</a>, <a href="/format/2312.15600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware Communication for Multi-agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 23nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Effective communication protocols in multi-agent reinforcement learning
(MARL) are critical to fostering cooperation and enhancing team performance. To
leverage communication, many previous works have proposed to compress local
information into a single message and broadcast it to all reachable agents.
This simplistic messaging mechanism, however, may fail to provide adequate,
critical, and relevant information to individual agents, especially in severely
bandwidth-limited scenarios. This motivates us to develop context-aware
communication schemes for MARL, aiming to deliver personalized messages to
different agents. Our communication protocol, named CACOM, consists of two
stages. In the first stage, agents exchange coarse representations in a
broadcast fashion, providing context for the second stage. Following this,
agents utilize attention mechanisms in the second stage to selectively generate
messages personalized for the receivers. Furthermore, we employ the learned
step size quantization (LSQ) technique for message quantization to reduce the
communication overhead. To evaluate the effectiveness of CACOM, we integrate it
with both actor-critic and value-based MARL algorithms. Empirical results on
cooperative benchmark tasks demonstrate that CACOM provides evident performance
gains over baselines under communication-constrained scenarios.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15603" title="Abstract">arXiv:2312.15603</a> [<a href="/pdf/2312.15603" title="Download PDF">pdf</a>, <a href="/format/2312.15603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Split-and-Privatize Framework for Large Language Model Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xicong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jue Hong</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+B">Bing Duan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zirui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yunlong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Fine-tuning is a prominent technique to adapt a pre-trained language model to
downstream scenarios. In parameter-efficient fine-tuning, only a small subset
of modules are trained over the downstream datasets, while leaving the rest of
the pre-trained model frozen to save computation resources. In recent years, a
popular productization form arises as Model-as-a-Service (MaaS), in which
vendors provide abundant pre-trained language models, server resources and core
functions, and customers can fine-tune, deploy and invoke their customized
model by accessing the one-stop MaaS with their own private dataset. In this
paper, we identify the model and data privacy leakage risks in MaaS
fine-tuning, and propose a Split-and-Privatize (SAP) framework, which manage to
mitigate the privacy issues by adapting the existing split learning
architecture. The proposed SAP framework is sufficiently investigated by
experiments, and the results indicate that it can enhance the empirical privacy
by 62% at the cost of 1% model performance degradation on the Stanford
Sentiment Treebank dataset.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15606" title="Abstract">arXiv:2312.15606</a> [<a href="/pdf/2312.15606" title="Download PDF">pdf</a>, <a href="/ps/2312.15606" title="Download PostScript">ps</a>, <a href="/format/2312.15606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Target Detection Algorithm in Traffic Scenes Based on Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xinyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruixuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, having passed the preliminary review by experts, about to be submitted to a relevant conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research presents a novel active detection model utilizing deep
reinforcement learning to accurately detect traffic objects in real-world
scenarios. The model employs a deep Q-network based on LSTM-CNN that identifies
and aligns target zones with specific categories of traffic objects through
implementing a top-down approach with efficient feature extraction of the
environment. The model integrates historical and current actions and
observations to make a comprehensive analysis. The design of the state space
and reward function takes into account the impact of time steps to enable the
model to complete the task in fewer steps. Tests conducted demonstrate the
model's proficiency, exhibiting exceptional precision and performance in
locating traffic signal lights and speed limit signs. The findings of this
study highlight the efficacy and potential of the deep reinforcement
learning-based active detection model in traffic-related applications,
underscoring its robust detection abilities and promising performance.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15608" title="Abstract">arXiv:2312.15608</a> [<a href="/pdf/2312.15608" title="Download PDF">pdf</a>, <a href="/format/2312.15608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated learning-outcome prediction with multi-layer privacy  protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yupei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuangshuang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+X">Xuequn Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, 3 tables. This preprint will be published in Frontiers of Computer Science on Dec 15, 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Frontiers of Computer Science, 2024,18(6):186604
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Learning-outcome prediction (LOP) is a long-standing and critical problem in
educational routes. Many studies have contributed to developing effective
models while often suffering from data shortage and low generalization to
various institutions due to the privacy-protection issue. To this end, this
study proposes a distributed grade prediction model, dubbed FecMap, by
exploiting the federated learning (FL) framework that preserves the private
data of local clients and communicates with others through a global generalized
model. FecMap considers local subspace learning (LSL), which explicitly learns
the local features against the global features, and multi-layer privacy
protection (MPP), which hierarchically protects the private features, including
model-shareable features and not-allowably shared features, to achieve
client-specific classifiers of high performance on LOP per institution. FecMap
is then achieved in an iteration manner with all datasets distributed on
clients by training a local neural network composed of a global part, a local
part, and a classification head in clients and averaging the global parts from
clients on the server. To evaluate the FecMap model, we collected three
higher-educational datasets of student academic records from engineering
majors. Experiment results manifest that FecMap benefits from the proposed LSL
and MPP and achieves steady performance on the task of LOP, compared with the
state-of-the-art models. This study makes a fresh attempt at the use of
federated learning in the learning-analytical task, potentially paving the way
to facilitating personalized education with privacy protection.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15610" title="Abstract">arXiv:2312.15610</a> [<a href="/pdf/2312.15610" title="Download PDF">pdf</a>, <a href="/format/2312.15610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Learning Geometric Eigen-Lengths Crucial for Fitting Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+Y">Yijia Weng</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+K">Kaichun Mo</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruoxi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L+J">Leonidas J. Guibas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023. Project page: <a href="https://yijiaweng.github.io/geo-eigen-length">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:36958-36977, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Some extremely low-dimensional yet crucial geometric eigen-lengths often
determine the success of some geometric tasks. For example, the height of an
object is important to measure to check if it can fit between the shelves of a
cabinet, while the width of a couch is crucial when trying to move it through a
doorway. Humans have materialized such crucial geometric eigen-lengths in
common sense since they are very useful in serving as succinct yet effective,
highly interpretable, and universal object representations. However, it remains
obscure and underexplored if learning systems can be equipped with similar
capabilities of automatically discovering such key geometric quantities from
doing tasks. In this work, we therefore for the first time formulate and
propose a novel learning problem on this question and set up a benchmark suite
including tasks, data, and evaluation metrics for studying the problem. We
focus on a family of common fitting tasks as the testbed for the proposed
learning problem. We explore potential solutions and demonstrate the
feasibility of learning eigen-lengths from simply observing successful and
failed fitting trials. We also attempt geometric grounding for more accurate
eigen-length measurement and study the reusability of the learned eigen-lengths
across multiple tasks. Our work marks the first exploratory step toward
learning crucial geometric eigen-lengths and we hope it can inspire future
research in tackling this important yet underexplored problem.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15612" title="Abstract">arXiv:2312.15612</a> [<a href="/pdf/2312.15612" title="Download PDF">pdf</a>, <a href="/format/2312.15612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APTv2: Benchmarking Animal Pose Estimation and Tracking with a  Large-scale Dataset and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yingqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yufei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Animal Pose Estimation and Tracking (APT) is a critical task in detecting and
monitoring the keypoints of animals across a series of video frames, which is
essential for understanding animal behavior. Past works relating to animals
have primarily focused on either animal tracking or single-frame animal pose
estimation only, neglecting the integration of both aspects. The absence of
comprehensive APT datasets inhibits the progression and evaluation of animal
pose estimation and tracking methods based on videos, thereby constraining
their real-world applications. To fill this gap, we introduce APTv2, the
pioneering large-scale benchmark for animal pose estimation and tracking. APTv2
comprises 2,749 video clips filtered and collected from 30 distinct animal
species. Each video clip includes 15 frames, culminating in a total of 41,235
frames. Following meticulous manual annotation and stringent verification, we
provide high-quality keypoint and tracking annotations for a total of 84,611
animal instances, split into easy and hard subsets based on the number of
instances that exists in the frame. With APTv2 as the foundation, we establish
a simple baseline method named \posetrackmethodname and provide benchmarks for
representative models across three tracks: (1) single-frame animal pose
estimation track to evaluate both intra- and inter-domain transfer learning
performance, (2) low-data transfer and generalization track to evaluate the
inter-species domain generalization performance, and (3) animal pose tracking
track. Our experimental results deliver key empirical insights, demonstrating
that APTv2 serves as a valuable benchmark for animal pose estimation and
tracking. It also presents new challenges and opportunities for future
research. The code and dataset are released at
\href{https://github.com/ViTAE-Transformer/APTv2}{https://github.com/ViTAE-Transformer/APTv2}.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15613" title="Abstract">arXiv:2312.15613</a> [<a href="/pdf/2312.15613" title="Download PDF">pdf</a>, <a href="/format/2312.15613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum bound principle preserving and energy decreasing exponential  time differencing schemes for the matrix-valued Allen-Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yaru Liu</a>, 
<a href="/search/math?searchtype=author&query=Quan%2C+C">Chaoyu Quan</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work delves into the exponential time differencing (ETD) schemes for the
matrix-valued Allen-Cahn equation. In fact, the maximum bound principle (MBP)
for the first- and second-order ETD schemes is presented in a prior publication
[SIAM Review, 63(2), 2021], assuming a symmetric initial matrix field.
Noteworthy is our novel contribution, demonstrating that the first- and
second-order ETD schemes for the matrix-valued Allen-Cahn equation -- both
being linear schemes -- unconditionally preserve the MBP, even in instances of
nonsymmetric initial conditions. Additionally, we prove that these two ETD
schemes preserve the energy dissipation law unconditionally for the
matrix-valued Allen-Cahn equation. Some numerical examples are presented to
verify our theoretical results and to simulate the evolution of corresponding
matrix fields.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15614" title="Abstract">arXiv:2312.15614</a> [<a href="/pdf/2312.15614" title="Download PDF">pdf</a>, <a href="/format/2312.15614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on  Software Engineering Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wentao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jidong Ge</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Liguo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Pre-trained models (PTMs) have achieved great success in various Software
Engineering (SE) downstream tasks following the ``pre-train then fine-tune''
paradigm. As fully fine-tuning all parameters of PTMs can be computationally
expensive, a widely used solution is parameter-efficient fine-tuning (PEFT),
which freezes PTMs while introducing extra parameters. Though work has been
done to test PEFT methods in the SE field, a comprehensive evaluation is still
lacking. This paper aims to fill in this gap by evaluating the effectiveness of
five PEFT methods on eight PTMs and four SE downstream tasks. For different
tasks and PEFT methods, we seek answers to the following research questions: 1)
Is it more effective to use PTMs trained specifically on source code, or is it
sufficient to use PTMs trained on natural language text? 2) What is the impact
of varying model sizes? 3) How does the model architecture affect the
performance? Besides effectiveness, we also discuss the efficiency of PEFT
methods, concerning the costs of required training time and GPU resource
consumption. We hope that our findings can provide a deeper understanding of
PEFT methods on various PTMs and SE downstream tasks. All the codes and data
are available at \url{https://github.com/zwtnju/PEFT.git}.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15616" title="Abstract">arXiv:2312.15616</a> [<a href="/pdf/2312.15616" title="Download PDF">pdf</a>, <a href="/format/2312.15616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty as a Predictor: Leveraging Self-Supervised Learning for  Zero-Shot MOS Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravuri%2C+A">Aditya Ravuri</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+E">Erica Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Yamagishi%2C+J">Junichi Yamagishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, sasb draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Predicting audio quality in voice synthesis and conversion systems is a
critical yet challenging task, especially when traditional methods like Mean
Opinion Scores (MOS) are cumbersome to collect at scale. This paper addresses
the gap in efficient audio quality prediction, especially in low-resource
settings where extensive MOS data from large-scale listening tests may be
unavailable. We demonstrate that uncertainty measures derived from
out-of-the-box pretrained self-supervised learning (SSL) models, such as
wav2vec, correlate with MOS scores. These findings are based on data from the
2022 and 2023 VoiceMOS challenges. We explore the extent of this correlation
across different models and language contexts, revealing insights into how
inherent uncertainties in SSL models can serve as effective proxies for audio
quality assessment. In particular, we show that the contrastive wav2vec models
are the most performant in all settings.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15617" title="Abstract">arXiv:2312.15617</a> [<a href="/pdf/2312.15617" title="Download PDF">pdf</a>, <a href="/format/2312.15617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GanFinger: GAN-Based Fingerprint Generation for Deep Neural Network  Ownership Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Huali Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+A">Anli Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaojun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Pei-Gen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chong-zhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep neural networks (DNNs) are extensively employed in a wide range of
application scenarios. Generally, training a commercially viable neural network
requires significant amounts of data and computing resources, and it is easy
for unauthorized users to use the networks illegally. Therefore, network
ownership verification has become one of the most crucial steps in safeguarding
digital assets. To verify the ownership of networks, the existing network
fingerprinting approaches perform poorly in the aspects of efficiency,
stealthiness, and discriminability. To address these issues, we propose a
network fingerprinting approach, named as GanFinger, to construct the network
fingerprints based on the network behavior, which is characterized by network
outputs of pairs of original examples and conferrable adversarial examples.
Specifically, GanFinger leverages Generative Adversarial Networks (GANs) to
effectively generate conferrable adversarial examples with imperceptible
perturbations. These examples can exhibit identical outputs on copyrighted and
pirated networks while producing different results on irrelevant networks.
Moreover, to enhance the accuracy of fingerprint ownership verification, the
network similarity is computed based on the accuracy-robustness distance of
fingerprint examples'outputs. To evaluate the performance of GanFinger, we
construct a comprehensive benchmark consisting of 186 networks with five
network structures and four popular network post-processing techniques. The
benchmark experiments demonstrate that GanFinger significantly outperforms the
state-of-the-arts in efficiency, stealthiness, and discriminability. It
achieves a remarkable 6.57 times faster in fingerprint generation and boosts
the ARUC value by 0.175, resulting in a relative improvement of about 26%.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15622" title="Abstract">arXiv:2312.15622</a> [<a href="/pdf/2312.15622" title="Download PDF">pdf</a>, <a href="/format/2312.15622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Face Image Coding via StyleGAN Prior: Towards Compression for  Human-Machine Collaborative Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Libiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siwei Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The accelerated proliferation of visual content and the rapid development of
machine vision technologies bring significant challenges in delivering visual
data on a gigantic scale, which shall be effectively represented to satisfy
both human and machine requirements. In this work, we investigate how
hierarchical representations derived from the advanced generative prior
facilitate constructing an efficient scalable coding paradigm for human-machine
collaborative vision. Our key insight is that by exploiting the StyleGAN prior,
we can learn three-layered representations encoding hierarchical semantics,
which are elaborately designed into the basic, middle, and enhanced layers,
supporting machine intelligence and human visual perception in a progressive
fashion. With the aim of achieving efficient compression, we propose the
layer-wise scalable entropy transformer to reduce the redundancy between
layers. Based on the multi-task scalable rate-distortion objective, the
proposed scheme is jointly optimized to achieve optimal machine analysis
performance, human perception experience, and compression ratio. We validate
the proposed paradigm's feasibility in face image compression. Extensive
qualitative and quantitative experimental results demonstrate the superiority
of the proposed paradigm over the latest compression standard Versatile Video
Coding (VVC) in terms of both machine analysis as well as human perception at
extremely low bitrates ($&lt;0.01$ bpp), offering new insights for human-machine
collaborative compression.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15626" title="Abstract">arXiv:2312.15626</a> [<a href="/pdf/2312.15626" title="Download PDF">pdf</a>, <a href="/ps/2312.15626" title="Download PostScript">ps</a>, <a href="/format/2312.15626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDF-star2Vec: RDF-star Graph Embeddings for Data Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Egami%2C+S">Shusaku Egami</a>, 
<a href="/search/cs?searchtype=author&query=Ugai%2C+T">Takanori Ugai</a>, 
<a href="/search/cs?searchtype=author&query=Oota%2C+M">Masateru Oota</a>, 
<a href="/search/cs?searchtype=author&query=Matsushita%2C+K">Kyoumoto Matsushita</a>, 
<a href="/search/cs?searchtype=author&query=Kawamura%2C+T">Takahiro Kawamura</a>, 
<a href="/search/cs?searchtype=author&query=Kozaki%2C+K">Kouji Kozaki</a>, 
<a href="/search/cs?searchtype=author&query=Fukuda%2C+K">Ken Fukuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, and this paper has been accepted by IEEE Access
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, Volume 11, pp.142030-142042, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge Graphs (KGs) such as Resource Description Framework (RDF) data
represent relationships between various entities through the structure of
triples (&lt;subject, predicate, object&gt;). Knowledge graph embedding (KGE) is
crucial in machine learning applications, specifically in node classification
and link prediction tasks. KGE remains a vital research topic within the
semantic web community. RDF-star introduces the concept of a quoted triple
(QT), a specific form of triple employed either as the subject or object within
another triple. Moreover, RDF-star permits a QT to act as compositional
entities within another QT, thereby enabling the representation of recursive,
hyper-relational KGs with nested structures. However, existing KGE models fail
to adequately learn the semantics of QTs and entities, primarily because they
do not account for RDF-star graphs containing multi-leveled nested QTs and
QT-QT relationships. This study introduces RDF-star2Vec, a novel KGE model
specifically designed for RDF-star graphs. RDF-star2Vec introduces graph walk
techniques that enable probabilistic transitions between a QT and its
compositional entities. Feature vectors for QTs, entities, and relations are
derived from generated sequences through the structured skip-gram model.
Additionally, we provide a dataset and a benchmarking framework for data mining
tasks focused on complex RDF-star graphs. Evaluative experiments demonstrated
that RDF-star2Vec yielded superior performance compared to recent extensions of
RDF2Vec in various tasks including classification, clustering, entity
relatedness, and QT similarity.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15628" title="Abstract">arXiv:2312.15628</a> [<a href="/pdf/2312.15628" title="Download PDF">pdf</a>, <a href="/format/2312.15628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced SNR-Aware Distillation for Guided Text-to-Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Diffusion models have demonstrated promising results in text-to-audio
generation tasks. However, their practical usability is hindered by slow
sampling speeds, limiting their applicability in high-throughput scenarios. To
address this challenge, progressive distillation methods have been effective in
producing more compact and efficient models. Nevertheless, these methods
encounter issues with unbalanced weights at both high and low noise levels,
potentially impacting the quality of generated samples. In this paper, we
propose the adaptation of the progressive distillation method to text-to-audio
generation tasks and introduce the Balanced SNR-Aware~(BSA) method, an enhanced
loss-weighting mechanism for diffusion distillation. The BSA method employs a
balanced approach to weight the loss for both high and low noise levels. We
evaluate our proposed method on the AudioCaps dataset and report experimental
results showing superior performance during the reverse diffusion process
compared to previous distillation methods with the same number of sampling
steps. Furthermore, the BSA method allows for a significant reduction in
sampling steps from 200 to 25, with minimal performance degradation when
compared to the original teacher models.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15630" title="Abstract">arXiv:2312.15630</a> [<a href="/pdf/2312.15630" title="Download PDF">pdf</a>, <a href="/format/2312.15630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesh-LOAM: Real-time Mesh-Based LiDAR Odometry and Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanjin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianke Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Despite having achieved real-time performance in mesh construction, most of
the current LiDAR odometry and meshing methods may struggle to deal with
complex scenes due to relying on explicit meshing schemes. They are usually
sensitive to noise. To overcome these limitations, we propose a real-time
mesh-based LiDAR odometry and mapping approach for large-scale scenes via
implicit reconstruction and a parallel spatial-hashing scheme. To efficiently
reconstruct triangular meshes, we suggest an incremental voxel meshing method
that updates every scan by traversing each point once and compresses space via
a scalable partition module. By taking advantage of rapid accessing triangular
meshes at any time, we design point-to-mesh odometry with location and
feature-based data association to estimate the poses between the incoming point
clouds and the recovered triangular meshes. The experimental results on four
datasets demonstrate the effectiveness of our proposed approach in generating
accurate motion trajectories and environmental mesh maps.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15631" title="Abstract">arXiv:2312.15631</a> [<a href="/pdf/2312.15631" title="Download PDF">pdf</a>, <a href="/format/2312.15631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instrumental Variables based DREM for Online Asymptotic Identification  of Perturbed Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Existing online continuous-time parameter estimation laws provide exact
(asymptotic/exponential or finite/fixed time) identification of dynamical
linear/nonlinear systems parameters only if the external perturbations are
equaled to zero or represented as a vanishing and absolutely integrable
function of time. However, real systems are generally affected by non-zero and
non-decaying disturbances, in the presence of which the above-mentioned
identification approaches ensure only boundedness of a parameter estimation
error. The main goal of this study is to close this gap and develop a novel
online continuous-time parameter estimator, which guarantees exact asymptotic
identification of unknown parameters of linear systems in the presence of
unknown but bounded perturbations. To achieve the aforementioned goal, it is
proposed to augment the deeply investigated Dynamic Regressor Extension and
Mixing (DREM) procedure with the novel Instrumental Variables (IV) based
extension scheme with averaging. Such an approach allows one to obtain a set of
scalar regression equations with asymptotically vanishing perturbation even if
the initial disturbance that affects the plant is only bounded. It is
rigorously proved that a gradient estimation law designed on the basis of such
scalar regressions ensures online asymptotic identification of the parameters
of the perturbed linear systems if the disturbance and control input do not
include signals with common frequencies, which is a weak assumption for
applications. Theoretical results are illustrated and supported with adequate
numerical simulations.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15633" title="Abstract">arXiv:2312.15633</a> [<a href="/pdf/2312.15633" title="Download PDF">pdf</a>, <a href="/format/2312.15633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuLA-GAN: Multi-Level Attention GAN for Enhanced Underwater Visibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakht%2C+A+B">Ahsan Baidar Bakht</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zikai Jia</a>, 
<a href="/search/cs?searchtype=author&query=Din%2C+M+u">Muhayy ud Din</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+W">Waseem Akram</a>, 
<a href="/search/cs?searchtype=author&query=Soud%2C+L+S">Lyes Saad Soud</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+L">Lakmal Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Defu Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shaoming He</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The underwater environment presents unique challenges, including color
distortions, reduced contrast, and blurriness, hindering accurate analysis. In
this work, we introduce MuLA-GAN, a novel approach that leverages the
synergistic power of Generative Adversarial Networks (GANs) and Multi-Level
Attention mechanisms for comprehensive underwater image enhancement. The
integration of Multi-Level Attention within the GAN architecture significantly
enhances the model's capacity to learn discriminative features crucial for
precise image restoration. By selectively focusing on relevant spatial and
multi-level features, our model excels in capturing and preserving intricate
details in underwater imagery, essential for various applications. Extensive
qualitative and quantitative analyses on diverse datasets, including UIEB test
dataset, UIEB challenge dataset, U45, and UCCS dataset, highlight the superior
performance of MuLA-GAN compared to existing state-of-the-art methods.
Experimental evaluations on a specialized dataset tailored for bio-fouling and
aquaculture applications demonstrate the model's robustness in challenging
environmental conditions. On the UIEB test dataset, MuLA-GAN achieves
exceptional PSNR (25.59) and SSIM (0.893) scores, surpassing Water-Net, the
second-best model, with scores of 24.36 and 0.885, respectively. This work not
only addresses a significant research gap in underwater image enhancement but
also underscores the pivotal role of Multi-Level Attention in enhancing GANs,
providing a novel and comprehensive framework for restoring underwater image
quality.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15634" title="Abstract">arXiv:2312.15634</a> [<a href="/pdf/2312.15634" title="Download PDF">pdf</a>, <a href="/ps/2312.15634" title="Download PostScript">ps</a>, <a href="/format/2312.15634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Feature Signal Transmission with Block-based Haptic Data  Reduction for Time-delayed Teleoperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanle Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper presents an innovative feature signal transmission approach
incorpo-rating block-based haptic data reduction to address time-delayed
teleoperation. Numerous data reduction techniques rely on perceptual deadband
(DB). In the preceding block-based approaches, the whole block within the DB is
discarded. However, disregarding all signals within the DB loses too much
information and hinders effective haptic signal tracking, as these signals
contain valuable infor-mation for signal reconstruction. Consequently, we
propose a feature signal transmission approach based on the block algorithm
that aggregates samples as a unit, enabling high-quality haptic data reduction.
In our proposed approach, we employ max-pooling to extract feature signals from
the signals within the DB. These feature signals are then transmitted by
adjusting the content of the trans-mission block. This methodology enables the
transmission of more useful infor-mation without introducing additional delay,
aside from the inherent algorithmic delay. Experimental results demonstrate the
superiority of our approach over oth-er state-of-the-art (SOTA) methods on
various assessment measures under dis-tinct channel delays.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15636" title="Abstract">arXiv:2312.15636</a> [<a href="/pdf/2312.15636" title="Download PDF">pdf</a>, <a href="/format/2312.15636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifting by Image -- Leveraging Image Cues for Accurate 3D Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The "lifting from 2D pose" method has been the dominant approach to 3D Human
Pose Estimation (3DHPE) due to the powerful visual analysis ability of 2D pose
estimators. Widely known, there exists a depth ambiguity problem when
estimating solely from 2D pose, where one 2D pose can be mapped to multiple 3D
poses. Intuitively, the rich semantic and texture information in images can
contribute to a more accurate "lifting" procedure. Yet, existing research
encounters two primary challenges. Firstly, the distribution of image data in
3D motion capture datasets is too narrow because of the laboratorial
environment, which leads to poor generalization ability of methods trained with
image information. Secondly, effective strategies for leveraging image
information are lacking. In this paper, we give new insight into the cause of
poor generalization problems and the effectiveness of image features. Based on
that, we propose an advanced framework. Specifically, the framework consists of
two stages. First, we enable the keypoints to query and select the beneficial
features from all image patches. To reduce the keypoints attention to
inconsequential background features, we design a novel Pose-guided Transformer
Layer, which adaptively limits the updates to unimportant image patches. Then,
through a designed Adaptive Feature Selection Module, we prune less significant
image patches from the feature map. In the second stage, we allow the keypoints
to further emphasize the retained critical image features. This progressive
learning approach prevents further training on insignificant image features.
Experimental results show that our model achieves state-of-the-art performance
on both the Human3.6M dataset and the MPI-INF-3DHP dataset.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15639" title="Abstract">arXiv:2312.15639</a> [<a href="/pdf/2312.15639" title="Download PDF">pdf</a>, <a href="/ps/2312.15639" title="Download PostScript">ps</a>, <a href="/format/2312.15639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinated Planning of Offshore Charging Stations and Electrified  Ships: A Case Study on Shanghai-Busan Maritime Route
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+H">Hanqi Tao</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+W">Wentao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hongcai Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ran Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Despite the success of electric vehicles on land, electrification of maritime
ships is challenged by the dilemma of range anxiety and cargo-carrying
capacity. The longer range requires larger batteries, which inevitably eat up
the precious cargo space and weight. This paper breaks new ground by proposing
a coordinated planning model for offshore charging stations (OCSs) and electric
ships (ESs), marking a first in this field. Strategically situated OCS can
partition a long maritime route into several shorter segments, which in turn
lead to smaller batteries and thus larger cargo capacities. The research
analyzed the impact of maritime geographical conditions on the placement and
sizing process and provided insights into the trade-offs between battery size,
cargo-carrying capacity, and the cruising range of different types of
electrified ships. Using real Automatic Identification System (AIS) data, we
estimated the economic feasibility of the Shanghai-Busan high-traffic maritime
route and conducted a sensitivity analysis on factors affecting its economic
viability. The results show that installing OCS can significantly reduce the
propulsion cost compared with ESs without OCS and traditional internal
combustion engine (ICE) ships.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15640" title="Abstract">arXiv:2312.15640</a> [<a href="/pdf/2312.15640" title="Download PDF">pdf</a>, <a href="/format/2312.15640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Report of the DOE/NSF Workshop on Correctness in Scientific Computing,  June 2023, Orlando, FL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gokhale%2C+M">Maya Gokhale</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Mayo%2C+J">Jackson Mayo</a>, 
<a href="/search/cs?searchtype=author&query=Nagarakatte%2C+S">Santosh Nagarakatte</a>, 
<a href="/search/cs?searchtype=author&query=Rubio-Gonz%C3%A1lez%2C+C">Cindy Rubio-Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+S+F">Stephen F. Siegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages. DOE/NSF Workshop on Correctness in Scientific Computing (CSC 2023) was a PLDI 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This report is a digest of the DOE/NSF Workshop on Correctness in Scientific
Computing (CSC'23) held on June 17, 2023, as part of the Federated Computing
Research Conference (FCRC) 2023. CSC was conceived by DOE and NSF to address
the growing concerns about correctness among those who employ computational
methods to perform large-scale scientific simulations. These concerns have
escalated, given the complexity, scale, and heterogeneity of today's HPC
software and hardware. If correctness is not proactively addressed, there is
the risk of producing flawed science on top of unacceptable productivity losses
faced by computational scientists and engineers. HPC systems are beginning to
include data-driven methods, including machine learning and surrogate models,
and their impact on overall HPC system correctness was also felt urgent to
discuss.
<br />Stakeholders of correctness in this space were identified to belong to
several sub-disciplines of computer science; from computer architecture
researchers who design special-purpose hardware that offers high energy
efficiencies; numerical algorithm designers who develop efficient computational
schemes based on reduced precision as well as reduced data movement; all the
way to researchers in programming language and formal methods who seek
methodologies for correct compilation and verification. To include attendees
with such a diverse set of backgrounds, CSC was held during the Federated
Computing Research Conference (FCRC) 2023.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15641" title="Abstract">arXiv:2312.15641</a> [<a href="/pdf/2312.15641" title="Download PDF">pdf</a>, <a href="/format/2312.15641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalising the Double-Pushout Approach to Graph Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%B6ldner%2C+R">Robert S&#xf6;ldner</a>, 
<a href="/search/cs?searchtype=author&query=Plump%2C+D">Detlef Plump</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this paper, we utilize Isabelle/HOL to develop a formal framework for the
basic theory of double-pushout graph transformation. Our work includes defining
essential concepts like graphs, morphisms, pushouts, and pullbacks, and
demonstrating their properties. We establish the uniqueness of derivations,
drawing upon Rosens 1975 research, and verify the Church-Rosser theorem using
Ehrigs and Kreowskis 1976 proof, thereby demonstrating the effectiveness of our
formalisation approach. The paper details our methodology in employing
Isabelle/HOL, including key design decisions that shaped the current iteration.
We explore the technical complexities involved in applying higher-order logic,
aiming to give readers an insightful perspective into the engaging aspects of
working with an Interactive Theorem Prover. This work emphasizes the increasing
importance of formal verification tools in clarifying complex mathematical
concepts.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15643" title="Abstract">arXiv:2312.15643</a> [<a href="/pdf/2312.15643" title="Download PDF">pdf</a>, <a href="/format/2312.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abductive Logical Reasoning on Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaxin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianshi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Abductive reasoning is logical reasoning that makes educated guesses to infer
the most likely reasons to explain the observations. However, the abductive
logical reasoning over knowledge graphs (KGs) is underexplored in KG
literature. In this paper, we initially and formally raise the task of
abductive logical reasoning over KGs, which involves inferring the most
probable logic hypothesis from the KGs to explain an observed entity set.
Traditional approaches use symbolic methods, like searching, to tackle the
knowledge graph problem. However, the symbolic methods are unsuitable for this
task, because the KGs are naturally incomplete, and the logical hypotheses can
be complex with multiple variables and relations. To address these issues, we
propose a generative approach to create logical expressions based on
observations. First, we sample hypothesis-observation pairs from the KG and use
supervised training to train a generative model that generates hypotheses from
observations. Since supervised learning only minimizes structural differences
between generated and reference hypotheses, higher structural similarity does
not guarantee a better explanation for observations. To tackle this issue, we
introduce the Reinforcement Learning from the Knowledge Graph (RLF-KG) method,
which minimizes the differences between observations and conclusions drawn from
the generated hypotheses according to the KG. Experimental results demonstrate
that transformer-based generative models can generate logical explanations
robustly and efficiently. Moreover, with the assistance of RLF-KG, the
generated hypothesis can provide better explanations for the observations, and
the method of supervised learning with RLF-KG achieves state-of-the-art results
on abductive knowledge graph reasoning on three widely used KGs.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15644" title="Abstract">arXiv:2312.15644</a> [<a href="/pdf/2312.15644" title="Download PDF">pdf</a>, <a href="/format/2312.15644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UVAGaze: Unsupervised 1-to-2 Views Adaptation for Gaze Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruicong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024. Code has been released at <a href="https://github.com/MickeyLLG/UVAGaze">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gaze estimation has become a subject of growing interest in recent research.
Most of the current methods rely on single-view facial images as input. Yet, it
is hard for these approaches to handle large head angles, leading to potential
inaccuracies in the estimation. To address this issue, adding a second-view
camera can help better capture eye appearance. However, existing multi-view
methods have two limitations. 1) They require multi-view annotations for
training, which are expensive. 2) More importantly, during testing, the exact
positions of the multiple cameras must be known and match those used in
training, which limits the application scenario. To address these challenges,
we propose a novel 1-view-to-2-views (1-to-2 views) adaptation solution in this
paper, the Unsupervised 1-to-2 Views Adaptation framework for Gaze estimation
(UVAGaze). Our method adapts a traditional single-view gaze estimator for
flexibly placed dual cameras. Here, the "flexibly" means we place the dual
cameras in arbitrary places regardless of the training data, without knowing
their extrinsic parameters. Specifically, the UVAGaze builds a dual-view mutual
supervision adaptation strategy, which takes advantage of the intrinsic
consistency of gaze directions between both views. In this way, our method can
not only benefit from common single-view pre-training, but also achieve more
advanced dual-view gaze estimation. The experimental results show that a
single-view estimator, when adapted for dual views, can achieve much higher
accuracy, especially in cross-dataset settings, with a substantial improvement
of 47.0%. Project page: https://github.com/MickeyLLG/UVAGaze.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15645" title="Abstract">arXiv:2312.15645</a> [<a href="/pdf/2312.15645" title="Download PDF">pdf</a>, <a href="/format/2312.15645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Variational Autoencoder for Sign Language Translation with  Cross-Modal Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Biao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Cong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yidong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as conference paper by AAAI24. The code and models are available at <a href="https://github.com/rzhao-zhsq/CV-SLT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sign language translation (SLT) aims to convert continuous sign language
videos into textual sentences. As a typical multi-modal task, there exists an
inherent modality gap between sign language videos and spoken language text,
which makes the cross-modal alignment between visual and textual modalities
crucial. However, previous studies tend to rely on an intermediate sign gloss
representation to help alleviate the cross-modal problem thereby neglecting the
alignment across modalities that may lead to compromised results. To address
this issue, we propose a novel framework based on Conditional Variational
autoencoder for SLT (CV-SLT) that facilitates direct and sufficient cross-modal
alignment between sign language videos and spoken language text. Specifically,
our CV-SLT consists of two paths with two Kullback-Leibler (KL) divergences to
regularize the outputs of the encoder and decoder, respectively. In the prior
path, the model solely relies on visual information to predict the target text;
whereas in the posterior path, it simultaneously encodes visual information and
textual knowledge to reconstruct the target text. The first KL divergence
optimizes the conditional variational autoencoder and regularizes the encoder
outputs, while the second KL divergence performs a self-distillation from the
posterior path to the prior path, ensuring the consistency of decoder outputs.
We further enhance the integration of textual information to the posterior path
by employing a shared Attention Residual Gaussian Distribution (ARGD), which
considers the textual information in the posterior path as a residual component
relative to the prior path. Extensive experiments conducted on public datasets
(PHOENIX14T and CSL-daily) demonstrate the effectiveness of our framework,
achieving new state-of-the-art results while significantly alleviating the
cross-modal representation discrepancy.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15646" title="Abstract">arXiv:2312.15646</a> [<a href="/pdf/2312.15646" title="Download PDF">pdf</a>, <a href="/ps/2312.15646" title="Download PostScript">ps</a>, <a href="/format/2312.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A graph-based multimodal framework to predict gentrification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eshtiyagh%2C+J">Javad Eshtiyagh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baotong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yujing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Linhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 3rd International Conference on Urban Informatics 2023 - Best
  Paper Award 3rd Place
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)

</div>
<p class="mathjax">Gentrification--the transformation of a low-income urban area caused by the
influx of affluent residents--has many revitalizing benefits. However, it also
poses extremely concerning challenges to low-income residents. To help
policymakers take targeted and early action in protecting low-income residents,
researchers have recently proposed several machine learning models to predict
gentrification using socioeconomic and image features. Building upon previous
studies, we propose a novel graph-based multimodal deep learning framework to
predict gentrification based on urban networks of tracts and essential
facilities (e.g., schools, hospitals, and subway stations). We train and test
the proposed framework using data from Chicago, New York City, and Los Angeles.
The model successfully predicts census-tract level gentrification with 0.9
precision on average. Moreover, the framework discovers a previously unexamined
strong relationship between schools and gentrification, which provides a basis
for further exploration of social factors affecting gentrification.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15650" title="Abstract">arXiv:2312.15650</a> [<a href="/pdf/2312.15650" title="Download PDF">pdf</a>, <a href="/ps/2312.15650" title="Download PostScript">ps</a>, <a href="/format/2312.15650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Advertising Mode for Device Discovery in Bluetooth Low Energy  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rongfei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongxing Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Device discovery has a great impact on the performance of Bluetooth low
energy (BLE). The performance of device discovery is highly related to the
advertising mode. BLE has two advertising modes: pseudo-random delay
advertising (RDA) and periodic deterministic advertising (PDA). Generally, PDA
has low discovery latency but is susceptible to persistent collisions, whereas
RDA does not suffer persistent collisions but has much larger discovery
latency. In this paper, we propose a novel hybrid advertising mode, called
Deterministic and pseudo-Random delay Advertising (DRA), which has the
advantages of both PDA and RDA. We develop an analytical model for DRA mode
based on a two-dimensional discrete-time Markov chain, and analyze the expected
discovery latency of DRA in a single-advertiser case and a multiple-advertiser
case. Simulation shows the accuracy of our analytical model, and also verifies
that DRA can achieve an excellent tradeoff between low discovery latency and
robustness to collisions.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15651" title="Abstract">arXiv:2312.15651</a> [<a href="/pdf/2312.15651" title="Download PDF">pdf</a>, <a href="/ps/2312.15651" title="Download PostScript">ps</a>, <a href="/format/2312.15651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permissive nominal terms and their unification: an infinite, co-infinite  approach to nominal techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>, 
<a href="/search/cs?searchtype=author&query=Gabbay%2C+M+J">Murdoch J. Gabbay</a>, 
<a href="/search/cs?searchtype=author&query=Mulligan%2C+D">Dominic Mulligan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Logic Journal of the IGPL, Volume 18, Issue 6, December 2010,
  Pages 769-822
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Nominal terms extend first-order terms with binding. They lack some
properties of first- and higher-order terms: Terms must be reasoned about in a
context of 'freshness assumptions'; it is not always possible to 'choose a
fresh variable symbol' for a nominal term; it is not always possible to
'alpha-convert a bound variable symbol' or to 'quotient by alpha-equivalence';
the notion of unifier is not based just on substitution.
<br />Permissive nominal terms closely resemble nominal terms but they recover
these properties, and in particular the 'always fresh' and 'always rename'
properties. In the permissive world, freshness contexts are elided, equality is
fixed, and the notion of unifier is based on substitution alone rather than on
nominal terms' notion of unification based on substitution plus extra freshness
conditions.
<br />We prove that expressivity is not lost moving to the permissive case and
provide an injection of nominal terms unification problems and their solutions
into permissive nominal terms problems and their solutions. We investigate the
relation between permissive nominal unification and higher-order pattern
unification. We show how to translate permissive nominal unification problems
and solutions in a sound, complete, and optimal manner, in suitable senses
which we make formal.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15653" title="Abstract">arXiv:2312.15653</a> [<a href="/pdf/2312.15653" title="Download PDF">pdf</a>, <a href="/format/2312.15653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Index Modulation for Fluid Antenna-Assisted MIMO Communications: System  Design and Performance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Pei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zihuai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Quddus%2C+A">Atta Quddus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,9 figures, publish to TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose a transmission mechanism for fluid antennas (FAs)
enabled multiple-input multiple-output (MIMO) communication systems based on
index modulation (IM), named FA-IM, which incorporates the principle of IM into
FAs-assisted MIMO system to improve the spectral efficiency (SE) without
increasing the hardware complexity. In FA-IM, the information bits are mapped
not only to the modulation symbols, but also the index of FA position patterns.
Additionally, the FA position pattern codebook is carefully designed to further
enhance the system performance by maximizing the effective channel gains. Then,
a low-complexity detector, referred to efficient sparse Bayesian detector, is
proposed by exploiting the inherent sparsity of the transmitted FA-IM signal
vectors. Finally, a closed-form expression for the upper bound on the average
bit error probability (ABEP) is derived under the finite-path and infinite-path
channel condition. Simulation results show that the proposed scheme is capable
of improving the SE performance compared to the existing FAs-assisted MIMO and
the fixed position antennas (FPAs)-assisted MIMO systems while obviating any
additional hardware costs. It has also been shown that the proposed scheme
outperforms the conventional FA-assisted MIMO scheme in terms of error
performance under the same transmission rate.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15654" title="Abstract">arXiv:2312.15654</a> [<a href="/pdf/2312.15654" title="Download PDF">pdf</a>, <a href="/format/2312.15654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMEX-RK methods for Landau-Lifshitz equation with arbitrary damping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gui%2C+Y">Yan Gui</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+J">Jingrun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by Communications in Mathematical Sciences and is prepared for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">Magnetization dynamics in ferromagnetic materials is modeled by the
Landau-Lifshitz (LL) equation, a nonlinear system of partial differential
equations. Among the numerical approaches, semi-implicit schemes are widely
used in the micromagnetics simulation, due to a nice compromise between
accuracy and efficiency. At each time step, only a linear system needs to be
solved and a projection is then applied to preserve the length of
magnetization. However, this linear system contains variable coefficients and a
non-symmetric structure, and thus an efficient linear solver is highly desired.
If the damping parameter becomes large, it has been realized that efficient
solvers are only available to a linear system with constant, symmetric, and
positive definite (SPD) structure. In this work, based on the implicit-explicit
Runge-Kutta (IMEX-RK) time discretization, we introduce an artificial damping
term, which is treated implicitly. The remaining terms are treated explicitly.
This strategy leads to a semi-implicit scheme with the following properties:
(1) only a few linear system with constant and SPD structure needs to be solved
at each time step; (2) it works for the LL equation with arbitrary damping
parameter; (3) high-order accuracy can be obtained with high-order IMEX-RK time
discretization. Numerically, second-order and third-order IMEX-RK methods are
designed in both the 1-D and 3-D domains. A comparison with the backward
differentiation formula scheme is undertaken, in terms of accuracy and
efficiency. The robustness of both numerical methods is tested on the first
benchmark problem from National Institute of Standards and Technology. The
linearized stability estimate and optimal rate convergence analysis are
provided for an alternate IMEX-RK2 numerical scheme as well.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15656" title="Abstract">arXiv:2312.15656</a> [<a href="/pdf/2312.15656" title="Download PDF">pdf</a>, <a href="/format/2312.15656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconditionally stable exponential integrator schemes for the 2D  Cahn-Hilliard equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+X">Xinyu Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Phase field models are gradient flows with their energy naturally dissipating
in time. In order to preserve this property, many numerical schemes have been
well-studied. In this paper we consider a well-known method, namely the
exponential integrator method (EI). In the literature a few works studied
several EI schemes for various phase field models and proved the energy
dissipation by either requiring a strong Lipschitz condition on the nonlinear
source term or certain $L^\infty$ bounds on the numerical solutions (maximum
principle). However for phase field models such as the (non-local)
Cahn-Hilliard equation, the maximum principle no longer exists. As a result,
solving such models via EI schemes remains open for a long time. In this paper
we aim to give a systematic approach on applying EI-type schemes to such models
by solving the Cahn-Hilliard equation with a first order EI scheme and showing
the energy dissipation. In fact second order EI schemes can be handled
similarly and we leave the discussion in a subsequent paper. To our best
knowledge, this is the first work to handle phase field models without assuming
any strong Lipschitz condition or $L^\infty$ boundedness. Furthermore, we will
analyze the $L^2$ error and present some numerical simulations to demonstrate
the dynamics.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15658" title="Abstract">arXiv:2312.15658</a> [<a href="/pdf/2312.15658" title="Download PDF">pdf</a>, <a href="/format/2312.15658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swap-based Deep Reinforcement Learning for Facility Location Problems in  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Combinatorics (math.CO)

</div>
<p class="mathjax">Facility location problems on graphs are ubiquitous in real world and hold
significant importance, yet their resolution is often impeded by NP-hardness.
Recently, machine learning methods have been proposed to tackle such classical
problems, but they are limited to the myopic constructive pattern and only
consider the problems in Euclidean space. To overcome these limitations, we
propose a general swap-based framework that addresses the p-median problem and
the facility relocation problem on graphs and a novel reinforcement learning
model demonstrating a keen awareness of complex graph structures. Striking a
harmonious balance between solution quality and running time, our method
surpasses handcrafted heuristics on intricate graph datasets. Additionally, we
introduce a graph generation process to simulate real-world urban road networks
with demand, facilitating the construction of large datasets for the classic
problem. For the initialization of the locations of facilities, we introduce a
physics-inspired strategy for the p-median problem, reaching more stable
solutions than the random strategy. The proposed pipeline coupling the classic
swap-based method with deep reinforcement learning marks a significant step
forward in addressing the practical challenges associated with facility
location on graphs.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15661" title="Abstract">arXiv:2312.15661</a> [<a href="/pdf/2312.15661" title="Download PDF">pdf</a>, <a href="/format/2312.15661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Potential of Large Language Models for Explainable  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yucong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingyue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating user-friendly explanations regarding why an item is recommended
has become increasingly common, largely due to advances in language generation
technology, which can enhance user trust and facilitate more informed
decision-making when using online services. However, existing explainable
recommendation systems focus on using small-size language models. It remains
uncertain what impact replacing the explanation generator with the recently
emerging large language models (LLMs) would have. Can we expect unprecedented
results?
<br />In this study, we propose LLMXRec, a simple yet effective two-stage
explainable recommendation framework aimed at further boosting the explanation
quality by employing LLMs. Unlike most existing LLM-based recommendation works,
a key characteristic of LLMXRec is its emphasis on the close collaboration
between previous recommender models and LLM-based explanation generators.
Specifically, by adopting several key fine-tuning techniques, including
parameter-efficient instructing tuning and personalized prompt techniques,
controllable and fluent explanations can be well generated to achieve the goal
of explanation recommendation. Most notably, we provide three different
perspectives to evaluate the effectiveness of the explanations. Finally, we
conduct extensive experiments over several benchmark recommender models and
publicly available datasets. The experimental results not only yield positive
results in terms of effectiveness and efficiency but also uncover some
previously unknown outcomes. To facilitate further explorations in this area,
the full code and detailed original results are open-sourced at
https://anonymous.4open.science/r/LLM_rec_explanation-7028/
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15663" title="Abstract">arXiv:2312.15663</a> [<a href="/pdf/2312.15663" title="Download PDF">pdf</a>, <a href="/format/2312.15663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IQAGPT: Image Quality Assessment with Vision-language and ChatGPT Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+C">Chuang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Hongming Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Ge Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), such as ChatGPT, have demonstrated impressive
capabilities in various tasks and attracted an increasing interest as a natural
language interface across many domains. Recently, large vision-language models
(VLMs) like BLIP-2 and GPT-4 have been intensively investigated, which learn
rich vision-language correlation from image-text pairs. However, despite these
developments, the application of LLMs and VLMs in image quality assessment
(IQA), particularly in medical imaging, remains to be explored, which is
valuable for objective performance evaluation and potential supplement or even
replacement of radiologists' opinions. To this end, this paper introduces
IQAGPT, an innovative image quality assessment system integrating an image
quality captioning VLM with ChatGPT for generating quality scores and textual
reports. First, we build a CT-IQA dataset for training and evaluation,
comprising 1,000 CT slices with diverse quality levels professionally
annotated. To better leverage the capabilities of LLMs, we convert annotated
quality scores into semantically rich text descriptions using a prompt
template. Second, we fine-tune the image quality captioning VLM on the CT-IQA
dataset to generate quality descriptions. The captioning model fuses the image
and text features through cross-modal attention. Third, based on the quality
descriptions, users can talk with ChatGPT to rate image quality scores or
produce a radiological quality report. Our preliminary results demonstrate the
feasibility of assessing image quality with large models. Remarkably, our
IQAGPT outperforms GPT-4 and CLIP-IQA, as well as the multi-task classification
and regression models that solely rely on images.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15667" title="Abstract">arXiv:2312.15667</a> [<a href="/pdf/2312.15667" title="Download PDF">pdf</a>, <a href="/format/2312.15667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy  Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+X">Xingzhou Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Norman%2C+T+J">Timothy J. Norman</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-Agent Policy Gradient (MAPG) has made significant progress in recent
years. However, centralized critics in state-of-the-art MAPG methods still face
the centralized-decentralized mismatch (CDM) issue, which means sub-optimal
actions by some agents will affect other agent's policy learning. While using
individual critics for policy updates can avoid this issue, they severely limit
cooperation among agents. To address this issue, we propose an agent topology
framework, which decides whether other agents should be considered in policy
gradient and achieves compromise between facilitating cooperation and
alleviating the CDM issue. The agent topology allows agents to use coalition
utility as learning objective instead of global utility by centralized critics
or local utility by individual critics. To constitute the agent topology,
various models are studied. We propose Topology-based multi-Agent Policy
gradiEnt (TAPE) for both stochastic and deterministic MAPG methods. We prove
the policy improvement theorem for stochastic TAPE and give a theoretical
explanation for the improved cooperation among agents. Experiment results on
several benchmarks show the agent topology is able to facilitate agent
cooperation and alleviate CDM issue respectively to improve performance of
TAPE. Finally, multiple ablation studies and a heuristic graph search algorithm
are devised to show the efficacy of the agent topology.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15668" title="Abstract">arXiv:2312.15668</a> [<a href="/pdf/2312.15668" title="Download PDF">pdf</a>, <a href="/ps/2312.15668" title="Download PostScript">ps</a>, <a href="/format/2312.15668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Air-to-Ground Communications Beyond 5G: UAV Swarm Formation Control and  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peiran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Minghua Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, to appear in IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Unmanned aerial vehicle (UAV) communications have been widely accepted as
promising technologies to support air-to-ground communications in the
forthcoming sixth-generation (6G) wireless networks. This paper proposes a
novel air-to-ground communication model consisting of aerial base stations
served by UAVs and terrestrial user equipments (UEs) by integrating the
technique of coordinated multi-point (CoMP) transmission with the theory of
stochastic geometry. In particular, a CoMP set consisting of multiple UAVs is
developed based on the theory of Poisson-Delaunay tetrahedralization. Effective
UAV formation control and UAV swarm tracking schemes for two typical scenarios,
including static and mobile UEs, are also developed using the multi-agent
system theory to ensure that collaborative UAVs can efficiently reach target
spatial positions for mission execution. Thanks to the ease of mathematical
tractability, this model provides explicit performance expressions for a
typical UE's coverage probability and achievable ergodic rate. Extensive
simulation and numerical results corroborate that the proposed scheme
outperforms UAV communications without CoMP transmission and obtains similar
performance to the conventional CoMP scheme while avoiding search overhead.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15670" title="Abstract">arXiv:2312.15670</a> [<a href="/pdf/2312.15670" title="Download PDF">pdf</a>, <a href="/format/2312.15670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Vocabulary Video Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+W">Wentao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuqian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accpeted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A comprehensive understanding of videos is inseparable from describing the
action with its contextual action-object interactions. However, many current
video understanding tasks prioritize general action classification and overlook
the actors and relationships that shape the nature of the action, resulting in
a superficial understanding of the action. Motivated by this, we introduce
Open-vocabulary Video Relation Extraction (OVRE), a novel task that views
action understanding through the lens of action-centric relation triplets. OVRE
focuses on pairwise relations that take part in the action and describes these
relation triplets with natural languages. Moreover, we curate the Moments-OVRE
dataset, which comprises 180K videos with action-centric relation triplets,
sourced from a multi-label action classification dataset. With Moments-OVRE, we
further propose a crossmodal mapping model to generate relation triplets as a
sequence. Finally, we benchmark existing cross-modal generation models on the
new task of OVRE.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15674" title="Abstract">arXiv:2312.15674</a> [<a href="/pdf/2312.15674" title="Download PDF">pdf</a>, <a href="/format/2312.15674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Multi-Agent Shared Layers are Universal Cognition of  Multi-Agent Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhengtao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruili Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Rongjun Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Multi-agent reinforcement learning shines as the pinnacle of multi-agent
systems, conquering intricate real-world challenges, fostering collaboration
and coordination among agents, and unleashing the potential for intelligent
decision-making across domains. However, training a multi-agent reinforcement
learning network is a formidable endeavor, demanding substantial computational
resources to interact with diverse environmental variables, extract state
representations, and acquire decision-making knowledge. The recent
breakthroughs in large-scale pre-trained models ignite our curiosity: Can we
uncover shared knowledge in multi-agent reinforcement learning and leverage
pre-trained models to expedite training for future tasks? Addressing this
issue, we present an innovative multi-task learning approach that aims to
extract and harness common decision-making knowledge, like cooperation and
competition, across different tasks. Our approach involves concurrent training
of multiple multi-agent tasks, with each task employing independent front-end
perception layers while sharing back-end decision-making layers. This effective
decoupling of state representation extraction from decision-making allows for
more efficient training and better transferability. To evaluate the efficacy of
our proposed approach, we conduct comprehensive experiments in two distinct
environments: the StarCraft Multi-agent Challenge (SMAC) and the Google
Research Football (GRF) environments. The experimental results unequivocally
demonstrate the smooth transferability of the shared decision-making network to
other tasks, thereby significantly reducing training costs and improving final
performance. Furthermore, visualizations authenticate the presence of general
multi-agent decision-making knowledge within the shared network layers, further
validating the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15679" title="Abstract">arXiv:2312.15679</a> [<a href="/pdf/2312.15679" title="Download PDF">pdf</a>, <a href="/format/2312.15679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BDIS-SLAM: A lightweight CPU-based dense stereo SLAM for surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingwei Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qiuchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by International Journal of Computer Assisted Radiology and Surgery. Code is available at <a href="https://github.com/JingweiSong/BDIS-SLAM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: Common dense stereo Simultaneous Localization and Mapping (SLAM)
approaches in Minimally Invasive Surgery (MIS) require high-end parallel
computational resources for real-time implementation. Yet, it is not always
feasible since the computational resources should be allocated to other tasks
like segmentation, detection, and tracking. To solve the problem of limited
parallel computational power, this research aims at a lightweight dense stereo
SLAM system that works on a single-core CPU and achieves real-time performance
(more than 30 Hz in typical scenarios). Methods: A new dense stereo mapping
module is integrated with the ORB-SLAM2 system and named BDIS-SLAM. Our new
dense stereo mapping module includes stereo matching and 3D dense depth mosaic
methods. Stereo matching is achieved with the recently proposed CPU-level
real-time matching algorithm Bayesian Dense Inverse Searching (BDIS). A
BDIS-based shape recovery and a depth mosaic strategy are integrated as a new
thread and coupled with the backbone ORB-SLAM2 system for real-time stereo
shape recovery. Results: Experiments on in-vivo data sets show that BDIS-SLAM
runs at over 30 Hz speed on modern single-core CPU in typical
endoscopy/colonoscopy scenarios. BDIS-SLAM only consumes around an additional
12% time compared with the backbone ORB-SLAM2. Although our lightweight
BDIS-SLAM simplifies the process by ignoring deformation and fusion procedures,
it can provide a usable dense mapping for modern MIS on computationally
constrained devices. Conclusion: The proposed BDIS-SLAM is a lightweight stereo
dense SLAM system for MIS. It achieves 30 Hz on a modern single-core CPU in
typical endoscopy/colonoscopy scenarios (image size around 640*480). BDIS-SLAM
provides a low-cost solution for dense mapping in MIS and has the potential to
be applied in surgical robots and AR systems.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15681" title="Abstract">arXiv:2312.15681</a> [<a href="/pdf/2312.15681" title="Download PDF">pdf</a>, <a href="/format/2312.15681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Fine-Tuning: A Successor to Full Fine-Tuning for Vision  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Chongjun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Fine-tuning pre-trained foundation models has gained significant popularity
in various research fields. Existing methods for fine-tuning can be roughly
divided into two categories, namely Parameter-Efficient Fine-Tuning and
High-Performance Fine-Tuning. The former aims at improving efficiency, while
the latter focuses on enhancing performance. Beyond these methods, we
demonstrate that Partial Fine-Tuning can be an innovative and promising
direction capable of concurrently enhancing both efficiency and accuracy. We
first validate eight manually-defined partial fine-tuning strategies across
kinds of datasets and vision transformer architectures, and find that some
partial fine-tuning strategies (e.g., ffn only or attention only) can achieve
better performance with fewer tuned parameters than full fine-tuning, and
selecting appropriate layers is critical to partial fine-tuning. Thus, we
propose a novel fine-tuned angle metric to guide the selection of appropriate
layers for partial fine-tuning, making it flexible to be adapted to various
scenarios for more practicable partial fine-tuning. Additionally, we show that
partial fine-tuning can serve as a new dimension for Model Soups, improving
both the model performance and generalization with fewer tuned parameters.
Comprehensive experiments on a wide range of datasets and models validate the
great potential of partial fine-tuning.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15682" title="Abstract">arXiv:2312.15682</a> [<a href="/pdf/2312.15682" title="Download PDF">pdf</a>, <a href="/format/2312.15682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Grating Based High-Frequency Motion Stimulus Paradigm for Steady-State  Motion Visual Evoked Potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atabek%2C+B">Bartu Atabek</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+E">Efecan Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Acarturk%2C+C">Cengiz Acarturk</a>, 
<a href="/search/cs?searchtype=author&query=Cakir%2C+M+P">Murat Perit Cakir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Objective: This paper proposes a novel type of stimulus in the shape of
sinusoidal gratings displayed with an imperceptibly high-frequency motion. The
stimulus has been designed for use in BCI (Brain Computer Interface)
applications that employ visually evoked potentials (VEPs) in an effort to
mitigate discomfort associated with VEPs. The stimuli set included traditional
VEP stimuli, already established in the literature, allowing comparative
analyses. We conducted analyses of signal distinction measures by calculating
the signal-to-noise ratio and the classification performance of its evoked
potentials. Methods: Fourteen participants were seated in a dimly lit room
facing a display. Participants' fixation on the central stimulus was controlled
by means of a desktop eye tracker. Participants attended a flicker-based
steady-state VEP (SSVEP) task, a motion-based steady-state-motion VEP (SSMVEP)
task, and the novel stimulus task (the imperceptible grating SSMVEP).
Participants were asked to complete behavioral fatigue scale tasks. Results: A
significant effect of stimulus type was observed, accompanied by insignificant
differences in prediction accuracy. Partially significant task effects were
obtained in fatigue scale tasks. Conclusion: The study revealed that the
imperceptible grating SSMVEP stimulus successfully evoked SSMVEP responses
within acceptable margins in the related cortical regions. This novel stimulus
contributes to BCI research by providing an imperceptible interface, improving
already established stimuli design in the SSVEP and the SSMVEP literature.
Significance: The present paper provides a novel SSMVEP stimulus type that may
inform the future design of effective VEP-based BCI paradigms that allow
seamless interaction with computer interfaces.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15684" title="Abstract">arXiv:2312.15684</a> [<a href="/pdf/2312.15684" title="Download PDF">pdf</a>, <a href="/format/2312.15684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic mean-shift clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lapidot%2C+I">Itshak Lapidot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper we presented a stochastic version mean-shift clustering
algorithm. In the stochastic version the data points "climb" to the modes of
the distribution collectively, while in the deterministic mean-shift, each
datum "climbs" individually, while all other data points remains in their
original coordinates. Stochastic version of the mean-shift clustering is
comparison with a standard (deterministic) mean-shift clustering on synthesized
2- and 3-dimensional data distributed between several Gaussian component. The
comparison performed in terms of cluster purity and class data purity. It was
found the the stochastic mean-shift clustering outperformed in most of the
cases the deterministic mean-shift.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15685" title="Abstract">arXiv:2312.15685</a> [<a href="/pdf/2312.15685" title="Download PDF">pdf</a>, <a href="/format/2312.15685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes Good Data for Alignment? A Comprehensive Study of Automatic  Data Selection in Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Weihao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Keqing He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Data and model checkpoints are available at <a href="https://github.com/hkust-nlp/deita">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Instruction tuning is a standard technique employed to align large language
models to end tasks and user preferences after the initial pretraining phase.
Recent research indicates the critical role of data engineering in instruction
tuning -- when appropriately selected, only limited data is necessary to
achieve superior performance. However, we still lack a principled understanding
of what makes good instruction tuning data for alignment, and how we should
select data automatically and effectively. In this work, we delve deeply into
automatic data selection strategies for alignment. We start with controlled
studies to measure data across three dimensions: complexity, quality, and
diversity, along which we examine existing methods and introduce novel
techniques for enhanced data measurement. Subsequently, we propose a simple
strategy to select data samples based on the measurement. We present deita
(short for Data-Efficient Instruction Tuning for Alignment), a series of models
fine-tuned from LLaMA and Mistral models using data samples automatically
selected with our proposed approach. Empirically, deita performs better or on
par with the state-of-the-art open-source alignment models with only 6K SFT
training data samples -- over 10x less than the data used in the baselines.
When further trained with direct preference optimization (DPO),
deita-Mistral-7B + DPO trained with 6K SFT and 10K DPO samples achieve 7.55
MT-Bench and 90.06% AlpacaEval scores. We anticipate this work to provide tools
on automatic data selection, facilitating data-efficient alignment. We release
our models as well as the selected datasets for future researches to
effectively align models more efficiently.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15686" title="Abstract">arXiv:2312.15686</a> [<a href="/pdf/2312.15686" title="Download PDF">pdf</a>, <a href="/format/2312.15686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PULASki: Learning inter-rater variability using statistical distances to  improve probabilistic segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Soumick Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Gaidzik%2C+F">Franziska Gaidzik</a>, 
<a href="/search/cs?searchtype=author&query=Sciarra%2C+A">Alessandro Sciarra</a>, 
<a href="/search/cs?searchtype=author&query=Mattern%2C+H">Hendrik Mattern</a>, 
<a href="/search/cs?searchtype=author&query=Janiga%2C+G">G&#xe1;bor Janiga</a>, 
<a href="/search/cs?searchtype=author&query=Speck%2C+O">Oliver Speck</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%BCrnberger%2C+A">Andreas N&#xfc;rnberger</a>, 
<a href="/search/cs?searchtype=author&query=Pathiraja%2C+S">Sahani Pathiraja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the domain of medical imaging, many supervised learning based methods for
segmentation face several challenges such as high variability in annotations
from multiple experts, paucity of labelled data and class imbalanced datasets.
These issues may result in segmentations that lack the requisite precision for
clinical analysis and can be misleadingly overconfident without associated
uncertainty quantification. We propose the PULASki for biomedical image
segmentation that accurately captures variability in expert annotations, even
in small datasets. Our approach makes use of an improved loss function based on
statistical distances in a conditional variational autoencoder structure
(Probabilistic UNet), which improves learning of the conditional decoder
compared to the standard cross-entropy particularly in class imbalanced
problems. We analyse our method for two structurally different segmentation
tasks (intracranial vessel and multiple sclerosis (MS) lesion) and compare our
results to four well-established baselines in terms of quantitative metrics and
qualitative output. Empirical results demonstrate the PULASKi method
outperforms all baselines at the 5\% significance level. The generated
segmentations are shown to be much more anatomically plausible than in the 2D
case, particularly for the vessel task. Our method can also be applied to a
wide range of multi-label segmentation tasks and and is useful for downstream
tasks such as hemodynamic modelling (computational fluid dynamics and data
assimilation), clinical decision making, and treatment planning.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15690" title="Abstract">arXiv:2312.15690</a> [<a href="/pdf/2312.15690" title="Download PDF">pdf</a>, <a href="/format/2312.15690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word length-aware text spotting: Enhancing detection and recognition in  dense text image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huabing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanduo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiayi Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene text spotting is essential in various computer vision applications,
enabling extracting and interpreting textual information from images. However,
existing methods often neglect the spatial semantics of word images, leading to
suboptimal detection recall rates for long and short words within long-tailed
word length distributions that exist prominently in dense scenes. In this
paper, we present WordLenSpotter, a novel word length-aware spotter for scene
text image detection and recognition, improving the spotting capabilities for
long and short words, particularly in the tail data of dense text images. We
first design an image encoder equipped with a dilated convolutional fusion
module to integrate multiscale text image features effectively. Then,
leveraging the Transformer framework, we synergistically optimize text
detection and recognition accuracy after iteratively refining text region image
features using the word length prior. Specially, we design a Spatial Length
Predictor module (SLP) using character count prior tailored to different word
lengths to constrain the regions of interest effectively. Furthermore, we
introduce a specialized word Length-aware Segmentation (LenSeg) proposal head,
enhancing the network's capacity to capture the distinctive features of long
and short terms within categories characterized by long-tailed distributions.
Comprehensive experiments on public datasets and our dense text spotting
dataset DSTD1500 demonstrate the superiority of our proposed methods,
particularly in dense text image detection and recognition tasks involving
long-tailed word length distributions encompassing a range of long and short
words.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15692" title="Abstract">arXiv:2312.15692</a> [<a href="/pdf/2312.15692" title="Download PDF">pdf</a>, <a href="/format/2312.15692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Fusion: Advancing Prompt Evolution through Hybridization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weidong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiuding Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaitong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhuwei Rao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+D">Di Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The fine-tuning of Large Language Models (LLMs) specialized in code
generation has seen notable advancements through the use of open-domain coding
queries. Despite the successes, existing methodologies like
\textit{Evol-Instruct} encounter performance limitations, impeding further
enhancements in code generation tasks. This paper examines the constraints of
existing prompt evolution techniques and introduces a novel approach,
\textit{Instruction Fusion} (IF). IF innovatively combines two distinct prompts
through a hybridization process, thereby enhancing the evolution of training
prompts for code LLMs. Our experimental results reveal that the proposed novel
method effectively addresses the shortcomings of prior methods, significantly
improving the performance of Code LLMs across five code generation benchmarks,
namely HumanEval, HumanEval+, MBPP, MBPP+ and MultiPL-E, which underscore the
effectiveness of \textit{Instruction Fusion} in advancing the capabilities of
LLMs in code generation.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15696" title="Abstract">arXiv:2312.15696</a> [<a href="/pdf/2312.15696" title="Download PDF">pdf</a>, <a href="/format/2312.15696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EcomGPT-CT: Continual Pre-training of E-commerce Large Language Models  with Semi-structured Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shirong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shulin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaobin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) pre-trained on massive corpora have exhibited
remarkable performance on various NLP tasks. However, applying these models to
specific domains still poses significant challenges, such as lack of domain
knowledge, limited capacity to leverage domain knowledge and inadequate
adaptation to domain-specific data formats. Considering the exorbitant cost of
training LLMs from scratch and the scarcity of annotated data within particular
domains, in this work, we focus on domain-specific continual pre-training of
LLMs using E-commerce domain as an exemplar. Specifically, we explore the
impact of continual pre-training on LLMs employing unlabeled general and
E-commercial corpora. Furthermore, we design a mixing strategy among different
data sources to better leverage E-commercial semi-structured data. We construct
multiple tasks to assess LLMs' few-shot In-context Learning ability and their
zero-shot performance after instruction tuning in E-commerce domain.
Experimental results demonstrate the effectiveness of continual pre-training of
E-commerce LLMs and the efficacy of our devised data mixing strategy.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15698" title="Abstract">arXiv:2312.15698</a> [<a href="/pdf/2312.15698" title="Download PDF">pdf</a>, <a href="/format/2312.15698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for  Program Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Andr&#xe9; Silva</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Sen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Monperrus%2C+M">Martin Monperrus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Automated Program Repair (APR) has evolved significantly with the advent of
Large Language Models (LLMs). Fine-tuning LLMs for program repair is a recent
avenue of research, with many dimensions which have not been explored. Existing
work mostly fine-tunes LLMs with naive code representations and is
fundamentally limited in its ability to fine-tune larger LLMs. To address this
problem, we propose RepairLLaMA, a novel program repair approach that combines
1) code representations for APR and 2) the state-of-the-art parameter-efficient
LLM fine-tuning technique called LoRA. This results in RepairLLaMA producing a
highly effective `program repair adapter' for fixing bugs with language models.
Our experiments demonstrate the validity of both concepts. First, fine-tuning
adapters with program repair specific code representations enables the model to
use meaningful repair signals. Second, parameter-efficient fine-tuning helps
fine-tuning to converge and contributes to the effectiveness of the repair
adapter to fix data-points outside the fine-tuning data distribution. Overall,
RepairLLaMA correctly fixes 125 Defects4J v2 and 82 HumanEval-Java bugs,
outperforming all baselines.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15702" title="Abstract">arXiv:2312.15702</a> [<a href="/pdf/2312.15702" title="Download PDF">pdf</a>, <a href="/format/2312.15702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Heads Are Better Than One: Complementary Experts for Long-Tailed  Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengcheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Elezi%2C+I">Ismail Elezi</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weiming Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address the challenging problem of Long-Tailed Semi-Supervised Learning
(LTSSL) where labeled data exhibit imbalanced class distribution and unlabeled
data follow an unknown distribution. Unlike in balanced SSL, the generated
pseudo-labels are skewed towards head classes, intensifying the training bias.
Such a phenomenon is even amplified as more unlabeled data will be mislabeled
as head classes when the class distribution of labeled and unlabeled datasets
are mismatched. To solve this problem, we propose a novel method named
ComPlementary Experts (CPE). Specifically, we train multiple experts to model
various class distributions, each of them yielding high-quality pseudo-labels
within one form of class distribution. Besides, we introduce Classwise Batch
Normalization for CPE to avoid performance degradation caused by feature
distribution mismatch between head and non-head classes. CPE achieves
state-of-the-art performances on CIFAR-10-LT, CIFAR-100-LT, and STL-10-LT
dataset benchmarks. For instance, on CIFAR-10-LT, CPE improves test accuracy by
over &gt;2.22% compared to baselines. Code is available at
https://github.com/machengcheng2016/CPE-LTSSL.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15707" title="Abstract">arXiv:2312.15707</a> [<a href="/pdf/2312.15707" title="Download PDF">pdf</a>, <a href="/format/2312.15707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Diffusion-based Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guoqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have attained remarkable success in the domains of image
generation and editing. It is widely recognized that employing larger inversion
and denoising steps in diffusion model leads to improved image reconstruction
quality. However, the editing performance of diffusion models tends to be no
more satisfactory even with increasing denoising steps. The deficiency in
editing could be attributed to the conditional Markovian property of the
editing process, where errors accumulate throughout denoising steps. To tackle
this challenge, we first propose an innovative framework where a rectifier
module is incorporated to modulate diffusion model weights with residual
features, thereby providing compensatory information to bridge the fidelity
gap. Furthermore, we introduce a novel learning paradigm aimed at minimizing
error propagation during the editing process, which trains the editing
procedure in a manner similar to denoising score-matching. Extensive
experiments demonstrate that our proposed framework and training strategy
achieve high-fidelity reconstruction and editing results across various levels
of denoising steps, meanwhile exhibits exceptional performance in terms of both
quantitative metric and qualitative assessments. Moreover, we explore our
model's generalization through several applications like image-to-image
translation and out-of-domain image editing.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15709" title="Abstract">arXiv:2312.15709</a> [<a href="/pdf/2312.15709" title="Download PDF">pdf</a>, <a href="/format/2312.15709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimesURL: Self-supervised Contrastive Learning for Universal Time Series  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiexi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songcan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning universal time series representations applicable to various types of
downstream tasks is challenging but valuable in real applications. Recently,
researchers have attempted to leverage the success of self-supervised
contrastive learning (SSCL) in Computer Vision(CV) and Natural Language
Processing(NLP) to tackle time series representation. Nevertheless, due to the
special temporal characteristics, relying solely on empirical guidance from
other domains may be ineffective for time series and difficult to adapt to
multiple downstream tasks. To this end, we review three parts involved in SSCL
including 1) designing augmentation methods for positive pairs, 2) constructing
(hard) negative pairs, and 3) designing SSCL loss. For 1) and 2), we find that
unsuitable positive and negative pair construction may introduce inappropriate
inductive biases, which neither preserve temporal properties nor provide
sufficient discriminative features. For 3), just exploring segment- or
instance-level semantics information is not enough for learning universal
representation. To remedy the above issues, we propose a novel self-supervised
framework named TimesURL. Specifically, we first introduce a
frequency-temporal-based augmentation to keep the temporal property unchanged.
And then, we construct double Universums as a special kind of hard negative to
guide better contrastive learning. Additionally, we introduce time
reconstruction as a joint optimization objective with contrastive learning to
capture both segment-level and instance-level information. As a result,
TimesURL can learn high-quality universal representations and achieve
state-of-the-art performance in 6 different downstream tasks, including short-
and long-term forecasting, imputation, classification, anomaly detection and
transfer learning.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15710" title="Abstract">arXiv:2312.15710</a> [<a href="/pdf/2312.15710" title="Download PDF">pdf</a>, <a href="/format/2312.15710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alleviating Hallucinations of Large Language Models through Induced  Hallucinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite their impressive capabilities, large language models (LLMs) have been
observed to generate responses that include inaccurate or fabricated
information, a phenomenon commonly known as ``hallucination''. In this work, we
propose a simple \textit{Induce-then-Contrast} Decoding (ICD) strategy to
alleviate hallucinations. We first construct a factually weak LLM by inducing
hallucinations from the original LLMs. Then, we penalize these induced
hallucinations during decoding to enhance the factuality of the generated
content. Concretely, we determine the final next-token predictions by
amplifying the predictions from the original model and downplaying the induced
untruthful predictions via contrastive decoding. Experimental results on both
discrimination-based and generation-based hallucination evaluation benchmarks,
such as TruthfulQA and \textsc{FActScore}, demonstrate that our proposed ICD
methods can effectively enhance the factuality of LLMs across various model
sizes and families. For example, when equipped with ICD, Llama2-7B-Chat and
Mistral-7B-Instruct achieve performance comparable to ChatGPT and GPT4 on
TruthfulQA, respectively.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15711" title="Abstract">arXiv:2312.15711</a> [<a href="/pdf/2312.15711" title="Download PDF">pdf</a>, <a href="/format/2312.15711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural BSSRDF: Object Appearance Representation Including Heterogeneous  Subsurface Scattering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=TG%2C+T">Thomson TG</a>, 
<a href="/search/cs?searchtype=author&query=Frisvad%2C+J+R">Jeppe Revall Frisvad</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthi%2C+R">Ravi Ramamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+H+W">Henrik Wann Jensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Monte Carlo rendering of translucent objects with heterogeneous scattering
properties is often expensive both in terms of memory and computation. If we do
path tracing and use a high dynamic range lighting environment, the rendering
becomes computationally heavy. We propose a compact and efficient neural method
for representing and rendering the appearance of heterogeneous translucent
objects. The neural representation function resembles a bidirectional
scattering-surface reflectance distribution function (BSSRDF). However,
conventional BSSRDF models assume a planar half-space medium and only surface
variation of the material, which is often not a good representation of the
appearance of real-world objects. Our method represents the BSSRDF of a full
object taking its geometry and heterogeneities into account. This is similar to
a neural radiance field, but our representation works for an arbitrary distant
lighting environment. In a sense, we present a version of neural precomputed
radiance transfer that captures all-frequency relighting of heterogeneous
translucent objects. We use a multi-layer perceptron (MLP) with skip
connections to represent the appearance of an object as a function of spatial
position, direction of observation, and direction of incidence. The latter is
considered a directional light incident across the entire non-self-shadowed
part of the object. We demonstrate the ability of our method to store highly
complex materials while having high accuracy when comparing to reference images
of the represented object in unseen lighting environments. As compared with
path tracing of a heterogeneous light scattering volume behind a refractive
interface, our method more easily enables importance sampling of the directions
of incidence and can be integrated into existing rendering frameworks while
achieving interactive frame rates.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15713" title="Abstract">arXiv:2312.15713</a> [<a href="/pdf/2312.15713" title="Download PDF">pdf</a>, <a href="/ps/2312.15713" title="Download PostScript">ps</a>, <a href="/format/2312.15713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PersianLLaMA: Towards Building First Persian Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+M+A">Mohammad Amin Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Ghafouri%2C+A">Arash Ghafouri</a>, 
<a href="/search/cs?searchtype=author&query=Firouzmandi%2C+M">Mahdi Firouzmandi</a>, 
<a href="/search/cs?searchtype=author&query=Naderi%2C+H">Hassan Naderi</a>, 
<a href="/search/cs?searchtype=author&query=Bidgoli%2C+B+M">Behrouz Minaei Bidgoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the widespread use of the Persian language by millions globally,
limited efforts have been made in natural language processing for this
language. The use of large language models as effective tools in various
natural language processing tasks typically requires extensive textual data and
robust hardware resources. Consequently, the scarcity of Persian textual data
and the unavailability of powerful hardware resources have hindered the
development of large language models for Persian. This paper introduces the
first large Persian language model, named PersianLLaMA, trained on a collection
of Persian texts and datasets. This foundational model comes in two versions,
with 7 and 13 billion parameters, trained on formal and colloquial Persian
texts using two different approaches. PersianLLaMA has been evaluated for
natural language generation tasks based on the latest evaluation methods,
namely using larger language models, and for natural language understanding
tasks based on automated machine metrics. The results indicate that
PersianLLaMA significantly outperforms its competitors in both understanding
and generating Persian text. PersianLLaMA marks an important step in the
development of Persian natural language processing and can be a valuable
resource for the Persian-speaking community. This large language model can be
used for various natural language processing tasks, especially text generation
like chatbots, question-answering, machine translation, and text summarization
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15715" title="Abstract">arXiv:2312.15715</a> [<a href="/pdf/2312.15715" title="Download PDF">pdf</a>, <a href="/format/2312.15715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiannan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zehuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of ICCV2023 UniRef. 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The reference-based object segmentation tasks, namely referring image
segmentation (RIS), few-shot image segmentation (FSS), referring video object
segmentation (RVOS), and video object segmentation (VOS), aim to segment a
specific object by utilizing either language or annotated masks as references.
Despite significant progress in each respective field, current methods are
task-specifically designed and developed in different directions, which hinders
the activation of multi-task capabilities for these tasks. In this work, we end
the current fragmented situation and propose UniRef++ to unify the four
reference-based object segmentation tasks with a single architecture. At the
heart of our approach is the proposed UniFusion module which performs
multiway-fusion for handling different tasks with respect to their specified
references. And a unified Transformer architecture is then adopted for
achieving instance-level segmentation. With the unified designs, UniRef++ can
be jointly trained on a broad range of benchmarks and can flexibly complete
multiple tasks at run-time by specifying the corresponding references. We
evaluate our unified models on various benchmarks. Extensive experimental
results indicate that our proposed UniRef++ achieves state-of-the-art
performance on RIS and RVOS, and performs competitively on FSS and VOS with a
parameter-shared network. Moreover, we showcase that the proposed UniFusion
module could be easily incorporated into the current advanced foundation model
SAM and obtain satisfactory results with parameter-efficient finetuning. Codes
and models are available at \url{https://github.com/FoundationVision/UniRef}.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15717" title="Abstract">arXiv:2312.15717</a> [<a href="/pdf/2312.15717" title="Download PDF">pdf</a>, <a href="/format/2312.15717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Interplay in Human Mobility: A Hierarchical  Reinforcement Learning Approach with Hypergraph Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaofan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dingqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Minghao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of human mobility, the decision-making process for selecting the
next-visit location is intricately influenced by a trade-off between spatial
and temporal constraints, which are reflective of individual needs and
preferences. This trade-off, however, varies across individuals, making the
modeling of these spatial-temporal dynamics a formidable challenge. To address
the problem, in this work, we introduce the "Spatial-temporal Induced
Hierarchical Reinforcement Learning" (STI-HRL) framework, for capturing the
interplay between spatial and temporal factors in human mobility
decision-making. Specifically, STI-HRL employs a two-tiered decision-making
process: the low-level focuses on disentangling spatial and temporal
preferences using dedicated agents, while the high-level integrates these
considerations to finalize the decision. To complement the hierarchical
decision setting, we construct a hypergraph to organize historical data,
encapsulating the multi-aspect semantics of human mobility. We propose a
cross-channel hypergraph embedding module to learn the representations as the
states to facilitate the decision-making cycle. Our extensive experiments on
two real-world datasets validate the superiority of STI-HRL over
state-of-the-art methods in predicting users' next visits across various
performance metrics.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15719" title="Abstract">arXiv:2312.15719</a> [<a href="/pdf/2312.15719" title="Download PDF">pdf</a>, <a href="/format/2312.15719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Get a Grip: Reconstructing Hand-Object Stable Grasps in Egocentric  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Damen%2C+D">Dima Damen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> webpage: <a href="https://zhifanzhu.github.io/getagrip">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address in-the-wild hand-object reconstruction for a known object category
in egocentric videos, focusing on temporal periods of stable grasps. We propose
the task of Hand-Object Stable Grasp Reconstruction (HO-SGR), the joint
reconstruction of frames during which the hand is stably holding the object. We
thus can constrain the object motion relative to the hand, effectively
regularising the reconstruction and improving performance. By analysing the 3D
ARCTIC dataset, we identify temporal periods where the contact area between the
hand and object vertices remain stable. We showcase that objects within stable
grasps move within a single degree of freedom (1~DoF). We thus propose a method
for jointly optimising all frames within a stable grasp by minimising the
object's rotation to that within a latent 1 DoF. We then extend this knowledge
to in-the-wild egocentric videos by labelling 2.4K clips of stable grasps from
the EPIC-KITCHENS dataset. Our proposed EPIC-Grasps dataset includes 390 object
instances of 9 categories, featuring stable grasps from videos of daily
interactions in 141 environments. Our method achieves significantly better
HO-SGR, both qualitatively and by computing the stable grasp area and 2D
projection labels of mask overlaps.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15720" title="Abstract">arXiv:2312.15720</a> [<a href="/pdf/2312.15720" title="Download PDF">pdf</a>, <a href="/format/2312.15720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set Prediction Guided by Semantic Concepts for Diverse Video Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yifan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chunfeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weiming Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> aaai 2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diverse video captioning aims to generate a set of sentences to describe the
given video in various aspects. Mainstream methods are trained with independent
pairs of a video and a caption from its ground-truth set without exploiting the
intra-set relationship, resulting in low diversity of generated captions.
Different from them, we formulate diverse captioning into a
semantic-concept-guided set prediction (SCG-SP) problem by fitting the
predicted caption set to the ground-truth set, where the set-level relationship
is fully captured. Specifically, our set prediction consists of two synergistic
tasks, i.e., caption generation and an auxiliary task of concept combination
prediction providing extra semantic supervision. Each caption in the set is
attached to a concept combination indicating the primary semantic content of
the caption and facilitating element alignment in set prediction. Furthermore,
we apply a diversity regularization term on concepts to encourage the model to
generate semantically diverse captions with various concept combinations. These
two tasks share multiple semantics-specific encodings as input, which are
obtained by iterative interaction between visual features and conceptual
queries. The correspondence between the generated captions and specific concept
combinations further guarantees the interpretability of our model. Extensive
experiments on benchmark datasets show that the proposed SCG-SP achieves
state-of-the-art (SOTA) performance under both relevance and diversity metrics.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15721" title="Abstract">arXiv:2312.15721</a> [<a href="/pdf/2312.15721" title="Download PDF">pdf</a>, <a href="/ps/2312.15721" title="Download PostScript">ps</a>, <a href="/format/2312.15721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV Trajectory Tracking via RNN-enhanced IMM-KF with ADS-B Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yian Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+Z">Ziye Jia</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qihui Wu</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+C">Chao Dong</a>, 
<a href="/search/eess?searchtype=author&query=Zhuang%2C+Z">Zirui Zhuang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+H">Huiling Hu</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+Q">Qi Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the increasing use of autonomous unmanned aerial vehicles (UAVs), it is
critical to ensure that they are continuously tracked and controlled,
especially when UAVs operate beyond the communication range of ground stations
(GSs). Conventional surveillance methods for UAVs, such as satellite
communications, ground mobile networks and radars are subject to high costs and
latency. The automatic dependent surveillance-broadcast (ADS-B) emerges as a
promising method to monitor UAVs, due to the advantages of real-time
capabilities, easy deployment and affordable cost. Therefore, we employ the
ADS-B for UAV trajectory tracking in this work. However, the inherent noise in
the transmitted data poses an obstacle for precisely tracking UAVs. Hence, we
propose the algorithm of recurrent neural network-enhanced interacting multiple
model-Kalman filter (RNN-enhanced IMM-KF) for UAV trajectory filtering.
Specifically, the algorithm utilizes the RNN to capture the maneuvering
behavior of UAVs and the noise level in the ADS-B data. Moreover, accurate UAV
tracking is achieved by adaptively adjusting the process noise matrix and
observation noise matrix of IMM-KF with the assistance of the RNN. The proposed
algorithm can facilitate GSs to make timely decisions during trajectory
deviations of UAVs and improve the airspace safety. Finally, via comprehensive
simulations, the total root mean square error of the proposed algorithm
decreases by 28.56%, compared to the traditional IMM-KF.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15722" title="Abstract">arXiv:2312.15722</a> [<a href="/pdf/2312.15722" title="Download PDF">pdf</a>, <a href="/format/2312.15722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-Domain Identification of Discrete-Time Systems using  Sum-of-Rational Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abdalmoaty%2C+M">Mohamed Abdalmoaty</a>, 
<a href="/search/eess?searchtype=author&query=Miller%2C+J">Jared Miller</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+M">Mingzhou Yin</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+R+S">Roy S. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a computationally tractable method for the identification of
stable canonical discrete-time rational transfer function models, using
frequency domain data. The problem is formulated as a global non-convex
optimization problem whose objective function is the sum of weighted squared
residuals at each observed frequency datapoint. Stability is enforced using a
polynomial matrix inequality constraint. The problem is solved globally by a
moment-sum-of-squares hierarchy of semidefinite programs through a framework
for sum-of-rational-functions optimization. Convergence of the
moment-sum-of-squares program is guaranteed as the bound on the degree of the
sum-of-squares polynomials approaches infinity. The performance of the proposed
method is demonstrated using numerical simulation examples.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15723" title="Abstract">arXiv:2312.15723</a> [<a href="/pdf/2312.15723" title="Download PDF">pdf</a>, <a href="/ps/2312.15723" title="Download PostScript">ps</a>, <a href="/format/2312.15723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of a double step scheme for a class of second order Clarke  subdifferential inclusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartosz%2C+K">Krzysztof Bartosz</a>, 
<a href="/search/math?searchtype=author&query=Szafraniec%2C+P">Pawe&#x142; Szafraniec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In this paper we deal with a second order evolution inclusion involving a
multivalued term generated by a Clarke subdifferential of a locally Lipschitz
potential. For this problem we construct a double step time-semidiscrete
approximation, known as the Rothe scheme. We study a sequence of solutions of
the semidiscrete approximate problems and provide its weak convergence to a
limit element that is a solution of the original problem.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15725" title="Abstract">arXiv:2312.15725</a> [<a href="/pdf/2312.15725" title="Download PDF">pdf</a>, <a href="/format/2312.15725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notes on Information Propagation in Noisy Multichannel Data Models:  Insights into Sensor Selection and Fusion in Multimodal Biomedical  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sameni%2C+R">Reza Sameni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Multimodality and multichannel monitoring have become increasingly popular
and accessible in engineering, Internet of Things, wearable devices, and
biomedical applications. In these contexts, given the diverse and complex
nature of data modalities, the relevance of sensor fusion and sensor selection
is heightened. In this note, we study the problem of channel/modality selection
and fusion from an information theoretical perspective, focusing on linear and
nonlinear signal mixtures corrupted by additive Gaussian noise. We revisit and
extend well-known properties of linear noisy data models in estimation and
information theory, providing practical insights that assist in the
decision-making process between channel (modality) selection and fusion. Using
the notion of multichannel signal-to-noise ratio, we derive conditions under
which, selection or fusion of multimodal/multichannel data can be beneficial or
redundant. This contributes to a better understanding of how to optimize sensor
fusion and selection from a theoretical standpoint, aiming to enhance
multimodal/multichannel system design, especially for biomedical
multichannel/multimodal applications.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15726" title="Abstract">arXiv:2312.15726</a> [<a href="/pdf/2312.15726" title="Download PDF">pdf</a>, <a href="/format/2312.15726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discontinuous Virtual Element Method for an elliptic variational  inequality of the second kind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartosz%2C+K">Krzysztof Bartosz</a>, 
<a href="/search/math?searchtype=author&query=Szafraniec%2C+P">Pawel Szafraniec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work, we analyse a simplified frictional contact problem and its
variational formulation that has a form of the elliptic variational inequality
of the second kind. For this problem, we consider a numerical approximation
based on virtual element method (VEM). The novelty of our approach consists in
the fact that we deal with a discontinuous version of the VEM. Our analysis
concerns the error estimation between the exact solution of the simplified
frictional contact problem and the approximate one.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15729" title="Abstract">arXiv:2312.15729</a> [<a href="/pdf/2312.15729" title="Download PDF">pdf</a>, <a href="/format/2312.15729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity-Based Recruitment in Crowdsensing By Combinatorial Multi-Armed  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sawwan%2C+A">Abdalaziz Sawwan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper explores mobile crowdsensing, which leverages mobile devices and
their users for collective sensing tasks under the coordination of a central
requester. The primary challenge here is the variability in the sensing
capabilities of individual workers, which are initially unknown and must be
progressively learned. In each round of task assignment, the requester selects
a group of workers to handle specific tasks. This process inherently leads to
task overlaps in the same round and repetitions across rounds. We propose a
novel model that enhances task diversity over the rounds by dynamically
adjusting the weight of tasks in each round based on their frequency of
assignment. Additionally, it accommodates the variability in task completion
quality caused by overlaps in the same round, which can range from the maximum
individual worker's quality to the summation of qualities of all assigned
workers in the overlap. A significant constraint in this process is the
requester's budget, which demands an efficient strategy for worker recruitment.
Our solution is to maximize the overall weighted quality of tasks completed in
each round. We employ a combinatorial multi-armed bandit framework with an
upper confidence bound approach for this purpose. The paper further presents a
regret analysis and simulations using realistic data to demonstrate the
efficacy of our model.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15731" title="Abstract">arXiv:2312.15731</a> [<a href="/pdf/2312.15731" title="Download PDF">pdf</a>, <a href="/format/2312.15731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinagyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haoran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianxiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Few-Shot Segmentation (FSS) aims to accomplish the novel class
segmentation task with a few annotated images. Current FSS research based on
meta-learning focus on designing a complex interaction mechanism between the
query and support feature. However, unlike humans who can rapidly learn new
things from limited samples, the existing approach relies solely on fixed
feature matching to tackle new tasks, lacking adaptability. In this paper, we
propose a novel framework based on the adapter mechanism, namely Adaptive FSS,
which can efficiently adapt the existing FSS model to the novel classes. In
detail, we design the Prototype Adaptive Module (PAM), which utilizes accurate
category information provided by the support set to derive class prototypes,
enhancing class-specific information in the multi-stage representation. In
addition, our approach is compatible with in diverse FSS methods with different
backbones by simply inserting PAM between the layers of the encoder.
Experiments demonstrate that our method effectively improves the performance of
the FSS models (e.g., MSANet, HDMNet, FPTrans, and DCAMA) and achieve new
state-of-the-art (SOTA) results (i.e., 72.4\% and 79.1\% mIoU on PASCAL-5$^i$
1-shot and 5-shot settings, 52.7\% and 60.0\% mIoU on COCO-20$^i$ 1-shot and
5-shot settings). Our code can be available at
https://github.com/jingw193/Adaptive_FSS.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15736" title="Abstract">arXiv:2312.15736</a> [<a href="/pdf/2312.15736" title="Download PDF">pdf</a>, <a href="/format/2312.15736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Blind Face Restoration with Generative Diffusion  Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jingfan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaocun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Blind face restoration is an important task in computer vision and has gained
significant attention due to its wide-range applications. In this work, we
delve into the potential of leveraging the pretrained Stable Diffusion for
blind face restoration. We propose BFRffusion which is thoughtfully designed to
effectively extract features from low-quality face images and could restore
realistic and faithful facial details with the generative prior of the
pretrained Stable Diffusion. In addition, we build a privacy-preserving face
dataset called PFHQ with balanced attributes like race, gender, and age. This
dataset can serve as a viable alternative for training blind face restoration
methods, effectively addressing privacy and bias concerns usually associated
with the real face datasets. Through an extensive series of experiments, we
demonstrate that our BFRffusion achieves state-of-the-art performance on both
synthetic and real-world public testing datasets for blind face restoration and
our PFHQ dataset is an available resource for training blind face restoration
networks. The codes, pretrained models, and dataset are released at
https://github.com/chenxx89/BFRffusion.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15738" title="Abstract">arXiv:2312.15738</a> [<a href="/pdf/2312.15738" title="Download PDF">pdf</a>, <a href="/ps/2312.15738" title="Download PostScript">ps</a>, <a href="/format/2312.15738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Robot Motion Block of A-star Algorithm for Robotic Path  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabir%2C+R">Raihan Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Watanobe%2C+Y">Yutaka Watanobe</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+R">Md. Rashedul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Naruse%2C+K">Keitaro Naruse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">An efficient robot path-planning model is vulnerable to the number of search
nodes, path cost, and time complexity. The conventional A-star (A*) algorithm
outperforms other grid-based algorithms for its heuristic search. However it
shows suboptimal performance for the time, space, and number of search nodes,
depending on the robot motion block (RMB). To address this challenge, this
study proposes an optimal RMB for the A* path-planning algorithm to enhance the
performance, where the robot movement costs are calculated by the proposed
adaptive cost function. Also, a selection process is proposed to select the
optimal RMB size. In this proposed model, grid-based maps are used, where the
robot's next move is determined based on the adaptive cost function by
searching among surrounding octet neighborhood grid cells. The cumulative value
from the output data arrays is used to determine the optimal motion block size,
which is formulated based on parameters. The proposed RMB significantly affects
the searching time complexity and number of search nodes of the A* algorithm
while maintaining almost the same path cost to find the goal position by
avoiding obstacles. For the experiment, a benchmarked online dataset is used
and prepared three different dimensional maps. The proposed approach is
validated using approximately 7000 different grid maps with various dimensions
and obstacle environments. The proposed model with an optimal RMB demonstrated
a remarkable improvement of 93.98% in the number of search cells and 98.94% in
time complexity compared to the conventional A* algorithm. Path cost for the
proposed model remained largely comparable to other state-of-the-art
algorithms. Also, the proposed model outperforms other state-of-the-art
algorithms.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15740" title="Abstract">arXiv:2312.15740</a> [<a href="/pdf/2312.15740" title="Download PDF">pdf</a>, <a href="/format/2312.15740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiSwift: Bandwidth Orchestrator for Multi-Stream Video Analytics on Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tingting Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+L">Liang Mi</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Haipeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaoming Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE INFOCOM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">High-definition (HD) cameras for surveillance and road traffic have
experienced tremendous growth, demanding intensive computation resources for
real-time analytics. Recently, offloading frames from the front-end device to
the back-end edge server has shown great promise. In multi-stream competitive
environments, efficient bandwidth management and proper scheduling are crucial
to ensure both high inference accuracy and high throughput. To achieve this
goal, we propose BiSwift, a bi-level framework that scales the concurrent
real-time video analytics by a novel adaptive hybrid codec integrated with
multi-level pipelines, and a global bandwidth controller for multiple video
streams. The lower-level front-back-end collaborative mechanism (called
adaptive hybrid codec) locally optimizes the accuracy and accelerates
end-to-end video analytics for a single stream. The upper-level scheduler aims
to accuracy fairness among multiple streams via the global bandwidth
controller. The evaluation of BiSwift shows that BiSwift is able to real-time
object detection on 9 streams with an edge device only equipped with an NVIDIA
RTX3070 (8G) GPU. BiSwift improves 10%$\sim$21% accuracy and presents
1.2$\sim$9$\times$ throughput compared with the state-of-the-art video
analytics pipelines.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15741" title="Abstract">arXiv:2312.15741</a> [<a href="/pdf/2312.15741" title="Download PDF">pdf</a>, <a href="/ps/2312.15741" title="Download PostScript">ps</a>, <a href="/format/2312.15741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Accuracy and Interpretability of Neural Networks for Wind  Power Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/eess?searchtype=author&query=Porte-Agel%2C+F">Fernando Porte-Agel</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+J">Jiannong Fang</a>, 
<a href="/search/eess?searchtype=author&query=Bak-Jensen%2C+B">Birgitte Bak-Jensen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhe Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+G">Gonghao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNNs) are receiving increasing attention in wind power
forecasting due to their ability to effectively capture complex patterns in
wind data. However, their forecasted errors are severely limited by the local
optimal weight issue in optimization algorithms, and their forecasted behavior
also lacks interpretability. To address these two challenges, this paper
firstly proposes simple but effective triple optimization strategies (TriOpts)
to accelerate the training process and improve the model performance of DNNs in
wind power forecasting. Then, permutation feature importance (PFI) and local
interpretable model-agnostic explanation (LIME) techniques are innovatively
presented to interpret forecasted behaviors of DNNs, from global and instance
perspectives. Simulation results show that the proposed TriOpts not only
drastically improve the model generalization of DNNs for both the deterministic
and probabilistic wind power forecasting, but also accelerate the training
process. Besides, the proposed PFI and LIME techniques can accurately estimate
the contribution of each feature to wind power forecasting, which helps to
construct feature engineering and understand how to obtain forecasted values
for a given sample.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15742" title="Abstract">arXiv:2312.15742</a> [<a href="/pdf/2312.15742" title="Download PDF">pdf</a>, <a href="/format/2312.15742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DI-V2X: Learning Domain-Invariant Representation for  Vehicle-Infrastructure Collaborative 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Li Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junbo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng-Zhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruigang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianbing Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> aaai2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vehicle-to-Everything (V2X) collaborative perception has recently gained
significant attention due to its capability to enhance scene understanding by
integrating information from various agents, e.g., vehicles, and
infrastructure. However, current works often treat the information from each
agent equally, ignoring the inherent domain gap caused by the utilization of
different LiDAR sensors of each agent, thus leading to suboptimal performance.
In this paper, we propose DI-V2X, that aims to learn Domain-Invariant
representations through a new distillation framework to mitigate the domain
discrepancy in the context of V2X 3D object detection. DI-V2X comprises three
essential components: a domain-mixing instance augmentation (DMA) module, a
progressive domain-invariant distillation (PDD) module, and a domain-adaptive
fusion (DAF) module. Specifically, DMA builds a domain-mixing 3D instance bank
for the teacher and student models during training, resulting in aligned data
representation. Next, PDD encourages the student models from different domains
to gradually learn a domain-invariant feature representation towards the
teacher, where the overlapping regions between agents are employed as guidance
to facilitate the distillation process. Furthermore, DAF closes the domain gap
between the students by incorporating calibration-aware domain-adaptive
attention. Extensive experiments on the challenging DAIR-V2X and V2XSet
benchmark datasets demonstrate DI-V2X achieves remarkable performance,
outperforming all the previous V2X models. Code is available at
https://github.com/Serenos/DI-V2X
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15744" title="Abstract">arXiv:2312.15744</a> [<a href="/pdf/2312.15744" title="Download PDF">pdf</a>, <a href="/format/2312.15744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intelligent Indoor Positioning Algorithm Based on Wi-Fi and Bluetooth  Low Energy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beigi%2C+K">Karamat Beigi</a>, 
<a href="/search/cs?searchtype=author&query=Shah-Mansouri%2C+H">Hamed Shah-Mansouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Indoor positioning plays a pivotal role in a wide range of applications, from
smart homes to industrial automation. In this paper, we propose a comprehensive
approach for accurate positioning in indoor environments through the
integration of existing Wi-Fi and Bluetooth Low Energy (BLE) devices. The
proposed algorithm involves acquiring the received signal strength indicator
(RSSI) data from these devices and capturing the complex interactions between
RSSI and positions. To enhance the accuracy of the collected data, we first use
a Kalman filter for denoising RSSI values, then categorize them into distinct
classes using the K-nearest neighbor (KNN) algorithm. Incorporating the
filtered RSSI data and the class information obtained from KNN, we then
introduce a recurrent neural network (RNN) architecture to estimate the
positions with a high precision. We further evaluate the accuracy of our
proposed algorithm through testbed experiments using ESP32 system on chip with
integrated Wi-Fi and BLE. The results show that we can accurately estimate the
positions with an average error of 61.29 cm, which demonstrates a 56\%
enhancement compared to the state-of-the-art existing works.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15746" title="Abstract">arXiv:2312.15746</a> [<a href="/pdf/2312.15746" title="Download PDF">pdf</a>, <a href="/format/2312.15746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Not Stable Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tianhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the significant successes of large language models (LLMs) in many
natural language processing tasks, there is growing interest among researchers
in exploring LLMs for novel recommender systems. However, we have observed that
directly using LLMs as a recommender system is usually unstable due to its
inherent position bias. To this end, we introduce exploratory research and find
consistent patterns of positional bias in LLMs that influence the performance
of recommendation across a range of scenarios. Then, we propose a Bayesian
probabilistic framework, STELLA (Stable LLM for Recommendation), which involves
a two-stage pipeline. During the first probing stage, we identify patterns in a
transition matrix using a probing detection dataset. And in the second
recommendation stage, a Bayesian strategy is employed to adjust the biased
output of LLMs with an entropy indicator. Therefore, our framework can
capitalize on existing pattern information to calibrate instability of LLMs,
and enhance recommendation performance. Finally, extensive experiments clearly
validate the effectiveness of our framework.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15747" title="Abstract">arXiv:2312.15747</a> [<a href="/pdf/2312.15747" title="Download PDF">pdf</a>, <a href="/format/2312.15747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Image and Scalar-Based Approaches in Preconditioner  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Souza%2C+M">Michael Souza</a>, 
<a href="/search/math?searchtype=author&query=Carvalho%2C+L+M">Luiz M. Carvalho</a>, 
<a href="/search/math?searchtype=author&query=Augusto%2C+D">Douglas Augusto</a>, 
<a href="/search/math?searchtype=author&query=Panetta%2C+J">Jairo Panetta</a>, 
<a href="/search/math?searchtype=author&query=Goldfeld%2C+P">Paulo Goldfeld</a>, 
<a href="/search/math?searchtype=author&query=Rodrigues%2C+J+R+P">Jos&#xe9; R.P. Rodrigues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Within high-performance computing (HPC), solving large sparse linear systems
efficiently remains paramount, with iterative methods being the predominant
choice. However, the performance of these methods is tightly coupled to the
aptness of the chosen preconditioner. The multifaceted nature of sparse
matrices makes the universal prescription of preconditioners elusive. Notably,
the key attribute of sparsity is not precisely captured by scalar metrics such
as bandwidth or matrix dimensions. Advancing prior methodologies, this research
introduces matrix sparsity depiction via RGB images. Utilizing a convolutional
neural network (CNN), the task of preconditioner selection turns into a
multi-class classification problem. Extensive tests on 126 SuiteSparse matrices
emphasize the enhanced prowess of the CNN model, noting a 32% boost in accuracy
and a 25% reduction in computational slowdown.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15751" title="Abstract">arXiv:2312.15751</a> [<a href="/pdf/2312.15751" title="Download PDF">pdf</a>, <a href="/format/2312.15751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Label Variation in Scientific Information Extraction via  Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+D">Dong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+X">Xanh Ho</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+Q">Quang-Thuy Ha</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+A">Akiko Aizawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, PACLIC 37
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Scientific Information Extraction (ScientificIE) is a critical task that
involves the identification of scientific entities and their relationships. The
complexity of this task is compounded by the necessity for domain-specific
knowledge and the limited availability of annotated data. Two of the most
popular datasets for ScientificIE are SemEval-2018 Task-7 and SciERC. They have
overlapping samples and differ in their annotation schemes, which leads to
conflicts. In this study, we first introduced a novel approach based on
multi-task learning to address label variations. We then proposed a soft
labeling technique that converts inconsistent labels into probabilistic
distributions. The experimental results demonstrated that the proposed method
can enhance the model robustness to label noise and improve the end-to-end
performance in both ScientificIE tasks. The analysis revealed that label
variations can be particularly effective in handling ambiguous instances.
Furthermore, the richness of the information captured by label variations can
potentially reduce data size requirements. The findings highlight the
importance of releasing variation labels and promote future research on other
tasks in other domains. Overall, this study demonstrates the effectiveness of
multi-task learning and the potential of label variations to enhance the
performance of ScientificIE.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15757" title="Abstract">arXiv:2312.15757</a> [<a href="/pdf/2312.15757" title="Download PDF">pdf</a>, <a href="/ps/2312.15757" title="Download PostScript">ps</a>, <a href="/format/2312.15757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic MIMO Architecture Design for Near-Field Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A novel dynamic hybrid beamforming architecture is proposed to achieve the
spatial multiplexing-power consumption tradeoff for near-field multiple-input
multiple-output (MIMO) networks, where each radio frequency (RF) chain is
connected to each antenna using a couple of independent phase shifters to
reduce the number of required RF chains. Based on this architecture, an
optimization problem is formulated that maximizes the sum of achievable rates
while minimizing the hardware power consumption. Both continuous and discrete
phase shifters are considered. 1) For continuous phase shifters, a weighted
minimum mean-square error-based two-stage (WMMSE-TS) algorithm is proposed,
where the same performance as the optimal fully-digital beamformer can be
achieved by the proposed hybrid beamformer even if the number of RF chains
equals the number of data streams. 2) For discrete phase shifters, a
penalty-based layered iterative (PLI) algorithm is proposed. The closed-form
analog and baseband digital beamformers are derived in each iteration.
Simulation results demonstrate that: 1) the proposed dynamic beamforming
architecture outperforms the conventional fixed hybrid beamforming architecture
in terms of spatial multiplexing-power consumption tradeoff, and 2) the
proposed algorithms achieve better performance than the other baseline schemes.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15762" title="Abstract">arXiv:2312.15762</a> [<a href="/pdf/2312.15762" title="Download PDF">pdf</a>, <a href="/format/2312.15762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robust Wasserstein Barycenter: The Model and Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qingyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Algorithms for accelerating robust Wasserstein barycenter problem
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Wasserstein barycenter problem is to compute the average of $m$ given
probability measures, which has been widely studied in many different areas;
however, real-world data sets are often noisy and huge, which impedes its
applications in practice. Hence, in this paper, we focus on improving the
computational efficiency of two types of robust Wasserstein barycenter problem
(RWB): fixed-support RWB (fixed-RWB) and free-support RWB (free-RWB); actually,
the former is a subroutine of the latter. Firstly, we improve efficiency
through model reducing; we reduce RWB as an augmented Wasserstein barycenter
problem, which works for both fixed-RWB and free-RWB. Especially, fixed-RWB can
be computed within $\widetilde{O}(\frac{mn^2}{\epsilon_+})$ time by using an
off-the-shelf solver, where $\epsilon_+$ is the pre-specified additive error
and $n$ is the size of locations of input measures. Then, for free-RWB, we
leverage a quality guaranteed data compression technique, coreset, to
accelerate computation by reducing the data set size $m$. It shows that running
algorithms on the coreset is enough instead of on the original data set. Next,
by combining the model reducing and coreset techniques above, we propose an
algorithm for free-RWB by updating the weights and locations alternatively.
Finally, our experiments demonstrate the efficiency of our techniques.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15763" title="Abstract">arXiv:2312.15763</a> [<a href="/pdf/2312.15763" title="Download PDF">pdf</a>, <a href="/format/2312.15763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Distributed Multi-User Secret Sharing with Multiple Secrets per User
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chigullapally%2C+R">Rasagna Chigullapally</a>, 
<a href="/search/cs?searchtype=author&query=Athi%2C+H">Harshithanjani Athi</a>, 
<a href="/search/cs?searchtype=author&query=Karamchandani%2C+N">Nikhil Karamchandani</a>, 
<a href="/search/cs?searchtype=author&query=Lalitha%2C+V">V. Lalitha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider a distributed multi-user secret sharing (DMUSS) setting in which
there is a dealer, $n$ storage nodes, and $m$ secrets. Each user demands a
$t$-subset of $m$ secrets. Earlier work in this setting dealt with the case of
$t=1$; in this work, we consider general $t$. The user downloads shares from
the storage nodes based on the designed access structure and reconstructs its
secrets. We identify a necessary condition on the access structures to ensure
weak secrecy. We also make a connection between access structures for this
problem and $t$-disjunct matrices. We apply various $t$-disjunct matrix
constructions in this setting and compare their performance in terms of the
number of storage nodes and communication complexity. We also derive bounds on
the optimal communication complexity of a distributed secret sharing protocol.
Finally, we characterize the capacity region of the DMUSS problem when the
access structure is specified.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15769" title="Abstract">arXiv:2312.15769</a> [<a href="/pdf/2312.15769" title="Download PDF">pdf</a>, <a href="/ps/2312.15769" title="Download PostScript">ps</a>, <a href="/format/2312.15769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lp-Norm Constrained One-Class Classifier Combination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nourmohammadi%2C+S">Sepehr Nourmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Arashloo%2C+S+R">Shervin Rahimzadeh Arashloo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Classifier fusion is established as an effective methodology for boosting
performance in different settings and one-class classification is no exception.
In this study, we consider the one-class classifier fusion problem by modelling
the sparsity/uniformity of the ensemble. To this end, we formulate a convex
objective function to learn the weights in a linear ensemble model and impose a
variable Lp-norm constraint on the weight vector. The vector-norm constraint
enables the model to adapt to the intrinsic uniformity/sparsity of the ensemble
in the space of base learners and acts as a (soft) classifier selection
mechanism by shaping the relative magnitudes of fusion weights. Drawing on the
Frank-Wolfe algorithm, we then present an effective approach to solve the
formulated convex constrained optimisation problem efficiently. We evaluate the
proposed one-class classifier combination approach on multiple data sets from
diverse application domains and illustrate its merits in comparison to the
existing approaches.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15770" title="Abstract">arXiv:2312.15770</a> [<a href="/pdf/2312.15770" title="Download PDF">pdf</a>, <a href="/format/2312.15770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Recipe for Scaling up Text-to-Video Generation with Text-free Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hangjie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhiwu Qing</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tf-t2v.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion-based text-to-video generation has witnessed impressive progress in
the past year yet still falls behind text-to-image generation. One of the key
reasons is the limited scale of publicly available data (e.g., 10M video-text
pairs in WebVid10M vs. 5B image-text pairs in LAION), considering the high cost
of video captioning. Instead, it could be far easier to collect unlabeled clips
from video platforms like YouTube. Motivated by this, we come up with a novel
text-to-video generation framework, termed TF-T2V, which can directly learn
with text-free videos. The rationale behind is to separate the process of text
decoding from that of temporal modeling. To this end, we employ a content
branch and a motion branch, which are jointly optimized with weights shared.
Following such a pipeline, we study the effect of doubling the scale of
training set (i.e., video-only WebVid10M) with some randomly collected
text-free videos and are encouraged to observe the performance improvement (FID
from 9.67 to 8.19 and FVD from 484 to 441), demonstrating the scalability of
our approach. We also find that our model could enjoy sustainable performance
gain (FID from 8.19 to 7.64 and FVD from 441 to 366) after reintroducing some
text labels for training. Finally, we validate the effectiveness and
generalizability of our ideology on both native text-to-video generation and
compositional video synthesis paradigms. Code and models will be publicly
available at https://tf-t2v.github.io/.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15771" title="Abstract">arXiv:2312.15771</a> [<a href="/pdf/2312.15771" title="Download PDF">pdf</a>, <a href="/format/2312.15771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Optimal System and Controller Design for Multibody Systems  with Joint Friction using Direct Sensitivities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verulkar%2C+A">Adwait Verulkar</a>, 
<a href="/search/eess?searchtype=author&query=Sandu%2C+C">Corina Sandu</a>, 
<a href="/search/eess?searchtype=author&query=Sandu%2C+A">Adrian Sandu</a>, 
<a href="/search/eess?searchtype=author&query=Dopico%2C+D">Daniel Dopico</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computational Engineering, Finance, and Science (cs.CE); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Real-world multibody systems are often subject to phenomena like friction,
joint clearances, and external events. These phenomena can significantly impact
the optimal design of the system and its controller. This work addresses the
gradient-based optimization methodology for multibody dynamic systems with
joint friction using a direct sensitivity approach for gradient computation.
After a thorough review of various friction models developed over the years,
the Brown McPhee model has been found to be the most suitable for the study due
to its accuracy for dynamic simulation and its compatibility with sensitivity
analysis. The methodology supports co-design of the system and its controller,
which is especially relevant for applications like robotics and
servo-mechanical systems where the actuation and the design are highly
dependent on each other. Numerical results are obtained using a new
implementation of the MBSVT (Multi-Body Systems at Virginia Tech) software
package; MBSVT 2.0 is reprogrammed in Julia for ease of implementation while
maintaining high computational efficiency. Three case studies are provided to
demonstrate the attractive properties of simultaneous optimal design and
control approach for certain applications.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15779" title="Abstract">arXiv:2312.15779</a> [<a href="/pdf/2312.15779" title="Download PDF">pdf</a>, <a href="/ps/2312.15779" title="Download PostScript">ps</a>, <a href="/format/2312.15779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Implementation of a Tool for Extracting Uzbek Syllables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salaev%2C+U">Ulugbek Salaev</a>, 
<a href="/search/cs?searchtype=author&query=Kuriyozov%2C+E">Elmurod Kuriyozov</a>, 
<a href="/search/cs?searchtype=author&query=Matlatipov%2C+G">Gayrat Matlatipov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at The Proceedings of 2023 IEEE XVI International Scientific and Technical Conference Actual Problems of Electronic Instrument Engineering (APEIE), 10-12 Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The accurate syllabification of words plays a vital role in various Natural
Language Processing applications. Syllabification is a versatile linguistic
tool with applications in linguistic research, language technology, education,
and various fields where understanding and processing language is essential. In
this paper, we present a comprehensive approach to syllabification for the
Uzbek language, including rule-based techniques and machine learning
algorithms. Our rule-based approach utilizes advanced methods for dividing
words into syllables, generating hyphenations for line breaks and count of
syllables. Additionally, we collected a dataset for evaluating and training
using machine learning algorithms comprising word-syllable mappings,
hyphenations, and syllable counts to predict syllable counts as well as for the
evaluation of the proposed model. Our results demonstrate the effectiveness and
efficiency of both approaches in achieving accurate syllabification. The
results of our experiments show that both approaches achieved a high level of
accuracy, exceeding 99%. This study provides valuable insights and
recommendations for future research on syllabification and related areas in not
only the Uzbek language itself, but also in other closely-related Turkic
languages with low-resource factor.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15784" title="Abstract">arXiv:2312.15784</a> [<a href="/pdf/2312.15784" title="Download PDF">pdf</a>, <a href="/format/2312.15784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AHAM: Adapt, Help, Ask, Model -- Harvesting LLMs for literature mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koloski%2C+B">Boshko Koloski</a>, 
<a href="/search/cs?searchtype=author&query=Lavra%C4%8D%2C+N">Nada Lavra&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Cestnik%2C+B">Bojan Cestnik</a>, 
<a href="/search/cs?searchtype=author&query=Pollak%2C+S">Senja Pollak</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0krlj%2C+B">Bla&#x17e; &#x160;krlj</a>, 
<a href="/search/cs?searchtype=author&query=Kastrin%2C+A">Andrej Kastrin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IDA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In an era marked by a rapid increase in scientific publications, researchers
grapple with the challenge of keeping pace with field-specific advances. We
present the `AHAM' methodology and a metric that guides the domain-specific
\textbf{adapt}ation of the BERTopic topic modeling framework to improve
scientific text analysis. By utilizing the LLaMa2 generative language model, we
generate topic definitions via one-shot learning by crafting prompts with the
\textbf{help} of domain experts to guide the LLM for literature mining by
\textbf{asking} it to model the topic names. For inter-topic similarity
evaluation, we leverage metrics from language generation and translation
processes to assess lexical and semantic similarity of the generated topics.
Our system aims to reduce both the ratio of outlier topics to the total number
of topics and the similarity between topic definitions. The methodology has
been assessed on a newly gathered corpus of scientific papers on
literature-based discovery. Through rigorous evaluation by domain experts, AHAM
has been validated as effective in uncovering intriguing and novel insights
within broad research areas. We explore the impact of domain adaptation of
sentence-transformers for the task of topic \textbf{model}ing using two
datasets, each specialized to specific scientific domains within arXiv and
medarxiv. We evaluate the impact of data size, the niche of adaptation, and the
importance of domain adaptation. Our results suggest a strong interaction
between domain adaptation and topic modeling precision in terms of outliers and
topic definitions.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15786" title="Abstract">arXiv:2312.15786</a> [<a href="/pdf/2312.15786" title="Download PDF">pdf</a>, <a href="/format/2312.15786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding 1-Planar Graphs in Ten Pages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandenburg%2C+F+J">Franz J. Brandenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Every planar graph has a 4-page book embedding and this bound is tight. We
show that every 1-planar graph, which is a graph that admits a drawing with at
most one crossing per edge, has a 10-page book embedding. In addition, four
pages are sometimes necessary and always sufficient if the planar skeleton,
obtained from a 1-planar drawing by removing all crossed edges, has a
Hamiltonian cycle.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15788" title="Abstract">arXiv:2312.15788</a> [<a href="/pdf/2312.15788" title="Download PDF">pdf</a>, <a href="/format/2312.15788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Stochastically-Descending Unrolled Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hadou%2C+S">Samar Hadou</a>, 
<a href="/search/cs?searchtype=author&query=NaderiAlizadeh%2C+N">Navid NaderiAlizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Deep unrolling, or unfolding, is an emerging learning-to-optimize method that
unrolls a truncated iterative algorithm in the layers of a trainable neural
network. However, the convergence guarantees and generalizability of the
unrolled networks are still open theoretical problems. To tackle these
problems, we provide deep unrolled architectures with a stochastic descent
nature by imposing descending constraints during training. The descending
constraints are forced layer by layer to ensure that each unrolled layer takes,
on average, a descent step toward the optimum during training. We theoretically
prove that the sequence constructed by the outputs of the unrolled layers is
then guaranteed to converge for unseen problems, assuming no distribution shift
between training and test problems. We also show that standard unrolling is
brittle to perturbations, and our imposed constraints provide the unrolled
networks with robustness to additive noise and perturbations. We numerically
assess unrolled architectures trained under the proposed constraints in two
different applications, including the sparse coding using learnable iterative
shrinkage and thresholding algorithm (LISTA) and image inpainting using
proximal generative flow (GLOW-Prox), and demonstrate the performance and
robustness benefits of the proposed method.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15793" title="Abstract">arXiv:2312.15793</a> [<a href="/pdf/2312.15793" title="Download PDF">pdf</a>, <a href="/format/2312.15793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unique Triangulated 1-Planar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandenburg%2C+F+J">Franz J. Brandenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">It is well-known that every 3-connected planar graph has a unique planar
embedding on the sphere. We study the extension to triangulated 1-planar
graphs, T1P graphs for short, which admit an embedding in which each edge is
crossed at most once and each face is a triangle, and obtain an algorithmic
solution by a cubic time recognition algorithm that also counts the number of
T1P embeddings. In particular, we show that every triangulated planar graph has
a unique T1P embedding, although it may admit many 1-planar embeddings, and
that any 6-connected T1P graph has a unique 1-planar embedding, except for full
generalized two-stars that admit two or eight 1-planar embeddings. Our
algorithm extends, refines, and corrects a previous recognition algorithm by
Chen, Grigni and Papadimitiou (``Recognizing Hole-Free 4-Map Graphs in Cubic
Time'', Algorithmica 45 (2006)).
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15796" title="Abstract">arXiv:2312.15796</a> [<a href="/pdf/2312.15796" title="Download PDF">pdf</a>, <a href="/format/2312.15796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenCast: Diffusion-based ensemble forecasting for medium-range weather
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Price%2C+I">Ilan Price</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez-Gonzalez%2C+A">Alvaro Sanchez-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Alet%2C+F">Ferran Alet</a>, 
<a href="/search/cs?searchtype=author&query=Ewalds%2C+T">Timo Ewalds</a>, 
<a href="/search/cs?searchtype=author&query=El-Kadi%2C+A">Andrew El-Kadi</a>, 
<a href="/search/cs?searchtype=author&query=Stott%2C+J">Jacklynn Stott</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Shakir Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Battaglia%2C+P">Peter Battaglia</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+R">Remi Lam</a>, 
<a href="/search/cs?searchtype=author&query=Willson%2C+M">Matthew Willson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text 15 pages, Appendices 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Probabilistic weather forecasting is critical for decision-making in
high-impact domains such as flood forecasting, energy system planning or
transportation routing, where quantifying the uncertainty of a forecast --
including probabilities of extreme events -- is essential to guide important
cost-benefit trade-offs and mitigation measures. Traditional probabilistic
approaches rely on producing ensembles from physics-based models, which sample
from a joint distribution over spatio-temporally coherent weather trajectories,
but are expensive to run. An efficient alternative is to use a machine learning
(ML) forecast model to generate the ensemble, however state-of-the-art ML
forecast models for medium-range weather are largely trained to produce
deterministic forecasts which minimise mean-squared-error. Despite improving
skills scores, they lack physical consistency, a limitation that grows at
longer lead times and impacts their ability to characterize the joint
distribution. We introduce GenCast, a ML-based generative model for ensemble
weather forecasting, trained from reanalysis data. It forecasts ensembles of
trajectories for 84 weather variables, for up to 15 days at 1 degree resolution
globally, taking around a minute per ensemble member on a single Cloud TPU v4
device. We show that GenCast is more skillful than ENS, a top operational
ensemble forecast, for more than 96\% of all 1320 verification targets on CRPS
and Ensemble-Mean RMSE, while maintaining good reliability and physically
consistent power spectra. Together our results demonstrate that ML-based
probabilistic weather forecasting can now outperform traditional ensemble
systems at 1 degree, opening new doors to skillful, fast weather forecasts that
are useful in key applications.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15805" title="Abstract">arXiv:2312.15805</a> [<a href="/pdf/2312.15805" title="Download PDF">pdf</a>, <a href="/format/2312.15805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astrocyte Regulated Neuromorphic CPG Control of Legged Robotic  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhuangyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Abhronil Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Neuromorphic computing systems, where information is transmitted through
action potentials in a bio-plausible fashion, is gaining increasing interest
due to its promise of low-power event-driven computing. Application of
neuromorphic computing in robotic locomotion research have largely focused on
Central Pattern Generators (CPGs) for bionics robotic control algorithms -
inspired from neural circuits governing the collaboration of the limb muscles
in animal movement. Implementation of artificial CPGs on neuromorphic hardware
platforms can potentially enable adaptive and energy-efficient edge robotics
applications in resource constrained environments. However, underlying rewiring
mechanisms in CPG for gait emergence process is not well understood. This work
addresses the missing gap in literature pertaining to CPG plasticity and
underscores the critical homeostatic functionality of astrocytes - a cellular
component in the brain that is believed to play a major role in multiple brain
functions. This paper introduces an astrocyte regulated Spiking Neural Network
(SNN)-based CPG for learning locomotion gait through Reward-Modulated STDP
(Izhikevich 2007) for quadruped robots, where the astrocytes help build
inhibitory connections among the artificial motor neurons in different limbs.
The SNN-based CPG is simulated on a multi-object physics simulation platform
resulting in the emergence of a trotting gait while running the robot on flat
ground. $23.3\times$ computational power savings is observed in comparison to a
state-of-the-art reinforcement learning based robot control algorithm. Such a
neuroscience-algorithm co-design approach can potentially enable a quantum leap
in the functionality of neuromorphic systems incorporating glial cell
functionality.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15808" title="Abstract">arXiv:2312.15808</a> [<a href="/pdf/2312.15808" title="Download PDF">pdf</a>, <a href="/format/2312.15808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Assisted Online Task Offloading and Resource Allocation in  MEC-Enabled Satellite-Aerial-Terrestrial Integrated Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yanmin Gong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanxiong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In the era of Internet of Things (IoT), multi-access edge computing
(MEC)-enabled satellite-aerial-terrestrial integrated network (SATIN) has
emerged as a promising technology to provide massive IoT devices with seamless
and reliable communication and computation services. This paper investigates
the cooperation of low Earth orbit (LEO) satellites, high altitude platforms
(HAPs), and terrestrial base stations (BSs) to provide relaying and computation
services for vastly distributed IoT devices. Considering the uncertainty in
dynamic SATIN systems, we formulate a stochastic optimization problem to
minimize the time-average expected service delay by jointly optimizing resource
allocation and task offloading while satisfying the energy constraints. To
solve the formulated problem, we first develop a Lyapunov-based online control
algorithm to decompose it into multiple one-slot problems. Since each one-slot
problem is a large-scale mixed-integer nonlinear program (MINLP) that is
intractable for classical computers, we further propose novel hybrid
quantum-classical generalized Benders' decomposition (HQCGBD) algorithms to
solve the problem efficiently by leveraging quantum advantages in parallel
computing. Numerical results validate the effectiveness of the proposed
MEC-enabled SATIN schemes.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15809" title="Abstract">arXiv:2312.15809</a> [<a href="/pdf/2312.15809" title="Download PDF">pdf</a>, <a href="/format/2312.15809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closed-Loop Multi-perspective Visual Servoing Approach with  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jiacheng Pei</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+K">Kaixin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaopeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Robotics and Biomimetics (ROBIO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional visual servoing methods suffer from serving between scenes from
multiple perspectives, which humans can complete with visual signals alone. In
this paper, we investigated how multi-perspective visual servoing could be
solved under robot-specific constraints, including self-collision, singularity
problems. We presented a novel learning-based multi-perspective visual servoing
framework, which iteratively estimates robot actions from latent space
representations of visual states using reinforcement learning. Furthermore, our
approaches were trained and validated in a Gazebo simulation environment with
connection to OpenAI/Gym. Through simulation experiments, we showed that our
method can successfully learn an optimal control policy given initial images
from different perspectives, and it outperformed the Direct Visual Servoing
algorithm with mean success rate of 97.0%.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15813" title="Abstract">arXiv:2312.15813</a> [<a href="/pdf/2312.15813" title="Download PDF">pdf</a>, <a href="/format/2312.15813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Effect Sizes in Malware Detection? Make Harder Train/Test Splits!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+T">Tirth Patel</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fred Lu</a>, 
<a href="/search/cs?searchtype=author&query=Raff%2C+E">Edward Raff</a>, 
<a href="/search/cs?searchtype=author&query=Nicholas%2C+C">Charles Nicholas</a>, 
<a href="/search/cs?searchtype=author&query=Matuszek%2C+C">Cynthia Matuszek</a>, 
<a href="/search/cs?searchtype=author&query=Holt%2C+J">James Holt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Conference on Applied Machine Learning for Information Security 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Industry practitioners care about small improvements in malware detection
accuracy because their models are deployed to hundreds of millions of machines,
meaning a 0.1\% change can cause an overwhelming number of false positives.
However, academic research is often restrained to public datasets on the order
of ten thousand samples and is too small to detect improvements that may be
relevant to industry. Working within these constraints, we devise an approach
to generate a benchmark of configurable difficulty from a pool of available
samples. This is done by leveraging malware family information from tools like
AVClass to construct training/test splits that have different generalization
rates, as measured by a secondary model. Our experiments will demonstrate that
using a less accurate secondary model with disparate features is effective at
producing benchmarks for a more sophisticated target model that is under
evaluation. We also ablate against alternative designs to show the need for our
approach.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15815" title="Abstract">arXiv:2312.15815</a> [<a href="/pdf/2312.15815" title="Download PDF">pdf</a>, <a href="/format/2312.15815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Generalization in Spoken Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Avik Ray</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yilin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in INTERSPEECH 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 24th INTERSPEECH Conference (INTERSPEECH 2023),
  Dublin, Ireland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">State-of-the-art spoken language understanding (SLU) models have shown
tremendous success in benchmark SLU datasets, yet they still fail in many
practical scenario due to the lack of model compositionality when trained on
limited training data. In this paper, we study two types of compositionality:
(a) novel slot combination, and (b) length generalization. We first conduct
in-depth analysis, and find that state-of-the-art SLU models often learn
spurious slot correlations during training, which leads to poor performance in
both compositional cases. To mitigate these limitations, we create the first
compositional splits of benchmark SLU datasets and we propose the first
compositional SLU model, including compositional loss and paired training that
tackle each compositional case respectively. On both benchmark and
compositional splits in ATIS and SNIPS, we show that our compositional SLU
model significantly outperforms (up to $5\%$ F1 score) state-of-the-art BERT
SLU model.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15816" title="Abstract">arXiv:2312.15816</a> [<a href="/pdf/2312.15816" title="Download PDF">pdf</a>, <a href="/format/2312.15816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEILP: Time Prediction over Knowledge Graphs via Logical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+S">Siheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Kerce%2C+J+C">James C Kerce</a>, 
<a href="/search/cs?searchtype=author&query=Fekri%2C+F">Faramarz Fekri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conventional embedding-based models approach event time prediction in
temporal knowledge graphs (TKGs) as a ranking problem. However, they often fall
short in capturing essential temporal relationships such as order and distance.
In this paper, we propose TEILP, a logical reasoning framework that naturaly
integrates such temporal elements into knowledge graph predictions. We first
convert TKGs into a temporal event knowledge graph (TEKG) which has a more
explicit representation of time in term of nodes of the graph. The TEKG equips
us to develop a differentiable random walk approach to time prediction.
Finally, we introduce conditional probability density functions, associated
with the logical rules involving the query interval, using which we arrive at
the time prediction. We compare TEILP with state-of-the-art methods on five
benchmark datasets. We show that our model achieves a significant improvement
over baselines while providing interpretable explanations. In particular, we
consider several scenarios where training samples are limited, event types are
imbalanced, and forecasting the time of future events based on only past events
is desired. In all these cases, TEILP outperforms state-of-the-art methods in
terms of robustness.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15817" title="Abstract">arXiv:2312.15817</a> [<a href="/pdf/2312.15817" title="Download PDF">pdf</a>, <a href="/format/2312.15817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning-Based Framework for Sim-to-Real Mapping of Lidar  Point Clouds in Autonomous Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haghighi%2C+H">Hamed Haghighi</a>, 
<a href="/search/cs?searchtype=author&query=Dianati%2C+M">Mehrdad Dianati</a>, 
<a href="/search/cs?searchtype=author&query=Debattista%2C+K">Kurt Debattista</a>, 
<a href="/search/cs?searchtype=author&query=Donzella%2C+V">Valentina Donzella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Perception sensor models are essential elements of automotive simulation
environments; they also serve as powerful tools for creating synthetic datasets
to train deep learning-based perception models. Developing realistic perception
sensor models poses a significant challenge due to the large gap between
simulated sensor data and real-world sensor outputs, known as the sim-to-real
gap. To address this problem, learning-based models have emerged as promising
solutions in recent years, with unparalleled potential to map low-fidelity
simulated sensor data into highly realistic outputs. Motivated by this
potential, this paper focuses on sim-to-real mapping of Lidar point clouds, a
widely used perception sensor in automated driving systems. We introduce a
novel Contrastive-Learning-based Sim-to-Real mapping framework, namely CLS2R,
inspired by the recent advancements in image-to-image translation techniques.
The proposed CLS2R framework employs a lossless representation of Lidar point
clouds, considering all essential Lidar attributes such as depth, reflectance,
and raydrop. We extensively evaluate the proposed framework, comparing it with
state-of-the-art image-to-image translation methods using a diverse range of
metrics to assess realness, faithfulness, and the impact on the performance of
a downstream task. Our results show that CLS2R demonstrates superior
performance across nearly all metrics. Source code is available at
https://github.com/hamedhaghighi/CLS2R.git.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15819" title="Abstract">arXiv:2312.15819</a> [<a href="/pdf/2312.15819" title="Download PDF">pdf</a>, <a href="/format/2312.15819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viral Marketing in Social Networks with Competing Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zehmakan%2C+A+N">Ahad N. Zehmakan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaotian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongzhi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAMAS-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Consider a directed network where each node is either red (using the red
product), blue (using the blue product), or uncolored (undecided). Then in each
round, an uncolored node chooses red (resp. blue) with some probability
proportional to the number of its red (resp. blue) out-neighbors. What is the
best strategy to maximize the expected final number of red nodes given the
budget to select $k$ red seed nodes? After proving that this problem is
computationally hard, we provide a polynomial time approximation algorithm with
the best possible approximation guarantee, building on the monotonicity and
submodularity of the objective function and exploiting the Monte Carlo method.
Furthermore, our experiments on various real-world and synthetic networks
demonstrate that our proposed algorithm outperforms other algorithms.
Additionally, we investigate the convergence time of the aforementioned process
both theoretically and experimentally. In particular, we prove several tight
bounds on the convergence time in terms of different graph parameters, such as
the number of nodes/edges, maximum out-degree and diameter, by developing novel
proof techniques.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15820" title="Abstract">arXiv:2312.15820</a> [<a href="/pdf/2312.15820" title="Download PDF">pdf</a>, <a href="/format/2312.15820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WebVLN: Vision-and-Language Navigation on Websites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pitawela%2C+D">Dileepa Pitawela</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chongyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gengze Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsiang-Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-and-Language Navigation (VLN) task aims to enable AI agents to
accurately understand and follow natural language instructions to navigate
through real-world environments, ultimately reaching specific target locations.
We recognise a promising opportunity to extend VLN to a comparable navigation
task that holds substantial significance in our daily lives, albeit within the
virtual realm: navigating websites on the Internet. This paper proposes a new
task named Vision-and-Language Navigation on Websites (WebVLN), where we use
question-based instructions to train an agent, emulating how users naturally
browse websites. Unlike the existing VLN task that only pays attention to
vision and instruction (language), the WebVLN agent further considers
underlying web-specific content like HTML, which could not be seen on the
rendered web pages yet contains rich visual and textual information. Toward
this goal, we contribute a dataset, WebVLN-v1, and introduce a novel approach
called Website-aware VLN Network (WebVLN-Net), which is built upon the
foundation of state-of-the-art VLN techniques. Experimental results show that
WebVLN-Net outperforms current VLN and web-related navigation methods. We
believe that the introduction of the new WebVLN task and its dataset will
establish a new dimension within the VLN domain and contribute to the broader
vision-and-language research community. The code is available at:
https://github.com/WebVLN/WebVLN.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15821" title="Abstract">arXiv:2312.15821</a> [<a href="/pdf/2312.15821" title="Download PDF">pdf</a>, <a href="/format/2312.15821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audiobox: Unified Audio Generation with Natural Language Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyas%2C+A">Apoorv Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bowen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+M">Matthew Le</a>, 
<a href="/search/cs?searchtype=author&query=Tjandra%2C+A">Andros Tjandra</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi-Chiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baishan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiemin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Adkins%2C+R">Robert Adkins</a>, 
<a href="/search/cs?searchtype=author&query=Ngan%2C+W">William Ngan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jeff Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+I">Ivan Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Akula%2C+B">Bapi Akula</a>, 
<a href="/search/cs?searchtype=author&query=Akinyemi%2C+A">Akinniyi Akinyemi</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+B">Brian Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Moritz%2C+R">Rashel Moritz</a>, 
<a href="/search/cs?searchtype=author&query=Yungster%2C+Y">Yael Yungster</a>, 
<a href="/search/cs?searchtype=author&query=Rakotoarison%2C+A">Alice Rakotoarison</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Summers%2C+C">Chris Summers</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+C">Carleigh Wood</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+J">Joshua Lane</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+M">Mary Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wei-Ning Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio is an essential part of our life, but creating it often requires
expertise and is time-consuming. Research communities have made great progress
over the past year advancing the performance of large scale audio generative
models for a single modality (speech, sound, or music) through adopting more
powerful generative models and scaling data. However, these models lack
controllability in several aspects: speech generation models cannot synthesize
novel styles based on text description and are limited on domain coverage such
as outdoor environments; sound generation models only provide coarse-grained
control based on descriptions like "a person speaking" and would only generate
mumbling human voices. This paper presents Audiobox, a unified model based on
flow-matching that is capable of generating various audio modalities. We design
description-based and example-based prompting to enhance controllability and
unify speech and sound generation paradigms. We allow transcript, vocal, and
other audio styles to be controlled independently when generating speech. To
improve model generalization with limited labels, we adapt a self-supervised
infilling objective to pre-train on large quantities of unlabeled audio.
Audiobox sets new benchmarks on speech and sound generation (0.745 similarity
on Librispeech for zero-shot TTS; 0.77 FAD on AudioCaps for text-to-sound) and
unlocks new methods for generating audio with novel vocal and acoustic styles.
We further integrate Bespoke Solvers, which speeds up generation by over 25
times compared to the default ODE solver for flow-matching, without loss of
performance on several tasks. Our demo is available at
https://audiobox.metademolab.com/
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15823" title="Abstract">arXiv:2312.15823</a> [<a href="/pdf/2312.15823" title="Download PDF">pdf</a>, <a href="/ps/2312.15823" title="Download PostScript">ps</a>, <a href="/format/2312.15823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sequential Detection and Tracking of Very Low SNR Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rezaie%2C+R">Reza Rezaie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">A sequential detection and tracking (SDT) approach is proposed for detection
and tracking of very low signal-to-noise (SNR) objects. The proposed approach
is compared with two existing particle filter track-before-track (TBD) methods.
It is shown that the former outperforms the latter. A conventional detection
and tracking (CDT) approach, based on one-data-frame thresholding, is
considered as a benchmark for comparison. Simulations demonstrate the
performance.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15824" title="Abstract">arXiv:2312.15824</a> [<a href="/pdf/2312.15824" title="Download PDF">pdf</a>, <a href="/ps/2312.15824" title="Download PostScript">ps</a>, <a href="/format/2312.15824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Few-Shot Bird Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moummad%2C+I">Ilyass Moummad</a>, 
<a href="/search/cs?searchtype=author&query=Serizel%2C+R">Romain Serizel</a>, 
<a href="/search/cs?searchtype=author&query=Farrugia%2C+N">Nicolas Farrugia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Self-supervised learning (SSL) in audio holds significant potential across
various domains, particularly in situations where abundant, unlabeled data is
readily available at no cost. This is particularly pertinent in bioacoustics,
where biologists routinely collect extensive sound datasets from the natural
environment. In this study, we demonstrate that SSL is capable of acquiring
meaningful representations of bird sounds from audio recordings without the
need for annotations. Our experiments showcase that these learned
representations exhibit the capacity to generalize to new bird species in
few-shot learning (FSL) scenarios. Additionally, we show that selecting windows
with high bird activation for self-supervised learning, using a pretrained
audio neural network, significantly enhances the quality of the learned
representations.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15825" title="Abstract">arXiv:2312.15825</a> [<a href="/pdf/2312.15825" title="Download PDF">pdf</a>, <a href="/ps/2312.15825" title="Download PostScript">ps</a>, <a href="/format/2312.15825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Radiomic Features and Gene Expression Profiles  in Histopathology Data Using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monroy%2C+L+C+R">Luis Carlos Rivera Monroy</a>, 
<a href="/search/cs?searchtype=author&query=Rist%2C+L">Leonhard Rist</a>, 
<a href="/search/cs?searchtype=author&query=Eberhardt%2C+M">Martin Eberhardt</a>, 
<a href="/search/cs?searchtype=author&query=Ostalecki%2C+C">Christian Ostalecki</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+A">Andreas Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Vera%2C+J">Julio Vera</a>, 
<a href="/search/cs?searchtype=author&query=Breininger%2C+K">Katharina Breininger</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at the German Conference on Medical Image Computing 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study leverages graph neural networks to integrate MELC data with
Radiomic-extracted features for melanoma classification, focusing on cell-wise
analysis. It assesses the effectiveness of gene expression profiles and
Radiomic features, revealing that Radiomic features, particularly when combined
with UMAP for dimensionality reduction, significantly enhance classification
performance. Notably, using Radiomics contributes to increased diagnostic
accuracy and computational efficiency, as it allows for the extraction of
critical data from fewer stains, thereby reducing operational costs. This
methodology marks an advancement in computational dermatology for melanoma cell
classification, setting the stage for future research and potential
developments.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15826" title="Abstract">arXiv:2312.15826</a> [<a href="/pdf/2312.15826" title="Download PDF">pdf</a>, <a href="/format/2312.15826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Item Promotion on Visually-Aware Recommender Systems by  Guided Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Lizhen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Visually-aware recommender systems have found widespread application in
domains where visual elements significantly contribute to the inference of
users' potential preferences. While the incorporation of visual information
holds the promise of enhancing recommendation accuracy and alleviating the
cold-start problem, it is essential to point out that the inclusion of item
images may introduce substantial security challenges. Some existing works have
shown that the item provider can manipulate item exposure rates to its
advantage by constructing adversarial images. However, these works cannot
reveal the real vulnerability of visually-aware recommender systems because (1)
The generated adversarial images are markedly distorted, rendering them easily
detectable by human observers; (2) The effectiveness of the attacks is
inconsistent and even ineffective in some scenarios. To shed light on the real
vulnerabilities of visually-aware recommender systems when confronted with
adversarial images, this paper introduces a novel attack method, IPDGI (Item
Promotion by Diffusion Generated Image). Specifically, IPDGI employs a guided
diffusion model to generate adversarial samples designed to deceive
visually-aware recommender systems. Taking advantage of accurately modeling
benign images' distribution by diffusion models, the generated adversarial
images have high fidelity with original images, ensuring the stealth of our
IPDGI. To demonstrate the effectiveness of our proposed methods, we conduct
extensive experiments on two commonly used e-commerce recommendation datasets
(Amazon Beauty and Amazon Baby) with several typical visually-aware recommender
systems. The experimental results show that our attack method has a significant
improvement in both the performance of promoting the long-tailed (i.e.,
unpopular) items and the quality of generated adversarial images.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15830" title="Abstract">arXiv:2312.15830</a> [<a href="/pdf/2312.15830" title="Download PDF">pdf</a>, <a href="/format/2312.15830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hairpin Motors for Electromobility: Twists and Bends of a Technological  Breakthrough that Initially Arrived A Century Too Soon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Goetz%2C+S+M">Stefan M. Goetz</a>, 
<a href="/search/eess?searchtype=author&query=F.%2C+R+L">Ricardo Lizana F.</a>, 
<a href="/search/eess?searchtype=author&query=Rivera%2C+S">Sebastian Rivera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">There is currently a major trend to hairpin-winding motors for small and
medium drives with increased power, specifically more torque density in the
automotive industry. Practically all large players in the field either already
use this winding technology or have announced doing so soon. However, hairpins,
bar windings, and other segmented winding techniques are not purely a material
and production issue. Instead their application to small drives influences all
aspects of the design of machines, which are currently explored and studied by
the industry. These range from not obvious gaps in the theory, parameter
studies for maxima of efficiency, possible as well as advantageous winding
schemes, thermal design, and ways to control ac losses to specific materials
and process difficulties. Despite the apparent novelty of the trend, however,
designers could revisit a widely forgotten knowledge base of more than 100
years for many of those questions. This old knowledge base and the
understanding that many recently presented concepts have been developed earlier
may speed up the technological development and appear to be a key to further
innovation. Instead, many problems need to be solved again and technologies
re-invented. Furthermore, as this technology has recently become merely
industry-driven, a substantial portion of the information and technological
developments are not available to the public -- a state that to our eyes may
harm the innovation capacity of the drives community.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15831" title="Abstract">arXiv:2312.15831</a> [<a href="/pdf/2312.15831" title="Download PDF">pdf</a>, <a href="/ps/2312.15831" title="Download PostScript">ps</a>, <a href="/format/2312.15831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outlier-immune Data-driven Linear Power Flow Model Construction via  Mixed-Integer Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yan%2C+G">Guoan Yan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhengshuo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The common approaches to construct a data-driven linear power flow (DD-LPF)
model cannot completely eliminate the adverse impacts of outliers in a training
dataset. In this letter, a novel outlier-immune DD-LPF model construction
method via mixed-integer programming is presented for automatically and
optimally identifying outliers to form a more accurate LPF model. Two
acceleration solution strategies are further suggested to reduce the
computational time. Case studies demonstrate the superior accuracy and
comparable computational time of the proposed method when compared to three
common approaches.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15832" title="Abstract">arXiv:2312.15832</a> [<a href="/pdf/2312.15832" title="Download PDF">pdf</a>, <a href="/ps/2312.15832" title="Download PostScript">ps</a>, <a href="/format/2312.15832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tomlinson-Harashima Cluster-Based Precoders for Cell-Free MU-MIMO  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flores%2C+A">A. Flores</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+K+V">K. V. Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures, 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cell-free (CF) multiple-input multiple-output (MIMO) systems generally employ
linear precoding techniques to mitigate the effects of multiuser interference.
However, the power loss, efficiency, and precoding accuracy of linear precoders
are usually improved by replacing them with nonlinear precoders that employ
perturbation and modulo operation. In this work, we propose nonlinear
user-centric precoders for CF MIMO, wherein different clusters of access points
(APs) serve different users in CF multiple-antenna networks. Each cluster of
APs is selected based on large-scale fading coefficients. The clustering
procedure results in a sparse nonlinear precoder. We further devise a
reduced-dimension nonlinear precoder, where clusters of users are created to
reduce the complexity of the nonlinear precoder, the amount of required
signaling, and the number of users. Numerical experiments show that the
proposed nonlinear techniques for CF systems lead to an enhanced performance
when compared to their linear counterparts.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15835" title="Abstract">arXiv:2312.15835</a> [<a href="/pdf/2312.15835" title="Download PDF">pdf</a>, <a href="/format/2312.15835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShallowBlocker: Improving Set Similarity Joins for Blocking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barlaug%2C+N">Nils Barlaug</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Blocking is a crucial step in large-scale entity matching but often requires
significant manual engineering from an expert for each new dataset. Recent work
has show that deep learning is state-of-the-art and has great potential for
achieving hands-off and accurate blocking compared to classical methods.
However, in practice, such deep learning methods are often unstable, offers
little interpretability, and require hyperparameter tuning and significant
computational resources.
<br />In this paper, we propose a hands-off blocking method based on classical
string similarity measures: ShallowBlocker. It uses a novel hybrid set
similarity join combining absolute similarity, relative similarity, and local
cardinality conditions with a new effective pre-candidate filter replacing size
filter. We show that the method achieves state-of-the-art pair effectiveness on
both unsupervised and supervised blocking in a scalable way.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15837" title="Abstract">arXiv:2312.15837</a> [<a href="/pdf/2312.15837" title="Download PDF">pdf</a>, <a href="/format/2312.15837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A data driven Koopman-Schur decomposition for computational analysis of  nonlinear dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Drma%C4%8D%2C+Z">Zlatko Drma&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Mezi%C4%87%2C+I">Igor Mezi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a new theoretical and computational framework for a
data driven Koopman mode analysis of nonlinear dynamics. To alleviate the
potential problem of ill-conditioned eigenvectors in the existing
implementations of the Dynamic Mode Decomposition (DMD) and the Extended
Dynamic Mode Decomposition (EDMD), the new method introduces a Koopman-Schur
decomposition that is entirely based on unitary transformations. The analysis
in terms of the eigenvectors as modes of a Koopman operator compression is
replaced with a modal decomposition in terms of a flag of invariant subspaces
that correspond to selected eigenvalues. The main computational tool from the
numerical linear algebra is the partial ordered Schur decomposition that
provides convenient orthonormal bases for these subspaces. In the case of real
data, a real Schur form is used and the computation is based on real orthogonal
transformations. The new computational scheme is presented in the framework of
the Extended DMD and the kernel trick is used.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15838" title="Abstract">arXiv:2312.15838</a> [<a href="/pdf/2312.15838" title="Download PDF">pdf</a>, <a href="/ps/2312.15838" title="Download PostScript">ps</a>, <a href="/format/2312.15838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SecQA: A Concise Question-Answering Dataset for Evaluating Large  Language Models in Computer Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zefang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this paper, we introduce SecQA, a novel dataset tailored for evaluating
the performance of Large Language Models (LLMs) in the domain of computer
security. Utilizing multiple-choice questions generated by GPT-4 based on the
"Computer Systems Security: Planning for Success" textbook, SecQA aims to
assess LLMs' understanding and application of security principles. We detail
the structure and intent of SecQA, which includes two versions of increasing
complexity, to provide a concise evaluation across various difficulty levels.
Additionally, we present an extensive evaluation of prominent LLMs, including
GPT-3.5-Turbo, GPT-4, Llama-2, Vicuna, Mistral, and Zephyr models, using both
0-shot and 5-shot learning settings. Our results, encapsulated in the SecQA v1
and v2 datasets, highlight the varying capabilities and limitations of these
models in the computer security context. This study not only offers insights
into the current state of LLMs in understanding security-related content but
also establishes SecQA as a benchmark for future advancements in this critical
research area.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15840" title="Abstract">arXiv:2312.15840</a> [<a href="/pdf/2312.15840" title="Download PDF">pdf</a>, <a href="/format/2312.15840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Contrastive Reconstruction for Cross-modal Medical Image-Report  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K">Kai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiuzhuang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cross-modal medical image-report retrieval task plays a significant role in
clinical diagnosis and various medical generative tasks. Eliminating
heterogeneity between different modalities to enhance semantic consistency is
the key challenge of this task. The current Vision-Language Pretraining (VLP)
models, with cross-modal contrastive learning and masked reconstruction as
joint training tasks, can effectively enhance the performance of cross-modal
retrieval. This framework typically employs dual-stream inputs, using unmasked
data for cross-modal contrastive learning and masked data for reconstruction.
However, due to task competition and information interference caused by
significant differences between the inputs of the two proxy tasks, the
effectiveness of representation learning for intra-modal and cross-modal
features is limited. In this paper, we propose an efficient VLP framework named
Masked Contrastive and Reconstruction (MCR), which takes masked data as the
sole input for both tasks. This enhances task connections, reducing information
interference and competition between them, while also substantially decreasing
the required GPU memory and training time. Moreover, we introduce a new
modality alignment strategy named Mapping before Aggregation (MbA). Unlike
previous methods, MbA maps different modalities to a common feature space
before conducting local feature aggregation, thereby reducing the loss of
fine-grained semantic information necessary for improved modality alignment.
Additionally, due to using only masked input, our method significantly reduces
the gpu memory and time required for training. Qualitative and quantitative
experiments conducted on the MIMIC-CXR dataset validate the effectiveness of
our approach, demonstrating state-of-the-art performance in medical cross-modal
retrieval tasks.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15842" title="Abstract">arXiv:2312.15842</a> [<a href="/pdf/2312.15842" title="Download PDF">pdf</a>, <a href="/format/2312.15842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation of LLM for Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Luyang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Ping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to DMO-EDU-LAK24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study proposes a method for distilling the knowledge of fine-tuned Large
Language Models (LLMs) into a smaller, more efficient, and accurate neural
network, specifically targeting the challenge of deploying these models on
resource-constrained devices. Our methodology involves training the smaller
student model using the prediction probabilities of the LLM, which serves as a
teacher model. This is achieved through a specialized loss function tailored to
learn from the LLM's output probabilities, ensuring that the student model
closely mimics the teacher's performance. To test this approach, we utilized a
large dataset, 7T, containing 6,684 student-written responses to science
questions and three other datasets with student-written responses. We also
compared performance with original neural network (NN) models to validate the
accuracy. Results have shown that the NN and distilled student models have
comparable accuracy to the teacher model for the 7T dataset; however, other
datasets have shown significantly lower accuracy (28% on average) for NN,
though our proposed distilled model is still able to achieve 12\% higher
accuracy than NN. Furthermore, the student model size ranges from 0.1M to
0.02M, 100 times smaller in terms of parameters and ten times smaller compared
with the original output model size. The significance of this research lies in
its potential to make advanced AI technologies accessible in typical
educational settings, particularly for automatic scoring.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15843" title="Abstract">arXiv:2312.15843</a> [<a href="/pdf/2312.15843" title="Download PDF">pdf</a>, <a href="/ps/2312.15843" title="Download PostScript">ps</a>, <a href="/format/2312.15843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Framework for Bounding Reachability Probabilities of  Continuous-time Stochastic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xue%2C+B">Bai Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This manuscript presents an innovative framework for constructing barrier
functions to bound reachability probabilities for continuous-time stochastic
systems described by stochastic differential equations (SDEs). The reachability
probabilities considered in this paper encompass two aspects: the probability
of reaching a set of specified states within a predefined finite time horizon,
and the probability of reaching a set of specified states at a particular time
instant. The barrier functions presented in this manuscript are developed
either by relaxing a parabolic partial differential equation that characterizes
the exact reachability probability or by applying the Gr\"onwall's inequality.
In comparison to the prevailing construction method, which relies on Doob's
non-negative supermartingale inequality (or Ville's inequality), the proposed
barrier functions provide stronger alternatives, complement existing methods,
or fill gaps.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15844" title="Abstract">arXiv:2312.15844</a> [<a href="/pdf/2312.15844" title="Download PDF">pdf</a>, <a href="/format/2312.15844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-To-Rank Approach for Identifying Everyday Objects Using a  Physical-World Search Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaneda%2C+K">Kanta Kaneda</a>, 
<a href="/search/cs?searchtype=author&query=Nagashima%2C+S">Shunya Nagashima</a>, 
<a href="/search/cs?searchtype=author&query=Korekata%2C+R">Ryosuke Korekata</a>, 
<a href="/search/cs?searchtype=author&query=Kambara%2C+M">Motonari Kambara</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Komei Sugiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for RAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Domestic service robots offer a solution to the increasing demand for daily
care and support. A human-in-the-loop approach that combines automation and
operator intervention is considered to be a realistic approach to their use in
society. Therefore, we focus on the task of retrieving target objects from
open-vocabulary user instructions in a human-in-the-loop setting, which we
define as the learning-to-rank physical objects (LTRPO) task. For example,
given the instruction "Please go to the dining room which has a round table.
Pick up the bottle on it," the model is required to output a ranked list of
target objects that the operator/user can select. In this paper, we propose
MultiRankIt, which is a novel approach for the LTRPO task. MultiRankIt
introduces the Crossmodal Noun Phrase Encoder to model the relationship between
phrases that contain referring expressions and the target bounding box, and the
Crossmodal Region Feature Encoder to model the relationship between the target
object and multiple images of its surrounding contextual environment.
Additionally, we built a new dataset for the LTRPO task that consists of
instructions with complex referring expressions accompanied by real indoor
environmental images that feature various target objects. We validated our
model on the dataset and it outperformed the baseline method in terms of the
mean reciprocal rank and recall@k. Furthermore, we conducted physical
experiments in a setting where a domestic service robot retrieved everyday
objects in a standardized domestic environment, based on users' instruction in
a human--in--the--loop setting. The experimental results demonstrate that the
success rate for object retrieval achieved 80%. Our code is available at
https://github.com/keio-smilab23/MultiRankIt.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15848" title="Abstract">arXiv:2312.15848</a> [<a href="/pdf/2312.15848" title="Download PDF">pdf</a>, <a href="/format/2312.15848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality-Collaborative Transformer with Hybrid Feature Reconstruction  for Robust Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chengxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As a vital aspect of affective computing, Multimodal Emotion Recognition has
been an active research area in the multimedia community. Despite recent
progress, this field still confronts two major challenges in real-world
applications: 1) improving the efficiency of constructing joint representations
from unaligned multimodal features, and 2) relieving the performance decline
caused by random modality feature missing. In this paper, we propose a unified
framework, Modality-Collaborative Transformer with Hybrid Feature
Reconstruction (MCT-HFR), to address these issues. The crucial component of MCT
is a novel attention-based encoder which concurrently extracts and dynamically
balances the intra- and inter-modality relations for all associated modalities.
With additional modality-wise parameter sharing, a more compact representation
can be encoded with less time and space complexity. To improve the robustness
of MCT, we further introduce HFR which consists of two modules: Local Feature
Imagination (LFI) and Global Feature Alignment (GFA). During model training,
LFI leverages complete features as supervisory signals to recover local missing
features, while GFA is designed to reduce the global semantic gap between
pairwise complete and incomplete representations. Experimental evaluations on
two popular benchmark datasets demonstrate that our proposed method
consistently outperforms advanced baselines in both complete and incomplete
data scenarios.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15849" title="Abstract">arXiv:2312.15849</a> [<a href="/pdf/2312.15849" title="Download PDF">pdf</a>, <a href="/ps/2312.15849" title="Download PostScript">ps</a>, <a href="/format/2312.15849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FODT: Fast, Online, Distributed and Temporary Failure Recovery Approach  for MEC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+J+F">Jose Fernan Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Mobile edge computing (MEC) can reduce the latency of cloud computing
successfully. However, the edge server may fail due to the hardware of software
issues. When the edge server failure happens, the users who offload tasks to
this server will be affected. How to recover the services for these affected
users quickly and effectively is challenging. Moreover, considering that the
server failure is continuous and temporary, and the failed server can be
repaired, the previous works cannot handle this problem effectively. Therefore,
in this paper, we propose the fast, online, distributed, and temporary failure
recovery algorithm (FODT) for MEC. In FODT, when edge sever failure happens,
only the affected APs recalculate their user-server allocation strategies and
the other APs do not change their strategies. For the affected access points
(Aps), the strategies before server failure are reused to reduce complexity and
latency. When the failed server is repaired, the influenced APs reuse the
strategies before server failure to offload task to this server. Based on this
approach, the FODT can achieve better performance than previous works. To the
best of knowledge, the FODT is the first failure recovery algorithm, and when
compared with previous research, it has higher failure recovery efficiency and
lower complexity with acceptable approximate ratio.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15850" title="Abstract">arXiv:2312.15850</a> [<a href="/pdf/2312.15850" title="Download PDF">pdf</a>, <a href="/ps/2312.15850" title="Download PostScript">ps</a>, <a href="/format/2312.15850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Efficiency Inference Accelerating Algorithm for NOMA-based Mobile  Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Muqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+J+F+M">Jose Fernan Martinez Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Splitting the inference model between device, edge server, and cloud can
improve the performance of EI greatly. Additionally, the non-orthogonal
multiple access (NOMA), which is the key supporting technologies of B5G/6G, can
achieve massive connections and high spectrum efficiency. Motivated by the
benefits of NOMA, integrating NOMA with model split in MEC to reduce the
inference latency further becomes attractive. However, the NOMA based
communication during split inference has not been properly considered in
previous works. Therefore, in this paper, we integrate the NOMA into split
inference in MEC, and propose the effective communication and computing
resource allocation algorithm to accelerate the model inference at edge.
Specifically, when the mobile user has a large model inference task needed to
be calculated in the NOMA-based MEC, it will take the energy consumption of
both device and edge server and the inference latency into account to find the
optimal model split strategy, subchannel allocation strategy (uplink and
downlink), and transmission power allocation strategy (uplink and downlink).
Since the minimum inference delay and energy consumption cannot be satisfied
simultaneously, and the variables of subchannel allocation and model split are
discrete, the gradient descent (GD) algorithm is adopted to find the optimal
tradeoff between them. Moreover, the loop iteration GD approach (Li-GD) is
proposed to reduce the complexity of GD algorithm that caused by the parameter
discrete. Additionally, the properties of the proposed algorithm are also
investigated, which demonstrate the effectiveness of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15851" title="Abstract">arXiv:2312.15851</a> [<a href="/pdf/2312.15851" title="Download PDF">pdf</a>, <a href="/format/2312.15851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph Enhanced Knowledge Tree Prompt Learning for Next-Basket  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+Z">Zi-Feng Mai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chang-Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhongjie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ya Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Next-basket recommendation (NBR) aims to infer the items in the next basket
given the corresponding basket sequence. Existing NBR methods are mainly based
on either message passing in a plain graph or transition modelling in a basket
sequence. However, these methods only consider point-to-point binary item
relations while item dependencies in real world scenarios are often in higher
order. Additionally, the importance of the same item to different users varies
due to variation of user preferences, and the relations between items usually
involve various aspects. As pretrained language models (PLMs) excel in multiple
tasks in natural language processing (NLP) and computer vision (CV), many
researchers have made great efforts in utilizing PLMs to boost recommendation.
However, existing PLM-based recommendation methods degrade when encountering
Out-Of-Vocabulary (OOV) items. OOV items are those whose IDs are out of PLM's
vocabulary and thus unintelligible to PLM. To settle the above challenges, we
propose a novel method HEKP4NBR, which transforms the knowledge graph (KG) into
prompts, namely Knowledge Tree Prompt (KTP), to help PLM encode the OOV item
IDs in the user's basket sequence. A hypergraph convolutional module is
designed to build a hypergraph based on item similarities measured by an MoE
model from multiple aspects and then employ convolution on the hypergraph to
model correlations among multiple items. Extensive experiments are conducted on
HEKP4NBR on two datasets based on real company data and validate its
effectiveness against multiple state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15853" title="Abstract">arXiv:2312.15853</a> [<a href="/pdf/2312.15853" title="Download PDF">pdf</a>, <a href="/format/2312.15853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curricular and Cyclical Loss for Time Series Learning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Moxian Song</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Derun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Shenda Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time series widely exists in real-world applications and many deep learning
models have performed well on it. Current research has shown the importance of
learning strategy for models, suggesting that the benefit is the order and size
of learning samples. However, no effective strategy has been proposed for time
series due to its abstract and dynamic construction. Meanwhile, the existing
one-shot tasks and continuous tasks for time series necessitate distinct
learning processes and mechanisms. No all-purpose approach has been suggested.
In this work, we propose a novel Curricular and CyclicaL loss (CRUCIAL) to
learn time series for the first time. It is model- and task-agnostic and can be
plugged on top of the original loss with no extra procedure. CRUCIAL has two
characteristics: It can arrange an easy-to-hard learning order by dynamically
determining the sample contribution and modulating the loss amplitude; It can
manage a cyclically changed dataset and achieve an adaptive cycle by
correlating the loss distribution and the selection probability. We prove that
compared with monotonous size, cyclical size can reduce expected error.
Experiments on 3 kinds of tasks and 5 real-world datasets show the benefits of
CRUCIAL for most deep learning models when learning time series.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15855" title="Abstract">arXiv:2312.15855</a> [<a href="/pdf/2312.15855" title="Download PDF">pdf</a>, <a href="/format/2312.15855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric-Aware Low-Light Image and Video Enhancement via Depth Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yingqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yan Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiafei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code will be released
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Low-Light Enhancement (LLE) is aimed at improving the quality of
photos/videos captured under low-light conditions. It is worth noting that most
existing LLE methods do not take advantage of geometric modeling. We believe
that incorporating geometric information can enhance LLE performance, as it
provides insights into the physical structure of the scene that influences
illumination conditions. To address this, we propose a Geometry-Guided
Low-Light Enhancement Refine Framework (GG-LLERF) designed to assist low-light
enhancement models in learning improved features for LLE by integrating
geometric priors into the feature representation space. In this paper, we
employ depth priors as the geometric representation. Our approach focuses on
the integration of depth priors into various LLE frameworks using a unified
methodology. This methodology comprises two key novel modules. First, a
depth-aware feature extraction module is designed to inject depth priors into
the image representation. Then, Hierarchical Depth-Guided Feature Fusion Module
(HDGFFM) is formulated with a cross-domain attention mechanism, which combines
depth-aware features with the original image features within the LLE model. We
conducted extensive experiments on public low-light image and video enhancement
benchmarks. The results illustrate that our designed framework significantly
enhances existing LLE methods.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15856" title="Abstract">arXiv:2312.15856</a> [<a href="/pdf/2312.15856" title="Download PDF">pdf</a>, <a href="/format/2312.15856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERF: Fine-Grained Interactive 3D Segmentation and Editing with Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Although significant progress has been made in the field of 2D-based
interactive editing, fine-grained 3D-based interactive editing remains
relatively unexplored. This limitation can be attributed to two main
challenges: the lack of an efficient 3D representation robust to different
modifications and the absence of an effective 3D interactive segmentation
method. In this paper, we introduce a novel fine-grained interactive 3D
segmentation and editing algorithm with radiance fields, which we refer to as
SERF. Our method entails creating a neural mesh representation by integrating
multi-view algorithms with pre-trained 2D models. Building upon this
representation, we introduce a novel surface rendering technique that preserves
local information and is robust to deformation. Moreover, this representation
forms the basis for achieving accurate and interactive 3D segmentation without
requiring 3D supervision. Harnessing this representation facilitates a range of
interactive 3D editing operations, encompassing tasks such as interactive
geometry editing and texture painting. Extensive experiments and visualization
examples of editing on both real and synthetic data demonstrate the superiority
of our method on representation quality and editing ability.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15858" title="Abstract">arXiv:2312.15858</a> [<a href="/pdf/2312.15858" title="Download PDF">pdf</a>, <a href="/format/2312.15858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Online Policies for Person Tracking in Multi-View Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nalaie%2C+K">Keivan Nalaie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rong Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce MVSparse, a novel and efficient framework for
cooperative multi-person tracking across multiple synchronized cameras. The
MVSparse system is comprised of a carefully orchestrated pipeline, combining
edge server-based models with distributed lightweight Reinforcement Learning
(RL) agents operating on individual cameras. These RL agents intelligently
select informative blocks within each frame based on historical camera data and
detection outcomes from neighboring cameras, significantly reducing
computational load and communication overhead. The edge server aggregates
multiple camera views to perform detection tasks and provides feedback to the
individual agents. By projecting inputs from various perspectives onto a common
ground plane and applying deep detection models, MVSparse optimally leverages
temporal and spatial redundancy in multi-view videos. Notably, our
contributions include an empirical analysis of multi-camera pedestrian tracking
datasets, the development of a multi-camera, multi-person detection pipeline,
and the implementation of MVSparse, yielding impressive results on both open
datasets and real-world scenarios. Experimentally, MVSparse accelerates overall
inference time by 1.88X and 1.60X compared to a baseline approach while only
marginally compromising tracking accuracy by 2.27% and 3.17%, respectively,
showcasing its promising potential for efficient multi-camera tracking
applications.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15859" title="Abstract">arXiv:2312.15859</a> [<a href="/pdf/2312.15859" title="Download PDF">pdf</a>, <a href="/format/2312.15859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCPMan: Shape Context and Prior Constrained Multi-scale Attention  Network for Pancreatic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Leilei Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuechen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinquan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Song Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the poor prognosis of Pancreatic cancer, accurate early detection and
segmentation are critical for improving treatment outcomes. However, pancreatic
segmentation is challenged by blurred boundaries, high shape variability, and
class imbalance. To tackle these problems, we propose a multiscale attention
network with shape context and prior constraint for robust pancreas
segmentation. Specifically, we proposed a Multi-scale Feature Extraction Module
(MFE) and a Mixed-scale Attention Integration Module (MAI) to address unclear
pancreas boundaries. Furthermore, a Shape Context Memory (SCM) module is
introduced to jointly model semantics across scales and pancreatic shape.
Active Shape Model (ASM) is further used to model the shape priors. Experiments
on NIH and MSD datasets demonstrate the efficacy of our model, which improves
the state-of-the-art Dice Score for 1.01% and 1.03% respectively. Our
architecture provides robust segmentation performance, against the blurry
boundaries, and variations in scale and shape of pancreas.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15861" title="Abstract">arXiv:2312.15861</a> [<a href="/pdf/2312.15861" title="Download PDF">pdf</a>, <a href="/format/2312.15861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Squeezing-Averse Virtual Try-On via Sequential Deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shim%2C+S">Sang-Heon Shim</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jiwoo Chung</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we first investigate a visual quality degradation problem
observed in recent high-resolution virtual try-on approach. The tendency is
empirically found that the textures of clothes are squeezed at the sleeve, as
visualized in the upper row of Fig.1(a). A main reason for the issue arises
from a gradient conflict between two popular losses, the Total Variation (TV)
and adversarial losses. Specifically, the TV loss aims to disconnect boundaries
between the sleeve and torso in a warped clothing mask, whereas the adversarial
loss aims to combine between them. Such contrary objectives feedback the
misaligned gradients to a cascaded appearance flow estimation, resulting in
undesirable squeezing artifacts. To reduce this, we propose a Sequential
Deformation (SD-VITON) that disentangles the appearance flow prediction layers
into TV objective-dominant (TVOB) layers and a task-coexistence (TACO) layer.
Specifically, we coarsely fit the clothes onto a human body via the TVOB
layers, and then keep on refining via the TACO layer. In addition, the bottom
row of Fig.1(a) shows a different type of squeezing artifacts around the waist.
To address it, we further propose that we first warp the clothes into a
tucked-out shirts style, and then partially erase the texture from the warped
clothes without hurting the smoothness of the appearance flows. Experimental
results show that our SD-VITON successfully resolves both types of artifacts
and outperforms the baseline methods. Source code will be available at
https://github.com/SHShim0513/SD-VITON.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15863" title="Abstract">arXiv:2312.15863</a> [<a href="/pdf/2312.15863" title="Download PDF">pdf</a>, <a href="/format/2312.15863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDiT: Interleaving Perception and Decision-making Transformers for Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiqun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jiangjin Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proc. of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024, full paper with oral presentation). Cover our preliminary study: <a href="/abs/2212.14538">arXiv:2212.14538</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">Designing better deep networks and better reinforcement learning (RL)
algorithms are both important for deep RL. This work studies the former.
Specifically, the Perception and Decision-making Interleaving Transformer
(PDiT) network is proposed, which cascades two Transformers in a very natural
way: the perceiving one focuses on \emph{the environmental perception} by
processing the observation at the patch level, whereas the deciding one pays
attention to \emph{the decision-making} by conditioning on the history of the
desired returns, the perceiver's outputs, and the actions. Such a network
design is generally applicable to a lot of deep RL settings, e.g., both the
online and offline RL algorithms under environments with either image
observations, proprioception observations, or hybrid image-language
observations. Extensive experiments show that PDiT can not only achieve
superior performance than strong baselines in different settings but also
extract explainable feature representations. Our code is available at
\url{https://github.com/maohangyu/PDiT}.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15864" title="Abstract">arXiv:2312.15864</a> [<a href="/pdf/2312.15864" title="Download PDF">pdf</a>, <a href="/format/2312.15864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BalMCTS: Balancing Objective Function and Search Nodes in MCTS for  Constraint Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yingkai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+H+H">Hankz Hankui Zhuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Constraint Optimization Problems (COP) pose intricate challenges in
combinatorial problems usually addressed through Branch and Bound (B\&amp;B)
methods, which involve maintaining priority queues and iteratively selecting
branches to search for solutions. However, conventional approaches take a
considerable amount of time to find optimal solutions, and it is also crucial
to quickly identify a near-optimal feasible solution in a shorter time. In this
paper, we aim to investigate the effectiveness of employing a depth-first
search algorithm for solving COP, specifically focusing on identifying optimal
or near-optimal solutions within top $n$ solutions. Hence, we propose a novel
heuristic neural network algorithm based on MCTS, which, by simultaneously
conducting search and training, enables the neural network to effectively serve
as a heuristic during Backtracking. Furthermore, our approach incorporates
encoding COP problems and utilizing graph neural networks to aggregate
information about variables and constraints, offering more appropriate
variables for assignments. Experimental results on stochastic COP instances
demonstrate that our method identifies feasible solutions with a gap of less
than 17.63% within the initial 5 feasible solutions. Moreover, when applied to
attendant Constraint Satisfaction Problem (CSP) instances, our method exhibits
a remarkable reduction of less than 5% in searching nodes compared to
state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15867" title="Abstract">arXiv:2312.15867</a> [<a href="/pdf/2312.15867" title="Download PDF">pdf</a>, <a href="/format/2312.15867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Punctuation Matters! Stealthy Backdoor Attack for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+X">Xuan Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhaoyang Han</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiangmao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Piji Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NLPCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recent studies have pointed out that natural language processing (NLP) models
are vulnerable to backdoor attacks. A backdoored model produces normal outputs
on the clean samples while performing improperly on the texts with triggers
that the adversary injects. However, previous studies on textual backdoor
attack pay little attention to stealthiness. Moreover, some attack methods even
cause grammatical issues or change the semantic meaning of the original texts.
Therefore, they can easily be detected by humans or defense systems. In this
paper, we propose a novel stealthy backdoor attack method against textual
models, which is called \textbf{PuncAttack}. It leverages combinations of
punctuation marks as the trigger and chooses proper locations strategically to
replace them. Through extensive experiments, we demonstrate that the proposed
method can effectively compromise multiple models in various tasks. Meanwhile,
we conduct automatic evaluation and human inspection, which indicate the
proposed method possesses good performance of stealthiness without bringing
grammatical issues and altering the meaning of sentences.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15868" title="Abstract">arXiv:2312.15868</a> [<a href="/pdf/2312.15868" title="Download PDF">pdf</a>, <a href="/format/2312.15868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Frame Interpolation with Region-Distinguishable Priors from SAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yan Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yingqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiafei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code will be released
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In existing Video Frame Interpolation (VFI) approaches, the motion estimation
between neighboring frames plays a crucial role. However, the estimation
accuracy in existing methods remains a challenge, primarily due to the inherent
ambiguity in identifying corresponding areas in adjacent frames for
interpolation. Therefore, enhancing accuracy by distinguishing different
regions before motion estimation is of utmost importance. In this paper, we
introduce a novel solution involving the utilization of open-world segmentation
models, e.g., SAM (Segment Anything Model), to derive Region-Distinguishable
Priors (RDPs) in different frames. These RDPs are represented as
spatial-varying Gaussian mixtures, distinguishing an arbitrary number of areas
with a unified modality. RDPs can be integrated into existing motion-based VFI
methods to enhance features for motion estimation, facilitated by our designed
play-and-plug Hierarchical Region-aware Feature Fusion Module (HRFFM). HRFFM
incorporates RDP into various hierarchical stages of VFI's encoder, using
RDP-guided Feature Normalization (RDPFN) in a residual learning manner. With
HRFFM and RDP, the features within VFI's encoder exhibit similar
representations for matched regions in neighboring frames, thus improving the
synthesis of intermediate frames. Extensive experiments demonstrate that HRFFM
consistently enhances VFI performance across various scenes.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15869" title="Abstract">arXiv:2312.15869</a> [<a href="/pdf/2312.15869" title="Download PDF">pdf</a>, <a href="/format/2312.15869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Report Generation based on Segment-Enhanced Contrastive  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruoqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hongliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Piji Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NLPCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automated radiology report generation has the potential to improve radiology
reporting and alleviate the workload of radiologists. However, the medical
report generation task poses unique challenges due to the limited availability
of medical data and the presence of data bias. To maximize the utility of
available data and reduce data bias, we propose MSCL (Medical image
Segmentation with Contrastive Learning), a framework that utilizes the Segment
Anything Model (SAM) to segment organs, abnormalities, bones, etc., and can pay
more attention to the meaningful ROIs in the image to get better visual
representations. Then we introduce a supervised contrastive loss that assigns
more weight to reports that are semantically similar to the target while
training. The design of this loss function aims to mitigate the impact of data
bias and encourage the model to capture the essential features of a medical
image and generate high-quality reports. Experimental results demonstrate the
effectiveness of our proposed model, where we achieve state-of-the-art
performance on the IU X-Ray public dataset.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15872" title="Abstract">arXiv:2312.15872</a> [<a href="/pdf/2312.15872" title="Download PDF">pdf</a>, <a href="/format/2312.15872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Encoders Scaling In The Transformer For Neural Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+C">Jia Cheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cavicchioli%2C+R">Roberto Cavicchioli</a>, 
<a href="/search/cs?searchtype=author&query=Berardinelli%2C+G">Giulia Berardinelli</a>, 
<a href="/search/cs?searchtype=author&query=Capotondi%2C+A">Alessandro Capotondi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Although the Transformer is currently the best-performing architecture in the
homogeneous configuration (self-attention only) in Neural Machine Translation,
many State-of-the-Art models in Natural Language Processing are made of a
combination of different Deep Learning approaches. However, these models often
focus on combining a couple of techniques only and it is unclear why some
methods are chosen over others. In this work, we investigate the effectiveness
of integrating an increasing number of heterogeneous methods. Based on a simple
combination strategy and performance-driven synergy criteria, we designed the
Multi-Encoder Transformer, which consists of up to five diverse encoders.
Results showcased that our approach can improve the quality of the translation
across a variety of languages and dataset sizes and it is particularly
effective in low-resource languages where we observed a maximum increase of
7.16 BLEU compared to the single-encoder model.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15873" title="Abstract">arXiv:2312.15873</a> [<a href="/pdf/2312.15873" title="Download PDF">pdf</a>, <a href="/format/2312.15873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Inter-Satellite Link Spanning Patterns on Networking  Performance in Mega-constellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangtong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaodong Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Menglong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chuan Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Low Earth orbit (LEO) mega-constellations rely on inter-satellite links
(ISLs) to provide global connectivity. We note that in addition to the general
constellation parameters, the ISL spanning patterns are also greatly influence
the final network structure and thus the network performance.
<br />In this work, we formulate the ISL spanning patterns, apply different
patterns to mega-constellation and generate multiple structures. Then, we delve
into the performance estimation of these networks, specifically evaluating
network capacity, throughput, latency, and routing path stretch. The
experimental findings provide insights into the optimal network structure under
diverse conditions, showcasing superior performance when compared to
alternative network configurations.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15874" title="Abstract">arXiv:2312.15874</a> [<a href="/pdf/2312.15874" title="Download PDF">pdf</a>, <a href="/ps/2312.15874" title="Download PostScript">ps</a>, <a href="/format/2312.15874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential Lower Bounds for Sums of ROABPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Prerona Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Kush%2C+D">Deepanshu Kush</a>, 
<a href="/search/cs?searchtype=author&query=Saraf%2C+S">Shubhangi Saraf</a>, 
<a href="/search/cs?searchtype=author&query=Shpilka%2C+A">Amir Shpilka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper, we prove the first \emph{super-polynomial} and, in fact,
\emph{exponential} lower bound for the model of \emph{sum of read-once
oblivious algebraic branching programs} (ROABPs). In particular, we give an
explicit polynomial such that any sum of ROABPs (equivalently, sum of
\emph{ordered} set-multilinear branching programs, each with a possibly
different ordering) computing it must have exponential size. This result
generalizes the seminal work of Nisan (STOC 1991), which proved an exponential
lower bound for a single ROABP. It also strengthens the work of Arvind and Raja
(Chic. J. Theor. Comput. Sci., 2016), as well as the work of Bhargav, Dwivedi,
and Saxena (2023), both of which established lower bounds against certain
restricted versions of this model, and strongly answers an open question from
both papers that asked to prove super-polynomial lower bounds for the
corresponding \emph{unrestricted} model.
<br />The significance of our lower bounds is underscored by the recent work of
Bhargav, Dwivedi, and Saxena (2023), which showed that super-polynomial lower
bounds against a sum of ordered set-multilinear branching programs -- for a
polynomial of sufficiently low degree -- would imply super-polynomial lower
bounds against general ABPs, thereby resolving Valiant's longstanding
conjecture that the permanent polynomial can not be computed efficiently by
ABPs. More precisely, their work shows that if one could obtain such lower
bounds when the degree is bounded by $O(\log n/ \log \log n)$, then it would
imply super-polynomial lower bounds against general ABPs. In this paper, we
show super-polynomial lower bounds against this model for a polynomial whose
degree is as small as $\omega(\log n)$. Prior to our work, showing such lower
bounds was open \emph{irrespective} of the assumption on the degree.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15877" title="Abstract">arXiv:2312.15877</a> [<a href="/pdf/2312.15877" title="Download PDF">pdf</a>, <a href="/format/2312.15877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PBCounter: Weighted Model Counting on Pseudo-Boolean Formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yong Lai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenghang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Minghao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In Weighted Model Counting (WMC), we assign weights to literals and compute
the sum of the weights of the models of a given propositional formula where the
weight of an assignment is the product of the weights of its literals. The
current WMC solvers work on Conjunctive Normal Form (CNF) formulas. However,
CNF is not a natural representation for human-being in many applications.
Motivated by the stronger expressive power of pseudo-Boolean (PB) formulas than
CNF, we propose to perform WMC on PB formulas. Based on a recent dynamic
programming algorithm framework called ADDMC for WMC, we implement a weighted
PB counting tool PBCounter. We compare PBCounter with the state-of-the-art
weighted model counters SharpSAT-TD, ExactMC, D4, and ADDMC, where the latter
tools work on CNF with encoding methods that convert PB constraints into a CNF
formula. The experiments on three domains of benchmarks show that PBCounter is
superior to the model counters on CNF formulas.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15880" title="Abstract">arXiv:2312.15880</a> [<a href="/pdf/2312.15880" title="Download PDF">pdf</a>, <a href="/format/2312.15880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowledgeNavigator: Leveraging Large Language Models for Enhanced  Reasoning over Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tiezheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qingwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiawei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yingyou Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language model (LLM) has achieved outstanding performance on various
downstream tasks with its powerful natural language understanding and zero-shot
capability, but LLM still suffers from knowledge limitation. Especially in
scenarios that require long logical chains or complex reasoning, the
hallucination and knowledge limitation of LLM limit its performance in question
answering (QA). In this paper, we propose a novel framework KnowledgeNavigator
to address these challenges by efficiently and accurately retrieving external
knowledge from knowledge graph and using it as a key factor to enhance LLM
reasoning. Specifically, KnowledgeNavigator first mines and enhances the
potential constraints of the given question to guide the reasoning. Then it
retrieves and filters external knowledge that supports answering through
iterative reasoning on knowledge graph with the guidance of LLM and the
question. Finally, KnowledgeNavigator constructs the structured knowledge into
effective prompts that are friendly to LLM to help its reasoning. We evaluate
KnowledgeNavigator on multiple public KGQA benchmarks, the experiments show the
framework has great effectiveness and generalization, outperforming previous
knowledge graph enhanced LLM methods and is comparable to the fully supervised
models.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15881" title="Abstract">arXiv:2312.15881</a> [<a href="/pdf/2312.15881" title="Download PDF">pdf</a>, <a href="/format/2312.15881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-aware Social Graph Transformer Networks for Stochastic  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Binghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sammut%2C+C">Claude Sammut</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Trajectory prediction is fundamental to various intelligent technologies,
such as autonomous driving and robotics. The motion prediction of pedestrians
and vehicles helps emergency braking, reduces collisions, and improves traffic
safety. Current trajectory prediction research faces problems of complex social
interactions, high dynamics and multi-modality. Especially, it still has
limitations in long-time prediction. We propose Attention-aware Social Graph
Transformer Networks for multi-modal trajectory prediction. We combine Graph
Convolutional Networks and Transformer Networks by generating stable resolution
pseudo-images from Spatio-temporal graphs through a designed stacking and
interception method. Furthermore, we design the attention-aware module to
handle social interaction information in scenarios involving mixed
pedestrian-vehicle traffic. Thus, we maintain the advantages of the Graph and
Transformer, i.e., the ability to aggregate information over an arbitrary
number of neighbors and the ability to perform complex time-dependent data
processing. We conduct experiments on datasets involving pedestrian, vehicle,
and mixed trajectories, respectively. Our results demonstrate that our model
minimizes displacement errors across various metrics and significantly reduces
the likelihood of collisions. It is worth noting that our model effectively
reduces the final displacement error, illustrating the ability of our model to
predict for a long time.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15883" title="Abstract">arXiv:2312.15883</a> [<a href="/pdf/2312.15883" title="Download PDF">pdf</a>, <a href="/format/2312.15883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think and Retrieval: A Hypothesis Knowledge Graph Enhanced Medical Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinke Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R">Rihong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yue Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hongxin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasha Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version 1.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We explore how the rise of Large Language Models (LLMs) significantly impacts
task performance in the field of Natural Language Processing. We focus on two
strategies, Retrieval-Augmented Generation (RAG) and Fine-Tuning (FT), and
propose the Hypothesis Knowledge Graph Enhanced (HyKGE) framework, leveraging a
knowledge graph to enhance medical LLMs. By integrating LLMs and knowledge
graphs, HyKGE demonstrates superior performance in addressing accuracy and
interpretability challenges, presenting potential applications in the medical
domain. Our evaluations using real-world datasets highlight HyKGE's superiority
in providing accurate knowledge with precise confidence, particularly in
complex and difficult scenarios. The code will be available until published.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15889" title="Abstract">arXiv:2312.15889</a> [<a href="/pdf/2312.15889" title="Download PDF">pdf</a>, <a href="/format/2312.15889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ANN vs SNN: A case study for Neural Decoding in Implantable  Brain-Machine Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Biyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P+V">Pao-Sheng Vincent Sun</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Arindam Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">While it is important to make implantable brain-machine interfaces (iBMI)
wireless to increase patient comfort and safety, the trend of increased channel
count in recent neural probes poses a challenge due to the concomitant increase
in the data rate. Extracting information from raw data at the source by using
edge computing is a promising solution to this problem, with integrated
intention decoders providing the best compression ratio. In this work, we
compare different neural networks (NN) for motor decoding in terms of accuracy
and implementation cost. We further show that combining traditional signal
processing techniques with machine learning ones deliver surprisingly good
performance even with simple NNs. Adding a block Bidirectional Bessel filter
provided maximum gains of $\approx 0.05$, $0.04$ and $0.03$ in $R^2$ for
ANN\_3d, SNN\_3D and ANN models, while the gains were lower ($\approx 0.02$ or
less) for LSTM and SNN\_streaming models. Increasing training data helped
improve the $R^2$ of all models by $0.03-0.04$ indicating they have more
capacity for future improvement. In general, LSTM and SNN\_streaming models
occupy the high and low ends of the pareto curves (for accuracy vs.
memory/operations) respectively while SNN\_3D and ANN\_3D occupy intermediate
positions. Our work presents state of the art results for this dataset and
paves the way for decoder-integrated-implants of the future.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15890" title="Abstract">arXiv:2312.15890</a> [<a href="/pdf/2312.15890" title="Download PDF">pdf</a>, <a href="/format/2312.15890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Multimodal Prompting With Missing Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jaehyuk Jang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yooseung Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, multimodal prompting, which introduces learnable missing-aware
prompts for all missing modality cases, has exhibited impressive performance.
However, it encounters two critical issues: 1) The number of prompts grows
exponentially as the number of modalities increases; and 2) It lacks robustness
in scenarios with different missing modality settings between training and
inference. In this paper, we propose a simple yet effective prompt design to
address these challenges. Instead of using missing-aware prompts, we utilize
prompts as modality-specific tokens, enabling them to capture the unique
characteristics of each modality. Furthermore, our prompt design leverages
orthogonality between prompts as a key element to learn distinct information
across different modalities and promote diversity in the learned
representations. Extensive experiments demonstrate that our prompt design
enhances both performance and robustness while reducing the number of prompts.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15894" title="Abstract">arXiv:2312.15894</a> [<a href="/pdf/2312.15894" title="Download PDF">pdf</a>, <a href="/format/2312.15894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Disruptive Background Suppression for Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Suho Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">SuBeen Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+S">Sangeek Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Seong%2C+H+S">Hyun Seok Seong</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot segmentation aims to accurately segment novel target objects within
query images using only a limited number of annotated support images. The
recent works exploit support background as well as its foreground to precisely
compute the dense correlations between query and support. However, they
overlook the characteristics of the background that generally contains various
types of objects. In this paper, we highlight this characteristic of background
which can bring problematic cases as follows: (1) when the query and support
backgrounds are dissimilar and (2) when objects in the support background are
similar to the target object in the query. Without any consideration of the
above cases, adopting the entire support background leads to a misprediction of
the query foreground as background. To address this issue, we propose
Task-disruptive Background Suppression (TBS), a module to suppress those
disruptive support background features based on two spatial-wise scores:
query-relevant and target-relevant scores. The former aims to mitigate the
impact of unshared features solely existing in the support background, while
the latter aims to reduce the influence of target-similar support background
features. Based on these two scores, we define a query background relevant
score that captures the similarity between the backgrounds of the query and the
support, and utilize it to scale support background features to adaptively
restrict the impact of disruptive support backgrounds. Our proposed method
achieves state-of-the-art performance on PASCAL-5 and COCO-20 datasets on
1-shot segmentation. Our official code is available at
github.com/SuhoPark0706/TBSNet.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15895" title="Abstract">arXiv:2312.15895</a> [<a href="/pdf/2312.15895" title="Download PDF">pdf</a>, <a href="/format/2312.15895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-aware SAM for Point-Prompted Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhaoyang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuehui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guorong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbin Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhenjun Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-point annotation in visual tasks, with the goal of minimizing
labelling costs, is becoming increasingly prominent in research. Recently,
visual foundation models, such as Segment Anything (SAM), have gained
widespread usage due to their robust zero-shot capabilities and exceptional
annotation performance. However, SAM's class-agnostic output and high
confidence in local segmentation introduce 'semantic ambiguity', posing a
challenge for precise category-specific segmentation. In this paper, we
introduce a cost-effective category-specific segmenter using SAM. To tackle
this challenge, we have devised a Semantic-Aware Instance Segmentation Network
(SAPNet) that integrates Multiple Instance Learning (MIL) with matching
capability and SAM with point prompts. SAPNet strategically selects the most
representative mask proposals generated by SAM to supervise segmentation, with
a specific focus on object category information. Moreover, we introduce the
Point Distance Guidance and Box Mining Strategy to mitigate inherent
challenges: 'group' and 'local' issues in weakly supervised segmentation. These
strategies serve to further enhance the overall segmentation performance. The
experimental results on Pascal VOC and COCO demonstrate the promising
performance of our proposed SAPNet, emphasizing its semantic matching
capabilities and its potential to advance point-prompted instance segmentation.
The code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15896" title="Abstract">arXiv:2312.15896</a> [<a href="/pdf/2312.15896" title="Download PDF">pdf</a>, <a href="/format/2312.15896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WWW: What, When, Where to Compute-in-Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tanvi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mustafa Ali</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+I">Indranil Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Compute-in-memory (CiM) has emerged as a compelling solution to alleviate
high data movement costs in von Neumann machines. CiM can perform massively
parallel general matrix multiplication (GEMM) operations in memory, the
dominant computation in Machine Learning (ML) inference. However, re-purposing
memory for compute poses key questions on 1) What type of CiM to use: Given a
multitude of analog and digital CiMs, determining their suitability from
systems perspective is needed. 2) When to use CiM: ML inference includes
workloads with a variety of memory and compute requirements, making it
difficult to identify when CiM is more beneficial than standard processing
cores. 3) Where to integrate CiM: Each memory level has different bandwidth and
capacity, that affects the data movement and locality benefits of CiM
integration.
<br />In this paper, we explore answers to these questions regarding CiM
integration for ML inference acceleration. We use Timeloop-Accelergy for early
system-level evaluation of CiM prototypes, including both analog and digital
primitives. We integrate CiM into different cache memory levels in an Nvidia
A100-like baseline architecture and tailor the dataflow for various ML
workloads. Our experiments show CiM architectures improve energy efficiency,
achieving up to 0.12x lower energy than the established baseline with INT-8
precision, and upto 4x performance gains with weight interleaving and
duplication. The proposed work provides insights into what type of CiM to use,
and when and where to optimally integrate it in the cache hierarchy for GEMM
acceleration.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15897" title="Abstract">arXiv:2312.15897</a> [<a href="/pdf/2312.15897" title="Download PDF">pdf</a>, <a href="/ps/2312.15897" title="Download PostScript">ps</a>, <a href="/format/2312.15897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Distillation for Open-Set Distributed Robot Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsukahara%2C+K">Kenta Tsukahara</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kanji Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">A typical assumption in state-of-the-art self-localization models is that an
annotated training dataset is available for the target workspace. However, this
is not necessarily true when a robot travels around the general open world.
This work introduces a novel training scheme for open-world distributed robot
systems. In our scheme, a robot (``student") can ask the other robots it meets
at unfamiliar places (``teachers") for guidance. Specifically, a
pseudo-training dataset is reconstructed from the teacher model and then used
for continual learning of the student model under domain, class, and vocabulary
incremental setup. Unlike typical knowledge transfer schemes, our scheme
introduces only minimal assumptions on the teacher model, so that it can handle
various types of open-set teachers, including those uncooperative, untrainable
(e.g., image retrieval engines), or black-box teachers (i.e., data privacy). In
this paper, we investigate a ranking function as an instance of such generic
models, using a challenging data-free recursive distillation scenario, where a
student once trained can recursively join the next-generation open teacher set.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15900" title="Abstract">arXiv:2312.15900</a> [<a href="/pdf/2312.15900" title="Download PDF">pdf</a>, <a href="/format/2312.15900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Generation: Multi-Modal Gesture Synthesis via Cascaded  Conditional Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zunnan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yachao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ronghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study aims to improve the generation of 3D gestures by utilizing
multimodal information from human speech. Previous studies have focused on
incorporating additional modalities to enhance the quality of generated
gestures. However, these methods perform poorly when certain modalities are
missing during inference. To address this problem, we suggest using
speech-derived multimodal priors to improve gesture generation. We introduce a
novel method that separates priors from speech and employs multimodal priors as
constraints for generating gestures. Our approach utilizes a chain-like
modeling method to generate facial blendshapes, body movements, and hand
gestures sequentially. Specifically, we incorporate rhythm cues derived from
facial deformation and stylization prior based on speech emotions, into the
process of generating gestures. By incorporating multimodal priors, our method
improves the quality of generated gestures and eliminate the need for expensive
setup preparation during inference. Extensive experiments and user studies
confirm that our proposed approach achieves state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15901" title="Abstract">arXiv:2312.15901</a> [<a href="/pdf/2312.15901" title="Download PDF">pdf</a>, <a href="/format/2312.15901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box Tuning of Vision-Language Models with Effective Gradient  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zixian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Parameter-efficient fine-tuning (PEFT) methods have provided an effective way
for adapting large vision-language models to specific tasks or scenarios.
Typically, they learn a very small scale of parameters for pre-trained models
in a white-box formulation, which assumes model architectures to be known and
parameters to be accessible. However, large models are often not open-source
due to considerations of preventing abuse or commercial factors, hence posing a
barrier to the deployment of white-box PEFT methods. To alleviate the
dependence on model accessibility, we introduce collaborative black-box tuning
(CBBT) for both textual prompt optimization and output feature adaptation for
black-box models. Specifically, considering that the backpropagation gradients
are blocked, we approximate the gradients of textual prompts by analyzing the
predictions with perturbed prompts. Secondly, a lightweight adapter is deployed
over the output feature of the inaccessible model, further facilitating the
model adaptation process. Empowered with these designs, our CBBT is extensively
evaluated on eleven downstream benchmarks and achieves remarkable improvements
compared to existing black-box VL adaptation methods. Code is released at
https://github.com/guozix/cbbt.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15903" title="Abstract">arXiv:2312.15903</a> [<a href="/pdf/2312.15903" title="Download PDF">pdf</a>, <a href="/format/2312.15903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Incremental Update Framework for Online Recommenders with Data-Driven  Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangdong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhiwei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chaosheng Fan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jie He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Changping Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Online recommenders have attained growing interest and created great revenue
for businesses. Given numerous users and items, incremental update becomes a
mainstream paradigm for learning large-scale models in industrial scenarios,
where only newly arrived data within a sliding window is fed into the model,
meeting the strict requirements of quick response. However, this strategy would
be prone to overfitting to newly arrived data. When there exists a significant
drift of data distribution, the long-term information would be discarded, which
harms the recommendation performance. Conventional methods address this issue
through native model-based continual learning methods, without analyzing the
data characteristics for online recommenders. To address the aforementioned
issue, we propose an incremental update framework for online recommenders with
Data-Driven Prior (DDP), which is composed of Feature Prior (FP) and Model
Prior (MP). The FP performs the click estimation for each specific value to
enhance the stability of the training process. The MP incorporates previous
model output into the current update while strictly following the Bayes rules,
resulting in a theoretically provable prior for the robust update. In this way,
both the FP and MP are well integrated into the unified framework, which is
model-agnostic and can accommodate various advanced interaction models.
Extensive experiments on two publicly available datasets as well as an
industrial dataset demonstrate the superior performance of the proposed
framework.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15905" title="Abstract">arXiv:2312.15905</a> [<a href="/pdf/2312.15905" title="Download PDF">pdf</a>, <a href="/format/2312.15905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Initialization for Personalized Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Lianyu Pang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xudong Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, there has been a surge in face personalization techniques,
benefiting from the advanced capabilities of pretrained text-to-image diffusion
models. Among these, a notable method is Textual Inversion, which generates
personalized images by inverting given images into textual embeddings. However,
methods based on Textual Inversion still struggle with balancing the trade-off
between reconstruction quality and editability. In this study, we examine this
issue through the lens of initialization. Upon closely examining traditional
initialization methods, we identified a significant disparity between the
initial and learned embeddings in terms of both scale and orientation. The
scale of the learned embedding can be up to 100 times greater than that of the
initial embedding. Such a significant change in the embedding could increase
the risk of overfitting, thereby compromising the editability. Driven by this
observation, we introduce a novel initialization method, termed Cross
Initialization, that significantly narrows the gap between the initial and
learned embeddings. This method not only improves both reconstruction and
editability but also reduces the optimization steps from 5000 to 320.
Furthermore, we apply a regularization term to keep the learned embedding close
to the initial embedding. We show that when combined with Cross Initialization,
this regularization term can effectively improve editability. We provide
comprehensive empirical evidence to demonstrate the superior performance of our
method compared to the baseline methods. Notably, in our experiments, Cross
Initialization is the only method that successfully edits an individual's
facial expression. Additionally, a fast version of our method allows for
capturing an input image in roughly 26 seconds, while surpassing the baseline
methods in terms of both reconstruction and editability. Code will be made
publicly available.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15906" title="Abstract">arXiv:2312.15906</a> [<a href="/pdf/2312.15906" title="Download PDF">pdf</a>, <a href="/format/2312.15906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Transferability for Cross-domain Trajectory Prediction via  Neural Stochastic Differential Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Daehee Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Jaewoo Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+K">Kuk-Jin Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-agent trajectory prediction is crucial for various practical
applications, spurring the construction of many large-scale trajectory
datasets, including vehicles and pedestrians. However, discrepancies exist
among datasets due to external factors and data acquisition strategies.
External factors include geographical differences and driving styles, while
data acquisition strategies include data acquisition rate, history/prediction
length, and detector/tracker error. Consequently, the proficient performance of
models trained on large-scale datasets has limited transferability on other
small-size datasets, bounding the utilization of existing large-scale datasets.
To address this limitation, we propose a method based on continuous and
stochastic representations of Neural Stochastic Differential Equations (NSDE)
for alleviating discrepancies due to data acquisition strategy. We utilize the
benefits of continuous representation for handling arbitrary time steps and the
use of stochastic representation for handling detector/tracker errors.
Additionally, we propose a dataset-specific diffusion network and its training
framework to handle dataset-specific detection/tracking errors. The
effectiveness of our method is validated against state-of-the-art trajectory
prediction models on the popular benchmark datasets: nuScenes, Argoverse, Lyft,
INTERACTION, and Waymo Open Motion Dataset (WOMD). Improvement in performance
gain on various source and target dataset configurations shows the generalized
competence of our approach in addressing cross-dataset discrepancies.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15907" title="Abstract">arXiv:2312.15907</a> [<a href="/pdf/2312.15907" title="Download PDF">pdf</a>, <a href="/format/2312.15907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align on the Fly: Adapting Chatbot Behavior to Established Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunpu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chern%2C+S">Steffi Chern</a>, 
<a href="/search/cs?searchtype=author&query=Chern%2C+E">Ethan Chern</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zekun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we aim to align large language models with the ever-changing,
complex, and diverse human values (e.g., social norms) across time and
locations. This presents a challenge to existing alignment techniques, such as
supervised fine-tuning, which internalize values within model parameters. To
overcome this, we propose an On-the-fly Preference Optimization (OPO) method,
which is a real-time alignment that works in a streaming way. It employs an
external memory to store established rules for alignment, which can constrain
LLMs' behaviors without further training, allowing for convenient updates and
customization of human values. We also introduce a scalable evaluation to
assess the proposed method more effectively. Experimental results on both
human-annotated and auto-generated questions from legal and moral domains
indicate the effectiveness of the proposed OPO method. Our code and data are
released at https://github.com/GAIR-NLP/OPO.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15908" title="Abstract">arXiv:2312.15908</a> [<a href="/pdf/2312.15908" title="Download PDF">pdf</a>, <a href="/format/2312.15908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Monte Carlo Tree Search for Partially Observable  Multi-agent Pathfinding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skrynnik%2C+A">Alexey Skrynnik</a>, 
<a href="/search/cs?searchtype=author&query=Andreychuk%2C+A">Anton Andreychuk</a>, 
<a href="/search/cs?searchtype=author&query=Yakovlev%2C+K">Konstantin Yakovlev</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+A">Aleksandr Panov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted to AAAI-2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The Multi-Agent Pathfinding (MAPF) problem involves finding a set of
conflict-free paths for a group of agents confined to a graph. In typical MAPF
scenarios, the graph and the agents' starting and ending vertices are known
beforehand, allowing the use of centralized planning algorithms. However, in
this study, we focus on the decentralized MAPF setting, where the agents may
observe the other agents only locally and are restricted in communications with
each other. Specifically, we investigate the lifelong variant of MAPF, where
new goals are continually assigned to the agents upon completion of previous
ones. Drawing inspiration from the successful AlphaZero approach, we propose a
decentralized multi-agent Monte Carlo Tree Search (MCTS) method for MAPF tasks.
Our approach utilizes the agent's observations to recreate the intrinsic Markov
decision process, which is then used for planning with a tailored for
multi-agent tasks version of neural MCTS. The experimental results show that
our approach outperforms state-of-the-art learnable MAPF solvers. The source
code is available at https://github.com/AIRI-Institute/mats-lp.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15909" title="Abstract">arXiv:2312.15909</a> [<a href="/pdf/2312.15909" title="Download PDF">pdf</a>, <a href="/format/2312.15909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Task Representation Learning for Offline  Meta-Reinforcement Learning with Data Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Renzhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen-Xiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zongzhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generalization and sample efficiency have been long-standing issues
concerning reinforcement learning, and thus the field of Offline
Meta-Reinforcement Learning~(OMRL) has gained increasing attention due to its
potential of solving a wide range of problems with static and limited offline
data. Existing OMRL methods often assume sufficient training tasks and data
coverage to apply contrastive learning to extract task representations.
However, such assumptions are not applicable in several real-world applications
and thus undermine the generalization ability of the representations. In this
paper, we consider OMRL with two types of data limitations: limited training
tasks and limited behavior diversity and propose a novel algorithm called
GENTLE for learning generalizable task representations in the face of data
limitations. GENTLE employs Task Auto-Encoder~(TAE), which is an
encoder-decoder architecture to extract the characteristics of the tasks.
Unlike existing methods, TAE is optimized solely by reconstruction of the state
transition and reward, which captures the generative structure of the task
models and produces generalizable representations when training tasks are
limited. To alleviate the effect of limited behavior diversity, we consistently
construct pseudo-transitions to align the data distribution used to train TAE
with the data distribution encountered during testing. Empirically, GENTLE
significantly outperforms existing OMRL methods on both in-distribution tasks
and out-of-distribution tasks across both the given-context protocol and the
one-shot protocol.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15910" title="Abstract">arXiv:2312.15910</a> [<a href="/pdf/2312.15910" title="Download PDF">pdf</a>, <a href="/format/2312.15910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dayong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Congcong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Derui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jason">Jason</a> (Minhui)Xue, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wanlei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine unlearning refers to the process of mitigating the influence of
specific training data on machine learning models based on removal requests
from data owners. However, one important area that has been largely overlooked
in the research of unlearning is reinforcement learning. Reinforcement learning
focuses on training an agent to make optimal decisions within an environment to
maximize its cumulative rewards. During the training, the agent tends to
memorize the features of the environment, which raises a significant concern
about privacy. As per data protection regulations, the owner of the environment
holds the right to revoke access to the agent's training data, thus
necessitating the development of a novel and pressing research field, known as
\emph{reinforcement unlearning}. Reinforcement unlearning focuses on revoking
entire environments rather than individual data samples. This unique
characteristic presents three distinct challenges: 1) how to propose unlearning
schemes for environments; 2) how to avoid degrading the agent's performance in
remaining environments; and 3) how to evaluate the effectiveness of unlearning.
To tackle these challenges, we propose two reinforcement unlearning methods.
The first method is based on decremental reinforcement learning, which aims to
erase the agent's previously acquired knowledge gradually. The second method
leverages environment poisoning attacks, which encourage the agent to learn
new, albeit incorrect, knowledge to remove the unlearning environment.
Particularly, to tackle the third challenge, we introduce the concept of
``environment inference attack'' to evaluate the unlearning outcomes. The
source code is available at
\url{https://anonymous.4open.science/r/Reinforcement-Unlearning-D347}.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15911" title="Abstract">arXiv:2312.15911</a> [<a href="/pdf/2312.15911" title="Download PDF">pdf</a>, <a href="/format/2312.15911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating and Reweighting Dense Contrastive Patterns for Unsupervised  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+S">Songmin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent unsupervised anomaly detection methods often rely on feature
extractors pretrained with auxiliary datasets or on well-crafted
anomaly-simulated samples. However, this might limit their adaptability to an
increasing set of anomaly detection tasks due to the priors in the selection of
auxiliary datasets or the strategy of anomaly simulation. To tackle this
challenge, we first introduce a prior-less anomaly generation paradigm and
subsequently develop an innovative unsupervised anomaly detection framework
named GRAD, grounded in this paradigm. GRAD comprises three essential
components: (1) a diffusion model (PatchDiff) to generate contrastive patterns
by preserving the local structures while disregarding the global structures
present in normal images, (2) a self-supervised reweighting mechanism to handle
the challenge of long-tailed and unlabeled contrastive patterns generated by
PatchDiff, and (3) a lightweight patch-level detector to efficiently
distinguish the normal patterns and reweighted contrastive patterns. The
generation results of PatchDiff effectively expose various types of anomaly
patterns, e.g. structural and logical anomaly patterns. In addition, extensive
experiments on both MVTec AD and MVTec LOCO datasets also support the
aforementioned observation and demonstrate that GRAD achieves competitive
anomaly detection accuracy and superior inference speed.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15912" title="Abstract">arXiv:2312.15912</a> [<a href="/pdf/2312.15912" title="Download PDF">pdf</a>, <a href="/format/2312.15912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryptoanalysis McEliece-type cryptosystem based on correction of errors  and erasures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yackushenoks%2C+K">Kirill Yackushenoks</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+F">Fedor Ivanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Krouk, Tavernier and Kabatiansky proposed new variants of the McEliece
cryptosystem. In this letter, it is shown that cryptosystem based on correction
of errors erasures is equal to the Mc-Eliece cryptosystem with worse parametrs
public key. It will also add an organic extension of the authors' idea,
although one that has its flaws...
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15914" title="Abstract">arXiv:2312.15914</a> [<a href="/pdf/2312.15914" title="Download PDF">pdf</a>, <a href="/format/2312.15914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving One-Shot Transmission in NR Sidelink Resource Allocation for  V2X Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hojeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyogon Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The Society of Automotive Engineers (SAE) has specified a wireless channel
congestion control algorithm for cellular vehicle-to-everything (C-V2X)
communication in J3161/1. A notable aspect of J3161/1 standard is that it
addresses persistent packet collisions between neighboring vehicles. Although
the chances are slim, the persistent collisions can cause so called the
wireless blind spot once the event takes place. Then the involved vehicles
cannot inform their presence to neighboring vehicles, an extremely dangerous
condition for driving safety. J3161's solution to the problem is stochastic
one-shot transmission, where the transmission occasionally occurs in a resource
that is not originally reserved. Through the one-shot transmission, the
worst-case packet inter-reception time (PIR) is bounded and the wireless blind
spot problem can be effectively mitigated. Interestingly, the standard one-shot
transmission scheme does not resolve the persistent collision relation itself.
This paper shows that by breaking out of the relation as soon as the persistent
collision condition is identified, vehicles can improve the worst-case PIR by
approximately 500 ms, the number of packet collisions per persistent collision
event by 10%, and the number of total collisions by 15% to 57% over the
standard one-shot transmission.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15915" title="Abstract">arXiv:2312.15915</a> [<a href="/pdf/2312.15915" title="Download PDF">pdf</a>, <a href="/format/2312.15915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChartBench: A Benchmark for Complex Visual Reasoning in Charts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Sinan Du</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yiyan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jian Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have demonstrated remarkable
multimodal understanding and generation capabilities. However, their
understanding of synthetic charts is limited, while existing benchmarks are
simplistic and the charts deviate significantly from real-world examples,
making it challenging to accurately assess MLLMs' chart comprehension
abilities. Hence, a challenging benchmark is essential for investigating
progress and uncovering the limitations of current MLLMs on chart data. In this
work, we propose to examine chart comprehension through more complex visual
logic and introduce ChartBench, a comprehensive chart benchmark to accurately
measure MLLMs' fundamental chart comprehension and data reliability.
Specifically, ChartBench consists of \textbf{41} categories, \textbf{2K}
charts, and \textbf{16K} QA annotations. While significantly expanding chart
types, ChartBench avoids direct labelling of data points, which requires MLLMs
to infer values akin to humans by leveraging elements like color, legends, and
coordinate systems. We also introduce an improved metric, \textit{Acc+}, which
accurately reflects MLLMs' chart comprehension abilities while avoiding
labor-intensive manual evaluations or costly GPT-based evaluations. We conduct
evaluations on \textbf{12} mainstream open-source models and \textbf{2}
outstanding proprietary models. Through extensive experiments, we reveal the
limitations of MLLMs on charts and provide insights to inspire the community to
pay closer attention to MLLMs' chart comprehension abilities. The benchmark and
code will be publicly available for research.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15916" title="Abstract">arXiv:2312.15916</a> [<a href="/pdf/2312.15916" title="Download PDF">pdf</a>, <a href="/format/2312.15916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monocular 3D Hand Mesh Recovery via Dual Noise Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaojian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zejun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current parametric models have made notable progress in 3D hand pose and
shape estimation. However, due to the fixed hand topology and complex hand
poses, current models are hard to generate meshes that are aligned with the
image well. To tackle this issue, we introduce a dual noise estimation method
in this paper. Given a single-view image as input, we first adopt a baseline
parametric regressor to obtain the coarse hand meshes. We assume the mesh
vertices and their image-plane projections are noisy, and can be associated in
a unified probabilistic model. We then learn the distributions of noise to
refine mesh vertices and their projections. The refined vertices are further
utilized to refine camera parameters in a closed-form manner. Consequently, our
method obtains well-aligned and high-quality 3D hand meshes. Extensive
experiments on the large-scale Interhand2.6M dataset demonstrate that the
proposed method not only improves the performance of its baseline by more than
10$\%$ but also achieves state-of-the-art performance. Project page:
\url{https://github.com/hanhuili/DNE4Hand}.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15918" title="Abstract">arXiv:2312.15918</a> [<a href="/pdf/2312.15918" title="Download PDF">pdf</a>, <a href="/format/2312.15918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Knowledge Makes Large Language Models Better In-context  Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuibai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhuohao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+G">Guangsheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages. Under review at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) exhibit emerging in-context learning abilities
through prompt engineering. The recent progress in large-scale generative
models has further expanded their use in real-world language applications.
However, the critical challenge of improving the generalizability and
factuality of LLMs in natural language understanding and question answering
remains under-explored. While previous in-context learning research has focused
on enhancing models to adhere to users' specific instructions and quality
expectations, and to avoid undesired outputs, little to no work has explored
the use of task-Specific fine-tuned Language Models (SLMs) to improve LLMs'
in-context learning during the inference stage. Our primary contribution is the
establishment of a simple yet effective framework that enhances the reliability
of LLMs as it: 1) generalizes out-of-distribution data, 2) elucidates how LLMs
benefit from discriminative models, and 3) minimizes hallucinations in
generative tasks. Using our proposed plug-in method, enhanced versions of Llama
2 and ChatGPT surpass their original versions regarding generalizability and
factuality. We offer a comprehensive suite of resources, including 16 curated
datasets, prompts, model checkpoints, and LLM outputs across 9 distinct tasks.
Our empirical analysis sheds light on the advantages of incorporating
discriminative models into LLMs and highlights the potential of our methodology
in fostering more reliable LLMs.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15919" title="Abstract">arXiv:2312.15919</a> [<a href="/pdf/2312.15919" title="Download PDF">pdf</a>, <a href="/ps/2312.15919" title="Download PostScript">ps</a>, <a href="/format/2312.15919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review on Causality Detection Based on Empirical Dynamic Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhihao%2C+C">Cao Zhihao</a>, 
<a href="/search/cs?searchtype=author&query=Hongchun%2C+Q">Qu Hongchun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Methodology (stat.ME)

</div>
<p class="mathjax">In contemporary scientific research, understanding the distinction between
correlation and causation is crucial. While correlation is a widely used
analytical standard, it does not inherently imply causation. This paper
addresses the potential for misinterpretation in relying solely on correlation,
especially in the context of nonlinear dynamics. Despite the rapid development
of various correlation research methodologies, including machine learning, the
exploration into mining causal correlations between variables remains ongoing.
Empirical Dynamic Modeling (EDM) emerges as a data-driven framework for
modeling dynamic systems, distinguishing itself by eschewing traditional
formulaic methods in data analysis. Instead, it reconstructs dynamic system
behavior directly from time series data. The fundamental premise of EDM is that
dynamic systems can be conceptualized as processes where a set of states,
governed by specific rules, evolve over time in a high-dimensional space. By
reconstructing these evolving states, dynamic systems can be effectively
modeled. Using EDM, this paper explores the detection of causal relationships
between variables within dynamic systems through their time series data. It
posits that if variable X causes variable Y, then the information about X is
inherent in Y and can be extracted from Y's data. This study begins by
examining the dialectical relationship between correlation and causation,
emphasizing that correlation does not equate to causation, and the absence of
correlation does not necessarily indicate a lack of causation.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15921" title="Abstract">arXiv:2312.15921</a> [<a href="/pdf/2312.15921" title="Download PDF">pdf</a>, <a href="/format/2312.15921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Precoder Design for Angle-of-Departure Estimation with  Limited-Resolution Phase Shifters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huiping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Keskin%2C+M+F">Musa Furkan Keskin</a>, 
<a href="/search/cs?searchtype=author&query=Wymeersch%2C+H">Henk Wymeersch</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xuesong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Linlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Thunberg%2C+J">Johan Thunberg</a>, 
<a href="/search/cs?searchtype=author&query=Tufvesson%2C+F">Fredrik Tufvesson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Hybrid analog-digital beamforming stands out as a key enabler for future
communication systems with a massive number of antennas. In this paper, we
investigate the hybrid precoder design problem for angle-of-departure (AoD)
estimation, where we take into account the practical constraint on the limited
resolution of phase shifters. Our goal is to design a radio-frequency (RF)
precoder and a base-band (BB) precoder to estimate AoD of the user with a high
accuracy. To this end, we propose a two-step strategy where we first obtain the
fully digital precoder that minimizes the angle error bound, and then the
resulting digital precoder is decomposed into an RF precoder and a BB precoder,
based on the alternating optimization and the alternating direction method of
multipliers. Besides, we derive the quantization error upper bound and analyse
the convergence behavior of the proposed algorithm. Numerical results
demonstrate the superior performance of the proposed method over
state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15922" title="Abstract">arXiv:2312.15922</a> [<a href="/pdf/2312.15922" title="Download PDF">pdf</a>, <a href="/format/2312.15922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Probing Contact Center Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nathan%2C+V">Varun Nathan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ayush Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Ingle%2C+D">Digvijay Ingle</a>, 
<a href="/search/cs?searchtype=author&query=Vepa%2C+J">Jithendra Vepa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Fine-tuning large language models (LLMs) with domain-specific instructions
has emerged as an effective method to enhance their domain-specific
understanding. Yet, there is limited work that examines the core
characteristics acquired during this process. In this study, we benchmark the
fundamental characteristics learned by contact-center (CC) specific instruction
fine-tuned LLMs with out-of-the-box (OOB) LLMs via probing tasks encompassing
conversational, channel, and automatic speech recognition (ASR) properties. We
explore different LLM architectures (Flan-T5 and Llama), sizes (3B, 7B, 11B,
13B), and fine-tuning paradigms (full fine-tuning vs PEFT). Our findings reveal
remarkable effectiveness of CC-LLMs on the in-domain downstream tasks, with
improvement in response acceptability by over 48% compared to OOB-LLMs.
Additionally, we compare the performance of OOB-LLMs and CC-LLMs on the widely
used SentEval dataset, and assess their capabilities in terms of surface,
syntactic, and semantic information through probing tasks. Intriguingly, we
note a relatively consistent performance of probing classifiers on the set of
probing tasks. Our observations indicate that CC-LLMs, while outperforming
their out-of-the-box counterparts, exhibit a tendency to rely less on encoding
surface, syntactic, and semantic properties, highlighting the intricate
interplay between domain-specific adaptation and probing task performance
opening up opportunities to explore behavior of fine-tuned language models in
specialized contexts.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15923" title="Abstract">arXiv:2312.15923</a> [<a href="/pdf/2312.15923" title="Download PDF">pdf</a>, <a href="/format/2312.15923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the Proximate Long-Tail Distribution in Compositional  Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haofeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Compositional Zero-Shot Learning (CZSL) aims to transfer knowledge from seen
state-object pairs to novel unseen pairs. In this process, visual bias caused
by the diverse interrelationship of state-object combinations blurs their
visual features, hindering the learning of distinguishable class prototypes.
Prevailing methods concentrate on disentangling states and objects directly
from visual features, disregarding potential enhancements that could arise from
a data viewpoint. Experimentally, we unveil the results caused by the above
problem closely approximate the long-tailed distribution. As a solution, we
transform CZSL into a proximate class imbalance problem. We mathematically
deduce the role of class prior within the long-tailed distribution in CZSL.
Building upon this insight, we incorporate visual bias caused by compositions
into the classifier's training and inference by estimating it as a proximate
class prior. This enhancement encourages the classifier to acquire more
discernible class prototypes for each composition, thereby achieving more
balanced predictions. Experimental results demonstrate that our approach
elevates the model's performance to the state-of-the-art level, without
introducing additional parameters. Our code is available at
\url{https://github.com/LanchJL/ProLT-CZSL}.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15924" title="Abstract">arXiv:2312.15924</a> [<a href="/pdf/2312.15924" title="Download PDF">pdf</a>, <a href="/format/2312.15924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Analysis of GEO Satellite Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+D">Dong-Hyun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Hongjae Nam</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Junil Choi</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+D+J">David J. Love</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, submitted to IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The extensive coverage offered by satellites makes them effective in
enhancing service continuity for users on dynamic airborne and maritime
platforms, such as airplanes and ships. In particular, geosynchronous Earth
orbit (GEO) satellites ensure stable connectivity for terrestrial users due to
their stationary characteristics when observed from Earth. This paper
introduces a novel approach to model and analyze GEO satellite networks using
stochastic geometry. We model the distribution of GEO satellites in the
geostationary orbit according to a binomial point process (BPP) and examine
satellite visibility depending on the terminal's latitude. Then, we identify
potential distribution cases for GEO satellites and derive case probabilities
based on the properties of the BPP. We also obtain the distance distributions
between the terminal and GEO satellites and derive the coverage probability of
the network. We further approximate the derived expressions using the Poisson
limit theorem. Monte Carlo simulations are performed to validate the analytical
findings, demonstrating a strong alignment between the analyses and
simulations. The simplified analytical results can be used to estimate the
coverage performance of GEO satellite networks by effectively modeling the
positions of GEO satellites.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15926" title="Abstract">arXiv:2312.15926</a> [<a href="/pdf/2312.15926" title="Download PDF">pdf</a>, <a href="/format/2312.15926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMS: Federated Learning with Mixture of Sparsely Activated Foundations  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Panlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kangshuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Foundation models have shown great success in natural language processing,
computer vision, and multimodal tasks. FMs have a large number of model
parameters, thus requiring a substantial amount of data to help optimize the
model during the training. Federated learning has revolutionized machine
learning by enabling collaborative learning from decentralized data while still
preserving the data privacy of clients. Despite the great benefits foundation
models can have empowered by federated learning, they face severe computation,
communication, and statistical challenges. In this paper, we propose a novel
two-stage federated learning algorithm called FedMS. A global expert is trained
in the first stage and a local expert is trained in the second stage to provide
better personalization. We construct a Mixture of Foundation Models (MoFM) with
these two experts and design a gate neural network with an inserted gate
adapter that joins the aggregation every communication round in the second
stage. To further adapt to edge computing scenarios with limited computational
resources, we design a novel Sparsely Activated LoRA (SAL) algorithm that
freezes the pre-trained foundation model parameters inserts low-rank adaptation
matrices into transformer blocks and activates them progressively during the
training. We employ extensive experiments to verify the effectiveness of FedMS,
results show that FedMS outperforms other SOTA baselines by up to 55.25% in
default settings.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15927" title="Abstract">arXiv:2312.15927</a> [<a href="/pdf/2312.15927" title="Download PDF">pdf</a>, <a href="/format/2312.15927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECHO: Efficient Dataset Condensation by Higher-Order Distribution  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hansong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shikun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengju Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Shiming Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted in AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of deep learning, training deep neural networks often requires
extensive data, leading to substantial costs. Dataset condensation addresses
this by learning a small synthetic set that preserves essential information
from the original large-scale dataset. Nowadays, optimization-oriented methods
dominate dataset condensation for state-of-the-art (SOTA) results, but their
computationally intensive bi-level optimization hinders practicality with large
datasets. To enhance efficiency, as alternative solutions,
Distribution-Matching (DM)-based methods reduce costs by aligning the
representation distributions of real and synthetic examples. However, current
DM-based methods still yield less comparable results to SOTA
optimization-oriented methods. In this paper, we argue that existing DM-based
methods overlook the higher-order alignment of the distributions, which may
lead to sub-optimal matching results. Inspired by this, we propose a new
DM-based method named as Efficient Dataset Condensation by Higher-Order
Distribution Alignment (ECHO). Specifically, rather than only aligning the
first-order moment of the representation distributions as previous methods, we
learn synthetic examples via further aligning the higher-order moments of the
representation distributions of real and synthetic examples based on the
classical theory of reproducing kernel Hilbert space. Experiments demonstrate
the proposed method achieves a significant performance boost while maintaining
efficiency across various scenarios.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15929" title="Abstract">arXiv:2312.15929</a> [<a href="/pdf/2312.15929" title="Download PDF">pdf</a>, <a href="/format/2312.15929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling identical linear multi-agent systems over directed graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaupa%2C+N">Nicola Zaupa</a> (LAAS-MAC, UT3), 
<a href="/search/cs?searchtype=author&query=Zaccarian%2C+L">Luca Zaccarian</a> (LAAS-MAC), 
<a href="/search/cs?searchtype=author&query=Queinnec%2C+I">Isabelle Queinnec</a> (LAAS-MAC), 
<a href="/search/cs?searchtype=author&query=Tarbouriech%2C+S">Sophie Tarbouriech</a> (LAAS-MAC), 
<a href="/search/cs?searchtype=author&query=Giordano%2C+G">Giulia Giordano</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 62st Conference on Decision and Control (CDC), IEEE, Dec
  2023, Singapore, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">We consider the problem of synchronizing a multi-agent system (MAS) composed
of several identical linear systems connected through a directed graph.To
design a suitable controller, we construct conditions based on Bilinear Matrix
Inequalities (BMIs) that ensure state synchronization.Since these conditions
are non-convex, we propose an iterative algorithm based on a suitable
relaxation that allows us to formulate Linear Matrix Inequality (LMI)
conditions.As a result, the algorithm yields a common static state-feedback
matrix for the controller that satisfies general linear performance
constraints.Our results are achieved under the mild assumption that the graph
is time-invariant and connected.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15935" title="Abstract">arXiv:2312.15935</a> [<a href="/pdf/2312.15935" title="Download PDF">pdf</a>, <a href="/ps/2312.15935" title="Download PostScript">ps</a>, <a href="/format/2312.15935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probability-graphons: Limits of large dense weighted graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abraham%2C+R">Romain Abraham</a> (IDP), 
<a href="/search/cs?searchtype=author&query=Delmas%2C+J">Jean-Fran&#xe7;ois Delmas</a> (CERMICS), 
<a href="/search/cs?searchtype=author&query=Weibel%2C+J">Julien Weibel</a> (IDP, CERMICS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Probability (math.PR)

</div>
<p class="mathjax">We introduce probability-graphons which are probability kernels that
generalize graphons to the case of weighted graphs. Probability-graphons appear
as the limit objects to study sequences of large weighted graphs whose
distribution of subgraph sampling converge. The edge-weights are taken from a
general Polish space, which also covers the case of decorated graphs. Here,
graphs can be either directed or undirected. Starting from a distance $d_m$
inducing the weak topology on measures, we define a cut distance on
probability-graphons, making it a Polish space, and study the properties of
this cut distance. In particular, we exhibit a tightness criterion for
probability-graphons related to relative compactness in the cut distance. We
also prove that under some conditions on the distance $d_m$, which are
satisfied for some well-know distances like the Prohorov distance, and the
Fortet-Mourier and Kantorovitch-Rubinstein norms, the topology induced by the
cut distance on the spaceof probability-graphons is independent from the choice
of $d_m$. Eventually, we prove that this topology coincides with the topology
induced by the convergence in distribution of the sampled subgraphs.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15937" title="Abstract">arXiv:2312.15937</a> [<a href="/pdf/2312.15937" title="Download PDF">pdf</a>, <a href="/ps/2312.15937" title="Download PostScript">ps</a>, <a href="/format/2312.15937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfect mixed codes from generalized Reed-Muller codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romanov%2C+A+M">Alexander M. Romanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we propose a new method for constructing $1$-perfect mixed
codes in the Cartesian product $\mathbb{F}_{n} \times \mathbb{F}_{q}^n$, where
$\mathbb{F}_{n}$ and $\mathbb{F}_{q}$ are finite fields of orders $n = q^m$ and
$q$. We consider generalized Reed-Muller codes of length $n = q^m$ and order
$(q - 1)m - 2$. Codes whose parameters are the same as the parameters of
generalized Reed-Muller codes are called Reed-Muller-like codes. The
construction we propose is based on partitions of distance-2 MDS codes into
Reed-Muller-like codes of order $(q - 1)m - 2$. We construct a set of
$q^{q^{cn}}$ nonequivalent 1-perfect mixed codes in the Cartesian product
$\mathbb{F}_{n} \times \mathbb{F}_{q}^{n}$, where the constant $c$ satisfies $c
&lt; 1$, $n = q^m$ and $m$ is a sufficiently large positive integer. We also prove
that each $1$-perfect mixed code in the Cartesian product $\mathbb{F}_{n}
\times \mathbb{F}_{q}^n$ corresponds to a certain partition of a distance-2 MDS
code into Reed-Muller-like codes of order $(q - 1)m - 2$.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15942" title="Abstract">arXiv:2312.15942</a> [<a href="/pdf/2312.15942" title="Download PDF">pdf</a>, <a href="/format/2312.15942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pano-NeRF: Synthesizing High Dynamic Range Novel Views with Geometry  from Sparse Low Dynamic Range Panoramic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Panoramic imaging research on geometry recovery and High Dynamic Range (HDR)
reconstruction becomes a trend with the development of Extended Reality (XR).
Neural Radiance Fields (NeRF) provide a promising scene representation for both
tasks without requiring extensive prior data. However, in the case of inputting
sparse Low Dynamic Range (LDR) panoramic images, NeRF often degrades with
under-constrained geometry and is unable to reconstruct HDR radiance from LDR
inputs. We observe that the radiance from each pixel in panoramic images can be
modeled as both a signal to convey scene lighting information and a light
source to illuminate other pixels. Hence, we propose the irradiance fields from
sparse LDR panoramic images, which increases the observation counts for
faithful geometry recovery and leverages the irradiance-radiance attenuation
for HDR reconstruction. Extensive experiments demonstrate that the irradiance
fields outperform state-of-the-art methods on both geometry recovery and HDR
reconstruction and validate their effectiveness. Furthermore, we show a
promising byproduct of spatially-varying lighting estimation. The code is
available at https://github.com/Lu-Zhan/Pano-NeRF.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15944" title="Abstract">arXiv:2312.15944</a> [<a href="/pdf/2312.15944" title="Download PDF">pdf</a>, <a href="/format/2312.15944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAL: Balancing Diversity and Novelty for Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shaozuo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our paper is accepted by TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The objective of Active Learning is to strategically label a subset of the
dataset to maximize performance within a predetermined labeling budget. In this
study, we harness features acquired through self-supervised learning. We
introduce a straightforward yet potent metric, Cluster Distance Difference, to
identify diverse data. Subsequently, we introduce a novel framework, Balancing
Active Learning (BAL), which constructs adaptive sub-pools to balance diverse
and uncertain data. Our approach outperforms all established active learning
methods on widely recognized benchmarks by 1.20%. Moreover, we assess the
efficacy of our proposed framework under extended settings, encompassing both
larger and smaller labeling budgets. Experimental results demonstrate that,
when labeling 80% of the samples, the performance of the current SOTA method
declines by 0.74%, whereas our proposed BAL achieves performance comparable to
the full dataset. Codes are available at https://github.com/JulietLJY/BAL.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15946" title="Abstract">arXiv:2312.15946</a> [<a href="/pdf/2312.15946" title="Download PDF">pdf</a>, <a href="/format/2312.15946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnchantDance: Unveiling the Potential of Music-Driven Dance Movement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Teng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zeyu Ling</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feilin Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Graphics (cs.GR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The task of music-driven dance generation involves creating coherent dance
movements that correspond to the given music. While existing methods can
produce physically plausible dances, they often struggle to generalize to
out-of-set data. The challenge arises from three aspects: 1) the high diversity
of dance movements and significant differences in the distribution of music
modalities, which make it difficult to generate music-aligned dance movements.
2) the lack of a large-scale music-dance dataset, which hinders the generation
of generalized dance movements from music. 3) The protracted nature of dance
movements poses a challenge to the maintenance of a consistent dance style. In
this work, we introduce the EnchantDance framework, a state-of-the-art method
for dance generation. Due to the redundancy of the original dance sequence
along the time axis, EnchantDance first constructs a strong dance latent space
and then trains a dance diffusion model on the dance latent space. To address
the data gap, we construct a large-scale music-dance dataset, ChoreoSpectrum3D
Dataset, which includes four dance genres and has a total duration of 70.32
hours, making it the largest reported music-dance dataset to date. To enhance
consistency between music genre and dance style, we pre-train a music genre
prediction network using transfer learning and incorporate music genre as extra
conditional information in the training of the dance diffusion model. Extensive
experiments demonstrate that our proposed framework achieves state-of-the-art
performance on dance quality, diversity, and consistency.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15948" title="Abstract">arXiv:2312.15948</a> [<a href="/pdf/2312.15948" title="Download PDF">pdf</a>, <a href="/format/2312.15948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How digital will the future be? Analysis of prospective scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bugeau%2C+A">Aur&#xe9;lie Bugeau</a> (IUF, LaBRI, UB), 
<a href="/search/cs?searchtype=author&query=Ligozat%2C+A">Anne-Laure Ligozat</a> (ENSIIE, LISN, STL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">With the climate change context, many prospective studies, generally
encompassing all areas of society, imagine possible futures to expand the range
of options. The role of digital technologies within these possible futures is
rarely specifically targeted. Which digital technologies and methodologies do
these studies envision in a world that has mitigated and adapted to climate
change? In this paper, we propose a typology for scenarios to survey digital
technologies and their applications in 14 prospective studies and their
corresponding 35 future scenarios. Our finding is that all the scenarios
consider digital technology to be present in the future. We observe that only a
few of them question our relationship with digital technology and all aspects
related to its materiality, and none of the general studies envision
breakthroughs concerning technologies used today. Our result demonstrates the
lack of a systemic view of information and communication technologies. We
therefore argue for new prospective studies to envision the future of ICT.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15949" title="Abstract">arXiv:2312.15949</a> [<a href="/pdf/2312.15949" title="Download PDF">pdf</a>, <a href="/format/2312.15949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperDeepONet: learning operator with complex target function space  using the limited resources via hypernetwork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Yong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S+W">Sung Woong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H+J">Hyung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 13 figures. Published as a conference paper at Eleventh International Conference on Learning Representations (ICLR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Fast and accurate predictions for complex physical dynamics are a significant
challenge across various applications. Real-time prediction on
resource-constrained hardware is even more crucial in real-world problems. The
deep operator network (DeepONet) has recently been proposed as a framework for
learning nonlinear mappings between function spaces. However, the DeepONet
requires many parameters and has a high computational cost when learning
operators, particularly those with complex (discontinuous or non-smooth) target
functions. This study proposes HyperDeepONet, which uses the expressive power
of the hypernetwork to enable the learning of a complex operator with a smaller
set of parameters. The DeepONet and its variant models can be thought of as a
method of injecting the input function information into the target function.
From this perspective, these models can be viewed as a particular case of
HyperDeepONet. We analyze the complexity of DeepONet and conclude that
HyperDeepONet needs relatively lower complexity to obtain the desired accuracy
for operator learning. HyperDeepONet successfully learned various operators
with fewer computational resources compared to other benchmarks.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15954" title="Abstract">arXiv:2312.15954</a> [<a href="/pdf/2312.15954" title="Download PDF">pdf</a>, <a href="/ps/2312.15954" title="Download PostScript">ps</a>, <a href="/format/2312.15954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On two-dimensional minimal linear codes over the rings  $\mathbb{Z}_{p^n}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+B">Biplab Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+R+K">Ratnesh Kumar Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">In this paper we study two dimensional minimal linear code over the ring
$\mathbb{Z}_{p^n}$(where $p$ is prime). We show that if the generator matrix
$G$ of the two dimensional linear code $M$ contains $p^n+p^{n-1}$ column vector
of the following type {\scriptsize{$u_{l_1}\begin{pmatrix} 1\\ 0
\end{pmatrix}$, $u_{l_2}\begin{pmatrix} 0\\1 \end{pmatrix}$,
$u_{l_3}\begin{pmatrix} 1\\u_1 \end{pmatrix}$, $u_{l_4}\begin{pmatrix} 1\\u_2
\end{pmatrix}$, \ldots,$u_{l_{p^n-p^{n-1}+2}} \begin{pmatrix}
1\\u_{p^n-p^{n-1}} \end{pmatrix}$, $u_{l_{p^n-p^{n-1}+3}}\begin{pmatrix} d_1 \\
1 \end{pmatrix}$, $u_{l_{p^n-p^{n-1}+4}}\begin{pmatrix} d_2\\ 1
\end{pmatrix}$,\ldots \dots,\\ $u_{l_{p^n+1}}\begin{pmatrix} d_{p^{n-1}-1}\\1
\end{pmatrix}$, $u_{l_{p^n+2}}\begin{pmatrix} 1\\d_1 \end{pmatrix}$,
$u_{l_{p^n+3}}\begin{pmatrix} 1\\d_2
\end{pmatrix}$,\ldots,$u_{l_{p^n+p^{n-1}}}\begin{pmatrix} 1 \\d_{p^{n-1}-1}
\end{pmatrix}$}}, where $u_i$ and $d_j$ are distinct units and zero divisors
respectively in the ring $\mathbb{Z}_{p^n}$ for $1\leq i \leq p^n+p^{n-1}$,
$1\leq j \leq p^{n-1}-1$ and additionally, denote $u_{l_i}$ as units in
$\mathbb{Z}_{p^n}$, then the module generated by $G$ is a minimal linear code.
Also we show that if any one column vector of the above types are not present
entirely in $G$, then the generated module is not a minimal linear code.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15955" title="Abstract">arXiv:2312.15955</a> [<a href="/pdf/2312.15955" title="Download PDF">pdf</a>, <a href="/format/2312.15955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Redundancy-based Automated Program Repair by Fine-grained  Pattern Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiajun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhirui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Redundancy-based automated program repair (APR), which generates patches by
referencing existing source code, has gained much attention since they are
effective in repairing real-world bugs with good interpretability. However,
since existing approaches either demand the existence of multi-line similar
code or randomly reference existing code, they can only repair a small number
of bugs with many incorrect patches, hindering their wide application in
practice. In this work, we aim to improve the effectiveness of redundancy-based
APR by exploring more effective source code reuse methods for improving the
number of correct patches and reducing incorrect patches. Specifically, we have
proposed a new repair technique named Repatt, which incorporates a two-level
pattern mining process for guiding effective patch generation (i.e., token and
expression levels). We have conducted an extensive experiment on the
widely-used Defects4J benchmark and compared Repatt with eight state-of-the-art
APR approaches. The results show that our approach complements existing
approaches by repairing {15} unique bugs compared with the latest deep
learning-based methods and {19} unique bugs compared with traditional repair
methods when providing the perfect fault localization. In addition, when the
perfect fault localization is unknown in real practice, Repatt significantly
outperforms the baseline approaches by achieving much higher patch precision,
i.e., {83.8\%}. Moreover, we further proposed an effective patch ranking
strategy for combining the strength of Repatt and the baseline methods. The
result shows that it repairs 124 bugs when only considering the Top-1 patches
and improves the best-performing repair method by repairing 39 more bugs. The
results demonstrate the effectiveness of our approach for practical use.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15959" title="Abstract">arXiv:2312.15959</a> [<a href="/pdf/2312.15959" title="Download PDF">pdf</a>, <a href="/format/2312.15959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Range Entropy Queries and Partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+S">Sanjay Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Sintos%2C+S">Stavros Sintos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICDT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Data partitioning that maximizes or minimizes Shannon entropy is a crucial
subroutine in data compression, columnar storage, and cardinality estimation
algorithms. These partition algorithms can be accelerated if we have a data
structure to find the entropy in different subsets of data when the algorithm
needs to decide what block to construct. While it is generally known how to
compute the entropy of a discrete distribution efficiently, we want to
efficiently derive the entropy among the data items that lie in a specific
area. We solve this problem in a typical setting when we deal with real data,
where data items are geometric points and each requested area is a query
(hyper)rectangle. More specifically, we consider a set $P$ of $n$ weighted and
colored points in $\mathbb{R}^d$. The goal is to construct a low space data
structure, such that given a query (hyper)rectangle $R$, it computes the
entropy based on the colors of the points in $P\cap R$, in sublinear time. We
show a conditional lower bound for this problem proving that we cannot hope for
data structures with near-linear space and near-constant query time. Then, we
propose exact data structures for $d=1$ and $d&gt;1$ with $o(n^{2d})$ space and
$o(n)$ query time. We also provide a tune parameter $t$ that the user can
choose to bound the asymptotic space and query time of the new data structures.
Next, we propose near linear space data structures for returning either an
additive or a multiplicative approximation of the entropy. Finally, we show how
we can use the new data structures to efficiently partition time series and
histograms with respect to entropy.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15960" title="Abstract">arXiv:2312.15960</a> [<a href="/pdf/2312.15960" title="Download PDF">pdf</a>, <a href="/format/2312.15960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoTCoder: Elevating Large Language Models with Modular of Thought for  Challenging Programming Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Model: <a href="https://huggingface.co/JingyaoLi/MoTCoder-15B-v1.0.">this https URL</a> Code: <a href="https://github.com/dvlab-research/MoTCoder">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large Language Models (LLMs) have showcased impressive capabilities in
handling straightforward programming tasks. However, their performance tends to
falter when confronted with more challenging programming problems. We observe
that conventional models often generate solutions as monolithic code blocks,
restricting their effectiveness in tackling intricate questions. To overcome
this limitation, we present Modular-of-Thought Coder (MoTCoder). We introduce a
pioneering framework for MoT instruction tuning, designed to promote the
decomposition of tasks into logical sub-tasks and sub-modules. Our
investigations reveal that, through the cultivation and utilization of
sub-modules, MoTCoder significantly improves both the modularity and
correctness of the generated solutions, leading to substantial relative pass@1
improvements of 12.9% on APPS and 9.43% on CodeContests. Our codes are
available at https://github.com/dvlab-research/MoTCoder.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15964" title="Abstract">arXiv:2312.15964</a> [<a href="/pdf/2312.15964" title="Download PDF">pdf</a>, <a href="/format/2312.15964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Guidance Tuning for Text-To-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dohae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Myungjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">In-Kwon Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in Text-to-Image (T2I) diffusion models have demonstrated
impressive success in generating high-quality images with zero-shot
generalization capabilities. Yet, current models struggle to closely adhere to
prompt semantics, often misrepresenting or overlooking specific attributes. To
address this, we propose a simple, training-free approach that modulates the
guidance direction of diffusion models during inference. We first decompose the
prompt semantics into a set of concepts, and monitor the guidance trajectory in
relation to each concept. Our key observation is that deviations in model's
adherence to prompt semantics are highly correlated with divergence of the
guidance from one or more of these concepts. Based on this observation, we
devise a technique to steer the guidance direction towards any concept from
which the model diverges. Extensive experimentation validates that our method
improves the semantic alignment of images generated by diffusion models in
response to prompts. Project page is available at: https://korguy.github.io/
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15965" title="Abstract">arXiv:2312.15965</a> [<a href="/pdf/2312.15965" title="Download PDF">pdf</a>, <a href="/format/2312.15965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic and Pessimistic Actor in RL:Decoupling Exploration and  Utilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingpu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Helin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zirui Song</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Miao Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/yydsok/OPARL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep neural network(DNN) generalization is limited by the over-reliance of
current offline reinforcement learning techniques on conservative processing of
existing datasets. This method frequently results in algorithms that settle for
suboptimal solutions that only adjust to a certain dataset. Similarly, in
online reinforcement learning, the previously imposed punitive pessimism also
deprives the model of its exploratory potential. Our research proposes a novel
framework, Optimistic and Pessimistic Actor Reinforcement Learning (OPARL).
OPARL employs a unique dual-actor approach: an optimistic actor dedicated to
exploration and a pessimistic actor focused on utilization, thereby effectively
differentiating between exploration and utilization strategies. This unique
combination in reinforcement learning methods fosters a more balanced and
efficient approach. It enables the optimization of policies that focus on
actions yielding high rewards through pessimistic utilization strategies, while
also ensuring extensive state coverage via optimistic exploration. Experiments
and theoretical study demonstrates OPARL improves agents' capacities for
application and exploration. In the most tasks of DMControl benchmark and
Mujoco environment, OPARL performed better than state-of-the-art methods. Our
code has released on https://github.com/yydsok/OPARL
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15966" title="Abstract">arXiv:2312.15966</a> [<a href="/pdf/2312.15966" title="Download PDF">pdf</a>, <a href="/format/2312.15966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Hyperdimensional Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ergun%2C+K">Kazim Ergun</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+R">Rishikanth Chandrasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Rosing%2C+T">Tajana Rosing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication, 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) enables a loose set of participating clients to
collaboratively learn a global model via coordination by a central server and
with no need for data sharing. Existing FL approaches that rely on complex
algorithms with massive models, such as deep neural networks (DNNs), suffer
from computation and communication bottlenecks. In this paper, we first propose
FedHDC, a federated learning framework based on hyperdimensional computing
(HDC). FedHDC allows for fast and light-weight local training on clients,
provides robust learning, and has smaller model communication overhead compared
to learning with DNNs. However, current HDC algorithms get poor accuracy when
classifying larger &amp; more complex images, such as CIFAR10. To address this
issue, we design FHDnn, which complements FedHDC with a self-supervised
contrastive learning feature extractor. We avoid the transmission of the DNN
and instead train only the HDC learner in a federated manner, which accelerates
learning, reduces transmission cost, and utilizes the robustness of HDC to
tackle network errors. We present a formal analysis of the algorithm and derive
its convergence rate both theoretically, and show experimentally that FHDnn
converges 3$\times$ faster vs. DNNs. The strategies we propose to improve the
communication efficiency enable our design to reduce communication costs by
66$\times$ vs. DNNs, local client compute and energy consumption by ~1.5 -
6$\times$, while being highly robust to network errors. Finally, our proposed
strategies for improving the communication efficiency have up to 32$\times$
lower communication costs with good accuracy.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15968" title="Abstract">arXiv:2312.15968</a> [<a href="/pdf/2312.15968" title="Download PDF">pdf</a>, <a href="/ps/2312.15968" title="Download PostScript">ps</a>, <a href="/format/2312.15968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An equilibrated flux a posteriori error estimator for defeaturing  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buffa%2C+A">Annalisa Buffa</a>, 
<a href="/search/math?searchtype=author&query=Chanon%2C+O">Ondine Chanon</a>, 
<a href="/search/math?searchtype=author&query=Grappein%2C+D">Denise Grappein</a>, 
<a href="/search/math?searchtype=author&query=V%C3%A1zquez%2C+R">Rafael V&#xe1;zquez</a>, 
<a href="/search/math?searchtype=author&query=Vohral%C3%ADk%2C+M">Martin Vohral&#xed;k</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">An a posteriori error estimator based on an equilibrated flux reconstruction
is proposed for defeaturing problems in the context of finite element
discretizations. Defeaturing consists in the simplification of a geometry by
removing features that are considered not relevant for the approximation of the
solution of a given PDE. In this work, the focus is on Poisson equation with
Neumann boundary conditions on the feature boundary. The estimator accounts
both for the so-called defeaturing error and for the numerical error committed
by approximating the solution on the defeatured domain. Unlike other estimators
that were previously proposed for defeaturing problems, the use of the
equilibrated flux reconstruction allows to obtain a sharp bound for the
numerical component of the error. Furthermore, it does not require the
evaluation of the normal trace of the numerical flux on the feature boundary:
this makes the estimator well-suited for finite element discretizations, in
which the normal trace of the numerical flux is typically discontinuous across
elements. The reliability of the estimator is proven and verified on several
numerical examples. Its capability to identify the most relevant features is
also shown, in anticipation of a future application to an adaptive strategy.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15969" title="Abstract">arXiv:2312.15969</a> [<a href="/pdf/2312.15969" title="Download PDF">pdf</a>, <a href="/ps/2312.15969" title="Download PostScript">ps</a>, <a href="/format/2312.15969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting the capacity of deep networks only at training stage for  nonlinear black-box system identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eivaghi%2C+V+M">Vahid MohammadZadeh Eivaghi</a>, 
<a href="/search/cs?searchtype=author&query=Shooredeli%2C+M+A">Mahdi Aliyari Shooredeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">To benefit from the modeling capacity of deep models in system
identification, without worrying about inference time, this study presents a
novel training strategy that uses deep models only at the training stage. For
this purpose two separate models with different structures and goals are
employed. The first one is a deep generative model aiming at modeling the
distribution of system output(s), called the teacher model, and the second one
is a shallow basis function model, named the student model, fed by system
input(s) to predict the system output(s). That means these isolated paths must
reach the same ultimate target. As deep models show a great performance in
modeling of highly nonlinear systems, aligning the representation space learned
by these two models make the student model to inherit the approximation power
of the teacher model. The proposed objective function consists of the objective
of each student and teacher model adding up with a distance penalty between the
learned latent representations. The simulation results on three nonlinear
benchmarks show a comparative performance with examined deep architectures
applied on the same benchmarks. Algorithmic transparency and structure
efficiency are also achieved as byproducts.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15970" title="Abstract">arXiv:2312.15970</a> [<a href="/pdf/2312.15970" title="Download PDF">pdf</a>, <a href="/format/2312.15970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Deformable Hypothesis Sampling for Accurate PatchMatch  Multi-View Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xianwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hanjiang Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a learnable Deformable Hypothesis Sampler
(DeformSampler) to address the challenging issue of noisy depth estimation for
accurate PatchMatch Multi-View Stereo (MVS). We observe that the heuristic
depth hypothesis sampling modes employed by PatchMatch MVS solvers are
insensitive to (i) the piece-wise smooth distribution of depths across the
object surface, and (ii) the implicit multi-modal distribution of depth
prediction probabilities along the ray direction on the surface points.
Accordingly, we develop DeformSampler to learn distribution-sensitive sample
spaces to (i) propagate depths consistent with the scene's geometry across the
object surface, and (ii) fit a Laplace Mixture model that approaches the
point-wise probabilities distribution of the actual depths along the ray
direction. We integrate DeformSampler into a learnable PatchMatch MVS system to
enhance depth estimation in challenging areas, such as piece-wise discontinuous
surface boundaries and weakly-textured regions. Experimental results on DTU and
Tanks \&amp; Temples datasets demonstrate its superior performance and
generalization capabilities compared to state-of-the-art competitors. Code is
available at https://github.com/Geo-Tell/DS-PMNet.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15971" title="Abstract">arXiv:2312.15971</a> [<a href="/pdf/2312.15971" title="Download PDF">pdf</a>, <a href="/format/2312.15971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Context Transformation Learning for Progressive Correspondence  Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guobao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most of existing correspondence pruning methods only concentrate on gathering
the context information as much as possible while neglecting effective ways to
utilize such information. In order to tackle this dilemma, in this paper we
propose Graph Context Transformation Network (GCT-Net) enhancing context
information to conduct consensus guidance for progressive correspondence
pruning. Specifically, we design the Graph Context Enhance Transformer which
first generates the graph network and then transforms it into multi-branch
graph contexts. Moreover, it employs self-attention and cross-attention to
magnify characteristics of each graph context for emphasizing the unique as
well as shared essential information. To further apply the recalibrated graph
contexts to the global domain, we propose the Graph Context Guidance
Transformer. This module adopts a confident-based sampling strategy to
temporarily screen high-confidence vertices for guiding accurate classification
by searching global consensus between screened vertices and remaining ones. The
extensive experimental results on outlier removal and relative pose estimation
clearly demonstrate the superior performance of GCT-Net compared to
state-of-the-art methods across outdoor and indoor datasets. The source code
will be available at: https://github.com/guobaoxiao/GCT-Net/.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15974" title="Abstract">arXiv:2312.15974</a> [<a href="/pdf/2312.15974" title="Download PDF">pdf</a>, <a href="/ps/2312.15974" title="Download PostScript">ps</a>, <a href="/format/2312.15974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Considerations about temporal rescaling, discretization, and  linearization of RNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caruso%2C+M">Mariano Caruso</a>, 
<a href="/search/cs?searchtype=author&query=Jarne%2C+C">Cecilia Jarne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 Figure, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">We explore the mathematical foundations of Recurrent Neural Networks (RNNs)
and three fundamental procedures: temporal rescaling, discretization, and
linearization. These techniques provide essential tools for characterizing RNN
behaviour, enabling insights into temporal dynamics, practical computational
implementation, and linear approximations for analysis. We discuss the flexible
order of application of these procedures, emphasizing their significance in
modelling and analyzing RNNs for computational neuroscience and machine
learning applications. We explicitly describe here under what conditions these
procedures can be interchangeable.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15975" title="Abstract">arXiv:2312.15975</a> [<a href="/pdf/2312.15975" title="Download PDF">pdf</a>, <a href="/format/2312.15975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filtered data based estimators for stochastic processes driven by  colored noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pavliotis%2C+G+A">Grigorios A. Pavliotis</a>, 
<a href="/search/math?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>, 
<a href="/search/math?searchtype=author&query=Zanoni%2C+A">Andrea Zanoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the problem of estimating unknown parameters in stochastic
differential equations driven by colored noise, given continuous-time
observations. Colored noise is modelled as a sequence of mean zero Gaussian
stationary processes with an exponential autocorrelation function, with
decreasing correlation time. Our goal is to infer parameters in the limit
equation, driven by white noise, given observations of the colored noise
dynamics. As in the case of parameter estimation for multiscale diffusions, the
observations are only compatible with the data in the white noise limit, and
classic estimators become biased, implying the need of preprocessing the data.
We consider both the maximum likelihood and the stochastic gradient descent in
continuous time estimators, and we propose modified versions of these methods,
in which the observations are filtered using an exponential filter. Both
stochastic differential equations with additive and multiplicative noise are
considered. We provide a convergence analysis for our novel estimators in the
limit of infinite data, and in the white noise limit, showing that the
estimators are asymptotically unbiased. We consider in detail the case of
multiplicative colored noise, in particular when the L\'evy area correction
drift appears in the limiting white noise equation. A series of numerical
experiments corroborates our theoretical results.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15980" title="Abstract">arXiv:2312.15980</a> [<a href="/pdf/2312.15980" title="Download PDF">pdf</a>, <a href="/format/2312.15980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HarmonyView: Harmonizing Consistency and Diversity in One-Image-to-3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sangmin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Byeongjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Go%2C+H">Hyojun Go</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin-Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://byeongjun-park.github.io/HarmonyView/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent progress in single-image 3D generation highlights the importance of
multi-view coherency, leveraging 3D priors from large-scale diffusion models
pretrained on Internet-scale images. However, the aspect of novel-view
diversity remains underexplored within the research landscape due to the
ambiguity in converting a 2D image into 3D content, where numerous potential
shapes can emerge. Here, we aim to address this research gap by simultaneously
addressing both consistency and diversity. Yet, striking a balance between
these two aspects poses a considerable challenge due to their inherent
trade-offs. This work introduces HarmonyView, a simple yet effective diffusion
sampling technique adept at decomposing two intricate aspects in single-image
3D generation: consistency and diversity. This approach paves the way for a
more nuanced exploration of the two critical dimensions within the sampling
process. Moreover, we propose a new evaluation metric based on CLIP image and
text encoders to comprehensively assess the diversity of the generated views,
which closely aligns with human evaluators' judgments. In experiments,
HarmonyView achieves a harmonious balance, demonstrating a win-win scenario in
both consistency and diversity.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15985" title="Abstract">arXiv:2312.15985</a> [<a href="/pdf/2312.15985" title="Download PDF">pdf</a>, <a href="/ps/2312.15985" title="Download PostScript">ps</a>, <a href="/format/2312.15985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Messages Improve Communication Efficiency among Isolated  Intelligent Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yuchuan Jang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Weijie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=meo%2C+C">Cristian meo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Individuals, despite having varied life experiences and learning processes,
can communicate effectively through languages. This study aims to explore the
efficiency of language as a communication medium. We put forth two specific
hypotheses: First, discrete messages are more effective than continuous ones
when agents have diverse personal experiences. Second, communications using
multiple discrete tokens are more advantageous than those using a single token.
To valdate these hypotheses, we designed multi-agent machine learning
experiments to assess communication efficiency using various information
transmission methods between speakers and listeners. Our empirical findings
indicate that, in scenarios where agents are exposed to different data,
communicating through sentences composed of discrete tokens offers the best
inter-agent communication efficiency. The limitations of our finding include
lack of systematic advantages over other more sophisticated encoder-decoder
model such as variational autoencoder and lack of evluation on non-image
dataset, which we will leave for future studies.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15987" title="Abstract">arXiv:2312.15987</a> [<a href="/pdf/2312.15987" title="Download PDF">pdf</a>, <a href="/ps/2312.15987" title="Download PostScript">ps</a>, <a href="/format/2312.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-Stack End-to-End Sub-THz Simulations at 140 GHz using NYUSIM  Channel Model in ns-3
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poddar%2C+H">Hitesh Poddar</a>, 
<a href="/search/cs?searchtype=author&query=Chowdary%2C+A">Akhileswar Chowdary</a>, 
<a href="/search/cs?searchtype=author&query=Rappaport%2C+T+S">Theodore S. Rappaport</a>, 
<a href="/search/cs?searchtype=author&query=Chafii%2C+M">Marwa Chafii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The next generation of wireless communication, is expected to harness the
potential of the sub-THz bands to achieve exceptional performance and
ubiquitous connectivity. However, network simulators such as ns-3 currently
lack support for channel models above 100 GHz. This limits the ability of
researchers to study, design, and evaluate systems operating above 100 GHz.
Here, we show that drop based NYUSIM channel model can be used to simulate
channels above 100 GHz in all 3GPP scenarios including urban microcell (UMi),
urban macrocell (UMa), rural macrocell (RMa), indoor hotspot (InH), and indoor
factory (InF). We evaluate the full stack downlink end-to-end performance
(throughput, latency and packet drop) experienced by single user equipment (UE)
connected to a Next Generation Node B (gNB) operating in the sub-THz bands for
three gNB-UE antenna configurations: 8x8-4x4, 16x16-4x4, and 64x64-8x8 by using
NYUSIM channel model at 140 GHz in the ns-3 mmWave module. Additionally, it is
found that determining the exact number of realizations required to obtain
statistically significant results using simulation platforms like ns-3 remains
challenging, as end-to-end performance metrics vary strongly with the number of
realizations. Hence, we show the variation in throughput vs number of
realizations and find the optimal number of realizations required to obtain
statistically significant results. We strongly encourage researchers worldwide
to adopt a similar approach, as it enables the readers to assess the accuracy
and reliability of the reported results and enhance the finding's overall
interpretability.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15993" title="Abstract">arXiv:2312.15993</a> [<a href="/pdf/2312.15993" title="Download PDF">pdf</a>, <a href="/ps/2312.15993" title="Download PostScript">ps</a>, <a href="/format/2312.15993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Kalman-based hybrid car following strategy using TD3 and CACC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Ruidong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Bin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=TAPUS%2C+A">Adriana TAPUS</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shiteng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Ying Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32pages,13figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">In autonomous driving, the hybrid strategy of deep reinforcement learning and
cooperative adaptive cruise control (CACC) can fully utilize the advantages of
the two algorithms and significantly improve the performance of car following.
However, it is challenging for the traditional hybrid strategy based on fixed
coefficients to adapt to mixed traffic flow scenarios, which may decrease the
performance and even lead to accidents. To address the above problems, a hybrid
car following strategy based on an adaptive Kalman Filter is proposed by
regarding CACC and Twin Delayed Deep Deterministic Policy Gradient (TD3)
algorithms. Different from traditional hybrid strategy based on fixed
coefficients, the Kalman gain H, using as an adaptive coefficient, is derived
from multi-timestep predictions and Monte Carlo Tree Search. At the end of
study, simulation results with 4157745 timesteps indicate that, compared with
the TD3 and HCFS algorithms, the proposed algorithm in this study can
substantially enhance the safety of car following in mixed traffic flow without
compromising the comfort and efficiency.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15994" title="Abstract">arXiv:2312.15994</a> [<a href="/pdf/2312.15994" title="Download PDF">pdf</a>, <a href="/format/2312.15994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Bias Mitigation through Proxy Sensitive Attribute Label  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+B">Bhushan Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+A">Anubha Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+D">Deepak Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+D">Darshika Tiwari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Modelling Uncertainty in the Financial World (MUFin) Workshop in AAAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Addressing bias in the trained machine learning system often requires access
to sensitive attributes. In practice, these attributes are not available either
due to legal and policy regulations or data unavailability for a given
demographic. Existing bias mitigation algorithms are limited in their
applicability to real-world scenarios as they require access to sensitive
attributes to achieve fairness. In this research work, we aim to address this
bottleneck through our proposed unsupervised proxy-sensitive attribute label
generation technique. Towards this end, we propose a two-stage approach of
unsupervised embedding generation followed by clustering to obtain
proxy-sensitive labels. The efficacy of our work relies on the assumption that
bias propagates through non-sensitive attributes that are correlated to the
sensitive attributes and, when mapped to the high dimensional latent space,
produces clusters of different demographic groups that exist in the data.
Experimental results demonstrate that bias mitigation using existing algorithms
such as Fair Mixup and Adversarial Debiasing yields comparable results on
derived proxy labels when compared against using true sensitive attributes.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15995" title="Abstract">arXiv:2312.15995</a> [<a href="/pdf/2312.15995" title="Download PDF">pdf</a>, <a href="/ps/2312.15995" title="Download PostScript">ps</a>, <a href="/format/2312.15995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization in Kernel Regression Under Realistic Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barzilai%2C+D">Daniel Barzilai</a>, 
<a href="/search/cs?searchtype=author&query=Shamir%2C+O">Ohad Shamir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">It is by now well-established that modern over-parameterized models seem to
elude the bias-variance tradeoff and generalize well despite overfitting noise.
Many recent works attempt to analyze this phenomenon in the relatively
tractable setting of kernel regression. However, as we argue in detail, most
past works on this topic either make unrealistic assumptions, or focus on a
narrow problem setup. This work aims to provide a unified theory to upper bound
the excess risk of kernel regression for nearly all common and realistic
settings. Specifically, we provide rigorous bounds that hold for common kernels
and for any amount of regularization, noise, any input dimension, and any
number of samples. Furthermore, we provide relative perturbation bounds for the
eigenvalues of kernel matrices, which may be of independent interest. These
reveal a self-regularization phenomenon, whereby a heavy tail in the
eigendecomposition of the kernel provides it with an implicit form of
regularization, enabling good generalization. When applied to common kernels,
our results imply benign overfitting in high input dimensions, nearly tempered
overfitting in fixed dimensions, and explicit convergence rates for regularized
regression. As a by-product, we obtain time-dependent bounds for neural
networks trained in the kernel regime.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15997" title="Abstract">arXiv:2312.15997</a> [<a href="/pdf/2312.15997" title="Download PDF">pdf</a>, <a href="/format/2312.15997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Large Language Models with Human Preferences through  Representation Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Muling Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Changze Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zixuan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aligning large language models (LLMs) with human preferences is crucial for
enhancing their utility in terms of helpfulness, truthfulness, safety,
harmlessness, and interestingness. Existing methods for achieving this
alignment often involves employing reinforcement learning from human feedback
(RLHF) to fine-tune LLMs based on human labels assessing the relative quality
of model responses. Nevertheless, RLHF is susceptible to instability during
fine-tuning and presents challenges in implementation.Drawing inspiration from
the emerging field of representation engineering (RepE), this study aims to
identify relevant representations for high-level human preferences embedded in
patterns of activity within an LLM, and achieve precise control of model
behavior by transforming its representations. This novel approach, denoted as
Representation Alignment from Human Feedback (RAHF), proves to be effective,
computationally efficient, and easy to implement.Extensive experiments
demonstrate the efficacy of RAHF in not only capturing but also manipulating
representations to align with a broad spectrum of human preferences or values,
rather than being confined to a singular concept or function (e.g. honesty or
bias). RAHF's versatility in accommodating diverse human preferences shows its
potential for advancing LLM performance.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15999" title="Abstract">arXiv:2312.15999</a> [<a href="/pdf/2312.15999" title="Download PDF">pdf</a>, <a href="/format/2312.15999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pricing with Contextual Elasticity and Heteroscedastic Valuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study an online contextual dynamic pricing problem, where customers decide
whether to purchase a product based on its features and price. We introduce a
novel approach to modeling a customer's expected demand by incorporating
feature-based price elasticity, which can be equivalently represented as a
valuation with heteroscedastic noise. To solve the problem, we propose a
computationally efficient algorithm called "Pricing with Perturbation (PwP)",
which enjoys an $O(\sqrt{dT\log T})$ regret while allowing arbitrary
adversarial input context sequences. We also prove a matching lower bound at
$\Omega(\sqrt{dT})$ to show the optimality regarding $d$ and $T$ (up to $\log
T$ factors). Our results shed light on the relationship between contextual
elasticity and heteroscedastic valuation, providing insights for effective and
practical pricing strategies.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16007" title="Abstract">arXiv:2312.16007</a> [<a href="/pdf/2312.16007" title="Download PDF">pdf</a>, <a href="/format/2312.16007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fully decentralized auditing approach for edge computing: A  Game-Theoretic Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seyedi%2C+Z">Zahra Seyedi</a>, 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+F">Farhad Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mohammad Ali</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Ximeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Edge storage presents a viable data storage alternative for application
vendors (AV), offering benefits such as reduced bandwidth overhead and latency
compared to cloud storage. However, data cached in edge computing systems is
susceptible to intentional or accidental disturbances. This paper proposes a
decentralized integrity auditing scheme to safeguard data integrity and counter
the traditional reliance on centralized third-party auditors (TPA), which are
unfit for distributed systems. Our novel approach employs edge servers (ES) as
mutual auditors, eliminating the need for a centralized entity. This
decentralization minimizes potential collusion with malicious auditors and
biases in audit outcomes. Using a strategic game model, we demonstrate that ESs
are more motivated to audit each other than TPAs. The auditing process is
addressed as a Nash Equilibrium problem, assuring accurate integrity proof
through incentives for ESs. Our scheme's security and performance are
rigorously assessed, showing it is secure within the random oracle model,
offers improved speed, and is cost-effective compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16010" title="Abstract">arXiv:2312.16010</a> [<a href="/pdf/2312.16010" title="Download PDF">pdf</a>, <a href="/format/2312.16010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Fairness in DareFightingICE Agents Evaluation Through a Delay  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nimpattanavong%2C+C">Chollakorn Nimpattanavong</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+T">Thai Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Ibrahim Khan</a>, 
<a href="/search/cs?searchtype=author&query=Thawonmas%2C+R">Ruck Thawonmas</a>, 
<a href="/search/cs?searchtype=author&query=Choensawat%2C+W">Worawat Choensawat</a>, 
<a href="/search/cs?searchtype=author&query=Sookhanaphibarn%2C+K">Kingkarn Sookhanaphibarn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an updated version of our 2023 IEEE Conference on Games paper of the same title where (a) Eqn. 3 has been revised, (b) Eqn. 5 has been added for clarity, and (c) an appendix has been added that contains the link to the source code and raw data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF)

</div>
<p class="mathjax">This paper proposes a delay mechanism to mitigate the impact of latency
differences in the gRPC framework--a high-performance, open-source universal
remote procedure call (RPC) framework--between different programming languages
on the performance of agents in DareFightingICE, a fighting game research
platform. The study finds that gRPC latency differences between Java and Python
can significantly impact real-time decision-making. Without a delay mechanism,
Java-based agents outperform Python-based ones due to lower gRPC latency on the
Java platform. However, with the proposed delay mechanism, both Java-based and
Python-based agents exhibit similar performance, leading to a fair comparison
between agents developed using different programming languages. Thus, this work
underscores the crucial importance of considering gRPC latency when developing
and evaluating agents in DareFightingICE, and the insights gained could
potentially extend to other gRPC-based applications.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16011" title="Abstract">arXiv:2312.16011</a> [<a href="/pdf/2312.16011" title="Download PDF">pdf</a>, <a href="/format/2312.16011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assigning Stationary Distributions to Sparse Stochastic Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gillis%2C+N">Nicolas Gillis</a>, 
<a href="/search/math?searchtype=author&query=Van+Dooren%2C+P">Paul Van Dooren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, code available from <a href="https://gitlab.com/ngillis/TSDP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC); Probability (math.PR); Computation (stat.CO)

</div>
<p class="mathjax">The target stationary distribution problem (TSDP) is the following: given an
irreducible stochastic matrix $G$ and a target stationary distribution $\hat
\mu$, construct a minimum norm perturbation, $\Delta$, such that $\hat G =
G+\Delta$ is also stochastic and has the prescribed target stationary
distribution, $\hat \mu$. In this paper, we revisit the TSDP under a constraint
on the support of $\Delta$, that is, on the set of non-zero entries of
$\Delta$. This is particularly meaningful in practice since one cannot
typically modify all entries of $G$. We first show how to construct a feasible
solution $\hat G$ that has essentially the same support as the matrix $G$. Then
we show how to compute globally optimal and sparse solutions using the
component-wise $\ell_1$ norm and linear optimization. We propose an efficient
implementation that relies on a column-generation approach which allows us to
solve sparse problems of size up to $10^5 \times 10^5$ in a few minutes. We
illustrate the proposed algorithms with several numerical experiments.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16012" title="Abstract">arXiv:2312.16012</a> [<a href="/pdf/2312.16012" title="Download PDF">pdf</a>, <a href="/format/2312.16012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection-based Intermediate Supervision for Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Daowan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuanyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenfeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, neural module networks (NMNs) have yielded ongoing success in
answering compositional visual questions, especially those involving multi-hop
visual and logical reasoning. NMNs decompose the complex question into several
sub-tasks using instance-modules from the reasoning paths of that question and
then exploit intermediate supervisions to guide answer prediction, thereby
improving inference interpretability. However, their performance may be
hindered due to sketchy modeling of intermediate supervisions. For instance,
(1) a prior assumption that each instance-module refers to only one grounded
object yet overlooks other potentially associated grounded objects, impeding
full cross-modal alignment learning; (2) IoU-based intermediate supervisions
may introduce noise signals as the bounding box overlap issue might guide the
model's focus towards irrelevant objects. To address these issues, a novel
method, \textbf{\underline{D}}etection-based \textbf{\underline{I}}ntermediate
\textbf{\underline{S}}upervision (DIS), is proposed, which adopts a generative
detection framework to facilitate multiple grounding supervisions via sequence
generation. As such, DIS offers more comprehensive and accurate intermediate
supervisions, thereby boosting answer prediction performance. Furthermore, by
considering intermediate results, DIS enhances the consistency in answering
compositional questions and their sub-questions.Extensive experiments
demonstrate the superiority of our proposed DIS, showcasing both improved
accuracy and state-of-the-art reasoning consistency compared to prior
approaches.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16014" title="Abstract">arXiv:2312.16014</a> [<a href="/pdf/2312.16014" title="Download PDF">pdf</a>, <a href="/format/2312.16014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Non-Line-of-Sight Imaging with Light Transport Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiarui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+R">Ruixu Geng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaolong Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yang Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Passive non-line-of-sight (NLOS) imaging has witnessed rapid development in
recent years, due to its ability to image objects that are out of sight. The
light transport condition plays an important role in this task since changing
the conditions will lead to different imaging models. Existing learning-based
NLOS methods usually train independent models for different light transport
conditions, which is computationally inefficient and impairs the practicality
of the models. In this work, we propose NLOS-LTM, a novel passive NLOS imaging
method that effectively handles multiple light transport conditions with a
single network. We achieve this by inferring a latent light transport
representation from the projection image and using this representation to
modulate the network that reconstructs the hidden image from the projection
image. We train a light transport encoder together with a vector quantizer to
obtain the light transport representation. To further regulate this
representation, we jointly learn both the reconstruction network and the
reprojection network during training. A set of light transport modulation
blocks is used to modulate the two jointly trained networks in a multi-scale
way. Extensive experiments on a large-scale passive NLOS dataset demonstrate
the superiority of the proposed method. The code is available at
https://github.com/JerryOctopus/NLOS-LTM.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16015" title="Abstract">arXiv:2312.16015</a> [<a href="/pdf/2312.16015" title="Download PDF">pdf</a>, <a href="/ps/2312.16015" title="Download PostScript">ps</a>, <a href="/format/2312.16015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Evaluation Techniques for Recommendation  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jadon%2C+A">Aryan Jadon</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A">Avinash Patil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The effectiveness of recommendation systems is pivotal to user engagement and
satisfaction in online platforms. As these recommendation systems increasingly
influence user choices, their evaluation transcends mere technical performance
and becomes central to business success. This paper addresses the multifaceted
nature of recommendation system evaluation by introducing a comprehensive suite
of metrics, each tailored to capture a distinct aspect of system performance.
We discuss similarity metrics that quantify the precision of content-based and
collaborative filtering mechanisms, along with candidate generation metrics
which measure how well the system identifies a broad yet pertinent range of
items. Following this, we delve into predictive metrics that assess the
accuracy of forecasted preferences, ranking metrics that evaluate the order in
which recommendations are presented, and business metrics that align system
performance with economic objectives.
<br />Our approach emphasizes the contextual application of these metrics and their
interdependencies. In this paper, we identify the strengths and limitations of
current evaluation practices and highlight the nuanced trade-offs that emerge
when optimizing recommendation systems across different metrics. The paper
concludes by proposing a framework for selecting and interpreting these metrics
to not only improve system performance but also to advance business goals. This
work is to aid researchers and practitioners in critically assessing
recommendation systems and fosters the development of more nuanced, effective,
and economically viable personalization strategies. Our code is available at
GitHub -
https://github.com/aryan-jadon/Evaluation-Metrics-for-Recommendation-Systems.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16016" title="Abstract">arXiv:2312.16016</a> [<a href="/pdf/2312.16016" title="Download PDF">pdf</a>, <a href="/format/2312.16016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V-STRONG: Visual Self-Supervised Traversability Learning for Off-road  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sanghun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">JoonHo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangyun Meng</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+A">Alexander Lambert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Reliable estimation of terrain traversability is critical for the successful
deployment of autonomous systems in wild, outdoor environments. Given the lack
of large-scale annotated datasets for off-road navigation, strictly-supervised
learning approaches remain limited in their generalization ability. To this
end, we introduce a novel, image-based self-supervised learning method for
traversability prediction, leveraging a state-of-the-art vision foundation
model for improved out-of-distribution performance. Our method employs
contrastive representation learning using both human driving data and
instance-based segmentation masks during training. We show that this simple,
yet effective, technique drastically outperforms recent methods in predicting
traversability for both on- and off-trail driving scenarios. We compare our
method with recent baselines on both a common benchmark as well as our own
datasets, covering a diverse range of outdoor environments and varied terrain
types. We also demonstrate the compatibility of resulting costmap predictions
with a model-predictive controller. Finally, we evaluate our approach on zero-
and few-shot tasks, demonstrating unprecedented performance for generalization
to new environments. Videos and additional material can be found here:
\url{https://sites.google.com/view/visual-traversability-learning}.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16018" title="Abstract">arXiv:2312.16018</a> [<a href="/pdf/2312.16018" title="Download PDF">pdf</a>, <a href="/format/2312.16018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Sichun Luo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haohan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yinya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aojun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuanzhang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+M">Mingjie Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated remarkable capabilities and
have been extensively deployed across various domains, including recommender
systems. Numerous studies have employed specialized \textit{prompts} to harness
the in-context learning capabilities intrinsic to LLMs. For example, LLMs are
prompted to act as zero-shot rankers for listwise ranking, evaluating candidate
items generated by a retrieval model for recommendation. Recent research
further uses instruction tuning techniques to align LLM with human preference
for more promising recommendations. Despite its potential, current research
overlooks the integration of multiple ranking tasks to enhance model
performance. Moreover, the signal from the conventional recommendation model is
not integrated into the LLM, limiting the current system performance.
<br />In this paper, we introduce RecRanker, tailored for instruction tuning LLM to
serve as the \textbf{Ranker} for top-\textit{k} \textbf{Rec}ommendations.
Specifically, we introduce importance-aware sampling, clustering-based
sampling, and penalty for repetitive sampling for sampling high-quality,
representative, and diverse training data. To enhance the prompt, we introduce
position shifting strategy to mitigate position bias and augment the prompt
with auxiliary information from conventional recommendation models, thereby
enriching the contextual understanding of the LLM. Subsequently, we utilize the
sampled data to assemble an instruction-tuning dataset with the augmented
prompt comprising three distinct ranking tasks: pointwise, pairwise, and
listwise rankings. We further propose a hybrid ranking method to enhance the
model performance by ensembling these ranking tasks. Our empirical evaluations
demonstrate the effectiveness of our proposed RecRanker in both direct and
sequential recommendation scenarios.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16020" title="Abstract">arXiv:2312.16020</a> [<a href="/pdf/2312.16020" title="Download PDF">pdf</a>, <a href="/format/2312.16020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Neural Pruning with Gradient Sampling Optimization for Residual  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this study, we explore an innovative approach for neural network
optimization, focusing on the application of gradient sampling techniques,
similar to those in StochGradAdam, during the pruning process. Our primary
objective is to maintain high accuracy levels in pruned models, a critical
challenge in resource-limited scenarios. Our extensive experiments reveal that
models optimized with gradient sampling techniques are more effective at
preserving accuracy during pruning compared to those using traditional
optimization methods. This finding underscores the significance of gradient
sampling in facilitating robust learning and enabling networks to retain
crucial information even after substantial reduction in their complexity. We
validate our approach across various datasets and neural architectures,
demonstrating its broad applicability and effectiveness. The paper also delves
into the theoretical aspects, explaining how gradient sampling techniques
contribute to the robustness of models during pruning. Our results suggest a
promising direction for creating efficient neural networks that do not
compromise on accuracy, even in environments with constrained computational
resources.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16023" title="Abstract">arXiv:2312.16023</a> [<a href="/pdf/2312.16023" title="Download PDF">pdf</a>, <a href="/format/2312.16023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocMSU: A Comprehensive Benchmark for Document-level Multimodal Sarcasm  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hang Du</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+G">Guoshun Nan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Binzhu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junrui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hehe Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qimei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaofeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Multimodal Sarcasm Understanding (MSU) has a wide range of applications in
the news field such as public opinion analysis and forgery detection. However,
existing MSU benchmarks and approaches usually focus on sentence-level MSU. In
document-level news, sarcasm clues are sparse or small and are often concealed
in long text. Moreover, compared to sentence-level comments like tweets, which
mainly focus on only a few trends or hot topics (e.g., sports events), content
in the news is considerably diverse. Models created for sentence-level MSU may
fail to capture sarcasm clues in document-level news. To fill this gap, we
present a comprehensive benchmark for Document-level Multimodal Sarcasm
Understanding (DocMSU). Our dataset contains 102,588 pieces of news with
text-image pairs, covering 9 diverse topics such as health, business, etc. The
proposed large-scale and diverse DocMSU significantly facilitates the research
of document-level MSU in real-world scenarios. To take on the new challenges
posed by DocMSU, we introduce a fine-grained sarcasm comprehension method to
properly align the pixel-level image features with word-level textual features
in documents. Experiments demonstrate the effectiveness of our method, showing
that it can serve as a baseline approach to the challenging DocMSU. Our code
and dataset are available at https://github.com/Dulpy/DocMSU.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16033" title="Abstract">arXiv:2312.16033</a> [<a href="/pdf/2312.16033" title="Download PDF">pdf</a>, <a href="/format/2312.16033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Hardness of Minimum Embedded Order Dependency Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramos%2C+A">Alejandro Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Uemura%2C+T">Takuya Uemura</a>, 
<a href="/search/cs?searchtype=author&query=Amagata%2C+D">Daichi Amagata</a>, 
<a href="/search/cs?searchtype=author&query=Shirai%2C+R">Ryo Shirai</a>, 
<a href="/search/cs?searchtype=author&query=Hara%2C+T">Takahiro Hara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Order Dependencies (ODs) have many applications, such as query optimization,
data integration, and data cleaning. Although many works addressed the problem
of discovering OD (and its variants), they do not consider datasets with
missing values, a standard observation in real-world datasets. This paper
introduces the novel notion of Embedded ODs (eODs) to deal with missing values.
The intuition of eODs is to confirm ODs only on tuples with no missing values
on a given embedding (a set of attributes). In this paper, we address the
problem of validating a given eOD. If the eOD holds, we return true. Otherwise,
we search for an updated embedding such that the updated eOD holds. If such
embedding does not exist, we return false. A trivial requirement is to consider
an embedding such that the number of ignored tuples is minimized. We show that
it is NP-complete to compute such embedding. We therefore propose an efficient
heuristic algorithm for validating embedded ODs. We conduct experiments on
real-world datasets, and the results confirm the efficiency of our algorithm.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16034" title="Abstract">arXiv:2312.16034</a> [<a href="/pdf/2312.16034" title="Download PDF">pdf</a>, <a href="/format/2312.16034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Ranking Mechanisms for the m-Capacitated Facility Location  Problem in Bayesian Mechanism Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auricchio%2C+G">Gennaro Auricchio</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxiao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In this paper, we initiate the study of the $m$-Capacitated Facility Location
Problem ($m$-CFLP) within a Bayesian Mechanism Design framework. We consider
the case in which every agent's private information is their position on a line
and assume that every agent's position is independently drawn from a common and
known distribution $\mu$. In this context, we propose the Extended Ranking
Mechanisms (ERMs), a truthful generalization of the recently introduced Ranking
Mechanisms, that allows to handle problems where the total facility capacity
exceeds the number of agents. Our primary results pertain to the study of the
efficiency guarantees of the ERMs. In particular, we demonstrate that the limit
of the ratio between the expected Social Cost of an ERM and the expected
optimal Social Cost is finite. En route to these results, we reveal that the
optimal Social Cost and the Social Cost of any ERMs can be expressed as the
objective value of a suitable norm minimization problem in the Wasserstein
space. We then tackle the problem of determining an optimal ERM tailored to a
$m$-CFLP and a distribution $\mu$. Specifically, we aim to identify an ERM
whose limit Bayesian approximation ratio is the lowest compared to all other
ERMs. We detail how to retrieve an optimal ERM in two frameworks: (i) when the
total facility capacity matches the number of agents and (ii) when $\mu$ is the
uniform distribution and we have two facilities to place. Lastly, we conduct
extensive numerical experiments to compare the performance of the ERMs against
other truthful mechanisms and to evaluate the convergence speed of the Bayesian
approximation ratio. In summary, all our findings highlight that a well-tuned
ERM consistently outperforms all other known mechanisms, making it a valid
choice for solving the $m$-CFLP within a Bayesian framework.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16036" title="Abstract">arXiv:2312.16036</a> [<a href="/pdf/2312.16036" title="Download PDF">pdf</a>, <a href="/format/2312.16036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Learning to Assess Dynamics of Affective Experience Ratings and  Physiological Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dollack%2C+F">Felix Dollack</a>, 
<a href="/search/cs?searchtype=author&query=Kiyokawa%2C+K">Kiyoshi Kiyokawa</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huakun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Perusquia-Hernandez%2C+M">Monica Perusquia-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+C">Chirag Raman</a>, 
<a href="/search/cs?searchtype=author&query=Uchiyama%2C+H">Hideaki Uchiyama</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xin Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript is to be published in the 2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The congruence between affective experiences and physiological changes has
been a debated topic for centuries. Recent technological advances in
measurement and data analysis provide hope to solve this epic challenge. Open
science and open data practices, together with data analysis challenges open to
the academic community, are also promising tools for solving this problem. In
this entry to the Emotion Physiology and Experience Collaboration (EPiC)
challenge, we propose a data analysis solution that combines theoretical
assumptions with data-driven methodologies. We used feature engineering and
ensemble selection. Each predictor was trained on subsets of the training data
that would maximize the information available for training. Late fusion was
used with an averaging step. We chose to average considering a ``wisdom of
crowds'' strategy. This strategy yielded an overall RMSE of 1.19 in the test
set. Future work should carefully explore if our assumptions are correct and
the potential of weighted fusion.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16037" title="Abstract">arXiv:2312.16037</a> [<a href="/pdf/2312.16037" title="Download PDF">pdf</a>, <a href="/format/2312.16037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical nonlinear aspects of hopping transport for reconfigurable logic  in disordered dopant networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tertilt%2C+H">Henri Tertilt</a>, 
<a href="/search/cs?searchtype=author&query=Mensing%2C+J">Jonas Mensing</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+M">Marlon Becker</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wiel%2C+W+G">Wilfred G. van der Wiel</a>, 
<a href="/search/cs?searchtype=author&query=Bobbert%2C+P+A">Peter A. Bobbert</a>, 
<a href="/search/cs?searchtype=author&query=Heuer%2C+A">Andreas Heuer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Methodology (stat.ME)

</div>
<p class="mathjax">Nonlinear behavior in the hopping transport of interacting charges enables
reconfigurable logic in disordered dopant network devices, where voltages
applied at control electrodes tune the relation between voltages applied at
input electrodes and the current measured at an output electrode. From kinetic
Monte Carlo simulations we analyze the critical nonlinear aspects of
variable-range hopping transport for realizing Boolean logic gates in these
devices on three levels. First, we quantify the occurrence of individual gates
for random choices of control voltages. We find that linearly inseparable gates
such as the XOR gate are less likely to occur than linearly separable gates
such as the AND gate, despite the fact that the number of different regions in
the multidimensional control voltage space for which AND or XOR gates occur is
comparable. Second, we use principal component analysis to characterize the
distribution of the output current vectors for the (00,10,01,11) logic input
combinations in terms of eigenvectors and eigenvalues of the output covariance
matrix. This allows a simple and direct comparison of the behavior of different
simulated devices and a comparison to experimental devices. Third, we quantify
the nonlinearity in the distribution of the output current vectors necessary
for realizing Boolean functionality by introducing three nonlinearity
indicators. The analysis provides a physical interpretation of the effects of
changing the hopping distance and temperature and is used in a comparison with
data generated by a deep neural network trained on a physical device.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16039" title="Abstract">arXiv:2312.16039</a> [<a href="/pdf/2312.16039" title="Download PDF">pdf</a>, <a href="/format/2312.16039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-scale Enhanced and Cross-generative Consistency Learning for  Semi-supervised Polyp Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yunqi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kelei He</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic polyp segmentation plays a crucial role in the early diagnosis and
treatment of colorectal cancer (CRC). However, existing methods heavily rely on
fully supervised training, which requires a large amount of labeled data with
time-consuming pixel-wise annotations. Moreover, accurately segmenting polyps
poses challenges due to variations in shape, size, and location. To address
these issues, we propose a novel Dual-scale Enhanced and Cross-generative
consistency learning framework for semi-supervised polyp Segmentation (DEC-Seg)
from colonoscopy images. First, we propose a Cross-level Feature Aggregation
(CFA) module that integrates cross-level adjacent layers to enhance the feature
representation ability across different resolutions. To address scale
variation, we present a scale-enhanced consistency constraint, which ensures
consistency in the segmentation maps generated from the same input image at
different scales. This constraint helps handle variations in polyp sizes and
improves the robustness of the model. Additionally, we design a scale-aware
perturbation consistency scheme to enhance the robustness of the mean teacher
model. Furthermore, we propose a cross-generative consistency scheme, in which
the original and perturbed images can be reconstructed using cross-segmentation
maps. This consistency constraint allows us to mine effective feature
representations and boost the segmentation performance. To produce more
accurate segmentation maps, we propose a Dual-scale Complementary Fusion (DCF)
module that integrates features from two scale-specific decoders operating at
different scales. Extensive experimental results on five benchmark datasets
demonstrate the effectiveness of our DEC-Seg against other state-of-the-art
semi-supervised segmentation approaches. The implementation code will be
released at https://github.com/taozh2017/DECSeg.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16040" title="Abstract">arXiv:2312.16040</a> [<a href="/pdf/2312.16040" title="Download PDF">pdf</a>, <a href="/format/2312.16040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Progressive Feature Embedding for Accurate NIR-to-RGB  Spectral Domain Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xingxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zaifeng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE VCIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">NIR-to-RGB spectral domain translation is a challenging task due to the
mapping ambiguities, and existing methods show limited learning capacities. To
address these challenges, we propose to colorize NIR images via a multi-scale
progressive feature embedding network (MPFNet), with the guidance of grayscale
image colorization. Specifically, we first introduce a domain translation
module that translates NIR source images into the grayscale target domain. By
incorporating a progressive training strategy, the statistical and semantic
knowledge from both task domains are efficiently aligned with a series of
pixel- and feature-level consistency constraints. Besides, a multi-scale
progressive feature embedding network is designed to improve learning
capabilities. Experiments show that our MPFNet outperforms state-of-the-art
counterparts by 2.55 dB in the NIR-to-RGB spectral domain translation task in
terms of PSNR.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16043" title="Abstract">arXiv:2312.16043</a> [<a href="/pdf/2312.16043" title="Download PDF">pdf</a>, <a href="/format/2312.16043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced  linear classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+H">Hyenkyun Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">This article presents a new polynomial parameterized sigmoid called SIGTRON,
which is an extended asymmetric sigmoid with Perceptron, and its companion
convex model called SIGTRON-imbalanced classification (SIC) model that employs
a virtual SIGTRON-induced convex loss function. In contrast to the conventional
$\pi$-weighted cost-sensitive learning model, the SIC model does not have an
external $\pi$-weight on the loss function but has internal parameters in the
virtual SIGTRON-induced loss function. As a consequence, when the given
training dataset is close to the well-balanced condition, we show that the
proposed SIC model is more adaptive to variations of the dataset, such as the
inconsistency of the scale-class-imbalance ratio between the training and test
datasets. This adaptation is achieved by creating a skewed hyperplane equation.
Additionally, we present a quasi-Newton optimization(L-BFGS) framework for the
virtual convex loss by developing an interval-based bisection line search.
Empirically, we have observed that the proposed approach outperforms
$\pi$-weighted convex focal loss and balanced classifier LIBLINEAR(logistic
regression, SVM, and L2SVM) in terms of test classification accuracy with $51$
two-class and $67$ multi-class datasets. In binary classification problems,
where the scale-class-imbalance ratio of the training dataset is not
significant but the inconsistency exists, a group of SIC models with the best
test accuracy for each dataset (TOP$1$) outperforms LIBSVM(C-SVC with RBF
kernel), a well-known kernel-based classifier.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16044" title="Abstract">arXiv:2312.16044</a> [<a href="/pdf/2312.16044" title="Download PDF">pdf</a>, <a href="/format/2312.16044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Traffic Signal Control Agents: Capacity and  Opportunity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+S">Siqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Traffic signal control is crucial for optimizing the efficiency of road
network by regulating traffic light phases. Existing research predominantly
focuses on heuristic or reinforcement learning (RL)-based methods, which often
lack transferability across diverse traffic scenarios and suffer from poor
interpretability. This paper introduces a novel approach, LLMLight, utilizing
large language models (LLMs) for traffic signal control tasks. By leveraging
LLMs' impressive generalization and zero-shot reasoning capabilities, LLMLight
executes a human-like decision-making process for efficient traffic management.
Specifically, the framework begins by composing task descriptions, current
traffic conditions, and prior knowledge into a prompt. Subsequently, we utilize
LLM's chain-of-thought (CoT) reasoning ability to identify the next traffic
signal phase, ensuring optimal efficiency in the road network. LLMLight
achieves state-of-the-art (SOTA) or competitive results across five real-world
traffic datasets. Notably, LLMLight showcases remarkable generalization,
interpretability, and zero-shot reasoning abilities, even without any training
for transportation management tasks. Our project is available at
https://github.com/usail-hkust/LLMTSCS.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16045" title="Abstract">arXiv:2312.16045</a> [<a href="/pdf/2312.16045" title="Download PDF">pdf</a>, <a href="/format/2312.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Positional Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kogkalidis%2C+K">Konstantinos Kogkalidis</a>, 
<a href="/search/cs?searchtype=author&query=Bernardy%2C+J">Jean-Philippe Bernardy</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+V">Vikas Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce a novel positional encoding strategy for Transformer-style
models, addressing the shortcomings of existing, often ad hoc, approaches. Our
framework provides a flexible mapping from the algebraic specification of a
domain to an interpretation as orthogonal operators. This design preserves the
algebraic characteristics of the source domain, ensuring that the model upholds
the desired structural properties. Our scheme can accommodate various
structures, including sequences, grids and trees, as well as their
compositions. We conduct a series of experiments to demonstrate the practical
applicability of our approach. Results suggest performance on par with or
surpassing the current state-of-the-art, without hyperparameter optimizations
or ``task search'' of any kind. Code will be made available at
\url{github.com/konstantinosKokos/UnitaryPE}.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16046" title="Abstract">arXiv:2312.16046</a> [<a href="/pdf/2312.16046" title="Download PDF">pdf</a>, <a href="/format/2312.16046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaNAS: Adaptively Post-processing with Self-supervised Neural  Architecture Search for Ensemble Rainfall Forecasts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yingpeng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Fudan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+N">Nong Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Previous post-processing studies on rainfall forecasts using numerical
weather prediction (NWP) mainly focus on statistics-based aspects, while
learning-based aspects are rarely investigated. Although some manually-designed
models are proposed to raise accuracy, they are customized networks, which need
to be repeatedly tried and verified, at a huge cost in time and labor.
Therefore, a self-supervised neural architecture search (NAS) method without
significant manual efforts called AdaNAS is proposed in this study to perform
rainfall forecast post-processing and predict rainfall with high accuracy. In
addition, we design a rainfall-aware search space to significantly improve
forecasts for high-rainfall areas. Furthermore, we propose a rainfall-level
regularization function to eliminate the effect of noise data during the
training. Validation experiments have been performed under the cases of
\emph{None}, \emph{Light}, \emph{Moderate}, \emph{Heavy} and \emph{Violent} on
a large-scale precipitation benchmark named TIGGE. Finally, the average
mean-absolute error (MAE) and average root-mean-square error (RMSE) of the
proposed AdaNAS model are 0.98 and 2.04 mm/day, respectively. Additionally, the
proposed AdaNAS model is compared with other neural architecture search methods
and previous studies. Compared results reveal the satisfactory performance and
superiority of the proposed AdaNAS model in terms of precipitation amount
prediction and intensity classification. Concretely, the proposed AdaNAS model
outperformed previous best-performing manual methods with MAE and RMSE
improving by 80.5\% and 80.3\%, respectively.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16047" title="Abstract">arXiv:2312.16047</a> [<a href="/pdf/2312.16047" title="Download PDF">pdf</a>, <a href="/format/2312.16047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D-Guided 3D Gaussian Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+K">Kun Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haolin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D Gaussian, as an explicit 3D representation method, has
demonstrated strong competitiveness over NeRF (Neural Radiance Fields) in terms
of expressing complex scenes and training duration. These advantages signal a
wide range of applications for 3D Gaussians in 3D understanding and editing.
Meanwhile, the segmentation of 3D Gaussians is still in its infancy. The
existing segmentation methods are not only cumbersome but also incapable of
segmenting multiple objects simultaneously in a short amount of time. In
response, this paper introduces a 3D Gaussian segmentation method implemented
with 2D segmentation as supervision. This approach uses input 2D segmentation
maps to guide the learning of the added 3D Gaussian semantic information, while
nearest neighbor clustering and statistical filtering refine the segmentation
results. Experiments show that our concise method can achieve comparable
performances on mIOU and mAcc for multi-object segmentation as previous
single-object segmentation methods.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16048" title="Abstract">arXiv:2312.16048</a> [<a href="/pdf/2312.16048" title="Download PDF">pdf</a>, <a href="/format/2312.16048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sliding Mode Control for 3-D Uncalibrated and Constrained Vision-based  Shape Servoing within Input Saturation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangqing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper designs a servo control system based on sliding mode control for
the shape control of elastic objects. In order to solve the effect of
non-smooth and asymmetric control saturation, a Gaussian-based continuous
differentiable asymmetric saturation function is used for this goal. The
proposed detection approach runs in a highly real-time manner. Meanwhile, this
paper uses sliding mode control to prove that the estimation stability of the
deformation Jacobian matrix and the system stability of the controller are
combined, which verifies the control stability of the closed-loop system
including estimation. Besides, an integral sliding mode function is designed to
avoid the need for second-order derivatives of variables, which enhances the
robustness of the system in actual situations. Finally, the Lyapunov theory is
used to prove the consistent final boundedness of all variables of the system.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16051" title="Abstract">arXiv:2312.16051</a> [<a href="/pdf/2312.16051" title="Download PDF">pdf</a>, <a href="/format/2312.16051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inter-X: Towards Versatile Human-Human Interaction Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xintao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Congsheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yizhou Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+F">Fengyun Rao</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+X">Xingdong Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://liangxuy.github.io/inter-x/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The analysis of the ubiquitous human-human interactions is pivotal for
understanding humans as social beings. Existing human-human interaction
datasets typically suffer from inaccurate body motions, lack of hand gestures
and fine-grained textual descriptions. To better perceive and generate
human-human interactions, we propose Inter-X, a currently largest human-human
interaction dataset with accurate body movements and diverse interaction
patterns, together with detailed hand gestures. The dataset includes ~11K
interaction sequences and more than 8.1M frames. We also equip Inter-X with
versatile annotations of more than 34K fine-grained human part-level textual
descriptions, semantic interaction categories, interaction order, and the
relationship and personality of the subjects. Based on the elaborate
annotations, we propose a unified benchmark composed of 4 categories of
downstream tasks from both the perceptual and generative directions. Extensive
experiments and comprehensive analysis show that Inter-X serves as a testbed
for promoting the development of versatile human-human interaction analysis.
Our dataset and benchmark will be publicly available for research purposes.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16054" title="Abstract">arXiv:2312.16054</a> [<a href="/pdf/2312.16054" title="Download PDF">pdf</a>, <a href="/format/2312.16054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Logically Consistent Chain-of-Thought Approach for Stance Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+D">Daijun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liwen Jing</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Zero-shot stance detection (ZSSD) aims to detect stances toward unseen
targets. Incorporating background knowledge to enhance transferability between
seen and unseen targets constitutes the primary approach of ZSSD. However,
these methods often struggle with a knowledge-task disconnect and lack logical
consistency in their predictions. To address these issues, we introduce a novel
approach named Logically Consistent Chain-of-Thought (LC-CoT) for ZSSD, which
improves stance detection by ensuring relevant and logically sound knowledge
extraction. LC-CoT employs a three-step process. Initially, it assesses whether
supplementary external knowledge is necessary. Subsequently, it uses API calls
to retrieve this knowledge, which can be processed by a separate LLM. Finally,
a manual exemplar guides the LLM to infer stance categories, using an if-then
logical structure to maintain relevance and logical coherence. This structured
approach to eliciting background knowledge enhances the model's capability,
outperforming traditional supervised methods without relying on labeled data.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16057" title="Abstract">arXiv:2312.16057</a> [<a href="/pdf/2312.16057" title="Download PDF">pdf</a>, <a href="/format/2312.16057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Importance-Aware Based for Multi-User Communication Over MIMO  Fading Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Haotai Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhicheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+W">Wannian An</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaodong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Semantic communication, as a novel communication paradigm, has attracted the
interest of many scholars, with multi-user, multi-input multi-output (MIMO)
scenarios being one of the critical contexts. This paper presents a semantic
importance-aware based communication system (SIA-SC) over MIMO Rayleigh fading
channels. Combining the semantic symbols' inequality and the equivalent
subchannels of MIMO channels based on Singular Value Decomposition (SVD)
maximizes the end-to-end semantic performance through the new layer mapping
method. For multi-user scenarios, a method of semantic interference
cancellation is proposed. Furthermore, a new metric, namely semantic
information distortion (SID), is established to unify the expressions of
semantic performance, which is affected by channel bandwidth ratio (CBR) and
signal-to-noise ratio (SNR). With the help of the proposed metric, we derived
performance expressions and Semantic Outage Probability (SOP) of SIA-SC for
Single-User Single-Input Single-Output (SU-SISO), Single-User MIMO (SU-MIMO),
Multi-Users SISO (MU-MIMO) and Multi-Users MIMO (MU-MIMO) scenarios. Numerical
experiments show that SIA-SC can significantly improve semantic performance
across various scenarios.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16060" title="Abstract">arXiv:2312.16060</a> [<a href="/pdf/2312.16060" title="Download PDF">pdf</a>, <a href="/ps/2312.16060" title="Download PostScript">ps</a>, <a href="/format/2312.16060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error-free Training for Artificial Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Bo Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, Matlab mfiles available for online download
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Conventional training methods for artificial neural network (ANN) models
never achieve zero error rate systematically for large data. A new training
method consists of three steps: first create an auxiliary data from
conventionally trained parameters which correspond exactly to a global minimum
for the loss function of the cloned data; second create a one-parameter
homotopy (hybrid) of the auxiliary data and the original data; and third train
the model for the hybrid data iteratively from the auxiliary data end of the
homotopy parameter to the original data end while maintaining the zero-error
training rate at every iteration. This continuationmethod is guaranteed to
converge numerically by a theorem which converts the ANN training problem into
a continuation problem for fixed points of a parameterized transformation in
the training parameter space to which the Uniform Contraction Mapping Theorem
from dynamical systems applies.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16061" title="Abstract">arXiv:2312.16061</a> [<a href="/pdf/2312.16061" title="Download PDF">pdf</a>, <a href="/format/2312.16061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Oriented Communication, Estimation, and Control over Bidirectional  Wireless Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+J">Jie Cao</a>, 
<a href="/search/eess?searchtype=author&query=Kurniawan%2C+E">Ernest Kurniawan</a>, 
<a href="/search/eess?searchtype=author&query=Amnart%2C+B">Boonkajay Amnart</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+S">Sumei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider a wireless networked control system (WNCS) with bidirectional
imperfect links for real-time applications such as smart grids. To maintain the
stability of WNCS, captured by the probability that plant state violates preset
values, at minimal cost, heterogeneous physical processes are monitored by
multiple sensors. This status information, such as dynamic plant state and
Markov Process-based context information, is then received/estimated by the
controller for remote control. However, scheduling multiple sensors and
designing the controller with limited resources is challenging due to their
coupling, delay, and transmission loss. We formulate a Constrained Markov
Decision Problem (CMDP) to minimize violation probability with cost
constraints. We reveal the relationship between the goal and different updating
actions by analyzing the significance of information that incorporates
goal-related usefulness and contextual importance. Subsequently, a
goal-oriented deterministic scheduling policy is proposed. Two sensing-assisted
control strategies and a control-aware estimation policy are proposed to
improve the violation probability-cost tradeoff, integrated with the scheduling
policy to form a goal-oriented co-design framework. Additionally, we explore
retransmission in downlink transmission and qualitatively analyze its
preference scenario. Simulation results demonstrate that the proposed
goal-oriented co-design policy outperforms previous work in simultaneously
reducing violation probability and cost
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16062" title="Abstract">arXiv:2312.16062</a> [<a href="/pdf/2312.16062" title="Download PDF">pdf</a>, <a href="/format/2312.16062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoTask: Executing Arbitrary Voice Commands by Exploring and Learning  from Mobile GUI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Lihang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Voice command interfaces (VCIs) have gained increasing importance, enabling
hands-free and eyes-free interaction with digital devices. However, the
inherent complexity in constructing effective voice interfaces has limited the
VCIs' functionalities to only a small fraction of GUI applications and tasks.
This paper presents AutoTask, a VCI capable of automating any task in any
mobile application without configuration or modification from developers or end
users. The primary challenge for AutoTask is the lack of knowledge, as it needs
to accomplish unknown tasks (e.g., user commands) within an unknown environment
(e.g., GUI). To address this challenge, AutoTask employs two strategies: (1)
trial and error: AutoTask explores the GUI, attempts potential operation
sequences, and recovers from errors through backtracking; (2) learning from the
environment: AutoTask accumulates experiences during exploration and summarizes
correct knowledge from these experiences. We implemented AutoTask on Android
devices and conducted an evaluation study, which proved the feasibility of
AutoTask.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16064" title="Abstract">arXiv:2312.16064</a> [<a href="/pdf/2312.16064" title="Download PDF">pdf</a>, <a href="/format/2312.16064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Oriented Integration of Sensing, Communication, Computing, and  Control for Mission-Critical Internet-of-Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kurniawan%2C+E">Ernest Kurniawan</a>, 
<a href="/search/cs?searchtype=author&query=Boonkajay%2C+A">Amnart Boonkajay</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sumei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Driven by the development goal of network paradigm and demand for various
functions in the sixth-generation (6G) mission-critical Internet-of-Things
(MC-IoT), we foresee a goal-oriented integration of sensing, communication,
computing, and control (GIS3C) in this paper. We first provide an overview of
the tasks, requirements, and challenges of MC-IoT. Then we introduce an
end-to-end GIS3C architecture, in which goal-oriented communication is
leveraged to bridge and empower sensing, communication, control, and computing
functionalities. By revealing the interplay among multiple subsystems in terms
of key performance indicators and parameters, this paper introduces unified
metrics, i.e., task completion effectiveness and cost, to facilitate S3C
co-design in MC-IoT. The preliminary results demonstrate the benefits of GIS3C
in improving task completion effectiveness while reducing costs. We also
identify and highlight the gaps and challenges in applying GIS3C in the future
6G networks.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16066" title="Abstract">arXiv:2312.16066</a> [<a href="/pdf/2312.16066" title="Download PDF">pdf</a>, <a href="/format/2312.16066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Prompt Learning Framework for Source Code Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yudu You</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hanwei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ACM Transactions on Software Engineering and Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">(Source) code summarization is the task of automatically generating natural
language summaries for given code snippets. Such summaries play a key role in
helping developers understand and maintain source code. Recently, with the
successful application of large language models (LLMs) in numerous fields,
software engineering researchers have also attempted to adapt LLMs to solve
code summarization tasks. The main adaptation schemes include instruction
prompting and task-oriented fine-tuning. However, instruction prompting
involves designing crafted prompts for zero-shot learning or selecting
appropriate samples for few-shot learning and requires users to have
professional domain knowledge, while task-oriented fine-tuning requires high
training costs. In this paper, we propose a novel prompt learning framework for
code summarization called PromptCS. PromptCS trains a prompt agent that can
generate continuous prompts to unleash the potential for LLMs in code
summarization. Compared to the human-written discrete prompt, the continuous
prompts are produced under the guidance of LLMs and are therefore easier to
understand by LLMs. PromptCS freezes the parameters of LLMs when training the
prompt agent, which can greatly reduce the requirements for training resources.
We evaluate PromptCS on the CodeSearchNet dataset involving multiple
programming languages. The results show that PromptCS significantly outperforms
instruction prompting schemes on all four widely used metrics. In some base
LLMs, e.g., CodeGen-Multi-2B and StarCoderBase-1B and -3B, PromptCS even
outperforms the task-oriented fine-tuning scheme. More importantly, the
training efficiency of PromptCS is faster than the task-oriented fine-tuning
scheme, with a more pronounced advantage on larger LLMs. The results of the
human evaluation demonstrate that PromptCS can generate more good summaries
compared to baselines.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16070" title="Abstract">arXiv:2312.16070</a> [<a href="/pdf/2312.16070" title="Download PDF">pdf</a>, <a href="/format/2312.16070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT Read Who You Are?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derner%2C+E">Erik Derner</a>, 
<a href="/search/cs?searchtype=author&query=Ku%C4%8Dera%2C+D">Dalibor Ku&#x10d;era</a>, 
<a href="/search/cs?searchtype=author&query=Oliver%2C+N">Nuria Oliver</a>, 
<a href="/search/cs?searchtype=author&query=Zah%C3%A1lka%2C+J">Jan Zah&#xe1;lka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The interplay between artificial intelligence (AI) and psychology,
particularly in personality assessment, represents an important emerging area
of research. Accurate personality trait estimation is crucial not only for
enhancing personalization in human-computer interaction but also for a wide
variety of applications ranging from mental health to education. This paper
analyzes the capability of a generic chatbot, ChatGPT, to effectively infer
personality traits from short texts. We report the results of a comprehensive
user study featuring texts written in Czech by a representative population
sample of 155 participants. Their self-assessments based on the Big Five
Inventory (BFI) questionnaire serve as the ground truth. We compare the
personality trait estimations made by ChatGPT against those by human raters and
report ChatGPT's competitive performance in inferring personality traits from
text. We also uncover a 'positivity bias' in ChatGPT's assessments across all
personality dimensions and explore the impact of prompt composition on
accuracy. This work contributes to the understanding of AI capabilities in
psychological assessment, highlighting both the potential and limitations of
using large language models for personality inference. Our research underscores
the importance of responsible AI development, considering ethical implications
such as privacy, consent, autonomy, and bias in AI applications.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16071" title="Abstract">arXiv:2312.16071</a> [<a href="/pdf/2312.16071" title="Download PDF">pdf</a>, <a href="/format/2312.16071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-based Shape from Polarization with Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+P">Peng Kang</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Srutarshi Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Chopp%2C+H">Henry Chopp</a>, 
<a href="/search/cs?searchtype=author&query=Katsaggelos%2C+A">Aggelos Katsaggelos</a>, 
<a href="/search/cs?searchtype=author&query=Cossairt%2C+O">Oliver Cossairt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in event-based shape determination from polarization offer a
transformative approach that tackles the trade-off between speed and accuracy
in capturing surface geometries. In this paper, we investigate event-based
shape from polarization using Spiking Neural Networks (SNNs), introducing the
Single-Timestep and Multi-Timestep Spiking UNets for effective and efficient
surface normal estimation. Specificially, the Single-Timestep model processes
event-based shape as a non-temporal task, updating the membrane potential of
each spiking neuron only once, thereby reducing computational and energy
demands. In contrast, the Multi-Timestep model exploits temporal dynamics for
enhanced data extraction. Extensive evaluations on synthetic and real-world
datasets demonstrate that our models match the performance of state-of-the-art
Artifical Neural Networks (ANNs) in estimating surface normals, with the added
advantage of superior energy efficiency. Our work not only contributes to the
advancement of SNNs in event-based sensing but also sets the stage for future
explorations in optimizing SNN architectures, integrating multi-modal data, and
scaling for applications on neuromorphic hardware.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16079" title="Abstract">arXiv:2312.16079</a> [<a href="/pdf/2312.16079" title="Download PDF">pdf</a>, <a href="/format/2312.16079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coexistence assessment and interference mitigation for 5G and Fixed  Satellite Stations in C-band in India
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Avinash Agarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we present the findings of a study conducted to assess the
coexistence of Fifth Generation (5G) wireless networks and Fixed Satellite
Station (FSS) receivers in the C-Band (3300-4200 MHz) in India. Through
simulations, we evaluate the coexistence feasibility and calculate the minimum
separation distances required to mitigate interference, consider-ing factors
such as 5G Base Station power, off-axis angle, clutter, filtering, and
shielding. Next, we present various interference mitigation techniques,
including distance, antenna tilt and height, power control, antenna design,
coordination, filtering, and others, aiming for balanced coexistence. The
simulation results corroborate the efficacy of these solutions in containing
interference from 5G in the C-Band FSS receivers. The paper offers valuable
insights into frequency allocation in India and considerations for 5G network
design, including site selection and antenna orientation. The insights provided
are relevant to other regions facing similar coexistence challenges. Overall,
this paper offers a comprehensive overview of 5G and FSS coexistence in the
C-band, emphasising the importance of addressing this issue during network
design and deployment.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16080" title="Abstract">arXiv:2312.16080</a> [<a href="/pdf/2312.16080" title="Download PDF">pdf</a>, <a href="/format/2312.16080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fractal-based Complex Belief Entropy for Uncertainty Measure in  Complex Evidence Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Keming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fuyuan Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Complex evidence theory, as a generalized D-S evidence theory, has attracted
academic attention because it can well express uncertainty by means of complex
basic belief assignment (CBBA), and realize uncertainty reasoning by complex
combination rule. However, the uncertainty measurement in complex evidence
theory is still an open issue. In order to make better decisions, a complex
pignistic belief transformation (CPBT) method has been proposed to assign CBBAs
of multi-element focal elements to subsets. The essence of CPBT is the
redistribution of complex mass function by means of the concept of fractal. In
this paper, based on fractal theory, experimental simulation and analysis have
been carried out on the generation process of CPBT in time dimension. Then, a
new fractal-based complex belief (FCB) entropy is proposed to measure the
uncertainty of CBBA. Finally, the properties of FCB entropy are analyzed, and
several examples are used to verify its effectiveness.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16083" title="Abstract">arXiv:2312.16083</a> [<a href="/pdf/2312.16083" title="Download PDF">pdf</a>, <a href="/format/2312.16083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Latent Graph-Guided Neural Temporal Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sikun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+H">Hongyuan Zha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Continuously-observed event occurrences, often exhibit self- and
mutually-exciting effects, which can be well modeled using temporal point
processes. Beyond that, these event dynamics may also change over time, with
certain periodic trends. We propose a novel variational auto-encoder to capture
such a mixture of temporal dynamics. More specifically, the whole time interval
of the input sequence is partitioned into a set of sub-intervals. The event
dynamics are assumed to be stationary within each sub-interval, but could be
changing across those sub-intervals. In particular, we use a sequential latent
variable model to learn a dependency graph between the observed dimensions, for
each sub-interval. The model predicts the future event times, by using the
learned dependency graph to remove the noncontributing influences of past
events. By doing so, the proposed model demonstrates its higher accuracy in
predicting inter-event times and event types for several real-world event
sequences, compared with existing state of the art neural point processes.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16084" title="Abstract">arXiv:2312.16084</a> [<a href="/pdf/2312.16084" title="Download PDF">pdf</a>, <a href="/format/2312.16084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LangSplat: 3D Language Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Minghan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wanhua Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiawei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+H">Hanspeter Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://langsplat.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human lives in a 3D world and commonly uses natural language to interact with
a 3D scene. Modeling a 3D language field to support open-ended language queries
in 3D has gained increasing attention recently. This paper introduces
LangSplat, which constructs a 3D language field that enables precise and
efficient open-vocabulary querying within 3D spaces. Unlike existing methods
that ground CLIP language embeddings in a NeRF model, LangSplat advances the
field by utilizing a collection of 3D Gaussians, each encoding language
features distilled from CLIP, to represent the language field. By employing a
tile-based splatting technique for rendering language features, we circumvent
the costly rendering process inherent in NeRF. Instead of directly learning
CLIP embeddings, LangSplat first trains a scene-wise language autoencoder and
then learns language features on the scene-specific latent space, thereby
alleviating substantial memory demands imposed by explicit modeling. Existing
methods struggle with imprecise and vague 3D language fields, which fail to
discern clear boundaries between objects. We delve into this issue and propose
to learn hierarchical semantics using SAM, thereby eliminating the need for
extensively querying the language field across various scales and the
regularization of DINO features. Extensive experiments on open-vocabulary 3D
object localization and semantic segmentation demonstrate that LangSplat
significantly outperforms the previous state-of-the-art method LERF by a large
margin. Notably, LangSplat is extremely efficient, achieving a {\speed}
$\times$ speedup compared to LERF at the resolution of 1440 $\times$ 1080. We
strongly recommend readers to check out our video results at
https://langsplat.github.io
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16087" title="Abstract">arXiv:2312.16087</a> [<a href="/pdf/2312.16087" title="Download PDF">pdf</a>, <a href="/ps/2312.16087" title="Download PostScript">ps</a>, <a href="/format/2312.16087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved decoding of expander codes: fundamental trade-off between  expansion ratio and minimum distance of inner code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+M">Minghui Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+C">Chong Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yuanting Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Tanner codes are graph-based linear codes whose parity-check matrices can be
characterized by a bipartite graph $G$ together with an inner code $C_0$.
Expander codes are Tanner codes whose defining bipartite graph $G$ has good
expansion property. The landmark work of Sipser and Spielman showed that every
bipartite expander $G$ with expansion ratio $\delta&gt;3/4$ together with a
parity-check code defines an expander code which corrects $\Omega(n)$ errors in
$O(n)$ time, where $n$ is the code length. Viderman showed that
$\delta&gt;2/3-\Omega(1)$ is already sufficient. Our paper is motivated by the
following natural and fundamental problem in decoding expander codes:
<br />\textbf{Question:} What are the sufficient and necessary conditions that
$\delta$ and $d_0$ should satisfy so that {\it every} bipartite expander $G$
with expansion ratio $\delta$ and {\it every} inner code $C_0$ with minimum
distance $d_0$ together define an expander code which corrects $\Omega(n)$
errors in $O(n)$ time?
<br />We give a near-optimal solution to the question above, showing that $\delta
d_0&gt;3$ is sufficient and $\delta d_0&gt;1$ is necessary. Our result significantly
improves the previously known result of Dowling and Gao, who showed that
$d_0=\Omega(c\delta^{-2})$ is sufficient, where $c$ is the left-degree of $G$.
We suspect that $\delta d_0&gt;1$ is also sufficient to solve the question above.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16098" title="Abstract">arXiv:2312.16098</a> [<a href="/pdf/2312.16098" title="Download PDF">pdf</a>, <a href="/format/2312.16098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with  Seq2seq Encoder-Decoder Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamber%2C+M+S">Manveer Singh Tamber</a>, 
<a href="/search/cs?searchtype=author&query=Pradeep%2C+R">Ronak Pradeep</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recent work in zero-shot listwise reranking using LLMs has achieved
state-of-the-art results. However, these methods are not without drawbacks. The
proposed methods rely on large LLMs with billions of parameters and limited
context sizes. This paper introduces LiT5-Distill and LiT5-Score, two methods
for efficient zero-shot listwise reranking, leveraging T5 sequence-to-sequence
encoder-decoder models. Our approaches demonstrate competitive reranking
effectiveness compared to recent state-of-the-art LLM rerankers with
substantially smaller models. Through LiT5-Score, we also explore the use of
cross-attention to calculate relevance scores to perform reranking, eliminating
the reliance on external passage relevance labels for training. We present a
range of models from 220M parameters to 3B parameters, all with strong
reranking results, challenging the necessity of large-scale models for
effective zero-shot reranking and opening avenues for more efficient listwise
reranking solutions. We provide code and scripts to reproduce our results at
https://github.com/castorini/LiT5.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16104" title="Abstract">arXiv:2312.16104</a> [<a href="/pdf/2312.16104" title="Download PDF">pdf</a>, <a href="/format/2312.16104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dotless Representation of Arabic Text: Analysis and Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Shaibani%2C+M+S">Maged S. Al-Shaibani</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I">Irfan Ahmad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel dotless representation of Arabic text as an
alternative to the standard Arabic text representation. We delve into its
implications through comprehensive analysis across five diverse corpora and
four different tokenization techniques. We explore the impact of dotless
representation on the relationships between tokenization granularity and
vocabulary size and compare them with standard text representation. Moreover,
we analyze the information density of dotless versus standard text using text
entropy calculations. To delve deeper into the implications of the dotless
representation, statistical and neural language models are constructed using
the various text corpora and tokenization techniques. A comparative assessment
is then made against language models developed using the standard Arabic text
representation. This multifaceted analysis provides valuable insights into the
potential advantages and challenges associated with the dotless representation.
Last but not the least, utilizing parallel corpora, we draw comparisons between
the text analysis of Arabic and English to gain further insights. Our findings
shed light on the potential benefits of dotless representation for various NLP
tasks, paving the way for further exploration for Arabic natural language
processing.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16106" title="Abstract">arXiv:2312.16106</a> [<a href="/pdf/2312.16106" title="Download PDF">pdf</a>, <a href="/format/2312.16106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clique Analysis and Bypassing in Continuous-Time Conflict-Based Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+T+T">Thayne T. Walker</a>, 
<a href="/search/cs?searchtype=author&query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
<a href="/search/cs?searchtype=author&query=Felner%2C+A">Ariel Felner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">While the study of unit-cost Multi-Agent Pathfinding (MAPF) problems has been
popular, many real-world problems require continuous time and costs due to
various movement models. In this context, this paper studies symmetry-breaking
enhancements for Continuous-Time Conflict-Based Search (CCBS), a solver for
continuous-time MAPF. Resolving conflict symmetries in MAPF can require an
exponential amount of work. We adapt known enhancements from unit-cost domains
for CCBS: bypassing, which resolves cost symmetries and biclique constraints
which resolve spatial conflict symmetries. We formulate a novel combination of
biclique constraints with disjoint splitting for spatial conflict symmetries.
Finally, we show empirically that these enhancements yield a statistically
significant performance improvement versus previous state of the art, solving
problems for up to 10% or 20% more agents in the same amount of time on dense
graphs.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16108" title="Abstract">arXiv:2312.16108</a> [<a href="/pdf/2312.16108" title="Download PDF">pdf</a>, <a href="/format/2312.16108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaneSegNet: Map Learning with Lane Segment Perception for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Peijin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bangjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A map, as crucial information for downstream applications of an autonomous
driving system, is usually represented in lanelines or centerlines. However,
existing literature on map learning primarily focuses on either detecting
geometry-based lanelines or perceiving topology relationships of centerlines.
Both of these methods ignore the intrinsic relationship of lanelines and
centerlines, that lanelines bind centerlines. While simply predicting both
types of lane in one model is mutually excluded in learning objective, we
advocate lane segment as a new representation that seamlessly incorporates both
geometry and topology information. Thus, we introduce LaneSegNet, the first
end-to-end mapping network generating lane segments to obtain a complete
representation of the road structure. Our algorithm features two key
modifications. One is a lane attention module to capture pivotal region details
within the long-range feature space. Another is an identical initialization
strategy for reference points, which enhances the learning of positional priors
for lane attention. On the OpenLane-V2 dataset, LaneSegNet outperforms previous
counterparts by a substantial gain across three tasks, \textit{i.e.}, map
element detection (+4.8 mAP), centerline perception (+6.9 DET$_l$), and the
newly defined one, lane segment perception (+5.6 mAP). Furthermore, it obtains
a real-time inference speed of 14.7 FPS. Code is accessible at
https://github.com/OpenDriveLab/LaneSegNet.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16109" title="Abstract">arXiv:2312.16109</a> [<a href="/pdf/2312.16109" title="Download PDF">pdf</a>, <a href="/format/2312.16109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> fMPI: Fast Novel View Synthesis in the Wild with Layered Scene  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohler%2C+J">Jonas Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+N+G">Nicolas Griffiths Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Cavalli%2C+L">Luca Cavalli</a>, 
<a href="/search/cs?searchtype=author&query=Herold%2C+C">Catherine Herold</a>, 
<a href="/search/cs?searchtype=author&query=Pumarola%2C+A">Albert Pumarola</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A+G">Alberto Garcia Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Thabet%2C+A">Ali Thabet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we propose two novel input processing paradigms for novel view
synthesis (NVS) methods based on layered scene representations that
significantly improve their runtime without compromising quality. Our approach
identifies and mitigates the two most time-consuming aspects of traditional
pipelines: building and processing the so-called plane sweep volume (PSV),
which is a high-dimensional tensor of planar re-projections of the input camera
views. In particular, we propose processing this tensor in parallel groups for
improved compute efficiency as well as super-sampling adjacent input planes to
generate denser, and hence more accurate scene representation. The proposed
enhancements offer significant flexibility, allowing for a balance between
performance and speed, thus making substantial steps toward real-time
applications. Furthermore, they are very general in the sense that any
PSV-based method can make use of them, including methods that employ multiplane
images, multisphere images, and layered depth images. In a comprehensive set of
experiments, we demonstrate that our proposed paradigms enable the design of an
NVS method that achieves state-of-the-art on public benchmarks while being up
to $50x$ faster than existing state-of-the-art methods. It also beats the
current forerunner in terms of speed by over $3x$, while achieving
significantly better rendering quality.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16113" title="Abstract">arXiv:2312.16113</a> [<a href="/pdf/2312.16113" title="Download PDF">pdf</a>, <a href="/format/2312.16113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Driven Causal Feature Distillation: Towards Trustworthy Risk  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengxuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2024 AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since artificial intelligence has seen tremendous recent successes in many
areas, it has sparked great interest in its potential for trustworthy and
interpretable risk prediction. However, most models lack causal reasoning and
struggle with class imbalance, leading to poor precision and recall. To address
this, we propose a Task-Driven Causal Feature Distillation model (TDCFD) to
transform original feature values into causal feature attributions for the
specific risk prediction task. The causal feature attribution helps describe
how much contribution the value of this feature can make to the risk prediction
result. After the causal feature distillation, a deep neural network is applied
to produce trustworthy prediction results with causal interpretability and high
precision/recall. We evaluate the performance of our TDCFD method on several
synthetic and real datasets, and the results demonstrate its superiority over
the state-of-the-art methods regarding precision, recall, interpretability, and
causality.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16116" title="Abstract">arXiv:2312.16116</a> [<a href="/pdf/2312.16116" title="Download PDF">pdf</a>, <a href="/format/2312.16116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the best convergence rate of lightning plus polynomial approximation  for $x^&#x3b1;$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiang%2C+S">Shuhuang Xiang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shunfeng Yang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yanghao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21pages, 5figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Trefethen and his collaborators in \cite{Herremans2023} built further on a
lightning approximation with a low-degree polynomial basis based on introducing
a new choice of the tapered exponentially clustering poles. The new scheme
achieves the optimal convergence rate for approximation of $x^\alpha$ on
$[0,1]$ as by the best rational approximation shown by Stahl in 2003,
illustrated through ample delicate numerical experiments. This paper, with the
aid of Poisson summation formula, Cauchy's integral theorem and the decay
behaviors of Fourier transforms, rigorously shows that the new scheme,
utilizing tapered exponentially clustering poles, achieves a root-exponential
convergence rate in approximating $x^\alpha$, from which Conjecture 3.1 in
\cite{Herremans2023} is confirmed, and the choice of the parameter
$\sigma=\frac{2\pi}{\sqrt{\alpha}}$ achieves the fastest convergence rate among
all $\sigma&gt;0$.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16118" title="Abstract">arXiv:2312.16118</a> [<a href="/pdf/2312.16118" title="Download PDF">pdf</a>, <a href="/format/2312.16118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Hybrid Stereo Matching With Nonlinear Regularization and Spatial  Pyramids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braunstein%2C+C">Cameron Braunstein</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Ilg%2C+E">Eddy Ilg</a> (1), 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a> (2) ((1) Saarland University, SIC, (2) MPI for Informatics, SIC)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures. To be published in the International Conference on 3D Vision (3DV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Quantum visual computing is advancing rapidly. This paper presents a new
formulation for stereo matching with nonlinear regularizers and spatial
pyramids on quantum annealers as a maximum a posteriori inference problem that
minimizes the energy of a Markov Random Field. Our approach is hybrid (i.e.,
quantum-classical) and is compatible with modern D-Wave quantum annealers,
i.e., it includes a quadratic unconstrained binary optimization (QUBO)
objective. Previous quantum annealing techniques for stereo matching are
limited to using linear regularizers, and thus, they do not exploit the
fundamental advantages of the quantum computing paradigm in solving
combinatorial optimization problems. In contrast, our method utilizes the full
potential of quantum annealing for stereo matching, as nonlinear regularizers
create optimization problems which are NP-hard. On the Middlebury benchmark, we
achieve an improved root mean squared accuracy over the previous state of the
art in quantum stereo matching of 2% and 22.5% when using different solvers.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16119" title="Abstract">arXiv:2312.16119</a> [<a href="/pdf/2312.16119" title="Download PDF">pdf</a>, <a href="/format/2312.16119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A bi-objective $&#x3b5;$-constrained framework for quality-cost  optimization in language model ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Aditi Singla</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aditya Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kukreja%2C+K">Kanishk Kukreja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We propose an ensembling framework that uses diverse open-sourced Large
Language Models (LLMs) to achieve high response quality while maintaining cost
efficiency. We formulate a bi-objective optimization problem to represent the
quality-cost tradeoff and then introduce an additional budget constraint that
reduces the problem to a straightforward 0/1 knapsack problem. We empirically
demonstrate that our framework outperforms the existing ensembling approaches
in response quality while significantly reducing costs.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16124" title="Abstract">arXiv:2312.16124</a> [<a href="/pdf/2312.16124" title="Download PDF">pdf</a>, <a href="/format/2312.16124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Olfactory Label Prediction on aroma-chemical Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sisson%2C+L">Laura Sisson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The application of deep learning techniques on aroma-chemicals has resulted
in models more accurate than human experts at predicting olfactory qualities.
However, public research in this domain has been limited to predicting the
qualities of single molecules, whereas in industry applications, perfumers and
food scientists are often concerned with blends of many odorants. In this
paper, we apply both existing and novel approaches to a dataset we gathered
consisting of labeled pairs of molecules. We present a publicly available model
capable of generating accurate predictions for the non-linear qualities arising
from blends of aroma-chemicals.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16125" title="Abstract">arXiv:2312.16125</a> [<a href="/pdf/2312.16125" title="Download PDF">pdf</a>, <a href="/format/2312.16125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The linear time encoding scheme fails to encode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dikstein%2C+Y">Yotam Dikstein</a>, 
<a href="/search/cs?searchtype=author&query=Dinur%2C+I">Irit Dinur</a>, 
<a href="/search/cs?searchtype=author&query=Sivan%2C+S">Shiri Sivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We point out an error in the paper "Linear Time Encoding of LDPC Codes" (by
Jin Lu and Jos\'e M. F. Moura, IEEE Trans). The paper claims to present a
linear time encoding algorithm for every LDPC code. We present a family of
counterexamples, and point out where the analysis fails. The algorithm in the
aforementioned paper fails to encode our counterexample, let alone in linear
time.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16127" title="Abstract">arXiv:2312.16127</a> [<a href="/pdf/2312.16127" title="Download PDF">pdf</a>, <a href="/format/2312.16127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Situational Awareness Based Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liman Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hanyang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages including appendix. Website will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This work pioneers evaluating emergent planning capabilities based on
situational awareness in large language models. We contribute (i) novel
benchmarks and metrics for standardized assessment; (ii) a unique dataset to
spur progress; and (iii) demonstrations that prompting and multi-agent schemes
significantly enhance planning performance in context-sensitive planning tasks.
Positioning this within a situated agent and automated planning research, we
highlight inherent reliability challenges--efficiently mapping world states to
actions without environmental guidance remains open despite simulated domain
advances. Although out-of-scope, limitations around validation methodology and
data availability indicate exciting directions, including fine-tuning on
expanded planning corpora and optimizations for triggering fast latent
planning. By conclusively demonstrating current methods' promise and
limitations via rigorous comparison, we catalyze investigating reliable
goal-directed reasoning for situated agents.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16129" title="Abstract">arXiv:2312.16129</a> [<a href="/pdf/2312.16129" title="Download PDF">pdf</a>, <a href="/format/2312.16129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Shape Sonification for Breast Cancer Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtz%2C+L">Laura Sch&#xfc;tz</a>, 
<a href="/search/cs?searchtype=author&query=Chemaly%2C+T+E">Trishia El Chemaly</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+E">Emmanuelle Weber</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+A">Anh Doan</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+J">Jacqueline Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+B">Bruce Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Leuze%2C+C">Christoph Leuze</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">About 20 percent of patients undergoing breast-conserving surgery require
reoperation due to cancerous tissue remaining inside the breast. Breast cancer
localization systems utilize auditory feedback to convey the distance between a
localization probe and a small marker (seed) implanted into the breast tumor
prior to surgery. However, no information on the location of the tumor margin
is provided. To reduce the reoperation rate by improving the usability and
accuracy of the surgical task, we developed an auditory display using shape
sonification to assist with tumor margin localization. Accuracy and usability
of the interactive shape sonification were determined on models of the female
breast in three user studies with both breast surgeons and non-clinical
participants. The comparative studies showed a significant increase in
usability (p&lt;0.05) and localization accuracy (p&lt;0.001) of the shape
sonification over the auditory feedback currently used in surgery.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16132" title="Abstract">arXiv:2312.16132</a> [<a href="/pdf/2312.16132" title="Download PDF">pdf</a>, <a href="/format/2312.16132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoleEval: A Bilingual Role Evaluation Benchmark for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tianhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sun Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our dataset will be available at <a href="https://github.com/Magnetic2014/RoleEval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The rapid evolution of large language models (LLMs) necessitates effective
benchmarks for evaluating their role knowledge, which is essential for
establishing connections with the real world and providing more immersive
interactions. This paper introduces RoleEval, a bilingual benchmark designed to
assess the memorization, utilization, and reasoning capabilities of role
knowledge. RoleEval comprises RoleEval-Global (including internationally
recognized characters) and RoleEval-Chinese (including characters popular in
China), with 6,000 Chinese-English parallel multiple-choice questions focusing
on 300 influential people and fictional characters drawn from a variety of
domains including celebrities, anime, comics, movies, TV series, games, and
fiction. These questions cover basic knowledge and multi-hop reasoning
abilities, aiming to systematically probe various aspects such as personal
information, relationships, abilities, and experiences of the characters. To
maintain high standards, we perform a hybrid quality check process combining
automatic and human verification, ensuring that the questions are diverse,
challenging, and discriminative.
<br />Our extensive evaluations of RoleEval across various open-source and
proprietary large language models, under both the zero- and few-shot settings,
reveal insightful findings. Notably, while GPT-4 outperforms other models on
RoleEval-Global, Chinese LLMs excel on RoleEval-Chinese, highlighting
significant knowledge distribution differences. We expect that RoleEval will
highlight the significance of assessing role knowledge for foundation models
across various languages and cultural settings.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16134" title="Abstract">arXiv:2312.16134</a> [<a href="/pdf/2312.16134" title="Download PDF">pdf</a>, <a href="/format/2312.16134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does PML exponentially absorb outgoing waves scattering from a periodic  surface?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+W">Wangtao Lu</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+K">Kuanrong Shen</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+R">Ruming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The PML method is well-known for its exponential convergence rate and easy
implementation for scattering problems with unbounded domains. For
rough-surface scattering problems, authors in [5] proved that the PML method
converges at most algebraically in the physical domain. However, the authors
also asked a question whether exponential convergence still holds for compact
subsets. In [25], one of our authors proved the exponential convergence for
periodic surfaces via the Floquet-Bloch transform when the wavenumber is
positive and not a half integer; when the wavenumber is a positive half
integer, a nearly fourth-order convergence rate was shown in [26]. The
extension of this method to locally perturbed cases is not straightforward,
since the domain is no longer periodic thus the Floquet-Bloch transform doesn't
work, especially when the domain topology is changed. Moreover, the exact decay
rate when the wavenumber is a half integer remains unclear. The purpose of this
paper is to address these two significant issues. For the first topic, the main
idea is to reduce the problem by the DtN map on an artificial curve, then the
convergence rate of the PML is obtained from the investigation of the DtN map.
It shows exactly the same convergence rate as in the unperturbed case. Second,
to illustrate the convergence rate when the wavenumber is a half integer, we
design a specific periodic structure for which the PML converges at the
fourth-order, showing that the algebraic convergence rate is sharp. We adopt a
previously developed high-accuracy PML-BIE solver to exhibit this unexpected
phenomenon.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16141" title="Abstract">arXiv:2312.16141</a> [<a href="/pdf/2312.16141" title="Download PDF">pdf</a>, <a href="/format/2312.16141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VirtualPainting: Addressing Sparsity with Virtual Points and  Distance-Aware Data Augmentation for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+S">Sudip Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Carrillo%2C+D">Dominic Carrillo</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+D">Deyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Nutt%2C+M">Michael Nutt</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Song Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent times, there has been a notable surge in multimodal approaches that
decorates raw LiDAR point clouds with camera-derived features to improve object
detection performance. However, we found that these methods still grapple with
the inherent sparsity of LiDAR point cloud data, primarily because fewer points
are enriched with camera-derived features for sparsely distributed objects. We
present an innovative approach that involves the generation of virtual LiDAR
points using camera images and enhancing these virtual points with semantic
labels obtained from image-based segmentation networks to tackle this issue and
facilitate the detection of sparsely distributed objects, particularly those
that are occluded or distant. Furthermore, we integrate a distance aware data
augmentation (DADA) technique to enhance the models capability to recognize
these sparsely distributed objects by generating specialized training samples.
Our approach offers a versatile solution that can be seamlessly integrated into
various 3D frameworks and 2D semantic segmentation methods, resulting in
significantly improved overall detection accuracy. Evaluation on the KITTI and
nuScenes datasets demonstrates substantial enhancements in both 3D and birds
eye view (BEV) detection benchmarks
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16142" title="Abstract">arXiv:2312.16142</a> [<a href="/pdf/2312.16142" title="Download PDF">pdf</a>, <a href="/format/2312.16142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Framework of Deep Reinforcement Learning for Joint O-RAN/MEC  Orchestration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murti%2C+F+W">Fahri Wisnu Murti</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Samad Ali</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is submitted to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-access Edge Computing (MEC) can be implemented together with Open Radio
Access Network (O-RAN) over commodity platforms to offer low-cost deployment
and bring the services closer to end-users. In this paper, a joint O-RAN/MEC
orchestration using a Bayesian deep reinforcement learning (RL)-based framework
is proposed that jointly controls the O-RAN functional splits, the allocated
resources and hosting locations of the O-RAN/MEC services across
geo-distributed platforms, and the routing for each O-RAN/MEC data flow. The
goal is to minimize the long-term overall network operation cost and maximize
the MEC performance criterion while adapting possibly time-varying O-RAN/MEC
demands and resource availability. This orchestration problem is formulated as
Markov decision process (MDP). However, the system consists of multiple BSs
that share the same resources and serve heterogeneous demands, where their
parameters have non-trivial relations. Consequently, finding the exact model of
the underlying system is impractical, and the formulated MDP renders in a large
state space with multi-dimensional discrete action. To address such modeling
and dimensionality issues, a novel model-free RL agent is proposed for our
solution framework. The agent is built from Double Deep Q-network (DDQN) that
tackles the large state space and is then incorporated with action branching,
an action decomposition method that effectively addresses the multi-dimensional
discrete action with linear increase complexity. Further, an efficient
exploration-exploitation strategy under a Bayesian framework using Thomson
sampling is proposed to improve the learning performance and expedite its
convergence. Trace-driven simulations are performed using an O-RAN-compliant
model. The results show that our approach is data-efficient (i.e., converges
faster) and increases the returned reward by 32\% than its non-Bayesian
version.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16143" title="Abstract">arXiv:2312.16143</a> [<a href="/pdf/2312.16143" title="Download PDF">pdf</a>, <a href="/format/2312.16143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trajectories of SGD Without Replacement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beneventano%2C+P">Pierfrancesco Beneventano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 73 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">This article examines the implicit regularization effect of Stochastic
Gradient Descent (SGD). We consider the case of SGD without replacement, the
variant typically used to optimize large-scale neural networks. We analyze this
algorithm in a more realistic regime than typically considered in theoretical
works on SGD, as, e.g., we allow the product of the learning rate and Hessian
to be $O(1)$. Our core theoretical result is that optimizing with SGD without
replacement is locally equivalent to making an additional step on a novel
regularizer. This implies that the trajectory of SGD without replacement
diverges from both noise-injected GD and SGD with replacement (in which batches
are sampled i.i.d.). Indeed, the two SGDs travel flat regions of the loss
landscape in distinct directions and at different speeds. In expectation, SGD
without replacement may escape saddles significantly faster and present a
smaller variance. Moreover, we find that SGD implicitly regularizes the trace
of the noise covariance in the eigendirections of small and negative Hessian
eigenvalues. This coincides with penalizing a weighted trace of the Fisher
Matrix and the Hessian on several vision tasks, thus encouraging sparsity in
the spectrum of the Hessian of the loss in line with empirical observations
from prior work. We also propose an explanation for why SGD does not train at
the edge of stability (as opposed to GD).
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16144" title="Abstract">arXiv:2312.16144</a> [<a href="/pdf/2312.16144" title="Download PDF">pdf</a>, <a href="/ps/2312.16144" title="Download PostScript">ps</a>, <a href="/format/2312.16144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JaColBERT and Hard Negatives, Towards Better Japanese-First Embeddings  for Retrieval: Early Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clavi%C3%A9%2C+B">Benjamin Clavi&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Document retrieval in many languages has been largely relying on
multi-lingual models, and leveraging the vast wealth of English training data.
In Japanese, the best performing deep-learning based retrieval approaches rely
on multilingual dense embeddings. In this work, we introduce (1) a
hard-negative augmented version of the Japanese MMARCO dataset and (2)
JaColBERT, a document retrieval model built on the ColBERT model architecture,
specifically for Japanese. JaColBERT vastly outperform all previous monolingual
retrieval approaches and competes with the best multilingual methods, despite
unfavourable evaluation settings (out-of-domain vs. in-domain for the
multilingual models). JaColBERT reaches an average Recall@10 of 0.813,
noticeably ahead of the previous monolingual best-performing model (0.716) and
only slightly behind multilingual-e5-base (0.820), though more noticeably
behind multilingual-e5-large (0.856). These results are achieved using only a
limited, entirely Japanese, training set, more than two orders of magnitudes
smaller than multilingual embedding models. We believe these results show great
promise to support retrieval-enhanced application pipelines in a wide variety
of domains.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16145" title="Abstract">arXiv:2312.16145</a> [<a href="/pdf/2312.16145" title="Download PDF">pdf</a>, <a href="/format/2312.16145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-dimensional Adapter to Rule Them All: Concepts, Diffusion Models and  Erasing Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Mengyao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Haiwen Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xuan Jin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuan He</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages for the main paper, 17 pages for the Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The prevalent use of commercial and open-source diffusion models (DMs) for
text-to-image generation prompts risk mitigation to prevent undesired
behaviors. Existing concept erasing methods in academia are all based on full
parameter or specification-based fine-tuning, from which we observe the
following issues: 1) Generation alternation towards erosion: Parameter drift
during target elimination causes alternations and potential deformations across
all generations, even eroding other concepts at varying degrees, which is more
evident with multi-concept erased; 2) Transfer inability &amp; deployment
inefficiency: Previous model-specific erasure impedes the flexible combination
of concepts and the training-free transfer towards other models, resulting in
linear cost growth as the deployment scenarios increase. To achieve
non-invasive, precise, customizable, and transferable elimination, we ground
our erasing framework on one-dimensional adapters to erase multiple concepts
from most DMs at once across versatile erasing applications. The
concept-SemiPermeable structure is injected as a Membrane (SPM) into any DM to
learn targeted erasing, and meantime the alteration and erosion phenomenon is
effectively mitigated via a novel Latent Anchoring fine-tuning strategy. Once
obtained, SPMs can be flexibly combined and plug-and-play for other DMs without
specific re-tuning, enabling timely and efficient adaptation to diverse
scenarios. During generation, our Facilitated Transport mechanism dynamically
regulates the permeability of each SPM to respond to different input prompts,
further minimizing the impact on other concepts. Quantitative and qualitative
results across ~40 concepts, 7 DMs and 4 erasing applications have demonstrated
the superior erasing of SPM. Our code and pre-tuned SPMs will be available on
the project page https://lyumengyao.github.io/projects/spm.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16148" title="Abstract">arXiv:2312.16148</a> [<a href="/pdf/2312.16148" title="Download PDF">pdf</a>, <a href="/format/2312.16148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Media Bias Taxonomy: A Systematic Literature Review on the Forms and  Automated Detection of Media Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spinde%2C+T">Timo Spinde</a>, 
<a href="/search/cs?searchtype=author&query=Hinterreiter%2C+S">Smilla Hinterreiter</a>, 
<a href="/search/cs?searchtype=author&query=Haak%2C+F">Fabian Haak</a>, 
<a href="/search/cs?searchtype=author&query=Ruas%2C+T">Terry Ruas</a>, 
<a href="/search/cs?searchtype=author&query=Giese%2C+H">Helge Giese</a>, 
<a href="/search/cs?searchtype=author&query=Meuschke%2C+N">Norman Meuschke</a>, 
<a href="/search/cs?searchtype=author&query=Gipp%2C+B">Bela Gipp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The way the media presents events can significantly affect public perception,
which in turn can alter people's beliefs and views. Media bias describes a
one-sided or polarizing perspective on a topic. This article summarizes the
research on computational methods to detect media bias by systematically
reviewing 3140 research papers published between 2019 and 2022. To structure
our review and support a mutual understanding of bias across research domains,
we introduce the Media Bias Taxonomy, which provides a coherent overview of the
current state of research on media bias from different perspectives. We show
that media bias detection is a highly active research field, in which
transformer-based classification approaches have led to significant
improvements in recent years. These improvements include higher classification
accuracy and the ability to detect more fine-granular types of bias. However,
we have identified a lack of interdisciplinarity in existing projects, and a
need for more awareness of the various types of media bias to support
methodologically thorough performance evaluations of media bias detection
systems. Concluding from our analysis, we see the integration of recent machine
learning advancements with reliable and diverse bias assessment strategies from
other research areas as the most promising area for future research
contributions in the field.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16149" title="Abstract">arXiv:2312.16149</a> [<a href="/pdf/2312.16149" title="Download PDF">pdf</a>, <a href="/format/2312.16149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuhang He</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhuangzhuang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024 Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we study an underexplored, yet important and challenging
problem: counting the number of distinct sounds in raw audio characterized by a
high degree of polyphonicity. We do so by systematically proposing a novel
end-to-end trainable neural network (which we call DyDecNet, consisting of a
dyadic decomposition front-end and backbone network), and quantifying the
difficulty level of counting depending on sound polyphonicity. The dyadic
decomposition front-end progressively decomposes the raw waveform dyadically
along the frequency axis to obtain time-frequency representation in
multi-stage, coarse-to-fine manner. Each intermediate waveform convolved by a
parent filter is further processed by a pair of child filters that evenly split
the parent filter's carried frequency response, with the higher-half child
filter encoding the detail and lower-half child filter encoding the
approximation. We further introduce an energy gain normalization to normalize
sound loudness variance and spectrum overlap, and apply it to each intermediate
parent waveform before feeding it to the two child filters. To better quantify
sound counting difficulty level, we further design three polyphony-aware
metrics: polyphony ratio, max polyphony and mean polyphony. We test DyDecNet on
various datasets to show its superiority, and we further show dyadic
decomposition network can be used as a general front-end to tackle other
acoustic tasks.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16151" title="Abstract">arXiv:2312.16151</a> [<a href="/pdf/2312.16151" title="Download PDF">pdf</a>, <a href="/format/2312.16151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Long-tailed Disease Diagnosis on Radiology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qiaoyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weike Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we aim to investigate the problem of large-scale,
large-vocabulary disease classification for radiologic images, which can be
formulated as a multi-modal, multi-anatomy, multi-label, long-tailed
classification. Our main contributions are three folds: (i), on dataset
construction, we build up an academically accessible, large-scale diagnostic
dataset that encompasses 5568 disorders linked with 930 unique ICD-10-CM codes,
containing 39,026 cases (192,675 scans). (ii), on model design, we present a
novel architecture that enables to process arbitrary number of input scans,
from various imaging modalities, which is trained with knowledge enhancement to
leverage the rich domain knowledge; (iii), on evaluation, we initialize a new
benchmark for multi-modal multi-anatomy long-tailed diagnosis. Our method shows
superior results on it. Additionally, our final model serves as a pre-trained
model, and can be finetuned to benefit diagnosis on various external datasets.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16154" title="Abstract">arXiv:2312.16154</a> [<a href="/pdf/2312.16154" title="Download PDF">pdf</a>, <a href="/format/2312.16154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Clustered Orienteering Problem with Subgroups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+L+E">Luciano E. Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Macharet%2C+D+G">Douglas G. Macharet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper introduces an extension to the Orienteering Problem (OP), called
Clustered Orienteering Problem with Subgroups (COPS). In this variant, nodes
are arranged into subgroups, and the subgroups are organized into clusters. A
reward is associated with each subgroup and is gained only if all of its nodes
are visited; however, at most one subgroup can be visited per cluster. The
objective is to maximize the total collected reward while attaining a travel
budget. We show that our new formulation has the ability to model and solve two
previous well-known variants, the Clustered Orienteering Problem (COP) and the
Set Orienteering Problem (SOP), in addition to other scenarios introduced here.
An Integer Linear Programming (ILP) formulation and a Tabu Search-based
heuristic are proposed to solve the problem. Experimental results indicate that
the ILP method can yield optimal solutions at the cost of time, whereas the
metaheuristic produces comparable solutions within a more reasonable
computational cost.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16156" title="Abstract">arXiv:2312.16156</a> [<a href="/pdf/2312.16156" title="Download PDF">pdf</a>, <a href="/format/2312.16156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Multimodal: A Comprehensive Survey of Adversarial Example  Generation in Question Answering Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yigit%2C+G">Gulsum Yigit</a>, 
<a href="/search/cs?searchtype=author&query=Amasyali%2C+M+F">Mehmet Fatih Amasyali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integrating adversarial machine learning with Question Answering (QA) systems
has emerged as a critical area for understanding the vulnerabilities and
robustness of these systems. This article aims to comprehensively review
adversarial example-generation techniques in the QA field, including textual
and multimodal contexts. We examine the techniques employed through systematic
categorization, providing a comprehensive, structured review. Beginning with an
overview of traditional QA models, we traverse the adversarial example
generation by exploring rule-based perturbations and advanced generative
models. We then extend our research to include multimodal QA systems, analyze
them across various methods, and examine generative models, seq2seq
architectures, and hybrid methodologies. Our research grows to different
defense strategies, adversarial datasets, and evaluation metrics and
illustrates the comprehensive literature on adversarial QA. Finally, the paper
considers the future landscape of adversarial question generation, highlighting
potential research directions that can advance textual and multimodal QA
systems in the context of adversarial challenges.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16158" title="Abstract">arXiv:2312.16158</a> [<a href="/pdf/2312.16158" title="Download PDF">pdf</a>, <a href="/ps/2312.16158" title="Download PostScript">ps</a>, <a href="/format/2312.16158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Association rule mining with earthquake data collected from Turkiye  region
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alturan%2C+B">Baha Alturan</a>, 
<a href="/search/cs?searchtype=author&query=Turker%2C+I">Ilker Turker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages and 6 tables. Submitted to ABANT 2nd INTERNATIONAL CONFERENCE ON SCIENTIFIC RESEARCHES
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Earthquakes are evaluated among the most destructive disasters for human
beings, as also experienced for Turkiye region. Data science has the property
of discovering hidden patterns in case a sufficient volume of data is supplied.
Time dependency of events, specifically being defined by co-occurrence in a
specific time window, may be handled as an associate rule mining task such as a
market-basket analysis application. In this regard, we assumed each day's
seismic activity as a single basket of events, leading to discovering the
association patterns between these events. Consequently, this study presents
the most prominent association rules for the earthquakes recorded in Turkiye
region in the last 5 years, each year presented separately. Results indicate
statistical inference with events recorded from regions of various distances,
which could be further verified with geologic evidence from the field. As a
result, we believe that the current study may form a statistical basis for the
future works with the aid of machine learning algorithm performed for associate
rule mining.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16159" title="Abstract">arXiv:2312.16159</a> [<a href="/pdf/2312.16159" title="Download PDF">pdf</a>, <a href="/format/2312.16159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Cross-Lingual Reranking with Large Language Models for  Low-Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adeyemi%2C+M">Mofetoluwa Adeyemi</a>, 
<a href="/search/cs?searchtype=author&query=Oladipo%2C+A">Akintunde Oladipo</a>, 
<a href="/search/cs?searchtype=author&query=Pradeep%2C+R">Ronak Pradeep</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have shown impressive zero-shot capabilities in
various document reranking tasks. Despite their successful implementations,
there is still a gap in existing literature on their effectiveness in
low-resource languages. To address this gap, we investigate how LLMs function
as rerankers in cross-lingual information retrieval (CLIR) systems for African
languages. Our implementation covers English and four African languages (Hausa,
Somali, Swahili, and Yoruba) and we examine cross-lingual reranking with
queries in English and passages in the African languages. Additionally, we
analyze and compare the effectiveness of monolingual reranking using both query
and document translations. We also evaluate the effectiveness of LLMs when
leveraging their own generated translations. To get a grasp of the
effectiveness of multiple LLMs, our study focuses on the proprietary models
RankGPT-4 and RankGPT-3.5, along with the open-source model, RankZephyr. While
reranking remains most effective in English, our results reveal that
cross-lingual reranking may be competitive with reranking in African languages
depending on the multilingual capability of the LLM.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16163" title="Abstract">arXiv:2312.16163</a> [<a href="/pdf/2312.16163" title="Download PDF">pdf</a>, <a href="/format/2312.16163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age of Information in Gossip Networks: A Friendly Introduction and  Literature Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaswan%2C+P">Priyanka Kaswan</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Purbesh Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Arunabh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Gossiping is a communication mechanism, used for fast information
dissemination in a network, where each node of the network randomly shares its
information with the neighboring nodes. To characterize the notion of fastness
in the context of gossip networks, age of information (AoI) is used as a
timeliness metric. In this article, we summarize the recent works related to
timely gossiping in a network. We start with the introduction of randomized
gossip algorithms as an epidemic algorithm for database maintenance, and how
the gossiping literature was later developed in the context of rumor spreading,
message passing and distributed mean estimation. Then, we motivate the need for
timely gossiping in applications such as source tracking and decentralized
learning. We evaluate timeliness scaling of gossiping in various network
topologies, such as, fully connected, ring, grid, generalized ring,
hierarchical, and sparse asymmetric networks. We discuss age-aware gossiping
and the higher order moments of the age process. We also consider different
variations of gossiping in networks, such as, file slicing and network coding,
reliable and unreliable sources, information mutation, different adversarial
actions in gossiping, and energy harvesting sensors. Finally, we conclude this
article with a few open problems and future directions in timely gossiping.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16168" title="Abstract">arXiv:2312.16168</a> [<a href="/pdf/2312.16168" title="Download PDF">pdf</a>, <a href="/format/2312.16168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social-Transmotion: Promptable Human Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saadatnejad%2C+S">Saeed Saadatnejad</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Messaoud%2C+K">Kaouther Messaoud</a>, 
<a href="/search/cs?searchtype=author&query=Alahi%2C+A">Alexandre Alahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Accurate human trajectory prediction is crucial for applications such as
autonomous vehicles, robotics, and surveillance systems. Yet, existing models
often fail to fully leverage the non-verbal social cues human subconsciously
communicate when navigating the space. To address this, we introduce
Social-Transmotion, a generic model that exploits the power of transformers to
handle diverse and numerous visual cues, capturing the multi-modal nature of
human behavior. We translate the idea of a prompt from Natural Language
Processing (NLP) to the task of human trajectory prediction, where a prompt can
be a sequence of x-y coordinates on the ground, bounding boxes or body poses.
This, in turn, augments trajectory data, leading to enhanced human trajectory
prediction. Our model exhibits flexibility and adaptability by capturing
spatiotemporal interactions between pedestrians based on the available visual
cues, whether they are poses, bounding boxes, or a combination thereof. By the
masking technique, we ensure our model's effectiveness even when certain visual
cues are unavailable, although performance is further boosted with the presence
of comprehensive visual data. We delve into the merits of using 2d versus 3d
poses, and a limited set of poses. Additionally, we investigate the spatial and
temporal attention map to identify which keypoints and frames of poses are
vital for optimizing human trajectory prediction. Our approach is validated on
multiple datasets, including JTA, JRDB, Pedestrians and Cyclists in Road
Traffic, and ETH-UCY. The code is publicly available:
https://github.com/vita-epfl/social-transmotion
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16170" title="Abstract">arXiv:2312.16170</a> [<a href="/pdf/2312.16170" title="Download PDF">pdf</a>, <a href="/format/2312.16170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards  Embodied AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaohan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runsen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+R">Ruiyuan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peisen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A multi-modal, ego-centric 3D perception dataset and benchmark for holistic 3D scene understanding. Project page: <a href="http://tai-wang.github.io/embodiedscan">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">In the realm of computer vision and robotics, embodied agents are expected to
explore their environment and carry out human instructions. This necessitates
the ability to fully understand 3D scenes given their first-person observations
and contextualize them into language for interaction. However, traditional
research focuses more on scene-level input and output setups from a global
view. To address the gap, we introduce EmbodiedScan, a multi-modal, ego-centric
3D perception dataset and benchmark for holistic 3D scene understanding. It
encompasses over 5k scans encapsulating 1M ego-centric RGB-D views, 1M language
prompts, 160k 3D-oriented boxes spanning over 760 categories, some of which
partially align with LVIS, and dense semantic occupancy with 80 common
categories. Building upon this database, we introduce a baseline framework
named Embodied Perceptron. It is capable of processing an arbitrary number of
multi-modal inputs and demonstrates remarkable 3D perception capabilities, both
within the two series of benchmarks we set up, i.e., fundamental 3D perception
tasks and language-grounded tasks, and in the wild. Codes, datasets, and
benchmarks will be available at https://github.com/OpenRobotLab/EmbodiedScan.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16171" title="Abstract">arXiv:2312.16171</a> [<a href="/pdf/2312.16171" title="Download PDF">pdf</a>, <a href="/format/2312.16171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principled Instructions Are All You Need for Questioning LLaMA-1/2,  GPT-3.5/4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bsharat%2C+S+M">Sondos Mahmoud Bsharat</a>, 
<a href="/search/cs?searchtype=author&query=Myrzakhan%2C+A">Aidar Myrzakhan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github at: <a href="https://github.com/VILA-Lab/ATLAS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces 26 guiding principles designed to streamline the
process of querying and prompting large language models. Our goal is to
simplify the underlying concepts of formulating questions for various scales of
large language models, examining their abilities, and enhancing user
comprehension on the behaviors of different scales of large language models
when feeding into different prompts. Extensive experiments are conducted on
LLaMA-1/2 (7B, 13B and 70B), GPT-3.5/4 to verify the effectiveness of the
proposed principles on instructions and prompts design. We hope that this work
provides a better guide for researchers working on the prompting of large
language models. Project page is available at
https://github.com/VILA-Lab/ATLAS.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 27 Dec 23</h3>
<dl>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14936" title="Abstract">arXiv:2312.14936</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.14936" title="Download PDF">pdf</a>, <a href="/format/2312.14936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerCNet: Periodic Complete Representation for Crystal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+J">Jiao Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xing%2C+Q">Qianli Xing</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ji%2C+J">Jinglong Ji</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yang%2C+B">Bo Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Crystal material representation is the foundation of crystal material
research. Existing works consider crystal molecules as graph data with
different representation methods and leverage the advantages of techniques in
graph learning. A reasonable crystal representation method should capture the
local and global information. However, existing methods only consider the local
information of crystal molecules by modeling the bond distance and bond angle
of first-order neighbors of atoms, which leads to the issue that different
crystals will have the same representation. To solve this many-to-one issue, we
consider the global information by further considering dihedral angles, which
can guarantee that the proposed representation corresponds one-to-one with the
crystal material. We first propose a periodic complete representation and
calculation algorithm for infinite extended crystal materials. A theoretical
proof for the representation that satisfies the periodic completeness is
provided. Based on the proposed representation, we then propose a network for
predicting crystal material properties, PerCNet, with a specially designed
message passing mechanism. Extensive experiments are conducted on two
real-world material benchmark datasets. The PerCNet achieves the best
performance among baseline methods in terms of MAE. In addition, our results
demonstrate the importance of the periodic scheme and completeness for crystal
representation learning.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14939" title="Abstract">arXiv:2312.14939</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.14939" title="Download PDF">pdf</a>, <a href="/format/2312.14939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Graph Representation Learning of Dynamic Brain Connectome  with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+B">Byung-Hoon Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Choi%2C+J">Jungwon Choi</a>, 
<a href="/search/q-bio?searchtype=author&query=Yun%2C+E">EungGu Yun</a>, 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+K">Kyungsang Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+J">Juho Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Temporal Graph Learning Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Graph Transformers have recently been successful in various graph
representation learning tasks, providing a number of advantages over
message-passing Graph Neural Networks. Utilizing Graph Transformers for
learning the representation of the brain functional connectivity network is
also gaining interest. However, studies to date have underlooked the temporal
dynamics of functional connectivity, which fluctuates over time. Here, we
propose a method for learning the representation of dynamic functional
connectivity with Graph Transformers. Specifically, we define the connectome
embedding, which holds the position, structure, and time information of the
functional connectivity graph, and use Transformers to learn its representation
across time. We perform experiments with over 50,000 resting-state fMRI samples
obtained from three datasets, which is the largest number of fMRI data used in
studies by far. The experimental results show that our proposed method
outperforms other competitive baselines in gender classification and age
regression tasks based on the functional connectivity extracted from the fMRI
data.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14953" title="Abstract">arXiv:2312.14953</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.14953" title="Download PDF">pdf</a>, <a href="/format/2312.14953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transportation Transformed: A Comprehensive Review of Dynamic Rerouting  in Multimodal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pratap%2C+S">Suyash Pratap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Optimization and Control (math.OC)

</div>
<p class="mathjax">The emergence of dynamic rerouting in multi-modal transportation networks has
emerged as a crucial area in operations research, revolutionizing routine
optimization. The review study analyzes multiple research publications on
algorithms and techniques related to dynamic rerouting to give a thorough
summary of the state of research in this field and provide future suggestions.
The research paper explains the importance of dynamic rerouting in modern
transportation systems and recognizes its critical role in tackling issues like
accidents, traffic congestion, and infrastructure constraints. In addition, the
review examines the development of dynamic rerouting techniques by examining
several studies to uncover the theoretical foundation, technological
developments, and effects of the practices on various forms of transportation.
The paper emphasizes the potential of technological advancements such as
artificial intelligence, the Internet of Things, and big data in transforming
routing efficiencies. Further, the review presents specific difficulties and
best practices for each mode of transportation, highlighting the many uses of
dynamic rerouting in air, sea, rail, and road transportation. The review also
digs deeper into the integration barriers common in multi-modal networks,
highlighting successful case studies that overcome these obstacles as well as
strategic approaches and regulatory modifications. Lastly, the research paper
assesses the impact of dynamic rerouting on urban development, sustainability,
and potential directions for future research such as the integration of large
language models. The comprehensive literature review incorporates multiple
research perspectives to offer significant insights into the efficacy,
challenges, and potential future pathways for dynamic rerouting within
multi-modal transportation networks.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14968" title="Abstract">arXiv:2312.14968</a> (cross-list from eess.IV) [<a href="/pdf/2312.14968" title="Download PDF">pdf</a>, <a href="/format/2312.14968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Edge Intelligence with Highly Discriminant LNT Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Mishra%2C+V+K">Vinod K. Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Kuo%2C+C+-+J">C.-C. Jay Kuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Big Data, AI and Adaptive Computing for Edge Sensing and Processing Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">AI algorithms at the edge demand smaller model sizes and lower computational
complexity. To achieve these objectives, we adopt a green learning (GL)
paradigm rather than the deep learning paradigm. GL has three modules: 1)
unsupervised representation learning, 2) supervised feature learning, and 3)
supervised decision learning. We focus on the second module in this work. In
particular, we derive new discriminant features from proper linear combinations
of input features, denoted by x, obtained in the first module. They are called
complementary and raw features, respectively. Along this line, we present a
novel supervised learning method to generate highly discriminant complementary
features based on the least-squares normal transform (LNT). LNT consists of two
steps. First, we convert a C-class classification problem to a binary
classification problem. The two classes are assigned with 0 and 1,
respectively. Next, we formulate a least-squares regression problem from the
N-dimensional (N-D) feature space to the 1-D output space, and solve the
least-squares normal equation to obtain one N-D normal vector, denoted by a1.
Since one normal vector is yielded by one binary split, we can obtain M normal
vectors with M splits. Then, Ax is called an LNT of x, where transform matrix A
in R^{M by N} by stacking aj^T, j=1, ..., M, and the LNT, Ax, can generate M
new features. The newly generated complementary features are shown to be more
discriminant than the raw features. Experiments show that the classification
performance can be improved by these new features.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14971" title="Abstract">arXiv:2312.14971</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.14971" title="Download PDF">pdf</a>, <a href="/format/2312.14971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Electricity Distribution Networks: The Impact of Demand  Coincidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gust%2C+G">Gunther Gust</a>, 
<a href="/search/physics?searchtype=author&query=Schl%C3%BCter%2C+A">Alexander Schl&#xfc;ter</a>, 
<a href="/search/physics?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>, 
<a href="/search/physics?searchtype=author&query=%C3%9Abeda%2C+I">Ignacio &#xda;beda</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+J+T">Jonathan T Lee</a>, 
<a href="/search/physics?searchtype=author&query=Neumann%2C+D">Dirk Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, to appear in European Journal of Operational Research (EJOR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">With the global effort to reduce carbon emissions, clean technologies such as
electric vehicles and heat pumps are increasingly introduced into electricity
distribution networks. These technologies considerably increase electricity
flows and can lead to more coincident electricity demand. In this paper, we
analyze how such increases in demand coincidence impact future distribution
network investments. For this purpose, we develop a novel model for designing
electricity distribution networks, called the distribution network
reconfiguration problem with line-specific demand coincidence (DNRP-LSDC). Our
analysis is two-fold: (1) We apply our model to a large sample of real-world
networks from a Swiss distribution network operator. We find that a high demand
coincidence due to, for example, a large-scale uptake of electric vehicles,
requires a substantial amount of new network line construction and increases
average network cost by 84 % in comparison to the status quo. (2) We use a set
of synthetic networks to isolate the effect of specific network
characteristics. Here, we show that high coincidence has a more detrimental
effect on large networks and on networks with low geographic consumer
densities, as present in, e. g., rural areas. We also show that expansion
measures are robust to variations in the cost parameters. Our results
demonstrate the necessity of designing policies and operational protocols that
reduce demand coincidence. Moreover, our findings show that operators of
distribution networks must consider the demand coincidence of new electricity
uses and adapt investment budgets accordingly. Here, our solution algorithms
for the DNRP-LSDC problem can support operators of distribution networks in
strategic and operational network design tasks.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14975" title="Abstract">arXiv:2312.14975</a> (cross-list from quant-ph) [<a href="/pdf/2312.14975" title="Download PDF">pdf</a>, <a href="/format/2312.14975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Random Quantum Networks for PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dees%2C+J">Josh Dees</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jacquier%2C+A">Antoine Jacquier</a>, 
<a href="/search/quant-ph?searchtype=author&query=Laizet%2C+S">Sylvain Laizet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Classical Physics-informed neural networks (PINNs) approximate solutions to
PDEs with the help of deep neural networks trained to satisfy the differential
operator and the relevant boundary conditions. We revisit this idea in the
quantum computing realm, using parameterised random quantum circuits as trial
solutions. We further adapt recent PINN-based techniques to our quantum
setting, in particular Gaussian smoothing. Our analysis concentrates on the
Poisson, the Heat and the Hamilton-Jacobi-Bellman equations, which are
ubiquitous in most areas of science. On the theoretical side, we develop a
complexity analysis of this approach, and show numerically that random quantum
networks can outperform more traditional quantum networks as well as random
classical networks.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14987" title="Abstract">arXiv:2312.14987</a> (cross-list from eess.IV) [<a href="/pdf/2312.14987" title="Download PDF">pdf</a>, <a href="/format/2312.14987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Image Registration with Stochastically Regularized  Biomechanical Equilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alvarez%2C+P">Pablo Alvarez</a> (MIMESIS), 
<a href="/search/eess?searchtype=author&query=Cotin%2C+S">St&#xe9;phane Cotin</a> (MIMESIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Numerous regularization methods for deformable image registration aim at
enforcing smooth transformations, but are difficult to tune-in a priori and
lack a clear physical basis. Physically inspired strategies have emerged,
offering a sound theoretical basis, but still necessitating complex
discretization and resolution schemes. This study introduces a regularization
strategy that does not require discretization, making it compatible with
current registration frameworks, while retaining the benefits of physically
motivated regularization for medical image registration. The proposed method
performs favorably in both synthetic and real datasets, exhibiting an accuracy
comparable to current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15048" title="Abstract">arXiv:2312.15048</a> (cross-list from quant-ph) [<a href="/pdf/2312.15048" title="Download PDF">pdf</a>, <a href="/format/2312.15048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Multigrid Ansatz for Variational Quantum Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Keller%2C+C+M">Christo Meriwether Keller</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eidenbenz%2C+S">Stephan Eidenbenz</a>, 
<a href="/search/quant-ph?searchtype=author&query=B%C3%A4rtschi%2C+A">Andreas B&#xe4;rtschi</a>, 
<a href="/search/quant-ph?searchtype=author&query=O%27Malley%2C+D">Daniel O&#x27;Malley</a>, 
<a href="/search/quant-ph?searchtype=author&query=Golden%2C+J">John Golden</a>, 
<a href="/search/quant-ph?searchtype=author&query=Misra%2C+S">Satyajayant Misra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computing is an emerging topic in engineering that promises to
enhance supercomputing using fundamental physics. In the near term, the best
candidate algorithms for achieving this advantage are variational quantum
algorithms (VQAs). We design and numerically evaluate a novel ansatz for VQAs,
focusing in particular on the variational quantum eigensolver (VQE). As our
ansatz is inspired by classical multigrid hierarchy methods, we call it
"multigrid'' ansatz. The multigrid ansatz creates a parameterized quantum
circuit for a quantum problem on $n$ qubits by successively building and
optimizing circuits for smaller qubit counts $j &lt; n$, reusing optimized
parameter values as initial solutions to next level hierarchy at $j+1$. We show
through numerical simulation that the multigrid ansatz outperforms the standard
hardware-efficient ansatz in terms of solution quality for the Laplacian
eigensolver as well as for a large class of combinatorial optimization problems
with specific examples for MaxCut and Maximum $k$-Satisfiability. Our studies
establish the multi-grid ansatz as a viable candidate for many VQAs and in
particular present a promising alternative to the QAOA approach for
combinatorial optimization problems.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15055" title="Abstract">arXiv:2312.15055</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.15055" title="Download PDF">pdf</a>, <a href="/format/2312.15055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Efficient GWAS Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Li%2C+K">Kexuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Genome-Wide Association Studies (GWAS) face unique challenges in the era of
big genomics data, particularly when dealing with ultra-high-dimensional
datasets where the number of genetic features significantly exceeds the
available samples. This paper introduces an extension to the feature selection
methodology proposed by Mirzaei et al. (2020), specifically tailored to tackle
the intricacies associated with ultra-high-dimensional GWAS data. Our extended
approach enhances the original method by introducing a Frobenius norm penalty
into the student network, augmenting its capacity to adapt to scenarios
characterized by a multitude of features and limited samples. Operating
seamlessly in both supervised and unsupervised settings, our method employs two
key neural networks. The first leverages an autoencoder or supervised
autoencoder for dimension reduction, extracting salient features from the
ultra-high-dimensional genomic data. The second network, a regularized
feed-forward model with a single hidden layer, is designed for precise feature
selection. The introduction of the Frobenius norm penalty in the student
network significantly boosts the method's resilience to the challenges posed by
ultra-high-dimensional GWAS datasets. Experimental results showcase the
efficacy of our approach in feature selection for GWAS data. The method not
only handles the inherent complexities of ultra-high-dimensional settings but
also demonstrates superior adaptability to the nuanced structures present in
genomics data. The flexibility and versatility of our proposed methodology are
underscored by its successful performance across a spectrum of experiments.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15064" title="Abstract">arXiv:2312.15064</a> (cross-list from eess.IV) [<a href="/pdf/2312.15064" title="Download PDF">pdf</a>, <a href="/format/2312.15064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Self-Supervised and Supervised Contrastive Learning for Multimodal  MRI Data: Towards Predicting Abnormal Neurodevelopment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hailong Li</a>, 
<a href="/search/eess?searchtype=author&query=Ralescu%2C+A+L">Anca L. Ralescu</a>, 
<a href="/search/eess?searchtype=author&query=Dillman%2C+J+R">Jonathan R. Dillman</a>, 
<a href="/search/eess?searchtype=author&query=Altaye%2C+M">Mekibib Altaye</a>, 
<a href="/search/eess?searchtype=author&query=Cecil%2C+K+M">Kim M. Cecil</a>, 
<a href="/search/eess?searchtype=author&query=Parikh%2C+N+A">Nehal A. Parikh</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Lili He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages. Submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The integration of different imaging modalities, such as structural,
diffusion tensor, and functional magnetic resonance imaging, with deep learning
models has yielded promising outcomes in discerning phenotypic characteristics
and enhancing disease diagnosis. The development of such a technique hinges on
the efficient fusion of heterogeneous multimodal features, which initially
reside within distinct representation spaces. Naively fusing the multimodal
features does not adequately capture the complementary information and could
even produce redundancy. In this work, we present a novel joint self-supervised
and supervised contrastive learning method to learn the robust latent feature
representation from multimodal MRI data, allowing the projection of
heterogeneous features into a shared common space, and thereby amalgamating
both complementary and analogous information across various modalities and
among similar subjects. We performed a comparative analysis between our
proposed method and alternative deep multimodal learning approaches. Through
extensive experiments on two independent datasets, the results demonstrated
that our method is significantly superior to several other deep multimodal
learning methods in predicting abnormal neurodevelopment. Our method has the
capability to facilitate computer-aided diagnosis within clinical practice,
harnessing the power of multimodal data.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15078" title="Abstract">arXiv:2312.15078</a> (cross-list from nlin.CG) [<a href="/pdf/2312.15078" title="Download PDF">pdf</a>, <a href="/format/2312.15078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On elementary cellular automata asymptotic (a)synchronism sensitivity  and complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Leiva%2C+I+D">Isabel Donoso Leiva</a>, 
<a href="/search/nlin?searchtype=author&query=Goles%2C+E">Eric Goles</a>, 
<a href="/search/nlin?searchtype=author&query=R%C3%ADos-Wilson%2C+M">Mart&#xed;n R&#xed;os-Wilson</a>, 
<a href="/search/nlin?searchtype=author&query=Sen%C3%A9%2C+S">Sylvain Sen&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cellular Automata and Lattice Gases (nlin.CG)</span>; Discrete Mathematics (cs.DM); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Among the fundamental questions in computer science is that of the impact of
synchronism/asynchronism on computations, which has been addressed in various
fields of the discipline: in programming, in networking, in concurrence theory,
in artificial learning, etc. In this paper, we tackle this question from a
standpoint which mixes discrete dynamical system theory and computational
complexity, by highlighting that the chosen way of making local computations
can have a drastic influence on the performed global computation itself. To do
so, we study how distinct update schedules may fundamentally change the
asymptotic behaviors of finite dynamical systems, by analyzing in particular
their limit cycle maximal period. For the message itself to be general and
impacting enough, we choose to focus on a ``simple'' computational model which
prevents underlying systems from having too many intrinsic degrees of freedom,
namely elementary cellular automata. More precisely, for elementary cellular
automata rules which are neither too simple nor too complex (the problem should
be meaningless for both), we show that update schedule changes can lead to
significant computational complexity jumps (from constant to superpolynomial
ones) in terms of their temporal asymptotes.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15124" title="Abstract">arXiv:2312.15124</a> (cross-list from quant-ph) [<a href="/pdf/2312.15124" title="Download PDF">pdf</a>, <a href="/format/2312.15124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On fundamental aspects of quantum extreme learning machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Xiong%2C+W">Weijie Xiong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Facelli%2C+G">Giorgio Facelli</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sahebi%2C+M">Mehrad Sahebi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Agnel%2C+O">Owen Agnel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chotibut%2C+T">Thiparat Chotibut</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thanasilp%2C+S">Supanut Thanasilp</a>, 
<a href="/search/quant-ph?searchtype=author&query=Holmes%2C+Z">Zo&#xeb; Holmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16+17 pages, 8+2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Quantum Extreme Learning Machines (QELMs) have emerged as a promising
framework for quantum machine learning. Their appeal lies in the rich feature
map induced by the dynamics of a quantum substrate - the quantum reservoir -
and the efficient post-measurement training via linear regression. Here we
study the expressivity of QELMs by decomposing the prediction of QELMs into a
Fourier series. We show that the achievable Fourier frequencies are determined
by the data encoding scheme, while Fourier coefficients depend on both the
reservoir and the measurement. Notably, the expressivity of QELMs is
fundamentally limited by the number of Fourier frequencies and the number of
observables, while the complexity of the prediction hinges on the reservoir. As
a cautionary note on scalability, we identify four sources that can lead to the
exponential concentration of the observables as the system size grows
(randomness, hardware noise, entanglement, and global measurements) and show
how this can turn QELMs into useless input-agnostic oracles. Our analysis
elucidates the potential and fundamental limitations of QELMs, and lays the
groundwork for systematically exploring quantum reservoir systems for other
machine learning tasks.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15136" title="Abstract">arXiv:2312.15136</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.15136" title="Download PDF">pdf</a>, <a href="/format/2312.15136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-to-End Structure Solutions from Information-Compromised  Diffraction Data via Generative Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Guo%2C+G">Gabe Guo</a>, 
<a href="/search/physics?searchtype=author&query=Goldfeder%2C+J">Judah Goldfeder</a>, 
<a href="/search/physics?searchtype=author&query=Lan%2C+L">Ling Lan</a>, 
<a href="/search/physics?searchtype=author&query=Ray%2C+A">Aniv Ray</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+A+H">Albert Hanming Yang</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+B">Boyuan Chen</a>, 
<a href="/search/physics?searchtype=author&query=Billinge%2C+S+J">Simon JL Billinge</a>, 
<a href="/search/physics?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The revolution in materials in the past century was built on a knowledge of
the atomic arrangements and the structure-property relationship. The sine qua
non for obtaining quantitative structural information is single crystal
crystallography. However, increasingly we need to solve structures in cases
where the information content in our input signal is significantly degraded,
for example, due to orientational averaging of grains, finite size effects due
to nanostructure, and mixed signals due to sample heterogeneity. Understanding
the structure property relationships in such situations is, if anything, more
important and insightful, yet we do not have robust approaches for
accomplishing it. In principle, machine learning (ML) and deep learning (DL)
are promising approaches since they augment information in the degraded input
signal with prior knowledge learned from large databases of already known
structures. Here we present a novel ML approach, a variational query-based
multi-branch deep neural network that has the promise to be a robust but
general tool to address this problem end-to-end. We demonstrate the approach on
computed powder x-ray diffraction (PXRD), along with partial chemical
composition information, as input. We choose as a structural representation a
modified electron density we call the Cartesian mapped electron density (CMED),
that straightforwardly allows our ML model to learn material structures across
different chemistries, symmetries and crystal systems. When evaluated on
theoretically simulated data for the cubic and trigonal crystal systems, the
system achieves up to $93.4\%$ average similarity with the ground truth on
unseen materials, both with known and partially-known chemical composition
information, showing great promise for successful structure solution even from
degraded and incomplete input data.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15179" title="Abstract">arXiv:2312.15179</a> (cross-list from stat.ME) [<a href="/pdf/2312.15179" title="Download PDF">pdf</a>, <a href="/format/2312.15179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating District-based Election Surveys with Synthetic Dirichlet  Likelihood
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mitra%2C+A">Adway Mitra</a>, 
<a href="/search/stat?searchtype=author&query=Dey%2C+P">Palash Dey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for International Conference on Autonomous and Multi-Agent Systems (AAMAS), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Multiagent Systems (cs.MA); Applications (stat.AP)

</div>
<p class="mathjax">In district-based multi-party elections, electors cast votes in their
respective districts. In each district, the party with maximum votes wins the
corresponding seat in the governing body. Election Surveys try to predict the
election outcome (vote shares and seat shares of parties) by querying a random
sample of electors. However, the survey results are often inconsistent with the
actual results, which could be due to multiple reasons. The aim of this work is
to estimate a posterior distribution over the possible outcomes of the
election, given one or more survey results. This is achieved using a prior
distribution over vote shares, election models to simulate the complete
election from the vote share, and survey models to simulate survey results from
a complete election. The desired posterior distribution over the space of
possible outcomes is constructed using Synthetic Dirichlet Likelihoods, whose
parameters are estimated from Monte Carlo sampling of elections using the
election models. We further show the same approach can also use be used to
evaluate the surveys - whether they were biased or not, based on the true
outcome once it is known. Our work offers the first-ever probabilistic model to
analyze district-based election surveys. We illustrate our approach with
extensive experiments on real and simulated data of district-based political
elections in India.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15182" title="Abstract">arXiv:2312.15182</a> (cross-list from eess.IV) [<a href="/pdf/2312.15182" title="Download PDF">pdf</a>, <a href="/format/2312.15182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrowing the semantic gaps in U-Net with learnable skip connections:  The case of medical image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+P">Peng Cao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaoli Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jinzhu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zaiane%2C+O">Osmar Zaiane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Most state-of-the-art methods for medical image segmentation adopt the
encoder-decoder architecture. However, this U-shaped framework still has
limitations in capturing the non-local multi-scale information with a simple
skip connection. To solve the problem, we firstly explore the potential
weakness of skip connections in U-Net on multiple segmentation tasks, and find
that i) not all skip connections are useful, each skip connection has different
contribution; ii) the optimal combinations of skip connections are different,
relying on the specific datasets. Based on our findings, we propose a new
segmentation framework, named UDTransNet, to solve three semantic gaps in
U-Net. Specifically, we propose a Dual Attention Transformer (DAT) module for
capturing the channel- and spatial-wise relationships to better fuse the
encoder features, and a Decoder-guided Recalibration Attention (DRA) module for
effectively connecting the DAT tokens and the decoder features to eliminate the
inconsistency. Hence, both modules establish a learnable connection to solve
the semantic gaps between the encoder and the decoder, which leads to a
high-performance segmentation model for medical images. Comprehensive
experimental results indicate that our UDTransNet produces higher evaluation
scores and finer segmentation results with relatively fewer parameters over the
state-of-the-art segmentation methods on different public datasets. Code:
https://github.com/McGregorWwww/UDTransNet.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15189" title="Abstract">arXiv:2312.15189</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.15189" title="Download PDF">pdf</a>, <a href="/format/2312.15189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helmholtz decomposition based windowed Green function methods for  elastic scattering problems on a half-space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+T">Tao Yin</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zheng%2C+W">Weiying Zheng</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+X">Xiaopeng Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper proposes a new Helmholtz decomposition based windowed Green
function (HD-WGF) method for solving the time-harmonic elastic scattering
problems on a half-space with Dirichlet boundary conditions in both 2D and 3D.
The Helmholtz decomposition is applied to separate the pressure and shear
waves, which satisfy the Helmholtz and Helmholtz/Maxwell equations,
respectively, and the corresponding boundary integral equations of type
$(\mathbb{I}+\mathbb{T})\bs\phi=\bs f$, that couple these two waves on the
unbounded surface, are derived based on the free-space fundamental solution of
Helmholtz equation. This approach avoids the treatment of the complex elastic
displacement tensor and traction operator that involved in the classical
integral equation method for elastic problems. Then a smooth ``slow-rise''
windowing function is introduced to truncate the boundary integral equations
and a ``correction'' strategy is proposed to ensure the uniformly fast
convergence for all incident angles of plane incidence. Numerical experiments
for both two and three dimensional problems are presented to demonstrate the
accuracy and efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15218" title="Abstract">arXiv:2312.15218</a> (cross-list from physics.geo-ph) [<a href="/pdf/2312.15218" title="Download PDF">pdf</a>, <a href="/ps/2312.15218" title="Download PostScript">ps</a>, <a href="/format/2312.15218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Neural Networks for Real-Time Earthquake Early Warning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+X">Xiong Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning enhances earthquake monitoring capabilities by mining seismic
waveforms directly. However, current neural networks, trained within specific
areas, face challenges in generalizing to diverse regions. Here, we employ a
data recombination method to create generalized earthquakes occurring at any
location with arbitrary station distributions for neural network training. The
trained models can then be applied to various regions with different monitoring
setups for earthquake detection and parameter evaluation from continuous
seismic waveform streams. This allows real-time Earthquake Early Warning (EEW)
to be initiated at the very early stages of an occurring earthquake. When
applied to substantial earthquake sequences across Japan and California (US),
our models reliably report earthquake locations and magnitudes within 4 seconds
after the first triggered station, with mean errors of 2.6-6.3 km and
0.05-0.17, respectively. These generalized neural networks facilitate global
applications of real-time EEW, eliminating complex empirical configurations
typically required by traditional methods.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15233" title="Abstract">arXiv:2312.15233</a> (cross-list from eess.IV) [<a href="/pdf/2312.15233" title="Download PDF">pdf</a>, <a href="/format/2312.15233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample selection with noise rate estimation in noise learning of medical  image analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Maolin Li</a>, 
<a href="/search/eess?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>, 
<a href="/search/eess?searchtype=author&query=Siomos%2C+V">Vasilis Siomos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning techniques have demonstrated remarkable success in the field of
medical image analysis. However, the existence of label noise within data
significantly hampers its performance. In this paper, we introduce a novel
noise-robust learning method which integrates noise rate estimation into sample
selection approaches for handling noisy datasets. We first estimate the noise
rate of a dataset with Linear Regression based on the distribution of loss
values. Then, potentially noisy samples are excluded based on this estimated
noise rate, and sparse regularization is further employed to improve the
robustness of our deep learning model. Our proposed method is evaluated on five
benchmark medical image classification datasets, including two datasets
featuring 3D medical images. Experiments show that our method outperforms other
existing noise-robust learning methods, especially when noise rate is very big.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15245" title="Abstract">arXiv:2312.15245</a> (cross-list from eess.SP) [<a href="/pdf/2312.15245" title="Download PDF">pdf</a>, <a href="/format/2312.15245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resonant Inductive Coupling Network for Human-Sized Magnetic Particle  Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohn%2C+F">Fabian Mohn</a>, 
<a href="/search/eess?searchtype=author&query=F%C3%B6rger%2C+F">Fynn F&#xf6;rger</a>, 
<a href="/search/eess?searchtype=author&query=Thieben%2C+F">Florian Thieben</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%B6ddel%2C+M">Martin M&#xf6;ddel</a>, 
<a href="/search/eess?searchtype=author&query=Schmale%2C+I">Ingo Schmale</a>, 
<a href="/search/eess?searchtype=author&query=Knopp%2C+T">Tobias Knopp</a>, 
<a href="/search/eess?searchtype=author&query=Graeser%2C+M">Matthias Graeser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">In Magnetic Particle Imaging, a field-free region is maneuvered throughout
the field of view using a time-varying magnetic field known as the drive-field.
Human-sized systems operate the drive-field in the kHz range and generate it by
utilizing strong currents that can rise to the kA range within a coil called
the drive field generator. Matching and tuning between a power amplifier, a
band-pass filter and the drive-field generator is required. Here, for reasons
of safety in future human scanners, a symmetrical topology and a transformer,
called inductive coupling network is used. Our primary objectives are to
achieve floating potentials to ensure patient safety, attaining high linearity
and high gain for the resonant transformer. We present a novel systematic
approach to the design of a loss-optimized resonant toroid with a D-shaped
cross section, employing segmentation to adjust the inductance-to-resistance
ratio while maintaining a constant quality factor. Simultaneously, we derive a
specific matching condition of a symmetric transmit-receive circuit for
magnetic particle imaging. The chosen setup filters the fundamental frequency
and allows simultaneous signal transmission and reception. In addition, the
decoupling of multiple drive field channels is discussed and the primary side
of the transformer is evaluated for maximum coupling and minimum stray field.
Two prototypes were constructed, measured, decoupled, and compared to the
derived theory and to method-of-moment based simulations.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15248" title="Abstract">arXiv:2312.15248</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.15248" title="Download PDF">pdf</a>, <a href="/format/2312.15248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Type-II Apollonian Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ma%2C+F">Fei Ma</a>, 
<a href="/search/physics?searchtype=author&query=Ouyang%2C+J">Jinzhi Ouyang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+P">Ping Wang</a>, 
<a href="/search/physics?searchtype=author&query=Shi%2C+H">Haobin Shi</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+W">Wei Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">The family of planar graphs is a particularly important family and models
many real-world networks. In this paper, we propose a principled framework
based on the widely-known Apollonian packing process to generate new planar
network, i.e., Type-II Apollonian network $\mathcal{A}_{t}$. The manipulation
is different from that of the typical Apollonian network, and is proceeded in
terms of the iterative addition of triangle instead of vertex. As a
consequence, network $\mathcal{A}_{t}$ turns out to be hamiltonian and
eulerian, however, the typical Apollonian network is not. Then, we in-depth
study some fundamental structural properties on network $\mathcal{A}_{t}$, and
verify that network $\mathcal{A}_{t}$ is sparse like most real-world networks,
has scale-free feature and small-world property, and exhibits disassortative
mixing structure. Next, we design an effective algorithm for solving the
problem of how to enumerate spanning trees on network $\mathcal{A}_{t}$, and
derive the asymptotic solution of the spanning tree entropy, which suggests
that Type-II Apollonian network is more reliable to a random removal of edges
than the typical Apollonian network. Additionally, we study trapping problem on
network $\mathcal{A}_{t}$, and use average trapping time as metric to show that
Type-II Apollonian network $\mathcal{A}_{t}$ has better structure for fast
information diffusion than the typical Apollonian network.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15252" title="Abstract">arXiv:2312.15252</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.15252" title="Download PDF">pdf</a>, <a href="/format/2312.15252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTIAM: A unified framework for predicting drug-target interactions,  binding affinities and activation/inhibition mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+Z">Zhangli Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Lei%2C+C">Chuqi Lei</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+K">Kaili Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Qin%2C+L">Libo Qin</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+J">Jing Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+M">Min Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate and robust prediction of drug-target interactions (DTIs) plays a
vital role in drug discovery. Despite extensive efforts have been invested in
predicting novel DTIs, existing approaches still suffer from insufficient
labeled data and cold start problems. More importantly, there is currently a
lack of studies focusing on elucidating the mechanism of action (MoA) between
drugs and targets. Distinguishing the activation and inhibition mechanisms is
critical and challenging in drug development. Here, we introduce a unified
framework called DTIAM, which aims to predict interactions, binding affinities,
and activation/inhibition mechanisms between drugs and targets. DTIAM learns
drug and target representations from large amounts of label-free data through
self-supervised pre-training, which accurately extracts the substructure and
contextual information of drugs and targets, and thus benefits the downstream
prediction based on these representations. DTIAM achieves substantial
performance improvement over other state-of-the-art methods in all tasks,
particularly in the cold start scenario. Moreover, independent validation
demonstrates the strong generalization ability of DTIAM. All these results
suggested that DTIAM can provide a practically useful tool for predicting novel
DTIs and further distinguishing the MoA of candidate drugs. DTIAM, for the
first time, provides a unified framework for accurate and robust prediction of
drug-target interactions, binding affinities, and activation/inhibition
mechanisms.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15260" title="Abstract">arXiv:2312.15260</a> (cross-list from astro-ph.EP) [<a href="/pdf/2312.15260" title="Download PDF">pdf</a>, <a href="/ps/2312.15260" title="Download PostScript">ps</a>, <a href="/format/2312.15260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surveying the ice condensation period at southern polar Mars using a CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gerg%C3%A1cz%2C+M">Mira Gerg&#xe1;cz</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kereszturi%2C+%C3%81">&#xc1;kos Kereszturi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Before the seasonal polar ice cap starts to expand towards lower latitudes on
Mars, small frost patches may condensate out during the cold night and they may
remain on the surface even during the day in shady areas. If ice in these areas
can persist before the arrival of the contiguous ice cap, they may remain after
the recession of it too, until the irradiation increases and the ice is met
with direct sunlight. In case these small patches form periodically at the same
location, slow chemical changes might occur as well. To see the spatial and
temporal occurrence of such ice patches, large number of optical images should
be searched for and checked. The aim of this study is to survey the ice
condensation period on the surface with an automatized method using a
Convolutional Neural Network (CNN) applied to High-Resolution Imaging Science
Experiment (HiRISE) imagery from the Mars Reconnaissance Orbiter mission. The
CNN trained to recognise small ice patches is automatizing the search, making
it feasible to analyse large datasets. Previously a manual image analysis was
conducted on 110 images from the southern hemisphere, captured by the HiRISE
camera. Out of these, 37 images were identified with smaller ice patches, which
were used to train the CNN. This approach is applied now to find further images
with potential water ice patches in the latitude band between -40{\deg} and
-60{\deg}, but contrarily to the training dataset recorded between
140-200{\deg} solar longitude, the images were taken from the condensation
period between Ls = 0{\deg} to 90{\deg}. The model was ran on 171 new HiRISE
images randomly picked from the given period between -40{\deg} and -60{\deg}
latitude band, creating 73155 small image chunks. The model classified 2 images
that show small, probably recently condensed frost patches and 327 chunks were
predicted to show ice with more than 60% probability.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15267" title="Abstract">arXiv:2312.15267</a> (cross-list from eess.SP) [<a href="/pdf/2312.15267" title="Download PDF">pdf</a>, <a href="/format/2312.15267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new type of window functions constructed with exponential function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+H">Haichao Xu</a>, 
<a href="/search/eess?searchtype=author&query=Suo%2C+X">Xingpao Suo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The Discrete Fourier Transform (DFT) is widely utilized for signal analysis
but is plagued by spectral leakage, leading to inaccuracies in signal
approximation. Window functions play a crucial role in mitigating spectral
leakage by providing weighting mechanisms for discrete signals. In this paper,
we introduce a novel window type based on exponential function, allowing for
adjustable parameters and diverse variations. We present the formulation,
properties, and motivation behind the design of the new window functions.
Additionally, we analyze their behavior and evaluate their performance by
comparing them with mainstream window functions using six parameters. Our
findings demonstrate that these new window functions exhibit outstanding
flexibility and versatility in signal analysis.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15277" title="Abstract">arXiv:2312.15277</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.15277" title="Download PDF">pdf</a>, <a href="/format/2312.15277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Student similarity network clustering -- Does the time it takes for an  answer to be selected follow a power-law?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Prates%2C+F+S+P">Filipe S. P. Prates</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures. Code and data available at <a href="https://github.com/FilipePrates/CPS765-Complex_Networks-Projeto_final-Similaridade_entre_alunos">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This article uses a dataset of answers to questions to generate student
similarity networks. Two similarity functions to determine the weights between
each pair of students are used, one that assumes a power-law distribution of
answers response times, and one that does not. The resulting networks are then
clustered using different community finding algorithms and their resulting
modularity is compared.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15282" title="Abstract">arXiv:2312.15282</a> (cross-list from stat.ML) [<a href="/pdf/2312.15282" title="Download PDF">pdf</a>, <a href="/format/2312.15282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Forecasting for Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Schultz%2C+D">Douglas Schultz</a>, 
<a href="/search/stat?searchtype=author&query=Stephan%2C+J">Johannes Stephan</a>, 
<a href="/search/stat?searchtype=author&query=Sieber%2C+J">Julian Sieber</a>, 
<a href="/search/stat?searchtype=author&query=Yeh%2C+T">Trudie Yeh</a>, 
<a href="/search/stat?searchtype=author&query=Kunz%2C+M">Manuel Kunz</a>, 
<a href="/search/stat?searchtype=author&query=Doupe%2C+P">Patrick Doupe</a>, 
<a href="/search/stat?searchtype=author&query=Januschowski%2C+T">Tim Januschowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a novel method for demand forecasting in a pricing
context. Here, modeling the causal relationship between price as an input
variable to demand is crucial because retailers aim to set prices in a (profit)
optimal manner in a downstream decision making problem. Our methods bring
together the Double Machine Learning methodology for causal inference and
state-of-the-art transformer-based forecasting models. In extensive empirical
experiments, we show on the one hand that our method estimates the causal
effect better in a fully controlled setting via synthetic, yet realistic data.
On the other hand, we demonstrate on real-world data that our method
outperforms forecasting methods in off-policy settings (i.e., when there's a
change in the pricing policy) while only slightly trailing in the on-policy
setting.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15285" title="Abstract">arXiv:2312.15285</a> (cross-list from quant-ph) [<a href="/pdf/2312.15285" title="Download PDF">pdf</a>, <a href="/ps/2312.15285" title="Download PostScript">ps</a>, <a href="/format/2312.15285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subset States and Pseudorandom States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jeronimo%2C+F+G">Fernando Granha Jeronimo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magrafta%2C+N">Nir Magrafta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+P">Pei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Pseudorandom states (PRS) are an important primitive in quantum cryptography.
In this paper, we show that subset states can be used to construct PRSs. A
subset state with respect to $S$, a subset of the computational basis, is \[
<br />\frac{1}{\sqrt{|S|}}\sum_{i\in S} |i\rangle. \] As a technical centerpiece,
we show that for any fixed subset size $|S|=s$ such that $s = o(2^n/\poly(n))$
and $s=\omega(\poly(n))$, where $n$ is the number of qubits, a subset state is
information-theoretically indistinguishable from a Haar random state even
provided with polynomially many copies. This range of parameter is tight. Our
result resolves a conjecture by Ji, Liu and Song.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15295" title="Abstract">arXiv:2312.15295</a> (cross-list from stat.ML) [<a href="/pdf/2312.15295" title="Download PDF">pdf</a>, <a href="/format/2312.15295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdamL: A fast adaptive gradient method incorporating loss function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xia%2C+L">Lu Xia</a>, 
<a href="/search/stat?searchtype=author&query=Massei%2C+S">Stefano Massei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Adaptive first-order optimizers are fundamental tools in deep learning,
although they may suffer from poor generalization due to the nonuniform
gradient scaling. In this work, we propose AdamL, a novel variant of the Adam
optimizer, that takes into account the loss function information to attain
better generalization results. We provide sufficient conditions that together
with the Polyak-Lojasiewicz inequality, ensure the linear convergence of AdamL.
As a byproduct of our analysis, we prove similar convergence properties for the
EAdam, and AdaBelief optimizers. Experimental results on benchmark functions
show that AdamL typically achieves either the fastest convergence or the lowest
objective function values when compared to Adam, EAdam, and AdaBelief. These
superior performances are confirmed when considering deep learning tasks such
as training convolutional neural networks, training generative adversarial
networks using vanilla convolutional neural networks, and long short-term
memory networks. Finally, in the case of vanilla convolutional neural networks,
AdamL stands out from the other Adam's variants and does not require the manual
adjustment of the learning rate during the later stage of the training.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15309" title="Abstract">arXiv:2312.15309</a> (cross-list from quant-ph) [<a href="/pdf/2312.15309" title="Download PDF">pdf</a>, <a href="/format/2312.15309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Runtime Assertions in Quantum Ternary Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Faghih%2C+E">Ehsan Faghih</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+H">Huiyang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">With the rapid advancement of quantum computing technology, there is a
growing need for new debugging tools for quantum programs. Recent research has
highlighted the potential of assertions for debugging quantum programs. In this
paper, we investigate assertions in quantum ternary systems, which are more
challenging than those in quantum binary systems due to the complexity of
ternary logic. We propose quantum ternary circuit designs to assert classical,
entanglement, and superposition states, specifically geared toward debugging
quantum ternary programs.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15320" title="Abstract">arXiv:2312.15320</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.15320" title="Download PDF">pdf</a>, <a href="/ps/2312.15320" title="Download PostScript">ps</a>, <a href="/format/2312.15320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Machine Learning Combining Facial Images and Clinical Texts  Improves Diagnosis of Rare Genetic Diseases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+D">Da Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+J">Jingye Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Klein%2C+S">Steven Klein</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Hsieh%2C+T">Tzung-Chien Hsieh</a>, 
<a href="/search/q-bio?searchtype=author&query=Krawitz%2C+P">Peter Krawitz</a>, 
<a href="/search/q-bio?searchtype=author&query=Weng%2C+C">Chunhua Weng</a>, 
<a href="/search/q-bio?searchtype=author&query=Lyon%2C+G+J">Gholson J. Lyon</a>, 
<a href="/search/q-bio?searchtype=author&query=Kalish%2C+J+M">Jennifer M. Kalish</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+K">Kai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM); Genomics (q-bio.GN)

</div>
<p class="mathjax">Individuals with suspected rare genetic disorders often undergo multiple
clinical evaluations, imaging studies, laboratory tests and genetic tests, to
find a possible answer over a prolonged period of multiple years. Addressing
this diagnostic odyssey thus have substantial clinical, psychosocial, and
economic benefits. Many rare genetic diseases have distinctive facial features,
which can be used by artificial intelligence algorithms to facilitate clinical
diagnosis, in prioritizing candidate diseases to be further examined by lab
tests or genetic assays, or in helping the phenotype-driven reinterpretation of
genome/exome sequencing data. However, existing methods using frontal facial
photo were built on conventional Convolutional Neural Networks (CNNs), rely
exclusively on facial images, and cannot capture non-facial phenotypic traits
and demographic information essential for guiding accurate diagnoses. Here we
introduce GestaltMML, a multimodal machine learning (MML) approach solely based
on the Transformer architecture. It integrates the facial images, demographic
information (age, sex, ethnicity), and clinical notes of patients to improve
prediction accuracy. Furthermore, we also introduce GestaltGPT, a GPT-based
methodology with few-short learning capacities that exclusively harnesses
textual inputs using a range of large language models (LLMs) including Llama 2,
GPT-J and Falcon. We evaluated these methods on a diverse range of datasets,
including 449 diseases from the GestaltMatcher Database, several in-house
datasets on Beckwith-Wiedemann syndrome, Sotos syndrome, NAA10-related syndrome
(neurodevelopmental syndrome) and others. Our results suggest that
GestaltMML/GestaltGPT effectively incorporate multiple modalities of data,
greatly narrow down candidate genetic diagnosis of rare diseases, and may
facilitate the reinterpretation of genome/exome sequencing data.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15325" title="Abstract">arXiv:2312.15325</a> (cross-list from math.CO) [<a href="/pdf/2312.15325" title="Download PDF">pdf</a>, <a href="/format/2312.15325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swap cosystolic expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dikstein%2C+Y">Yotam Dikstein</a>, 
<a href="/search/math?searchtype=author&query=Dinur%2C+I">Irit Dinur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Algebraic Topology (math.AT)

</div>
<p class="mathjax">We introduce and study swap cosystolic expansion, a new expansion property of
simplicial complexes. We prove lower bounds for swap coboundary expansion of
spherical buildings and use them to lower bound swap cosystolic expansion of
the LSV Ramanujan complexes. Our motivation is the recent work (in a companion
paper) showing that swap cosystolic expansion implies agreement theorems.
Together the two works show that these complexes support agreement tests in the
low acceptance regime.
<br />Swap cosystolic expansion is defined by considering, for a given complex $X$,
its faces complex $F^r X$, whose vertices are $r$-faces of $X$ and where two
vertices are connected if their disjoint union is also a face in $X$. The faces
complex $F^r X$ is a derandomizetion of the product of $X$ with itself $r$
times. The graph underlying $F^rX$ is the swap walk of $X$, known to have
excellent spectral expansion. The swap cosystolic expansion of $X$ is defined
to be the cosystolic expansion of $F^r X$.
<br />Our main result is a $\exp(-O(\sqrt r))$ lower bound on the swap coboundary
expansion of the spherical building and the swap cosystolic expansion of the
LSV complexes. For more general coboundary expanders we show a weaker lower
bound of $exp(-O(r))$.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15326" title="Abstract">arXiv:2312.15326</a> (cross-list from math.CO) [<a href="/pdf/2312.15326" title="Download PDF">pdf</a>, <a href="/ps/2312.15326" title="Download PostScript">ps</a>, <a href="/format/2312.15326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Connected Strongly-Proportional Cake-Cutting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jank%C3%B3%2C+Z">Zsuzsanna Jank&#xf3;</a>, 
<a href="/search/math?searchtype=author&query=Jo%C3%B3%2C+A">Attila Jo&#xf3;</a>, 
<a href="/search/math?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are looking for a necessary and sufficient condition for three agents with not strictly-positive valuations. Any ideas?
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">A cake allocation is called *strongly-proportional* if it allocates each
agent a piece worth for them strictly more than their fair share of 1/n the
total cake value. It is called *connected* if it allocates each agent a
connected piece. We present a necessary and sufficient condition for the
existence of a strongly-proportional connected cake-allocation among agents
with strictly positive valuations.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15332" title="Abstract">arXiv:2312.15332</a> (cross-list from math.OC) [<a href="/pdf/2312.15332" title="Download PDF">pdf</a>, <a href="/format/2312.15332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benign Nonconvex Landscapes in Optimal and Robust Control, Part I:  Global Optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/math?searchtype=author&query=Pai%2C+C">Chih-fan Pai</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+Y">Yujie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 79 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Direct policy search has achieved great empirical success in reinforcement
learning. Many recent studies have revisited its theoretical foundation for
continuous control, which reveals elegant nonconvex geometry in various
benchmark problems, especially in fully observable state-feedback cases. This
paper considers two fundamental optimal and robust control problems with
partial observability: the Linear Quadratic Gaussian (LQG) control with
stochastic noises, and $\mathcal{H}_\infty$ robust control with adversarial
noises. In the policy space, the former problem is smooth but nonconvex, while
the latter one is nonsmooth and nonconvex. We highlight some interesting and
surprising ``discontinuity'' of LQG and $\mathcal{H}_\infty$ cost functions
around the boundary of their domains. Despite the lack of convexity (and
possibly smoothness), our main results show that for a class of non-degenerate
policies, all Clarke stationary points are globally optimal and there is no
spurious local minimum for both LQG and $\mathcal{H}_\infty$ control. Our proof
techniques rely on a new and unified framework of Extended Convex Lifting
(ECL), which reconciles the gap between nonconvex policy optimization and
convex reformulations. This ECL framework is of independent interest, and we
will discuss its details in Part II of this paper.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15349" title="Abstract">arXiv:2312.15349</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.15349" title="Download PDF">pdf</a>, <a href="/format/2312.15349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A WECC-based Model for Simulating Two-stage Market Clearing with  High-temporal-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zheng%2C+N">Ningkun Zheng</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+B">Bolun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a new open-source model for simulating two-stage market
clearing based on the Western Electricity Coordinating Council Anchor Data Set.
We model accurate two-stage market clearing with day-ahead unit commitment at
hourly resolution and real-time economic dispatch with five-minute resolution.
Both day-ahead unit commitment and real-time economic dispatch can incorporate
look-ahead rolling horizons. The model includes seven market regions and a full
year of data, detailing 2,403 individual generation assets across diverse
energy sources. The year-long simulation demonstrates the capability of our
model to closely reflect the generation and price patterns of the California
ISO. Our sensitivity analysis revealed that extending the ED look-ahead horizon
reduces system costs by up to 0.12%. We expect this new system model to fulfill
the needs of conducting electricity market analysis at finer time granularity
for market designs and emerging technology integration. While we focus on the
western interconnection, the model serves as a base to simulate other two-stage
clearing market locations.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15385" title="Abstract">arXiv:2312.15385</a> (cross-list from q-fin.MF) [<a href="/pdf/2312.15385" title="Download PDF">pdf</a>, <a href="/format/2312.15385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete-Time Mean-Variance Strategy Based on Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Cui%2C+X">Xiangyu Cui</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+X">Xun Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Shi%2C+Y">Yun Shi</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+S">Si Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1904.11392">arXiv:1904.11392</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Finance (q-fin.MF)</span>; Machine Learning (cs.LG); Portfolio Management (q-fin.PM)

</div>
<p class="mathjax">This paper studies a discrete-time mean-variance model based on reinforcement
learning. Compared with its continuous-time counterpart in \cite{zhou2020mv},
the discrete-time model makes more general assumptions about the asset's return
distribution. Using entropy to measure the cost of exploration, we derive the
optimal investment strategy, whose density function is also Gaussian type.
Additionally, we design the corresponding reinforcement learning algorithm.
Both simulation experiments and empirical analysis indicate that our
discrete-time model exhibits better applicability when analyzing real-world
data than the continuous-time model.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15387" title="Abstract">arXiv:2312.15387</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.15387" title="Download PDF">pdf</a>, <a href="/format/2312.15387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotifPiece: A Data-Driven Approach for Effective Motif Extraction and  Molecular Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yu%2C+Z">Zhaoning Yu</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+H">Hongyang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Motif extraction is an important task in motif based molecular representation
learning. Previously, machine learning approaches employing either rule-based
or string-based techniques to extract motifs. Rule-based approaches may extract
motifs that aren't frequent or prevalent within the molecular data, which can
lead to an incomplete understanding of essential structural patterns in
molecules. String-based methods often lose the topological information inherent
in molecules. This can be a significant drawback because topology plays a vital
role in defining the spatial arrangement and connectivity of atoms within a
molecule, which can be critical for understanding its properties and behavior.
In this paper, we develop a data-driven motif extraction technique known as
MotifPiece, which employs statistical measures to define motifs. To
comprehensively evaluate the effectiveness of MotifPiece, we introduce a
heterogeneous learning module. Our model shows an improvement compared to
previously reported models. Additionally, we demonstrate that its performance
can be further enhanced in two ways: first, by incorporating more data to aid
in generating a richer motif vocabulary, and second, by merging multiple
datasets that share enough motifs, allowing for cross-dataset learning.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15389" title="Abstract">arXiv:2312.15389</a> (cross-list from eess.IV) [<a href="/pdf/2312.15389" title="Download PDF">pdf</a>, <a href="/format/2312.15389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TJDR: A High-Quality Diabetic Retinopathy Pixel-Level Annotation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mao%2C+J">Jingxin Mao</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+X">Xiaoyu Ma</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+Y">Yanlong Bi</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Rongqing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diabetic retinopathy (DR), as a debilitating ocular complication,
necessitates prompt intervention and treatment. Despite the effectiveness of
artificial intelligence in aiding DR grading, the progression of research
toward enhancing the interpretability of DR grading through precise lesion
segmentation faces a severe hindrance due to the scarcity of pixel-level
annotated DR datasets. To mitigate this, this paper presents and delineates
TJDR, a high-quality DR pixel-level annotation dataset, which comprises 561
color fundus images sourced from the Tongji Hospital Affiliated to Tongji
University. These images are captured using diverse fundus cameras including
Topcon's TRC-50DX and Zeiss CLARUS 500, exhibit high resolution. For the sake
of adhering strictly to principles of data privacy, the private information of
images is meticulously removed while ensuring clarity in displaying anatomical
structures such as the optic disc, retinal blood vessels, and macular fovea.
The DR lesions are annotated using the Labelme tool, encompassing four
prevalent DR lesions: Hard Exudates (EX), Hemorrhages (HE), Microaneurysms
(MA), and Soft Exudates (SE), labeled respectively from 1 to 4, with 0
representing the background. Significantly, experienced ophthalmologists
conduct the annotation work with rigorous quality assurance, culminating in the
construction of this dataset. This dataset has been partitioned into training
and testing sets and publicly released to contribute to advancements in the DR
lesion segmentation research community.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15408" title="Abstract">arXiv:2312.15408</a> (cross-list from eess.IV) [<a href="/pdf/2312.15408" title="Download PDF">pdf</a>, <a href="/format/2312.15408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perception-Distortion Balanced Super-Resolution: A Multi-Objective  Optimization Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+L">Lingchen Sun</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+J">Jie Liang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shuaizheng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yong%2C+H">Hongwei Yong</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">High perceptual quality and low distortion degree are two important goals in
image restoration tasks such as super-resolution (SR). Most of the existing SR
methods aim to achieve these goals by minimizing the corresponding yet
conflicting losses, such as the $\ell_1$ loss and the adversarial loss.
Unfortunately, the commonly used gradient-based optimizers, such as Adam, are
hard to balance these objectives due to the opposite gradient decent directions
of the contradictory losses. In this paper, we formulate the
perception-distortion trade-off in SR as a multi-objective optimization problem
and develop a new optimizer by integrating the gradient-free evolutionary
algorithm (EA) with gradient-based Adam, where EA and Adam focus on the
divergence and convergence of the optimization directions respectively. As a
result, a population of optimal models with different perception-distortion
preferences is obtained. We then design a fusion network to merge these models
into a single stronger one for an effective perception-distortion trade-off.
Experiments demonstrate that with the same backbone network, the
perception-distortion balanced SR model trained by our method can achieve
better perceptual quality than its competitors while attaining better
reconstruction fidelity. Codes and models can be found at
https://github.com/csslc/EA-Adam.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15421" title="Abstract">arXiv:2312.15421</a> (cross-list from math.FA) [<a href="/pdf/2312.15421" title="Download PDF">pdf</a>, <a href="/ps/2312.15421" title="Download PostScript">ps</a>, <a href="/format/2312.15421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How averaged is the projection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Song%2C+S">Shuang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Projection operators are important in Analysis, Optimization and Algorithm.
It is well known that these operators are firmly nonexpansive. In this paper,
we provide an exact result that sharpens this well-known result. We develop the
theory of averaged operators and provide a lower bound. We give a result on the
avergedness of operator compositions. We also provide some nonlinear examples
to illustrate our results.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15431" title="Abstract">arXiv:2312.15431</a> (cross-list from math.OC) [<a href="/pdf/2312.15431" title="Download PDF">pdf</a>, <a href="/format/2312.15431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Approximations for a Bi-level Formulation of Data-Enabled  Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shang%2C+X">Xu Shang</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Willems' fundamental lemma, which characterizes linear time-invariant
(LTI) systems using input and output trajectories, has found many successful
applications. Combining this with receding horizon control leads to a popular
Data-EnablEd Predictive Control (DeePC) scheme. DeePC is first established for
LTI systems and has been extended and applied for practical systems beyond LTI
settings. However, the relationship between different DeePC variants, involving
regularization and dimension reduction, remains unclear. In this paper, we
first introduce a new bi-level optimization formulation that combines a data
pre-processing step as an inner problem (system identification) and predictive
control as an outer problem (online control). We next discuss a series of
convex approximations by relaxing some hard constraints in the bi-level
optimization as suitable regularization terms, accounting for an implicit
identification. These include some existing DeePC variants as well as two new
variants, for which we establish their equivalence under appropriate settings.
Notably, our analysis reveals a novel variant, called DeePC-SVD-Iter, which has
remarkable empirical performance of direct methods on systems beyond
deterministic LTI settings.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15458" title="Abstract">arXiv:2312.15458</a> (cross-list from stat.ML) [<a href="/pdf/2312.15458" title="Download PDF">pdf</a>, <a href="/ps/2312.15458" title="Download PostScript">ps</a>, <a href="/format/2312.15458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conservative Exploration for Policy Optimization via Off-Policy Policy  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Daoudi%2C+P">Paul Daoudi</a>, 
<a href="/search/stat?searchtype=author&query=Formoso%2C+M">Mathias Formoso</a>, 
<a href="/search/stat?searchtype=author&query=Gaizi%2C+O">Othman Gaizi</a>, 
<a href="/search/stat?searchtype=author&query=Azize%2C+A">Achraf Azize</a>, 
<a href="/search/stat?searchtype=author&query=Garcelon%2C+E">Evrard Garcelon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A precondition for the deployment of a Reinforcement Learning agent to a
real-world system is to provide guarantees on the learning process. While a
learning algorithm will eventually converge to a good policy, there are no
guarantees on the performance of the exploratory policies. We study the problem
of conservative exploration, where the learner must at least be able to
guarantee its performance is at least as good as a baseline policy. We propose
the first conservative provably efficient model-free algorithm for policy
optimization in continuous finite-horizon problems. We leverage importance
sampling techniques to counterfactually evaluate the conservative condition
from the data self-generated by the algorithm. We derive a regret bound and
show that (w.h.p.) the conservative constraint is never violated during
learning. Finally, we leverage these insights to build a general schema for
conservative exploration in DeepRL via off-policy policy evaluation techniques.
We show empirically the effectiveness of our methods.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15463" title="Abstract">arXiv:2312.15463</a> (cross-list from eess.AS) [<a href="/pdf/2312.15463" title="Download PDF">pdf</a>, <a href="/format/2312.15463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent and Relevant: Rethink the Query Embedding in General Sound  Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuanyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Weng%2C+C">Chao Weng</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The query-based audio separation usually employs specific queries to extract
target sources from a mixture of audio signals. Currently, most query-based
separation models need additional networks to obtain query embedding. In this
way, separation model is optimized to be adapted to the distribution of query
embedding. However, query embedding may exhibit mismatches with separation
models due to inconsistent structures and independent information. In this
paper, we present CaRE-SEP, a consistent and relevant embedding network for
general sound separation to encourage a comprehensive reconsideration of query
usage in audio separation. CaRE-SEP alleviates the potential mismatch between
queries and separation in two aspects, including sharing network structure and
sharing feature information. First, a Swin-Unet model with a shared encoder is
conducted to unify query encoding and sound separation into one model,
eliminating the network architecture difference and generating consistent
distribution of query and separation features. Second, by initializing CaRE-SEP
with a pretrained classification network and allowing gradient backpropagation,
the query embedding is optimized to be relevant to the separation feature,
further alleviating the feature mismatch problem. Experimental results indicate
the proposed CaRE-SEP model substantially improves the performance of
separation tasks. Moreover, visualizations validate the potential mismatch and
how CaRE-SEP solves it.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15469" title="Abstract">arXiv:2312.15469</a> (cross-list from stat.ML) [<a href="/pdf/2312.15469" title="Download PDF">pdf</a>, <a href="/format/2312.15469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Estimation of the Central Mean Subspace via Smoothed Gradient  Outer Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yuan%2C+G">Gan Yuan</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+M">Mingyue Xu</a>, 
<a href="/search/stat?searchtype=author&query=Kpotufe%2C+S">Samory Kpotufe</a>, 
<a href="/search/stat?searchtype=author&query=Hsu%2C+D">Daniel Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We consider the problem of sufficient dimension reduction (SDR) for
multi-index models. The estimators of the central mean subspace in prior works
either have slow (non-parametric) convergence rates, or rely on stringent
distributional conditions (e.g., the covariate distribution $P_{\mathbf{X}}$
being elliptical symmetric). In this paper, we show that a fast parametric
convergence rate of form $C_d \cdot n^{-1/2}$ is achievable via estimating the
\emph{expected smoothed gradient outer product}, for a general class of
distribution $P_{\mathbf{X}}$ admitting Gaussian or heavier distributions. When
the link function is a polynomial with a degree of at most $r$ and
$P_{\mathbf{X}}$ is the standard Gaussian, we show that the prefactor depends
on the ambient dimension $d$ as $C_d \propto d^r$.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15487" title="Abstract">arXiv:2312.15487</a> (cross-list from eess.IV) [<a href="/pdf/2312.15487" title="Download PDF">pdf</a>, <a href="/format/2312.15487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BSRAW: Improving Blind RAW Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Conde%2C+M+V">Marcos V. Conde</a>, 
<a href="/search/eess?searchtype=author&query=Vasluianu%2C+F">Florin Vasluianu</a>, 
<a href="/search/eess?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In smartphones and compact cameras, the Image Signal Processor (ISP)
transforms the RAW sensor image into a human-readable sRGB image. Most popular
super-resolution methods depart from a sRGB image and upscale it further,
improving its quality. However, modeling the degradations in the sRGB domain is
complicated because of the non-linear ISP transformations. Despite this known
issue, only a few methods work directly with RAW images and tackle real-world
sensor degradations. We tackle blind image super-resolution in the RAW domain.
We design a realistic degradation pipeline tailored specifically for training
models with raw sensor data. Our approach considers sensor noise, defocus,
exposure, and other common issues. Our BSRAW models trained with our pipeline
can upscale real-scene RAW images and improve their quality. As part of this
effort, we also present a new DSLM dataset and benchmark for this task.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15517" title="Abstract">arXiv:2312.15517</a> (cross-list from math.OC) [<a href="/pdf/2312.15517" title="Download PDF">pdf</a>, <a href="/format/2312.15517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the mixed monotonicity of polynomial functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tahir%2C+A+M">Adam M Tahir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, it is shown that every univariate polynomial function is mixed
monotone globally with a polynomial decomposition function. The decomposition
functions can be constructed from the Gram matrix representation of polynomial
functions. The tightness of polynomial decomposition functions is discussed. An
example is provided to show that polynomial decomposition functions, in
addition to being global decomposition functions, can be much tighter than
local decomposition functions constructed using local Jacobian bounds.
Furthermore, an example is provided to demonstrate the application to reachable
set over-approximation.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15519" title="Abstract">arXiv:2312.15519</a> (cross-list from math.CO) [<a href="/pdf/2312.15519" title="Download PDF">pdf</a>, <a href="/ps/2312.15519" title="Download PostScript">ps</a>, <a href="/format/2312.15519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-kernels in split graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Langlois%2C+H">H&#xe9;l&#xe8;ne Langlois</a>, 
<a href="/search/math?searchtype=author&query=Meunier%2C+F">Fr&#xe9;d&#xe9;ric Meunier</a>, 
<a href="/search/math?searchtype=author&query=Rizzi%2C+R">Romeo Rizzi</a>, 
<a href="/search/math?searchtype=author&query=Vialette%2C+S">St&#xe9;phane Vialette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In a digraph, a quasi-kernel is a subset of vertices that is independent and
such that the shortest path from every vertex to this subset is of length at
most two. The "small quasi-kernel conjecture," proposed by Erd\H{o}s and
Sz\'ekely in 1976, postulates that every sink-free digraph has a quasi-kernel
whose size is within a fraction of the total number of vertices. The conjecture
is even more precise with a $1/2$ ratio, but even with larger ratio, this
property is known to hold only for few classes of graphs.
<br />The focus here is on small quasi-kernels in split graphs. This family of
graphs has played a special role in the study of the conjecture since it was
used to disprove a strengthening that postulated the existence of two disjoint
quasi-kernels. The paper proves that every sink-free split digraph $D$ has a
quasi-kernel of size at most $\frac{3}{4}|V(D)|$, and even of size at most two
when the graph is an orientation of a complete split graph. It is also shown
that computing a quasi-kernel of minimal size in a split digraph is W[2]-hard.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15521" title="Abstract">arXiv:2312.15521</a> (cross-list from math.OC) [<a href="/pdf/2312.15521" title="Download PDF">pdf</a>, <a href="/format/2312.15521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BP-MPC: Optimizing Closed-Loop Performance of MPC using BackPropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zuliani%2C+R">Riccardo Zuliani</a>, 
<a href="/search/math?searchtype=author&query=Balta%2C+E+C">Efe C. Balta</a>, 
<a href="/search/math?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Model predictive control (MPC) is pervasive in research and industry.
However, designing the cost function and the constraints of the MPC to maximize
closed-loop performance remains an open problem. To achieve optimal tuning, we
propose a backpropagation scheme that solves a policy optimization problem with
nonlinear system dynamics and MPC policies. We enforce the system dynamics
using linearization and allow the MPC problem to contain elements that depend
on the current system state and on past MPC solutions. Moreover, we propose a
simple extension that can deal with losses of feasibility. Our approach, unlike
all other methods already present in the literature, enjoys convergence
guarantees.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15566" title="Abstract">arXiv:2312.15566</a> (cross-list from stat.ML) [<a href="/pdf/2312.15566" title="Download PDF">pdf</a>, <a href="/format/2312.15566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Copula-Based Survival Analysis for Dependent Censoring with  Identifiability Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Ling%2C+C+K">Chun Kai Ling</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+X">Xuanhui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appears in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Censoring is the central problem in survival analysis where either the
time-to-event (for instance, death), or the time-tocensoring (such as loss of
follow-up) is observed for each sample. The majority of existing machine
learning-based survival analysis methods assume that survival is conditionally
independent of censoring given a set of covariates; an assumption that cannot
be verified since only marginal distributions is available from the data. The
existence of dependent censoring, along with the inherent bias in current
estimators has been demonstrated in a variety of applications, accentuating the
need for a more nuanced approach. However, existing methods that adjust for
dependent censoring require practitioners to specify the ground truth copula.
This requirement poses a significant challenge for practical applications, as
model misspecification can lead to substantial bias. In this work, we propose a
flexible deep learning-based survival analysis method that simultaneously
accommodate for dependent censoring and eliminates the requirement for
specifying the ground truth copula. We theoretically prove the identifiability
of our model under a broad family of copulas and survival distributions.
Experiments results from a wide range of datasets demonstrate that our approach
successfully discerns the underlying dependency structure and significantly
reduces survival estimation bias when compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15574" title="Abstract">arXiv:2312.15574</a> (cross-list from math.ST) [<a href="/pdf/2312.15574" title="Download PDF">pdf</a>, <a href="/ps/2312.15574" title="Download PostScript">ps</a>, <a href="/format/2312.15574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Rates for Switchback Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jia%2C+S">Su Jia</a>, 
<a href="/search/math?searchtype=author&query=Bhattacharya%2C+S">Sohom Bhattacharya</a>, 
<a href="/search/math?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+C+L">Christina Lee Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Switchback experimental design, wherein a single unit (e.g., a whole system)
is exposed to a single random treatment for interspersed blocks of time,
tackles both cross-unit and temporal interference. Hu and Wager (2022) recently
proposed a treatment-effect estimator that truncates the beginnings of blocks
and established a $T^{-1/3}$ rate for estimating the global average treatment
effect (GATE) in a Markov setting with rapid mixing. They claim this rate is
optimal and suggest focusing instead on a different (and design-dependent)
estimand so as to enjoy a faster rate. For the same design we propose an
alternative estimator that uses the whole block and surprisingly show that it
in fact achieves an estimation rate of $\sqrt{\log T/T}$ for the original
design-independent GATE estimand under the same assumptions.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15575" title="Abstract">arXiv:2312.15575</a> (cross-list from eess.IV) [<a href="/pdf/2312.15575" title="Download PDF">pdf</a>, <a href="/format/2312.15575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Born Series Operator for Biomedical Ultrasound Computed  Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Z">Zhijun Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yihang Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Youjia Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yubing Li</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zuoqiang Shi</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">He Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Ultrasound Computed Tomography (USCT) provides a radiation-free option for
high-resolution clinical imaging. Despite its potential, the computationally
intensive Full Waveform Inversion (FWI) required for tissue property
reconstruction limits its clinical utility. This paper introduces the Neural
Born Series Operator (NBSO), a novel technique designed to speed up wave
simulations, thereby facilitating a more efficient USCT image reconstruction
process through an NBSO-based FWI pipeline. Thoroughly validated on
comprehensive brain and breast datasets, simulated under experimental USCT
conditions, the NBSO proves to be accurate and efficient in both forward
simulation and image reconstruction. This advancement demonstrates the
potential of neural operators in facilitating near real-time USCT
reconstruction, making the clinical application of USCT increasingly viable and
promising.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15595" title="Abstract">arXiv:2312.15595</a> (cross-list from stat.ML) [<a href="/pdf/2312.15595" title="Download PDF">pdf</a>, <a href="/format/2312.15595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Inflated Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wei%2C+H">Haoyu Wei</a>, 
<a href="/search/stat?searchtype=author&query=Wan%2C+R">Runzhe Wan</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/stat?searchtype=author&query=Song%2C+R">Rui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
<p class="mathjax">Many real applications of bandits have sparse non-zero rewards, leading to
slow learning rates. A careful distribution modeling that utilizes
problem-specific structures is known as critical to estimation efficiency in
the statistics literature, yet is under-explored in bandits. To fill the gap,
we initiate the study of zero-inflated bandits, where the reward is modeled as
a classic semi-parametric distribution called zero-inflated distribution. We
carefully design Upper Confidence Bound (UCB) and Thompson Sampling (TS)
algorithms for this specific structure. Our algorithms are suitable for a very
general class of reward distributions, operating under tail assumptions that
are considerably less stringent than the typical sub-Gaussian requirements.
Theoretically, we derive the regret bounds for both the UCB and TS algorithms
for multi-armed bandit, showing that they can achieve rate-optimal regret when
the reward distribution is sub-Gaussian. The superior empirical performance of
the proposed methods is shown via extensive numerical studies.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15638" title="Abstract">arXiv:2312.15638</a> (cross-list from math.OC) [<a href="/pdf/2312.15638" title="Download PDF">pdf</a>, <a href="/format/2312.15638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Aware Control of Discrete-Time Stochastic Systems: Integrating  Kalman Filter and Worst-case CVaR in Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kishida%2C+M">Masako Kishida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes control approaches for discrete-time linear systems
subject to stochastic disturbances. It employs Kalman filter to estimate the
mean and covariance of the state propagation, and the worst-case conditional
value-at-risk (CVaR) to quantify the tail risk using the estimated mean and
covariance. The quantified risk is then integrated into a control barrier
function (CBF) to derive constraints for controller synthesis, addressing tail
risks near safe set boundaries. Two optimization-based control methods are
presented using the obtained constraints for half-space and ellipsoidal safe
sets, respectively. The effectiveness of the obtained results is demonstrated
using numerical simulations.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15665" title="Abstract">arXiv:2312.15665</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.15665" title="Download PDF">pdf</a>, <a href="/format/2312.15665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Modal Contrastive Diffusion Model for Therapeutic Peptide  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yongkang Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+X">Xuan Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+F">Feng Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Xiong%2C+Z">Zhankun Xiong</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Therapeutic peptides represent a unique class of pharmaceutical agents
crucial for the treatment of human diseases. Recently, deep generative models
have exhibited remarkable potential for generating therapeutic peptides, but
they only utilize sequence or structure information alone, which hinders the
performance in generation. In this study, we propose a Multi-Modal Contrastive
Diffusion model (MMCD), fusing both sequence and structure modalities in a
diffusion framework to co-generate novel peptide sequences and structures.
Specifically, MMCD constructs the sequence-modal and structure-modal diffusion
models, respectively, and devises a multi-modal contrastive learning strategy
with intercontrastive and intra-contrastive in each diffusion timestep, aiming
to capture the consistency between two modalities and boost model performance.
The inter-contrastive aligns sequences and structures of peptides by maximizing
the agreement of their embeddings, while the intra-contrastive differentiates
therapeutic and non-therapeutic peptides by maximizing the disagreement of
their sequence/structure embeddings simultaneously. The extensive experiments
demonstrate that MMCD performs better than other state-of-theart deep
generative methods in generating therapeutic peptides across various metrics,
including antimicrobial/anticancer score, diversity, and peptide-docking.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15680" title="Abstract">arXiv:2312.15680</a> (cross-list from math.CO) [<a href="/pdf/2312.15680" title="Download PDF">pdf</a>, <a href="/ps/2312.15680" title="Download PostScript">ps</a>, <a href="/format/2312.15680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bialternant formula for Schur polynomials with repeating variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gonz%C3%A1lez-Serrano%2C+L+A">Luis Angel Gonz&#xe1;lez-Serrano</a>, 
<a href="/search/math?searchtype=author&query=Maximenko%2C+E+A">Egor A. Maximenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider polynomials of the form
$\operatorname{s}_\lambda(y_1^{[\varkappa_1]},\ldots,y_n^{[\varkappa_n]})$,
where $\lambda$ is an integer partition, $\operatorname{s}_\lambda$ is the
Schur polynomial associated to $\lambda$, and $y_j^{[\varkappa_j]}$ denotes
$y_j$ repeated $\varkappa_j$ times. We represent
$\operatorname{s}_\lambda(y_1^{[\varkappa_1]},\ldots,y_n^{[\varkappa_n]})$ as a
quotient whose the denominator is the determinant of the confluent Vandermonde
matrix, and the numerator is the determinant of some generalized confluent
Vandermonde matrix. We give three algebraic proofs of this formula.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15701" title="Abstract">arXiv:2312.15701</a> (cross-list from eess.IV) [<a href="/pdf/2312.15701" title="Download PDF">pdf</a>, <a href="/format/2312.15701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotation Equivariant Proximal Operator for Deep Unfolding Methods in  Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fu%2C+J">Jiahong Fu</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+Q">Qi Xie</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zongben Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The deep unfolding approach has attracted significant attention in computer
vision tasks, which well connects conventional image processing modeling
manners with more recent deep learning techniques. Specifically, by
establishing a direct correspondence between algorithm operators at each
implementation step and network modules within each layer, one can rationally
construct an almost ``white box'' network architecture with high
interpretability. In this architecture, only the predefined component of the
proximal operator, known as a proximal network, needs manual configuration,
enabling the network to automatically extract intrinsic image priors in a
data-driven manner. In current deep unfolding methods, such a proximal network
is generally designed as a CNN architecture, whose necessity has been proven by
a recent theory. That is, CNN structure substantially delivers the
translational invariant image prior, which is the most universally possessed
structural prior across various types of images. However, standard CNN-based
proximal networks have essential limitations in capturing the rotation symmetry
prior, another universal structural prior underlying general images. This
leaves a large room for further performance improvement in deep unfolding
approaches. To address this issue, this study makes efforts to suggest a
high-accuracy rotation equivariant proximal network that effectively embeds
rotation symmetry priors into the deep unfolding framework. Especially, we
deduce, for the first time, the theoretical equivariant error for such a
designed proximal network with arbitrary layers under arbitrary rotation
degrees. This analysis should be the most refined theoretical conclusion for
such error evaluation to date and is also indispensable for supporting the
rationale behind such networks with intrinsic interpretability requirements.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15799" title="Abstract">arXiv:2312.15799</a> (cross-list from stat.ML) [<a href="/pdf/2312.15799" title="Download PDF">pdf</a>, <a href="/format/2312.15799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Conformal Prediction under Data Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Plassier%2C+V">Vincent Plassier</a>, 
<a href="/search/stat?searchtype=author&query=Kotelevskii%2C+N">Nikita Kotelevskii</a>, 
<a href="/search/stat?searchtype=author&query=Rubashevskii%2C+A">Aleksandr Rubashevskii</a>, 
<a href="/search/stat?searchtype=author&query=Noskov%2C+F">Fedor Noskov</a>, 
<a href="/search/stat?searchtype=author&query=Velikanov%2C+M">Maksim Velikanov</a>, 
<a href="/search/stat?searchtype=author&query=Fishkov%2C+A">Alexander Fishkov</a>, 
<a href="/search/stat?searchtype=author&query=Horvath%2C+S">Samuel Horvath</a>, 
<a href="/search/stat?searchtype=author&query=Takac%2C+M">Martin Takac</a>, 
<a href="/search/stat?searchtype=author&query=Moulines%2C+E">Eric Moulines</a>, 
<a href="/search/stat?searchtype=author&query=Panov%2C+M">Maxim Panov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Conformal Prediction (CP) stands out as a robust framework for uncertainty
quantification, which is crucial for ensuring the reliability of predictions.
However, common CP methods heavily rely on data exchangeability, a condition
often violated in practice. Existing approaches for tackling
non-exchangeability lead to methods that are not computable beyond the simplest
examples. This work introduces a new efficient approach to CP that produces
provably valid confidence sets for fairly general non-exchangeable data
distributions. We illustrate the general theory with applications to the
challenging setting of federated learning under data heterogeneity between
agents. Our method allows constructing provably valid personalized prediction
sets for agents in a fully federated way. The effectiveness of the proposed
method is demonstrated in a series of experiments on real-world datasets.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15972" title="Abstract">arXiv:2312.15972</a> (cross-list from eess.IV) [<a href="/pdf/2312.15972" title="Download PDF">pdf</a>, <a href="/format/2312.15972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Self Supervised StyleGAN for Image Annotation and Classification with  Extremely Limited Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hochberg%2C+D+C">Dana Cohen Hochberg</a>, 
<a href="/search/eess?searchtype=author&query=Greenspan%2C+H">Hayit Greenspan</a>, 
<a href="/search/eess?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Medical Imaging
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Medical Imaging, 41(12), Dec. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent success of learning-based algorithms can be greatly attributed to
the immense amount of annotated data used for training. Yet, many datasets lack
annotations due to the high costs associated with labeling, resulting in
degraded performances of deep learning methods. Self-supervised learning is
frequently adopted to mitigate the reliance on massive labeled datasets since
it exploits unlabeled data to learn relevant feature representations. In this
work, we propose SS-StyleGAN, a self-supervised approach for image annotation
and classification suitable for extremely small annotated datasets. This novel
framework adds self-supervision to the StyleGAN architecture by integrating an
encoder that learns the embedding to the StyleGAN latent space, which is
well-known for its disentangled properties. The learned latent space enables
the smart selection of representatives from the data to be labeled for improved
classification performance. We show that the proposed method attains strong
classification results using small labeled datasets of sizes 50 and even 10. We
demonstrate the superiority of our approach for the tasks of COVID-19 and liver
tumor pathology identification.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16002" title="Abstract">arXiv:2312.16002</a> (cross-list from eess.AS) [<a href="/pdf/2312.16002" title="Download PDF">pdf</a>, <a href="/format/2312.16002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The NUS-HLT System for ICASSP2024 ICMC-ASR Grand Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ge%2C+M">Meng Ge</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yizhou Peng</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Yidi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jingru Lin</a>, 
<a href="/search/eess?searchtype=author&query=Ao%2C+J">Junyi Ao</a>, 
<a href="/search/eess?searchtype=author&query=Yildirim%2C+M+S">Mehmet Sinan Yildirim</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haizhou Li</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+M">Mengling Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. 2 pages. For ICMC-ASR-2023 Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper summarizes our team's efforts in both tracks of the ICMC-ASR
Challenge for in-car multi-channel automatic speech recognition. Our submitted
systems for ICMC-ASR Challenge include the multi-channel front-end enhancement
and diarization, training data augmentation, speech recognition modeling with
multi-channel branches. Tested on the offical Eval1 and Eval2 set, our best
system achieves a relative 34.3% improvement in CER and 56.5% improvement in
cpCER, compared to the offical baseline system.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16004" title="Abstract">arXiv:2312.16004</a> (cross-list from stat.AP) [<a href="/pdf/2312.16004" title="Download PDF">pdf</a>, <a href="/format/2312.16004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Gerber-Shiu function in the classical risk model with interest  using collocation method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yu%2C+Z">Zan Yu</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+L">Lianzeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The Gerber-Shiu function is a classical research topic in actuarial
science.However, exact solutions are only available in the literature for very
specific cases where the claim amounts follow distributions such as the
exponential distribution. This presents a longstanding challenge, particularly
from a computational perspective. For the classical risk process in continuous
time, the Gerber-Shiu discounted penalty function satisfies a class of Volterra
integral equations. In this paper, we use the collocation method to compute the
Gerber-Shiu function for risk model with interest. Our methodology demonstrates
that the function can be expressed as a linear algebraic system, which is
straightforward to implement. One major advantage of our approach is that it
does not require any specific distributional assumptions on the claim amounts,
except for mild differentiability and continuity conditions that can be easily
verified. We also examine the convergence orders of the collocation method.
Finally, we present several numerical examples to illustrate the desirable
performance of our proposed method.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16019" title="Abstract">arXiv:2312.16019</a> (cross-list from stat.ML) [<a href="/pdf/2312.16019" title="Download PDF">pdf</a>, <a href="/format/2312.16019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Survival Analysis with Adversarial Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Potter%2C+M">Michael Potter</a>, 
<a href="/search/stat?searchtype=author&query=Maxenti%2C+S">Stefano Maxenti</a>, 
<a href="/search/stat?searchtype=author&query=Everett%2C+M">Michael Everett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, submission to IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Survival Analysis (SA) is about modeling the time for an event of interest to
occur, which has important applications in many fields, including medicine,
defense, finance, and aerospace. Recent work has demonstrated the benefits of
using Neural Networks (NNs) to capture complicated relationships in SA.
However, the datasets used to train these models are often subject to
uncertainty (e.g., noisy measurements, human error), which we show can
substantially degrade the performance of existing techniques. To address this
issue, this work leverages recent advances in NN verification to provide new
algorithms for generating fully parametric survival models that are robust to
such uncertainties. In particular, we introduce a robust loss function for
training the models and use CROWN-IBP regularization to address the
computational challenges with solving the resulting Min-Max problem. To
evaluate the proposed approach, we apply relevant perturbations to publicly
available datasets in the SurvSet repository and compare survival models
against several baselines. We empirically show that Survival Analysis with
Adversarial Regularization (SAWAR) method on average ranks best for dataset
perturbations of varying magnitudes on metrics such as Negative Log Likelihood
(NegLL), Integrated Brier Score (IBS), and Concordance Index (CI), concluding
that adversarial regularization enhances performance in SA. Code:
https://github.com/mlpotter/SAWAR
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16024" title="Abstract">arXiv:2312.16024</a> (cross-list from eess.IV) [<a href="/pdf/2312.16024" title="Download PDF">pdf</a>, <a href="/format/2312.16024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-and-Play Regularization on Magnitude with Deep Priors for 3D  Near-Field MIMO Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oral%2C+O">Okyanus Oral</a>, 
<a href="/search/eess?searchtype=author&query=Oktem%2C+F+S">Figen S. Oktem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Near-field radar imaging systems are recently used in a wide range of
applications, such as medical diagnosis, through-wall imaging, concealed weapon
detection, and nondestructive evaluation. In this paper, we consider the
problem of reconstructing the three-dimensional (3D) complex-valued
reflectivity distribution of the near-field scene from sparse multiple-input
multiple-output (MIMO) array measurements. Using the alternating direction
method of multipliers (ADMM) framework, we solve this inverse problem by
enforcing regularization on the magnitude of the complex-valued reflectivity
distribution. For this, we provide a general expression for the proximal
mapping associated with such regularization functionals. This equivalently
corresponds to the solution of a complex-valued denoising problem which
involves regularization on the magnitude. By utilizing this expression, we
develop a novel and efficient plug-and-play (PnP) reconstruction method that
consists of simple update steps. Due to the success of data-adaptive deep
priors in various imaging problems, we also train a 3D deep denoiser to exploit
within the developed PnP framework for MIMO imaging. The effectiveness of the
developed learning-based PnP approach is illustrated under various compressive
and noisy observation scenarios using both simulated data and experimental
measurements. The performance is also compared with sparsity priors and the
commonly used analytical approaches such as back-projection and Kirchhoff
migration. The results demonstrate that the developed technique not only
provides state-of-the-art reconstruction performance for 3D real-world targets,
but also enables fast computation. Our approach provides a unified general
framework to effectively handle arbitrary regularization on the magnitude of a
complex-valued unknown and is equally applicable to other radar image formation
problems (including SAR).
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16025" title="Abstract">arXiv:2312.16025</a> (cross-list from quant-ph) [<a href="/pdf/2312.16025" title="Download PDF">pdf</a>, <a href="/ps/2312.16025" title="Download PostScript">ps</a>, <a href="/format/2312.16025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Output Length of One-Way State Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hhan%2C+M">Minki Hhan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Morimae%2C+T">Tomoyuki Morimae</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yamakawa%2C+T">Takashi Yamakawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We study output length of one-way state generators (OWSGs) and their weaker
variants.
<br />- Standard OWSGs. Recently, Cavalar et al. (<a href="/abs/2312.08363">arXiv:2312.08363</a>) give OWSGs with
$m$-qubit outputs for any $m=\omega(\log \lambda)$, where $\lambda$ is the
security parameter, and conjecture that there do not exist OWSGs with $O(\log
\log \lambda)$-qubit outputs. We prove their conjecture in a stronger manner by
showing that there do not exist OWSGs with $O(\log \lambda)$-qubit outputs.
This means that their construction is optimal in terms of output length.
<br />- Constant-advantage OWSGs. Let $\epsilon$-OWSGs be a parameterized variant
of OWSGs where a quantum polynomial-time adversary's advantage is at most
$\epsilon$. For any constant $\epsilon&gt;0$, we construct $\epsilon$-OWSGs with
$O(\log \log \lambda)$-qubit outputs assuming the existence of subexponentially
secure OWFs. We show that this is almost tight by proving that there do not
exist $O(1)$-OWSGs with $(\log \log \lambda)/2+O(1)$-qubit outputs.
<br />- Weak OWSGs. We refer to $(1-1/\mathsf{poly}(\lambda))$-OWSGs as weak OWSGs.
We construct weak OWSGs with $m$-qubit outputs for any $m=\omega(1)$ assuming
the existence of exponentially secure injective OWFs with linear expansion. We
show that this is tight by proving that there do not exist weak OWSGs with
$O(1)$-qubit outputs.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16026" title="Abstract">arXiv:2312.16026</a> (cross-list from math.OC) [<a href="/pdf/2312.16026" title="Download PDF">pdf</a>, <a href="/format/2312.16026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic AGV Task Allocation in Intelligent Warehouses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dehghan%2C+A">Arash Dehghan</a>, 
<a href="/search/math?searchtype=author&query=Cevik%2C+M">Mucahit Cevik</a>, 
<a href="/search/math?searchtype=author&query=Bodur%2C+M">Merve Bodur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the integration of Automated Guided Vehicles (AGVs) in
warehouse order picking, a crucial and cost-intensive aspect of warehouse
operations. The booming AGV industry, accelerated by the COVID-19 pandemic, is
witnessing widespread adoption due to its efficiency, reliability, and
cost-effectiveness in automating warehouse tasks. This paper focuses on
enhancing the picker-to-parts system, prevalent in small to medium-sized
warehouses, through the strategic use of AGVs. We discuss the benefits and
applications of AGVs in various warehouse tasks, highlighting their
transformative potential in improving operational efficiency. We examine the
deployment of AGVs by leading companies in the industry, showcasing their
varied functionalities in warehouse management. Addressing the gap in research
on optimizing operational performance in hybrid environments where humans and
AGVs coexist, our study delves into a dynamic picker-to-parts warehouse
scenario. We propose a novel approach Neural Approximate Dynamic Programming
approach for coordinating a mixed team of human and AGV workers, aiming to
maximize order throughput and operational efficiency. This involves innovative
solutions for non-myopic decision making, order batching, and battery
management. We also discuss the integration of advanced robotics technology in
automating the complete order-picking process. Through a comprehensive
numerical study, our work offers valuable insights for managing a heterogeneous
workforce in a hybrid warehouse setting, contributing significantly to the
field of warehouse automation and logistics.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16052" title="Abstract">arXiv:2312.16052</a> (cross-list from math.CO) [<a href="/pdf/2312.16052" title="Download PDF">pdf</a>, <a href="/format/2312.16052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pattern Avoidance for Fibonacci Sequences using $k$-Regular Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Downing%2C+E">Emily Downing</a>, 
<a href="/search/math?searchtype=author&query=Hartung%2C+E">Elizabeth Hartung</a>, 
<a href="/search/math?searchtype=author&query=Williams%2C+A">Aaron Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, submitted to special journal issue for Permutation Patterns 2023 (PP23) in DMTCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Two $k$-ary Fibonacci recurrences are $a_k(n) = a_k(n-1) + k \cdot a_k(n-2)$
and $b_k(n) = k \cdot b_k(n-1) + b_k(n-2)$. We provide a simple proof that
$a_k(n)$ is the number of $k$-regular words over $[n] = \{1,2,\ldots,n\}$ that
avoid patterns $\{121, 123, 132, 213\}$ when using base cases $a_k(0) = a_k(1)
= 1$ for any $k \geq 1$. This was previously proven by Kuba and Panholzer in
the context of Wilf-equivalence for restricted Stirling permutations, and it
creates Simion and Schmidt's classic result on the Fibonacci sequence when
$k=1$, and the Jacobsthal sequence when $k=2$. We complement this theorem by
proving that $b_k(n)$ is the number of $k$-regular words over $[n]$ that avoid
$\{122, 213\}$ with $b_k(0) = b_k(1) = 1$ for any~$k \geq 2$. Finally, we
conjecture that $|Av^{2}_{n}(\underline{121}, 123, 132, 213)| = a_1(n)^2$ for
$n \geq 0$. That is, vincularizing the Stirling pattern in Kuba and Panholzer's
Jacobsthal result gives the Fibonacci-squared numbers.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16082" title="Abstract">arXiv:2312.16082</a> (cross-list from quant-ph) [<a href="/pdf/2312.16082" title="Download PDF">pdf</a>, <a href="/ps/2312.16082" title="Download PostScript">ps</a>, <a href="/format/2312.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Quantum Kalman Decomposition: A Gramian Matrix Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+J">Jinghao Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Z">Zhiyuan Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Petersen%2C+I+R">Ian R. Petersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 2 figures, submitted for publication. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Kalman canonical form for quantum linear systems was derived in
\cite{ZGPG18}. The purpose of this paper is to present an alternative
derivation by means of a Gramian matrix approach. Controllability and
observability Gramian matrices are defined for linear quantum systems, which
are used to characterize various subspaces. Based on these characterizations,
real orthogonal and block symplectic coordinate transformation matrices are
constructed to transform a given quantum linear system to the Kalman canonical
form. An example is used to illustrate the main results.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16139" title="Abstract">arXiv:2312.16139</a> (cross-list from stat.ME) [<a href="/pdf/2312.16139" title="Download PDF">pdf</a>, <a href="/format/2312.16139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly component analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Valla%2C+R">Romain Valla</a>, 
<a href="/search/stat?searchtype=author&query=Mozharovskyi%2C+P">Pavlo Mozharovskyi</a>, 
<a href="/search/stat?searchtype=author&query=d%27Alch%C3%A9-Buc%2C+F">Florence d&#x27;Alch&#xe9;-Buc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 25 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">At the crossway of machine learning and data analysis, anomaly detection aims
at identifying observations that exhibit abnormal behaviour. Be it measurement
errors, disease development, severe weather, production quality default(s)
(items) or failed equipment, financial frauds or crisis events, their on-time
identification and isolation constitute an important task in almost any area of
industry and science. While a substantial body of literature is devoted to
detection of anomalies, little attention is payed to their explanation. This is
the case mostly due to intrinsically non-supervised nature of the task and
non-robustness of the exploratory methods like principal component analysis
(PCA).
<br />We introduce a new statistical tool dedicated for exploratory analysis of
abnormal observations using data depth as a score. Anomaly component analysis
(shortly ACA) is a method that searches a low-dimensional data representation
that best visualises and explains anomalies. This low-dimensional
representation not only allows to distinguish groups of anomalies better than
the methods of the state of the art, but as well provides a -- linear in
variables and thus easily interpretable -- explanation for anomalies. In a
comparative simulation and real-data study, ACA also proves advantageous for
anomaly analysis with respect to methods present in the literature.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16160" title="Abstract">arXiv:2312.16160</a> (cross-list from stat.ME) [<a href="/pdf/2312.16160" title="Download PDF">pdf</a>, <a href="/format/2312.16160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymmPI: Predictive Inference for Data with Group Symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dobriban%2C+E">Edgar Dobriban</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+M">Mengxin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Quantifying the uncertainty of predictions is a core problem in modern
statistics. Methods for predictive inference have been developed under a
variety of assumptions, often -- for instance, in standard conformal prediction
-- relying on the invariance of the distribution of the data under special
groups of transformations such as permutation groups. Moreover, many existing
methods for predictive inference aim to predict unobserved outcomes in
sequences of feature-outcome observations. Meanwhile, there is interest in
predictive inference under more general observation models (e.g., for partially
observed features) and for data satisfying more general distributional
symmetries (e.g., rotationally invariant or coordinate-independent observations
in physics). Here we propose SymmPI, a methodology for predictive inference
when data distributions have general group symmetries in arbitrary observation
models. Our methods leverage the novel notion of distributional equivariant
transformations, which process the data while preserving their distributional
invariances. We show that SymmPI has valid coverage under distributional
invariance and characterize its performance under distribution shift,
recovering recent results as special cases. We apply SymmPI to predict
unobserved values associated to vertices in a network, where the distribution
is unchanged under relabelings that keep the network structure unchanged. In
several simulations in a two-layer hierarchical model, and in an empirical data
analysis example, SymmPI performs favorably compared to existing methods.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 27 Dec 23</h3>
<dl>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1612.02503" title="Abstract">arXiv:1612.02503</a> (replaced) [<a href="/pdf/1612.02503" title="Download PDF">pdf</a>, <a href="/ps/1612.02503" title="Download PostScript">ps</a>, <a href="/format/1612.02503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What do Shannon-type Inequalities, Submodular Width, and Disjunctive  Datalog have to do with one another?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khamis%2C+M+A">Mahmoud Abo Khamis</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hung Q. Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Suciu%2C+D">Dan Suciu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1901.07845" title="Abstract">arXiv:1901.07845</a> (replaced) [<a href="/pdf/1901.07845" title="Download PDF">pdf</a>, <a href="/format/1901.07845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical analysis of a non-clamped dynamic thermoviscoelastic contact  problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartman%2C+P">Piotr Bartman</a>, 
<a href="/search/math?searchtype=author&query=Bartosz%2C+K">Krzysztof Bartosz</a>, 
<a href="/search/math?searchtype=author&query=Jureczka%2C+M">Micha&#x142; Jureczka</a>, 
<a href="/search/math?searchtype=author&query=Szafraniec%2C+P">Pawe&#x142; Szafraniec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1905.07426" title="Abstract">arXiv:1905.07426</a> (replaced) [<a href="/pdf/1905.07426" title="Download PDF">pdf</a>, <a href="/format/1905.07426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error analysis for a fractional-derivative parabolic problem on  quasi-graded meshes using barrier functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kopteva%2C+N">Natalia Kopteva</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+X">Xiangyun Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1905.05070">arXiv:1905.05070</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM J. Numer. Anal., 58 (2020), 1217-1238
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.08031" title="Abstract">arXiv:1908.08031</a> (replaced) [<a href="/pdf/1908.08031" title="Download PDF">pdf</a>, <a href="/format/1908.08031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuSHR: A Low-Cost, Open-Source Robotic Racecar for Education and  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+S+S">Siddhartha S. Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Lancaster%2C+P">Patrick Lancaster</a>, 
<a href="/search/cs?searchtype=author&query=Michalove%2C+J">Johan Michalove</a>, 
<a href="/search/cs?searchtype=author&query=Schmittle%2C+M">Matt Schmittle</a>, 
<a href="/search/cs?searchtype=author&query=Summers%2C+C">Colin Summers</a>, 
<a href="/search/cs?searchtype=author&query=Rockett%2C+M">Matthew Rockett</a>, 
<a href="/search/cs?searchtype=author&query=Scalise%2C+R">Rosario Scalise</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J+R">Joshua R. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Mavrogiannis%2C+C">Christoforos Mavrogiannis</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+F">Fereshteh Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added Rosario Scalise to the author list
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.16453" title="Abstract">arXiv:2006.16453</a> (replaced) [<a href="/pdf/2006.16453" title="Download PDF">pdf</a>, <a href="/ps/2006.16453" title="Download PostScript">ps</a>, <a href="/format/2006.16453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frege&#x27;s theory of types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bentzen%2C+B">Bruno Bentzen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Manuscrito, 46(4), pp. 1-47, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.07007" title="Abstract">arXiv:2008.07007</a> (replaced) [<a href="/pdf/2008.07007" title="Download PDF">pdf</a>, <a href="/format/2008.07007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Representations in Explainable AI: From Theory to Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sokol%2C+K">Kacper Sokol</a>, 
<a href="/search/cs?searchtype=author&query=Flach%2C+P">Peter Flach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.04453" title="Abstract">arXiv:2011.04453</a> (replaced) [<a href="/pdf/2011.04453" title="Download PDF">pdf</a>, <a href="/ps/2011.04453" title="Download PostScript">ps</a>, <a href="/format/2011.04453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved List-Decodability of Reed--Solomon Codes via Tree Packings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zeyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ray Li</a>, 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+C">Chong Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Tamo%2C+I">Itzhak Tamo</a>, 
<a href="/search/cs?searchtype=author&query=Wootters%2C+M">Mary Wootters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to SICOMP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.11816" title="Abstract">arXiv:2012.11816</a> (replaced) [<a href="/pdf/2012.11816" title="Download PDF">pdf</a>, <a href="/ps/2012.11816" title="Download PostScript">ps</a>, <a href="/format/2012.11816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular CT: Unifying Geometry and Representation Learning for  Molecules at Different Scales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yao-Kun Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yaqiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y+I">Yi Isaac Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y+Q">Yi Qin Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3; update figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Soft Condensed Matter (cond-mat.soft)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.03482" title="Abstract">arXiv:2101.03482</a> (replaced) [<a href="/pdf/2101.03482" title="Download PDF">pdf</a>, <a href="/format/2101.03482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Proper Basis for a Zero-dimensional Polynomial Ideal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ma%2C+S">Sheng-Ming Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages. I name the new type of basis in the old version as the proper basis in the new version. The length of the paper is shortened from more than 70 pages to less than 30 pages in its current form. I also add the benchmark testing results to corroborate the impressive efficiency of the proper basis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Symbolic Computation (cs.SC); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12654" title="Abstract">arXiv:2104.12654</a> (replaced) [<a href="/pdf/2104.12654" title="Download PDF">pdf</a>, <a href="/format/2104.12654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger Bounds for Weak Epsilon-Nets in Higher Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubin%2C+N">Natan Rubin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version accepted to STOC 2021. The exponent is corrected in dimension 3, and slightly improved in all dimensions $d\geq 4$. Submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.01340" title="Abstract">arXiv:2106.01340</a> (replaced) [<a href="/pdf/2106.01340" title="Download PDF">pdf</a>, <a href="/ps/2106.01340" title="Download PostScript">ps</a>, <a href="/format/2106.01340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transaction Fee Mechanism Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roughgarden%2C+T">Tim Roughgarden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at Journal of the ACM. Preliminary version appeared in the 22nd ACM Conference on Economics and Computation (EC '21). This academic paper partially overlaps with the longer general-audience report published as <a href="/abs/2012.00854">arXiv:2012.00854</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.10362" title="Abstract">arXiv:2106.10362</a> (replaced) [<a href="/pdf/2106.10362" title="Download PDF">pdf</a>, <a href="/format/2106.10362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jolteon and Ditto: Network-Adaptive Efficient Consensus with  Asynchronous Fallback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gelashvili%2C+R">Rati Gelashvili</a>, 
<a href="/search/cs?searchtype=author&query=Kokoris-Kogias%2C+L">Lefteris Kokoris-Kogias</a>, 
<a href="/search/cs?searchtype=author&query=Sonnino%2C+A">Alberto Sonnino</a>, 
<a href="/search/cs?searchtype=author&query=Spiegelman%2C+A">Alexander Spiegelman</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Z">Zhuolun Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2103.03181">arXiv:2103.03181</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.10918" title="Abstract">arXiv:2106.10918</a> (replaced) [<a href="/pdf/2106.10918" title="Download PDF">pdf</a>, <a href="/format/2106.10918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of Multiple Source Code Representations on Software  Engineering Tasks -- An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swarna%2C+K+C">Karthik Chandra Swarna</a>, 
<a href="/search/cs?searchtype=author&query=Mathews%2C+N+S">Noble Saji Mathews</a>, 
<a href="/search/cs?searchtype=author&query=Vagavolu%2C+D">Dheeraj Vagavolu</a>, 
<a href="/search/cs?searchtype=author&query=Chimalakonda%2C+S">Sridhar Chimalakonda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.14136" title="Abstract">arXiv:2106.14136</a> (replaced) [<a href="/pdf/2106.14136" title="Download PDF">pdf</a>, <a href="/format/2106.14136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Listen As You Wish: Audio based Event Detection via Text-to-Audio  Grounding in Smart Cities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingzhu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yupeng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.13616" title="Abstract">arXiv:2107.13616</a> (replaced) [<a href="/pdf/2107.13616" title="Download PDF">pdf</a>, <a href="/format/2107.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proposal-based Few-shot Sound Event Detection for Speech and  Environmental Sounds with Perceivers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wolters%2C+P">Piper Wolters</a>, 
<a href="/search/eess?searchtype=author&query=Sizemore%2C+L">Logan Sizemore</a>, 
<a href="/search/eess?searchtype=author&query=Daw%2C+C">Chris Daw</a>, 
<a href="/search/eess?searchtype=author&query=Hutchinson%2C+B">Brian Hutchinson</a>, 
<a href="/search/eess?searchtype=author&query=Phillips%2C+L">Lauren Phillips</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated results based on additional experimentation and moved dataset generation prose to stand-alone section
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Neural and Evolutionary Computing (cs.NE); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.00824" title="Abstract">arXiv:2108.00824</a> (replaced) [<a href="/pdf/2108.00824" title="Download PDF">pdf</a>, <a href="/format/2108.00824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ising Game on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Leonidov%2C+A">Andrey Leonidov</a>, 
<a href="/search/physics?searchtype=author&query=Savvateev%2C+A">Alexey Savvateev</a>, 
<a href="/search/physics?searchtype=author&query=Semenov%2C+A+G">Andrew G. Semenov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/1912.09584">arXiv:1912.09584</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.01537" title="Abstract">arXiv:2109.01537</a> (replaced) [<a href="/pdf/2109.01537" title="Download PDF">pdf</a>, <a href="/format/2109.01537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gkoumas%2C+D">Dimitris Gkoumas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tsakalidis%2C+A">Adam Tsakalidis</a>, 
<a href="/search/cs?searchtype=author&query=Wolters%2C+M">Maria Wolters</a>, 
<a href="/search/cs?searchtype=author&query=Zubiaga%2C+A">Arkaitz Zubiaga</a>, 
<a href="/search/cs?searchtype=author&query=Purver%2C+M">Matthew Purver</a>, 
<a href="/search/cs?searchtype=author&query=Liakata%2C+M">Maria Liakata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.01627" title="Abstract">arXiv:2109.01627</a> (replaced) [<a href="/pdf/2109.01627" title="Download PDF">pdf</a>, <a href="/format/2109.01627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interplay between Self-Driving Cars and Public Transportation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lanzetti%2C+N">Nicolas Lanzetti</a>, 
<a href="/search/eess?searchtype=author&query=Schiffer%2C+M">Maximilian Schiffer</a>, 
<a href="/search/eess?searchtype=author&query=Ostrovsky%2C+M">Michael Ostrovsky</a>, 
<a href="/search/eess?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the IEEE Transactions on Control of Network Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.07073" title="Abstract">arXiv:2109.07073</a> (replaced) [<a href="/pdf/2109.07073" title="Download PDF">pdf</a>, <a href="/format/2109.07073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Globally Consistent 3D LiDAR Mapping with GPU-accelerated GICP Matching  Cost Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koide%2C+K">Kenji Koide</a>, 
<a href="/search/cs?searchtype=author&query=Yokozuka%2C+M">Masashi Yokozuka</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+S">Shuji Oishi</a>, 
<a href="/search/cs?searchtype=author&query=Banno%2C+A">Atsuhiko Banno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letters, Video: <a href="https://youtu.be/TarRKF_Xd2E">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.12679" title="Abstract">arXiv:2109.12679</a> (replaced) [<a href="/pdf/2109.12679" title="Download PDF">pdf</a>, <a href="/format/2109.12679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Be More Active! Understanding the Differences between Mean and Sampled  Representations of Variational Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonheme%2C+L">Lisa Bonheme</a>, 
<a href="/search/cs?searchtype=author&query=Grzes%2C+M">Marek Grzes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the main paper of 20 pages plus an appendix; 29 pages in total. Published as a JMLR article. The final version is available at <a href="https://jmlr.org/papers/v24/21-1145.html">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research 24 (2023): 1-30
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.04941" title="Abstract">arXiv:2111.04941</a> (replaced) [<a href="/pdf/2111.04941" title="Download PDF">pdf</a>, <a href="/format/2111.04941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving PDE-constrained Control Problems Using Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hwang%2C+R">Rakhoon Hwang</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+J+Y">Jae Yong Lee</a>, 
<a href="/search/math?searchtype=author&query=Shin%2C+J+Y">Jin Young Shin</a>, 
<a href="/search/math?searchtype=author&query=Hwang%2C+H+J">Hyung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures. Published as a conference paper at Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05486" title="Abstract">arXiv:2111.05486</a> (replaced) [<a href="/pdf/2111.05486" title="Download PDF">pdf</a>, <a href="/format/2111.05486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncoupled Bandit Learning towards Rationalizability: Benchmarks,  Barriers, and Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jibang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fan Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.07434" title="Abstract">arXiv:2112.07434</a> (replaced) [<a href="/pdf/2112.07434" title="Download PDF">pdf</a>, <a href="/format/2112.07434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Limits of Natural Language Inference Based Setup for  Few-Shot Intent Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ayush Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+V">Vijit Malik</a>, 
<a href="/search/cs?searchtype=author&query=Vepa%2C+J">Jithendra Vepa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> At Interspeech 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.05759" title="Abstract">arXiv:2201.05759</a> (replaced) [<a href="/pdf/2201.05759" title="Download PDF">pdf</a>, <a href="/format/2201.05759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairIF: Boosting Fairness in Deep Learning via Influence Functions with  Validation Set Sensitive Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07379" title="Abstract">arXiv:2201.07379</a> (replaced) [<a href="/pdf/2201.07379" title="Download PDF">pdf</a>, <a href="/ps/2201.07379" title="Download PostScript">ps</a>, <a href="/format/2201.07379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UxNB-Enabled Cell-Free Massive MIMO with HAPS-Assisted Sub-THz  Backhauling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+O">Omid Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, Accepted for publication at IEEE TVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.13393" title="Abstract">arXiv:2202.13393</a> (replaced) [<a href="/pdf/2202.13393" title="Download PDF">pdf</a>, <a href="/format/2202.13393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransKD: Transformer Knowledge Distillation for Efficient Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Roitberg%2C+A">Alina Roitberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code is publicly available at <a href="https://github.com/RuipingL/TransKD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00526" title="Abstract">arXiv:2203.00526</a> (replaced) [<a href="/pdf/2203.00526" title="Download PDF">pdf</a>, <a href="/format/2203.00526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Latent Space Optimization of Generative Molecular Design  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abeer%2C+A+N+M+N">A N M Nafiz Abeer</a>, 
<a href="/search/cs?searchtype=author&query=Urban%2C+N">Nathan Urban</a>, 
<a href="/search/cs?searchtype=author&query=Weil%2C+M+R">M Ryan Weil</a>, 
<a href="/search/cs?searchtype=author&query=Alexander%2C+F+J">Francis J. Alexander</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+B">Byung-Jun Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01077" title="Abstract">arXiv:2203.01077</a> (replaced) [<a href="/pdf/2203.01077" title="Download PDF">pdf</a>, <a href="/ps/2203.01077" title="Download PostScript">ps</a>, <a href="/format/2203.01077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Gap between Training Data and Deployed Environment by  On-Device Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sunaga%2C+K">Kazuki Sunaga</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+M">Masaaki Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Matsutani%2C+H">Hiroki Matsutani</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Micro (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.02466" title="Abstract">arXiv:2203.02466</a> (replaced) [<a href="/pdf/2203.02466" title="Download PDF">pdf</a>, <a href="/format/2203.02466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Opinion Formation and Decision Making Under Communication Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kayaalp%2C+M">Mert Kayaalp</a>, 
<a href="/search/eess?searchtype=author&query=Bordignon%2C+V">Virginia Bordignon</a>, 
<a href="/search/eess?searchtype=author&query=Sayed%2C+A+H">Ali H. Sayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14064" title="Abstract">arXiv:2203.14064</a> (replaced) [<a href="/pdf/2203.14064" title="Download PDF">pdf</a>, <a href="/format/2203.14064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BARGAIN-MATCH: A Game Theoretical Approach for Resource Allocation and  Task Offloading in Vehicular Edge Computing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zemin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Geng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Dongpu Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.10789" title="Abstract">arXiv:2204.10789</a> (replaced) [<a href="/pdf/2204.10789" title="Download PDF">pdf</a>, <a href="/ps/2204.10789" title="Download PostScript">ps</a>, <a href="/format/2204.10789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of Locally Tight Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fandinno%2C+J">Jorge Fandinno</a>, 
<a href="/search/cs?searchtype=author&query=Lifschitz%2C+V">Vladimir Lifschitz</a>, 
<a href="/search/cs?searchtype=author&query=Temple%2C+N">Nathan Temple</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration for publication in Theory and Practice of Logic Programming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01515" title="Abstract">arXiv:2206.01515</a> (replaced) [<a href="/pdf/2206.01515" title="Download PDF">pdf</a>, <a href="/format/2206.01515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Deep Learning via Decision Boundary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shiye Lei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fengxiang He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TNNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14911" title="Abstract">arXiv:2206.14911</a> (replaced) [<a href="/pdf/2206.14911" title="Download PDF">pdf</a>, <a href="/format/2206.14911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Weight Euclidean $(1+\varepsilon)$-Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B3th%2C+C+D">Csaba D. T&#xf3;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 9 figures. An extended abstract appeared in the Proceedings of WG 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00515" title="Abstract">arXiv:2207.00515</a> (replaced) [<a href="/pdf/2207.00515" title="Download PDF">pdf</a>, <a href="/ps/2207.00515" title="Download PostScript">ps</a>, <a href="/format/2207.00515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Structure of Hypergraphs Arising in Cellular Mobile Communication  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+A">Ashwin Ganesan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06062" title="Abstract">arXiv:2207.06062</a> (replaced) [<a href="/pdf/2207.06062" title="Download PDF">pdf</a>, <a href="/format/2207.06062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably stable learning control of linear dynamics with multiplicative  noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coppens%2C+P">Peter Coppens</a>, 
<a href="/search/math?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06339" title="Abstract">arXiv:2207.06339</a> (replaced) [<a href="/pdf/2207.06339" title="Download PDF">pdf</a>, <a href="/format/2207.06339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning robust marking policies for adaptive mesh refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gillette%2C+A">Andrew Gillette</a>, 
<a href="/search/math?searchtype=author&query=Keith%2C+B">Brendan Keith</a>, 
<a href="/search/math?searchtype=author&query=Petrides%2C+S">Socratis Petrides</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07416" title="Abstract">arXiv:2207.07416</a> (replaced) [<a href="/pdf/2207.07416" title="Download PDF">pdf</a>, <a href="/ps/2207.07416" title="Download PostScript">ps</a>, <a href="/format/2207.07416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Incompleteness of Hilbert System for a Combination of Classical  and Intuitionistic Propositional Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toyooka%2C+M">Masanobu Toyooka</a>, 
<a href="/search/cs?searchtype=author&query=Sano%2C+K">Katsuhiko Sano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08143" title="Abstract">arXiv:2207.08143</a> (replaced) [<a href="/pdf/2207.08143" title="Download PDF">pdf</a>, <a href="/format/2207.08143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can large language models reason about medical questions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%C3%A9vin%2C+V">Valentin Li&#xe9;vin</a>, 
<a href="/search/cs?searchtype=author&query=Hother%2C+C+E">Christoffer Egeberg Hother</a>, 
<a href="/search/cs?searchtype=author&query=Motzfeldt%2C+A+G">Andreas Geert Motzfeldt</a>, 
<a href="/search/cs?searchtype=author&query=Winther%2C+O">Ole Winther</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 23 figures. v1: results using InstructGPT, v2.0: added the Codex experiments, v2.1: added the missing test MedMCQA results for Codex 5-shot CoT and using k=100 samples, v3.0: added results for open source models -- ready for publication (final version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08757" title="Abstract">arXiv:2207.08757</a> (replaced) [<a href="/pdf/2207.08757" title="Download PDF">pdf</a>, <a href="/format/2207.08757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preventing Inferences through Data Dependencies on Sensitive Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pappachan%2C+P">Primal Pappachan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shufan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xi He</a>, 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+S">Sharad Mehrotra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper accepted at 48th International Conference on Very Large Databases (VLDB 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10438" title="Abstract">arXiv:2207.10438</a> (replaced) [<a href="/e-print/2207.10438" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Prior Knowledge into Reinforcement Learning for Soft  Tissue Manipulation with Autonomous Grasping Point Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xian He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shanlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+B">Bo Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript requires major revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14539" title="Abstract">arXiv:2207.14539</a> (replaced) [<a href="/pdf/2207.14539" title="Download PDF">pdf</a>, <a href="/format/2207.14539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training General Trajectory Embeddings with Maximum Multi-view  Entropy Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Huaiyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shengnan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jilin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, accepted by IEEE Trans. on Knowledge and Data Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14653" title="Abstract">arXiv:2207.14653</a> (replaced) [<a href="/pdf/2207.14653" title="Download PDF">pdf</a>, <a href="/format/2207.14653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble forecasts in reproducing kernel Hilbert space family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Duf%C3%A9e%2C+B">Benjamin Duf&#xe9;e</a>, 
<a href="/search/math-ph?searchtype=author&query=Hug%2C+B">B&#xe9;renger Hug</a>, 
<a href="/search/math-ph?searchtype=author&query=M%C3%A9min%2C+E">Etienne M&#xe9;min</a>, 
<a href="/search/math-ph?searchtype=author&query=Tissot%2C+G">Gilles Tissot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07316" title="Abstract">arXiv:2208.07316</a> (replaced) [<a href="/pdf/2208.07316" title="Download PDF">pdf</a>, <a href="/format/2208.07316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MENLI: Robust Evaluation Metrics from Natural Language Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Eger%2C+S">Steffen Eger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TACL 2023 Camera-ready version; updated after proofreading by the journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11464" title="Abstract">arXiv:2208.11464</a> (replaced) [<a href="/pdf/2208.11464" title="Download PDF">pdf</a>, <a href="/format/2208.11464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FactMix: Using a Few Labeled In-domain Examples to Generalize to  Cross-domain Named Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lifan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wenyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by COLING 2022, oral paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02442" title="Abstract">arXiv:2209.02442</a> (replaced) [<a href="/pdf/2209.02442" title="Download PDF">pdf</a>, <a href="/format/2209.02442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimCLF: A Simple Contrastive Learning Framework for Function-level  Binary Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=RuiJin%2C+S">Sun RuiJin</a>, 
<a href="/search/cs?searchtype=author&query=Shize%2C+G">Guo Shize</a>, 
<a href="/search/cs?searchtype=author&query=Jinhong%2C+G">Guo Jinhong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Li Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dazhi%2C+Z">Zhan Dazhi</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Sun Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhisong%2C+P">Pan Zhisong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02535" title="Abstract">arXiv:2209.02535</a> (replaced) [<a href="/pdf/2209.02535" title="Download PDF">pdf</a>, <a href="/format/2209.02535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Transformers in Embedding Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dar%2C+G">Guy Dar</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09866" title="Abstract">arXiv:2209.09866</a> (replaced) [<a href="/pdf/2209.09866" title="Download PDF">pdf</a>, <a href="/format/2209.09866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchy of Nondeterminism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radi%2C+B+A">Bader Abu Radi</a>, 
<a href="/search/cs?searchtype=author&query=Kupferman%2C+O">Orna Kupferman</a>, 
<a href="/search/cs?searchtype=author&query=Leshkowitz%2C+O">Ofer Leshkowitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 6 figures, added a section about MDPs and GFM automata
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13820" title="Abstract">arXiv:2209.13820</a> (replaced) [<a href="/pdf/2209.13820" title="Download PDF">pdf</a>, <a href="/format/2209.13820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-order accurate multi-sub-step implicit integration algorithms with  dissipation control for second-order hyperbolic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jinze Li</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hua Li</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+K">Kaiping Yu</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 27 figures, and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02215" title="Abstract">arXiv:2210.02215</a> (replaced) [<a href="/pdf/2210.02215" title="Download PDF">pdf</a>, <a href="/ps/2210.02215" title="Download PostScript">ps</a>, <a href="/format/2210.02215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Statistical Complexity of Estimation and Testing under Privacy  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lalanne%2C+C">Cl&#xe9;ment Lalanne</a> (DANTE, OCKHAM), 
<a href="/search/cs?searchtype=author&query=Garivier%2C+A">Aur&#xe9;lien Garivier</a> (UMPA-ENSL), 
<a href="/search/cs?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a> (DANTE, OCKHAM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research Journal, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03087" title="Abstract">arXiv:2210.03087</a> (replaced) [<a href="/pdf/2210.03087" title="Download PDF">pdf</a>, <a href="/format/2210.03087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krantz%2C+J">Jacob Krantz</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Shurjo Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Corso%2C+J">Jason Corso</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+P">Peter Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Stefan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04026" title="Abstract">arXiv:2210.04026</a> (replaced) [<a href="/pdf/2210.04026" title="Download PDF">pdf</a>, <a href="/format/2210.04026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Generalizable 6D Pose Tracking of an In-Hand Object with  Tactile Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaomeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haocheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08415" title="Abstract">arXiv:2210.08415</a> (replaced) [<a href="/pdf/2210.08415" title="Download PDF">pdf</a>, <a href="/format/2210.08415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Accuracy for the Training of DNNs Via the Uniform Doubling  Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shmalo%2C+Y">Yitzchak Shmalo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12723" title="Abstract">arXiv:2210.12723</a> (replaced) [<a href="/pdf/2210.12723" title="Download PDF">pdf</a>, <a href="/ps/2210.12723" title="Download PostScript">ps</a>, <a href="/format/2210.12723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Faithful Deep Sensitivity Estimation for Accelerated Magnetic  Resonance Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+H">Haoming Fang</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+B">Boxuan Shi</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+L">Lijun Bao</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Liuhong Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jianjun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+W">Wenping Wei</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jianzhong Lin</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+D">Di Guo</a>, 
<a href="/search/eess?searchtype=author&query=Qu%2C+X">Xiaobo Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16511" title="Abstract">arXiv:2210.16511</a> (replaced) [<a href="/pdf/2210.16511" title="Download PDF">pdf</a>, <a href="/format/2210.16511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Uniform Approach to Compare Architectures in Decentralized  Discrete-Event Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ritsuka%2C+K">K. Ritsuka</a> (1), 
<a href="/search/eess?searchtype=author&query=Rudie%2C+K">Karen Rudie</a> (1) ((1) Queen&#x27;s University, Kingston, Canada)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04218" title="Abstract">arXiv:2211.04218</a> (replaced) [<a href="/pdf/2211.04218" title="Download PDF">pdf</a>, <a href="/format/2211.04218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustered Federated Learning based on Nonconvex Pairwise Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07206" title="Abstract">arXiv:2211.07206</a> (replaced) [<a href="/pdf/2211.07206" title="Download PDF">pdf</a>, <a href="/format/2211.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior:  From Theory to Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rothfuss%2C+J">Jonas Rothfuss</a>, 
<a href="/search/stat?searchtype=author&query=Josifoski%2C+M">Martin Josifoski</a>, 
<a href="/search/stat?searchtype=author&query=Fortuin%2C+V">Vincent Fortuin</a>, 
<a href="/search/stat?searchtype=author&query=Krause%2C+A">Andreas Krause</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> JMLR, 62 pages, text overlap with <a href="/abs/2002.05551">arXiv:2002.05551</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research (24), 2023, 1-62
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13929" title="Abstract">arXiv:2211.13929</a> (replaced) [<a href="/pdf/2211.13929" title="Download PDF">pdf</a>, <a href="/format/2211.13929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XKD: Cross-modal Knowledge Distillation with Domain Alignment for Video  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+P">Pritam Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01792" title="Abstract">arXiv:2212.01792</a> (replaced) [<a href="/pdf/2212.01792" title="Download PDF">pdf</a>, <a href="/ps/2212.01792" title="Download PostScript">ps</a>, <a href="/format/2212.01792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification by sparse additive models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Abramovich%2C+F">Felix Abramovich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02758" title="Abstract">arXiv:2212.02758</a> (replaced) [<a href="/pdf/2212.02758" title="Download PDF">pdf</a>, <a href="/format/2212.02758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Data Heterogeneity in Federated Learning with Class Prototypes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yutong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at AAAI 2023. This is a technical report version that contains an appendix with additional details about experiments and proofs for technical results. Grant information is also added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05259" title="Abstract">arXiv:2212.05259</a> (replaced) [<a href="/pdf/2212.05259" title="Download PDF">pdf</a>, <a href="/format/2212.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Real-time Learning of Dynamical Systems from Noisy Streaming  Data: A Koopman Operator Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sinha%2C+S">S. Sinha</a>, 
<a href="/search/math?searchtype=author&query=Nandanoori%2C+S+P">Sai P. Nandanoori</a>, 
<a href="/search/math?searchtype=author&query=Barajas-Solano%2C+D">David Barajas-Solano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07203" title="Abstract">arXiv:2212.07203</a> (replaced) [<a href="/pdf/2212.07203" title="Download PDF">pdf</a>, <a href="/format/2212.07203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision-free Source Seeking Control Methods for Unicycle Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tinghua Li</a>, 
<a href="/search/cs?searchtype=author&query=Jayawardhana%2C+B">Bayu Jayawardhana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08965" title="Abstract">arXiv:2212.08965</a> (replaced) [<a href="/pdf/2212.08965" title="Download PDF">pdf</a>, <a href="/format/2212.08965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed Neural Networks with Periodic Activation Functions for  Solute Transport in Heterogeneous Porous Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faroughi%2C+S+A">Salah A Faroughi</a>, 
<a href="/search/cs?searchtype=author&query=Soltanmohammad%2C+R">Ramin Soltanmohammad</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+P">Pingki Datta</a>, 
<a href="/search/cs?searchtype=author&query=Mahjour%2C+S+K">Seyed Kourosh Mahjour</a>, 
<a href="/search/cs?searchtype=author&query=Faroughi%2C+S">Shirko Faroughi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10368" title="Abstract">arXiv:2212.10368</a> (replaced) [<a href="/pdf/2212.10368" title="Download PDF">pdf</a>, <a href="/format/2212.10368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Event Modeling: Self-Supervised Pretraining for Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klenk%2C+S">Simon Klenk</a>, 
<a href="/search/cs?searchtype=author&query=Bonello%2C+D">David Bonello</a>, 
<a href="/search/cs?searchtype=author&query=Koestler%2C+L">Lukas Koestler</a>, 
<a href="/search/cs?searchtype=author&query=Araslanov%2C+N">Nikita Araslanov</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at WACV 2024. Code: <a href="https://github.com/tum-vision/mem">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10522" title="Abstract">arXiv:2212.10522</a> (replaced) [<a href="/pdf/2212.10522" title="Download PDF">pdf</a>, <a href="/format/2212.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers Go for the LOLs: Generating (Humourous) Titles from  Scientific Abstracts End-to-End
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Eger%2C+S">Steffen Eger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Eval4NLP 2023 Camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14521" title="Abstract">arXiv:2212.14521</a> (replaced) [<a href="/pdf/2212.14521" title="Download PDF">pdf</a>, <a href="/ps/2212.14521" title="Download PostScript">ps</a>, <a href="/format/2212.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative hulls and quantum codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderson%2C+S+E">Sarah E. Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Camps-Moreno%2C+E">Eduardo Camps-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+H+H">Hiram H. L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+G+L">Gretchen L. Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>, 
<a href="/search/cs?searchtype=author&query=Soprunov%2C+I">Ivan Soprunov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01829" title="Abstract">arXiv:2301.01829</a> (replaced) [<a href="/pdf/2301.01829" title="Download PDF">pdf</a>, <a href="/ps/2301.01829" title="Download PostScript">ps</a>, <a href="/format/2301.01829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> t-SMILES: A Scalable Fragment-based Molecular Representation Framework  for De Novo Molecule Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Juan-Ni Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Li-Juan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hai-Long Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Ru-Qin Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04576" title="Abstract">arXiv:2301.04576</a> (replaced) [<a href="/pdf/2301.04576" title="Download PDF">pdf</a>, <a href="/format/2301.04576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision-free Source Seeking and Flocking Control of Multi-agents with  Connectivity Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tinghua Li</a>, 
<a href="/search/eess?searchtype=author&query=Jayawardhana%2C+B">Bayu Jayawardhana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05603" title="Abstract">arXiv:2301.05603</a> (replaced) [<a href="/pdf/2301.05603" title="Download PDF">pdf</a>, <a href="/format/2301.05603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shiye Lei</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Pattern Analysis and Machine Intelligence (
  Volume: 46, Issue: 1, January 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07695" title="Abstract">arXiv:2301.07695</a> (replaced) [<a href="/pdf/2301.07695" title="Download PDF">pdf</a>, <a href="/format/2301.07695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyubok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Hyeonji Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Seongsu Bae</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yeonsu Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Woncheol Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Seongjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jong-Yeup Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at NeurIPS 2022 (Track on Datasets and Benchmarks)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10737" title="Abstract">arXiv:2301.10737</a> (replaced) [<a href="/pdf/2301.10737" title="Download PDF">pdf</a>, <a href="/format/2301.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Control of Partial Differential Equations Using  Convolutional Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peitz%2C+S">Sebastian Peitz</a>, 
<a href="/search/cs?searchtype=author&query=Stenner%2C+J">Jan Stenner</a>, 
<a href="/search/cs?searchtype=author&query=Chidananda%2C+V">Vikas Chidananda</a>, 
<a href="/search/cs?searchtype=author&query=Wallscheid%2C+O">Oliver Wallscheid</a>, 
<a href="/search/cs?searchtype=author&query=Brunton%2C+S+L">Steven L. Brunton</a>, 
<a href="/search/cs?searchtype=author&query=Taira%2C+K">Kunihiko Taira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10923" title="Abstract">arXiv:2301.10923</a> (replaced) [<a href="/pdf/2301.10923" title="Download PDF">pdf</a>, <a href="/format/2301.10923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust Region-Based Safe Distributional Reinforcement Learning for  Multiple Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dohyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Songhwai Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11798" title="Abstract">arXiv:2301.11798</a> (replaced) [<a href="/pdf/2301.11798" title="Download PDF">pdf</a>, <a href="/format/2301.11798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedSegDiff-V2: Diffusion based Medical Image Segmentation with  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Junde Wu</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Min Xu</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Y">Yueming Jin</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code will be released at <a href="https://github.com/KidsWithTokens/MedSegDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11923" title="Abstract">arXiv:2301.11923</a> (replaced) [<a href="/pdf/2301.11923" title="Download PDF">pdf</a>, <a href="/format/2301.11923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information loss from dimensionality reduction in 5D-Gaussian spectral  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Schelle%2C+A">A. Schelle</a>, 
<a href="/search/physics?searchtype=author&query=L%C3%BCling%2C+H">H. L&#xfc;ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Scholarly article on arXiv (2023). Whitepaper on Github
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12363" title="Abstract">arXiv:2301.12363</a> (replaced) [<a href="/pdf/2301.12363" title="Download PDF">pdf</a>, <a href="/format/2301.12363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuralKalman: A Learnable Kalman Filter for Acoustic Echo Cancellation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Meng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">DeLiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The term of the algorithm is renamed because it conflicts with an existing KalmanNet algorithm proposed by Revach et. al. (<a href="/abs/2107.10043">arXiv:2107.10043</a>); Accepted by ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13335" title="Abstract">arXiv:2301.13335</a> (replaced) [<a href="/pdf/2301.13335" title="Download PDF">pdf</a>, <a href="/format/2301.13335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Large Language Model Enhanced Pseudo 3D Perception Framework  for Visual Commonsense Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01477" title="Abstract">arXiv:2302.01477</a> (replaced) [<a href="/pdf/2302.01477" title="Download PDF">pdf</a>, <a href="/ps/2302.01477" title="Download PostScript">ps</a>, <a href="/format/2302.01477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reduction-based Framework for Sequential Decision Making with Delayed  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunchang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01633" title="Abstract">arXiv:2302.01633</a> (replaced) [<a href="/pdf/2302.01633" title="Download PDF">pdf</a>, <a href="/format/2302.01633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Sequential Split Learning on Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yipeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinchen Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02778" title="Abstract">arXiv:2302.02778</a> (replaced) [<a href="/pdf/2302.02778" title="Download PDF">pdf</a>, <a href="/format/2302.02778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reversible random number generation for adjoint Monte Carlo simulation  of the heat equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=L%C3%B8vbak%2C+E">Emil L&#xf8;vbak</a>, 
<a href="/search/math?searchtype=author&query=Blondeel%2C+F">Fr&#xe9;d&#xe9;ric Blondeel</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+A">Adam Lee</a>, 
<a href="/search/math?searchtype=author&query=Vanroye%2C+L">Lander Vanroye</a>, 
<a href="/search/math?searchtype=author&query=Van+Barel%2C+A">Andreas Van Barel</a>, 
<a href="/search/math?searchtype=author&query=Samaey%2C+G">Giovanni Samaey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, accepted for the proceedings of MCQMC22, minor rephrasing upon reviewer suggestion and corrections in acknowledgements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04178" title="Abstract">arXiv:2302.04178</a> (replaced) [<a href="/pdf/2302.04178" title="Download PDF">pdf</a>, <a href="/format/2302.04178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with  GFlowNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atanackovic%2C+L">Lazar Atanackovic</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+A">Alexander Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+L+J">Leo J. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Hartford%2C+J">Jason Hartford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04452" title="Abstract">arXiv:2302.04452</a> (replaced) [<a href="/pdf/2302.04452" title="Download PDF">pdf</a>, <a href="/format/2302.04452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Information-Theoretic Analysis of Nonstationary Bandit Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Seungki Min</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+D">Daniel Russo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06943" title="Abstract">arXiv:2302.06943</a> (replaced) [<a href="/pdf/2302.06943" title="Download PDF">pdf</a>, <a href="/format/2302.06943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Statistical Estimation of Many Quantiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lalanne%2C+C">Cl&#xe9;ment Lalanne</a> (ENS de Lyon, DANTE, OCKHAM), 
<a href="/search/stat?searchtype=author&query=Garivier%2C+A">Aur&#xe9;lien Garivier</a> (UMPA-ENSL, MC2), 
<a href="/search/stat?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a> (DANTE, OCKHAM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICML 2023 - 40th International Conference on Machine Learning, Jul
  2023, Honolulu, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06961" title="Abstract">arXiv:2302.06961</a> (replaced) [<a href="/pdf/2302.06961" title="Download PDF">pdf</a>, <a href="/format/2302.06961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical  Awareness for Robust Fovea Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Sifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jionglong Su</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaowei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+K">Kang Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07409" title="Abstract">arXiv:2302.07409</a> (replaced) [<a href="/pdf/2302.07409" title="Download PDF">pdf</a>, <a href="/format/2302.07409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Learning Theory Beyond Batch Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohan%2C+P">Preetham Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures, 2 tables; v4: entirely reorganized paper with more detailed proofs; handles the adversary-provides-a-distribution model independently;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Quantum Physics (quant-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08005" title="Abstract">arXiv:2302.08005</a> (replaced) [<a href="/pdf/2302.08005" title="Download PDF">pdf</a>, <a href="/format/2302.08005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slapo: A Schedule Language for Progressive Optimization of Large Deep  Learning Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongzheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C+H">Cody Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yida Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASPLOS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08387" title="Abstract">arXiv:2302.08387</a> (replaced) [<a href="/pdf/2302.08387" title="Download PDF">pdf</a>, <a href="/format/2302.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEALLA: Learning Lightweight Language-agnostic Sentence Embeddings with  Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhuoyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Nakagawa%2C+T">Tetsuji Nakagawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2023 main conference; LEALLA models: <a href="https://www.kaggle.com/models/google/lealla">this https URL</a> (modified url in v2 of this paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14691" title="Abstract">arXiv:2302.14691</a> (replaced) [<a href="/pdf/2302.14691" title="Download PDF">pdf</a>, <a href="/format/2302.14691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Effectiveness of Task-Agnostic Prefix Prompt for  Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Seonghyeon Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Hyeonbin Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sohee Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+H">Hyeongu Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yireun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00859" title="Abstract">arXiv:2303.00859</a> (replaced) [<a href="/pdf/2303.00859" title="Download PDF">pdf</a>, <a href="/format/2303.00859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FuNVol: A Multi-Asset Implied Volatility Market Simulator using  Functional Principal Components and Neural SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Choudhary%2C+V">Vedant Choudhary</a>, 
<a href="/search/q-fin?searchtype=author&query=Jaimungal%2C+S">Sebastian Jaimungal</a>, 
<a href="/search/q-fin?searchtype=author&query=Bergeron%2C+M">Maxime Bergeron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 19 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Statistical Finance (q-fin.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00952" title="Abstract">arXiv:2303.00952</a> (replaced) [<a href="/pdf/2303.00952" title="Download PDF">pdf</a>, <a href="/format/2303.00952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuscleMap: Towards Video-based Activated Muscle Group Estimation in the  Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+D">David Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Roitberg%2C+A">Alina Roitberg</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The contributed dataset and code are made publicly available at <a href="https://github.com/KPeng9510/MuscleMap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03642" title="Abstract">arXiv:2303.03642</a> (replaced) [<a href="/pdf/2303.03642" title="Download PDF">pdf</a>, <a href="/ps/2303.03642" title="Download PostScript">ps</a>, <a href="/format/2303.03642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best-of-Both-Worlds Fairness in Committee Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aziz%2C+H">Haris Aziz</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xinhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+M">Mashbat Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Vollen%2C+J">Jeremy Vollen</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+T">Toby Walsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 19th Conference on Web and Internet Economics (WINE), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06748" title="Abstract">arXiv:2303.06748</a> (replaced) [<a href="/pdf/2303.06748" title="Download PDF">pdf</a>, <a href="/format/2303.06748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTT: An Example-Driven Tabular Transformer for Joinability by Leveraging  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nobari%2C+A+D">Arash Dargahi Nobari</a>, 
<a href="/search/cs?searchtype=author&query=Rafiei%2C+D">Davood Rafiei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08977" title="Abstract">arXiv:2303.08977</a> (replaced) [<a href="/pdf/2303.08977" title="Download PDF">pdf</a>, <a href="/format/2303.08977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeblurSR: Event-Based Motion Deblurring Under the Spiking Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chen Song</a>, 
<a href="/search/cs?searchtype=author&query=Bajaj%2C+C">Chandrajit Bajaj</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qixing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10420" title="Abstract">arXiv:2303.10420</a> (replaced) [<a href="/pdf/2303.10420" title="Download PDF">pdf</a>, <a href="/ps/2303.10420" title="Download PostScript">ps</a>, <a href="/format/2303.10420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zu%2C+C">Can Zu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zekai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yuhan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zeyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11117" title="Abstract">arXiv:2303.11117</a> (replaced) [<a href="/pdf/2303.11117" title="Download PDF">pdf</a>, <a href="/format/2303.11117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmotionIC: Emotional Inertia and Contagion-Driven Dependency Modeling  for Emotion Recognition in Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yingjian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SCIENCE CHINA Information Sciences (SCIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11876" title="Abstract">arXiv:2303.11876</a> (replaced) [<a href="/pdf/2303.11876" title="Download PDF">pdf</a>, <a href="/format/2303.11876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An implicit function theorem for the stream calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boreale%2C+M">Michele Boreale</a>, 
<a href="/search/cs?searchtype=author&query=Collodi%2C+L">Luisa Collodi</a>, 
<a href="/search/cs?searchtype=author&query=Gorla%2C+D">Daniele Gorla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12332" title="Abstract">arXiv:2303.12332</a> (replaced) [<a href="/pdf/2303.12332" title="Download PDF">pdf</a>, <a href="/format/2303.12332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Temporal Action Localization by Inferring Salient  Snippet-Feature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+W">Wulian Yun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengshi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuanming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huadong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Thirty-Eighth AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14496" title="Abstract">arXiv:2303.14496</a> (replaced) [<a href="/pdf/2303.14496" title="Download PDF">pdf</a>, <a href="/format/2303.14496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Explanation Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pukdee%2C+R">Rattana Pukdee</a>, 
<a href="/search/cs?searchtype=author&query=Sam%2C+D">Dylan Sam</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Balcan%2C+M">Maria-Florina Balcan</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14620" title="Abstract">arXiv:2303.14620</a> (replaced) [<a href="/pdf/2303.14620" title="Download PDF">pdf</a>, <a href="/format/2303.14620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PBScaler: A Bottleneck-aware Autoscaling Framework for  Microservice-based Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shuaiyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zekun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Duantengchuan Li</a>, 
<a href="/search/cs?searchtype=author&query=H%2C+P+C+K">Patrick C. K. H</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15216" title="Abstract">arXiv:2303.15216</a> (replaced) [<a href="/pdf/2303.15216" title="Download PDF">pdf</a>, <a href="/format/2303.15216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Risk-Aware Option Hedging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Wu%2C+D">David Wu</a>, 
<a href="/search/q-fin?searchtype=author&query=Jaimungal%2C+S">Sebastian Jaimungal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00670" title="Abstract">arXiv:2304.00670</a> (replaced) [<a href="/pdf/2304.00670" title="Download PDF">pdf</a>, <a href="/format/2304.00670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Juyeb Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">In-Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+W">Jun Won Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kum%2C+D">Dongsuk Kum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/CVF International Conference on Computer Vision (ICCV'23). Code is available at <a href="https://github.com/youngskkim/CRN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00910" title="Abstract">arXiv:2304.00910</a> (replaced) [<a href="/pdf/2304.00910" title="Download PDF">pdf</a>, <a href="/format/2304.00910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating One-Shot View Planning with a Single Next-Best View via  Long-Tail Multiview Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Sicong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dengler%2C+N">Nils Dengler</a>, 
<a href="/search/cs?searchtype=author&query=Zaenker%2C+T">Tobias Zaenker</a>, 
<a href="/search/cs?searchtype=author&query=Dawood%2C+M">Murad Dawood</a>, 
<a href="/search/cs?searchtype=author&query=Bennewitz%2C+M">Maren Bennewitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised and Resubmitted to IEEE Transaction on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01046" title="Abstract">arXiv:2304.01046</a> (replaced) [<a href="/pdf/2304.01046" title="Download PDF">pdf</a>, <a href="/format/2304.01046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Manifold Learning for Reading Comprehension and Logical Reasoning  Tasks with Polytuplet Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jeffrey Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+I">Ivan Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FICC 2023, Revised to correct clerical errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02711" title="Abstract">arXiv:2304.02711</a> (replaced) [<a href="/pdf/2304.02711" title="Download PDF">pdf</a>, <a href="/format/2304.02711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured prompt interrogation and recursive extraction of semantics  (SPIRES): A method for populating knowledge bases using zero-shot learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caufield%2C+J+H">J. Harry Caufield</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+H">Harshad Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Emonet%2C+V">Vincent Emonet</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+N+L">Nomi L. Harris</a>, 
<a href="/search/cs?searchtype=author&query=Joachimiak%2C+M+P">Marcin P. Joachimiak</a>, 
<a href="/search/cs?searchtype=author&query=Matentzoglu%2C+N">Nicolas Matentzoglu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">HyeongSik Kim</a>, 
<a href="/search/cs?searchtype=author&query=Moxon%2C+S+A+T">Sierra A.T. Moxon</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+J+T">Justin T. Reese</a>, 
<a href="/search/cs?searchtype=author&query=Haendel%2C+M+A">Melissa A. Haendel</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+P+N">Peter N. Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Mungall%2C+C+J">Christopher J. Mungall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated 2023-12-22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03446" title="Abstract">arXiv:2304.03446</a> (replaced) [<a href="/pdf/2304.03446" title="Download PDF">pdf</a>, <a href="/format/2304.03446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Collaborative Distributed Diffusion-Based AI-Generated Content  (AIGC) in Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>, 
<a href="/search/cs?searchtype=author&query=Xuemin">Xuemin</a> (Sherman)
<a href="/search/cs?searchtype=author&query=Shen">Shen</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For more technical details about this paper, please refer to "User-Centric Interactive AI for Distributed Diffusion Model-based AI-Generated Content'' in <a href="/abs/2311.11094">arXiv:2311.11094</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05501" title="Abstract">arXiv:2304.05501</a> (replaced) [<a href="/pdf/2304.05501" title="Download PDF">pdf</a>, <a href="/ps/2304.05501" title="Download PostScript">ps</a>, <a href="/format/2304.05501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L3MVN: Leveraging Large Language Models for Visual Target Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bangguo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+H">Hamidreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05506" title="Abstract">arXiv:2304.05506</a> (replaced) [<a href="/pdf/2304.05506" title="Download PDF">pdf</a>, <a href="/ps/2304.05506" title="Download PostScript">ps</a>, <a href="/format/2304.05506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frontier Semantic Exploration for Visual Target Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bangguo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+H">Hamidreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06876" title="Abstract">arXiv:2304.06876</a> (replaced) [<a href="/pdf/2304.06876" title="Download PDF">pdf</a>, <a href="/format/2304.06876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ho%2C+Q+H">Qi Heng Ho</a>, 
<a href="/search/eess?searchtype=author&query=Sunberg%2C+Z+N">Zachary N. Sunberg</a>, 
<a href="/search/eess?searchtype=author&query=Lahijanian%2C+M">Morteza Lahijanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 9, no. 2, pp. 931-938,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07531" title="Abstract">arXiv:2304.07531</a> (replaced) [<a href="/pdf/2304.07531" title="Download PDF">pdf</a>, <a href="/format/2304.07531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining for Cost Awareness in the Infrastructure as Code Artifacts of  Cloud-based Applications: an Exploratory Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feitosa%2C+D">Daniel Feitosa</a>, 
<a href="/search/cs?searchtype=author&query=Penca%2C+M">Matei-Tudor Penca</a>, 
<a href="/search/cs?searchtype=author&query=Berardi%2C+M">Massimiliano Berardi</a>, 
<a href="/search/cs?searchtype=author&query=Boza%2C+R">Rares-Dorian Boza</a>, 
<a href="/search/cs?searchtype=author&query=Andrikopoulos%2C+V">Vasilios Andrikopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10598" title="Abstract">arXiv:2304.10598</a> (replaced) [<a href="/pdf/2304.10598" title="Download PDF">pdf</a>, <a href="/format/2304.10598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Feedback Control Design for Non-Convex Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sawant%2C+M">Mayur Sawant</a>, 
<a href="/search/cs?searchtype=author&query=Polushin%2C+I">Ilia Polushin</a>, 
<a href="/search/cs?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11310" title="Abstract">arXiv:2304.11310</a> (replaced) [<a href="/pdf/2304.11310" title="Download PDF">pdf</a>, <a href="/format/2304.11310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twilight SLAM: Navigating Low-Light Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Surya Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mazotti%2C+B">Billy Mazotti</a>, 
<a href="/search/cs?searchtype=author&query=Rajani%2C+D+M">Dhyey Manish Rajani</a>, 
<a href="/search/cs?searchtype=author&query=Mayilvahanan%2C+S">Sarvesh Mayilvahanan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14318" title="Abstract">arXiv:2304.14318</a> (replaced) [<a href="/pdf/2304.14318" title="Download PDF">pdf</a>, <a href="/format/2304.14318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> q2d: Turning Questions into Dialogs to Teach Models How to Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Ganor%2C+S">Shlomi Cohen-Ganor</a>, 
<a href="/search/cs?searchtype=author&query=Hakimi%2C+I">Ido Hakimi</a>, 
<a href="/search/cs?searchtype=author&query=Lewenberg%2C+Y">Yoad Lewenberg</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Weinreb%2C+E">Enav Weinreb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023. Website: <a href="https://question2dialog.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01461" title="Abstract">arXiv:2305.01461</a> (replaced) [<a href="/pdf/2305.01461" title="Download PDF">pdf</a>, <a href="/format/2305.01461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Integer Optimal Control via Reinforcement Learning: A Case Study  on Hybrid Vehicle Energy Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jinming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuan Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02437" title="Abstract">arXiv:2305.02437</a> (replaced) [<a href="/pdf/2305.02437" title="Download PDF">pdf</a>, <a href="/format/2305.02437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Di Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiuying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02512" title="Abstract">arXiv:2305.02512</a> (replaced) [<a href="/pdf/2305.02512" title="Download PDF">pdf</a>, <a href="/ps/2305.02512" title="Download PostScript">ps</a>, <a href="/format/2305.02512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Grassmannian to Simplicial High-Dimensional Expanders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Golowich%2C+L">Louis Golowich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edits to improve exposition, added references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03148" title="Abstract">arXiv:2305.03148</a> (replaced) [<a href="/pdf/2305.03148" title="Download PDF">pdf</a>, <a href="/format/2305.03148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMEL: Co-Designing AI Models and Embedded DRAMs for Efficient On-Device  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S+Q">Sai Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tambe%2C+T">Thierry Tambe</a>, 
<a href="/search/cs?searchtype=author&query=Cuevas%2C+N">Nestor Cuevas</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Gu-Yeon Wei</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+D">David Brooks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03535" title="Abstract">arXiv:2305.03535</a> (replaced) [<a href="/pdf/2305.03535" title="Download PDF">pdf</a>, <a href="/format/2305.03535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Next-generation Surgical Navigation: Marker-less Multi-view 6DoF Pose  Estimation of Surgical Instruments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hein%2C+J">Jonas Hein</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcanti%2C+N">Nicola Cavalcanti</a>, 
<a href="/search/cs?searchtype=author&query=Suter%2C+D">Daniel Suter</a>, 
<a href="/search/cs?searchtype=author&query=Zingg%2C+L">Lukas Zingg</a>, 
<a href="/search/cs?searchtype=author&query=Carrillo%2C+F">Fabio Carrillo</a>, 
<a href="/search/cs?searchtype=author&query=Calvet%2C+L">Lilian Calvet</a>, 
<a href="/search/cs?searchtype=author&query=Farshad%2C+M">Mazda Farshad</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%BCrnstahl%2C+P">Philipp F&#xfc;rnstahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04186" title="Abstract">arXiv:2305.04186</a> (replaced) [<a href="/pdf/2305.04186" title="Download PDF">pdf</a>, <a href="/format/2305.04186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Specific Query-Key Attention Modeling for Weakly-Supervised  Temporal Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Katsaggelos%2C+A+K">Aggelos K. Katsaggelos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05031" title="Abstract">arXiv:2305.05031</a> (replaced) [<a href="/pdf/2305.05031" title="Download PDF">pdf</a>, <a href="/ps/2305.05031" title="Download PostScript">ps</a>, <a href="/format/2305.05031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast randomized algorithms for computing the generalized tensor SVD  based on the tubal product
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmadi-Asl%2C+S">Salman Ahmadi-Asl</a>, 
<a href="/search/math?searchtype=author&query=Ugwu%2C+U">Ugochukwu Ugwu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05276" title="Abstract">arXiv:2305.05276</a> (replaced) [<a href="/pdf/2305.05276" title="Download PDF">pdf</a>, <a href="/format/2305.05276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery from Subsampled Time Series with Proxy Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingzhou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lingjing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06141" title="Abstract">arXiv:2305.06141</a> (replaced) [<a href="/pdf/2305.06141" title="Download PDF">pdf</a>, <a href="/ps/2305.06141" title="Download PostScript">ps</a>, <a href="/format/2305.06141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Semantic Localization with Graph Neural Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+M">Mitsuki Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kanji Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+R">Ryogo Yamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Iwata%2C+D">Daiki Iwata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACPR2023 (extended version)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition. ACPR 2023. Lecture Notes in Computer Science,
  vol 14406. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06547" title="Abstract">arXiv:2305.06547</a> (replaced) [<a href="/pdf/2305.06547" title="Download PDF">pdf</a>, <a href="/format/2305.06547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Lyapunov Control for Discrete-Time Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+A">Andrew Clark</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06743" title="Abstract">arXiv:2305.06743</a> (replaced) [<a href="/pdf/2305.06743" title="Download PDF">pdf</a>, <a href="/format/2305.06743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicitly normalized forecaster with clipping for linear and non-linear  heavy-tailed multi-armed bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorn%2C+Y">Yuriy Dorn</a>, 
<a href="/search/cs?searchtype=author&query=Kornilov%2C+N">Nikita Kornilov</a>, 
<a href="/search/cs?searchtype=author&query=Kutuzov%2C+N">Nikolay Kutuzov</a>, 
<a href="/search/cs?searchtype=author&query=Nazin%2C+A">Alexander Nazin</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>, 
<a href="/search/cs?searchtype=author&query=Gasnikov%2C+A">Alexander Gasnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07223" title="Abstract">arXiv:2305.07223</a> (replaced) [<a href="/pdf/2305.07223" title="Download PDF">pdf</a>, <a href="/format/2305.07223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transavs: End-To-End Audio-Visual Segmentation With Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+Y">Yuhang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhenye Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+M">Mingmin Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07882" title="Abstract">arXiv:2305.07882</a> (replaced) [<a href="/pdf/2305.07882" title="Download PDF">pdf</a>, <a href="/ps/2305.07882" title="Download PostScript">ps</a>, <a href="/format/2305.07882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Use Concerns of Generative AI and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grinbaum%2C+A">Alexei Grinbaum</a>, 
<a href="/search/cs?searchtype=author&query=Adomaitis%2C+L">Laurynas Adomaitis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08422" title="Abstract">arXiv:2305.08422</a> (replaced) [<a href="/pdf/2305.08422" title="Download PDF">pdf</a>, <a href="/ps/2305.08422" title="Download PostScript">ps</a>, <a href="/format/2305.08422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The generalized Pythagorean theorem on the compactifications of certain  dually flat spaces via toric geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fujita%2C+H">Hajime Fujita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures : Minor revisions on the format, title changed according to referee's suggestion, typos corrected, explanation added, to appear in Information Geometry : Mistake in the example in Section 6.1 corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symplectic Geometry (math.SG)</span>; Information Theory (cs.IT); Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08685" title="Abstract">arXiv:2305.08685</a> (replaced) [<a href="/pdf/2305.08685" title="Download PDF">pdf</a>, <a href="/format/2305.08685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-VG: Self-paced Curriculum Adapting of CLIP for Visual Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Linhui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoshan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+F">Fang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transaction on Multimedia (2023), Paper page: <a href="https://ieeexplore.ieee.org/abstract/document/10269126.">this https URL</a> Code are available at <a href="https://github.com/linhuixiao/CLIP-VG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09168" title="Abstract">arXiv:2305.09168</a> (replaced) [<a href="/pdf/2305.09168" title="Download PDF">pdf</a>, <a href="/format/2305.09168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Static Pricing Guarantees for Queueing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergquist%2C+J">Jacob Bergquist</a>, 
<a href="/search/cs?searchtype=author&query=Elmachtoub%2C+A+N">Adam N. Elmachtoub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09956" title="Abstract">arXiv:2305.09956</a> (replaced) [<a href="/pdf/2305.09956" title="Download PDF">pdf</a>, <a href="/ps/2305.09956" title="Download PostScript">ps</a>, <a href="/format/2305.09956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Adversarial Consistency of Surrogate Risks for Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frank%2C+N">Natalie Frank</a>, 
<a href="/search/cs?searchtype=author&query=Niles-Weed%2C+J">Jonathan Niles-Weed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, published in NeurIps 2023. version 3: added acknowledgements, no other changes. version 2: reorganized Section 4 and added proofs of the approximate complimentary slackness theorems. arXiv admin note: text overlap with <a href="/abs/2206.09099">arXiv:2206.09099</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10400" title="Abstract">arXiv:2305.10400</a> (replaced) [<a href="/pdf/2305.10400" title="Download PDF">pdf</a>, <a href="/format/2305.10400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What You See is What You Read? Improving Text-Image Alignment Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yarom%2C+M">Michal Yarom</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Changpinyo%2C+S">Soravit Changpinyo</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+O">Oran Lang</a>, 
<a href="/search/cs?searchtype=author&query=Ofek%2C+E">Eran Ofek</a>, 
<a href="/search/cs?searchtype=author&query=Szpektor%2C+I">Idan Szpektor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Website: <a href="https://wysiwyr-itm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13245" title="Abstract">arXiv:2305.13245</a> (replaced) [<a href="/pdf/2305.13245" title="Download PDF">pdf</a>, <a href="/format/2305.13245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GQA: Training Generalized Multi-Query Transformer Models from Multi-Head  Checkpoints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ainslie%2C+J">Joshua Ainslie</a>, 
<a href="/search/cs?searchtype=author&query=Lee-Thorp%2C+J">James Lee-Thorp</a>, 
<a href="/search/cs?searchtype=author&query=de+Jong%2C+M">Michiel de Jong</a>, 
<a href="/search/cs?searchtype=author&query=Zemlyanskiy%2C+Y">Yury Zemlyanskiy</a>, 
<a href="/search/cs?searchtype=author&query=Lebr%C3%B3n%2C+F">Federico Lebr&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Sanghai%2C+S">Sumit Sanghai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023. Added to related work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13450" title="Abstract">arXiv:2305.13450</a> (replaced) [<a href="/pdf/2305.13450" title="Download PDF">pdf</a>, <a href="/format/2305.13450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Fine-Grained Synchronization of Dependent GPU Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jangda%2C+A">Abhinav Jangda</a>, 
<a href="/search/cs?searchtype=author&query=Maleki%2C+S">Saeed Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Dehnavi%2C+M+M">Maryam Mehri Dehnavi</a>, 
<a href="/search/cs?searchtype=author&query=Musuvathi%2C+M">Madan Musuvathi</a>, 
<a href="/search/cs?searchtype=author&query=Saarikivi%2C+O">Olli Saarikivi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13773" title="Abstract">arXiv:2305.13773</a> (replaced) [<a href="/pdf/2305.13773" title="Download PDF">pdf</a>, <a href="/format/2305.13773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Fine-grained Motion Diffusion for Text-driven Human Motion  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoning Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huaijiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14901" title="Abstract">arXiv:2305.14901</a> (replaced) [<a href="/pdf/2305.14901" title="Download PDF">pdf</a>, <a href="/format/2305.14901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Questions Training with Latent Answers for Robust Multistep  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14910" title="Abstract">arXiv:2305.14910</a> (replaced) [<a href="/pdf/2305.14910" title="Download PDF">pdf</a>, <a href="/format/2305.14910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Shortcuts to Triggers: Backdoor Defense with Denoised PoE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14943" title="Abstract">arXiv:2305.14943</a> (replaced) [<a href="/pdf/2305.14943" title="Download PDF">pdf</a>, <a href="/format/2305.14943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Rate Free Sampling in Constrained Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sharrock%2C+L">Louis Sharrock</a>, 
<a href="/search/stat?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>, 
<a href="/search/stat?searchtype=author&query=Nemeth%2C+C">Christopher Nemeth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15408" title="Abstract">arXiv:2305.15408</a> (replaced) [<a href="/pdf/2305.15408" title="Download PDF">pdf</a>, <a href="/format/2305.15408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Revealing the Mystery behind Chain of Thought: A Theoretical  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Guhao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bohang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuntian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haotian Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Di He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages; Camera-ready version for NeurIPS 2023 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16695" title="Abstract">arXiv:2305.16695</a> (replaced) [<a href="/pdf/2305.16695" title="Download PDF">pdf</a>, <a href="/format/2305.16695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Search for Stability: Learning Dynamics of Strategic Publishers with  Initial Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madmon%2C+O">Omer Madmon</a>, 
<a href="/search/cs?searchtype=author&query=Pipano%2C+I">Idan Pipano</a>, 
<a href="/search/cs?searchtype=author&query=Reinman%2C+I">Itamar Reinman</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16941" title="Abstract">arXiv:2305.16941</a> (replaced) [<a href="/pdf/2305.16941" title="Download PDF">pdf</a>, <a href="/format/2305.16941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milli%2C+S">Smitha Milli</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+M">Micah Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yike Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S">Sashrika Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sebastian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A+D">Anca D. Dragan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17214" title="Abstract">arXiv:2305.17214</a> (replaced) [<a href="/pdf/2305.17214" title="Download PDF">pdf</a>, <a href="/format/2305.17214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast, Attend and Diffuse to Decode High-Resolution Images from Brain  Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18341" title="Abstract">arXiv:2305.18341</a> (replaced) [<a href="/pdf/2305.18341" title="Download PDF">pdf</a>, <a href="/format/2305.18341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse-Tuning Models of Code with Reinforcement Learning Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Abhinav Jain</a> (1), 
<a href="/search/cs?searchtype=author&query=Adiole%2C+C">Chima Adiole</a> (1), 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a> (2), 
<a href="/search/cs?searchtype=author&query=Reps%2C+T">Thomas Reps</a> (3), 
<a href="/search/cs?searchtype=author&query=Jermaine%2C+C">Chris Jermaine</a> (1) ((1) Rice University, (2) UT Austin, (3) University of Wisconsin)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19082" title="Abstract">arXiv:2305.19082</a> (replaced) [<a href="/pdf/2305.19082" title="Download PDF">pdf</a>, <a href="/format/2305.19082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding Inequalities for Barron-type Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00959" title="Abstract">arXiv:2306.00959</a> (replaced) [<a href="/pdf/2306.00959" title="Download PDF">pdf</a>, <a href="/format/2306.00959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Algorithms for Matroid Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banihashem%2C+K">Kiarash Banihashem</a>, 
<a href="/search/cs?searchtype=author&query=Biabani%2C+L">Leyla Biabani</a>, 
<a href="/search/cs?searchtype=author&query=Goudarzi%2C+S">Samira Goudarzi</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Jabbarzade%2C+P">Peyman Jabbarzade</a>, 
<a href="/search/cs?searchtype=author&query=Monemizadeh%2C+M">Morteza Monemizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01461" title="Abstract">arXiv:2306.01461</a> (replaced) [<a href="/pdf/2306.01461" title="Download PDF">pdf</a>, <a href="/format/2306.01461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyDiffuse: Polygonal Shape Reconstruction via Guided Set Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruizhi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Furukawa%2C+Y">Yasutaka Furukawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://poly-diffuse.github.io/">this https URL</a>; NeurIPS 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01704" title="Abstract">arXiv:2306.01704</a> (replaced) [<a href="/pdf/2306.01704" title="Download PDF">pdf</a>, <a href="/format/2306.01704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal-controlled Frame Swap for Generating High-Fidelity Stereo  Driving Data for Autonomy Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yedi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiangyu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Le Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aniket Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Mortin%2C+E">Eric Mortin</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Hanumant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ostadabbas%2C+S">Sarah Ostadabbas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01997" title="Abstract">arXiv:2306.01997</a> (replaced) [<a href="/pdf/2306.01997" title="Download PDF">pdf</a>, <a href="/format/2306.01997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UADB: Unsupervised Anomaly Detection Booster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hangting Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhining Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xinyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Wei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+X">Xiaofan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE 39th International Conference on Data Engineering (ICDE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02559" title="Abstract">arXiv:2306.02559</a> (replaced) [<a href="/pdf/2306.02559" title="Download PDF">pdf</a>, <a href="/format/2306.02559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Exact Enumeration of Single-Source Geodesics on a Non-Convex  Polyhedron
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tateiri%2C+K">Kazuma Tateiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03269" title="Abstract">arXiv:2306.03269</a> (replaced) [<a href="/pdf/2306.03269" title="Download PDF">pdf</a>, <a href="/format/2306.03269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Knowledge-Guided Fuzzing of Deep Learning Libraries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harzevili%2C+N+S">Nima Shiri Harzevili</a>, 
<a href="/search/cs?searchtype=author&query=Mohajer%2C+M+M">Mohammad Mahdi Mohajer</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Moshi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+V">Hung Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03831" title="Abstract">arXiv:2306.03831</a> (replaced) [<a href="/pdf/2306.03831" title="Download PDF">pdf</a>, <a href="/format/2306.03831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GEO-Bench: Toward Foundation Models for Earth Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lacoste%2C+A">Alexandre Lacoste</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+N">Nils Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+P">Pau Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Sherwin%2C+E+D">Evan David Sherwin</a>, 
<a href="/search/cs?searchtype=author&query=Kerner%2C+H">Hannah Kerner</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCtjens%2C+B">Bj&#xf6;rn L&#xfc;tjens</a>, 
<a href="/search/cs?searchtype=author&query=Irvin%2C+J+A">Jeremy Andrew Irvin</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+D">David Dao</a>, 
<a href="/search/cs?searchtype=author&query=Alemohammad%2C+H">Hamed Alemohammad</a>, 
<a href="/search/cs?searchtype=author&query=Drouin%2C+A">Alexandre Drouin</a>, 
<a href="/search/cs?searchtype=author&query=Gunturkun%2C+M">Mehmet Gunturkun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gabriel Huang</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+D">David Vazquez</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+D">Dava Newman</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.00570">arXiv:2112.00570</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04354" title="Abstract">arXiv:2306.04354</a> (replaced) [<a href="/pdf/2306.04354" title="Download PDF">pdf</a>, <a href="/format/2306.04354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-Newton FDE in One-Bit Pseudo-Randomly Quantized Massive MIMO-OFDM  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Y%C4%B1lmaz%2C+G">G&#xf6;khan Y&#x131;lmaz</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1lmaz%2C+A+%C3%96">Ali &#xd6;zg&#xfc;r Y&#x131;lmaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05685" title="Abstract">arXiv:2306.05685</a> (replaced) [<a href="/pdf/2306.05685" title="Download PDF">pdf</a>, <a href="/format/2306.05685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+W">Wei-Lin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Siyuan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhanghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yonghao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E+P">Eric P. Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06093" title="Abstract">arXiv:2306.06093</a> (replaced) [<a href="/pdf/2306.06093" title="Download PDF">pdf</a>, <a href="/format/2306.06093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+B">Bipasha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gaurav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Aditya Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Agaram%2C+R">Rohith Agaram</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K+M">K Madhava Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srinath Sridhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://hyp-nerf.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06157" title="Abstract">arXiv:2306.06157</a> (replaced) [<a href="/pdf/2306.06157" title="Download PDF">pdf</a>, <a href="/format/2306.06157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Localization for Buggy Deep Learning Framework Conversions in  Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louloudakis%2C+N">Nikolaos Louloudakis</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+P">Perry Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+J">Jos&#xe9; Cano</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+A">Ajitha Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06208" title="Abstract">arXiv:2306.06208</a> (replaced) [<a href="/pdf/2306.06208" title="Download PDF">pdf</a>, <a href="/format/2306.06208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeltaNN: Assessing the Impact of Computational Environment Parameters on  the Performance of Image Recognition Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louloudakis%2C+N">Nikolaos Louloudakis</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+P">Perry Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+J">Jos&#xe9; Cano</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+A">Ajitha Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06334" title="Abstract">arXiv:2306.06334</a> (replaced) [<a href="/pdf/2306.06334" title="Download PDF">pdf</a>, <a href="/format/2306.06334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Face-Upwinded Spectral Element Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pan%2C+Y">Yulong Pan</a>, 
<a href="/search/math?searchtype=author&query=Persson%2C+P">Per-Olof Persson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06406" title="Abstract">arXiv:2306.06406</a> (replaced) [<a href="/e-print/2306.06406" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D3L: Decomposition of 3D Rotation and Lift from 2D Joint to 3D for Human  Mesh Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xiaoyang Hao</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jun Cheng</a> (2), 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a> (2) ((1) Southern University of Science and Technology, (2) Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More proper explanations are needed to be added to provide comprehensive information. Additionally, it mistakenly omitted a key contributor
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09361" title="Abstract">arXiv:2306.09361</a> (replaced) [<a href="/pdf/2306.09361" title="Download PDF">pdf</a>, <a href="/format/2306.09361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFAS: Emotion Recognition through Multiple Perspectives Fusion  Architecture Search Emulating Human Cognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Haiyang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fulin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lian%2C+Z">Zheng Lian</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yingying Guo</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shilei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10249" title="Abstract">arXiv:2306.10249</a> (replaced) [<a href="/pdf/2306.10249" title="Download PDF">pdf</a>, <a href="/format/2306.10249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Generative AI Models for Telecom: The Next Big Thing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bariah%2C+L">Lina Bariah</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qiyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Hang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Bader%2C+F">Faouzi Bader</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10280" title="Abstract">arXiv:2306.10280</a> (replaced) [<a href="/pdf/2306.10280" title="Download PDF">pdf</a>, <a href="/format/2306.10280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenGSL: A Comprehensive Benchmark for Graph Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhiyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+B">Bochao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuanyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qiaoyu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 21 figures. Camera-ready version for NeurIPS Datasets and Benchmarks Track 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10531" title="Abstract">arXiv:2306.10531</a> (replaced) [<a href="/pdf/2306.10531" title="Download PDF">pdf</a>, <a href="/format/2306.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenPose: Generative Category-level Object Pose Estimation via Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingdong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10982" title="Abstract">arXiv:2306.10982</a> (replaced) [<a href="/pdf/2306.10982" title="Download PDF">pdf</a>, <a href="/format/2306.10982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Over-the-Air Federated Learning Over MIMO Fading  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jia Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+A">Ying-Jun Angela Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11920" title="Abstract">arXiv:2306.11920</a> (replaced) [<a href="/pdf/2306.11920" title="Download PDF">pdf</a>, <a href="/format/2306.11920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NILUT: Conditional Neural Implicit 3D Lookup Tables for Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conde%2C+M+V">Marcos V. Conde</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez-Corral%2C+J">Javier Vazquez-Corral</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+M+S">Michael S. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 - The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12383" title="Abstract">arXiv:2306.12383</a> (replaced) [<a href="/pdf/2306.12383" title="Download PDF">pdf</a>, <a href="/ps/2306.12383" title="Download PostScript">ps</a>, <a href="/format/2306.12383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and  Optimal Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yining Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Baihe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12519" title="Abstract">arXiv:2306.12519</a> (replaced) [<a href="/pdf/2306.12519" title="Download PDF">pdf</a>, <a href="/format/2306.12519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long Polynomial Modular Multiplication using Low-Complexity Number  Theoretic Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiu%2C+S">Sin-Wei Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Parhi%2C+K+K">Keshab K. Parhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12574" title="Abstract">arXiv:2306.12574</a> (replaced) [<a href="/pdf/2306.12574" title="Download PDF">pdf</a>, <a href="/format/2306.12574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient and straightforward online quantization method for a data  stream through remove-birth updating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujita%2C+K">Kazuhisa Fujita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12633" title="Abstract">arXiv:2306.12633</a> (replaced) [<a href="/pdf/2306.12633" title="Download PDF">pdf</a>, <a href="/ps/2306.12633" title="Download PostScript">ps</a>, <a href="/format/2306.12633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial guesswork with quantum side information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Avirmed%2C+B">Baasanchimed Avirmed</a>, 
<a href="/search/quant-ph?searchtype=author&query=Niinomi%2C+K">Kaito Niinomi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dall%27Arno%2C+M">Michele Dall&#x27;Arno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Information and Computation 23, 1105 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13531" title="Abstract">arXiv:2306.13531</a> (replaced) [<a href="/pdf/2306.13531" title="Download PDF">pdf</a>, <a href="/format/2306.13531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WBCAtt: A White Blood Cell Dataset Annotated with Detailed Morphological  Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsutsui%2C+S">Satoshi Tsutsui</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+W">Winnie Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bihan Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14535" title="Abstract">arXiv:2306.14535</a> (replaced) [<a href="/pdf/2306.14535" title="Download PDF">pdf</a>, <a href="/ps/2306.14535" title="Download PostScript">ps</a>, <a href="/format/2306.14535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> About the Cost of Central Privacy in Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lalanne%2C+C">Cl&#xe9;ment Lalanne</a> (ENS de Lyon, OCKHAM), 
<a href="/search/cs?searchtype=author&query=Garivier%2C+A">Aur&#xe9;lien Garivier</a> (UMPA-ENSL, MC2), 
<a href="/search/cs?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a> (OCKHAM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research Journal, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14790" title="Abstract">arXiv:2306.14790</a> (replaced) [<a href="/pdf/2306.14790" title="Download PDF">pdf</a>, <a href="/ps/2306.14790" title="Download PostScript">ps</a>, <a href="/format/2306.14790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Assessment of Divergent Thinking in Chinese Language with  TransDis: A Transformer-Based Language Model Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaoyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yubo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15419" title="Abstract">arXiv:2306.15419</a> (replaced) [<a href="/pdf/2306.15419" title="Download PDF">pdf</a>, <a href="/format/2306.15419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Freestyle 3D-Aware Portrait Synthesis Based on Compositional Generative  Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tianxiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project website: <a href="https://tianxiangma.github.io/FF3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01200" title="Abstract">arXiv:2307.01200</a> (replaced) [<a href="/pdf/2307.01200" title="Download PDF">pdf</a>, <a href="/format/2307.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProxyCap: Real-time Monocular Full-body Capture in World Space via  Human-Centric Proxy-to-Motion Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liangxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our project page is <a href="https://zhangyux15.github.io/ProxyCapV2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02588" title="Abstract">arXiv:2307.02588</a> (replaced) [<a href="/pdf/2307.02588" title="Download PDF">pdf</a>, <a href="/format/2307.02588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransformerG2G: Adaptive time-stepping for learning temporal graph  embeddings using transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varghese%2C+A+J">Alan John Varghese</a>, 
<a href="/search/cs?searchtype=author&query=Bora%2C+A">Aniruddha Bora</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengjia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02779" title="Abstract">arXiv:2307.02779</a> (replaced) [<a href="/pdf/2307.02779" title="Download PDF">pdf</a>, <a href="/format/2307.02779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Empowered Autonomous Edge AI for Connected  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yifei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jiawei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Communication Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02813" title="Abstract">arXiv:2307.02813</a> (replaced) [<a href="/pdf/2307.02813" title="Download PDF">pdf</a>, <a href="/format/2307.02813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPDG: A Contrastive Pre-Training Method for Dynamic Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bei%2C+Y">Yuanchen Bei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+H">Huixuan Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haishuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengdi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+J">Jiajun Bu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, accepted by ICDE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02948" title="Abstract">arXiv:2307.02948</a> (replaced) [<a href="/pdf/2307.02948" title="Download PDF">pdf</a>, <a href="/format/2307.02948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Point Cloud Downsampling for Fast and Accurate Global Trajectory  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koide%2C+K">Kenji Koide</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+S">Shuji Oishi</a>, 
<a href="/search/cs?searchtype=author&query=Yokozuka%2C+M">Masashi Yokozuka</a>, 
<a href="/search/cs?searchtype=author&query=Banno%2C+A">Atsuhiko Banno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05385" title="Abstract">arXiv:2307.05385</a> (replaced) [<a href="/pdf/2307.05385" title="Download PDF">pdf</a>, <a href="/format/2307.05385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Kernels for Interpretable and Efficient Medical Time Series  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+S+F">Sully F. Chen</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zhicheng Guo</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+C">Cheng Ding</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xiao Hu</a>, 
<a href="/search/eess?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05473" title="Abstract">arXiv:2307.05473</a> (replaced) [<a href="/pdf/2307.05473" title="Download PDF">pdf</a>, <a href="/format/2307.05473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Blocks World: Qualitative 3D Decomposition by Rendering  Primitives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monnier%2C+T">Tom Monnier</a>, 
<a href="/search/cs?searchtype=author&query=Austin%2C+J">Jake Austin</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Efros%2C+A+A">Alexei A. Efros</a>, 
<a href="/search/cs?searchtype=author&query=Aubry%2C+M">Mathieu Aubry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage with code and videos: <a href="https://www.tmonnier.com/DBW.">this https URL</a> V2 update includes comparisons based on NeuS, hyperparameter analysis and failure cases
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05722" title="Abstract">arXiv:2307.05722</a> (replaced) [<a href="/pdf/2307.05722" title="Download PDF">pdf</a>, <a href="/format/2307.05722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Model for Graph Data Understanding in Online  Job Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Likang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhaopeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07516" title="Abstract">arXiv:2307.07516</a> (replaced) [<a href="/pdf/2307.07516" title="Download PDF">pdf</a>, <a href="/ps/2307.07516" title="Download PostScript">ps</a>, <a href="/format/2307.07516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voting-based Multimodal Automatic Deception Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Touma%2C+L">Lana Touma</a>, 
<a href="/search/cs?searchtype=author&query=Horani%2C+M+A">Mohammad Al Horani</a>, 
<a href="/search/cs?searchtype=author&query=Tailouni%2C+M">Manar Tailouni</a>, 
<a href="/search/cs?searchtype=author&query=Dahabiah%2C+A">Anas Dahabiah</a>, 
<a href="/search/cs?searchtype=author&query=Jallad%2C+K+A">Khloud Al Jallad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07538" title="Abstract">arXiv:2307.07538</a> (replaced) [<a href="/pdf/2307.07538" title="Download PDF">pdf</a>, <a href="/format/2307.07538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy stable and conservative dynamical low-rank approximation for the  Su-Olson problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baumann%2C+L">Lena Baumann</a>, 
<a href="/search/math?searchtype=author&query=Einkemmer%2C+L">Lukas Einkemmer</a>, 
<a href="/search/math?searchtype=author&query=Klingenberg%2C+C">Christian Klingenberg</a>, 
<a href="/search/math?searchtype=author&query=Kusch%2C+J">Jonas Kusch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07635" title="Abstract">arXiv:2307.07635</a> (replaced) [<a href="/pdf/2307.07635" title="Download PDF">pdf</a>, <a href="/format/2307.07635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoTracker: It is Better to Track Together
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karaev%2C+N">Nikita Karaev</a>, 
<a href="/search/cs?searchtype=author&query=Rocco%2C+I">Ignacio Rocco</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+B">Benjamin Graham</a>, 
<a href="/search/cs?searchtype=author&query=Neverova%2C+N">Natalia Neverova</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and model weights are available at: <a href="https://co-tracker.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07763" title="Abstract">arXiv:2307.07763</a> (replaced) [<a href="/pdf/2307.07763" title="Download PDF">pdf</a>, <a href="/format/2307.07763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tightly-Coupled LiDAR-Visual SLAM Based on Geometric Features for Mobile  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Ke Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhifeng Teng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ROBIO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08668" title="Abstract">arXiv:2307.08668</a> (replaced) [<a href="/pdf/2307.08668" title="Download PDF">pdf</a>, <a href="/format/2307.08668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study in Zucker: Insights on Interactions Between Humans and Small  Service Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Day%2C+A">Alex Day</a>, 
<a href="/search/cs?searchtype=author&query=Karamouzas%2C+I">Ioannis Karamouzas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09807" title="Abstract">arXiv:2307.09807</a> (replaced) [<a href="/pdf/2307.09807" title="Download PDF">pdf</a>, <a href="/ps/2307.09807" title="Download PostScript">ps</a>, <a href="/format/2307.09807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-Complexity Beamforming Design for Beyond-Diagonal RIS aided  Multi-User Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11349" title="Abstract">arXiv:2307.11349</a> (replaced) [<a href="/pdf/2307.11349" title="Download PDF">pdf</a>, <a href="/format/2307.11349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EV-Planner: Energy-Efficient Robot Navigation via Event-Based  Physics-Guided Neuromorphic Planner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Sourav Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Manna%2C+R+K">Rohan Kumar Manna</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12480" title="Abstract">arXiv:2307.12480</a> (replaced) [<a href="/pdf/2307.12480" title="Download PDF">pdf</a>, <a href="/format/2307.12480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Resource Allocation Policy: Vertex-GNN or Edge-GNN?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenyang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13799" title="Abstract">arXiv:2307.13799</a> (replaced) [<a href="/pdf/2307.13799" title="Download PDF">pdf</a>, <a href="/format/2307.13799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upward Planarity Testing of Biconnected Outerplanar DAGs Solves  Partition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frati%2C+F">Fabrizio Frati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14439" title="Abstract">arXiv:2307.14439</a> (replaced) [<a href="/pdf/2307.14439" title="Download PDF">pdf</a>, <a href="/format/2307.14439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed Integral Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kortvelesy%2C+R">Ryan Kortvelesy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14492" title="Abstract">arXiv:2307.14492</a> (replaced) [<a href="/pdf/2307.14492" title="Download PDF">pdf</a>, <a href="/ps/2307.14492" title="Download PostScript">ps</a>, <a href="/format/2307.14492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension-Minimality and Primality of Counter Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almagor%2C+S">Shaull Almagor</a>, 
<a href="/search/cs?searchtype=author&query=Avni%2C+G">Guy Avni</a>, 
<a href="/search/cs?searchtype=author&query=Sinclair-Banks%2C+H">Henry Sinclair-Banks</a>, 
<a href="/search/cs?searchtype=author&query=Yeshurun%2C+A">Asaf Yeshurun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16082" title="Abstract">arXiv:2307.16082</a> (replaced) [<a href="/pdf/2307.16082" title="Download PDF">pdf</a>, <a href="/format/2307.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnrichEvent: Enriching Social Data with Contextual Information for  Emerging Event Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esfahani%2C+M+S">Mohammadali Sefidi Esfahani</a>, 
<a href="/search/cs?searchtype=author&query=Akbari%2C+M">Mohammad Akbari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03266" title="Abstract">arXiv:2308.03266</a> (replaced) [<a href="/pdf/2308.03266" title="Download PDF">pdf</a>, <a href="/format/2308.03266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and  Effective Hotword Customization Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yexin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zerui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanni Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhifu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03314" title="Abstract">arXiv:2308.03314</a> (replaced) [<a href="/pdf/2308.03314" title="Download PDF">pdf</a>, <a href="/format/2308.03314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining  GPT with Program Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Daoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yue Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a technical report from Nanyang Technological University
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03321" title="Abstract">arXiv:2308.03321</a> (replaced) [<a href="/pdf/2308.03321" title="Download PDF">pdf</a>, <a href="/format/2308.03321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFN: Adaptive Fusion Normalization via an Encoder-Decoder Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2106.01899">arXiv:2106.01899</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03448" title="Abstract">arXiv:2308.03448</a> (replaced) [<a href="/pdf/2308.03448" title="Download PDF">pdf</a>, <a href="/format/2308.03448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Explicit Calibration Implicit: Calibrate Denoiser Instead of the  Noise Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jia-Wen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Ling-Hao Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chunle Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xialei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05695" title="Abstract">arXiv:2308.05695</a> (replaced) [<a href="/pdf/2308.05695" title="Download PDF">pdf</a>, <a href="/format/2308.05695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Diffusion as Self-supervised Representation Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zixuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06595" title="Abstract">arXiv:2308.06595</a> (replaced) [<a href="/pdf/2308.06595" title="Download PDF">pdf</a>, <a href="/format/2308.06595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisIT-Bench: A Benchmark for Vision-Language Instruction Following  Inspired by Real-World Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Rulin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wanrong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Awadalla%2C+A">Anas Awadalla</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Josh Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Taori%2C+R">Rohan Taori</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, Datasets and Benchmarks. Website: <a href="https://visit-bench.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06815" title="Abstract">arXiv:2308.06815</a> (replaced) [<a href="/pdf/2308.06815" title="Download PDF">pdf</a>, <a href="/format/2308.06815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing the cloud? Don&#x27;t train models. Build oracles!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bang%2C+T">Tiemo Bang</a>, 
<a href="/search/cs?searchtype=author&query=Power%2C+C">Conor Power</a>, 
<a href="/search/cs?searchtype=author&query=Ameli%2C+S">Siavash Ameli</a>, 
<a href="/search/cs?searchtype=author&query=Crooks%2C+N">Natacha Crooks</a>, 
<a href="/search/cs?searchtype=author&query=Hellerstein%2C+J+M">Joseph M. Hellerstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready publication for CIDR'24: <a href="https://www.cidrdb.org/cidr2024/papers/p47-bang.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07948" title="Abstract">arXiv:2308.07948</a> (replaced) [<a href="/pdf/2308.07948" title="Download PDF">pdf</a>, <a href="/format/2308.07948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Symmetries in Pick and Place
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haojie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tangri%2C+A">Arsh Tangri</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Platt%2C+R">Robert Platt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Journal of Robotics Research. arXiv admin note: substantial text overlap with <a href="/abs/2202.09400">arXiv:2202.09400</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09891" title="Abstract">arXiv:2308.09891</a> (replaced) [<a href="/pdf/2308.09891" title="Download PDF">pdf</a>, <a href="/format/2308.09891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin  Transformer and LSTM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Song Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">RongNian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10169" title="Abstract">arXiv:2308.10169</a> (replaced) [<a href="/pdf/2308.10169" title="Download PDF">pdf</a>, <a href="/format/2308.10169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Real-time Path Planning with Self-evolving Particle Swarm  Optimization in Dynamic Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+J">Jinghao Xin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ning Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10531" title="Abstract">arXiv:2308.10531</a> (replaced) [<a href="/pdf/2308.10531" title="Download PDF">pdf</a>, <a href="/format/2308.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRFormer: Text Detection Transformer with Incorporated Segmentation and  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bu%2C+Q">Qingwen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sungrae Park</a>, 
<a href="/search/cs?searchtype=author&query=Khang%2C+M">Minsoo Khang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yichuan Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Title changed. Accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10800" title="Abstract">arXiv:2308.10800</a> (replaced) [<a href="/pdf/2308.10800" title="Download PDF">pdf</a>, <a href="/format/2308.10800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fact-checking information generated by a large language model can  decrease news discernment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DeVerna%2C+M+R">Matthew R. DeVerna</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H+Y">Harry Yaojun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai-Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Menczer%2C+F">Filippo Menczer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11730" title="Abstract">arXiv:2308.11730</a> (replaced) [<a href="/pdf/2308.11730" title="Download PDF">pdf</a>, <a href="/format/2308.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Prompting for Multi-Document Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lipka%2C+N">Nedim Lipka</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R+A">Ryan A. Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+A">Alexa Siu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12009" title="Abstract">arXiv:2308.12009</a> (replaced) [<a href="/pdf/2308.12009" title="Download PDF">pdf</a>, <a href="/format/2308.12009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StofNet: Super-resolution Time of Flight Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hahne%2C+C">Christopher Hahne</a>, 
<a href="/search/cs?searchtype=author&query=Hayoz%2C+M">Michel Hayoz</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12110" title="Abstract">arXiv:2308.12110</a> (replaced) [<a href="/pdf/2308.12110" title="Download PDF">pdf</a>, <a href="/format/2308.12110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Stein Variational Trajectory Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Power%2C+T">Thomas Power</a>, 
<a href="/search/cs?searchtype=author&query=Berenson%2C+D">Dmitry Berenson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12161" title="Abstract">arXiv:2308.12161</a> (replaced) [<a href="/pdf/2308.12161" title="Download PDF">pdf</a>, <a href="/format/2308.12161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven decision-focused surrogate modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gupta%2C+R">Rishabh Gupta</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12590" title="Abstract">arXiv:2308.12590</a> (replaced) [<a href="/pdf/2308.12590" title="Download PDF">pdf</a>, <a href="/format/2308.12590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning of Implicit Shape Representation with Dense  Correspondence for Deformable Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahe Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaoming Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Cuixia Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12960" title="Abstract">arXiv:2308.12960</a> (replaced) [<a href="/pdf/2308.12960" title="Download PDF">pdf</a>, <a href="/format/2308.12960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Realistic Zero-Shot Classification via Self Structural Semantic  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F">Fahad Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13150" title="Abstract">arXiv:2308.13150</a> (replaced) [<a href="/pdf/2308.13150" title="Download PDF">pdf</a>, <a href="/format/2308.13150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Breast Cancer Histopathology Image Classification Using  Dual-Activated Lightweight Attention ResNet50 Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Suxing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures,6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13961" title="Abstract">arXiv:2308.13961</a> (replaced) [<a href="/pdf/2308.13961" title="Download PDF">pdf</a>, <a href="/format/2308.13961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Translate Meanings, Not Just Words: IdiomKB&#x27;s Role in Optimizing  Idiomatic Translation with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiangjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Siyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shimin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14089" title="Abstract">arXiv:2308.14089</a> (replaced) [<a href="/pdf/2308.14089" title="Download PDF">pdf</a>, <a href="/format/2308.14089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedAlign: A Clinician-Generated Dataset for Instruction Following with  Electronic Medical Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fleming%2C+S+L">Scott L. Fleming</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Alejandro Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Haberkorn%2C+W+J">William J. Haberkorn</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+J+A">Jenelle A. Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Reis%2C+E+P">Eduardo P. Reis</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+R">Rahul Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Blankemeier%2C+L">Louis Blankemeier</a>, 
<a href="/search/cs?searchtype=author&query=Genkins%2C+J+Z">Julian Z. Genkins</a>, 
<a href="/search/cs?searchtype=author&query=Steinberg%2C+E">Ethan Steinberg</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+B+S">Birju S. Patel</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+C">Chia-Chun Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Callahan%2C+A">Alison Callahan</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Z">Zepeng Huo</a>, 
<a href="/search/cs?searchtype=author&query=Gatidis%2C+S">Sergios Gatidis</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+S+J">Scott J. Adams</a>, 
<a href="/search/cs?searchtype=author&query=Fayanju%2C+O">Oluseyi Fayanju</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S+J">Shreya J. Shah</a>, 
<a href="/search/cs?searchtype=author&query=Savage%2C+T">Thomas Savage</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+E">Ethan Goh</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+A+S">Akshay S. Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Aghaeepour%2C+N">Nima Aghaeepour</a>, 
<a href="/search/cs?searchtype=author&query=Sharp%2C+C">Christopher Sharp</a>, 
<a href="/search/cs?searchtype=author&query=Pfeffer%2C+M+A">Michael A. Pfeffer</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+H">Jonathan H. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Morse%2C+K+E">Keith E. Morse</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E+P">Emma P. Brunskill</a>, 
<a href="/search/cs?searchtype=author&query=Fries%2C+J+A">Jason A. Fries</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N+H">Nigam H. Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14602" title="Abstract">arXiv:2308.14602</a> (replaced) [<a href="/pdf/2308.14602" title="Download PDF">pdf</a>, <a href="/ps/2308.14602" title="Download PostScript">ps</a>, <a href="/format/2308.14602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Progress in Energy Management of Connected Hybrid Electric  Vehicles Using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hua%2C+M">Min Hua</a>, 
<a href="/search/eess?searchtype=author&query=Shuai%2C+B">Bin Shuai</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jinhai Wang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Y">Yinglong He</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+H">Hongming Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14958" title="Abstract">arXiv:2308.14958</a> (replaced) [<a href="/pdf/2308.14958" title="Download PDF">pdf</a>, <a href="/format/2308.14958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust topology optimisation of lattice structures with spatially  correlated uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ben-Yelun%2C+I">Ismael Ben-Yelun</a>, 
<a href="/search/math?searchtype=author&query=Yuksel%2C+A+O">Ahmet Oguzhan Yuksel</a>, 
<a href="/search/math?searchtype=author&query=Cirak%2C+F">Fehmi Cirak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16182" title="Abstract">arXiv:2308.16182</a> (replaced) [<a href="/pdf/2308.16182" title="Download PDF">pdf</a>, <a href="/format/2308.16182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GREC: Generalized Referring Expression Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shuting He</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GREC Technical Report, Project Page: <a href="https://henghuiding.github.io/GRES">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16902" title="Abstract">arXiv:2308.16902</a> (replaced) [<a href="/pdf/2308.16902" title="Download PDF">pdf</a>, <a href="/format/2308.16902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short Paper: Accountable Safety Implies Finality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neu%2C+J">Joachim Neu</a>, 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Financial Cryptography and Data Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01220" title="Abstract">arXiv:2309.01220</a> (replaced) [<a href="/pdf/2309.01220" title="Download PDF">pdf</a>, <a href="/format/2309.01220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the numerical approximation of the distance to singularity for  matrix-valued functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gnazzo%2C+M">Miryam Gnazzo</a>, 
<a href="/search/math?searchtype=author&query=Guglielmi%2C+N">Nicola Guglielmi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01966" title="Abstract">arXiv:2309.01966</a> (replaced) [<a href="/pdf/2309.01966" title="Download PDF">pdf</a>, <a href="/format/2309.01966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaPlus: Integrating Nesterov Momentum and Precise Stepsize Adjustment  on AdamW Basis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Lei Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02692" title="Abstract">arXiv:2309.02692</a> (replaced) [<a href="/pdf/2309.02692" title="Download PDF">pdf</a>, <a href="/format/2309.02692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hy-DeFake: Hypergraph Neural Networks for Detecting Fake News in Online  Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xing Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zitai Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04031" title="Abstract">arXiv:2309.04031</a> (replaced) [<a href="/pdf/2309.04031" title="Download PDF">pdf</a>, <a href="/format/2309.04031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Representation Transfer from Large Language Models to  End-to-End ASR Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udagawa%2C+T">Takuma Udagawa</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+M">Masayuki Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Kurata%2C+G">Gakuto Kurata</a>, 
<a href="/search/cs?searchtype=author&query=Muraoka%2C+M">Masayasu Muraoka</a>, 
<a href="/search/cs?searchtype=author&query=Saon%2C+G">George Saon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04780" title="Abstract">arXiv:2309.04780</a> (replaced) [<a href="/pdf/2309.04780" title="Download PDF">pdf</a>, <a href="/format/2309.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Degradation Representation Constraint for Single Image Deraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuhong He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Long Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jun Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05226" title="Abstract">arXiv:2309.05226</a> (replaced) [<a href="/pdf/2309.05226" title="Download PDF">pdf</a>, <a href="/format/2309.05226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Beamforming and Compression Design for Per-Antenna Power  Constrained Cooperative Cellular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xilai Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ya-Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, accepted for publication in IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05396" title="Abstract">arXiv:2309.05396</a> (replaced) [<a href="/pdf/2309.05396" title="Download PDF">pdf</a>, <a href="/format/2309.05396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SlideSpeech: A Large-Scale Slide-Enriched Audio-Visual Corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuezhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06397" title="Abstract">arXiv:2309.06397</a> (replaced) [<a href="/pdf/2309.06397" title="Download PDF">pdf</a>, <a href="/ps/2309.06397" title="Download PostScript">ps</a>, <a href="/format/2309.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Separation of Control Flow and Data Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arellanes%2C+D">Damian Arellanes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06415" title="Abstract">arXiv:2309.06415</a> (replaced) [<a href="/pdf/2309.06415" title="Download PDF">pdf</a>, <a href="/format/2309.06415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Down the Toxicity Rabbit Hole: Investigating PaLM 2 Guardrails
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khorramrouz%2C+A">Adel Khorramrouz</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Sujan Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Arka Dutta</a>, 
<a href="/search/cs?searchtype=author&query=KhudaBukhsh%2C+A+R">Ashiqur R. KhudaBukhsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07640" title="Abstract">arXiv:2309.07640</a> (replaced) [<a href="/pdf/2309.07640" title="Download PDF">pdf</a>, <a href="/format/2309.07640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indoor Scene Reconstruction with Fine-Grained Details Using Hybrid  Representation and Normal Prior Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Sheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yubin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Matthieu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yu-Hui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07867" title="Abstract">arXiv:2309.07867</a> (replaced) [<a href="/pdf/2309.07867" title="Download PDF">pdf</a>, <a href="/format/2309.07867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beta Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhendong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Huangjie Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation (stat.CO); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08072" title="Abstract">arXiv:2309.08072</a> (replaced) [<a href="/pdf/2309.08072" title="Download PDF">pdf</a>, <a href="/format/2309.08072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-Net: A Synergistic Spectral and Learning-based Network for Efficient  Bird Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08201" title="Abstract">arXiv:2309.08201</a> (replaced) [<a href="/pdf/2309.08201" title="Download PDF">pdf</a>, <a href="/format/2309.08201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity-Aware Distributed Learning for Gaussian Processes with Linear  Multiple Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suwandi%2C+R+C">Richard Cornelius Suwandi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhidi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiguo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Theodoridis%2C+S">Sergios Theodoridis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08420" title="Abstract">arXiv:2309.08420</a> (replaced) [<a href="/pdf/2309.08420" title="Download PDF">pdf</a>, <a href="/format/2309.08420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDCSR: Federated Cross-domain Sequential Recommendation via  Disentangled Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09180" title="Abstract">arXiv:2309.09180</a> (replaced) [<a href="/pdf/2309.09180" title="Download PDF">pdf</a>, <a href="/format/2309.09180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Speaker Diarization Using Memory-Aware Multi-Speaker Embedding  with Sequence-to-Sequence Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Gaobin Yang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+M">Maokui He</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+S">Shutong Niu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+Y">Yanyan Yue</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+S">Shuangqing Qian</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shilong Wu</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+C">Chin-Hui Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09262" title="Abstract">arXiv:2309.09262</a> (replaced) [<a href="/pdf/2309.09262" title="Download PDF">pdf</a>, <a href="/format/2309.09262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptVC: Flexible Stylistic Voice Conversion in Latent Space Driven by  Natural Language Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Jixun Yao</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yuguang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Lei%2C+Y">Yi Lei</a>, 
<a href="/search/eess?searchtype=author&query=Ning%2C+Z">Ziqian Ning</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yanni Hu</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Yu Pan</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+J">Jingjing Yin</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Hongbin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Heng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10342" title="Abstract">arXiv:2309.10342</a> (replaced) [<a href="/pdf/2309.10342" title="Download PDF">pdf</a>, <a href="/format/2309.10342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Beamforming Structure for Rate Splitting Multiple Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure,accepted for publication in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11988" title="Abstract">arXiv:2309.11988</a> (replaced) [<a href="/pdf/2309.11988" title="Download PDF">pdf</a>, <a href="/ps/2309.11988" title="Download PostScript">ps</a>, <a href="/format/2309.11988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relaxed Conditions for Parameterized Linear Matrix Inequality in the  Form of Nested Fuzzy Summations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+D+W">Do Wan Kim</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+D">Donghwan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE Transactions on Systems, Man and Cybernetics: Systems for possible publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12334" title="Abstract">arXiv:2309.12334</a> (replaced) [<a href="/pdf/2309.12334" title="Download PDF">pdf</a>, <a href="/ps/2309.12334" title="Download PostScript">ps</a>, <a href="/format/2309.12334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Knowledge Tracing is an implicit dynamic multidimensional item  response theory model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vie%2C+J">Jill-J&#xea;nn Vie</a> (SODA), 
<a href="/search/cs?searchtype=author&query=Kashima%2C+H">Hisashi Kashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 3 tables, accepted at ICCE 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCE 2023 - The 31st International Conference on Computers in
  Education, Asia-Pacific Society for Computers in Education, Dec 2023, Matsue,
  Shimane, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13504" title="Abstract">arXiv:2309.13504</a> (replaced) [<a href="/pdf/2309.13504" title="Download PDF">pdf</a>, <a href="/format/2309.13504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Is All You Need For Blind Room Volume Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chunxi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+M">Maoshen Jia</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Meiran Li</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+C">Changchun Bao</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+W">Wenyu Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, to be published in proceedings of ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14030" title="Abstract">arXiv:2309.14030</a> (replaced) [<a href="/pdf/2309.14030" title="Download PDF">pdf</a>, <a href="/format/2309.14030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeWave: Discrete EEG Waves Encoding for Brain Dynamics to Text  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinzhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14259" title="Abstract">arXiv:2309.14259</a> (replaced) [<a href="/pdf/2309.14259" title="Download PDF">pdf</a>, <a href="/format/2309.14259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Here Be Livestreams: Trade-offs in Creating Temporal Maps of Reddit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Partridge%2C+V">Virginia Partridge</a>, 
<a href="/search/cs?searchtype=author&query=Mangat%2C+J">Jasmine Mangat</a>, 
<a href="/search/cs?searchtype=author&query=Curran%2C+R">Rebecca Curran</a>, 
<a href="/search/cs?searchtype=author&query=McGrady%2C+R">Ryan McGrady</a>, 
<a href="/search/cs?searchtype=author&query=Zuckerman%2C+E">Ethan Zuckerman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14316" title="Abstract">arXiv:2309.14316</a> (replaced) [<a href="/pdf/2309.14316" title="Download PDF">pdf</a>, <a href="/format/2309.14316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics of Language Models: Part 3.1, Knowledge Storage and Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allen-Zhu%2C+Z">Zeyuan Allen-Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V2 polishes writing, fixing author name
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14745" title="Abstract">arXiv:2309.14745</a> (replaced) [<a href="/pdf/2309.14745" title="Download PDF">pdf</a>, <a href="/format/2309.14745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSPFusion: A Semantic Structure-Preserving Approach for Infrared and  Visible Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zijing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shunli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junzhe Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14970" title="Abstract">arXiv:2309.14970</a> (replaced) [<a href="/pdf/2309.14970" title="Download PDF">pdf</a>, <a href="/format/2309.14970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Hypernetworks are Surprisingly Strong in Meta-RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beck%2C+J">Jacob Beck</a>, 
<a href="/search/cs?searchtype=author&query=Vuorio%2C+R">Risto Vuorio</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023. We provide code at <a href="https://github.com/jacooba/hyper">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15074" title="Abstract">arXiv:2309.15074</a> (replaced) [<a href="/pdf/2309.15074" title="Download PDF">pdf</a>, <a href="/format/2309.15074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Language based Context Modeling and Reasoning for Ubiquitous  Computing with Large Language Models: A Tutorial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sijia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16426" title="Abstract">arXiv:2309.16426</a> (replaced) [<a href="/pdf/2309.16426" title="Download PDF">pdf</a>, <a href="/format/2309.16426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QwenGrasp: A Usage of Large Vision-Language Model for Target-Oriented  Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zonghan He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haobin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16924" title="Abstract">arXiv:2309.16924</a> (replaced) [<a href="/pdf/2309.16924" title="Download PDF">pdf</a>, <a href="/format/2309.16924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Rotation Averaging Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hainan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yangdong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shuhan Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00806" title="Abstract">arXiv:2310.00806</a> (replaced) [<a href="/pdf/2310.00806" title="Download PDF">pdf</a>, <a href="/format/2310.00806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Design Principles for Frequentist Sequential Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunbei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeevi%2C+A">Assaf Zeevi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01037" title="Abstract">arXiv:2310.01037</a> (replaced) [<a href="/pdf/2310.01037" title="Download PDF">pdf</a>, <a href="/format/2310.01037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeisT: A foundational deep learning model for earthquake monitoring  tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+S">Sen Li</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/physics?searchtype=author&query=Cao%2C+A">Anye Cao</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+C">Changbin Wang</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Y">Yaoqi Liu</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Y">Yapeng Liu</a>, 
<a href="/search/physics?searchtype=author&query=Niu%2C+Q">Qiang Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01393" title="Abstract">arXiv:2310.01393</a> (replaced) [<a href="/pdf/2310.01393" title="Download PDF">pdf</a>, <a href="/format/2310.01393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shilin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Size Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yining Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangliang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yunhai Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01545" title="Abstract">arXiv:2310.01545</a> (replaced) [<a href="/pdf/2310.01545" title="Download PDF">pdf</a>, <a href="/format/2310.01545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RF-ULM: Deep Learning for Radio-Frequency Ultrasound Localization  Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hahne%2C+C">Christopher Hahne</a>, 
<a href="/search/cs?searchtype=author&query=Chabouh%2C+G">Georges Chabouh</a>, 
<a href="/search/cs?searchtype=author&query=Chavignon%2C+A">Arthur Chavignon</a>, 
<a href="/search/cs?searchtype=author&query=Couture%2C+O">Olivier Couture</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01569" title="Abstract">arXiv:2310.01569</a> (replaced) [<a href="/pdf/2310.01569" title="Download PDF">pdf</a>, <a href="/format/2310.01569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Option Discovery for Planning, by Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Young%2C+K">Kenny Young</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+R+S">Richard S. Sutton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed incorrect arrows on some figures in the appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03165" title="Abstract">arXiv:2310.03165</a> (replaced) [<a href="/pdf/2310.03165" title="Download PDF">pdf</a>, <a href="/format/2310.03165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Accuracy in Deep Learning Using Random Matrix Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berlyand%2C+L">Leonid Berlyand</a>, 
<a href="/search/cs?searchtype=author&query=Sandier%2C+E">Etienne Sandier</a>, 
<a href="/search/cs?searchtype=author&query=Shmalo%2C+Y">Yitzchak Shmalo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05266" title="Abstract">arXiv:2310.05266</a> (replaced) [<a href="/pdf/2310.05266" title="Download PDF">pdf</a>, <a href="/format/2310.05266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DELTAHANDS: A Synergistic Dexterous Hand Framework Based on Delta Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+Z">Zilin Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kevin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kroemer%2C+O">Oliver Kroemer</a>, 
<a href="/search/cs?searchtype=author&query=Temel%2C+F+Z">F. Zeynep Temel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05354" title="Abstract">arXiv:2310.05354</a> (replaced) [<a href="/pdf/2310.05354" title="Download PDF">pdf</a>, <a href="/format/2310.05354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Initial Investigation of Neural Replay Simulator for Over-the-Air  Adversarial Perturbations to Automatic Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Liumeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06150" title="Abstract">arXiv:2310.06150</a> (replaced) [<a href="/pdf/2310.06150" title="Download PDF">pdf</a>, <a href="/format/2310.06150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Diffusion Model for DNA Sequence Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zehui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuhao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Huygelen%2C+T+A+B">Tim August B. Huygelen</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Akashaditya Das</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Guoxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Stan%2C+G">Guy-Bart Stan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 Conference on Neural Information Processing Systems (NeurIPS 2023) AI for Science Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07937" title="Abstract">arXiv:2310.07937</a> (replaced) [<a href="/pdf/2310.07937" title="Download PDF">pdf</a>, <a href="/format/2310.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bangguo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+H">Hamidreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08464" title="Abstract">arXiv:2310.08464</a> (replaced) [<a href="/pdf/2310.08464" title="Download PDF">pdf</a>, <a href="/format/2310.08464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crowdsourced and Automatic Speech Prominence Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morrison%2C+M">Max Morrison</a>, 
<a href="/search/eess?searchtype=author&query=Pawar%2C+P">Pranav Pawar</a>, 
<a href="/search/eess?searchtype=author&query=Pruyne%2C+N">Nathan Pruyne</a>, 
<a href="/search/eess?searchtype=author&query=Cole%2C+J">Jennifer Cole</a>, 
<a href="/search/eess?searchtype=author&query=Pardo%2C+B">Bryan Pardo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08475" title="Abstract">arXiv:2310.08475</a> (replaced) [<a href="/pdf/2310.08475" title="Download PDF">pdf</a>, <a href="/format/2310.08475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Edit Multimodal Large Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingbin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08699" title="Abstract">arXiv:2310.08699</a> (replaced) [<a href="/pdf/2310.08699" title="Download PDF">pdf</a>, <a href="/format/2310.08699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLadder: Supporting Programmers with Hierarchical Code Generation in  Multi-Level Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yen%2C+R">Ryan Yen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiawen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+S">Sangho Suh</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haijun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09235" title="Abstract">arXiv:2310.09235</a> (replaced) [<a href="/pdf/2310.09235" title="Download PDF">pdf</a>, <a href="/format/2310.09235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoPrompt: Supporting Prompt Sharing and Referring in Collaborative  Natural Language Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+F+L">Felicia Li Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+R">Ryan Yen</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yuzhe You</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09596" title="Abstract">arXiv:2310.09596</a> (replaced) [<a href="/pdf/2310.09596" title="Download PDF">pdf</a>, <a href="/format/2310.09596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RethinkingTMSC: An Empirical Study for Target-Oriented Multimodal  Sentiment Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Junfeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09739" title="Abstract">arXiv:2310.09739</a> (replaced) [<a href="/pdf/2310.09739" title="Download PDF">pdf</a>, <a href="/format/2310.09739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AugUndo: Scaling Up Augmentations for Unsupervised Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yangchao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+Y">Tian Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyoungseob Park</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+D">Dong Lao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alex Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09977" title="Abstract">arXiv:2310.09977</a> (replaced) [<a href="/pdf/2310.09977" title="Download PDF">pdf</a>, <a href="/format/2310.09977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ABACuS: All-Bank Activation Counters for Scalable and Low Overhead  RowHammer Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Tugrul%2C+Y+C">Yahya Can Tugrul</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+N">Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Yuksel%2C+I+E">Ismail Emir Yuksel</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Rhyner%2C+S">Steve Rhyner</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">Abdullah Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in USENIX Security '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10072" title="Abstract">arXiv:2310.10072</a> (replaced) [<a href="/pdf/2310.10072" title="Download PDF">pdf</a>, <a href="/format/2310.10072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning ChatGPT for Automatic Scoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Computers and Education: Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10451" title="Abstract">arXiv:2310.10451</a> (replaced) [<a href="/pdf/2310.10451" title="Download PDF">pdf</a>, <a href="/format/2310.10451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum walk-based scheme for distributed searching on arbitrary  graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Roget%2C+M">Mathieu Roget</a>, 
<a href="/search/quant-ph?searchtype=author&query=Di+Molfetta%2C+G">Giuseppe Di Molfetta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11346" title="Abstract">arXiv:2310.11346</a> (replaced) [<a href="/pdf/2310.11346" title="Download PDF">pdf</a>, <a href="/format/2310.11346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalizable Multi-Camera 3D Object Detection via Perspective  Debiasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Q">Qing Lian</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11971" title="Abstract">arXiv:2310.11971</a> (replaced) [<a href="/pdf/2310.11971" title="Download PDF">pdf</a>, <a href="/format/2310.11971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Generalization of Alignment with Human Preferences through  Group Invariant Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yuan Hua</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wenbin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haoran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12019" title="Abstract">arXiv:2310.12019</a> (replaced) [<a href="/pdf/2310.12019" title="Download PDF">pdf</a>, <a href="/format/2310.12019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DesignQuizzer: A Community-Powered Conversational Agent for Learning  Visual Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhenhui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiaoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Oulasvirta%2C+A">Antti Oulasvirta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12615" title="Abstract">arXiv:2310.12615</a> (replaced) [<a href="/pdf/2310.12615" title="Download PDF">pdf</a>, <a href="/format/2310.12615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Abstractions for Characterizing Communication Requirements in  Asynchronous Distributed Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galeana%2C+H+R">Hugo Rincon Galeana</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+U">Ulrich Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13266" title="Abstract">arXiv:2310.13266</a> (replaced) [<a href="/pdf/2310.13266" title="Download PDF">pdf</a>, <a href="/format/2310.13266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measurement-Based Small-Scale Channel Model for Sub-6 GHz RIS-Assisted  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jian Sang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jifeng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Boning Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14403" title="Abstract">arXiv:2310.14403</a> (replaced) [<a href="/pdf/2310.14403" title="Download PDF">pdf</a>, <a href="/format/2310.14403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> O3D: Offline Data-driven Discovery and Distillation for Sequential  Decision-Making with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuchen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanchao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengda Xu</a>, 
<a href="/search/cs?searchtype=author&query=Madhushani%2C+U">Udari Madhushani</a>, 
<a href="/search/cs?searchtype=author&query=Vann%2C+J">Jared Vann</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+D">Deepeka Garg</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+S">Sumitra Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14807" title="Abstract">arXiv:2310.14807</a> (replaced) [<a href="/pdf/2310.14807" title="Download PDF">pdf</a>, <a href="/ps/2310.14807" title="Download PostScript">ps</a>, <a href="/format/2310.14807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Chaitin&#x27;s Heuristic Principle and Halting Probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Salehi%2C+S">Saeed Salehi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages (consisting of two parts)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Information Theory (cs.IT); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14958" title="Abstract">arXiv:2310.14958</a> (replaced) [<a href="/pdf/2310.14958" title="Download PDF">pdf</a>, <a href="/format/2310.14958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Real-World Image De-Weathering with Imperfect Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaohe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chaoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+L">Lei Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15296" title="Abstract">arXiv:2310.15296</a> (replaced) [<a href="/pdf/2310.15296" title="Download PDF">pdf</a>, <a href="/format/2310.15296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based  LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fanyou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sengamedu%2C+S">Srinivasan Sengamedu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures, EMNLP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15399" title="Abstract">arXiv:2310.15399</a> (replaced) [<a href="/pdf/2310.15399" title="Download PDF">pdf</a>, <a href="/ps/2310.15399" title="Download PostScript">ps</a>, <a href="/format/2310.15399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GESI: Gammachirp Envelope Similarity Index for Predicting  Intelligibility of Simulated Hearing Loss Sounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yamamoto%2C+A">Ayako Yamamoto</a>, 
<a href="/search/eess?searchtype=author&query=Irino%2C+T">Toshio Irino</a>, 
<a href="/search/eess?searchtype=author&query=Miyazaki%2C+F">Fuki Miyazaki</a>, 
<a href="/search/eess?searchtype=author&query=Tamaru%2C+H">Honoka Tamaru</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was revised and resubmitted on December 26, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15400" title="Abstract">arXiv:2310.15400</a> (replaced) [<a href="/pdf/2310.15400" title="Download PDF">pdf</a>, <a href="/format/2310.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A practical approach to computing Lyapunov exponents of renewal and  delay equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breda%2C+D">Dimitri Breda</a>, 
<a href="/search/math?searchtype=author&query=Liessi%2C+D">Davide Liessi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16407" title="Abstract">arXiv:2310.16407</a> (replaced) [<a href="/pdf/2310.16407" title="Download PDF">pdf</a>, <a href="/format/2310.16407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-Theoretic Generalization Analysis for Topology-aware  Heterogeneous Federated Edge Learning over Noisy Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheshun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in IEEE Signal Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16979" title="Abstract">arXiv:2310.16979</a> (replaced) [<a href="/pdf/2310.16979" title="Download PDF">pdf</a>, <a href="/format/2310.16979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo  Label Self-Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mithun%2C+N+C">Niluthpol Chowdhury Mithun</a>, 
<a href="/search/cs?searchtype=author&query=Rajvanshi%2C+A">Abhinav Rajvanshi</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+H">Han-Pang Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Samarasekera%2C+S">Supun Samarasekera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18378" title="Abstract">arXiv:2310.18378</a> (replaced) [<a href="/pdf/2310.18378" title="Download PDF">pdf</a>, <a href="/format/2310.18378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ontology Revision based on Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qiu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guilin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuxin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaye Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Site Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jianjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Songtao Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18652" title="Abstract">arXiv:2310.18652</a> (replaced) [<a href="/pdf/2310.18652" title="Download PDF">pdf</a>, <a href="/format/2310.18652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health  Records with Chest X-ray Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Seongsu Bae</a>, 
<a href="/search/cs?searchtype=author&query=Kyung%2C+D">Daeun Kyung</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J">Jaehee Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+E">Eunbyeol Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyubok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kweon%2C+S">Sunjun Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jungwoo Oh</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Lei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E+I">Eric I-Chao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Tackeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Datasets and Benchmarks Track (10 pages for main text, 4 pages for references, 39 pages for supplementary materials)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01056" title="Abstract">arXiv:2311.01056</a> (replaced) [<a href="/pdf/2311.01056" title="Download PDF">pdf</a>, <a href="/format/2311.01056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboration and Transition: Distilling Item Transitions into  Multi-Query Self-Attention for Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yansong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+F">Fengran Mo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jian-Yun Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WSDM 2024 Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01212" title="Abstract">arXiv:2311.01212</a> (replaced) [<a href="/pdf/2311.01212" title="Download PDF">pdf</a>, <a href="/format/2311.01212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level Relation Learning for Cross-domain Few-shot Hyperspectral  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Longwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhigang Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianzhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junyong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01248" title="Abstract">arXiv:2311.01248</a> (replaced) [<a href="/pdf/2311.01248" title="Download PDF">pdf</a>, <a href="/format/2311.01248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal and Force-Matched Imitation Learning with a See-Through  Visuotactile Sensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ablett%2C+T">Trevor Ablett</a>, 
<a href="/search/cs?searchtype=author&query=Limoyo%2C+O">Oliver Limoyo</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+A">Adam Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Jilani%2C+A">Affan Jilani</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqi%2C+K">Kaleem Siddiqi</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Robotics (T-RO): Special Section on Tactile Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01796" title="Abstract">arXiv:2311.01796</a> (replaced) [<a href="/pdf/2311.01796" title="Download PDF">pdf</a>, <a href="/format/2311.01796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Augment Distributions for Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yonggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01813" title="Abstract">arXiv:2311.01813</a> (replaced) [<a href="/pdf/2311.01813" title="Download PDF">pdf</a>, <a href="/format/2311.01813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain  Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rundong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sishuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02240" title="Abstract">arXiv:2311.02240</a> (replaced) [<a href="/pdf/2311.02240" title="Download PDF">pdf</a>, <a href="/format/2311.02240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Machine Unlearning Benchmarks: Forgetting the Personal  Identities in Facial Recognition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dasol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Dongbin Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the AAAI 2024 Workshop on Privacy-Preserving Artificial Intelligence (PPAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02554" title="Abstract">arXiv:2311.02554</a> (replaced) [<a href="/pdf/2311.02554" title="Download PDF">pdf</a>, <a href="/format/2311.02554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pilot-Based Key Distribution and Encryption for Secure Coherent Passive  Optical Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haide Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Ji Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qingxin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jianrui Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yongqing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaohui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been submitted to the Journal of Lightwave Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04945" title="Abstract">arXiv:2311.04945</a> (replaced) [<a href="/pdf/2311.04945" title="Download PDF">pdf</a>, <a href="/format/2311.04945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto deep learning for bioacoustic signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tosato%2C+G">Giulio Tosato</a>, 
<a href="/search/cs?searchtype=author&query=Shehata%2C+A">Abdelrahman Shehata</a>, 
<a href="/search/cs?searchtype=author&query=Janssen%2C+J">Joshua Janssen</a>, 
<a href="/search/cs?searchtype=author&query=Kamp%2C+K">Kees Kamp</a>, 
<a href="/search/cs?searchtype=author&query=Jati%2C+P">Pramatya Jati</a>, 
<a href="/search/cs?searchtype=author&query=Stowell%2C+D">Dan Stowell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05197" title="Abstract">arXiv:2311.05197</a> (replaced) [<a href="/pdf/2311.05197" title="Download PDF">pdf</a>, <a href="/ps/2311.05197" title="Download PostScript">ps</a>, <a href="/format/2311.05197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning in Computed Tomography Pulmonary Angiography Imaging: A  Dual-Pronged Approach for Pulmonary Embolism Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bushra%2C+F">Fabiha Bushra</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+E+H">Muhammad E. H. Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Sarmun%2C+R">Rusab Sarmun</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+S">Saidul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Said%2C+M">Menatalla Said</a>, 
<a href="/search/cs?searchtype=author&query=Zoghoul%2C+S+B">Sohaib Bassam Zoghoul</a>, 
<a href="/search/cs?searchtype=author&query=Mushtak%2C+A">Adam Mushtak</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hashimi%2C+I">Israa Al-Hashimi</a>, 
<a href="/search/cs?searchtype=author&query=Alqahtani%2C+A">Abdulrahman Alqahtani</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Anwarul Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Expert Systems With Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05276" title="Abstract">arXiv:2311.05276</a> (replaced) [<a href="/pdf/2311.05276" title="Download PDF">pdf</a>, <a href="/format/2311.05276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMVG: A Multi-stage Image Vectorization Model with the Segment-Anything  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haokun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+J+I">Juang Ian Chong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Teng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Ran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Rosin%2C+P+L">Paul L. Rosin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06982" title="Abstract">arXiv:2311.06982</a> (replaced) [<a href="/pdf/2311.06982" title="Download PDF">pdf</a>, <a href="/format/2311.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral stability and perturbation results for kernel differentiation  matrices on the sphere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hangelbroek%2C+T">Thomas Hangelbroek</a>, 
<a href="/search/math?searchtype=author&query=Rieger%2C+C">Christian Rieger</a>, 
<a href="/search/math?searchtype=author&query=Wright%2C+G">Grady Wright</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06983" title="Abstract">arXiv:2311.06983</a> (replaced) [<a href="/pdf/2311.06983" title="Download PDF">pdf</a>, <a href="/format/2311.06983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Different View of Sigma-Delta Modulators Under the Lens of Pulse  Frequency Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Medina%2C+V">Victor Medina</a> (1), 
<a href="/search/eess?searchtype=author&query=Rombouts%2C+P">Pieter Rombouts</a> (2), 
<a href="/search/eess?searchtype=author&query=Hernandez%2C+L">Luis Hernandez</a> (1) ((1) Carlos III University, Madrid, Spain. (2) Ghent University, Belgium.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 28 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07125" title="Abstract">arXiv:2311.07125</a> (replaced) [<a href="/pdf/2311.07125" title="Download PDF">pdf</a>, <a href="/format/2311.07125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Challenging Multiple Instance Learning for Whole Slide Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Honglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07475" title="Abstract">arXiv:2311.07475</a> (replaced) [<a href="/e-print/2311.07475" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Face Dataset Generation and Masked Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuying Ning</a>, 
<a href="/search/cs?searchtype=author&query=Belhumeur%2C+P+N">Peter N. Belhumeur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is not a conference paper and is just a technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07831" title="Abstract">arXiv:2311.07831</a> (replaced) [<a href="/pdf/2311.07831" title="Download PDF">pdf</a>, <a href="/ps/2311.07831" title="Download PostScript">ps</a>, <a href="/format/2311.07831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covering Codes, List-Decodable Codes and Strong Singleton-Like Bounds in  the Sum-Rank Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, minor errors corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09889" title="Abstract">arXiv:2311.09889</a> (replaced) [<a href="/pdf/2311.09889" title="Download PDF">pdf</a>, <a href="/format/2311.09889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Generation from Brain Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lioma%2C+C">Christina Lioma</a>, 
<a href="/search/cs?searchtype=author&query=Ruotsalo%2C+T">Tuukka Ruotsalo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10944" title="Abstract">arXiv:2311.10944</a> (replaced) [<a href="/pdf/2311.10944" title="Download PDF">pdf</a>, <a href="/format/2311.10944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deception Detection from Linguistic and Physiological Data Streams Using  Bimodal Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Panfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Abouelenien%2C+M">Mohamed Abouelenien</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11056" title="Abstract">arXiv:2311.11056</a> (replaced) [<a href="/pdf/2311.11056" title="Download PDF">pdf</a>, <a href="/format/2311.11056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choose Your Simulator Wisely: A Review on Open-source Simulators for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Weihao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qiyuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11167" title="Abstract">arXiv:2311.11167</a> (replaced) [<a href="/pdf/2311.11167" title="Download PDF">pdf</a>, <a href="/format/2311.11167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Machine Learning Models for Quantum Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fu%2C+T">Tim Fu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preliminary version of the paper and is subject to further revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11261" title="Abstract">arXiv:2311.11261</a> (replaced) [<a href="/pdf/2311.11261" title="Download PDF">pdf</a>, <a href="/format/2311.11261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Prompt Tuning for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingjun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lingyu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11296" title="Abstract">arXiv:2311.11296</a> (replaced) [<a href="/pdf/2311.11296" title="Download PDF">pdf</a>, <a href="/format/2311.11296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Algorithms for Minimizing the Total Weighted  Completion Time of Coflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chi-Yeh Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11575" title="Abstract">arXiv:2311.11575</a> (replaced) [<a href="/pdf/2311.11575" title="Download PDF">pdf</a>, <a href="/format/2311.11575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing multivariate normality by testing independence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Daniu%C5%A1is%2C+P">Povilas Daniu&#x161;is</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12188" title="Abstract">arXiv:2311.12188</a> (replaced) [<a href="/pdf/2311.12188" title="Download PDF">pdf</a>, <a href="/ps/2311.12188" title="Download PostScript">ps</a>, <a href="/format/2311.12188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT and post-test probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weisenthal%2C+S+J">Samuel J. Weisenthal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 138 pages, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12875" title="Abstract">arXiv:2311.12875</a> (replaced) [<a href="/pdf/2311.12875" title="Download PDF">pdf</a>, <a href="/format/2311.12875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nav-Q: Quantum Deep Reinforcement Learning for Collision-Free Navigation  of Self-Driving Cars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+A">Akash Sinha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Macaluso%2C+A">Antonio Macaluso</a>, 
<a href="/search/quant-ph?searchtype=author&query=Klusch%2C+M">Matthias Klusch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 12 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13892" title="Abstract">arXiv:2311.13892</a> (replaced) [<a href="/pdf/2311.13892" title="Download PDF">pdf</a>, <a href="/format/2311.13892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Phrase Debiaser: Debiasing Masked Language Models at a  Multi-Token Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bingkang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+D">Dehan Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zongzhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Honglei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longtao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16552" title="Abstract">arXiv:2311.16552</a> (replaced) [<a href="/pdf/2311.16552" title="Download PDF">pdf</a>, <a href="/format/2311.16552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandyPriors: Physically Consistent Perception of Hand-Object  Interactions with Differentiable Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yi-Ling Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guanglei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Heiden%2C+E">Eric Heiden</a>, 
<a href="/search/cs?searchtype=author&query=Turpin%2C+D">Dylan Turpin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingzhou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Macklin%2C+M">Miles Macklin</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16918" title="Abstract">arXiv:2311.16918</a> (replaced) [<a href="/pdf/2311.16918" title="Download PDF">pdf</a>, <a href="/format/2311.16918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail  Richness in Text-to-3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lingteng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiaodong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Q">Qi Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mutian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yushuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weihao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zilong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://aigc3d.github.io/richdreamer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17280" title="Abstract">arXiv:2311.17280</a> (replaced) [<a href="/pdf/2311.17280" title="Download PDF">pdf</a>, <a href="/format/2311.17280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Ishika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by O-DRUM @ CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17366" title="Abstract">arXiv:2311.17366</a> (replaced) [<a href="/pdf/2311.17366" title="Download PDF">pdf</a>, <a href="/format/2311.17366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Hierarchical Temporal Transformer for Hand Action Recognition  and Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yilin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ohkawa%2C+T">Takehiko Ohkawa</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jia Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17842" title="Abstract">arXiv:2311.17842</a> (replaced) [<a href="/pdf/2311.17842" title="Download PDF">pdf</a>, <a href="/format/2311.17842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Before You Leap: Unveiling the Power of GPT-4V in Robotic  Vision-Language Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yingdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Fanqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv v2: add appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00343" title="Abstract">arXiv:2312.00343</a> (replaced) [<a href="/pdf/2312.00343" title="Download PDF">pdf</a>, <a href="/format/2312.00343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenStereo: A Comprehensive Benchmark for Stereo Matching and Strong  Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xianda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Juntao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00645" title="Abstract">arXiv:2312.00645</a> (replaced) [<a href="/pdf/2312.00645" title="Download PDF">pdf</a>, <a href="/format/2312.00645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bricman%2C+P">Paul Bricman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> addressed erratum, updated contact info
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01339" title="Abstract">arXiv:2312.01339</a> (replaced) [<a href="/pdf/2312.01339" title="Download PDF">pdf</a>, <a href="/format/2312.01339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+M+Z">Mohamed Zaky Saad</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper for ArabicNLP 2023 - The First Arabic Natural Language Processing Conference - Co-located with EMNLP 2023 in Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01678" title="Abstract">arXiv:2312.01678</a> (replaced) [<a href="/pdf/2312.01678" title="Download PDF">pdf</a>, <a href="/format/2312.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jellyfish: A Large Language Model for Data Preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haochen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuyang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Oyamada%2C+M">Masafumi Oyamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint under submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01700" title="Abstract">arXiv:2312.01700</a> (replaced) [<a href="/pdf/2312.01700" title="Download PDF">pdf</a>, <a href="/format/2312.01700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Management For Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zige Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02042" title="Abstract">arXiv:2312.02042</a> (replaced) [<a href="/pdf/2312.02042" title="Download PDF">pdf</a>, <a href="/format/2312.02042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kirchhoff Meets Johnson: In Pursuit of Unconditionally Secure  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, Under review for publication (revised version with certain improvements)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02317" title="Abstract">arXiv:2312.02317</a> (replaced) [<a href="/pdf/2312.02317" title="Download PDF">pdf</a>, <a href="/format/2312.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNN2R: Weakly-Supervised Rationale-Providing Question Answering over  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rossetto%2C+L">Luca Rossetto</a>, 
<a href="/search/cs?searchtype=author&query=Cochez%2C+M">Michael Cochez</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+A">Abraham Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02646" title="Abstract">arXiv:2312.02646</a> (replaced) [<a href="/pdf/2312.02646" title="Download PDF">pdf</a>, <a href="/format/2312.02646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMSGL: Series-Aligned Multi-Scale Graph Learning for Spatio-Temporal  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xiaobei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Luolin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kurths%2C+J">Jurgen Kurths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02751" title="Abstract">arXiv:2312.02751</a> (replaced) [<a href="/pdf/2312.02751" title="Download PDF">pdf</a>, <a href="/format/2312.02751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-NERF: Representing Scene Changes as Directional Consistency  Difference-based NeRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rui Huang</a> (1), 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Binbin Jiang</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingyi Zhao</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">William Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a> (1), 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a> (2 and 3) ((1) College of Computer Science and Technology, Civil Aviation University of China, China, (2) IHPC, Agency for Science, Technology and Research, Singapore, (3) CFAR, Agency for Science, Technology and Research, Singapore)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03212" title="Abstract">arXiv:2312.03212</a> (replaced) [<a href="/pdf/2312.03212" title="Download PDF">pdf</a>, <a href="/format/2312.03212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Bayesian Optimization Under Partial Observations: Balanced  Improvements and Provable Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The full version of our accepted paper in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03325" title="Abstract">arXiv:2312.03325</a> (replaced) [<a href="/pdf/2312.03325" title="Download PDF">pdf</a>, <a href="/format/2312.03325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAGC:Feature Augmentation on Geodesic Curve in the Pre-Shape Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuexing Han</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Guanxin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03685" title="Abstract">arXiv:2312.03685</a> (replaced) [<a href="/e-print/2312.03685" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Travelling Wave Solutions using Tanh Method for two-dimensional  Stochastic Allen-Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alzubaidi%2C+H">Hasan Alzubaidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Need to be revised in section of the derivation of exact travelling wave solutions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03752" title="Abstract">arXiv:2312.03752</a> (replaced) [<a href="/pdf/2312.03752" title="Download PDF">pdf</a>, <a href="/format/2312.03752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Scoring of Students&#x27; Science Writing Using Hybrid Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AI4ED-AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03863" title="Abstract">arXiv:2312.03863</a> (replaced) [<a href="/pdf/2312.03863" title="Download PDF">pdf</a>, <a href="/format/2312.03863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhongwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Samiul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhongnan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanlu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mosharaf Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04025" title="Abstract">arXiv:2312.04025</a> (replaced) [<a href="/pdf/2312.04025" title="Download PDF">pdf</a>, <a href="/format/2312.04025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moirai: Towards Optimal Placement for Distributed Inference on  Heterogeneous Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beibei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhihui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S+X">Sean Xiaoyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04569" title="Abstract">arXiv:2312.04569</a> (replaced) [<a href="/pdf/2312.04569" title="Download PDF">pdf</a>, <a href="/ps/2312.04569" title="Download PostScript">ps</a>, <a href="/format/2312.04569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do referees integrate evaluation criteria into their overall  judgment? Evidence from grant peer review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hug%2C+S+E">Sven E. Hug</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05332" title="Abstract">arXiv:2312.05332</a> (replaced) [<a href="/pdf/2312.05332" title="Download PDF">pdf</a>, <a href="/format/2312.05332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming  Controllers Inspired by Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yiwen Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zishuo Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yihan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+N">Na Li</a>, 
<a href="/search/eess?searchtype=author&query=Mo%2C+Y">Yilin Mo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05910" title="Abstract">arXiv:2312.05910</a> (replaced) [<a href="/pdf/2312.05910" title="Download PDF">pdf</a>, <a href="/format/2312.05910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Kalman Filtering-Aided Variational Inference for Gaussian  Process State-Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhidi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Thi%C3%A9ry%2C+A+H">Alexandre Hoang Thi&#xe9;ry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05911" title="Abstract">arXiv:2312.05911</a> (replaced) [<a href="/pdf/2312.05911" title="Download PDF">pdf</a>, <a href="/ps/2312.05911" title="Download PostScript">ps</a>, <a href="/format/2312.05911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A leave-one-out approach to approximate message passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bao%2C+Z">Zhigang Bao</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+Q">Qiyang Han</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xiaocong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06177" title="Abstract">arXiv:2312.06177</a> (replaced) [<a href="/pdf/2312.06177" title="Download PDF">pdf</a>, <a href="/format/2312.06177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Physics-Informed Machine Learning for Uncertainty  Quantification in High-Dimensional Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yifei Zong</a>, 
<a href="/search/cs?searchtype=author&query=Barajas-Solano%2C+D">David Barajas-Solano</a>, 
<a href="/search/cs?searchtype=author&query=Tartakovsky%2C+A+M">Alexandre M. Tartakovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06199" title="Abstract">arXiv:2312.06199</a> (replaced) [<a href="/pdf/2312.06199" title="Download PDF">pdf</a>, <a href="/format/2312.06199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transferable Adversarial Attacks with Centralized Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yu-an Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yajie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruinan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wencong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06353" title="Abstract">arXiv:2312.06353</a> (replaced) [<a href="/pdf/2312.06353" title="Download PDF">pdf</a>, <a href="/format/2312.06353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Full-Parameter Tuning of Billion-Sized Language Models with  Communication Cost under 18 Kilobytes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Daoyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+B">Bingchen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes are available at <a href="https://github.com/alibaba/FederatedScope/tree/FedKSeed.">this https URL</a> We will continuously update the codebase and arXiv version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06625" title="Abstract">arXiv:2312.06625</a> (replaced) [<a href="/pdf/2312.06625" title="Download PDF">pdf</a>, <a href="/format/2312.06625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Mean Field Games from Population and Environment Observations  By Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jinyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chenchen Mou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xianjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06635" title="Abstract">arXiv:2312.06635</a> (replaced) [<a href="/pdf/2312.06635" title="Download PDF">pdf</a>, <a href="/format/2312.06635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gated Linear Attention Transformers with Hardware-Efficient Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+R">Rameswar Panda</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> minor fix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06718" title="Abstract">arXiv:2312.06718</a> (replaced) [<a href="/pdf/2312.06718" title="Download PDF">pdf</a>, <a href="/format/2312.06718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Foundation Models for Intelligent Manufacturing  Applications: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dereck%2C+S+S">Semujju Stuart Dereck</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xianwei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Ye Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zhuo Long</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wensheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X+G">X.G. Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+R">Ruiyan Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07331" title="Abstract">arXiv:2312.07331</a> (replaced) [<a href="/pdf/2312.07331" title="Download PDF">pdf</a>, <a href="/format/2312.07331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupled Confusion Correction: Learning from Crowds with Sparse  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hansong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shikun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chenggang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Shiming Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted in AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07353" title="Abstract">arXiv:2312.07353</a> (replaced) [<a href="/pdf/2312.07353" title="Download PDF">pdf</a>, <a href="/format/2312.07353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP in Medical Imaging: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+L">Lin Teng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Disheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page available at <a href="https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07401" title="Abstract">arXiv:2312.07401</a> (replaced) [<a href="/pdf/2312.07401" title="Download PDF">pdf</a>, <a href="/format/2312.07401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Diversified Preferences of Large Language Model Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianhao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wanshun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07625" title="Abstract">arXiv:2312.07625</a> (replaced) [<a href="/pdf/2312.07625" title="Download PDF">pdf</a>, <a href="/format/2312.07625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astrocyte-Enabled Advancements in Spiking Neural Networks for Large  Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jindong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07823" title="Abstract">arXiv:2312.07823</a> (replaced) [<a href="/pdf/2312.07823" title="Download PDF">pdf</a>, <a href="/format/2312.07823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Lens: Instance-Centric Semantic Alignment for Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07991" title="Abstract">arXiv:2312.07991</a> (replaced) [<a href="/pdf/2312.07991" title="Download PDF">pdf</a>, <a href="/format/2312.07991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the Global Aggregation of Local Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mor%2C+A">Alon Mor</a>, 
<a href="/search/cs?searchtype=author&query=Belinkov%2C+Y">Yonatan Belinkov</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08019" title="Abstract">arXiv:2312.08019</a> (replaced) [<a href="/pdf/2312.08019" title="Download PDF">pdf</a>, <a href="/format/2312.08019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdapEdit: Spatio-Temporal Guided Adaptive Editing Algorithm for  Text-Based Continuity-Sensitive Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+G">Guoli Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08372" title="Abstract">arXiv:2312.08372</a> (replaced) [<a href="/pdf/2312.08372" title="Download PDF">pdf</a>, <a href="/format/2312.08372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-guided Graph Cut for 3D Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haoyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">He Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sida Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruizhen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://zju3dv.github.io/sam_graph">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08550" title="Abstract">arXiv:2312.08550</a> (replaced) [<a href="/pdf/2312.08550" title="Download PDF">pdf</a>, <a href="/format/2312.08550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonics of Learning: Universal Fourier Features Emerge in Invariant  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marchetti%2C+G+L">Giovanni Luca Marchetti</a>, 
<a href="/search/cs?searchtype=author&query=Hillar%2C+C">Christopher Hillar</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>, 
<a href="/search/cs?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08585" title="Abstract">arXiv:2312.08585</a> (replaced) [<a href="/e-print/2312.08585" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Key Factors of Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingxuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Linzhuang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bihui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruifeng Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I am requesting the withdrawal of this paper from arXiv due to the realization that the overall composition and structure of the article are not yet sufficiently refined. It is my intention to thoroughly revise and enhance the paper to ensure that it meets the highest standards of academic writing and accurately reflects the research conducted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08642" title="Abstract">arXiv:2312.08642</a> (replaced) [<a href="/pdf/2312.08642" title="Download PDF">pdf</a>, <a href="/format/2312.08642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metacognition-Enhanced Few-Shot Prompting With Positive Reinforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08749" title="Abstract">arXiv:2312.08749</a> (replaced) [<a href="/pdf/2312.08749" title="Download PDF">pdf</a>, <a href="/format/2312.08749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Label Bias in Machine Learning: Fairness through Confident  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zenan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08874" title="Abstract">arXiv:2312.08874</a> (replaced) [<a href="/pdf/2312.08874" title="Download PDF">pdf</a>, <a href="/format/2312.08874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Attention: On the Integration of Softmax and Linear Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tianzhu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yizeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhuofan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08889" title="Abstract">arXiv:2312.08889</a> (replaced) [<a href="/pdf/2312.08889" title="Download PDF">pdf</a>, <a href="/format/2312.08889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained  Geometry and Appearance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanyou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08901" title="Abstract">arXiv:2312.08901</a> (replaced) [<a href="/pdf/2312.08901" title="Download PDF">pdf</a>, <a href="/format/2312.08901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting LLM Reasoning: Push the Limits of Few-shot Learning with  Reinforced In-Context Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+L">Li Lyna Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09245" title="Abstract">arXiv:2312.09245</a> (replaced) [<a href="/pdf/2312.09245" title="Download PDF">pdf</a>, <a href="/format/2312.09245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral  Planning States for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiangwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">ChuanYang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Haoming Zou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wenwen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Silei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hanming Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09257" title="Abstract">arXiv:2312.09257</a> (replaced) [<a href="/pdf/2312.09257" title="Download PDF">pdf</a>, <a href="/format/2312.09257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-Inspired Machine Intelligence: A Survey of  Neurobiologically-Plausible Credit Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ororbia%2C+A+G">Alexander G. Ororbia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09425" title="Abstract">arXiv:2312.09425</a> (replaced) [<a href="/pdf/2312.09425" title="Download PDF">pdf</a>, <a href="/ps/2312.09425" title="Download PostScript">ps</a>, <a href="/format/2312.09425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YouTube Video Analytics for Patient Health Literacy: Evidence from  Colonoscopy Preparation Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yawen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Susarla%2C+A">Anjana Susarla</a>, 
<a href="/search/cs?searchtype=author&query=Padman%2C+R">Rema Padman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 30th WORKSHOP ON INFORMATION TECHNOLOGIES AND SYSTEMS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09520" title="Abstract">arXiv:2312.09520</a> (replaced) [<a href="/pdf/2312.09520" title="Download PDF">pdf</a>, <a href="/format/2312.09520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SlowTrack: Increasing the Latency of Camera-based Perception in  Autonomous Driving Using Adversarial Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+A">Qi Alfred Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09598" title="Abstract">arXiv:2312.09598</a> (replaced) [<a href="/pdf/2312.09598" title="Download PDF">pdf</a>, <a href="/format/2312.09598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLAF: Contrastive Learning with Augmented Features for Imbalanced  Semi-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+B">Bowen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin-Chun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-Chuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09781" title="Abstract">arXiv:2312.09781</a> (replaced) [<a href="/pdf/2312.09781" title="Download PDF">pdf</a>, <a href="/format/2312.09781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSQA: An End-to-End Model for Generative Spoken Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shih%2C+M">Min-Han Shih</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H">Ho-Lam Chung</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+Y">Yu-Chi Pai</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+M">Ming-Hao Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guan-Ting Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shang-Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09821" title="Abstract">arXiv:2312.09821</a> (replaced) [<a href="/pdf/2312.09821" title="Download PDF">pdf</a>, <a href="/format/2312.09821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fragility, Robustness and Antifragility in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pravin%2C+C">Chandresh Pravin</a>, 
<a href="/search/cs?searchtype=author&query=Martino%2C+I">Ivan Martino</a>, 
<a href="/search/cs?searchtype=author&query=Nicosia%2C+G">Giuseppe Nicosia</a>, 
<a href="/search/cs?searchtype=author&query=Ojha%2C+V">Varun Ojha</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Artificial Intelligence 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09951" title="Abstract">arXiv:2312.09951</a> (replaced) [<a href="/pdf/2312.09951" title="Download PDF">pdf</a>, <a href="/ps/2312.09951" title="Download PostScript">ps</a>, <a href="/format/2312.09951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Alon-Tarsi Number of Some Line and Total graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prajnanaswaroopa%2C+S">S. Prajnanaswaroopa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10032" title="Abstract">arXiv:2312.10032</a> (replaced) [<a href="/pdf/2312.10032" title="Download PDF">pdf</a>, <a href="/format/2312.10032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Osprey: Pixel Understanding with Visual Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuqian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wentong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Dongqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xinjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianke Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, Code and Demo link:<a href="https://github.com/CircleRadon/Osprey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10104" title="Abstract">arXiv:2312.10104</a> (replaced) [<a href="/pdf/2312.10104" title="Download PDF">pdf</a>, <a href="/format/2312.10104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICD-LM: Configuring Vision-Language In-Context Demonstrations by  Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yingzhe Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yucheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10381" title="Abstract">arXiv:2312.10381</a> (replaced) [<a href="/pdf/2312.10381" title="Download PDF">pdf</a>, <a href="/format/2312.10381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SECap: Speech Emotion Captioning with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yaoxun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiaochu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shixiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Rongzhi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10385" title="Abstract">arXiv:2312.10385</a> (replaced) [<a href="/pdf/2312.10385" title="Download PDF">pdf</a>, <a href="/format/2312.10385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitate the Good and Avoid the Bad: An Incremental Approach to Safe  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+H">Huy Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+T">Tien Mai</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+P">Pradeep Varakantham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10407" title="Abstract">arXiv:2312.10407</a> (replaced) [<a href="/pdf/2312.10407" title="Download PDF">pdf</a>, <a href="/ps/2312.10407" title="Download PostScript">ps</a>, <a href="/format/2312.10407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepArt: A Benchmark to Advance Fidelity Research in AI-Generated  Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wentao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanyao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Swalpa Kumar Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the second version of this work, and new contributors join and the modification content is greatly increased
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10587" title="Abstract">arXiv:2312.10587</a> (replaced) [<a href="/pdf/2312.10587" title="Download PDF">pdf</a>, <a href="/format/2312.10587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2E-AT: A Unified Framework for Tackling Uncertainty in Task-aware  End-to-end Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wangkun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10628" title="Abstract">arXiv:2312.10628</a> (replaced) [<a href="/pdf/2312.10628" title="Download PDF">pdf</a>, <a href="/format/2312.10628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T2M-HiFiGPT: Generating High Quality Human Motion from Textual  Descriptions with Residual Discrete Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Congyi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.06052">arXiv:2301.06052</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10766" title="Abstract">arXiv:2312.10766</a> (replaced) [<a href="/pdf/2312.10766" title="Download PDF">pdf</a>, <a href="/format/2312.10766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaojun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10833" title="Abstract">arXiv:2312.10833</a> (replaced) [<a href="/pdf/2312.10833" title="Download PDF">pdf</a>, <a href="/format/2312.10833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An answer to the questions regarding AI gender bias, Submitted to Educational Technology &amp; Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10943" title="Abstract">arXiv:2312.10943</a> (replaced) [<a href="/pdf/2312.10943" title="Download PDF">pdf</a>, <a href="/format/2312.10943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Stealing Attack against Graph Classification with Authenticity,  Uncertainty and Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10987" title="Abstract">arXiv:2312.10987</a> (replaced) [<a href="/pdf/2312.10987" title="Download PDF">pdf</a>, <a href="/format/2312.10987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Contamination Issues in Brain-to-Text Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Congchi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhiwei Fang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jie He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Changping Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Piji Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11152" title="Abstract">arXiv:2312.11152</a> (replaced) [<a href="/pdf/2312.11152" title="Download PDF">pdf</a>, <a href="/format/2312.11152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Based Tri-Channel Graph Convolution Neural Network for Aspect  Sentiment Triplet Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiaqian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S.Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11193" title="Abstract">arXiv:2312.11193</a> (replaced) [<a href="/pdf/2312.11193" title="Download PDF">pdf</a>, <a href="/ps/2312.11193" title="Download PostScript">ps</a>, <a href="/format/2312.11193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Paraphrasing The Original Text&quot; Makes High Accuracy Long-Context QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijiong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chinese version of this paper can be downloaded from (<a href="https://cloud.tsinghua.edu.cn/d/5894ec4442e54a6aac96/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11201" title="Abstract">arXiv:2312.11201</a> (replaced) [<a href="/pdf/2312.11201" title="Download PDF">pdf</a>, <a href="/format/2312.11201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Refining Underlying Information Framework for Monaural Speech  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+R">Rui Cao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tianrui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+M">Meng Ge</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11242" title="Abstract">arXiv:2312.11242</a> (replaced) [<a href="/pdf/2312.11242" title="Download PDF">pdf</a>, <a href="/format/2312.11242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Changyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinnian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian-Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update title+abstract+intro+appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11444" title="Abstract">arXiv:2312.11444</a> (replaced) [<a href="/pdf/2312.11444" title="Download PDF">pdf</a>, <a href="/format/2312.11444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-depth Look at Gemini&#x27;s Language Abilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+S+N">Syeda Nahida Akter</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zichun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Muhamed%2C+A">Aashiq Muhamed</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+T">Tianyue Ou</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uerle%2C+A">Alex B&#xe4;uerle</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+%C3%81+A">&#xc1;ngel Alexander Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Dholakia%2C+K">Krish Dholakia</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Chenyan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11518" title="Abstract">arXiv:2312.11518</a> (replaced) [<a href="/pdf/2312.11518" title="Download PDF">pdf</a>, <a href="/format/2312.11518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Modeling in the Era of Large Language Models: Current Research and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhaoxuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Data Engineering Bulletin 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11562" title="Abstract">arXiv:2312.11562</a> (replaced) [<a href="/pdf/2312.11562" title="Download PDF">pdf</a>, <a href="/format/2312.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Reasoning with Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+R">Ruihang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Figures, 160 Pages, 750+ References, Project Page <a href="https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11571" title="Abstract">arXiv:2312.11571</a> (replaced) [<a href="/pdf/2312.11571" title="Download PDF">pdf</a>, <a href="/format/2312.11571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Stealing Attack against Recommender System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11583" title="Abstract">arXiv:2312.11583</a> (replaced) [<a href="/pdf/2312.11583" title="Download PDF">pdf</a>, <a href="/format/2312.11583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Based Energy Transportation Safety: Pipeline Radial Threat Estimation  Using Intelligent Sensing System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chengyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qinmin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+L+P">C. L. Philip Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11740" title="Abstract">arXiv:2312.11740</a> (replaced) [<a href="/pdf/2312.11740" title="Download PDF">pdf</a>, <a href="/format/2312.11740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composable Design of Multiphase Fluid Dynamics Solvers in Flash-X
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhruv%2C+A">Akash Dhruv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12021" title="Abstract">arXiv:2312.12021</a> (replaced) [<a href="/pdf/2312.12021" title="Download PDF">pdf</a>, <a href="/format/2312.12021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Anchored Contrastive Pre-training for Few-Shot Relation  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Da Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yanglei Gan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Run Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuxiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wannian Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12223" title="Abstract">arXiv:2312.12223</a> (replaced) [<a href="/pdf/2312.12223" title="Download PDF">pdf</a>, <a href="/format/2312.12223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Detection of Perfect and Partial Input-Dependent  Symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urbano%2C+A">Alonso Urbano</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+W">David W. Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures, corrected typos, revised argument in Appendix B.1, results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12340" title="Abstract">arXiv:2312.12340</a> (replaced) [<a href="/pdf/2312.12340" title="Download PDF">pdf</a>, <a href="/format/2312.12340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Geometric Fracture Assembly via Co-creation Space among  Assemblers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexi Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12564" title="Abstract">arXiv:2312.12564</a> (replaced) [<a href="/pdf/2312.12564" title="Download PDF">pdf</a>, <a href="/format/2312.12564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leading the Pack: N-player Opponent Shaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Souly%2C+A">Alexandra Souly</a>, 
<a href="/search/cs?searchtype=author&query=Willi%2C+T">Timon Willi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Akbir Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+R">Robert Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chris Lu</a>, 
<a href="/search/cs?searchtype=author&query=Grefenstette%2C+E">Edward Grefenstette</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12715" title="Abstract">arXiv:2312.12715</a> (replaced) [<a href="/pdf/2312.12715" title="Download PDF">pdf</a>, <a href="/format/2312.12715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Performance Maximizing Ensembles with Explainability Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pisztora%2C+V">Vincent Pisztora</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12809" title="Abstract">arXiv:2312.12809</a> (replaced) [<a href="/pdf/2312.12809" title="Download PDF">pdf</a>, <a href="/format/2312.12809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gecko: Automated Feature Degradation for Cloud Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+K">Kapil Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 supplemental pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12850" title="Abstract">arXiv:2312.12850</a> (replaced) [<a href="/pdf/2312.12850" title="Download PDF">pdf</a>, <a href="/ps/2312.12850" title="Download PostScript">ps</a>, <a href="/format/2312.12850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Analysis of the Linguistic Provenance of English Place  Names
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalvean%2C+M">Michael Dalvean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13332" title="Abstract">arXiv:2312.13332</a> (replaced) [<a href="/pdf/2312.13332" title="Download PDF">pdf</a>, <a href="/format/2312.13332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ternary-type Opacity and Hybrid Odometry for RGB-only NeRF-SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nachkov%2C+A">Asen Nachkov</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Songyou Peng</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13533" title="Abstract">arXiv:2312.13533</a> (replaced) [<a href="/pdf/2312.13533" title="Download PDF">pdf</a>, <a href="/format/2312.13533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Clinical Coding for Outpatient Departments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+V">Viktor Schlegel</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+A+R">Abhinav Ramesh Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh-Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tsung-Han Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V+P">Vijay Prakash Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei-Hsian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+S">Stefan Winkler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, preprint under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13555" title="Abstract">arXiv:2312.13555</a> (replaced) [<a href="/pdf/2312.13555" title="Download PDF">pdf</a>, <a href="/format/2312.13555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CR-SAM: Curvature Regularized Sharpness-Aware Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wunsch%2C+D+C">Donald C. Wunsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, main track. Code available on Github. Appendix is also included in this updated version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13680" title="Abstract">arXiv:2312.13680</a> (replaced) [<a href="/pdf/2312.13680" title="Download PDF">pdf</a>, <a href="/format/2312.13680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGE: Embedding Temporal Knowledge Graphs in a Product Space of  Heterogeneous Geometric Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiaxin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Nayyeri%2C+M">Mojtaba Nayyeri</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinan Li</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13700" title="Abstract">arXiv:2312.13700</a> (replaced) [<a href="/pdf/2312.13700" title="Download PDF">pdf</a>, <a href="/ps/2312.13700" title="Download PostScript">ps</a>, <a href="/format/2312.13700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer boycotts in convex games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fokkink%2C+R">Robbert Fokkink</a>, 
<a href="/search/cs?searchtype=author&query=de+Munnik%2C+H">Hans de Munnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13702" title="Abstract">arXiv:2312.13702</a> (replaced) [<a href="/pdf/2312.13702" title="Download PDF">pdf</a>, <a href="/format/2312.13702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local certification of local properties: tight bounds, trade-offs and  new parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousquet%2C+N">Nicolas Bousquet</a>, 
<a href="/search/cs?searchtype=author&query=Feuilloley%2C+L">Laurent Feuilloley</a>, 
<a href="/search/cs?searchtype=author&query=Zeitoun%2C+S">S&#xe9;bastien Zeitoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13772" title="Abstract">arXiv:2312.13772</a> (replaced) [<a href="/pdf/2312.13772" title="Download PDF">pdf</a>, <a href="/format/2312.13772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Task Performance and Model Calibration with Supervised and  Self-Ensembled In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengzu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Glava%C5%A1%2C+G">Goran Glava&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 5 tables (20 pages, 5 figures, 13 tables including references and appendices)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13923" title="Abstract">arXiv:2312.13923</a> (replaced) [<a href="/pdf/2312.13923" title="Download PDF">pdf</a>, <a href="/format/2312.13923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-CO2: Cooperation of Online and Offline Models for Severe Data  Heterogeneity in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13933" title="Abstract">arXiv:2312.13933</a> (replaced) [<a href="/pdf/2312.13933" title="Download PDF">pdf</a>, <a href="/format/2312.13933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Probabilistic Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dou Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lingwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14062" title="Abstract">arXiv:2312.14062</a> (replaced) [<a href="/pdf/2312.14062" title="Download PDF">pdf</a>, <a href="/ps/2312.14062" title="Download PostScript">ps</a>, <a href="/format/2312.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimate and long-time energy conservation of a symmetric  low-regularity integrator for nonlinear Klein-Gordon equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/math?searchtype=author&query=Miao%2C+Z">Zhen Miao</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yaolin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14091" title="Abstract">arXiv:2312.14091</a> (replaced) [<a href="/pdf/2312.14091" title="Download PDF">pdf</a>, <a href="/format/2312.14091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HD-Painter: High-Resolution and Prompt-Faithful Text-Guided Image  Inpainting with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manukyan%2C+H">Hayk Manukyan</a>, 
<a href="/search/cs?searchtype=author&query=Sargsyan%2C+A">Andranik Sargsyan</a>, 
<a href="/search/cs?searchtype=author&query=Atanyan%2C+B">Barsegh Atanyan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Navasardyan%2C+S">Shant Navasardyan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14135" title="Abstract">arXiv:2312.14135</a> (replaced) [<a href="/pdf/2312.14135" title="Download PDF">pdf</a>, <a href="/format/2312.14135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Penghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Saining Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page with code: <a href="https://vstar-seal.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14187" title="Abstract">arXiv:2312.14187</a> (replaced) [<a href="/pdf/2312.14187" title="Download PDF">pdf</a>, <a href="/format/2312.14187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with  Refined Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaojian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+N">Ning Shang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yishujie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Qiufeng Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14222" title="Abstract">arXiv:2312.14222</a> (replaced) [<a href="/pdf/2312.14222" title="Download PDF">pdf</a>, <a href="/format/2312.14222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Topology Isomorphism Expertise Embedded Graph Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yifan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14430" title="Abstract">arXiv:2312.14430</a> (replaced) [<a href="/html/2312.14430" title="Download HTML">html</a>, <a href="/format/2312.14430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>, 
<a href="/search/cs?searchtype=author&query=Minato%2C+T">Takashi Minato</a>, 
<a href="/search/cs?searchtype=author&query=Nishizaki%2C+H">Hiromitsu Nishizaki</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+T">Takayuki Nagai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a proceedings of the Dialogue Robot Competition 2023. Totally 13 papers are indexed in the proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14492" title="Abstract">arXiv:2312.14492</a> (replaced) [<a href="/pdf/2312.14492" title="Download PDF">pdf</a>, <a href="/format/2312.14492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Enhanced Transformer for Single Image Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+S">Seungjun An</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonghoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gyeongnyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jeongyeol Baek</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeongwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ku-cvlab.github.io/CETR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14507" title="Abstract">arXiv:2312.14507</a> (replaced) [<a href="/pdf/2312.14507" title="Download PDF">pdf</a>, <a href="/format/2312.14507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Harmonic Parameter Estimation Using Differentiable DSP and  Spectral Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torres%2C+B">Bernardo Torres</a> (S2A, IDS, LTCI), 
<a href="/search/cs?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a> (S2A, IDS, LTCI), 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Ga&#xeb;l Richard</a> (S2A, IDS, LTCI)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Acoustics, Speech and Signal
  Processing, Apr 2024, Seoul, South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14713" title="Abstract">arXiv:2312.14713</a> (replaced) [<a href="/pdf/2312.14713" title="Download PDF">pdf</a>, <a href="/format/2312.14713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Transfer Multiobjective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14745" title="Abstract">arXiv:2312.14745</a> (replaced) [<a href="/pdf/2312.14745" title="Download PDF">pdf</a>, <a href="/ps/2312.14745" title="Download PostScript">ps</a>, <a href="/format/2312.14745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strengthening Nash Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14769" title="Abstract">arXiv:2312.14769</a> (replaced) [<a href="/pdf/2312.14769" title="Download PDF">pdf</a>, <a href="/ps/2312.14769" title="Download PostScript">ps</a>, <a href="/format/2312.14769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model (LLM) Bias Index -- LLMBI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>, 
<a href="/search/cs?searchtype=author&query=Anas%2C+M">Muhammad Anas</a>, 
<a href="/search/cs?searchtype=author&query=Saina%2C+D">Deepthi Saina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14775" title="Abstract">arXiv:2312.14775</a> (replaced) [<a href="/pdf/2312.14775" title="Download PDF">pdf</a>, <a href="/ps/2312.14775" title="Download PostScript">ps</a>, <a href="/format/2312.14775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounding the Communication Complexity of Fault-Tolerant Common Coin  Tossing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+J+Y">Joseph Y. Halpern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14793" title="Abstract">arXiv:2312.14793</a> (replaced) [<a href="/pdf/2312.14793" title="Download PDF">pdf</a>, <a href="/format/2312.14793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Value of Mediation in Long Cheap Talk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arieli%2C+I">Itai Arieli</a>, 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14847" title="Abstract">arXiv:2312.14847</a> (replaced) [<a href="/pdf/2312.14847" title="Download PDF">pdf</a>, <a href="/format/2312.14847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Training of Graph Neural Networks for Optimal Markov-Chain  Partitioning Using the Kemeny Constant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Martino%2C+S+A">Sam Alexander Martino</a>, 
<a href="/search/physics?searchtype=author&query=Morado%2C+J">Jo&#xe3;o Morado</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/physics?searchtype=author&query=Lu%2C+Z">Zhenghao Lu</a>, 
<a href="/search/physics?searchtype=author&query=Rosta%2C+E">Edina Rosta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14852" title="Abstract">arXiv:2312.14852</a> (replaced) [<a href="/pdf/2312.14852" title="Download PDF">pdf</a>, <a href="/format/2312.14852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACO: Topics in Algorithmic COde generation dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongao Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo-Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chen Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14890" title="Abstract">arXiv:2312.14890</a> (replaced) [<a href="/pdf/2312.14890" title="Download PDF">pdf</a>, <a href="/format/2312.14890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language  Models via Complexity Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lizhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haoyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hemphill%2C+L">Libby Hemphill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14919" title="Abstract">arXiv:2312.14919</a> (replaced) [<a href="/pdf/2312.14919" title="Download PDF">pdf</a>, <a href="/format/2312.14919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lift-Attend-Splat: Bird&#x27;s-eye-view camera-lidar fusion using  transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gunn%2C+J">James Gunn</a>, 
<a href="/search/cs?searchtype=author&query=Lenyk%2C+Z">Zygmunt Lenyk</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Anuj Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Donati%2C+A">Andrea Donati</a>, 
<a href="/search/cs?searchtype=author&query=Buburuzan%2C+A">Alexandru Buburuzan</a>, 
<a href="/search/cs?searchtype=author&query=Redford%2C+J">John Redford</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+R">Romain Mueller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated method figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14924" title="Abstract">arXiv:2312.14924</a> (replaced) [<a href="/pdf/2312.14924" title="Download PDF">pdf</a>, <a href="/format/2312.14924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Convolutional Neural Networks with the Forward-Forward  algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scodellaro%2C+R">Riccardo Scodellaro</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Ajinkya Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+F">Frauke Alves</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6ter%2C+M">Matthias Schr&#xf6;ter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item550">Cross-lists</a></li>
<li><a href="#item616">Replacements</a></li>
</ul>
<small>[ total of 1023 entries:  <b>1-1023</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
