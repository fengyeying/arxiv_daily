<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 26 Dec 23  to  Thu 28 Dec 23, announced Fri, 29 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item414">Cross-lists</a></li>
<li><a href="#item484">Replacements</a></li>
</ul>
<small>[ total of 754 entries:  <b>1-754</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 29 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16174" title="Abstract">arXiv:2312.16174</a> [<a href="/pdf/2312.16174" title="Download PDF">pdf</a>, <a href="/format/2312.16174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Industrial Internet of Things Intelligence Empowering Smart  Manufacturing: A Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yujiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Q">Qingmin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mengjie Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaomao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Renchao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F+R">F. Richard Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Now under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The fiercely competitive business environment and increasingly personalized
customization needs are driving the digital transformation and upgrading of the
manufacturing industry. IIoT intelligence, which can provide innovative and
efficient solutions for various aspects of the manufacturing value chain,
illuminates the path of transformation for the manufacturing industry. It is
time to provide a systematic vision of IIoT intelligence. However, existing
surveys often focus on specific areas of IIoT intelligence, leading researchers
and readers to have biases in their understanding of IIoT intelligence, that
is, believing that research in one direction is the most important for the
development of IIoT intelligence, while ignoring contributions from other
directions. Therefore, this paper provides a comprehensive overview of IIoT
intelligence. We first conduct an in-depth analysis of the inevitability of
manufacturing transformation and study the successful experiences from the
practices of Chinese enterprises. Then we give our definition of IIoT
intelligence and demonstrate the value of IIoT intelligence for industries in
fucntions, operations, deployments, and application. Afterwards, we propose a
hierarchical development architecture for IIoT intelligence, which consists of
five layers. The practical values of technical upgrades at each layer are
illustrated by a close look on lighthouse factories. Following that, we
identify seven kinds of technologies that accelerate the transformation of
manufacturing, and clarify their contributions. Finally, we explore the open
challenges and development trends from four aspects to inspire future
researches.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16176" title="Abstract">arXiv:2312.16176</a> [<a href="/pdf/2312.16176" title="Download PDF">pdf</a>, <a href="/format/2312.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GreenFlow: A Computation Allocation Framework for Building  Environmentally Sound Recommendation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xingyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhining Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yanchu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chenyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yize Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Thirty-Second International Joint Conference on
  Artificial Intelligence AI for Good. Pages 6103-6111
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Given the enormous number of users and items, industrial cascade
recommendation systems (RS) are continuously expanded in size and complexity to
deliver relevant items, such as news, services, and commodities, to the
appropriate users. In a real-world scenario with hundreds of thousands requests
per second, significant computation is required to infer personalized results
for each request, resulting in a massive energy consumption and carbon emission
that raises concern.
<br />This paper proposes GreenFlow, a practical computation allocation framework
for RS, that considers both accuracy and carbon emission during inference. For
each stage (e.g., recall, pre-ranking, ranking, etc.) of a cascade RS, when a
user triggers a request, we define two actions that determine the computation:
(1) the trained instances of models with different computational complexity;
and (2) the number of items to be inferred in the stage. We refer to the
combinations of actions in all stages as action chains. A reward score is
estimated for each action chain, followed by dynamic primal-dual optimization
considering both the reward and computation budget. Extensive experiments
verify the effectiveness of the framework, reducing computation consumption by
41% in an industrial mobile application while maintaining commercial revenue.
Moreover, the proposed framework saves approximately 5000kWh of electricity and
reduces 3 tons of carbon emissions per day.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16177" title="Abstract">arXiv:2312.16177</a> [<a href="/pdf/2312.16177" title="Download PDF">pdf</a>, <a href="/format/2312.16177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Infer Unobserved Behaviors: Estimating User&#x27;s Preference for  a Site over Other Sites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A+R">Atanu R Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+T">Tanay Anand</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+P">Paridhi Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Lakshmy%2C+A+V">A V Lakshmy</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vishal Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">A site's recommendation system relies on knowledge of its users' preferences
to offer relevant recommendations to them. These preferences are for attributes
that comprise items and content shown on the site, and are estimated from the
data of users' interactions with the site. Another form of users' preferences
is material too, namely, users' preferences for the site over other sites,
since that shows users' base level propensities to engage with the site.
Estimating users' preferences for the site, however, faces major obstacles
because (a) the focal site usually has no data of its users' interactions with
other sites; these interactions are users' unobserved behaviors for the focal
site; and (b) the Machine Learning literature in recommendation does not offer
a model of this situation. Even if (b) is resolved, the problem in (a) persists
since without access to data of its users' interactions with other sites, there
is no ground truth for evaluation. Moreover, it is most useful when (c) users'
preferences for the site can be estimated at the individual level, since the
site can then personalize recommendations to individual users. We offer a
method to estimate individual user's preference for a focal site, under this
premise. In particular, we compute the focal site's share of a user's online
engagements without any data from other sites. We show an evaluation framework
for the model using only the focal site's data, allowing the site to test the
model. We rely upon a Hierarchical Bayes Method and perform estimation in two
different ways - Markov Chain Monte Carlo and Stochastic Gradient with Langevin
Dynamics. Our results find good support for the approach to computing
personalized share of engagement and for its evaluation.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16180" title="Abstract">arXiv:2312.16180</a> [<a href="/pdf/2312.16180" title="Download PDF">pdf</a>, <a href="/format/2312.16180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating salient representations and label Variance in Dimensional  Speech Emotion Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+V">Vikramjit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jingping Nie</a>, 
<a href="/search/cs?searchtype=author&query=Azemi%2C+E">Erdrin Azemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Representations derived from models such as BERT (Bidirectional Encoder
Representations from Transformers) and HuBERT (Hidden units BERT), have helped
to achieve state-of-the-art performance in dimensional speech emotion
recognition. Despite their large dimensionality, and even though these
representations are not tailored for emotion recognition tasks, they are
frequently used to train large speech emotion models with high memory and
computational costs. In this work, we show that there exist lower-dimensional
subspaces within the these pre-trained representational spaces that offer a
reduction in downstream model complexity without sacrificing performance on
emotion estimation. In addition, we model label uncertainty in the form of
grader opinion variance, and demonstrate that such information can improve the
models generalization capacity and robustness. Finally, we compare the
robustness of the emotion models against acoustic degradations and observed
that the reduced dimensional representations were able to retain the
performance similar to the full-dimensional representations without significant
regression in dimensional emotion performance.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16183" title="Abstract">arXiv:2312.16183</a> [<a href="/pdf/2312.16183" title="Download PDF">pdf</a>, <a href="/format/2312.16183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightGCN: Evaluated and Enhanced
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapralova%2C+M">Milena Kapralova</a>, 
<a href="/search/cs?searchtype=author&query=Pantea%2C+L">Luca Pantea</a>, 
<a href="/search/cs?searchtype=author&query=Blahovici%2C+A">Andrei Blahovici</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS'23 Workshop on New in ML; 3 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper analyses LightGCN in the context of graph recommendation
algorithms. Despite the initial design of Graph Convolutional Networks for
graph classification, the non-linear operations are not always essential.
LightGCN enables linear propagation of embeddings, enhancing performance. We
reproduce the original findings, assess LightGCN's robustness on diverse
datasets and metrics, and explore Graph Diffusion as an augmentation of signal
propagation in LightGCN.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16184" title="Abstract">arXiv:2312.16184</a> [<a href="/pdf/2312.16184" title="Download PDF">pdf</a>, <a href="/format/2312.16184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Knowledge Injection for AIXI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang-Zhao%2C+S">Samuel Yang-Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+S">Kee Siong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marcus Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures, extended length version of paper to be published in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Prior approximations of AIXI, a Bayesian optimality notion for general
reinforcement learning, can only approximate AIXI's Bayesian environment model
using an a-priori defined set of models. This is a fundamental source of
epistemic uncertainty for the agent in settings where the existence of
systematic bias in the predefined model class cannot be resolved by simply
collecting more data from the environment. We address this issue in the context
of Human-AI teaming by considering a setup where additional knowledge for the
agent in the form of new candidate models arrives from a human operator in an
online fashion. We introduce a new agent called DynamicHedgeAIXI that maintains
an exact Bayesian mixture over dynamically changing sets of models via a
time-adaptive prior constructed from a variant of the Hedge algorithm. The
DynamicHedgeAIXI agent is the richest direct approximation of AIXI known to
date and comes with good performance guarantees. Experimental results on
epidemic control on contact networks validates the agent's practical utility.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16188" title="Abstract">arXiv:2312.16188</a> [<a href="/pdf/2312.16188" title="Download PDF">pdf</a>, <a href="/format/2312.16188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The curious case of the test set AUROC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+M">Michael Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Hazan%2C+A">Alon Hazan</a>, 
<a href="/search/cs?searchtype=author&query=Dittmer%2C+S">S&#xf6;ren Dittmer</a>, 
<a href="/search/cs?searchtype=author&query=Rudd%2C+J+H+F">James H.F. Rudd</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Whilst the size and complexity of ML models have rapidly and significantly
increased over the past decade, the methods for assessing their performance
have not kept pace. In particular, among the many potential performance
metrics, the ML community stubbornly continues to use (a) the area under the
receiver operating characteristic curve (AUROC) for a validation and test
cohort (distinct from training data) or (b) the sensitivity and specificity for
the test data at an optimal threshold determined from the validation ROC.
However, we argue that considering scores derived from the test ROC curve alone
gives only a narrow insight into how a model performs and its ability to
generalise.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16189" title="Abstract">arXiv:2312.16189</a> [<a href="/pdf/2312.16189" title="Download PDF">pdf</a>, <a href="/format/2312.16189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenRL: A Unified Reinforcement Learning Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wentse Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiwen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bie%2C+F">Fuqing Bie</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+W">Wei-Wei Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present OpenRL, an advanced reinforcement learning (RL) framework designed
to accommodate a diverse array of tasks, from single-agent challenges to
complex multi-agent systems. OpenRL's robust support for self-play training
empowers agents to develop advanced strategies in competitive settings.
Notably, OpenRL integrates Natural Language Processing (NLP) with RL, enabling
researchers to address a combination of RL training and language-centric tasks
effectively. Leveraging PyTorch's robust capabilities, OpenRL exemplifies
modularity and a user-centric approach. It offers a universal interface that
simplifies the user experience for beginners while maintaining the flexibility
experts require for innovation and algorithm development. This equilibrium
enhances the framework's practicality, adaptability, and scalability,
establishing a new standard in RL research. To delve into OpenRL's features, we
invite researchers and enthusiasts to explore our GitHub repository at
https://github.com/OpenRL-Lab/openrl and access our comprehensive documentation
at https://openrl-docs.readthedocs.io.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16191" title="Abstract">arXiv:2312.16191</a> [<a href="/pdf/2312.16191" title="Download PDF">pdf</a>, <a href="/ps/2312.16191" title="Download PostScript">ps</a>, <a href="/format/2312.16191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Taming the Triangle -- On the Interplays between Fairness,  Interpretability and Privacy in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferry%2C+J">Julien Ferry</a> (LAAS-ROC), 
<a href="/search/cs?searchtype=author&query=A%C3%AFvodji%2C+U">Ulrich A&#xef;vodji</a> (ETS), 
<a href="/search/cs?searchtype=author&query=Gambs%2C+S">S&#xe9;bastien Gambs</a> (UQAM), 
<a href="/search/cs?searchtype=author&query=Huguet%2C+M">Marie-Jos&#xe9; Huguet</a> (LAAS-ROC), 
<a href="/search/cs?searchtype=author&query=Siala%2C+M">Mohamed Siala</a> (LAAS-ROC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning techniques are increasingly used for high-stakes
decision-making, such as college admissions, loan attribution or recidivism
prediction. Thus, it is crucial to ensure that the models learnt can be audited
or understood by human users, do not create or reproduce discrimination or
bias, and do not leak sensitive information regarding their training data.
Indeed, interpretability, fairness and privacy are key requirements for the
development of responsible machine learning, and all three have been studied
extensively during the last decade. However, they were mainly considered in
isolation, while in practice they interplay with each other, either positively
or negatively. In this Systematization of Knowledge (SoK) paper, we survey the
literature on the interactions between these three desiderata. More precisely,
for each pairwise interaction, we summarize the identified synergies and
tensions. These findings highlight several fundamental theoretical and
empirical conflicts, while also demonstrating that jointly considering these
different requirements is challenging when one aims at preserving a high level
of utility. To solve this issue, we also discuss possible conciliation
mechanisms, showing that a careful design can enable to successfully handle
these different concerns in practice.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16192" title="Abstract">arXiv:2312.16192</a> [<a href="/pdf/2312.16192" title="Download PDF">pdf</a>, <a href="/format/2312.16192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method for Auto-Differentiation of the Voronoi Tessellation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shumilin%2C+S">Sergei Shumilin</a>, 
<a href="/search/cs?searchtype=author&query=Ryabov%2C+A">Alexander Ryabov</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>, 
<a href="/search/cs?searchtype=author&query=Vanovskii%2C+V">Vladimir Vanovskii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Voronoi tessellation, also known as Voronoi diagram, is an important
computational geometry technique that has applications in various scientific
disciplines. It involves dividing a given space into regions based on the
proximity to a set of points. Autodifferentiation is a powerful tool for
solving optimization tasks. Autodifferentiation assumes constructing a
computational graph that allows to compute gradients using backpropagation
algorithm. However, often the Voronoi tessellation remains the only
non-differentiable part of a pipeline, prohibiting end-to-end differentiation.
We present the method for autodifferentiation of the 2D Voronoi tessellation.
The method allows one to construct the Voronoi tessellation and pass gradients,
making the construction end-to-end differentiable. We provide the
implementation details and present several important applications. To the best
of our knowledge this is the first autodifferentiable realization of the
Voronoi tessellation providing full set of Voronoi geometrical parameters in a
differentiable way.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16193" title="Abstract">arXiv:2312.16193</a> [<a href="/pdf/2312.16193" title="Download PDF">pdf</a>, <a href="/format/2312.16193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-border Exchange of CBDCs using Layer-2 Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gogol%2C+K">Krzysztof Gogol</a>, 
<a href="/search/cs?searchtype=author&query=Messias%2C+J">Johnnatan Messias</a>, 
<a href="/search/cs?searchtype=author&query=Schlosser%2C+M">Malte Schlosser</a>, 
<a href="/search/cs?searchtype=author&query=Kraner%2C+B">Benjamin Kraner</a>, 
<a href="/search/cs?searchtype=author&query=Tessone%2C+C">Claudio Tessone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper will be presented at the CfC 2024 Academic Track Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper proposes a novel multi-layer blockchain architecture for the
cross-border trading of CBDCs. The permissioned layer-2, by relying on the
public consensus of the underlying network, assures the security and integrity
of the transactions and ensures interoperability with domestic CBDCs
implementations. Multiple Layer-3s operate various Automated Market Makers
(AMMs) and compete with each other for the lowest costs. To provide insights
into the practical implications of the system, simulations of trading costs are
conducted based on historical FX rates, with Project Mariana as a benchmark.
The study shows that, even with liquidity fragmentation, a multi-layer and
multi-AMM setup is more cost-efficient than a single AMM.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16197" title="Abstract">arXiv:2312.16197</a> [<a href="/pdf/2312.16197" title="Download PDF">pdf</a>, <a href="/format/2312.16197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INFAMOUS-NeRF: ImproviNg FAce MOdeling Using Semantically-Aligned  Hypernetworks with Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+A">Andrew Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhiyuan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sarkis%2C+M">Michel Sarkis</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+N">Ning Bi</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yiying Tong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose INFAMOUS-NeRF, an implicit morphable face model that introduces
hypernetworks to NeRF to improve the representation power in the presence of
many training subjects. At the same time, INFAMOUS-NeRF resolves the classic
hypernetwork tradeoff of representation power and editability by learning
semantically-aligned latent spaces despite the subject-specific models, all
without requiring a large pretrained model. INFAMOUS-NeRF further introduces a
novel constraint to improve NeRF rendering along the face boundary. Our
constraint can leverage photometric surface rendering and multi-view
supervision to guide surface color prediction and improve rendering near the
surface. Finally, we introduce a novel, loss-guided adaptive sampling method
for more effective NeRF training by reducing the sampling redundancy. We show
quantitatively and qualitatively that our method achieves higher representation
power than prior face modeling methods in both controlled and in-the-wild
settings. Code and models will be released upon publication.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16199" title="Abstract">arXiv:2312.16199</a> [<a href="/pdf/2312.16199" title="Download PDF">pdf</a>, <a href="/format/2312.16199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing User Intent Capture in Session-Based Recommendation with  Attribute Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yifan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingfeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tianyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Bing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The goal of session-based recommendation in E-commerce is to predict the next
item that an anonymous user will purchase based on the browsing and purchase
history. However, constructing global or local transition graphs to supplement
session data can lead to noisy correlations and user intent vanishing. In this
work, we propose the Frequent Attribute Pattern Augmented Transformer (FAPAT)
that characterizes user intents by building attribute transition graphs and
matching attribute patterns. Specifically, the frequent and compact attribute
patterns are served as memory to augment session representations, followed by a
gate and a transformer block to fuse the whole session information. Through
extensive experiments on two public benchmarks and 100 million industrial data
in three domains, we demonstrate that FAPAT consistently outperforms
state-of-the-art methods by an average of 4.5% across various evaluation
metrics (Hits, NDCG, MRR). Besides evaluating the next-item prediction, we
estimate the models' capabilities to capture user intents via predicting items'
attributes and period-item recommendations.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16200" title="Abstract">arXiv:2312.16200</a> [<a href="/pdf/2312.16200" title="Download PDF">pdf</a>, <a href="/ps/2312.16200" title="Download PostScript">ps</a>, <a href="/format/2312.16200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security in 5G Networks -- How 5G networks help Mitigate Location  Tracking Vulnerability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Abshir Ali</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanqun Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As 5G networks become more mainstream, privacy has come to the forefront of
end users. More scrutiny has been shown to previous generation cellular
technologies such as 3G and 4G on how they handle sensitive metadata
transmitted from an end user mobile device to base stations during registration
with a cellular network. These generation cellular networks do not enforce any
encryption on this information transmitted during this process, giving
malicious actors an easy way to intercept the information. Such an interception
can allow an adversary to locate end users with shocking accuracy. This paper
investigates this problem in great detail and discusses how a newly introduced
approach in 5G networks is helping combat this problem. The paper discusses the
implications of this vulnerability and the technical details of the new
approach, including the encryption schemes used to secure this sensitive
information. Finally, the paper will discuss any limitations to this new
approach.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16202" title="Abstract">arXiv:2312.16202</a> [<a href="/pdf/2312.16202" title="Download PDF">pdf</a>, <a href="/format/2312.16202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Travelling Pixels: Bitemporal Features Integration with Foundation  Model for Remote Sensing Image Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Change detection, a prominent research area in remote sensing, is pivotal in
observing and analyzing surface transformations. Despite significant
advancements achieved through deep learning-based methods, executing
high-precision change detection in spatio-temporally complex remote sensing
scenarios still presents a substantial challenge. The recent emergence of
foundation models, with their powerful universality and generalization
capabilities, offers potential solutions. However, bridging the gap of data and
tasks remains a significant obstacle. In this paper, we introduce Time
Travelling Pixels (TTP), a novel approach that integrates the latent knowledge
of the SAM foundation model into change detection. This method effectively
addresses the domain shift in general knowledge transfer and the challenge of
expressing homogeneous and heterogeneous characteristics of multi-temporal
images. The state-of-the-art results obtained on the LEVIR-CD underscore the
efficacy of the TTP. The Code is available at \url{https://kychen.me/TTP}.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16203" title="Abstract">arXiv:2312.16203</a> [<a href="/pdf/2312.16203" title="Download PDF">pdf</a>, <a href="/format/2312.16203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Consented Federated Recommender System Against Personalized  Attribute Inference Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recommender systems can be privacy-sensitive. To protect users' private
historical interactions, federated learning has been proposed in distributed
learning for user representations. Using federated recommender (FedRec)
systems, users can train a shared recommendation model on local devices and
prevent raw data transmissions and collections. However, the recommendation
model learned by a common FedRec may still be vulnerable to private information
leakage risks, particularly attribute inference attacks, which means that the
attacker can easily infer users' personal attributes from the learned model.
Additionally, traditional FedRecs seldom consider the diverse privacy
preference of users, leading to difficulties in balancing the recommendation
utility and privacy preservation. Consequently, FedRecs may suffer from
unnecessary recommendation performance loss due to over-protection and private
information leakage simultaneously. In this work, we propose a novel
user-consented federated recommendation system (UC-FedRec) to flexibly satisfy
the different privacy needs of users by paying a minimum recommendation
accuracy price. UC-FedRec allows users to self-define their privacy preferences
to meet various demands and makes recommendations with user consent.
Experiments conducted on different real-world datasets demonstrate that our
framework is more efficient and flexible compared to baselines.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16204" title="Abstract">arXiv:2312.16204</a> [<a href="/pdf/2312.16204" title="Download PDF">pdf</a>, <a href="/format/2312.16204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Prompt Relabeling for diffusion model with RLDF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiaxin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have shown impressive performance in many domains, including
image generation, time series prediction, and reinforcement learning. The
algorithm demonstrates superior performance over the traditional GAN and
transformer based methods. However, the model's capability to follow natural
language instructions (e.g., spatial relationships between objects, generating
complex scenes) is still unsatisfactory. This has been an important research
area to enhance such capability. Prior works adopt reinforcement learning to
adjust the behavior of the diffusion models. However, RL methods not only
require careful reward design and complex hyperparameter tuning, but also fails
to incorporate rich natural language feedback. In this work, we propose
iterative prompt relabeling (IP-RLDF), a novel algorithm that aligns images to
text through iterative image sampling and prompt relabeling. IP-RLDF first
samples a batch of images conditioned on the text, then relabels the text
prompts of unmatched text-image pairs with classifier feedback. We conduct
thorough experiments on three different models, including SDv2, GLIGEN, and
SDXL, testing their capability to generate images following instructions. With
IP-RLDF, we improved up to 15.22% (absolute improvement) on the challenging
spatial relation VISOR benchmark, demonstrating superior performance compared
to previous RL methods.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16210" title="Abstract">arXiv:2312.16210</a> [<a href="/pdf/2312.16210" title="Download PDF">pdf</a>, <a href="/ps/2312.16210" title="Download PostScript">ps</a>, <a href="/format/2312.16210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterated Resultants and Rational Functions in Real Quantifier  Elimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davenport%2C+J+H">James H. Davenport</a>, 
<a href="/search/cs?searchtype=author&query=England%2C+M">Matthew England</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+S">Scott McCallum</a>, 
<a href="/search/cs?searchtype=author&query=Uncu%2C+A+K">Ali K. Uncu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to Mathematics in Computer Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">This paper builds and extends on the authors previous work related to the
algorithmic tool, Cylindrical Algebraic Decomposition (CAD), and one of its
core applications, Real Quantifier Elimination (QE). These topics are at the
heart of symbolic computation and were first implemented in computer algebra
systems decades ago, but have recently received renewed interest as part of the
ongoing development of SMT solvers for non-linear real arithmetic.
<br />First, we consider the use of iterated univariate resultants in traditional
CAD, and how this leads to inefficiencies, especially in the case of an input
with multiple equational constraints. We reproduce the workshop paper
[Davenport \&amp; England, 2023], adding important clarifications to our
suggestions first made there to make use of multivariate resultants in the
projection phase of CAD. We then consider an alternative approach to this
problem first documented in [McCallum \&amp; Brown, 2009] which redefines the
actual object under construction, albeit only in the case of two equational
constraints. We correct an important typo and provide a missing proof in that
paper.
<br />We finish by revising the topic of how to deal with SMT or Real QE problems
expressed using rational functions (as opposed to the usual polynomial ones)
noting that these are often found in industrial applications. We revisit a
proposal made in [Uncu, Davenport and England, 2023] for doing this in the case
of satisfiability, explaining why such an approach does not trivially extend to
more complicated quantification structure and giving a suitable alternative.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16211" title="Abstract">arXiv:2312.16211</a> [<a href="/pdf/2312.16211" title="Download PDF">pdf</a>, <a href="/format/2312.16211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable AI Approach to Large Language Model Assisted Causal Model  Auditing and Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fitzgibbon%2C+B">Brette Fitzgibbon</a>, 
<a href="/search/cs?searchtype=author&query=Garofolo%2C+D">Dino Garofolo</a>, 
<a href="/search/cs?searchtype=author&query=Kota%2C+A">Akshith Kota</a>, 
<a href="/search/cs?searchtype=author&query=Papenhausen%2C+E">Eric Papenhausen</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+K">Klaus Mueller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Causal networks are widely used in many fields, including epidemiology,
social science, medicine, and engineering, to model the complex relationships
between variables. While it can be convenient to algorithmically infer these
models directly from observational data, the resulting networks are often
plagued with erroneous edges. Auditing and correcting these networks may
require domain expertise frequently unavailable to the analyst. We propose the
use of large language models such as ChatGPT as an auditor for causal networks.
Our method presents ChatGPT with a causal network, one edge at a time, to
produce insights about edge directionality, possible confounders, and mediating
variables. We ask ChatGPT to reflect on various aspects of each causal link and
we then produce visualizations that summarize these viewpoints for the human
analyst to direct the edge, gather more data, or test further hypotheses. We
envision a system where large language models, automated causal inference, and
the human analyst and domain expert work hand in hand as a team to derive
holistic and comprehensive causal models for any given case scenario. This
paper presents first results obtained with an emerging prototype.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16213" title="Abstract">arXiv:2312.16213</a> [<a href="/pdf/2312.16213" title="Download PDF">pdf</a>, <a href="/format/2312.16213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding the Feasibility and Minimizing the Height of Tangles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firman%2C+O">Oksana Firman</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Klemz%2C+B">Boris Klemz</a>, 
<a href="/search/cs?searchtype=author&query=Ravsky%2C+A">Alexander Ravsky</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is a merger of <a href="/abs/1901.06548">arXiv:1901.06548</a> and <a href="/abs/2002.12251">arXiv:2002.12251</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study the following combinatorial problem. Given a set of $n$ y-monotone
\emph{wires}, a \emph{tangle} determines the order of the wires on a number of
horizontal \emph{layers} such that the orders of the wires on any two
consecutive layers differ only in swaps of neighboring wires. Given a
multiset~$L$ of \emph{swaps} (that is, unordered pairs of wires) and an initial
order of the wires, a tangle \emph{realizes}~$L$ if each pair of wires changes
its order exactly as many times as specified by~$L$. \textsc{List-Feasibility}
is the problem of finding a tangle that realizes a given list~$L$ if such a
tangle exists. \textsc{Tangle-Height Minimization} is the problem of finding a
tangle that realizes a given list and additionally uses the minimum number of
layers. \textsc{List-Feasibility} (and therefore \textsc{Tangle-Height
Minimization}) is NP-hard [Yamanaka, Horiyama, Uno, Wasa; CCCG 2018].
<br />We prove that \textsc{List-Feasibility} remains NP-hard if every pair of
wires swaps only a constant number of times. On the positive side, we present
an algorithm for \textsc{Tangle-Height Minimization} that computes an optimal
tangle for $n$ wires and a given list~$L$ of swaps in $O((2|L|/n^2+1)^{n^2/2}
\cdot \varphi^n \cdot n)$ time, where $\varphi \approx 1.618$ is the golden
ratio and $|L|$ is the total number of swaps in~$L$. From this algorithm, we
derive a simpler and faster version to solve \textsc{List-Feasibility}. We also
use the algorithm to show that \textsc{List-Feasibility} is in NP and
fixed-parameter tractable with respect to the number of wires. For
\emph{simple} lists, where every swap occurs at most once, we show how to solve
\textsc{Tangle-Height Minimization} in $O(n!\varphi^n)$ time.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16215" title="Abstract">arXiv:2312.16215</a> [<a href="/pdf/2312.16215" title="Download PDF">pdf</a>, <a href="/format/2312.16215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUNDIAL: 3D Satellite Understanding through Direct, Ambient, and Complex  Lighting Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behari%2C+N">Nikhil Behari</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A">Akshat Dave</a>, 
<a href="/search/cs?searchtype=author&query=Tiwary%2C+K">Kushagra Tiwary</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">William Yang</a>, 
<a href="/search/cs?searchtype=author&query=Raskar%2C+R">Ramesh Raskar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D modeling from satellite imagery is essential in areas of environmental
science, urban planning, agriculture, and disaster response. However,
traditional 3D modeling techniques face unique challenges in the remote sensing
context, including limited multi-view baselines over extensive regions, varying
direct, ambient, and complex illumination conditions, and time-varying scene
changes across captures. In this work, we introduce SUNDIAL, a comprehensive
approach to 3D reconstruction of satellite imagery using neural radiance
fields. We jointly learn satellite scene geometry, illumination components, and
sun direction in this single-model approach, and propose a secondary shadow ray
casting technique to 1) improve scene geometry using oblique sun angles to
render shadows, 2) enable physically-based disentanglement of scene albedo and
illumination, and 3) determine the components of illumination from direct,
ambient (sky), and complex sources. To achieve this, we incorporate lighting
cues and geometric priors from remote sensing literature in a neural rendering
approach, modeling physical properties of satellite scenes such as shadows,
scattered sky illumination, and complex illumination and shading of vegetation
and water. We evaluate the performance of SUNDIAL against existing NeRF-based
techniques for satellite scene modeling and demonstrate improved scene and
lighting disentanglement, novel view and lighting rendering, and geometry and
sun direction estimation on challenging scenes with small baselines, sparse
inputs, and variable illumination.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16217" title="Abstract">arXiv:2312.16217</a> [<a href="/pdf/2312.16217" title="Download PDF">pdf</a>, <a href="/format/2312.16217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ManipLLM: Embodied Multimodal Large Language Model for Object-Centric  Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yiran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Haoran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yuxing Long</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Robot manipulation relies on accurately predicting contact points and
end-effector directions to ensure successful operation. However, learning-based
robot manipulation, trained on a limited category within a simulator, often
struggles to achieve generalizability, especially when confronted with
extensive categories. Therefore, we introduce an innovative approach for robot
manipulation that leverages the robust reasoning capabilities of Multimodal
Large Language Models (MLLMs) to enhance the stability and generalization of
manipulation. By fine-tuning the injected adapters, we preserve the inherent
common sense and reasoning ability of the MLLMs while equipping them with the
ability for manipulation. The fundamental insight lies in the introduced
fine-tuning paradigm, encompassing object category understanding, affordance
prior reasoning, and object-centric pose prediction to stimulate the reasoning
ability of MLLM in manipulation. During inference, our approach utilizes an RGB
image and text prompt to predict the end effector's pose in chain of thoughts.
After the initial contact is established, an active impedance adaptation policy
is introduced to plan the upcoming waypoints in a closed-loop manner. Moreover,
in real world, we design a test-time adaptation (TTA) strategy for manipulation
to enable the model better adapt to the current real-world scene configuration.
Experiments in simulator and real-world show the promising performance of
ManipLLM. More details and demonstrations can be found at
https://sites.google.com/view/manipllm.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16218" title="Abstract">arXiv:2312.16218</a> [<a href="/pdf/2312.16218" title="Download PDF">pdf</a>, <a href="/format/2312.16218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-VolTran: Fast and Generalizable One-Shot Image to 3D Object  Structure via HyperNetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simon%2C+C">Christian Simon</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sen He</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Rua%2C+J">Juan-Manuel Perez-Rua</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Frost Xu</a>, 
<a href="/search/cs?searchtype=author&query=Benhalloum%2C+A">Amine Benhalloum</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Solving image-to-3D from a single view is an ill-posed problem, and current
neural reconstruction methods addressing it through diffusion models still rely
on scene-specific optimization, constraining their generalization capability.
To overcome the limitations of existing approaches regarding generalization and
consistency, we introduce a novel neural rendering technique. Our approach
employs the signed distance function as the surface representation and
incorporates generalizable priors through geometry-encoding volumes and
HyperNetworks. Specifically, our method builds neural encoding volumes from
generated multi-view inputs. We adjust the weights of the SDF network
conditioned on an input image at test-time to allow model adaptation to novel
scenes in a feed-forward manner via HyperNetworks. To mitigate artifacts
derived from the synthesized views, we propose the use of a volume transformer
module to improve the aggregation of image features instead of processing each
viewpoint separately. Through our proposed method, dubbed as Hyper-VolTran, we
avoid the bottleneck of scene-specific optimization and maintain consistency
across the images generated from multiple viewpoints. Our experiments show the
advantages of our proposed approach with consistent results and rapid
generation.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16220" title="Abstract">arXiv:2312.16220</a> [<a href="/pdf/2312.16220" title="Download PDF">pdf</a>, <a href="/format/2312.16220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Mirage: The Impostor Bias and the Deepfake Detection Challenge in the  Era of Artificial Illusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casu%2C+M">Mirko Casu</a>, 
<a href="/search/cs?searchtype=author&query=Guarnera%2C+L">Luca Guarnera</a>, 
<a href="/search/cs?searchtype=author&query=Caponnetto%2C+P">Pasquale Caponnetto</a>, 
<a href="/search/cs?searchtype=author&query=Battiato%2C+S">Sebastiano Battiato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper provides a comprehensive analysis of cognitive biases in forensics
and digital forensics, examining their implications for decision-making
processes in these fields. It explores the various types of cognitive biases
that may arise during forensic investigations and digital forensic analyses,
such as confirmation bias, expectation bias, overconfidence in errors,
contextual bias, and attributional biases. It also evaluates existing methods
and techniques used to mitigate cognitive biases in these contexts, assessing
the effectiveness of interventions aimed at reducing biases and improving
decision-making outcomes. Additionally, this paper introduces a new cognitive
bias, called "impostor bias", that may affect the use of generative Artificial
Intelligence (AI) tools in forensics and digital forensics. The impostor bias
is the tendency to doubt the authenticity or validity of the output generated
by AI tools, such as deepfakes, in the form of audio, images, and videos. This
bias may lead to erroneous judgments or false accusations, undermining the
reliability and credibility of forensic evidence. The paper discusses the
potential causes and consequences of the impostor bias, and suggests some
strategies to prevent or counteract it. By addressing these topics, this paper
seeks to offer valuable insights into understanding cognitive biases in
forensic practices and provide recommendations for future research and
practical applications to enhance the objectivity and validity of forensic
investigations.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16221" title="Abstract">arXiv:2312.16221</a> [<a href="/pdf/2312.16221" title="Download PDF">pdf</a>, <a href="/format/2312.16221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEMP3D: Temporally Continuous 3D Human Pose Estimation Under Occlusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lal%2C+R">Rohit Lal</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+Y">Yash Garg</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Arindam Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+C">Calvin-Khang Ta</a>, 
<a href="/search/cs?searchtype=author&query=Raychaudhuri%2C+D+S">Dripta S. Raychaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+M+S">M. Salman Asif</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing 3D human pose estimation methods perform remarkably well in both
monocular and multi-view settings. However, their efficacy diminishes
significantly in the presence of heavy occlusions, which limits their practical
utility. For video sequences, temporal continuity can help infer accurate
poses, especially in heavily occluded frames. In this paper, we aim to leverage
this potential of temporal continuity through human motion priors, coupled with
large-scale pre-training on 3D poses and self-supervised learning, to enhance
3D pose estimation in a given video sequence. This leads to a temporally
continuous 3D pose estimate on unlabelled in-the-wild videos, which may contain
occlusions, while exclusively relying on pre-trained 3D pose models. We propose
an unsupervised method named TEMP3D that aligns a motion prior model on a given
in-the-wild video using existing SOTA single image-based 3D pose estimation
methods to give temporally continuous output under occlusions. To evaluate our
method, we test it on the Occluded Human3.6M dataset, our custom-built dataset
which contains significantly large (up to 100%) human body occlusions
incorporated into the Human3.6M dataset. We achieve SOTA results on Occluded
Human3.6M and the OcMotion dataset while maintaining competitive performance on
non-occluded data. URL: https://sites.google.com/ucr.edu/temp3d
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16222" title="Abstract">arXiv:2312.16222</a> [<a href="/pdf/2312.16222" title="Download PDF">pdf</a>, <a href="/format/2312.16222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Any Events via Weighted Adaptation of Pivotal Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinjian Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we delve into the nuanced challenge of tailoring the Segment
Anything Models (SAMs) for integration with event data, with the overarching
objective of attaining robust and universal object segmentation within the
event-centric domain. One pivotal issue at the heart of this endeavor is the
precise alignment and calibration of embeddings derived from event-centric data
such that they harmoniously coincide with those originating from RGB imagery.
Capitalizing on the vast repositories of datasets with paired events and RGB
images, our proposition is to harness and extrapolate the profound knowledge
encapsulated within the pre-trained SAM framework. As a cornerstone to
achieving this, we introduce a multi-scale feature distillation methodology.
This methodology rigorously optimizes the alignment of token embeddings
originating from event data with their RGB image counterparts, thereby
preserving and enhancing the robustness of the overall architecture.
Considering the distinct significance that token embeddings from intermediate
layers hold for higher-level embeddings, our strategy is centered on accurately
calibrating the pivotal token embeddings. This targeted calibration is aimed at
effectively managing the discrepancies in high-level embeddings originating
from both the event and image domains. Extensive experiments on different
datasets demonstrate the effectiveness of the proposed distillation method.
Code in <a href="http://github.com/happychenpipi/EventSAM.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16226" title="Abstract">arXiv:2312.16226</a> [<a href="/pdf/2312.16226" title="Download PDF">pdf</a>, <a href="/ps/2312.16226" title="Download PostScript">ps</a>, <a href="/format/2312.16226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Person Re-Identification: Tensor-based Feature Fusion and  Multilinear Subspace Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+A+A">Akram Abderraouf Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Chouchane%2C+A">Ammar Chouchane</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.10470">arXiv:2312.10470</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Person re-identification (PRe-ID) is a computer vision issue, that has been a
fertile research area in the last few years. It aims to identify persons across
different non-overlapping camera views. In this paper, We propose a novel
PRe-ID system that combines tensor feature representation and multilinear
subspace learning. Our method exploits the power of pre-trained Convolutional
Neural Networks (CNNs) as a strong deep feature extractor, along with two
complementary descriptors, Local Maximal Occurrence (LOMO) and Gaussian Of
Gaussian (GOG). Then, Tensor-based Cross-View Quadratic Discriminant Analysis
(TXQDA) is used to learn a discriminative subspace that enhances the
separability between different individuals. Mahalanobis distance is used to
match and similarity computation between query and gallery samples. Finally, we
evaluate our approach by conducting experiments on three datasets VIPeR, GRID,
and PRID450s.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16228" title="Abstract">arXiv:2312.16228</a> [<a href="/pdf/2312.16228" title="Download PDF">pdf</a>, <a href="/format/2312.16228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Audio Transformer for Audio Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024. arXiv admin note: substantial text overlap with <a href="/abs/2201.00520">arXiv:2201.00520</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Neural and Evolutionary Computing (cs.NE); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Transformers have achieved promising results on a variety of tasks. However,
the quadratic complexity in self-attention computation has limited the
applications, especially in low-resource settings and mobile or edge devices.
Existing works have proposed to exploit hand-crafted attention patterns to
reduce computation complexity. However, such hand-crafted patterns are
data-agnostic and may not be optimal. Hence, it is likely that relevant keys or
values are being reduced, while less important ones are still preserved. Based
on this key insight, we propose a novel deformable audio Transformer for audio
recognition, named DATAR, where a deformable attention equipping with a pyramid
transformer backbone is constructed and learnable. Such an architecture has
been proven effective in prediction tasks,~\textit{e.g.}, event classification.
Moreover, we identify that the deformable attention map computation may
over-simplify the input feature, which can be further enhanced. Hence, we
introduce a learnable input adaptor to alleviate this issue, and DATAR achieves
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16230" title="Abstract">arXiv:2312.16230</a> [<a href="/pdf/2312.16230" title="Download PDF">pdf</a>, <a href="/format/2312.16230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Decision Landscapes: The Impact of Principals on  Decision-Making Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huangxing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We explored decision-making dynamics in social systems, referencing the 'herd
behavior' from prior studies where individuals follow preceding choices without
understanding the underlying reasons. While previous research highlighted a
preference for the optimal choice without external influences, our study
introduced principals or external guides, adding complexity to the
decision-making process. The reliability of these principals significantly
influenced decisions. Notably, even occasional trust in an unreliable principal
could alter decision outcomes. Furthermore, when a principal's advice was
purely random, heightened trust led to more decision errors. Our findings
emphasize the need for caution when placing trust in decision-making contexts.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16233" title="Abstract">arXiv:2312.16233</a> [<a href="/pdf/2312.16233" title="Download PDF">pdf</a>, <a href="/format/2312.16233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chatbot is Not All You Need: Information-rich Prompting for More  Realistic Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seokhoon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Makhmud%2C+A">Assentay Makhmud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent Large Language Models (LLMs) have shown remarkable capabilities in
mimicking fictional characters or real humans in conversational settings.
However, the realism and consistency of these responses can be further enhanced
by providing richer information of the agent being mimicked. In this paper, we
propose a novel approach to generate more realistic and consistent responses
from LLMs, leveraging five senses, attributes, emotional states, relationship
with the interlocutor, and memories. By incorporating these factors, we aim to
increase the LLM's capacity for generating natural and realistic reactions in
conversational exchanges. Through our research, we expect to contribute to the
development of LLMs that demonstrate improved capabilities in mimicking
fictional characters. We release a new benchmark dataset and all our codes,
prompts, and sample results on our Github:
https://github.com/srafsasm/InfoRichBot
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16239" title="Abstract">arXiv:2312.16239</a> [<a href="/pdf/2312.16239" title="Download PDF">pdf</a>, <a href="/format/2312.16239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PNL to HOL: from the logic of nominal sets to the logic of higher-order  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>, 
<a href="/search/cs?searchtype=author&query=Gabbay%2C+M+J">Murdoch J. Gabbay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/1111.4611">arXiv:1111.4611</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Theoretical Computer Science, Volume 451, 14 September 2012, Pages
  38-69
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Permissive-Nominal Logic (PNL) extends first-order predicate logic with
term-formers that can bind names in their arguments. It takes a semantics in
(permissive-)nominal sets. In PNL, the forall-quantifier or lambda-binder are
just term-formers satisfying axioms, and their denotation is functions on
nominal atoms-abstraction.
<br />Then we have higher-order logic (HOL) and its models in ordinary (i.e.
Zermelo-Fraenkel) sets; the denotation of forall or lambda is functions on full
or partial function spaces.
<br />This raises the following question: how are these two models of binding
connected? What translation is possible between PNL and HOL, and between
nominal sets and functions?
<br />We exhibit a translation of PNL into HOL, and from models of PNL to certain
models of HOL. It is natural, but also partial: we translate a restricted
subsystem of full PNL to HOL. The extra part which does not translate is the
symmetry properties of nominal sets with respect to permutations. To use a
little nominal jargon: we can translate names and binding, but not their
nominal equivariance properties. This seems reasonable since HOL -- and
ordinary sets -- are not equivariant.
<br />Thus viewed through this translation, PNL and HOL and their models do
different things, but they enjoy non-trivial and rich subsystems which are
isomorphic.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16240" title="Abstract">arXiv:2312.16240</a> [<a href="/pdf/2312.16240" title="Download PDF">pdf</a>, <a href="/format/2312.16240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging Vision Transformers from Different Tasks and Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Mingzhu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work targets to merge various Vision Transformers (ViTs) trained on
different tasks (i.e., datasets with different object categories) or domains
(i.e., datasets with the same categories but different environments) into one
unified model, yielding still good performance on each task or domain. Previous
model merging works focus on either CNNs or NLP models, leaving the ViTs
merging research untouched. To fill this gap, we first explore and find that
existing model merging methods cannot well handle the merging of the whole ViT
models and still have improvement space. To enable the merging of the whole
ViT, we propose a simple-but-effective gating network that can both merge all
kinds of layers (e.g., Embedding, Norm, Attention, and MLP) and select the
suitable classifier. Specifically, the gating network is trained by unlabeled
datasets from all the tasks (domains), and predicts the probability of which
task (domain) the input belongs to for merging the models during inference. To
further boost the performance of the merged model, especially when the
difficulty of merging tasks increases, we design a novel metric of model weight
similarity, and utilize it to realize controllable and combined weight merging.
Comprehensive experiments on kinds of newly established benchmarks, validate
the superiority of the proposed ViT merging framework for different tasks and
domains. Our method can even merge beyond 10 ViT models from different vision
tasks with a negligible effect on the performance of each task.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16242" title="Abstract">arXiv:2312.16242</a> [<a href="/pdf/2312.16242" title="Download PDF">pdf</a>, <a href="/format/2312.16242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Knowledge Distillation under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Ziyu Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaofeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Knowledge distillation transfers knowledge from large models into small
models, and has recently made remarkable achievements. However, few studies has
investigated the mechanism of knowledge distillation against distribution
shift. Distribution shift refers to the data distribution drifts between
training and testing phases. In this paper, we reconsider the paradigm of
knowledge distillation by reformulating the objective function in shift
situations. Under the real scenarios, we propose a unified and systematic
framework to benchmark knowledge distillation against two general
distributional shifts including diversity and correlation shift. The evaluation
benchmark covers more than 30 methods from algorithmic, data-driven, and
optimization perspectives for five benchmark datasets. Overall, we conduct
extensive experiments on the student model. We reveal intriguing observations
of poor teaching performance under distribution shifts; in particular, complex
algorithms and data augmentation offer limited gains in many cases.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16243" title="Abstract">arXiv:2312.16243</a> [<a href="/pdf/2312.16243" title="Download PDF">pdf</a>, <a href="/format/2312.16243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are All Unseen Data Out-of-Distribution?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuxiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+H">Haoang Chi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Distributions of unseen data have been all treated as out-of-distribution
(OOD), making their generalization a significant challenge. Much evidence
suggests that the size increase of training data can monotonically decrease
generalization errors in test data. However, this is not true from other
observations and analysis. In particular, when the training data have multiple
source domains and the test data contain distribution drifts, then not all
generalization errors on the test data decrease monotonically with the
increasing size of training data. Such a non-decreasing phenomenon is formally
investigated under a linear setting with empirical verification across varying
visual benchmarks. Motivated by these results, we redefine the OOD data as a
type of data outside the convex hull of the training domains and prove a new
generalization bound based on this new definition. It implies that the
effectiveness of a well-trained model can be guaranteed for the unseen data
that is within the convex hull of the training domains. But, for some data
beyond the convex hull, a non-decreasing error trend can happen. Therefore, we
investigate the performance of popular strategies such as data augmentation and
pre-training to overcome this issue. Moreover, we propose a novel reinforcement
learning selection algorithm in the source domains only that can deliver
superior performance over the baseline methods.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16244" title="Abstract">arXiv:2312.16244</a> [<a href="/pdf/2312.16244" title="Download PDF">pdf</a>, <a href="/format/2312.16244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality-missing RGBT Tracking via Invertible Prompt Learning and A  High-quality Data Simulation Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+A">Andong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+j">jiacong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current RGBT tracking researches mainly focus on the modality-complete
scenarios, overlooking the modality-missing challenge in real-world scenes. In
this work, we comprehensively investigate the impact of modality-missing
challenge in RGBT tracking and propose a novel invertible prompt learning
approach, which integrates the content-preserving prompts into a well-trained
tracking model to adapt to various modality-missing scenarios, for
modality-missing RGBT tracking. In particular, given one modality-missing
scenario, we propose to utilize the available modality to generate the prompt
of the missing modality to adapt to RGBT tracking model. However, the
cross-modality gap between available and missing modalities usually causes
semantic distortion and information loss in prompt generation. To handle this
issue, we propose the invertible prompt learning scheme by incorporating the
full reconstruction of the input available modality from the prompt in prompt
generation model. Considering that there lacks a modality-missing RGBT tracking
dataset and many modality-missing scenarios are difficult to capture, we design
a high-quality data simulation method based on hierarchical combination schemes
to generate real-world modality-missing data. Extensive experiments on three
modality-missing datasets show that our method achieves significant performance
improvements compared with state-of-the-art methods. We will release the code
and simulation dataset.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16245" title="Abstract">arXiv:2312.16245</a> [<a href="/pdf/2312.16245" title="Download PDF">pdf</a>, <a href="/format/2312.16245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iKUN: Speak to Trackers without Retraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yunhao Du</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Cheng Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+F">Fei Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring multi-object tracking (RMOT) aims to track multiple objects based
on input textual descriptions. Previous works realize it by simply integrating
an extra textual module into the multi-object tracker. However, they typically
need to retrain the entire framework and have difficulties in optimization. In
this work, we propose an insertable Knowledge Unification Network, termed iKUN,
to enable communication with off-the-shelf trackers in a plug-and-play manner.
Concretely, a knowledge unification module (KUM) is designed to adaptively
extract visual features based on textual guidance. Meanwhile, to improve the
localization accuracy, we present a neural version of Kalman filter (NKF) to
dynamically adjust process noise and observation noise based on the current
motion status. Moreover, to address the problem of open-set long-tail
distribution of textual descriptions, a test-time similarity calibration method
is proposed to refine the confidence score with pseudo frequency. Extensive
experiments on Refer-KITTI dataset verify the effectiveness of our framework.
Finally, to speed up the development of RMOT, we also contribute a more
challenging dataset, Refer-Dance, by extending public DanceTrack dataset with
motion and dressing descriptions. The code and dataset will be released in
https://github.com/dyhBUPT/iKUN.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16246" title="Abstract">arXiv:2312.16246</a> [<a href="/pdf/2312.16246" title="Download PDF">pdf</a>, <a href="/format/2312.16246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nighttime Person Re-Identification via Collaborative Enhancement Network  with Multi-domain Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+A">Andong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+T">Tianrui Zha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prevalent nighttime ReID methods typically combine relighting networks and
ReID networks in a sequential manner, which not only restricts the ReID
performance by the quality of relighting images, but also neglects the
effective collaborative modeling between image relighting and person ReID
tasks. To handle these problems, we propose a novel Collaborative Enhancement
Network called CENet, which performs the multilevel feature interactions in a
parallel framework, for nighttime person ReID. In particular, CENet is a
parallel Transformer network, in which the designed parallel structure can
avoid the impact of the quality of relighting images on ReID performance. To
perform effective collaborative modeling between image relighting and person
ReID tasks, we integrate the multilevel feature interactions in CENet.
Specifically, we share the Transformer encoder to build the low-level feature
interaction, and then perform the feature distillation to transfer the
high-level features from image relighting to ReID. In addition, the sizes of
existing real-world nighttime person ReID datasets are small, and large-scale
synthetic ones exhibit substantial domain gaps with real-world data. To
leverage both small-scale real-world and large-scale synthetic training data,
we develop a multi-domain learning algorithm, which alternately utilizes both
kinds of data to reduce the inter-domain difference in the training of CENet.
Extensive experiments on two real nighttime datasets, \textit{Night600} and
\textit{RGBNT201$_{rgb}$}, and a synthetic nighttime ReID dataset are conducted
to validate the effectiveness of CENet. We will release the code and synthetic
dataset.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16247" title="Abstract">arXiv:2312.16247</a> [<a href="/pdf/2312.16247" title="Download PDF">pdf</a>, <a href="/format/2312.16247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Accurate and Temporally Consistent Video Restoration from Raw  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Denoising and demosaicking are two fundamental steps in reconstructing a
clean full-color video from raw data, while performing video denoising and
demosaicking jointly, namely VJDD, could lead to better video restoration
performance than performing them separately. In addition to restoration
accuracy, another key challenge to VJDD lies in the temporal consistency of
consecutive frames. This issue exacerbates when perceptual regularization terms
are introduced to enhance video perceptual quality. To address these
challenges, we present a new VJDD framework by consistent and accurate latent
space propagation, which leverages the estimation of previous frames as prior
knowledge to ensure consistent recovery of the current frame. A data temporal
consistency (DTC) loss and a relational perception consistency (RPC) loss are
accordingly designed. Compared with the commonly used flow-based losses, the
proposed losses can circumvent the error accumulation problem caused by
inaccurate flow estimation and effectively handle intensity changes in videos,
improving much the temporal consistency of output videos while preserving
texture details. Extensive experiments demonstrate the leading VJDD performance
of our method in term of restoration accuracy, perceptual quality and temporal
consistency. Codes and dataset are available at
\url{https://github.com/GuoShi28/VJDD}.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16248" title="Abstract">arXiv:2312.16248</a> [<a href="/pdf/2312.16248" title="Download PDF">pdf</a>, <a href="/format/2312.16248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XuanCe: A Comprehensive and Unified Deep Reinforcement Learning Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenzhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wenzhe Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangran Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jingyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lele Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+C">Chaoxu Mu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changyin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures, 32 conferences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)

</div>
<p class="mathjax">In this paper, we present XuanCe, a comprehensive and unified deep
reinforcement learning (DRL) library designed to be compatible with PyTorch,
TensorFlow, and MindSpore. XuanCe offers a wide range of functionalities,
including over 40 classical DRL and multi-agent DRL algorithms, with the
flexibility to easily incorporate new algorithms and environments. It is a
versatile DRL library that supports CPU, GPU, and Ascend, and can be executed
on various operating systems such as Ubuntu, Windows, MacOS, and EulerOS.
Extensive benchmarks conducted on popular environments including MuJoCo, Atari,
and StarCraftII multi-agent challenge demonstrate the library's impressive
performance. XuanCe is open-source and can be accessed at
https://github.com/agi-brain/xuance.git.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16250" title="Abstract">arXiv:2312.16250</a> [<a href="/pdf/2312.16250" title="Download PDF">pdf</a>, <a href="/format/2312.16250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of Object Tracking in Low-Light Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+A">Anqi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Anantrasirichai%2C+N">Nantheera Anantrasirichai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate object tracking in low-light environments is crucial, particularly
in surveillance and ethology applications. However, achieving this is
significantly challenging due to the poor quality of captured sequences.
Factors such as noise, color imbalance, and low contrast contribute to these
challenges. This paper presents a comprehensive study examining the impact of
these distortions on automatic object trackers. Additionally, we propose a
solution to enhance tracking performance by integrating denoising and low-light
enhancement methods into the transformer-based object tracking system.
Experimental results show that the proposed tracker, trained with low-light
synthetic datasets, outperforms both the vanilla MixFormer and Siam R-CNN.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16251" title="Abstract">arXiv:2312.16251</a> [<a href="/pdf/2312.16251" title="Download PDF">pdf</a>, <a href="/format/2312.16251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaScript: Few-Shot Handwritten Chinese Content Generation via  Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+J">Jiazi Bu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we propose MetaScript, a novel Chinese content generation
system designed to address the diminishing presence of personal handwriting
styles in the digital representation of Chinese characters. Our approach
harnesses the power of few-shot learning to generate Chinese characters that
not only retain the individual's unique handwriting style but also maintain the
efficiency of digital typing. Trained on a diverse dataset of handwritten
styles, MetaScript is adept at producing high-quality stylistic imitations from
minimal style references and standard fonts. Our work demonstrates a practical
solution to the challenges of digital typography in preserving the personal
touch in written communication, particularly in the context of Chinese script.
Notably, our system has demonstrated superior performance in various
evaluations, including recognition accuracy, inception score, and Frechet
inception distance. At the same time, the training conditions of our model are
easy to meet and facilitate generalization to real applications.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16253" title="Abstract">arXiv:2312.16253</a> [<a href="/pdf/2312.16253" title="Download PDF">pdf</a>, <a href="/ps/2312.16253" title="Download PostScript">ps</a>, <a href="/format/2312.16253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Communication Byzantine Reliable Broadcast under a  Message Adversary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albouy%2C+T">Timoth&#xe9; Albouy</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+D">Davide Frey</a>, 
<a href="/search/cs?searchtype=author&query=Gelles%2C+R">Ran Gelles</a>, 
<a href="/search/cs?searchtype=author&query=Hazay%2C+C">Carmit Hazay</a>, 
<a href="/search/cs?searchtype=author&query=Raynal%2C+M">Michel Raynal</a>, 
<a href="/search/cs?searchtype=author&query=Schiller%2C+E+M">Elad Michael Schiller</a>, 
<a href="/search/cs?searchtype=author&query=Taiani%2C+F">Francois Taiani</a>, 
<a href="/search/cs?searchtype=author&query=Zikas%2C+V">Vassilis Zikas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We address the problem of Reliable Broadcast in asynchronous message-passing
systems with $n$ nodes, of which up to $t$ are malicious (faulty), in addition
to a message adversary that can drop some of the messages sent by correct
(non-faulty) nodes.
<br />We present a Message-Adversary-Tolerant Byzantine Reliable Broadcast (MBRB)
algorithm that communicates an almost optimal amount of $O(|m|+n^2\kappa)$ bits
per node, where $|m|$ represents the length of the application message and
$\kappa=\Omega(\log n)$ is a security parameter. This improves upon the
state-of-the-art MBRB solution (Albouy, Frey, Raynal, and Ta\"iani, SSS 2021),
which incurs communication of $O(n|m|+n^2\kappa )$ bits per node.
<br />Our solution sends at most $4n^2$ messages overall, which is asymptotically
optimal. Reduced communication is achieved by employing coding techniques that
replace the need for all nodes to (re-)broadcast the entire message~$m$.
Instead, nodes forward authenticated fragments of the encoding of $m$ using an
erasure-correcting code. Under the cryptographic assumptions of PKI and
collision-resistant hash, and assuming $n &gt; 3t + 2d$, where the adversary drops
at most~$d$ messages per broadcast, our algorithm allows most of the correct
nodes to reconstruct~$m$, despite missing fragments caused by the malicious
nodes and the message adversary.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16256" title="Abstract">arXiv:2312.16256</a> [<a href="/pdf/2312.16256" title="Download PDF">pdf</a>, <a href="/format/2312.16256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+L">Lu Ling</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Yichen Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhi Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wentian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+C">Cheng Xin</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lantao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zixun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yawen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuanmao Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xingpeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ashok%2C+R">Rohan Ashok</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Aniruddha Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangrui Kong</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianti Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Benes%2C+B">Bedrich Benes</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We have witnessed significant progress in deep learning-based 3D vision,
ranging from neural radiance field (NeRF) based 3D representation learning to
applications in novel view synthesis (NVS). However, existing scene-level
datasets for deep learning-based 3D vision, limited to either synthetic
environments or a narrow selection of real-world scenes, are quite
insufficient. This insufficiency not only hinders a comprehensive benchmark of
existing methods but also caps what could be explored in deep learning-based 3D
analysis. To address this critical gap, we present DL3DV-10K, a large-scale
scene dataset, featuring 51.2 million frames from 10,510 videos captured from
65 types of point-of-interest (POI) locations, covering both bounded and
unbounded scenes, with different levels of reflection, transparency, and
lighting. We conducted a comprehensive benchmark of recent NVS methods on
DL3DV-10K, which revealed valuable insights for future research in NVS. In
addition, we have obtained encouraging results in a pilot study to learn
generalizable NeRF from DL3DV-10K, which manifests the necessity of a
large-scale scene-level dataset to forge a path toward a foundation model for
learning 3D representation. Our DL3DV-10K dataset, benchmark results, and
models will be publicly accessible at https://dl3dv-10k.github.io/DL3DV-10K/.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16257" title="Abstract">arXiv:2312.16257</a> [<a href="/pdf/2312.16257" title="Download PDF">pdf</a>, <a href="/format/2312.16257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More than Correlation: Do Large Language Models Learn Causal  Representations of Space?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yida Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yixian Gan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Li Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaohan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work found high mutual information between the learned representations
of large language models (LLMs) and the geospatial property of its input,
hinting an emergent internal model of space. However, whether this internal
space model has any causal effects on the LLMs' behaviors was not answered by
that work, led to criticism of these findings as mere statistical correlation.
Our study focused on uncovering the causality of the spatial representations in
LLMs. In particular, we discovered the potential spatial representations in
DeBERTa, GPT-Neo using representational similarity analysis and linear and
non-linear probing. Our casual intervention experiments showed that the spatial
representations influenced the model's performance on next word prediction and
a downstream task that relies on geospatial information. Our experiments
suggested that the LLMs learn and use an internal model of space in solving
geospatial related tasks.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16258" title="Abstract">arXiv:2312.16258</a> [<a href="/pdf/2312.16258" title="Download PDF">pdf</a>, <a href="/format/2312.16258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Planning of Active Distribution Network and EV Charging Stations  Considering Vehicle-to-Grid Functionality and Reactive Power Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yongheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+X">Xinwei Shen</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a collaborative planning model for the active
distribution network (ADN) and electric vehicle (EV) charging stations that
fully considers the vehicle-to-grid (V2G) function and reactive power support
of EVs in different regions. This paper employs a sequential decomposition
method based on the physical characteristics of the problem, breaking down the
holistic problem into two sub-problems for solution. Subproblem I optimizes the
charging and discharging behavior of the autopilot electric vehicles (AEVs)
using a mixed-integer linear programming (MILP) model. Subproblem II uses a
mixed-integer second-order cone programming (MISOCP) model to plan the ADN and
retrofit or construct V2G charging stations (V2GCS), as well as multiple
distributed generation resources (DGRs). The paper also analyzes the impact of
the bi-directional active-reactive power interaction of V2GCS on ADN planning.
The presented model was tested in the 47 nodes ADN in Longgang District,
Shenzhen, China, and the IEEE 33 nodes ADN, demonstrating that decomposition
can significantly improve the speed of solving large-scale problems while
maintaining accuracy with low AEV penetration.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16261" title="Abstract">arXiv:2312.16261</a> [<a href="/pdf/2312.16261" title="Download PDF">pdf</a>, <a href="/format/2312.16261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdapterDistillation: Non-Destructive Task Composition with Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yicheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Teng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jing Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023: Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Leveraging knowledge from multiple tasks through introducing a small number
of task specific parameters into each transformer layer, also known as
adapters, receives much attention recently. However, adding an extra fusion
layer to implement knowledge composition not only increases the inference time
but also is non-scalable for some applications. To avoid these issues, we
propose a two-stage knowledge distillation algorithm called
AdapterDistillation. In the first stage, we extract task specific knowledge by
using local data to train a student adapter. In the second stage, we distill
the knowledge from the existing teacher adapters into the student adapter to
help its inference. Extensive experiments on frequently asked question
retrieval in task-oriented dialog systems validate the efficiency of
AdapterDistillation. We show that AdapterDistillation outperforms existing
algorithms in terms of accuracy, resource consumption and inference time.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16262" title="Abstract">arXiv:2312.16262</a> [<a href="/pdf/2312.16262" title="Download PDF">pdf</a>, <a href="/format/2312.16262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic In-Context Learning from Nearest Neighbors for Bundle Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kaidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xinghua Qu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hui Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyuan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Product bundling has evolved into a crucial marketing strategy in e-commerce.
However, current studies are limited to generating (1) fixed-size or single
bundles, and most importantly, (2) bundles that do not reflect consistent user
intents, thus being less intelligible or useful to users. This paper explores
two interrelated tasks, i.e., personalized bundle generation and the underlying
intent inference based on users' interactions in a session, leveraging the
logical reasoning capability of large language models. We introduce a dynamic
in-context learning paradigm, which enables ChatGPT to seek tailored and
dynamic lessons from closely related sessions as demonstrations while
performing tasks in the target session. Specifically, it first harnesses
retrieval augmented generation to identify nearest neighbor sessions for each
target session. Then, proper prompts are designed to guide ChatGPT to perform
the two tasks on neighbor sessions. To enhance reliability and mitigate the
hallucination issue, we develop (1) a self-correction strategy to foster mutual
improvement in both tasks without supervision signals; and (2) an auto-feedback
mechanism to recurrently offer dynamic supervision based on the distinct
mistakes made by ChatGPT on various neighbor sessions. Thus, the target session
can receive customized and dynamic lessons for improved performance by
observing the demonstrations of its neighbor sessions. Finally, experimental
results on three real-world datasets verify the effectiveness of our methods on
both tasks. Additionally, the inferred intents can prove beneficial for other
intriguing downstream tasks, such as crafting appealing bundle names.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16264" title="Abstract">arXiv:2312.16264</a> [<a href="/pdf/2312.16264" title="Download PDF">pdf</a>, <a href="/format/2312.16264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPnet: Estimating Garment Sewing Patterns from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seungchan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sumin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sung-Hee Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel method for reconstructing 3D garment models from
a single image of a posed user. Previous studies that have primarily focused on
accurately reconstructing garment geometries to match the input garment image
may often result in unnatural-looking garments when deformed for new poses. To
overcome this limitation, our approach takes a different approach by inferring
the fundamental shape of the garment through sewing patterns from a single
image, rather than directly reconstructing 3D garments. Our method consists of
two stages. Firstly, given a single image of a posed user, it predicts the
garment image worn on a T-pose, representing the baseline form of the garment.
Then, it estimates the sewing pattern parameters based on the T-pose garment
image. By simulating the stitching and draping of the sewing pattern using
physics simulation, we can generate 3D garments that can adaptively deform to
arbitrary poses. The effectiveness of our method is validated through ablation
studies on the major components and a comparison with other approaches.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16267" title="Abstract">arXiv:2312.16267</a> [<a href="/pdf/2312.16267" title="Download PDF">pdf</a>, <a href="/format/2312.16267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing the Success Probability of Policy Allocations in Online  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Betlei%2C+A">Artem Betlei</a>, 
<a href="/search/cs?searchtype=author&query=Vladimirova%2C+M">Mariia Vladimirova</a>, 
<a href="/search/cs?searchtype=author&query=Sebbar%2C+M">Mehdi Sebbar</a>, 
<a href="/search/cs?searchtype=author&query=Urien%2C+N">Nicolas Urien</a>, 
<a href="/search/cs?searchtype=author&query=Rahier%2C+T">Thibaud Rahier</a>, 
<a href="/search/cs?searchtype=author&query=Heymann%2C+B">Benjamin Heymann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to AAAI 2024, 7 pages main text, 9 pages references and appendix, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">The effectiveness of advertising in e-commerce largely depends on the ability
of merchants to bid on and win impressions for their targeted users. The
bidding procedure is highly complex due to various factors such as market
competition, user behavior, and the diverse objectives of advertisers. In this
paper we consider the problem at the level of user timelines instead of
individual bid requests, manipulating full policies (i.e. pre-defined bidding
strategies) and not bid values. In order to optimally allocate policies to
users, typical multiple treatments allocation methods solve knapsack-like
problems which aim at maximizing an expected value under constraints. In the
industrial contexts such as online advertising, we argue that optimizing for
the probability of success is a more suited objective than expected value
maximization, and we introduce the SuccessProbaMax algorithm that aims at
finding the policy allocation which is the most likely to outperform a fixed
reference policy. Finally, we conduct comprehensive experiments both on
synthetic and real-world data to evaluate its performance. The results
demonstrate that our proposed algorithm outperforms conventional expected-value
maximization algorithms in terms of success rate.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16268" title="Abstract">arXiv:2312.16268</a> [<a href="/pdf/2312.16268" title="Download PDF">pdf</a>, <a href="/format/2312.16268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360 Layout Estimation via Orthogonal Planes Disentanglement and  Multi-view Geometric Consistency Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhijie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junsong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Lang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+K">Kang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.00971">arXiv:2303.00971</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing panoramic layout estimation solutions tend to recover room
boundaries from a vertically compressed sequence, yielding imprecise results as
the compression process often muddles the semantics between various planes.
Besides, these data-driven approaches impose an urgent demand for massive data
annotations, which are laborious and time-consuming. For the first problem, we
propose an orthogonal plane disentanglement network (termed DOPNet) to
distinguish ambiguous semantics. DOPNet consists of three modules that are
integrated to deliver distortion-free, semantics-clean, and detail-sharp
disentangled representations, which benefit the subsequent layout recovery. For
the second problem, we present an unsupervised adaptation technique tailored
for horizon-depth and ratio representations. Concretely, we introduce an
optimization strategy for decision-level layout analysis and a 1D cost volume
construction method for feature-level multi-view aggregation, both of which are
designed to fully exploit the geometric consistency across multiple
perspectives. The optimizer provides a reliable set of pseudo-labels for
network training, while the 1D cost volume enriches each view with
comprehensive scene information derived from other perspectives. Extensive
experiments demonstrate that our solution outperforms other SoTA models on both
monocular layout estimation and multi-view layout estimation tasks.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16271" title="Abstract">arXiv:2312.16271</a> [<a href="/pdf/2312.16271" title="Download PDF">pdf</a>, <a href="/ps/2312.16271" title="Download PostScript">ps</a>, <a href="/format/2312.16271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function-Correcting Codes for Symbol-Pair Read Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Q">Qingfeng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bocong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Function-correcting codes are a class of codes designed to protect the
function evaluation of a message against errors whose key advantage is the
reduced redundancy. In this paper, we extend function-correcting codes from
binary symmetric channels to symbol-pair read channels. We introduce
irregular-pair-distance codes and connect them with function-correcting
symbol-pair codes. Using the connection, we derive general upper and lower
bounds on the optimal redundancy of function-correcting symbol-pair codes. For
ease of evaluation, we simplify these bounds and employ the simplified bounds
to specific functions including pair-locally binary functions, pair weight
functions and pair weight distribution functions.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16272" title="Abstract">arXiv:2312.16272</a> [<a href="/pdf/2312.16272" title="Download PDF">pdf</a>, <a href="/format/2312.16272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSR-Encoder: Encoding Selective Subject Representation for  Subject-Driven Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yiren Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jinpeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Han Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Z">Zhongliang Jing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in subject-driven image generation have led to zero-shot
generation, yet precise selection and focus on crucial subject representations
remain challenging. Addressing this, we introduce the SSR-Encoder, a novel
architecture designed for selectively capturing any subject from single or
multiple reference images. It responds to various query modalities including
text and masks, without necessitating test-time fine-tuning. The SSR-Encoder
combines a Token-to-Patch Aligner that aligns query inputs with image patches
and a Detail-Preserving Subject Encoder for extracting and preserving fine
features of the subjects, thereby generating subject embeddings. These
embeddings, used in conjunction with original text embeddings, condition the
generation process. Characterized by its model generalizability and efficiency,
the SSR-Encoder adapts to a range of custom models and control modules.
Enhanced by the Embedding Consistency Regularization Loss for improved
training, our extensive experiments demonstrate its effectiveness in versatile
and high-quality image generation, indicating its broad applicability. Project
page: https://ssr-encoder.github.io
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16273" title="Abstract">arXiv:2312.16273</a> [<a href="/pdf/2312.16273" title="Download PDF">pdf</a>, <a href="/ps/2312.16273" title="Download PostScript">ps</a>, <a href="/format/2312.16273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordination and Machine Learning in Multi-Robot Systems: Applications  in Robotic Soccer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reis%2C+L+P">Luis Paulo Reis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the concepts of Artificial Intelligence,
Multi-Agent-Systems, Coordination, Intelligent Robotics and Deep Reinforcement
Learning. Emphasis is given on and how AI and DRL, may be efficiently used to
create efficient robot skills and coordinated robotic teams, capable of
performing very complex actions and tasks, such as playing a game of soccer.
The paper also presents the concept of robotic soccer and the vision and
structure of the RoboCup initiative with emphasis on the Humanoid Simulation 3D
league and the new challenges this competition, poses. The final topics
presented at the paper are based on the research developed/coordinated by the
author throughout the last 22 years in the context of the FCPortugal project.
The paper presents a short description of the coordination methodologies
developed, such as: Strategy, Tactics, Formations, Setplays, and Coaching
Languages and the use of Machine Learning to optimize the use of this concepts.
The topics presented also include novel stochastic search algorithms for black
box optimization and their use in the optimization of omnidirectional walking
skills, robotic multi-agent learning and the creation of a humanoid kick with
controlled distance. Finally, new applications using variations of the Proximal
Policy Optimization algorithm and advanced modelling for robot and multi-robot
learning are briefly explained with emphasis for our new humanoid sprinting and
running skills and an amazing humanoid robot soccer dribbling skill. FCPortugal
project enabled us to publish more than 100 papers and win several competitions
in different leagues and many scientific awards at RoboCup. In total, our team
won more than 40 awards in international competitions including a clear victory
at the Simulation 3D League at RoboCup 2022 competition, scoring 84 goals and
conceding only 2.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16274" title="Abstract">arXiv:2312.16274</a> [<a href="/pdf/2312.16274" title="Download PDF">pdf</a>, <a href="/format/2312.16274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Flexible, Scalable, and Adaptive Multi-Modal Conditioned Face  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jingjing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xinran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent progress in multi-modal conditioned face synthesis has enabled the
creation of visually striking and accurately aligned facial images. Yet,
current methods still face issues with scalability, limited flexibility, and a
one-size-fits-all approach to control strength, not accounting for the
differing levels of conditional entropy, a measure of unpredictability in data
given some condition, across modalities. To address these challenges, we
introduce a novel uni-modal training approach with modal surrogates, coupled
with an entropy-aware modal-adaptive modulation, to support flexible, scalable,
and scalable multi-modal conditioned face synthesis network. Our uni-modal
training with modal surrogate that only leverage uni-modal data, use modal
surrogate to decorate condition with modal-specific characteristic and serve as
linker for inter-modal collaboration , fully learns each modality control in
face synthesis process as well as inter-modal collaboration. The entropy-aware
modal-adaptive modulation finely adjust diffusion noise according to
modal-specific characteristics and given conditions, enabling well-informed
step along denoising trajectory and ultimately leading to synthesis results of
high fidelity and quality. Our framework improves multi-modal face synthesis
under various conditions, surpassing current methods in image quality and
fidelity, as demonstrated by our thorough experimental results.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16275" title="Abstract">arXiv:2312.16275</a> [<a href="/pdf/2312.16275" title="Download PDF">pdf</a>, <a href="/format/2312.16275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Before Recommendation: Semantic Aspect-Aware Review  Exploitation via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Recommendation systems harness user-item interactions like clicks and reviews
to learn their representations. Previous studies improve recommendation
accuracy and interpretability by modeling user preferences across various
aspects and intents. However, the aspects and intents are inferred directly
from user reviews or behavior patterns, suffering from the data noise and the
data sparsity problem. Furthermore, it is difficult to understand the reasons
behind recommendations due to the challenges of interpreting implicit aspects
and intents. Inspired by the deep semantic understanding offered by large
language models (LLMs), we introduce a chain-based prompting approach to
uncover semantic aspect-aware interactions, which provide clearer insights into
user behaviors at a fine-grained semantic level. To incorporate the abundant
interactions of various aspects, we propose the simple yet effective Semantic
Aspect-based Graph Convolution Network (short for SAGCN). By performing graph
convolutions on multiple semantic aspect graphs, SAGCN efficiently combines
embeddings across multiple semantic aspects for final user and item
representations. The effectiveness of the SAGCN was evaluated on three publicly
available datasets through extensive experiments, which revealed that it
outperforms all other competitors. Furthermore, interpretability analysis
experiments were conducted to demonstrate the interpretability of incorporating
semantic aspects into the model.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16276" title="Abstract">arXiv:2312.16276</a> [<a href="/pdf/2312.16276" title="Download PDF">pdf</a>, <a href="/ps/2312.16276" title="Download PostScript">ps</a>, <a href="/format/2312.16276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-coalgebraic view of Fitting&#x27;s Heyting-valued modal logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+L+K">Litan Kumar Das</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+K+S">Kumar Sankar Ray</a>, 
<a href="/search/cs?searchtype=author&query=Mali%2C+P+C">Prakash Chandra Mali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Fitting's Heyting-valued modal logic and Heyting-valued logic have previously
been examined from an algebraic perspective. Topological duality theorems have
been developed in addition to algebraic axiomatizations with the completeness
of Fitting's logic and modal logic. Recently, bitopological techniques have
been used to study duality for Heyting-valued logic. But the development of
duality for Heyting-valued modal logic noticeably lacks bitopology and
biVietoris-coalgebra techniques. We are trying to bridge this gap in this
paper. We establish a bitopological duality for algebras of Fitting's
Heyting-valued modal logic. We build a bi-Vietoris functor on the category of
Heyting-valued pairwise Boolean spaces, denoted by $PBS_{\mathcal{L}}$. In the
end, we derive a dual equivalence between algebras of Fitting's Heyting-valued
modal logic and categories of bi-Vietoris coalgebras. We thus conclude that,
with respect to the coalgebras of a bi-Vietoris functor, Fitting's many-valued
modal logic is sound and complete.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16279" title="Abstract">arXiv:2312.16279</a> [<a href="/pdf/2312.16279" title="Download PDF">pdf</a>, <a href="/format/2312.16279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud-Device Collaborative Learning for Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanqun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junpeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kevin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+M">Maurice Chong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yijiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The burgeoning field of Multimodal Large Language Models (MLLMs) has
exhibited remarkable performance in diverse tasks such as captioning,
commonsense reasoning, and visual scene understanding. However, the deployment
of these large-scale MLLMs on client devices is hindered by their extensive
model parameters, leading to a notable decline in generalization capabilities
when these models are compressed for device deployment. Addressing this
challenge, we introduce a Cloud-Device Collaborative Continual Adaptation
framework, designed to enhance the performance of compressed, device-deployed
MLLMs by leveraging the robust capabilities of cloud-based, larger-scale MLLMs.
Our framework is structured into three key components: a device-to-cloud uplink
for efficient data transmission, cloud-based knowledge adaptation, and an
optimized cloud-to-device downlink for model deployment. In the uplink phase,
we employ an Uncertainty-guided Token Sampling (UTS) strategy to effectively
filter out-of-distribution tokens, thereby reducing transmission costs and
improving training efficiency. On the cloud side, we propose Adapter-based
Knowledge Distillation (AKD) method to transfer refined knowledge from
large-scale to compressed, pocket-size MLLMs. Furthermore, we propose a Dynamic
Weight update Compression (DWC) strategy for the downlink, which adaptively
selects and quantizes updated weight parameters, enhancing transmission
efficiency and reducing the representational disparity between cloud and device
models. Extensive experiments on several multimodal benchmarks demonstrate the
superiority of our proposed framework over prior Knowledge Distillation and
device-cloud collaboration methods. Notably, we also validate the feasibility
of our approach to real-world experiments.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16291" title="Abstract">arXiv:2312.16291</a> [<a href="/pdf/2312.16291" title="Download PDF">pdf</a>, <a href="/format/2312.16291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observable Propagation: A Data-Efficient Approach to Uncover Feature  Vectors in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunefsky%2C+J">Jacob Dunefsky</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">A key goal of current mechanistic interpretability research in NLP is to find
linear features (also called "feature vectors") for transformers: directions in
activation space corresponding to concepts that are used by a given model in
its computation. Present state-of-the-art methods for finding linear features
require large amounts of labelled data -- both laborious to acquire and
computationally expensive to utilize. In this work, we introduce a novel
method, called "observable propagation" (in short: ObsProp), for finding linear
features used by transformer language models in computing a given task -- using
almost no data. Our paradigm centers on the concept of observables, linear
functionals corresponding to given tasks. We then introduce a mathematical
theory for the analysis of feature vectors: we provide theoretical motivation
for why LayerNorm nonlinearities do not affect the direction of feature
vectors; we also introduce a similarity metric between feature vectors called
the coupling coefficient which estimates the degree to which one feature's
output correlates with another's. We use ObsProp to perform extensive
qualitative investigations into several tasks, including gendered occupational
bias, political party prediction, and programming language detection. Our
results suggest that ObsProp surpasses traditional approaches for finding
feature vectors in the low-data regime, and that ObsProp can be used to better
understand the mechanisms responsible for bias in large language models. Code
for experiments can be found at github.com/jacobdunefsky/ObservablePropagation.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16300" title="Abstract">arXiv:2312.16300</a> [<a href="/pdf/2312.16300" title="Download PDF">pdf</a>, <a href="/format/2312.16300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Static and Dynamic Intermediate Languages for Accelerator  Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Caleb Kim</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pai Li</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+A">Anshuman Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Butt%2C+A">Andrew Butt</a>, 
<a href="/search/cs?searchtype=author&query=Sampson%2C+A">Adrian Sampson</a>, 
<a href="/search/cs?searchtype=author&query=Nigam%2C+R">Rachit Nigam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Compilers for accelerator design languages (ADLs) translate high-level
languages into application-specific hardware. ADL compilers rely on a hardware
control interface to compose hardware units. There are two choices: static
control, which relies on cycle-level timing; or dynamic control, which uses
explicit signalling to avoid depending on timing details. Static control is
efficient but brittle; dynamic control incurs hardware costs to support
compositional reasoning. Piezo is an ADL compiler that unifies static and
dynamic control in a single intermediate language (IL). Its key insight is that
the IL's static fragment is a refinement of its dynamic fragment: static code
admits a subset of the run-time behaviors of the dynamic equivalent. Piezo can
optimize code by combining facts from static and dynamic submodules, and it
opportunistically converts code from dynamic to static control styles. We
implement Piezo as an extension to an existing dynamic ADL compiler, Calyx. We
use Piezo to implement an MLIR frontend, a systolic array generator, and a
packet-scheduling hardware generator to demonstrate its optimizations and the
static-dynamic interactions it enables.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16309" title="Abstract">arXiv:2312.16309</a> [<a href="/pdf/2312.16309" title="Download PDF">pdf</a>, <a href="/ps/2312.16309" title="Download PostScript">ps</a>, <a href="/format/2312.16309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contribuci&#xf3;n de la sem&#xe1;ntica combinatoria al desarrollo de  herramientas digitales multiling&#xfc;es
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=V%C3%A1zquez%2C+M+J+D">Mar&#xed;a Jos&#xe9; Dom&#xed;nguez V&#xe1;zquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, in Spanish language. C\'irculo de ling\"u\'istica aplicada a la comunicaci\'on, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper describes how the field of Combinatorial Semantics has contributed
to the design of three prototypes for the automatic generation of argument
patterns in nominal phrases in Spanish, French and German (Xera, Combinatoria
and CombiContext). It also shows the importance of knowing about the argument
syntactic-semantic interface in a production situation in the context of
foreign languages. After a descriptive section on the design, typologie and
information levels of the resources, there follows an explanation of the
central role of the combinatorial meaning (roles and ontological features). The
study deals with different semantic f ilters applied in the selection,
organization and expansion of the lexicon, being these key pieces for the
generation of grammatically correct and semantically acceptable mono- and
biargumental nominal phrases.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16311" title="Abstract">arXiv:2312.16311</a> [<a href="/pdf/2312.16311" title="Download PDF">pdf</a>, <a href="/ps/2312.16311" title="Download PostScript">ps</a>, <a href="/format/2312.16311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zur Darstellung eines mehrstufigen Prototypbegriffs in der  multilingualen automatischen Sprachgenerierung: vom Korpus &#xfc;ber word  embeddings bis hin zum automatischen W&#xf6;rterbuch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=V%C3%A1zquez%2C+M+J+D">Mar&#xed;a Jos&#xe9; Dom&#xed;nguez V&#xe1;zquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, in German language
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Lexikos 31 (AFRILEX-reeks/series 31: 2021):
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The multilingual dictionary of noun valency Portlex is considered to be the
trigger for the creation of the automatic language generators Xera and
Combinatoria, whose development and use is presented in this paper. Both
prototypes are used for the automatic generation of nominal phrases with their
mono- and bi-argumental valence slots, which could be used, among others, as
dictionary examples or as integrated components of future autonomous
E-Learning-Tools. As samples for new types of automatic valency dictionaries
including user interaction, we consider the language generators as we know them
today. In the specific methodological procedure for the development of the
language generators, the syntactic-semantic description of the noun slots turns
out to be the main focus from a syntagmatic and paradigmatic point of view.
Along with factors such as representativeness, grammatical correctness,
semantic coherence, frequency and the variety of lexical candidates, as well as
semantic classes and argument structures, which are fixed components of both
resources, a concept of a multi-sided prototype stands out. The combined
application of this prototype concept as well as of word embeddings together
with techniques from the field of automatic natural language processing and
generation (NLP and NLG) opens up a new way for the future development of
automatically generated plurilingual valency dictionaries. All things
considered, the paper depicts the language generators both from the point of
view of their development as well as from that of the users. The focus lies on
the role of the prototype concept within the development of the resources.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16313" title="Abstract">arXiv:2312.16313</a> [<a href="/pdf/2312.16313" title="Download PDF">pdf</a>, <a href="/format/2312.16313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Key Components of OOD Generalization via Diversification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benoit%2C+H">Harold Benoit</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liangze Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Atanov%2C+A">Andrei Atanov</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+O+F">O&#x11f;uzhan Fatih Kar</a>, 
<a href="/search/cs?searchtype=author&query=Rigotti%2C+M">Mattia Rigotti</a>, 
<a href="/search/cs?searchtype=author&query=Zamir%2C+A">Amir Zamir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Real-world datasets may contain multiple features that explain the training
data equally well, i.e., learning any of them would lead to correct predictions
on the training data. However, many of them can be spurious, i.e., lose their
predictive power under a distribution shift and fail to generalize to
out-of-distribution (OOD) data. Recently developed ``diversification'' methods
approach this problem by finding multiple diverse hypotheses that rely on
different features. This paper aims to study this class of methods and identify
the key components contributing to their OOD generalization abilities.
<br />We show that (1) diversification methods are highly sensitive to the
distribution of the unlabeled data used for diversification and can
underperform significantly when away from a method-specific sweet spot. (2)
Diversification alone is insufficient for OOD generalization. The choice of the
used learning algorithm, e.g., the model's architecture and pretraining, is
crucial, and using the second-best choice leads to an up to 20% absolute drop
in accuracy.(3) The optimal choice of learning algorithm depends on the
unlabeled data, and vice versa.Finally, we show that the above pitfalls cannot
be alleviated by increasing the number of diverse hypotheses, allegedly the
major feature of diversification methods.
<br />These findings provide a clearer understanding of the critical design factors
influencing the OOD generalization of diversification methods. They can guide
practitioners in how to use the existing methods best and guide researchers in
developing new, better ones.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16314" title="Abstract">arXiv:2312.16314</a> [<a href="/pdf/2312.16314" title="Download PDF">pdf</a>, <a href="/format/2312.16314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical LoRE: Local Recovery of Erasures: Local recovery using  polynomials, curves, surfaces, and liftings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haymaker%2C+K">Kathryn Haymaker</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+H+H">Hiram H. L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Malmskog%2C+B">Beth Malmskog</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+G+L">Gretchen L. Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Pi%C3%B1ero%2C+F">Fernando Pi&#xf1;ero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC); Algebraic Geometry (math.AG)

</div>
<p class="mathjax">Employing underlying geometric and algebraic structures allows for
constructing bespoke codes for local recovery of erasures. We survey techniques
for enriching classical codes with additional machinery, such as using lines or
curves in projective space for local recovery sets or products of curves to
enhance the availability of data.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16315" title="Abstract">arXiv:2312.16315</a> [<a href="/pdf/2312.16315" title="Download PDF">pdf</a>, <a href="/ps/2312.16315" title="Download PostScript">ps</a>, <a href="/format/2312.16315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursos lexicogr&#xe1;ficos electr&#xf3;nicos multiling&#xfc;es y  pluriling&#xfc;es: definici&#xf3;n y clasificaci&#xf3;n tipol&#xf3;gico-descriptiva
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=V%C3%A1zquez%2C+M+J+D">Mar&#xed;a Jos&#xe9; Dom&#xed;nguez V&#xe1;zquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, in Spanish language
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Revista Internacional de Lenguas Extranjeras, 10, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The aim of this paper is to provide a classification of multilingual and
plurilingual electronic lexicographic resources which would enable, one the one
hand, the implementation of quantitative and qualitative criteria to produce a
typological taxonomy of lexicographical tools, such as dictionaries, as opposed
to platforms and websites and, on the other, the distinction of multilingual
and plurilingual resources in terms of their larger or lesser prototyping
degree. In addition to offering a thorough description of the different
resources, this paper also puts forward some parameters and typological
proposals to define and demarcate a number of electronic resources,
particularly multilingual dictionaries and portals, while also outlining, and
even questioning, the object of study of multilingual and plurilingual
lexicography.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16322" title="Abstract">arXiv:2312.16322</a> [<a href="/pdf/2312.16322" title="Download PDF">pdf</a>, <a href="/format/2312.16322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-Envisioned Post-Quantum Secure Sanitizable Signature for  Audit Logs Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+V">Vikas Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Baidya%2C+P">Paresh Baidya</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+S+K">Sumit Kumar Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Mesnager%2C+S">Sihem Mesnager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Audit logs are one of the most important tools for transparently tracking
system events and maintaining continuous oversight in corporate organizations
and enterprise business systems. There are many cases where the audit logs
contain sensitive data, or the audit logs are enormous. In these situations,
dealing with a subset of the data is more practical than the entire data set.
To provide a secure solution to handle these issues, a sanitizable signature
scheme (SSS) is a viable cryptographic primitive. Herein, we first present the
\textit{first} post-quantum secure multivariate-based SSS, namely ${\sf
Mul-SAN}$. Our proposed design provides unforgeability, privacy, immutability,
signer accountability, and sanitizer accountability under the assumption that
the $MQ$ problem is NP-hard. ${\sf Mul-SAN}$ is very efficient and only
requires computing field multiplications and additions over a finite field for
its implementation. ${\sf Mul-SAN}$ presents itself as a practical method to
partially delegate control of the authenticated data in avenues like the
healthcare industry and government organizations. We also explore using
Blockchain to provide a tamper-proof and robust audit log mechanism.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16323" title="Abstract">arXiv:2312.16323</a> [<a href="/pdf/2312.16323" title="Download PDF">pdf</a>, <a href="/format/2312.16323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new local and explicit kinetic method for linear and non-linear  convection-diffusion problems with finite kinetic speeds: II.  Multi-dimensional case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wissocq%2C+G">Gauthier Wissocq</a>, 
<a href="/search/math?searchtype=author&query=Abgrall%2C+R">R&#xe9;mi Abgrall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We extend to multi-dimensions the work of [1], where new fully explicit
kinetic methods were built for the approximation of linear and non-linear
convection-diffusion problems. The fundamental principles from the earlier work
are retained: (1) rather than aiming for the desired equations in the strict
limit of a vanishing relaxation parameter, as is commonly done in the diffusion
limit of kinetic methods, diffusion terms are sought as a first-order
correction of this limit in a Chapman-Enskog expansion, (2) introducing a
coupling between the conserved variables within the relaxation process by a
specifically designed collision matrix makes it possible to systematically
match a desired diffusion. Extending this strategy to multi-dimensions cannot,
however, be achieved through simple directional splitting, as diffusion is
likely to couple space directions with each other, such as with shear viscosity
in the Navier-Stokes equations. In this work, we show how rewriting the
collision matrix in terms of moments can address this issue, regardless of the
number of kinetic waves, while ensuring conservation systematically. This
rewriting allows for introducing a new class of kinetic models called
\emph{regularized} models, simplifying the numerical methods and establishing
connections with Jin-Xin models. Subsequently, new explicit arbitrary
high-order kinetic schemes are formulated and validated on standard
two-dimensional cases from the literature. Excellent results are obtained in
the simulation of a shock-boundary layer interaction, validating their ability
to approximate the Navier-Stokes equations with kinetic speeds obeying nothing
but a subcharacteristic condition along with a hyperbolic constraint on the
time step.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16335" title="Abstract">arXiv:2312.16335</a> [<a href="/pdf/2312.16335" title="Download PDF">pdf</a>, <a href="/format/2312.16335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeanVec: Search your vectors faster by making them fit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tepper%2C+M">Mariano Tepper</a>, 
<a href="/search/cs?searchtype=author&query=Bhati%2C+I+S">Ishwar Singh Bhati</a>, 
<a href="/search/cs?searchtype=author&query=Aguerrebere%2C+C">Cecilia Aguerrebere</a>, 
<a href="/search/cs?searchtype=author&query=Hildebrand%2C+M">Mark Hildebrand</a>, 
<a href="/search/cs?searchtype=author&query=Willke%2C+T">Ted Willke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Modern deep learning models have the ability to generate high-dimensional
vectors whose similarity reflects semantic resemblance. Thus, similarity
search, i.e., the operation of retrieving those vectors in a large collection
that are similar to a given query, has become a critical component of a wide
range of applications that demand highly accurate and timely answers. In this
setting, the high vector dimensionality puts similarity search systems under
compute and memory pressure, leading to subpar performance. Additionally,
cross-modal retrieval tasks have become increasingly common, e.g., where a user
inputs a text query to find the most relevant images for that query. However,
these queries often have different distributions than the database embeddings,
making it challenging to achieve high accuracy. In this work, we present
LeanVec, a framework that combines linear dimensionality reduction with vector
quantization to accelerate similarity search on high-dimensional vectors while
maintaining accuracy. We present LeanVec variants for in-distribution (ID) and
out-of-distribution (OOD) queries. LeanVec-ID yields accuracies on par with
those from recently introduced deep learning alternatives whose computational
overhead precludes their usage in practice. LeanVec-OOD uses a novel technique
for dimensionality reduction that considers the query and database
distributions to simultaneously boost the accuracy and the performance of the
framework even further (even presenting competitive results when the query and
database distributions match). All in all, our extensive and varied
experimental results show that LeanVec produces state-of-the-art results, with
up to 3.7x improvement in search throughput and up to 4.9x faster index build
time over the state of the art.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16336" title="Abstract">arXiv:2312.16336</a> [<a href="/pdf/2312.16336" title="Download PDF">pdf</a>, <a href="/ps/2312.16336" title="Download PostScript">ps</a>, <a href="/format/2312.16336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning temporal formulas from examples is hard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mascle%2C+C">Corto Mascle</a>, 
<a href="/search/cs?searchtype=author&query=Fijalkow%2C+N">Nathana&#xeb;l Fijalkow</a>, 
<a href="/search/cs?searchtype=author&query=Lagarde%2C+G">Guillaume Lagarde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is a long version of the article <a href="/abs/2102.00876">arXiv:2102.00876</a> presented in the International Conference on Grammatical Inference (ICGI) in 2021. It includes much stronger and more general results than the extended abstract. Submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We study the problem of learning linear temporal logic (LTL) formulas from
examples, as a first step towards expressing a property separating positive and
negative instances in a way that is comprehensible for humans. In this paper we
initiate the study of the computational complexity of the problem. Our main
results are hardness results: we show that the LTL learning problem is
NP-complete, both for the full logic and for almost all of its fragments. This
motivates the search for efficient heuristics, and highlights the complexity of
expressing separating properties in concise natural language.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16337" title="Abstract">arXiv:2312.16337</a> [<a href="/pdf/2312.16337" title="Download PDF">pdf</a>, <a href="/format/2312.16337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Contamination: Language Models May Not Be Few-Shot Anymore
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changmao Li</a>, 
<a href="/search/cs?searchtype=author&query=Flanigan%2C+J">Jeffrey Flanigan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) offer impressive performance in various
zero-shot and few-shot tasks. However, their success in zero-shot and few-shot
settings may be affected by task contamination, a potential limitation that has
not been thoroughly examined. This paper investigates how zero-shot and
few-shot performance of LLMs has changed chronologically over time. Utilizing
GPT-3 series models and several other recent open-sourced LLMs, and controlling
for dataset difficulty, we find that on datasets released before the LLM
training data creation date, LLMs perform surprisingly better than on datasets
released after. This strongly indicates that, for many LLMs, there exists task
contamination on zero-shot and few-shot evaluation for datasets released prior
to the LLMs' training data creation date. Additionally, we utilize training
data inspection, task example extraction, and a membership inference attack,
which reveal further evidence of task contamination. Importantly, we find that
for classification tasks with no possibility of task contamination, LLMs rarely
demonstrate statistically significant improvements over simple majority
baselines, in both zero and few-shot settings.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16338" title="Abstract">arXiv:2312.16338</a> [<a href="/pdf/2312.16338" title="Download PDF">pdf</a>, <a href="/ps/2312.16338" title="Download PostScript">ps</a>, <a href="/format/2312.16338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-of-the-Art in Nudity Classification: A Comparative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akyon%2C+F+C">Fatih Cagatay Akyon</a>, 
<a href="/search/cs?searchtype=author&query=Temizel%2C+A">Alptekin Temizel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a comparative analysis of existing nudity classification
techniques for classifying images based on the presence of nudity, with a focus
on their application in content moderation. The evaluation focuses on CNN-based
models, vision transformer, and popular open-source safety checkers from Stable
Diffusion and Large-scale Artificial Intelligence Open Network (LAION). The
study identifies the limitations of current evaluation datasets and highlights
the need for more diverse and challenging datasets. The paper discusses the
potential implications of these findings for developing more accurate and
effective image classification systems on online platforms. Overall, the study
emphasizes the importance of continually improving image classification models
to ensure the safety and well-being of platform users. The project page,
including the demonstrations and results is publicly available at
https://github.com/fcakyon/content-moderation-deep-learning.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16339" title="Abstract">arXiv:2312.16339</a> [<a href="/pdf/2312.16339" title="Download PDF">pdf</a>, <a href="/format/2312.16339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Pyramid Adversarial Training for Improved ViT Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiang%2C+P">Ping-yeh Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yipin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Poursaeed%2C+O">Omid Poursaeed</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+S+N">Satya Narayan Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ashish Shah</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, Pyramid Adversarial training (Herrmann et al., 2022) has been shown
to be very effective for improving clean accuracy and distribution-shift
robustness of vision transformers. However, due to the iterative nature of
adversarial training, the technique is up to 7 times more expensive than
standard training. To make the method more efficient, we propose Universal
Pyramid Adversarial training, where we learn a single pyramid adversarial
pattern shared across the whole dataset instead of the sample-wise patterns.
With our proposed technique, we decrease the computational cost of Pyramid
Adversarial training by up to 70% while retaining the majority of its benefit
on clean performance and distribution-shift robustness. In addition, to the
best of our knowledge, we are also the first to find that universal adversarial
training can be leveraged to improve clean model performance.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16340" title="Abstract">arXiv:2312.16340</a> [<a href="/pdf/2312.16340" title="Download PDF">pdf</a>, <a href="/format/2312.16340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternate Training of Shared and Task-Specific Parameters for Multi-Task  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellavia%2C+S">Stefania Bellavia</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santa%2C+F">Francesco Della Santa</a>, 
<a href="/search/cs?searchtype=author&query=Papini%2C+A">Alessandra Papini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper introduces novel alternate training procedures for hard-parameter
sharing Multi-Task Neural Networks (MTNNs). Traditional MTNN training faces
challenges in managing conflicting loss gradients, often yielding sub-optimal
performance. The proposed alternate training method updates shared and
task-specific weights alternately, exploiting the multi-head architecture of
the model. This approach reduces computational costs, enhances training
regularization, and improves generalization. Convergence properties similar to
those of the classical stochastic gradient method are established. Empirical
experiments demonstrate delayed overfitting, improved prediction, and reduced
computational demands. In summary, our alternate training procedures offer a
promising advancement for the training of hard-parameter sharing MTNNs.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16351" title="Abstract">arXiv:2312.16351</a> [<a href="/pdf/2312.16351" title="Download PDF">pdf</a>, <a href="/format/2312.16351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs with User-defined Prompts as Generic Data Operators for Reliable  Data Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Luyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Thakurdesai%2C+N">Nikhil Thakurdesai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianpeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Korpeoglu%2C+E">Evren Korpeoglu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sushant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Achan%2C+K">Kannan Achan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 8 figures, 1st IEEE International Workshop on Data Engineering and Modeling for AI (DEMAI), IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data processing is one of the fundamental steps in machine learning pipelines
to ensure data quality. Majority of the applications consider the user-defined
function (UDF) design pattern for data processing in databases. Although the
UDF design pattern introduces flexibility, reusability and scalability, the
increasing demand on machine learning pipelines brings three new challenges to
this design pattern -- not low-code, not dependency-free and not
knowledge-aware. To address these challenges, we propose a new design pattern
that large language models (LLMs) could work as a generic data operator
(LLM-GDO) for reliable data cleansing, transformation and modeling with their
human-compatible performance. In the LLM-GDO design pattern, user-defined
prompts (UDPs) are used to represent the data processing logic rather than
implementations with a specific programming language. LLMs can be centrally
maintained so users don't have to manage the dependencies at the run-time.
Fine-tuning LLMs with domain-specific data could enhance the performance on the
domain-specific tasks which makes data processing knowledge-aware. We
illustrate these advantages with examples in different data processing tasks.
Furthermore, we summarize the challenges and opportunities introduced by LLMs
to provide a complete view of this design pattern for more discussions.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16352" title="Abstract">arXiv:2312.16352</a> [<a href="/pdf/2312.16352" title="Download PDF">pdf</a>, <a href="/ps/2312.16352" title="Download PostScript">ps</a>, <a href="/format/2312.16352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smuche: Scalar-Multiplicative Caching in Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongfang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Addressing the challenge of balancing security and efficiency when deploying
machine learning systems in untrusted environments, such as federated learning,
remains a critical concern. A promising strategy to tackle this issue involves
optimizing the performance of fully homomorphic encryption (HE). Recent
research highlights the efficacy of advanced caching techniques, such as Rache,
in significantly enhancing the performance of HE schemes without compromising
security. However, Rache is constrained by an inherent limitation: its
performance overhead is heavily influenced by the characteristics of plaintext
models, specifically exhibiting a caching time complexity of $\mathcal{O}(N)$,
where $N$ represents the number of cached pivots based on specific radixes.
This caching overhead becomes impractical for handling large-scale data. In
this study, we introduce a novel \textit{constant-time} caching technique that
is independent of any parameters. The core concept involves applying scalar
multiplication to a single cached ciphertext, followed by the introduction of a
completely new and constant-time randomness. Leveraging the inherent
characteristics of constant-time construction, we coin the term ``Smuche'' for
this innovative caching technique, which stands for Scalar-multiplicative
Caching of Homomorphic Encryption. We implemented Smuche from scratch and
conducted comparative evaluations against two baseline schemes, Rache and CKKS.
Our experimental results underscore the effectiveness of Smuche in addressing
the identified limitations and optimizing the performance of homomorphic
encryption in practical scenarios.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16355" title="Abstract">arXiv:2312.16355</a> [<a href="/pdf/2312.16355" title="Download PDF">pdf</a>, <a href="/format/2312.16355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Cost Modeling of Space-filling Curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kulik%2C+L">Lars Kulik</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">A space-filling curve (SFC) maps points in a multi-dimensional space to
one-dimensional points by discretizing the multi-dimensional space into cells
and imposing a linear order on the cells. This way, an SFC enables the indexing
of multi-dimensional data using a one-dimensional index such as a B+-tree.
Choosing an appropriate SFC is crucial, as different SFCs have different
effects on query performance. Currently, there are two primary strategies: 1)
deterministic schemes, which are computationally efficient but often yield
suboptimal query performance, and 2) dynamic schemes, which consider a broad
range of candidate SFCs based on cost functions but incur significant
computational overhead. Despite these strategies, existing methods cannot
efficiently measure the effectiveness of SFCs under heavy query workloads and
numerous SFC options.
<br />To address this problem, we propose means of constant-time cost estimations
that can enhance existing SFC selection algorithms, enabling them to learn more
effective SFCs. Additionally, we propose an SFC learning method that leverages
reinforcement learning and our cost estimation to choose an SFC pattern
efficiently. Experimental studies offer evidence of the effectiveness and
efficiency of the proposed means of cost estimation and SFC learning.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16361" title="Abstract">arXiv:2312.16361</a> [<a href="/pdf/2312.16361" title="Download PDF">pdf</a>, <a href="/ps/2312.16361" title="Download PostScript">ps</a>, <a href="/format/2312.16361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DLOT: An Open-Source Application to Assist Human Observers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashwin%2C+T+S">T S Ashwin</a>, 
<a href="/search/cs?searchtype=author&query=Shafi%2C+S+D">Shaikh Danish Shafi</a>, 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+R">Rajendran Ramkumar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 31st International Conference on Computers in Education, Volume 1,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Adaptive intelligent educational systems are gaining popularity, offering
personalized learning experiences to students based on their individual needs
and styles. One crucial feature of such systems is real-time personalized
feedback. However, identifying real-time learning processes impacting student
performance remains challenging due to data volume constraints. Current
research often relies on labor-intensive human observation, which is
time-consuming and not scalable. To efficiently collect real-time data, an
observation tool is essential. Qualitative/Mixed Method research explores
participant experiences in education, social science, and healthcare, utilizing
methods like focus groups and observations. However, these methods can be
labor-intensive, particularly in maintaining observation time intervals.
Existing tools lack comprehensive support for education-focused focus groups
and observations. To address these issues, this paper introduces the Data
Logging and Organizational Tool (DLOT), a flexible tool designed for
qualitative studies with human observers. DLOT offers customizable time
intervals, cross-platform compatibility, and data saving and sharing options.
The tool empowers observers to log timestamped data and is available on GitHub.
The DLOT was validated through two studies. The first study predicted students'
affective states using real-time annotations collected via DLOT, observing 30
students in each class. The second study created multimodal datasets in a
computer-enabled learning environment, observing 38 students individually. A
successful usability test was conducted, offering a potential solution to
challenges in real-time learning process identification and labor-intensive
qualitative research observation.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16362" title="Abstract">arXiv:2312.16362</a> [<a href="/pdf/2312.16362" title="Download PDF">pdf</a>, <a href="/ps/2312.16362" title="Download PostScript">ps</a>, <a href="/format/2312.16362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keeping Teams in the Game: Predicting Dropouts in Online Problem-Based  Learning Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panwar%2C+A">Aditya Panwar</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+A+T">Ashwin T S</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+R">Ramkumar Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Arya%2C+K">Kavi Arya</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 31st International Conference on Computers in Education, Volume 1,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Online learning and MOOCs have become increasingly popular in recent years,
and the trend will continue, given the technology boom. There is a dire need to
observe learners' behavior in these online courses, similar to what instructors
do in a face-to-face classroom. Learners' strategies and activities become
crucial to understanding their behavior. One major challenge in online courses
is predicting and preventing dropout behavior. While several studies have tried
to perform such analysis, there is still a shortage of studies that employ
different data streams to understand and predict the drop rates. Moreover,
studies rarely use a fully online team-based collaborative environment as their
context. Thus, the current study employs an online longitudinal problem-based
learning (PBL) collaborative robotics competition as the testbed. Through
methodological triangulation, the study aims to predict dropout behavior via
the contributions of Discourse discussion forum 'activities' of participating
teams, along with a self-reported Online Learning Strategies Questionnaire
(OSLQ). The study also uses Qualitative interviews to enhance the ground truth
and results. The OSLQ data is collected from more than 4000 participants.
Furthermore, the study seeks to establish the reliability of OSLQ to advance
research within online environments. Various Machine Learning algorithms are
applied to analyze the data. The findings demonstrate the reliability of OSLQ
with our substantial sample size and reveal promising results for predicting
the dropout rate in online competition.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16363" title="Abstract">arXiv:2312.16363</a> [<a href="/pdf/2312.16363" title="Download PDF">pdf</a>, <a href="/format/2312.16363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polygon Detection from a Set of Lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+A">Alfredo Ferreira Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+M+J">Manuel J. Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Jorge%2C+J+A">Joaquim A. Jorge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Detecting polygons defined by a set of line segments in a plane is an
important step in analyzing vector drawings. This paper presents an approach
combining several algorithms to detect basic polygons from arbitrary line
segments. The resulting algorithm runs in polynomial time and space, with
complexities of $O\bigl((N + M)^4\bigr)$ and $O\bigl((N + M)^2\bigr)$, where
$N$ is the number of line segments and $M$ is the number of intersections
between line segments. Our choice of algorithms was made to strike a good
compromise between efficiency and ease of implementation. The result is a
simple and efficient solution to detect polygons from lines.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16364" title="Abstract">arXiv:2312.16364</a> [<a href="/pdf/2312.16364" title="Download PDF">pdf</a>, <a href="/format/2312.16364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Verification for Knowledge-Based Logic of Risky Driving  Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+A">Anda Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sprinkle%2C+J">Jonathan Sprinkle</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+T+T">Taylor T. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Many decision-making scenarios in modern life benefit from the decision
support of artificial intelligence algorithms, which focus on a data-driven
philosophy and automated programs or systems. However, crucial decision issues
related to security, fairness, and privacy should consider more human knowledge
and principles to supervise such AI algorithms to reach more proper solutions
and to benefit society more effectively. In this work, we extract
knowledge-based logic that defines risky driving formats learned from public
transportation accident datasets, which haven't been analyzed in detail to the
best of our knowledge. More importantly, this knowledge is critical for
recognizing traffic hazards and could supervise and improve AI models in
safety-critical systems. Then we use automated verification methods to verify
the robustness of such logic. More specifically, we gather 72 accident datasets
from Data.gov and organize them by state. Further, we train Decision Tree and
XGBoost models on each state's dataset, deriving accident judgment logic.
Finally, we deploy robustness verification on these tree-based models under
multiple parameter combinations.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16365" title="Abstract">arXiv:2312.16365</a> [<a href="/pdf/2312.16365" title="Download PDF">pdf</a>, <a href="/format/2312.16365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Third-Person Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+T">Timo Klein</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+S">Susanna Weinberger</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>, 
<a href="/search/cs?searchtype=author&query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of third-person imitation learning with the
additional challenge that the learner must select the perspective from which
they observe the expert. In our setting, each perspective provides only limited
information about the expert's behavior, and the learning agent must carefully
select and combine information from different perspectives to achieve
competitive performance. This setting is inspired by real-world imitation
learning applications, e.g., in robotics, a robot might observe a human
demonstrator via camera and receive information from different perspectives
depending on the camera's position. We formalize the aforementioned active
third-person imitation learning problem, theoretically analyze its
characteristics, and propose a generative adversarial network-based active
learning approach. Empirically, we demstrate that our proposed approach can
effectively learn from expert demonstrations and explore the importance of
different architectural choices for the learner's performance.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16370" title="Abstract">arXiv:2312.16370</a> [<a href="/pdf/2312.16370" title="Download PDF">pdf</a>, <a href="/format/2312.16370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly Tight Bounds For Differentially Private Min $s$-$t$ and Multiway  Cut
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalirrooyfard%2C+M">Mina Dalirrooyfard</a>, 
<a href="/search/cs?searchtype=author&query=Mitrovi%C4%87%2C+S">Slobodan Mitrovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Nevmyvaka%2C+Y">Yuriy Nevmyvaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Finding min $s$-$t$ cuts in graphs is a basic algorithmic tool with
applications in image segmentation, community detection, reinforcement
learning, and data clustering. In this problem, we are given two nodes as
terminals, and the goal is to remove the smallest number of edges from the
graph so that these two terminals are disconnected. We study the complexity of
differential privacy for the min $s$-$t$ cut problem and show nearly tight
lower and upper bounds where we achieve privacy at no cost for running time
efficiency. We also develop a differentially private algorithm for the multiway
$k$-cut problem, in which we are given $k$ nodes as terminals that we would
like to disconnect. As a function of $k$, we obtain privacy guarantees that are
exponentially more efficient than applying the advanced composition theorem to
known algorithms for multiway $k$-cut. Finally, we empirically evaluate the
approximation of our differentially private min $s$-$t$ cut algorithm and show
that it almost matches the quality of the output of non-private ones.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16374" title="Abstract">arXiv:2312.16374</a> [<a href="/pdf/2312.16374" title="Download PDF">pdf</a>, <a href="/format/2312.16374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Polygraph: Uncovering LLMs&#x27; Factual Discernment through Intermediate  Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinwen He</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yujia Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chengan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have revolutionized various domains with
extensive knowledge and creative capabilities. However, a critical issue with
LLMs is their tendency to produce outputs that diverge from factual reality.
This phenomenon is particularly concerning in sensitive applications such as
medical consultation and legal advice, where accuracy is paramount. In this
paper, we introduce the LLM factoscope, a novel Siamese network-based model
that leverages the inner states of LLMs for factual detection. Our
investigation reveals distinguishable patterns in LLMs' inner states when
generating factual versus non-factual content. We demonstrate the LLM
factoscope's effectiveness across various architectures, achieving over 96%
accuracy in factual detection. Our work opens a new avenue for utilizing LLMs'
inner states for factual detection and encourages further exploration into
LLMs' inner workings for enhanced reliability and transparency.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16377" title="Abstract">arXiv:2312.16377</a> [<a href="/pdf/2312.16377" title="Download PDF">pdf</a>, <a href="/format/2312.16377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heavy-Traffic Optimal Size- and State-Aware Dispatching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Runhan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Grosof%2C+I">Isaac Grosof</a>, 
<a href="/search/cs?searchtype=author&query=Scully%2C+Z">Ziv Scully</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">Dispatching systems, where arriving jobs are immediately assigned to one of
multiple queues, are ubiquitous in computer systems and service systems. A
natural and practically relevant model is one in which each queue serves jobs
in FCFS (First-Come First-Served) order. We consider the case where the
dispatcher is size-aware, meaning it learns the size (i.e. service time) of
each job as it arrives; and state-aware, meaning it always knows the amount of
work (i.e. total remaining service time) at each queue. While size- and
state-aware dispatching to FCFS queues has been extensively studied, little is
known about optimal dispatching for the objective of minimizing mean delay. A
major obstacle is that no nontrivial lower bound on mean delay is known, even
in heavy traffic (i.e. the limit as load approaches capacity). This makes it
difficult to prove that any given policy is optimal, or even heavy-traffic
optimal.
<br />In this work, we propose the first size- and state-aware dispatching policy
that provably minimizes mean delay in heavy traffic. Our policy, called CARD
(Controlled Asymmetry Reduces Delay), keeps all but one of the queues short,
then routes as few jobs as possible to the one long queue. We prove an upper
bound on CARD's mean delay, and we prove the first nontrivial lower bound on
the mean delay of any size- and state-aware dispatching policy. Both results
apply to any number of servers. Our bounds match in heavy traffic, implying
CARD's heavy-traffic optimality. In particular, CARD's heavy-traffic
performance improves upon that of LWL (Least Work Left), SITA (Size Interval
Task Assignment), and other policies from the literature whose heavy-traffic
performance is known.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16378" title="Abstract">arXiv:2312.16378</a> [<a href="/pdf/2312.16378" title="Download PDF">pdf</a>, <a href="/format/2312.16378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Knowledge Acquisition for Content-Centric Cognitive Agents  Using LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oruganti%2C+S">Sanjay Oruganti</a>, 
<a href="/search/cs?searchtype=author&query=Nirenburg%2C+S">Sergei Nirenburg</a>, 
<a href="/search/cs?searchtype=author&query=English%2C+J">Jesse English</a>, 
<a href="/search/cs?searchtype=author&query=McShane%2C+M">Marjorie McShane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, AAAI Fall Symposium Series 2023 on Integrating Cognitive Architecture and Generative Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The paper describes a system that uses large language model (LLM) technology
to support the automatic learning of new entries in an intelligent agent's
semantic lexicon. The process is bootstrapped by an existing non-toy lexicon
and a natural language generator that converts formal, ontologically-grounded
representations of meaning into natural language sentences. The learning method
involves a sequence of LLM requests and includes an automatic quality control
step. To date, this learning method has been applied to learning multiword
expressions whose meanings are equivalent to those of transitive verbs in the
agent's lexicon. The experiment demonstrates the benefits of a hybrid learning
architecture that integrates knowledge-based methods and resources with both
traditional data analytics and LLMs.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16379" title="Abstract">arXiv:2312.16379</a> [<a href="/pdf/2312.16379" title="Download PDF">pdf</a>, <a href="/format/2312.16379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photovoltaic power forecasting using quantum machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagingalieva%2C+A">Asel Sagingalieva</a>, 
<a href="/search/cs?searchtype=author&query=Komornyik%2C+S">Stefan Komornyik</a>, 
<a href="/search/cs?searchtype=author&query=Senokosov%2C+A">Arsenii Senokosov</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Ayush Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Sedykh%2C+A">Alexander Sedykh</a>, 
<a href="/search/cs?searchtype=author&query=Mansell%2C+C">Christopher Mansell</a>, 
<a href="/search/cs?searchtype=author&query=Tsurkan%2C+O">Olga Tsurkan</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+K">Karan Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Pflitsch%2C+M">Markus Pflitsch</a>, 
<a href="/search/cs?searchtype=author&query=Melnikov%2C+A">Alexey Melnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Emerging Technologies (cs.ET); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Predicting solar panel power output is crucial for advancing the energy
transition but is complicated by the variable and non-linear nature of solar
energy. This is influenced by numerous meteorological factors, geographical
positioning, and photovoltaic cell properties, posing significant challenges to
forecasting accuracy and grid stability. Our study introduces a suite of
solutions centered around hybrid quantum neural networks designed to tackle
these complexities. The first proposed model, the Hybrid Quantum Long
Short-Term Memory, surpasses all tested models by over 40% lower mean absolute
and mean squared errors. The second proposed model, Hybrid Quantum
Sequence-to-Sequence neural network, once trained, predicts photovoltaic power
with 16% lower mean absolute error for arbitrary time intervals without the
need for prior meteorological data, highlighting its versatility. Moreover, our
hybrid models perform better even when trained on limited datasets, underlining
their potential utility in data-scarce scenarios. These findings represent a
stride towards resolving time series prediction challenges in energy power
forecasting through hybrid quantum models, showcasing the transformative
potential of quantum machine learning in catalyzing the renewable energy
transition.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16383" title="Abstract">arXiv:2312.16383</a> [<a href="/pdf/2312.16383" title="Download PDF">pdf</a>, <a href="/ps/2312.16383" title="Download PostScript">ps</a>, <a href="/format/2312.16383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frame-level emotional state alignment method for speech emotion  recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yingming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yayue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jinlong Xue</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yichen Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ya Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech emotion recognition (SER) systems aim to recognize human emotional
state during human-computer interaction. Most existing SER systems are trained
based on utterance-level labels. However, not all frames in an audio have
affective states consistent with utterance-level label, which makes it
difficult for the model to distinguish the true emotion of the audio and
perform poorly. To address this problem, we propose a frame-level emotional
state alignment method for SER. First, we fine-tune HuBERT model to obtain a
SER system with task-adaptive pretraining (TAPT) method, and extract embeddings
from its transformer layers to form frame-level pseudo-emotion labels with
clustering. Then, the pseudo labels are used to pretrain HuBERT. Hence, the
each frame output of HuBERT has corresponding emotional information. Finally,
we fine-tune the above pretrained HuBERT for SER by adding an attention layer
on the top of it, which can focus only on those frames that are emotionally
more consistent with utterance-level label. The experimental results performed
on IEMOCAP indicate that our proposed method performs better than
state-of-the-art (SOTA) methods.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16385" title="Abstract">arXiv:2312.16385</a> [<a href="/pdf/2312.16385" title="Download PDF">pdf</a>, <a href="/format/2312.16385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical Insight of Earth: A Cloud-Platform of Intelligent Computing  for Geospatial Big Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+Y">Yuanbin Man</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jichao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The rapid accumulation of Earth observation data presents a formidable
challenge for the processing capabilities of traditional remote sensing desktop
software, particularly when it comes to analyzing expansive geographical areas
and prolonged temporal sequences. Cloud computing has emerged as a
transformative solution, surmounting the barriers traditionally associated with
the management and computation of voluminous datasets. This paper introduces
the Analytical Insight of Earth (AI Earth), an innovative remote sensing
intelligent computing cloud platform, powered by the robust Alibaba Cloud
infrastructure. AI Earth provides an extensive collection of publicly available
remote sensing datasets, along with a suite of computational tools powered by a
high-performance computing engine. Furthermore, it provides a variety of
classic deep learning (DL) models and a novel remote sensing large vision
segmentation model tailored to different recognition tasks. The platform
enables users to upload their unique samples for model training and to deploy
third-party models, thereby increasing the accessibility and openness of DL
applications. This platform will facilitate researchers in leveraging remote
sensing data for large-scale applied research in areas such as resources,
environment, ecology, and climate.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16388" title="Abstract">arXiv:2312.16388</a> [<a href="/pdf/2312.16388" title="Download PDF">pdf</a>, <a href="/format/2312.16388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Mixture Proposals with Pull-Push Learning Scheme to Capture  Diverse Events for Weakly Supervised Temporal Video Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunoh Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jungchan Cho</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Joonsang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+Y">YoungJoon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+Y">Jin Young Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the weakly supervised temporal video grounding study, previous methods use
predetermined single Gaussian proposals which lack the ability to express
diverse events described by the sentence query. To enhance the expression
ability of a proposal, we propose a Gaussian mixture proposal (GMP) that can
depict arbitrary shapes by learning importance, centroid, and range of every
Gaussian in the mixture. In learning GMP, each Gaussian is not trained in a
feature space but is implemented over a temporal location. Thus the
conventional feature-based learning for Gaussian mixture model is not valid for
our case. In our special setting, to learn moderately coupled Gaussian mixture
capturing diverse events, we newly propose a pull-push learning scheme using
pulling and pushing losses, each of which plays an opposite role to the other.
The effects of components in our scheme are verified in-depth with extensive
ablation studies and the overall scheme achieves state-of-the-art performance.
Our code is available at https://github.com/sunoh-kim/pps.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16391" title="Abstract">arXiv:2312.16391</a> [<a href="/pdf/2312.16391" title="Download PDF">pdf</a>, <a href="/format/2312.16391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Spatial Temporal Consistency of Joint Visual Tactile Perception  in VR Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fuqiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kehan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zhuoyi Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by the IEEE Haptic Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the development of VR technology, especially the emergence of the
metaverse concept, the integration of visual and tactile perception has become
an expected experience in human-machine interaction. Therefore, achieving
spatial-temporal consistency of visual and tactile information in VR
applications has become a necessary factor for realizing this experience. The
state-of-the-art vibrotactile datasets generally contain temporal-level
vibrotactile information collected by randomly sliding on the surface of an
object, along with the corresponding image of the material/texture. However,
they lack the position/spatial information that corresponds to the signal
acquisition, making it difficult to achieve spatiotemporal alignment of
visual-tactile data. Therefore, we develop a new data acquisition system in
this paper which can collect visual and vibrotactile signals of different
textures/materials with spatial and temporal consistency. In addition, we
develop a VR-based application call "V-Touching" by leveraging the dataset
generated by the new acquisition system, which can provide pixel-to-taxel joint
visual-tactile perception when sliding over the surface of objects in the
virtual environment with distinct vibrotactile feedback of different
textures/materials. Our data and code are available at
\url{https://github.com/wmtlab/Pixel2Taxel}.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16392" title="Abstract">arXiv:2312.16392</a> [<a href="/pdf/2312.16392" title="Download PDF">pdf</a>, <a href="/format/2312.16392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Depth Networks with Skippable Sub-Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Woochul Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Systematic adaptation of network depths at runtime can be an effective way to
control inference latency and meet the resource condition of various devices.
However, previous depth adaptive networks do not provide general principles and
a formal explanation on why and which layers can be skipped, and, hence, their
approaches are hard to be generalized and require long and complex training
steps. In this paper, we present an architectural pattern and training method
for adaptive depth networks that can provide flexible accuracy-efficiency
trade-offs in a single network. In our approach, every residual stage is
divided into 2 consecutive sub-paths with different properties. While the first
sub-path is mandatory for hierarchical feature learning, the other is optimized
to incur minimal performance degradation even if it is skipped. Unlike previous
adaptive networks, our approach does not iteratively self-distill a fixed set
of sub-networks, resulting in significantly shorter training time. However,
once deployed on devices, it can instantly construct sub-networks of varying
depths to provide various accuracy-efficiency trade-offs in a single model. We
provide a formal rationale for why the proposed architectural pattern and
training method can reduce overall prediction errors while minimizing the
impact of skipping selected sub-paths. We also demonstrate the generality and
effectiveness of our approach with various residual networks, both from
convolutional neural networks and vision transformers.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16397" title="Abstract">arXiv:2312.16397</a> [<a href="/pdf/2312.16397" title="Download PDF">pdf</a>, <a href="/format/2312.16397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Distance and Shortest-Path Oracles for Fault-Tolerant  Geometric Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyungjin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jihun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+E">Eunjin Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In this paper, we present approximate distance and shortest-path oracles for
fault-tolerant Euclidean spanners motivated by the routing problem in
real-world road networks. An $f$-fault-tolerant Euclidean $t$-spanner for a set
$V$ of $n$ points in $\mathbb{R}^d$ is a graph $G=(V,E)$ where, for any two
points $p$ and $q$ in $V$ and a set $F$ of $f$ vertices of $V$, the distance
between $p$ and $q$ in $G-F$ is at most $t$ times their Euclidean distance.
Given an $f$-fault-tolerant Euclidean $t$-spanner $G$ with $O(n)$ edges and a
constant $\varepsilon$, our data structure has size $O_{t,f}(n\log n)$, and
this allows us to compute an $(1+\varepsilon)$-approximate distance in $G-F$
between $s$ and $s'$ can be computed in constant time for any two vertices $s$
and $s'$ and a set $F$ of $f$ failed vertices. Also, with a data structure of
size $O_{t,f}(n\log n\log\log n)$,
<br />we can compute an $(1+\varepsilon)$-approximate shortest path in $G-F$
between $s$ and $s'$ in $O_{t,f}(\log^2 n\log\log n+\textsf{sol})$ time for any
two vertices $s$ and $s'$ and a set $F$ of failed vertices, where
$\textsf{sol}$ denotes the number of vertices in the returned path.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16400" title="Abstract">arXiv:2312.16400</a> [<a href="/pdf/2312.16400" title="Download PDF">pdf</a>, <a href="/format/2312.16400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LGMRec: Local and Global Graph Learning for Multimodal Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhiqiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guohui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Si Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+B">Bin Ruan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The multimodal recommendation has gradually become the infrastructure of
online media platforms, enabling them to provide personalized service to users
through a joint modeling of user historical behaviors (e.g., purchases, clicks)
and item various modalities (e.g., visual and textual). The majority of
existing studies typically focus on utilizing modal features or modal-related
graph structure to learn user local interests. Nevertheless, these approaches
encounter two limitations: (1) Shared updates of user ID embeddings result in
the consequential coupling between collaboration and multimodal signals; (2)
Lack of exploration into robust global user interests to alleviate the sparse
interaction problems faced by local interest modeling. To address these issues,
we propose a novel Local and Global Graph Learning-guided Multimodal
Recommender (LGMRec), which jointly models local and global user interests.
Specifically, we present a local graph embedding module to independently learn
collaborative-related and modality-related embeddings of users and items with
local topological relations. Moreover, a global hypergraph embedding module is
designed to capture global user and item embeddings by modeling insightful
global dependency relations. The global embeddings acquired within the
hypergraph embedding space can then be combined with two decoupled local
embeddings to improve the accuracy and robustness of recommendations. Extensive
experiments conducted on three benchmark datasets demonstrate the superiority
of our LGMRec over various state-of-the-art recommendation baselines,
showcasing its effectiveness in modeling both local and global user interests.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16401" title="Abstract">arXiv:2312.16401</a> [<a href="/pdf/2312.16401" title="Download PDF">pdf</a>, <a href="/format/2312.16401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Adversarial Patch Generation Method Based on Latent Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fazhan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, some research show that deep neural networks are vulnerable to the
adversarial attacks, the well-trainned samples or patches could be used to
trick the neural network detector or human visual perception. However, these
adversarial patches, with their conspicuous and unusual patterns, lack
camouflage and can easily raise suspicion in the real world. To solve this
problem, this paper proposed a novel adversarial patch method called the Latent
Diffusion Patch (LDP), in which, a pretrained encoder is first designed to
compress the natural images into a feature space with key characteristics. Then
trains the diffusion model using the above feature space. Finally, explore the
latent space of the pretrained diffusion model using the image denoising
technology. It polishes the patches and images through the powerful natural
abilities of diffusion models, making them more acceptable to the human visual
system. Experimental results, both digital and physical worlds, show that LDPs
achieve a visual subjectivity score of 87.3%, while still maintaining effective
attack capabilities.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16403" title="Abstract">arXiv:2312.16403</a> [<a href="/pdf/2312.16403" title="Download PDF">pdf</a>, <a href="/format/2312.16403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Time-aware Graph Structures for Spatially Correlated Time  Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jilin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Peng Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatio-temporal forecasting of future values of spatially correlated time
series is important across many cyber-physical systems (CPS). Recent studies
offer evidence that the use of graph neural networks to capture latent
correlations between time series holds a potential for enhanced forecasting.
However, most existing methods rely on pre-defined or self-learning graphs,
which are either static or unintentionally dynamic, and thus cannot model the
time-varying correlations that exhibit trends and periodicities caused by the
regularity of the underlying processes in CPS. To tackle such limitation, we
propose Time-aware Graph Structure Learning (TagSL), which extracts time-aware
correlations among time series by measuring the interaction of node and time
representations in high-dimensional spaces. Notably, we introduce time
discrepancy learning that utilizes contrastive learning with distance-based
regularization terms to constrain learned spatial correlations to a trend
sequence. Additionally, we propose a periodic discriminant function to enable
the capture of periodic changes from the state of nodes. Next, we present a
Graph Convolution-based Gated Recurrent Unit (GCGRU) that jointly captures
spatial and temporal dependencies while learning time-aware and node-specific
patterns. Finally, we introduce a unified framework named Time-aware Graph
Convolutional Recurrent Network (TGCRN), combining TagSL, and GCGRU in an
encoder-decoder architecture for multi-step spatio-temporal forecasting. We
report on experiments with TGCRN and popular existing approaches on five
real-world datasets, thus providing evidence that TGCRN is capable of advancing
the state-of-the-art. We also cover a detailed ablation study and visualization
analysis, offering detailed insight into the effectiveness of time-aware
structure learning.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16409" title="Abstract">arXiv:2312.16409</a> [<a href="/pdf/2312.16409" title="Download PDF">pdf</a>, <a href="/format/2312.16409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Sub-graph Distillation for Robust Semi-supervised Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengfei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Continual learning (CL) has shown promising results and comparable
performance to learning at once in a fully supervised manner. However, CL
strategies typically require a large number of labeled samples, making their
real-life deployment challenging. In this work, we focus on semi-supervised
continual learning (SSCL), where the model progressively learns from partially
labeled data with unknown categories. We provide a comprehensive analysis of
SSCL and demonstrate that unreliable distributions of unlabeled data lead to
unstable training and refinement of the progressing stages. This problem
severely impacts the performance of SSCL. To address the limitations, we
propose a novel approach called Dynamic Sub-Graph Distillation (DSGD) for
semi-supervised continual learning, which leverages both semantic and
structural information to achieve more stable knowledge distillation on
unlabeled data and exhibit robustness against distribution bias. Firstly, we
formalize a general model of structural distillation and design a dynamic graph
construction for the continual learning progress. Next, we define a structure
distillation vector and design a dynamic sub-graph distillation algorithm,
which enables end-to-end training and adaptability to scale up tasks. The
entire proposed method is adaptable to various CL methods and supervision
settings. Finally, experiments conducted on three datasets CIFAR10, CIFAR100,
and ImageNet-100, with varying supervision ratios, demonstrate the
effectiveness of our proposed approach in mitigating the catastrophic
forgetting problem in semi-supervised continual learning scenarios.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16410" title="Abstract">arXiv:2312.16410</a> [<a href="/pdf/2312.16410" title="Download PDF">pdf</a>, <a href="/format/2312.16410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Change Model (SCM) for Unsupervised Change detection in VHR  Remote Sensing Images: a Case Study of Buildings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiaoliang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanzhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to International Geoscience and Remote Sensing Symposium (IGARSS), 2024. 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of Remote Sensing (RS) widely employs Change Detection (CD) on
very-high-resolution (VHR) images. A majority of extant deep-learning-based
methods hinge on annotated samples to complete the CD process. Recently, the
emergence of Vision Foundation Model (VFM) enables zero-shot predictions in
particular vision tasks. In this work, we propose an unsupervised CD method
named Segment Change Model (SCM), built upon the Segment Anything Model (SAM)
and Contrastive Language-Image Pre-training (CLIP). Our method recalibrates
features extracted at different scales and integrates them in a top-down manner
to enhance discriminative change edges. We further design an innovative
Piecewise Semantic Attention (PSA) scheme, which can offer semantic
representation without training, thereby minimize pseudo change phenomenon.
Through conducting experiments on two public datasets, the proposed SCM
increases the mIoU from 46.09% to 53.67% on the LEVIR-CD dataset, and from
47.56% to 52.14% on the WHU-CD dataset. Our codes are available at
https://github.com/StephenApX/UCD-SCM.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16413" title="Abstract">arXiv:2312.16413</a> [<a href="/pdf/2312.16413" title="Download PDF">pdf</a>, <a href="/format/2312.16413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Coflows Scheduling Algorithms for Minimizing the  Total Weighted Completion Time and Makespan in Heterogeneous Parallel  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chi-Yeh Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.11296">arXiv:2311.11296</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Coflow is a network abstraction used to represent communication patterns in
data centers. The coflow scheduling problem encountered in large data centers
is a challenging $\mathcal{NP}$-hard problem. This paper tackles the scheduling
problem of coflows with release times in heterogeneous parallel networks, which
feature an architecture consisting of multiple network cores running in
parallel. Two polynomial-time approximation algorithms are presented in this
paper, designed to minimize the total weighted completion time and makespan in
heterogeneous parallel networks, respectively. For any given $\epsilon&gt;0$, our
proposed approximation algorithm for minimizing the total weighted completion
time achieves approximation ratios of $3 + \epsilon$ and $2 + \epsilon$ in the
cases of arbitrary and zero release times, respectively. Additionally, we
introduce an approximation algorithm for minimizing the makespan, achieving an
approximation ratio of $2 + \epsilon$ for $\epsilon&gt;0$. Notably, these
advancements surpass the previously best-known approximation ratio of $O(\log
m/ \log \log m)$ for both minimizing the total weighted completion time and
makespan. This result also improves upon the previous approximation ratios of
$6-\frac{2}{m}$ and $5-\frac{2}{m}$ for arbitrary and zero release times,
respectively, in identical parallel networks.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16414" title="Abstract">arXiv:2312.16414</a> [<a href="/pdf/2312.16414" title="Download PDF">pdf</a>, <a href="/format/2312.16414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bellman Optimal Step-size Straightening of Flow-Matching Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B">Bao Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B">Binh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+A">Viet Anh Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Flow matching is a powerful framework for generating high-quality samples in
various applications, especially image synthesis. However, the intensive
computational demands of these models, especially during the fine-tuning
process and sampling processes, pose significant challenges for low-resource
scenarios. This paper introduces Bellman Optimal Step-size Straightening (BOSS)
technique for distilling flow-matching generative models: it aims specifically
for a few step efficient image sampling while adhering to a computational
budget constraint. First, this technique involves a dynamic programming
algorithm that optimizes the step sizes of the pretrained network. Then, it
refines the velocity network to match the optimal step sizes, aiming to
straighten the generation paths. Extensive experimental evaluations across
image generation tasks demonstrate the efficacy of BOSS in terms of both
resource utilization and image quality. Our results reveal that BOSS achieves
substantial gains in efficiency while maintaining competitive sample quality,
effectively bridging the gap between low-resource constraints and the demanding
requirements of flow-matching generative models. Our paper also fortifies the
responsible development of artificial intelligence, offering a more sustainable
generative model that reduces computational costs and environmental footprints.
Our code can be found at https://anonymous.4open.science/r/DRL-8E88.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16415" title="Abstract">arXiv:2312.16415</a> [<a href="/pdf/2312.16415" title="Download PDF">pdf</a>, <a href="/ps/2312.16415" title="Download PostScript">ps</a>, <a href="/format/2312.16415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Minimum Steiner Cut in Maximum Flow Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Matthew Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jason Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We devise a deterministic algorithm for minimum Steiner cut which uses
polylogarithmic maximum flow calls and near-linear time outside of these
maximum flow calls. This improves on Li and Panigrahi's (FOCS 2020) algorithm
which takes $O(m^{1+\epsilon})$ time outside of maximum flow calls. Our
algorithm thus shows that deterministic minimum Steiner cut can be solved in
maximum flow time up to polylogarithmic factors, given any black-box
deterministic maximum flow algorithm. Our main technical contribution is a
novel deterministic graph decomposition method for terminal vertices which
generalizes all existing $s$-strong partitioning methods and may have future
applications.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16418" title="Abstract">arXiv:2312.16418</a> [<a href="/pdf/2312.16418" title="Download PDF">pdf</a>, <a href="/format/2312.16418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining Latent Homophilic Structures over Heterophilic Graphs for  Robust Graph Convolution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Chenyang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+G">Guoshun Nan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+T">Tianyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wendi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhiyang Teng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lijuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qimei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaofeng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appeared in the proceedings of AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph convolution networks (GCNs) are extensively utilized in various graph
tasks to mine knowledge from spatial data. Our study marks the pioneering
attempt to quantitatively investigate the GCN robustness over omnipresent
heterophilic graphs for node classification. We uncover that the predominant
vulnerability is caused by the structural out-of-distribution (OOD) issue. This
finding motivates us to present a novel method that aims to harden GCNs by
automatically learning Latent Homophilic Structures over heterophilic graphs.
We term such a methodology as LHS. To elaborate, our initial step involves
learning a latent structure by employing a novel self-expressive technique
based on multi-node interactions. Subsequently, the structure is refined using
a pairwisely constrained dual-view contrastive learning approach. We
iteratively perform the above procedure, enabling a GCN model to aggregate
information in a homophilic way on heterophilic graphs. Armed with such an
adaptable structure, we can properly mitigate the structural OOD threats over
heterophilic graphs. Experiments on various benchmarks show the effectiveness
of the proposed LHS approach for robust GCNs.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16423" title="Abstract">arXiv:2312.16423</a> [<a href="/pdf/2312.16423" title="Download PDF">pdf</a>, <a href="/format/2312.16423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Method for Solving Four Types of SAT Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Congying Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tiande Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bonan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Existing methods provide varying algorithms for different types of Boolean
satisfiability problems (SAT), lacking a general solution framework.
Accordingly, this study proposes a unified framework DCSAT based on integer
programming and reinforcement learning (RL) algorithm to solve different types
of SAT problems such as MaxSAT, Weighted MaxSAT, PMS, WPMS. Specifically, we
first construct a consolidated integer programming representation for four
types of SAT problems by adjusting objective function coefficients. Secondly,
we construct an appropriate reinforcement learning models based on the 0-1
integer programming for SAT problems. Based on the binary tree search
structure, we apply the Monte Carlo tree search (MCTS) method on SAT problems.
Finally, we prove that this method can find all optimal Boolean assignments
based on Wiener-khinchin law of large Numbers. We experimentally verify that
this paradigm can prune the unnecessary search space to find the optimal
Boolean assignments for the problem. Furthermore, the proposed method can
provide diverse labels for supervised learning methods for SAT problems.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16424" title="Abstract">arXiv:2312.16424</a> [<a href="/pdf/2312.16424" title="Download PDF">pdf</a>, <a href="/format/2312.16424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Contrastive Learning for Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taeyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kibok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS Workshop on Self-Supervised Learning: Theory and Practice, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Contrastive learning has shown to be effective to learn representations from
time series in a self-supervised way. However, contrasting similar time series
instances or values from adjacent timestamps within a time series leads to
ignore their inherent correlations, which results in deteriorating the quality
of learned representations. To address this issue, we propose SoftCLT, a simple
yet effective soft contrastive learning strategy for time series. This is
achieved by introducing instance-wise and temporal contrastive loss with soft
assignments ranging from zero to one. Specifically, we define soft assignments
for 1) instance-wise contrastive loss by the distance between time series on
the data space, and 2) temporal contrastive loss by the difference of
timestamps. SoftCLT is a plug-and-play method for time series contrastive
learning that improves the quality of learned representations without bells and
whistles. In experiments, we demonstrate that SoftCLT consistently improves the
performance in various downstream tasks including classification,
semi-supervised learning, transfer learning, and anomaly detection, showing
state-of-the-art performance. Code is available at this repository:
https://github.com/seunghan96/softclt.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16425" title="Abstract">arXiv:2312.16425</a> [<a href="/pdf/2312.16425" title="Download PDF">pdf</a>, <a href="/format/2312.16425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Hand 3D Object Reconstruction from a Monocular RGB Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shijian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Rengan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuchi Huo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our work aims to reconstruct a 3D object that is held and rotated by a hand
in front of a static RGB camera. Previous methods that use implicit neural
representations to recover the geometry of a generic hand-held object from
multi-view images achieved compelling results in the visible part of the
object. However, these methods falter in accurately capturing the shape within
the hand-object contact region due to occlusion. In this paper, we propose a
novel method that deals with surface reconstruction under occlusion by
incorporating priors of 2D occlusion elucidation and physical contact
constraints. For the former, we introduce an object amodal completion network
to infer the 2D complete mask of objects under occlusion. To ensure the
accuracy and view consistency of the predicted 2D amodal masks, we devise a
joint optimization method for both amodal mask refinement and 3D
reconstruction. For the latter, we impose penetration and attraction
constraints on the local geometry in contact regions. We evaluate our approach
on HO3D and HOD datasets and demonstrate that it outperforms the
state-of-the-art methods in terms of reconstruction surface quality, with an
improvement of $52\%$ on HO3D and $20\%$ on HOD. Project webpage:
https://east-j.github.io/ihor.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16426" title="Abstract">arXiv:2312.16426</a> [<a href="/pdf/2312.16426" title="Download PDF">pdf</a>, <a href="/ps/2312.16426" title="Download PostScript">ps</a>, <a href="/format/2312.16426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral approximation of $&#x3c8;$-fractional differential equation based  on mapped Jacobi functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+T">Tinggang Zhao</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+Z">Zhenyu Zhao</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+C">Changpin Li</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+D">Dongxia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a full length version of a submission to TWMS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Fractional calculus with respect to function $\psi$, also named as
$\psi$-fractional calculus, generalizes the Hadamard and the Riemann-Liouville
fractional calculi, which causes challenge in numerical treatment. In this
paper we study spectral-type methods using mapped Jacobi functions (MJFs) as
basis functions and obtain efficient algorithms to solve $\psi$-fractional
differential equations. In particular, we setup the Petrov-Galerkin spectral
method and spectral collocation method for initial and boundary value problems
involving $\psi$-fractional derivatives. We develop basic approximation theory
for the MJFs and conduct the error estimates of the derived methods. We also
establish a recurrence relation to evaluate the collocation differentiation
matrix for implementing the spectral collocation algorithm. Numerical examples
confirm the theoretical results and demonstrate the effectiveness of the
spectral and collocation methods.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16427" title="Abstract">arXiv:2312.16427</a> [<a href="/pdf/2312.16427" title="Download PDF">pdf</a>, <a href="/format/2312.16427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Embed Time Series Patches Independently
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taeyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kibok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS Workshop on Self-Supervised Learning: Theory and Practice, 2023. Oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Masked time series modeling has recently gained much attention as a
self-supervised representation learning strategy for time series. Inspired by
masked image modeling in computer vision, recent works first patchify and
partially mask out time series, and then train Transformers to capture the
dependencies between patches by predicting masked patches from unmasked
patches. However, we argue that capturing such patch dependencies might not be
an optimal strategy for time series representation learning; rather, learning
to embed patches independently results in better time series representations.
Specifically, we propose to use 1) the simple patch reconstruction task, which
autoencode each patch without looking at other patches, and 2) the simple
patch-wise MLP that embeds each patch independently. In addition, we introduce
complementary contrastive learning to hierarchically capture adjacent time
series information efficiently. Our proposed method improves time series
forecasting and classification performance compared to state-of-the-art
Transformer-based models, while it is more efficient in terms of the number of
parameters and training/inference time. Code is available at this repository:
https://github.com/seunghan96/pits.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16429" title="Abstract">arXiv:2312.16429</a> [<a href="/pdf/2312.16429" title="Download PDF">pdf</a>, <a href="/format/2312.16429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAD-PVI: A General Accelerated Dynamic-Weight Particle-Based Variational  Inference Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangyikang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huminhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanbin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hui Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Particle-based Variational Inference (ParVI) methods approximate the target
distribution by iteratively evolving finite weighted particle systems. Recent
advances of ParVI methods reveal the benefits of accelerated position update
strategies and dynamic weight adjustment approaches. In this paper, we propose
the first ParVI framework that possesses both accelerated position update and
dynamical weight adjustment simultaneously, named the General Accelerated
Dynamic-Weight Particle-based Variational Inference (GAD-PVI) framework.
Generally, GAD-PVI simulates the semi-Hamiltonian gradient flow on a novel
Information-Fisher-Rao space, which yields an additional decrease on the local
functional dissipation. GAD-PVI is compatible with different dissimilarity
functionals and associated smoothing approaches under three information
metrics. Experiments on both synthetic and real-world data demonstrate the
faster convergence and reduced approximation error of GAD-PVI methods over the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16430" title="Abstract">arXiv:2312.16430</a> [<a href="/pdf/2312.16430" title="Download PDF">pdf</a>, <a href="/format/2312.16430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference as Reward, Maximum Preference Optimization with Importance  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zaifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Preference learning is a key technology for aligning language models with
human values. Reinforcement Learning from Human Feedback (RLHF) is a model
based algorithm to optimize preference learning, which first fitting a reward
model for preference score, and then optimizing generating policy with
on-policy PPO algorithm to maximize the reward. The processing of RLHF is
complex, time-consuming and unstable. Direct Preference Optimization (DPO)
algorithm using off-policy algorithm to direct optimize generating policy and
eliminating the need for reward model, which is data efficient and stable. DPO
use Bradley-Terry model and log-loss which leads to over-fitting to the
preference data at the expense of ignoring KL-regularization term when
preference near deterministic. IPO uses a root-finding pairwise MSE loss to
solve the ignoring KL-regularization problem, and learning an optimal policy.
But IPO's pairwise loss still can't s make the KL-regularization to work. In
this paper, we design a simple and intuitive off-policy preferences
optimization algorithm from an importance sampling view, and add an off-policy
KL-regularization term which makes KL-regularization truly effective. To
simplify the learning process and save memory usage, we can generate
regularization data in advance, which eliminate the needs for both reward model
and reference policy in the stage of optimization.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16436" title="Abstract">arXiv:2312.16436</a> [<a href="/pdf/2312.16436" title="Download PDF">pdf</a>, <a href="/format/2312.16436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gemini: Mapping and Architecture Co-exploration for Large-scale DNN  Chiplet Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jingwei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuotong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuchen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhanhong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guiming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaisheng Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Chiplet technology enables the integration of an increasing number of
transistors on a single accelerator with higher yield in the post-Moore era,
addressing the immense computational demands arising from rapid AI
advancements. However, it also introduces more expensive packaging costs and
costly Die-to-Die (D2D) interfaces, which require more area, consume higher
power, and offer lower bandwidth than on-chip interconnects. Maximizing the
benefits and minimizing the drawbacks of chiplet technology is crucial for
developing large-scale DNN chiplet accelerators, which poses challenges to both
architecture and mapping. Despite its importance in the post-Moore era, methods
to address these challenges remain scarce.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16438" title="Abstract">arXiv:2312.16438</a> [<a href="/pdf/2312.16438" title="Download PDF">pdf</a>, <a href="/format/2312.16438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Spatial Attention and Proprioceptive Data-Driven Reinforcement  Learning for Robust Peg-in-Hole Task Under Variable Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yasutomi%2C+A+Y">Andr&#xe9; Yuji Yasutomi</a>, 
<a href="/search/cs?searchtype=author&query=Ichiwara%2C+H">Hideyuki Ichiwara</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+H">Hiroshi Ito</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+H">Hiroki Mori</a>, 
<a href="/search/cs?searchtype=author&query=Ogata%2C+T">Tetsuya Ogata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters in 08 February 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 8, issue 3, pp.
  1834-1841, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Anchor-bolt insertion is a peg-in-hole task performed in the construction
field for holes in concrete. Efforts have been made to automate this task, but
the variable lighting and hole surface conditions, as well as the requirements
for short setup and task execution time make the automation challenging. In
this study, we introduce a vision and proprioceptive data-driven robot control
model for this task that is robust to challenging lighting and hole surface
conditions. This model consists of a spatial attention point network (SAP) and
a deep reinforcement learning (DRL) policy that are trained jointly end-to-end
to control the robot. The model is trained in an offline manner, with a
sample-efficient framework designed to reduce training time and minimize the
reality gap when transferring the model to the physical world. Through
evaluations with an industrial robot performing the task in 12 unknown holes,
starting from 16 different initial positions, and under three different
lighting conditions (two with misleading shadows), we demonstrate that SAP can
generate relevant attention points of the image even in challenging lighting
conditions. We also show that the proposed model enables task execution with
higher success rate and shorter task completion time than various baselines.
Due to the proposed model's high effectiveness even in severe lighting, initial
positions, and hole conditions, and the offline training framework's high
sample-efficiency and short training time, this approach can be easily applied
to construction.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16446" title="Abstract">arXiv:2312.16446</a> [<a href="/pdf/2312.16446" title="Download PDF">pdf</a>, <a href="/format/2312.16446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Variable as Effect, in Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiselyov%2C+O">Oleg Kiselyov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-reviewed, accepted for presentation and presented at the ACM SIGPLAN HOPE 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Variable environment is the time-honored way of making sense of free
variables, used in programming language theory as well when writing
interpreters and some compilers. Algebraic effects give another way, as was
pointed already at HOPE 2017. Although a theoretical curiosity, it may have
surprising practical benefits: a new way of writing compilers, with the
incremental type-checking, with easy variable usage, leaf function analyses.
This work-in-progress report prototypes and illustrates the idea.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16450" title="Abstract">arXiv:2312.16450</a> [<a href="/pdf/2312.16450" title="Download PDF">pdf</a>, <a href="/format/2312.16450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FCDNet: Frequency-Guided Complementary Dependency Modeling for  Multivariate Time-Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Ye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+S">Shijie Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7figures, in submission to Neural Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multivariate time-series (MTS) forecasting is a challenging task in many
real-world non-stationary dynamic scenarios. In addition to intra-series
temporal signals, the inter-series dependency also plays a crucial role in
shaping future trends. How to enable the model's awareness of dependency
information has raised substantial research attention. Previous approaches have
either presupposed dependency constraints based on domain knowledge or imposed
them using real-time feature similarity. However, MTS data often exhibit both
enduring long-term static relationships and transient short-term interactions,
which mutually influence their evolving states. It is necessary to recognize
and incorporate the complementary dependencies for more accurate MTS
prediction. The frequency information in time series reflects the evolutionary
rules behind complex temporal dynamics, and different frequency components can
be used to well construct long-term and short-term interactive dependency
structures between variables. To this end, we propose FCDNet, a concise yet
effective framework for multivariate time-series forecasting. Specifically,
FCDNet overcomes the above limitations by applying two light-weight dependency
constructors to help extract long- and short-term dependency information
adaptively from multi-level frequency patterns. With the growth of input
variables, the number of trainable parameters in FCDNet only increases
linearly, which is conducive to the model's scalability and avoids
over-fitting. Additionally, adopting a frequency-based perspective can
effectively mitigate the influence of noise within MTS data, which helps
capture more genuine dependencies. The experimental results on six real-world
datasets from multiple fields show that FCDNet significantly exceeds strong
baselines, with an average improvement of 6.82% on MAE, 4.98% on RMSE, and
4.91% on MAPE.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16451" title="Abstract">arXiv:2312.16451</a> [<a href="/pdf/2312.16451" title="Download PDF">pdf</a>, <a href="/format/2312.16451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization with Vital Phase Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Ingyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wooju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Myung%2C+H">Hyun Myung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural networks have shown remarkable performance in image
classification. However, their performance significantly deteriorates with
corrupted input data. Domain generalization methods have been proposed to train
robust models against out-of-distribution data. Data augmentation in the
frequency domain is one of such approaches that enable a model to learn phase
features to establish domain-invariant representations. This approach changes
the amplitudes of the input data while preserving the phases. However, using
fixed phases leads to susceptibility to phase fluctuations because amplitudes
and phase fluctuations commonly occur in out-of-distribution. In this study, to
address this problem, we introduce an approach using finite variation of the
phases of input data rather than maintaining fixed phases. Based on the
assumption that the degree of domain-invariant features varies for each phase,
we propose a method to distinguish phases based on this degree. In addition, we
propose a method called vital phase augmentation (VIPAug) that applies the
variation to the phases differently according to the degree of domain-invariant
features of given phases. The model depends more on the vital phases that
contain more domain-invariant features for attaining robustness to amplitude
and phase fluctuations. We present experimental evaluations of our proposed
approach, which exhibited improved performance for both clean and corrupted
data. VIPAug achieved SOTA performance on the benchmark CIFAR-10 and CIFAR-100
datasets, as well as near-SOTA performance on the ImageNet-100 and ImageNet
datasets. Our code is available at https://github.com/excitedkid/vipaug.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16456" title="Abstract">arXiv:2312.16456</a> [<a href="/pdf/2312.16456" title="Download PDF">pdf</a>, <a href="/format/2312.16456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive trajectory-constrained exploration strategy for deep  reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guojian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Faguo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+N">Ning Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhiming Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 36 figures; accepted by Knowledge-Based Systems, not published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep reinforcement learning (DRL) faces significant challenges in addressing
the hard-exploration problems in tasks with sparse or deceptive rewards and
large state spaces. These challenges severely limit the practical application
of DRL. Most previous exploration methods relied on complex architectures to
estimate state novelty or introduced sensitive hyperparameters, resulting in
instability. To mitigate these issues, we propose an efficient adaptive
trajectory-constrained exploration strategy for DRL. The proposed method guides
the policy of the agent away from suboptimal solutions by leveraging incomplete
offline demonstrations as references. This approach gradually expands the
exploration scope of the agent and strives for optimality in a constrained
optimization manner. Additionally, we introduce a novel policy-gradient-based
optimization algorithm that utilizes adaptively clipped trajectory-distance
rewards for both single- and multi-agent reinforcement learning. We provide a
theoretical analysis of our method, including a deduction of the worst-case
approximation error bounds, highlighting the validity of our approach for
enhancing exploration. To evaluate the effectiveness of the proposed method, we
conducted experiments on two large 2D grid world mazes and several MuJoCo
tasks. The extensive experimental results demonstrate the significant
advantages of our method in achieving temporally extended exploration and
avoiding myopic and suboptimal behaviors in both single- and multi-agent
settings. Notably, the specific metrics and quantifiable results further
support these findings. The code used in the study is available at
\url{https://github.com/buaawgj/TACE}.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16457" title="Abstract">arXiv:2312.16457</a> [<a href="/pdf/2312.16457" title="Download PDF">pdf</a>, <a href="/format/2312.16457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> City-on-Web: Real-time Neural Rendering of Large-scale Scenes on the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiwen Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ustc3dv.github.io/City-on-Web/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">NeRF has significantly advanced 3D scene reconstruction, capturing intricate
details across various environments. Existing methods have successfully
leveraged radiance field baking to facilitate real-time rendering of small
scenes. However, when applied to large-scale scenes, these techniques encounter
significant challenges, struggling to provide a seamless real-time experience
due to limited resources in computation, memory, and bandwidth. In this paper,
we propose City-on-Web, which represents the whole scene by partitioning it
into manageable blocks, each with its own Level-of-Detail, ensuring high
fidelity, efficient memory management and fast rendering. Meanwhile, we
carefully design the training and inference process such that the final
rendering result on web is consistent with training. Thanks to our novel
representation and carefully designed training/inference process, we are the
first to achieve real-time rendering of large-scale scenes in
resource-constrained environments. Extensive experimental results demonstrate
that our method facilitates real-time rendering of large-scale scenes on a web
platform, achieving 32FPS at 1080P resolution with an RTX 3060 GPU, while
simultaneously achieving a quality that closely rivals that of state-of-the-art
methods. Project page: https://ustc3dv.github.io/City-on-Web/
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16460" title="Abstract">arXiv:2312.16460</a> [<a href="/pdf/2312.16460" title="Download PDF">pdf</a>, <a href="/ps/2312.16460" title="Download PostScript">ps</a>, <a href="/format/2312.16460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Fault Tolerance for Efficient Batch Matrix Multiplication  via an Additive Combinatorics Lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Censor-Hillel%2C+K">Keren Censor-Hillel</a>, 
<a href="/search/cs?searchtype=author&query=Machino%2C+Y">Yuka Machino</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+P">Pedro Soto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Fault tolerance is a major concern in distributed computational settings. In
the classic master-worker setting, a server (the master) needs to perform some
heavy computation which it may distribute to $m$ other machines (workers) in
order to speed up the time complexity. In this setting, it is crucial that the
computation is made robust to failed workers, in order for the master to be
able to retrieve the result of the joint computation despite failures. A prime
complexity measure is thus the \emph{recovery threshold}, which is the number
of workers that the master needs to wait for in order to derive the output.
This is the counterpart to the number of failed workers that it can tolerate.
<br />In this paper, we address the fundamental and well-studied task of matrix
multiplication. Specifically, our focus is on when the master needs to multiply
a batch of $n$ pairs of matrices. Several coding techniques have been proven
successful in reducing the recovery threshold for this task, and one approach
that is also very efficient in terms of computation time is called \emph{Rook
Codes}. The previously best known recovery threshold for batch matrix
multiplication using Rook Codes is $O(n^{\log_2{3}})=O(n^{1.585})$.
<br />Our main contribution is a lower bound proof that says that any Rook Code for
batch matrix multiplication must have a recovery threshold that is at least
$\omega(n)$. Notably, we employ techniques from Additive Combinatorics in order
to prove this, which may be of further interest. Moreover, we show a Rook Code
that achieves a recovery threshold of $n^{1+o(1)}$, establishing a near-optimal
answer to the fault tolerance of this coding scheme.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16462" title="Abstract">arXiv:2312.16462</a> [<a href="/pdf/2312.16462" title="Download PDF">pdf</a>, <a href="/format/2312.16462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-accuracy numerical methods and convergence analysis for  Schr&#xf6;dinger equation with incommensurate potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+S">Shifeng Li</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Juan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Numerical solving the Schr\"odinger equation with incommensurate potentials
presents a great challenge since its solutions could be space-filling
quasiperiodic structures without translational symmetry nor decay. In this
paper, we propose two high-accuracy numerical methods to solve the
time-dependent quasiperiodic Schr\"odinger equation. Concretely, we discretize
the spatial variables by the quasiperiodic spectral method and the projection
method, and the time variable by the second-order operator splitting method.
The corresponding convergence analysis is also presented and shows that the
proposed methods both have exponential convergence rate in space and second
order accuracy in time, respectively. Meanwhile, we analyse the computational
complexity of these numerical algorithms. One- and two-dimensional numerical
results verify these convergence conclusions, and demonstrate that the
projection method is more efficient.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16465" title="Abstract">arXiv:2312.16465</a> [<a href="/pdf/2312.16465" title="Download PDF">pdf</a>, <a href="/format/2312.16465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Contact Whole Body Force Control for Position-Controlled Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rouxel%2C+Q">Quentin Rouxel</a> (LARSEN), 
<a href="/search/cs?searchtype=author&query=Ivaldi%2C+S">Serena Ivaldi</a> (LARSEN), 
<a href="/search/cs?searchtype=author&query=Mouret%2C+J">Jean-Baptiste Mouret</a> (LARSEN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Many humanoid and multi-legged robots are controlled in positions rather than
in torques, preventing direct control of contact forces, and hampering their
ability to create multiple contacts to enhance their balance, such as placing a
hand on a wall or a handrail. This paper introduces the SEIKO (Sequential
Equilibrium Inverse Kinematic Optimization) pipeline, drawing inspiration from
flexibility models used in serial elastic actuators to indirectly control
contact forces on traditional position-controlled robots. SEIKO formulates
whole-body retargeting from Cartesian commands and admittance control using two
quadratic programs solved in real time. We validated our pipeline with
experiments on the real, full-scale humanoid robot Talos in various
multicontact scenarios, including pushing tasks, far-reaching tasks, stair
climbing, and stepping on sloped surfaces. This work opens the possibility of
stable, contact-rich behaviors while getting around many of the challenges of
torque-controlled robots. Code and videos are available at
https://hucebot.github.io/seiko_controller_website/ .
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16467" title="Abstract">arXiv:2312.16467</a> [<a href="/pdf/2312.16467" title="Download PDF">pdf</a>, <a href="/format/2312.16467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer and Alignment Network for Generalized Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+W">Wenbin An</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+F">Feng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenkai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Ping Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generalized Category Discovery is a crucial real-world task. Despite the
improved performance on known categories, current methods perform poorly on
novel categories. We attribute the poor performance to two reasons: biased
knowledge transfer between labeled and unlabeled data and noisy representation
learning on the unlabeled data. To mitigate these two issues, we propose a
Transfer and Alignment Network (TAN), which incorporates two knowledge transfer
mechanisms to calibrate the biased knowledge and two feature alignment
mechanisms to learn discriminative features. Specifically, we model different
categories with prototypes and transfer the prototypes in labeled data to
correct model bias towards known categories. On the one hand, we pull instances
with known categories in unlabeled data closer to these prototypes to form more
compact clusters and avoid boundary overlap between known and novel categories.
On the other hand, we use these prototypes to calibrate noisy prototypes
estimated from unlabeled data based on category similarities, which allows for
more accurate estimation of prototypes for novel categories that can be used as
reliable learning targets later. After knowledge transfer, we further propose
two feature alignment mechanisms to acquire both instance- and category-level
knowledge from unlabeled data by aligning instance features with both augmented
features and the calibrated prototypes, which can boost model performance on
both known and novel categories with less noise. Experiments on three benchmark
datasets show that our model outperforms SOTA methods, especially on novel
categories. Theoretical analysis is provided for an in-depth understanding of
our model in general. Our code and data are available at
https://github.com/Lackel/TAN.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16470" title="Abstract">arXiv:2312.16470</a> [<a href="/pdf/2312.16470" title="Download PDF">pdf</a>, <a href="/format/2312.16470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReSynthDetect: A Fundus Anomaly Detection Network with Reconstruction  and Synthetic Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+J">Jingqi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinji Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shiwen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+K">Kang Dang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaowei Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting anomalies in fundus images through unsupervised methods is a
challenging task due to the similarity between normal and abnormal tissues, as
well as their indistinct boundaries. The current methods have limitations in
accurately detecting subtle anomalies while avoiding false positives. To
address these challenges, we propose the ReSynthDetect network which utilizes a
reconstruction network for modeling normal images, and an anomaly generator
that produces synthetic anomalies consistent with the appearance of fundus
images. By combining the features of consistent anomaly generation and image
reconstruction, our method is suited for detecting fundus abnormalities. The
proposed approach has been extensively tested on benchmark datasets such as
EyeQ and IDRiD, demonstrating state-of-the-art performance in both image-level
and pixel-level anomaly detection. Our experiments indicate a substantial 9%
improvement in AUROC on EyeQ and a significant 17.1% improvement in AUPR on
IDRiD.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16472" title="Abstract">arXiv:2312.16472</a> [<a href="/pdf/2312.16472" title="Download PDF">pdf</a>, <a href="/format/2312.16472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Flows and the Capacity of a Discrete Memoryless Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beretta%2C+G">G. Beretta</a>, 
<a href="/search/cs?searchtype=author&query=Chiarot%2C+G">G. Chiarot</a>, 
<a href="/search/cs?searchtype=author&query=Cin%C3%A0%2C+A+E">A. E. Cin&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Pelillo%2C+M">M. Pelillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures. Submitted to IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">One of the fundamental problems of information theory, since its foundation
by Shannon in 1948, has been the computation of the capacity of a discrete
memoryless channel, a quantity expressing the maximum rate at which information
can travel through the channel. In the literature, several algorithms were
proposed to approximately compute the capacity of a discrete memoryless
channel, being an analytical solution unavailable for the general discrete
memoryless channel. This paper presents a novel approach to compute the
capacity, which is based on a continuous-time dynamical system. Such a
dynamical system can indeed be regarded as a continuous-time version of the
Blahut-Arimoto algorithm. In fact, the updating map appearing in the
Blahut-Arimoto algorithm is here obtained as a suitable discretization of the
vector flow presented, using an analogy with some game-theoretical models.
Finally, this analogy suggests a high-level hardware circuit design enabling
analog computation to estimate the capacity.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16473" title="Abstract">arXiv:2312.16473</a> [<a href="/pdf/2312.16473" title="Download PDF">pdf</a>, <a href="/ps/2312.16473" title="Download PostScript">ps</a>, <a href="/format/2312.16473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolSets: Molecular Graph Deep Sets Learning for Mixture Property  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rondinelli%2C+J+M">James M. Rondinelli</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures, 2+4 tables, working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Recent advances in machine learning (ML) have expedited materials discovery
and design. One significant challenge faced in ML for materials is the
expansive combinatorial space of potential materials formed by diverse
constituents and their flexible configurations. This complexity is particularly
evident in molecular mixtures, a frequently explored space for materials such
as battery electrolytes. Owing to the complex structures of molecules and the
sequence-independent nature of mixtures, conventional ML methods have
difficulties in modeling such systems. Here we present MolSets, a specialized
ML model for molecular mixtures. Representing individual molecules as graphs
and their mixture as a set, MolSets leverages a graph neural network and the
deep sets architecture to extract information at the molecule level and
aggregate it at the mixture level, thus addressing local complexity while
retaining global flexibility. We demonstrate the efficacy of MolSets in
predicting the conductivity of lithium battery electrolytes and highlight its
benefits in virtual screening of the combinatorial chemical space.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16475" title="Abstract">arXiv:2312.16475</a> [<a href="/pdf/2312.16475" title="Download PDF">pdf</a>, <a href="/format/2312.16475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Continual Learning via Knowledge Fusion: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data privacy and silos are nontrivial and greatly challenging in many
real-world applications. Federated learning is a decentralized approach to
training models across multiple local clients without the exchange of raw data
from client devices to global servers. However, existing works focus on a
static data environment and ignore continual learning from streaming data with
incremental tasks. Federated Continual Learning (FCL) is an emerging paradigm
to address model learning in both federated and continual learning
environments. The key objective of FCL is to fuse heterogeneous knowledge from
different clients and retain knowledge of previous tasks while learning on new
ones. In this work, we delineate federated learning and continual learning
first and then discuss their integration, i.e., FCL, and particular FCL via
knowledge fusion. In summary, our motivations are four-fold: we (1) raise a
fundamental problem called ''spatial-temporal catastrophic forgetting'' and
evaluate its impact on the performance using a well-known method called
federated averaging (FedAvg), (2) integrate most of the existing FCL methods
into two generic frameworks, namely synchronous FCL and asynchronous FCL, (3)
categorize a large number of methods according to the mechanism involved in
knowledge fusion, and finally (4) showcase an outlook on the future work of
FCL.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16476" title="Abstract">arXiv:2312.16476</a> [<a href="/pdf/2312.16476" title="Download PDF">pdf</a>, <a href="/format/2312.16476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVGDreamer: Text Guided SVG Generation with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Ximing Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haitao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, text-guided scalable vector graphics (SVGs) synthesis has shown
promise in domains such as iconography and sketch. However, existing
text-to-SVG generation methods lack editability and struggle with visual
quality and result diversity. To address these limitations, we propose a novel
text-guided vector graphics synthesis method called SVGDreamer. SVGDreamer
incorporates a semantic-driven image vectorization (SIVE) process that enables
the decomposition of synthesis into foreground objects and background, thereby
enhancing editability. Specifically, the SIVE process introduce attention-based
primitive control and an attention-mask loss function for effective control and
manipulation of individual elements. Additionally, we propose a Vectorized
Particle-based Score Distillation (VPSD) approach to tackle the challenges of
color over-saturation, vector primitives over-smoothing, and limited result
diversity in existing text-to-SVG generation methods. Furthermore, on the basis
of VPSD, we introduce Reward Feedback Learning (ReFL) to accelerate VPSD
convergence and improve aesthetic appeal. Extensive experiments have been
conducted to validate the effectiveness of SVGDreamer, demonstrating its
superiority over baseline methods in terms of editability, visual quality, and
diversity.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16477" title="Abstract">arXiv:2312.16477</a> [<a href="/pdf/2312.16477" title="Download PDF">pdf</a>, <a href="/format/2312.16477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lixiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qingzhe Cui</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuanyan Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13pages, 8 figuers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, the results of view-based 3D shape recognition methods have
saturated, and models with excellent performance cannot be deployed on
memory-limited devices due to their huge size of parameters. To address this
problem, we introduce a compression method based on knowledge distillation for
this field, which largely reduces the number of parameters while preserving
model performance as much as possible. Specifically, to enhance the
capabilities of smaller models, we design a high-performing large model called
Group Multi-view Vision Transformer (GMViT). In GMViT, the view-level ViT first
establishes relationships between view-level features. Additionally, to capture
deeper features, we employ the grouping module to enhance view-level features
into group-level features. Finally, the group-level ViT aggregates group-level
features into complete, well-formed 3D shape descriptors. Notably, in both
ViTs, we introduce spatial encoding of camera coordinates as innovative
position embeddings. Furthermore, we propose two compressed versions based on
GMViT, namely GMViT-simple and GMViT-mini. To enhance the training
effectiveness of the small models, we introduce a knowledge distillation method
throughout the GMViT process, where the key outputs of each GMViT component
serve as distillation targets. Extensive experiments demonstrate the efficacy
of the proposed method. The large model GMViT achieves excellent 3D
classification and retrieval results on the benchmark datasets ModelNet,
ShapeNetCore55, and MCB. The smaller models, GMViT-simple and GMViT-mini,
reduce the parameter size by 8 and 17.6 times, respectively, and improve shape
recognition speed by 1.5 times on average, while preserving at least 90% of the
classification and retrieval performance.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16478" title="Abstract">arXiv:2312.16478</a> [<a href="/pdf/2312.16478" title="Download PDF">pdf</a>, <a href="/format/2312.16478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy Correspondence Learning with Self-Reinforcing Errors Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+Z">Zhuohang Dang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chengyou Jia</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Cross-modal retrieval relies on well-matched large-scale datasets that are
laborious in practice. Recently, to alleviate expensive data collection,
co-occurring pairs from the Internet are automatically harvested for training.
However, it inevitably includes mismatched pairs, \ie, noisy correspondences,
undermining supervision reliability and degrading performance. Current methods
leverage deep neural networks' memorization effect to address noisy
correspondences, which overconfidently focus on \emph{similarity-guided
training with hard negatives} and suffer from self-reinforcing errors. In light
of above, we introduce a novel noisy correspondence learning framework, namely
\textbf{S}elf-\textbf{R}einforcing \textbf{E}rrors \textbf{M}itigation (SREM).
Specifically, by viewing sample matching as classification tasks within the
batch, we generate classification logits for the given sample. Instead of a
single similarity score, we refine sample filtration through energy uncertainty
and estimate model's sensitivity of selected clean samples using swapped
classification entropy, in view of the overall prediction distribution.
Additionally, we propose cross-modal biased complementary learning to leverage
negative matches overlooked in hard-negative training, further improving model
optimization stability and curbing self-reinforcing errors. Extensive
experiments on challenging benchmarks affirm the efficacy and efficiency of
SREM.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16480" title="Abstract">arXiv:2312.16480</a> [<a href="/pdf/2312.16480" title="Download PDF">pdf</a>, <a href="/format/2312.16480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permissive-Nominal Logic (journal version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>, 
<a href="/search/cs?searchtype=author&query=Gabbay%2C+M+J">Murdoch J. Gabbay</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Computational Logic, Volume 13, Number 3,
  Article 20, Publication date: August 2012
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Permissive-Nominal Logic (PNL) is an extension of first-order predicate logic
in which term-formers can bind names in their arguments. This allows for direct
axiomatisations with binders, such as of the lambda-binder of the
lambda-calculus or the forall-binder of first-order logic. It also allows us to
finitely axiomatise arithmetic, and similarly to axiomatise 'nominal'
datatypes-with-binding. Just like first- and higher-order logic, equality
reasoning is not necessary to alpha-rename. This gives PNL much of the
expressive power of higher-order logic, but models and derivations of PNL are
first-order in character, and the logic seems to strike a good balance between
expressivity and simplicity.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16483" title="Abstract">arXiv:2312.16483</a> [<a href="/pdf/2312.16483" title="Download PDF">pdf</a>, <a href="/ps/2312.16483" title="Download PostScript">ps</a>, <a href="/format/2312.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressivity and Approximation Properties of Deep Neural Networks with  ReLU$^k$ Activation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Juncai He</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+T">Tong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinchao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we investigate the expressivity and approximation properties
of deep neural networks employing the ReLU$^k$ activation function for $k \geq
2$. Although deep ReLU networks can approximate polynomials effectively, deep
ReLU$^k$ networks have the capability to represent higher-degree polynomials
precisely. Our initial contribution is a comprehensive, constructive proof for
polynomial representation using deep ReLU$^k$ networks. This allows us to
establish an upper bound on both the size and count of network parameters.
Consequently, we are able to demonstrate a suboptimal approximation rate for
functions from Sobolev spaces as well as for analytic functions. Additionally,
through an exploration of the representation power of deep ReLU$^k$ networks
for shallow networks, we reveal that deep ReLU$^k$ networks can approximate
functions from a range of variation spaces, extending beyond those generated
solely by the ReLU$^k$ activation function. This finding demonstrates the
adaptability of deep ReLU$^k$ networks in approximating functions within
various variation spaces.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16485" title="Abstract">arXiv:2312.16485</a> [<a href="/pdf/2312.16485" title="Download PDF">pdf</a>, <a href="/format/2312.16485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlocal problems with anti-symmetric and anti-reflective boundary  conditions: a computational analysis and numerical comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sousa%2C+E">Erc&#xed;lia Sousa</a>, 
<a href="/search/math?searchtype=author&query=Tablino-Possio%2C+C">Cristina Tablino-Possio</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+R">Rolf Krause</a>, 
<a href="/search/math?searchtype=author&query=Serra-Capizzano%2C+S">Stefano Serra-Capizzano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In recent literature, for modeling reasons, fractional differential problems
have been considered equipped with anti-symmetric boundary conditions. Twenty
years ago the anti-reflective boundary conditions were introduced in a context
of signal processing and imaging for increasing the quality of the
reconstruction of a blurred signal/image contaminated by noise and for reducing
the overall complexity to that of few fast sine transforms i.e. to $O(N\log N)$
real arithmetic operations, where $N$ is the number of pixels. Here we consider
the anti-symmetric boundary conditions and we introduce the anti-reflective
boundary conditions in the context of nonlocal problems of fractional
differential type. In the latter context, we study both types of boundary
conditions, which in reality are similar in the essentials, from the
perspective of computational efficiency, by considering nontruncated and
truncated versions. Several numerical tests, tables, and visualizations are
provided and critically discussed.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16486" title="Abstract">arXiv:2312.16486</a> [<a href="/pdf/2312.16486" title="Download PDF">pdf</a>, <a href="/format/2312.16486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanGu-Draw: Advancing Resource-Efficient Text-to-Image Synthesis with  Time-Decoupled Training and Reusable Coop-Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guansong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanfan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+M">Minzhe Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: $\href{<a href="https://pangu-draw.github.io">this https URL</a>}{this~https~URL}$
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current large-scale diffusion models represent a giant leap forward in
conditional image synthesis, capable of interpreting diverse cues like text,
human poses, and edges. However, their reliance on substantial computational
resources and extensive data collection remains a bottleneck. On the other
hand, the integration of existing diffusion models, each specialized for
different controls and operating in unique latent spaces, poses a challenge due
to incompatible image resolutions and latent space embedding structures,
hindering their joint use. Addressing these constraints, we present
"PanGu-Draw", a novel latent diffusion model designed for resource-efficient
text-to-image synthesis that adeptly accommodates multiple control signals. We
first propose a resource-efficient Time-Decoupling Training Strategy, which
splits the monolithic text-to-image model into structure and texture
generators. Each generator is trained using a regimen that maximizes data
utilization and computational efficiency, cutting data preparation by 48% and
reducing training resources by 51%. Secondly, we introduce "Coop-Diffusion", an
algorithm that enables the cooperative use of various pre-trained diffusion
models with different latent spaces and predefined resolutions within a unified
denoising process. This allows for multi-control image synthesis at arbitrary
resolutions without the necessity for additional data or retraining. Empirical
validations of Pangu-Draw show its exceptional prowess in text-to-image and
multi-control image generation, suggesting a promising direction for future
model training efficiencies and generation versatility. The largest 5B T2I
PanGu-Draw model is released on the Ascend platform. Project page:
https://pangu-draw.github.io
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16487" title="Abstract">arXiv:2312.16487</a> [<a href="/pdf/2312.16487" title="Download PDF">pdf</a>, <a href="/format/2312.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nominal semantics for predicate logic: algebras, substitution,  quantifiers, and limits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>, 
<a href="/search/cs?searchtype=author&query=Gabbay%2C+M+J">Murdoch J. Gabbay</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 9th Italian Convention on Computational Logic
  (CILC 2012), pages 104-118, CEUR Workshop Proceedings Volume 857, ISSN
  1613-0073 (urn:nbn:de:0074-857-8).
  https://nbn-resolving.org/urn:nbn:de:0074-857-8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We define a model of predicate logic in which every term and predicate, open
or closed, has an absolute denotation independently of a valuation of the
variables. For each variable a, the domain of the model contains an element
[[a]] which is the denotation of the term a (which is also a variable symbol).
Similarly, the algebra interpreting predicates in the model directly interprets
open predicates. Because of this models must also incorporate notions of
substitution and quantification. These notions are axiomatic, and need not be
applied only to sets of syntax. We prove soundness and show how every
'ordinary' model (i.e. model based on sets and valuations) can be translated to
one of our nominal models, and thus also prove completeness.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16488" title="Abstract">arXiv:2312.16488</a> [<a href="/pdf/2312.16488" title="Download PDF">pdf</a>, <a href="/format/2312.16488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source Code is a Graph, Not a Sequence: A Cross-Lingual Perspective on  Code Clone Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahaman%2C+M+A">Mohammed Ataaur Rahaman</a>, 
<a href="/search/cs?searchtype=author&query=Ive%2C+J">Julia Ive</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Source code clone detection is the task of finding code fragments that have
the same or similar functionality, but may differ in syntax or structure. This
task is important for software maintenance, reuse, and quality assurance (Roy
et al. 2009). However, code clone detection is challenging, as source code can
be written in different languages, domains, and styles. In this paper, we argue
that source code is inherently a graph, not a sequence, and that graph-based
methods are more suitable for code clone detection than sequence-based methods.
We compare the performance of two state-of-the-art models: CodeBERT (Feng et
al. 2020), a sequence-based model, and CodeGraph (Yu et al. 2023), a
graph-based model, on two benchmark data-sets: BCB (Svajlenko et al. 2014) and
PoolC (PoolC no date). We show that CodeGraph outperforms CodeBERT on both
data-sets, especially on cross-lingual code clones. To the best of our
knowledge, this is the first work to demonstrate the superiority of graph-based
methods over sequence-based methods on cross-lingual code clone detection.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16489" title="Abstract">arXiv:2312.16489</a> [<a href="/pdf/2312.16489" title="Download PDF">pdf</a>, <a href="/ps/2312.16489" title="Download PostScript">ps</a>, <a href="/format/2312.16489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best-of-Both-Worlds Linear Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+M">Masahiro Kato</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+S">Shinji Ito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Econometrics (econ.EM); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">This study investigates the problem of $K$-armed linear contextual bandits,
an instance of the multi-armed bandit problem, under an adversarial corruption.
At each round, a decision-maker observes an independent and identically
distributed context and then selects an arm based on the context and past
observations. After selecting an arm, the decision-maker incurs a loss
corresponding to the selected arm. The decision-maker aims to minimize the
cumulative loss over the trial. The goal of this study is to develop a strategy
that is effective in both stochastic and adversarial environments, with
theoretical guarantees. We first formulate the problem by introducing a novel
setting of bandits with adversarial corruption, referred to as the contextual
adversarial regime with a self-bounding constraint. We assume linear models for
the relationship between the loss and the context. Then, we propose a strategy
that extends the RealLinExp3 by Neu &amp; Olkhovskaya (2020) and the
Follow-The-Regularized-Leader (FTRL). The regret of our proposed algorithm is
shown to be upper-bounded by $O\left(\min\left\{\frac{(\log(T))^3}{\Delta_{*}}
+ \sqrt{\frac{C(\log(T))^3}{\Delta_{*}}},\ \
\sqrt{T}(\log(T))^2\right\}\right)$, where $T \in\mathbb{N}$ is the number of
rounds, $\Delta_{*} &gt; 0$ is the constant minimum gap between the best and
suboptimal arms for any context, and $C\in[0, T] $ is an adversarial corruption
parameter. This regret upper bound implies
$O\left(\frac{(\log(T))^3}{\Delta_{*}}\right)$ in a stochastic environment and
by $O\left( \sqrt{T}(\log(T))^2\right)$ in an adversarial environment. We refer
to our strategy as the Best-of-Both-Worlds (BoBW) RealFTRL, due to its
theoretical guarantees in both stochastic and adversarial regimes.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16490" title="Abstract">arXiv:2312.16490</a> [<a href="/pdf/2312.16490" title="Download PDF">pdf</a>, <a href="/format/2312.16490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding News Creation Intents: Frame, Dataset, and Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danding Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Q">Qiang Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Juan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Silong Su</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Beizhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siyuan Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">As the disruptive changes in the media economy and the proliferation of
alternative news media outlets, news intent has progressively deviated from
ethical standards that serve the public interest. News intent refers to the
purpose or intention behind the creation of a news article. While the
significance of research on news intent has been widely acknowledged, the
absence of a systematic news intent understanding framework hinders further
exploration of news intent and its downstream applications. To bridge this gap,
we propose News INTent (NINT) frame, the first component-aware formalism for
understanding the news creation intent based on research in philosophy,
psychology, and cognitive science. Within this frame, we define the news intent
identification task and provide a benchmark dataset with fine-grained labels
along with an efficient benchmark method. Experiments demonstrate that NINT is
beneficial in both the intent identification task and downstream tasks that
demand a profound understanding of news. This work marks a foundational step
towards a more systematic exploration of news creation intents.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16496" title="Abstract">arXiv:2312.16496</a> [<a href="/pdf/2312.16496" title="Download PDF">pdf</a>, <a href="/format/2312.16496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rational Economic Behaviours in the Bitcoin Lightning Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carotti%2C+A">Andrea Carotti</a>, 
<a href="/search/cs?searchtype=author&query=Sguanci%2C+C">Cosimo Sguanci</a>, 
<a href="/search/cs?searchtype=author&query=Sidiropoulos%2C+A">Anastasios Sidiropoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The Bitcoin Lightning Network (LN) is designed to improve the scalability of
blockchain systems by using off-chain payment paths to settle transactions in a
faster, cheaper, and more private manner. This work aims to empirically study
LN's fee revenue for network participants. Under realistic assumptions on
payment amounts, routing algorithms and traffic distribution, we analyze the
economic returns of the network's largest routing nodes which currently hold
the network together, and assess whether the centralizing tendency is
incentive-compatible from an economic viewpoint. Moreover, since recent
literature has proved that participation is economically irrational for the
majority of large nodes, we evaluate the long-term impact on the network
topology when participants start behaving rationally.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16497" title="Abstract">arXiv:2312.16497</a> [<a href="/pdf/2312.16497" title="Download PDF">pdf</a>, <a href="/ps/2312.16497" title="Download PostScript">ps</a>, <a href="/format/2312.16497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobility and Cost Aware Inference Accelerating Algorithm for Edge  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ning Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+k">kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenchao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 16 figures. arXiv admin note: substantial text overlap with <a href="/abs/2312.15850">arXiv:2312.15850</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The edge intelligence (EI) has been widely applied recently. Spliting the
model between device, edge server, and cloud can improve the performance of EI
greatly. The model segmentation without user mobility has been investigated
deeply by previous works. However, in most use cases of EI, the end devices are
mobile. Only a few works have been carried out on this aspect. These works
still have many issues, such as ignoring the energy consumption of mobile
device, inappropriate network assumption, and low effectiveness on adaptiving
user mobility, etc. Therefore, for addressing the disadvantages of model
segmentation and resource allocation in previous works, we propose mobility and
cost aware model segmentation and resource allocation algorithm for
accelerating the inference at edge (MCSA). Specfically, in the scenario without
user mobility, the loop interation gradient descent (Li-GD) algorithm is
provided. When the mobile user has a large model inference task needs to be
calculated, it will take the energy consumption of mobile user, the
communication and computing resource renting cost, and the inference delay into
account to find the optimal model segmentation and resource allocation
strategy. In the scenario with user mobility, the mobiity aware Li-GD (MLi-GD)
algorithm is proposed to calculate the optimal strategy. Then, the properties
of the proposed algorithms are investigated, including convergence, complexity,
and approximation ratio. The experimental results demonstrate the effectiveness
of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16498" title="Abstract">arXiv:2312.16498</a> [<a href="/pdf/2312.16498" title="Download PDF">pdf</a>, <a href="/format/2312.16498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Non-Uniform Low-Light Image Enhancement Method with Multi-Scale  Attention Transformer and Luminance Consistency Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baofeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+F">Feng Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhihang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiansheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chun Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Low-light image enhancement aims to improve the perception of images
collected in dim environments and provide high-quality data support for image
recognition tasks. When dealing with photos captured under non-uniform
illumination, existing methods cannot adaptively extract the differentiated
luminance information, which will easily cause over-exposure and
under-exposure. From the perspective of unsupervised learning, we propose a
multi-scale attention Transformer named MSATr, which sufficiently extracts
local and global features for light balance to improve the visual quality.
Specifically, we present a multi-scale window division scheme, which uses
exponential sequences to adjust the window size of each layer. Within
different-sized windows, the self-attention computation can be refined,
ensuring the pixel-level feature processing capability of the model. For
feature interaction across windows, a global transformer branch is constructed
to provide comprehensive brightness perception and alleviate exposure problems.
Furthermore, we propose a loop training strategy, using the diverse images
generated by weighted mixing and a luminance consistency loss to improve the
model's generalization ability effectively. Extensive experiments on several
benchmark datasets quantitatively and qualitatively prove that our MSATr is
superior to state-of-the-art low-light image enhancement methods, and the
enhanced images have more natural brightness and outstanding details. The code
is released at https://github.com/fang001021/MSATr.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16499" title="Abstract">arXiv:2312.16499</a> [<a href="/pdf/2312.16499" title="Download PDF">pdf</a>, <a href="/format/2312.16499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camera calibration for the surround-view system: a benchmark and dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">L Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">C Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">S Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">S Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Y Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Surround-view system (SVS) is widely used in the Advanced Driver Assistance
System (ADAS). SVS uses four fisheye lenses to monitor real-time scenes around
the vehicle. However, accurate intrinsic and extrinsic parameter estimation is
required for the proper functioning of the system. At present, the intrinsic
calibration can be pipeline by utilizing checkerboard algorithm, while
extrinsic calibration is still immature. Therefore, we proposed a specific
calibration pipeline to estimate extrinsic parameters robustly. This scheme
takes a driving sequence of four cameras as input. It firstly utilizes lane
line to roughly estimate each camera pose. Considering the environmental
condition differences in each camera, we separately select strategies from two
methods to accurately estimate the extrinsic parameters. To achieve accurate
estimates for both front and rear camera, we proposed a method that mutually
iterating line detection and pose estimation. As for bilateral camera, we
iteratively adjust the camera pose and position by minimizing texture and edge
error between ground projections of adjacent cameras. After estimating the
extrinsic parameters, the surround-view image can be synthesized by
homography-based transformation. The proposed pipeline can robustly estimate
the four SVS camera extrinsic parameters in real driving environments. In
addition, to evaluate the proposed scheme, we build a surround-view fisheye
dataset, which contains 40 videos with 32,000 frames, acquired from different
real traffic scenarios. All the frames in each video are manually labeled with
lane annotation, with its GT extrinsic parameters. Moreover, this surround-view
dataset could be used by other researchers to evaluate their performance. The
dataset will be available soon.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16501" title="Abstract">arXiv:2312.16501</a> [<a href="/pdf/2312.16501" title="Download PDF">pdf</a>, <a href="/format/2312.16501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inkjet-Printed High-Yield, Reconfigurable, and Recyclable Memristors on  Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingfei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zesheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Sibghah Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Saptarsi Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Macadam%2C+N">Nasiruddin Macadam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Binghan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+G">Guolin Yun</a>, 
<a href="/search/cs?searchtype=author&query=Wilk%2C+K">Kasia Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+F">Feng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Fairclough%2C+S">Simon Fairclough</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Oliver%2C+R">Rachel Oliver</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+T">Tawfique Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Reconfigurable memristors featuring neural and synaptic functions hold great
potential for neuromorphic circuits by simplifying system architecture, cutting
power consumption, and boosting computational efficiency. Their additive
manufacturing on sustainable substrates offers unique advantages for future
electronics, including low environmental impact. Here, exploiting
structure-property relationship of MoS2 nanoflake-based resistive layer, we
present paper-based, inkjet-printed, reconfigurable memristors. With &gt;90% yield
from a 16x65 device array, our memristors demonstrate robust resistive
switching, with $&gt;10^5$ ON-OFF ratio and &lt;0.5 V operation in non-volatile
state. Through modulation of compliance current, the devices transition into
volatile state, with only 50 pW switching power consumption, rivalling
state-of-the-art metal oxide-based counterparts. We show device recyclability
and stable, reconfigurable operation following disassembly, material collection
and re-fabrication. We further demonstrate synaptic plasticity and neuronal
leaky integrate-and-fire functionality, with disposable applications in smart
packaging and simulated medical image diagnostics. Our work shows a sustainable
pathway towards printable, high-yield, reconfigurable neuromorphic devices,
with minimal environmental footprint.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16502" title="Abstract">arXiv:2312.16502</a> [<a href="/pdf/2312.16502" title="Download PDF">pdf</a>, <a href="/format/2312.16502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bezier-based Regression Feature Descriptor for Deformable Linear Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangqing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, a feature extraction approach for the deformable linear object
is presented, which uses a Bezier curve to represent the original geometric
shape. The proposed extraction strategy is combined with a parameterization
technique, the goal is to compute the regression features from the
visual-feedback RGB image, and finally obtain the efficient shape feature in
the low-dimensional latent space. Existing works of literature often fail to
capture the complex characteristics in a unified framework. They also struggle
in scenarios where only local shape descriptors are used to guide the robot to
complete the manipulation. To address these challenges, we propose a feature
extraction technique using a parameterization approach to generate the
regression features, which leverages the power of the Bezier curve and linear
regression. The proposed extraction method effectively captures topological
features and node characteristics, making it well-suited for the deformation
object manipulation task. Large mount of simulations are conducted to evaluate
the presented method. Our results demonstrate that the proposed method
outperforms existing methods in terms of prediction accuracy, robustness, and
computational efficiency. Furthermore, our approach enables the extraction of
meaningful insights from the predicted links, thereby contributing to a better
understanding of the shape of the deformable linear objects. Overall, this work
represents a significant step forward in the use of Bezier curve for shape
representation.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16503" title="Abstract">arXiv:2312.16503</a> [<a href="/pdf/2312.16503" title="Download PDF">pdf</a>, <a href="/format/2312.16503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Enhanced Reservoir Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6ster%2C+F">Felix K&#xf6;ster</a>, 
<a href="/search/cs?searchtype=author&query=Kanno%2C+K">Kazutaka Kanno</a>, 
<a href="/search/cs?searchtype=author&query=Ohkubo%2C+J">Jun Ohkubo</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+A">Atsushi Uchida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Photonic reservoir computing has been recently utilized in time series
forecasting as the need for hardware implementations to accelerate these
predictions has increased. Forecasting chaotic time series remains a
significant challenge, an area where the conventional reservoir computing
framework encounters limitations of prediction accuracy. We introduce an
attention mechanism to the reservoir computing model in the output stage. This
attention layer is designed to prioritize distinct features and temporal
sequences, thereby substantially enhancing the forecasting accuracy. Our
results show that a photonic reservoir computer enhanced with the attention
mechanism exhibits improved forecasting capabilities for smaller reservoirs.
These advancements highlight the transformative possibilities of reservoir
computing for practical applications where accurate forecasting of chaotic time
series is crucial.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16505" title="Abstract">arXiv:2312.16505</a> [<a href="/pdf/2312.16505" title="Download PDF">pdf</a>, <a href="/ps/2312.16505" title="Download PostScript">ps</a>, <a href="/format/2312.16505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous iterations of HSS method for non-Hermitian linear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gbikpi-Benissan%2C+G">Guillaume Gbikpi-Benissan</a>, 
<a href="/search/math?searchtype=author&query=Zou%2C+Q">Qinmeng Zou</a>, 
<a href="/search/math?searchtype=author&query=Magoul%C3%A8s%2C+F">Fr&#xe9;d&#xe9;ric Magoul&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">A general asynchronous alternating iterative model is designed, for which
convergence is theoretically ensured both under classical spectral radius bound
and, then, for a classical class of matrix splittings for $\mathsf H$-matrices.
The computational model can be thought of as a two-stage alternating iterative
method, which well suits to the well-known Hermitian and skew-Hermitian
splitting (HSS) approach, with the particularity here of considering only one
inner iteration. Experimental parallel performance comparison is conducted
between the generalized minimal residual (GMRES) algorithm, the standard HSS
and our asynchronous variant, on both real and complex non-Hermitian linear
systems respectively arising from convection-diffusion and structural dynamics
problems. A significant gain on execution time is observed in both cases.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16507" title="Abstract">arXiv:2312.16507</a> [<a href="/pdf/2312.16507" title="Download PDF">pdf</a>, <a href="/format/2312.16507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Methodical Discovery and Handling of Hidden Assumptions in  Complex Systems and Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harel%2C+D">David Harel</a>, 
<a href="/search/cs?searchtype=author&query=A%C3%9Fmann%2C+U">Uwe A&#xdf;mann</a>, 
<a href="/search/cs?searchtype=author&query=Fournier%2C+F">Fabiana Fournier</a>, 
<a href="/search/cs?searchtype=author&query=Limonad%2C+L">Lior Limonad</a>, 
<a href="/search/cs?searchtype=author&query=Marron%2C+A">Assaf Marron</a>, 
<a href="/search/cs?searchtype=author&query=Szekely%2C+S">Smadar Szekely</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Methodologies for development of complex systems and models include external
reviews by domain and technology experts. Among others, such reviews can
uncover undocumented built-in assumptions that may be critical for correct and
safe operation or constrain applicability. Since such assumptions may still
escape human-centered processes like reviews, agile development, and risk
analyses, here, we contribute toward making this process more methodical and
automatable. We first present a blueprint for a taxonomy and formalization of
the problem. We then show that a variety of digital artifacts of the system or
model can be automatically checked against extensive reference knowledge. Since
mimicking the breadth and depth of knowledge and skills of experts may appear
unattainable, we illustrate the basic feasibility of automation with
rudimentary experiments using OpenAI's ChatGPT. We believe that systematic
handling of this aspect of system engineering can contribute significantly to
the quality and safety of complex systems and models, and to the efficiency of
development projects. We dedicate this work to Werner Damm, whose contributions
to modeling and model-based development, in industry and academia, with a
special focus on safety, helped establish a solid foundation to our discipline
and to the work of many scientists and professionals, including, naturally, the
approaches and techniques described here.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16508" title="Abstract">arXiv:2312.16508</a> [<a href="/pdf/2312.16508" title="Download PDF">pdf</a>, <a href="/format/2312.16508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilayer control of synchronization and cascading failures in power  grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Olmi%2C+S">Simona Olmi</a>, 
<a href="/search/eess?searchtype=author&query=Gambuzza%2C+L+V">Lucia Valentina Gambuzza</a>, 
<a href="/search/eess?searchtype=author&query=Frasca%2C+M">Mattia Frasca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Adaptation and Self-Organizing Systems (nlin.AO); Classical Physics (physics.class-ph)

</div>
<p class="mathjax">In this work, we propose a control scheme for power grids subject to large
perturbations that cause the failure of a node of the grid. Under such
circumstances, the system may lose synchrony and, in addition, a cascade of
line failures can be triggered as an effect of the flow redistribution that
activates the protection mechanisms equipped on each line of the grid. To
devise a control action for addressing this problem, we adopt a multi-layer
network-based description of the power grid that incorporates an overflow
condition to model the possibility of cascading failures. The two other layers
of the structure are devoted to the control, one implements the distributed
proportional control law, and the other the integral control law. To exemplify
the application of our model, we study the Italian high-voltage power grid for
different parameters and topologies of the control layers.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16510" title="Abstract">arXiv:2312.16510</a> [<a href="/pdf/2312.16510" title="Download PDF">pdf</a>, <a href="/ps/2312.16510" title="Download PostScript">ps</a>, <a href="/format/2312.16510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure and Optimization of Parameters for Neural Network Controllers  in Automatic Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feofilov%2C+S">Sergey Feofilov</a>, 
<a href="/search/cs?searchtype=author&query=Khapkin%2C+D">Dmitry Khapkin</a>, 
<a href="/search/cs?searchtype=author&query=Kozyr%2C+A">Andrey Kozyr</a>, 
<a href="/search/cs?searchtype=author&query=Heiss%2C+E">Eduard Heiss</a>, 
<a href="/search/cs?searchtype=author&query=Efromeev%2C+A">Andrey Efromeev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages with 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The article outlines the methodology of structural and parametric synthesis
of neural network controllers for controlling objects with limiters under
incomplete information about the controlled object. Artificial neural networks
are used to create controllers that are sequentially integrated into a control
system with control objects. Reinforcement learning and pre-building a neural
network imitator of the control object are used to synthesize the neural
network controller. This approach is particularly effective when classical
control system synthesis methods are not applicable due to significant
nonlinearity and the difficulty in forming a mathematical model of the control
object with the required accuracy. The proposed methods expand the class of
technical systems for which direct synthesis of near-optimal control laws is
possible. The robustness, adaptability and technical feasibility of neural
network controllers make them interesting for practical applications. The main
attention in the article is paid to the choice of neural network structure in
the imitator and controller, formation of training samples taking into account
the limitations of the control object.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16511" title="Abstract">arXiv:2312.16511</a> [<a href="/pdf/2312.16511" title="Download PDF">pdf</a>, <a href="/format/2312.16511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S2M: Converting Single-Turn to Multi-Turn Datasets for Conversational  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baokui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yicheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Teng Xu</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+S">Siye liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Supplying data augmentation to conversational question answering (CQA) can
effectively improve model performance. However, there is less improvement from
single-turn datasets in CQA due to the distribution gap between single-turn and
multi-turn datasets. On the other hand, while numerous single-turn datasets are
available, we have not utilized them effectively. To solve this problem, we
propose a novel method to convert single-turn datasets to multi-turn datasets.
The proposed method consists of three parts, namely, a QA pair Generator, a QA
pair Reassembler, and a question Rewriter. Given a sample consisting of context
and single-turn QA pairs, the Generator obtains candidate QA pairs and a
knowledge graph based on the context. The Reassembler utilizes the knowledge
graph to get sequential QA pairs, and the Rewriter rewrites questions from a
conversational perspective to obtain a multi-turn dataset S2M. Our experiments
show that our method can synthesize effective training resources for CQA.
Notably, S2M ranks 1st place on the QuAC leaderboard at the time of submission
(Aug 24th, 2022).
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16513" title="Abstract">arXiv:2312.16513</a> [<a href="/pdf/2312.16513" title="Download PDF">pdf</a>, <a href="/format/2312.16513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It Is Time To Steer: A Scalable Framework for Analysis-driven Attack  Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palma%2C+A">Alessandro Palma</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+M">Marco Angelini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In modern computer networks where sophisticated cyber attacks occur daily, a
timely cyber risk assessment becomes paramount. Attack Graph (AG) represents
the best-suited solution to model and analyze multi-step attacks on computer
networks, although they suffer from poor scalability due to their combinatorial
complexity. This paper introduces an analysis-driven framework for AG
generation. It enables real-time attack path analysis before the completion of
the AG generation with a quantifiable statistical significance. We further
accelerate the AG generation by steering it with the analysis query and
supporting a novel workflow in which the analyst can query the system anytime.
To show the capabilities of the proposed framework, we perform an extensive
quantitative validation and we present a realistic case study on networks of
unprecedented size. It demonstrates the advantages of our approach in terms of
scalability and fitting to common attack path analyses.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16516" title="Abstract">arXiv:2312.16516</a> [<a href="/pdf/2312.16516" title="Download PDF">pdf</a>, <a href="/format/2312.16516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConstScene: Dataset and Model for Advancing Robust Semantic Segmentation  in Construction Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salimi%2C+M">Maghsood Salimi</a>, 
<a href="/search/cs?searchtype=author&query=Loni%2C+M">Mohammad Loni</a>, 
<a href="/search/cs?searchtype=author&query=Afshar%2C+S">Sara Afshar</a>, 
<a href="/search/cs?searchtype=author&query=Sirjani%2C+M">Marjan Sirjani</a>, 
<a href="/search/cs?searchtype=author&query=Cicchetti%2C+A">Antonio Cicchetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The increasing demand for autonomous machines in construction environments
necessitates the development of robust object detection algorithms that can
perform effectively across various weather and environmental conditions. This
paper introduces a new semantic segmentation dataset specifically tailored for
construction sites, taking into account the diverse challenges posed by adverse
weather and environmental conditions. The dataset is designed to enhance the
training and evaluation of object detection models, fostering their
adaptability and reliability in real-world construction applications. Our
dataset comprises annotated images captured under a wide range of different
weather conditions, including but not limited to sunny days, rainy periods,
foggy atmospheres, and low-light situations. Additionally, environmental
factors such as the existence of dirt/mud on the camera lens are integrated
into the dataset through actual captures and synthetic generation to simulate
the complex conditions prevalent in construction sites. We also generate
synthetic images of the annotations including precise semantic segmentation
masks for various objects commonly found in construction environments, such as
wheel loader machines, personnel, cars, and structural elements. To demonstrate
the dataset's utility, we evaluate state-of-the-art object detection algorithms
on our proposed benchmark. The results highlight the dataset's success in
adversarial training models across diverse conditions, showcasing its efficacy
compared to existing datasets that lack such environmental variability.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16520" title="Abstract">arXiv:2312.16520</a> [<a href="/pdf/2312.16520" title="Download PDF">pdf</a>, <a href="/format/2312.16520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Diagnosability Analysis of Switched and Modular Battery Packs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hashemniya%2C+F">Fatemeh Hashemniya</a>, 
<a href="/search/eess?searchtype=author&query=Balachandran%2C+A">Arvind Balachandran</a>, 
<a href="/search/eess?searchtype=author&query=Frisk%2C+E">Erik Frisk</a>, 
<a href="/search/eess?searchtype=author&query=Krysander%2C+M">Mattias Krysander</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Safety, reliability, and durability are targets of all engineering systems,
including Li-ion batteries in electric vehicles. This paper focuses on sensor
setup exploration for a battery-integrated modular multilevel converter
(BI-MMC) that can be part of a solution to sustainable electrification of
vehicles. BI-MMC contains switches to convert DC to AC to drive an electric
machine. The various configurations of switches result in different operation
modes, which in turn, pose great challenges for diagnostics. The study explores
diverse sensor arrangements and system configurations for detecting and
isolating faults in modular battery packs. Configurations involving a minimum
of two modules integrated into the pack are essential to successfully isolate
all faults. The findings indicate that the default sensor setup is insufficient
for achieving complete fault isolability. Additionally, the investigation also
demonstrates that current sensors in the submodules do not contribute
significantly to fault isolability. Further, the results on switch positions
show that the system configuration has a significant impact on fault
isolability. A combination of appropriate sensor data and system configuration
is important in achieving optimal diagnosability, which is a paramount
objective in ensuring system safety.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16523" title="Abstract">arXiv:2312.16523</a> [<a href="/pdf/2312.16523" title="Download PDF">pdf</a>, <a href="/ps/2312.16523" title="Download PostScript">ps</a>, <a href="/format/2312.16523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping bibliographic metadata collections: the case of OpenCitations  Meta and OpenAlex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizzetto%2C+E">Elia Rizzetto</a>, 
<a href="/search/cs?searchtype=author&query=Peroni%2C+S">Silvio Peroni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">This study describes the methodology and analyses the results of the process
of mapping entities between two large open bibliographic metadata collections,
OpenCitations Meta and OpenAlex. The primary objective of this mapping is to
integrate OpenAlex internal identifiers into the existing metadata of
bibliographic resources in OpenCitations Meta, thereby interlinking and
aligning these collections. Furthermore, analysing the output of the mapping
provides a unique perspective on the consistency and accuracy of bibliographic
metadata, offering a valuable tool for identifying potential inconsistencies in
the processed data.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16525" title="Abstract">arXiv:2312.16525</a> [<a href="/pdf/2312.16525" title="Download PDF">pdf</a>, <a href="/format/2312.16525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosis of Small-world Bias in Random Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Argyris%2C+G">Georgios Argyris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Background: Imagine a paper with n nodes on it where each pair undergoes a
coin toss experiment; if heads we connect the pair with an undirected link,
while tails maintain the disconnection. This procedure yields a random graph.
Now consider duplicating this network onto another paper with a slight bias-a
fraction of its links (approximately 1/10) undergo rearrangement. If we shuffle
the two papers, how can we distinguish the pure random graph from the biased
one? Results: In response to this challenge, we propose a novel metric called
Randomness Index (RI). The closer the metric to zero is, the higher degree of
randomness in the graph. The RI can distinguish between dense small-world
networks and dense random graphs; a distinction which is impossible by
conventional small-world properties like clustering coefficient and average
path length. To validate its effectiveness, we apply the RI to temporal
correlation networks of stock indices. Our findings reveal a reduction in
randomness during global economic recession periods. Conclusion: The RI emerges
as a powerful metric capable of characterizing small-world topology, especially
in scenarios where other network measures fail. Beyond its utility in network
analysis, the RI is promising for change-point (anomaly) detection in dynamical
systems studied by means of multivariate time series.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16528" title="Abstract">arXiv:2312.16528</a> [<a href="/pdf/2312.16528" title="Download PDF">pdf</a>, <a href="/ps/2312.16528" title="Download PostScript">ps</a>, <a href="/format/2312.16528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Opinion Leaders in a Telegram Network of Forwarded  Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tucci%2C+G">Giulia Tucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, submitted to ACM Web Sci 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Unraveling the role of opinion leaders in the digital realm, this study
investigates the influence of key actors on Telegram, a hybrid platform that
combines messaging app features with social network dynamics, where channel
administrators gain a unique authoritative role. This research aims to create a
method to identify opinion leaders in a network of forwarded messages on
Telegram, adapting a method originally developed to be applied to Twitter. The
adapted method is showcased through a case study during the 2022 Brazilian
Presidential Election, involving the monitoring of 25 pro-Bolsonaro groups. The
findings contribute to understanding the dynamics of digital opinion
leadership, particularly in politically charged environments.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16529" title="Abstract">arXiv:2312.16529</a> [<a href="/pdf/2312.16529" title="Download PDF">pdf</a>, <a href="/format/2312.16529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Enriched Category Theory to Construct the Nearest Neighbour  Classification Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pugh%2C+M">Matthew Pugh</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">Jo Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Cirstea%2C+C">Corina Cirstea</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+N">Nick Harris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">Exploring whether Enriched Category Theory could provide the foundation of an
alternative approach to Machine Learning. This paper is the first to construct
and motivate a Machine Learning algorithm solely with Enriched Category Theory.
In order to supplement evidence that Category Theory can be used to motivate
robust and explainable algorithms, it is shown that a series of reasonable
assumptions about a dataset lead to the construction of the Nearest Neighbours
Algorithm. In particular, as an extension of the original dataset using
profunctors in the category of Lawvere metric spaces. This leads to a
definition of an Enriched Nearest Neighbours Algorithm, which consequently also
produces an enriched form of the Voronoi diagram. This paper is intended to be
accessible without any knowledge of Category Theory
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16533" title="Abstract">arXiv:2312.16533</a> [<a href="/pdf/2312.16533" title="Download PDF">pdf</a>, <a href="/format/2312.16533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerability Scanners for Ethereum Smart Contracts: A Large-Scale Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sendner%2C+C">Christoph Sendner</a>, 
<a href="/search/cs?searchtype=author&query=Petzi%2C+L">Lukas Petzi</a>, 
<a href="/search/cs?searchtype=author&query=Stang%2C+J">Jasper Stang</a>, 
<a href="/search/cs?searchtype=author&query=Dmitrienko%2C+A">Alexandra Dmitrienko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Ethereum smart contracts, which are autonomous decentralized applications on
the blockchain that manage assets often exceeding millions of dollars, have
become primary targets for cyberattacks. In 2023 alone, such vulnerabilities
led to substantial financial losses exceeding a billion of US dollars. To
counter these threats, various tools have been developed by academic and
commercial entities to detect and mitigate vulnerabilities in smart contracts.
Our study investigates the gap between the effectiveness of existing security
scanners and the vulnerabilities that still persist in practice. We compiled
four distinct datasets for this analysis. The first dataset comprises 77,219
source codes extracted directly from the blockchain, while the second includes
over 4 million bytecodes obtained from Ethereum Mainnet and testnets. The other
two datasets consist of nearly 14,000 manually annotated smart contracts and
373 smart contracts verified through audits, providing a foundation for a
rigorous ground truth analysis on bytecode and source code. Using the unlabeled
datasets, we conducted a comprehensive quantitative evaluation of 17
vulnerability scanners, revealing considerable discrepancies in their findings.
Our analysis of the ground truth datasets indicated poor performance across all
the tools we tested. This study unveils the reasons for poor performance and
underscores that the current state of the art for smart contract security falls
short in effectively addressing open problems, highlighting that the challenge
of effectively detecting vulnerabilities remains a significant and unresolved
issue.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16534" title="Abstract">arXiv:2312.16534</a> [<a href="/pdf/2312.16534" title="Download PDF">pdf</a>, <a href="/format/2312.16534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Use of Multiple Conversational Agent Interlocutors in Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cox%2C+S+R">Samuel Rhys Cox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages; Workshop paper presented at Inter.HAI'23 - the first workshop on Interdisciplinary Approaches in Human-Agent Interaction, held in conjunction with the International Conference on Human-Agent Interaction, December 4th, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With growing capabilities of large language models (LLMs) comes growing
affordances for human-like and context-aware conversational partners. On from
this, some recent work has investigated the use of LLMs to simulate multiple
conversational partners, such as to assist users with problem solving or to
simulate an environment populated entirely with LLMs. Beyond this, we are
interested in discussing and exploring the use of LLMs to simulate multiple
personas to assist and augment users in educational settings that could benefit
from multiple interlocutors. We discuss prior work that uses LLMs to simulate
multiple personas sharing the same environment, and discuss example scenarios
where multiple conversational agent partners could be used in education.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16541" title="Abstract">arXiv:2312.16541</a> [<a href="/pdf/2312.16541" title="Download PDF">pdf</a>, <a href="/format/2312.16541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of a nonconforming finite element method for vector-valued  Laplacians on the surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mehlmann%2C+C">Carolin Mehlmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Recently a nonconforming surface finite element was developed to discretize
2D vector-valued compressible flow problems in a 3D domain. In this
contribution we derive an error analysis for this approach on a vector-valued
Laplace problem, which is an important operator for fluid-equations on the
surface. In our setup, the problem is approximated via edge-integration on
local flat triangles using the nonconforming linear Crouzeix-Raviart element.
The flat planes coincide with the surface at the edge midpoints. This is also
the place, where the Crouzeix-Raviart element requires continuity between two
neighbouring elements. The developed Crouzeix-Raviart approximation is a
non-parametric approach that works on local coordinate systems, established in
each triangle. This setup is numerically efficient and straightforward to
implement. For this Crouzeix-Raviart discretization we derive optimal error
bounds in the $H^1$-norm and $L^2$-norm and present an estimate for the
geometric error. Numerical experiments validate the theoretical results.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16542" title="Abstract">arXiv:2312.16542</a> [<a href="/pdf/2312.16542" title="Download PDF">pdf</a>, <a href="/format/2312.16542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FALCON: Feature-Label Constrained Graph Net Collapse for Memory  Efficient GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adnel%2C+C">Christopher Adnel</a>, 
<a href="/search/cs?searchtype=author&query=Rekik%2C+I">Islem Rekik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Network (GNN) ushered in a new era of machine learning with
interconnected datasets. While traditional neural networks can only be trained
on independent samples, GNN allows for the inclusion of inter-sample
interactions in the training process. This gain, however, incurs additional
memory cost, rendering most GNNs unscalable for real-world applications
involving vast and complicated networks with tens of millions of nodes (e.g.,
social circles, web graphs, and brain graphs). This means that storing the
graph in the main memory can be difficult, let alone training the GNN model
with significantly less GPU memory. While much of the recent literature has
focused on either mini-batching GNN methods or quantization, graph reduction
methods remain largely scarce. Furthermore, present graph reduction approaches
have several drawbacks. First, most graph reduction focuses only on the
inference stage (e.g., condensation and distillation) and requires full graph
GNN training, which does not reduce training memory footprint. Second, many
methods focus solely on the graph's structural aspect, ignoring the initial
population feature-label distribution, resulting in a skewed post-reduction
label distribution. Here, we propose a Feature-Label COnstrained graph Net
collapse, FALCON, to address these limitations. Our three core contributions
lie in (i) designing FALCON, a topology-aware graph reduction technique that
preserves feature-label distribution; (ii) implementation of FALCON with other
memory reduction methods (i.e., mini-batched GNN and quantization) for further
memory reduction; (iii) extensive benchmarking and ablation studies against
SOTA methods to evaluate FALCON memory reduction. Our extensive results show
that FALCON can significantly collapse various public datasets while achieving
equal prediction quality across GNN models. Code:
https://github.com/basiralab/FALCON
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16547" title="Abstract">arXiv:2312.16547</a> [<a href="/pdf/2312.16547" title="Download PDF">pdf</a>, <a href="/format/2312.16547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreqyWM: Frequency Watermarking for the New Data Economy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%B0%C5%9Fler%2C+D">Devri&#x15f; &#x130;&#x15f;ler</a>, 
<a href="/search/cs?searchtype=author&query=Cabana%2C+E">Elisa Cabana</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Recuero%2C+A">Alvaro Garcia-Recuero</a>, 
<a href="/search/cs?searchtype=author&query=Koutrika%2C+G">Georgia Koutrika</a>, 
<a href="/search/cs?searchtype=author&query=Laoutaris%2C+N">Nikolaos Laoutaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">We present a novel technique for modulating the appearance frequency of a few
tokens within a dataset for encoding an invisible watermark that can be used to
protect ownership rights upon data. We develop optimal as well as fast
heuristic algorithms for creating and verifying such watermarks. We also
demonstrate the robustness of our technique against various attacks and derive
analytical bounds for the false positive probability of erroneously detecting a
watermark on a dataset that does not carry it. Our technique is applicable to
both single dimensional and multidimensional datasets, is independent of token
type, allows for a fine control of the introduced distortion, and can be used
in a variety of use cases that involve buying and selling data in contemporary
data marketplaces.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16548" title="Abstract">arXiv:2312.16548</a> [<a href="/pdf/2312.16548" title="Download PDF">pdf</a>, <a href="/ps/2312.16548" title="Download PostScript">ps</a>, <a href="/format/2312.16548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A proposed new metric for the conceptual diversity of a text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phd%2C+%C4%B0+D">&#x130;lknur D&#xf6;nmez Phd</a>, 
<a href="/search/cs?searchtype=author&query=Phd%2C+M+H">Mehmet Hakl&#x131;d&#x131;r Phd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 graphical figures, 3 algorithm figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
<p class="mathjax">A word may contain one or more hidden concepts. While the "animal" word
evokes many images in our minds and encapsulates many concepts (birds, dogs,
cats, crocodiles, etc.), the `parrot' word evokes a single image (a colored
bird with a short, hooked beak and the ability to mimic sounds). In spoken or
written texts, we use some words in a general sense and some in a detailed way
to point to a specific object. Until now, a text's conceptual diversity value
cannot be determined using a standard and precise technique. This research
contributes to the natural language processing field of AI by offering a
standardized method and a generic metric for evaluating and comparing concept
diversity in different texts and domains. It also contributes to the field of
semantic research of languages. If we give examples for the diversity score of
two sentences, "He discovered an unknown entity." has a high conceptual
diversity score (16.6801), and "The endoplasmic reticulum forms a series of
flattened sacs within the cytoplasm of eukaryotic cells." sentence has a low
conceptual diversity score which is 3.9068.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16549" title="Abstract">arXiv:2312.16549</a> [<a href="/pdf/2312.16549" title="Download PDF">pdf</a>, <a href="/format/2312.16549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Robust are LLMs to In-Context Majority Label Bias?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Karan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Roychowdhury%2C+S">Sumegh Roychowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Kasa%2C+S+R">Siva Rajesh Kasa</a>, 
<a href="/search/cs?searchtype=author&query=Kasa%2C+S+K">Santhosh Kumar Kasa</a>, 
<a href="/search/cs?searchtype=author&query=Bhanushali%2C+A">Anish Bhanushali</a>, 
<a href="/search/cs?searchtype=author&query=Pattisapu%2C+N">Nikhil Pattisapu</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+P+S">Prasanna Srinivasa Murthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 2 table. Accepted at Workshop on Responsible Language Modeling, AAAI 2024, (www.aaai.org)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In the In-Context Learning (ICL) setup, various forms of label biases can
manifest. One such manifestation is majority label bias, which arises when the
distribution of labeled examples in the in-context samples is skewed towards
one or more specific classes making Large Language Models (LLMs) more prone to
predict those labels. Such discrepancies can arise from various factors,
including logistical constraints, inherent biases in data collection methods,
limited access to diverse data sources, etc. which are unavoidable in a
real-world industry setup. In this work, we study the robustness of in-context
learning in LLMs to shifts that occur due to majority label bias within the
purview of text classification tasks. Prior works have shown that in-context
learning with LLMs is susceptible to such biases. In our study, we go one level
deeper and show that the robustness boundary varies widely for different models
and tasks, with certain LLMs being highly robust (~90%) to majority label bias.
Additionally, our findings also highlight the impact of model size and the
richness of instructional prompts contributing towards model robustness. We
restrict our study to only publicly available open-source models to ensure
transparency and reproducibility.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16551" title="Abstract">arXiv:2312.16551</a> [<a href="/pdf/2312.16551" title="Download PDF">pdf</a>, <a href="/format/2312.16551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Image Quality Assessment: A Brief Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miaohui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Blind Image Quality Assessment (BIQA) is essential for automatically
evaluating the perceptual quality of visual signals without access to the
references. In this survey, we provide a comprehensive analysis and discussion
of recent developments in the field of BIQA. We have covered various aspects,
including hand-crafted BIQAs that focus on distortion-specific and
general-purpose methods, as well as deep-learned BIQAs that employ supervised
and unsupervised learning techniques. Additionally, we have explored multimodal
quality assessment methods that consider interactions between visual and audio
modalities, as well as visual and text modalities. Finally, we have offered
insights into representative BIQA databases, including both synthetic and
authentic distortions. We believe this survey provides valuable understandings
into the latest developments and emerging trends for the visual quality
community.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16552" title="Abstract">arXiv:2312.16552</a> [<a href="/pdf/2312.16552" title="Download PDF">pdf</a>, <a href="/format/2312.16552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AE-Flow: AutoEncoder Normalizing Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mosi%C5%84ski%2C+J">Jakub Mosi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Bili%C5%84ski%2C+P">Piotr Bili&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Merritt%2C+T">Thomas Merritt</a>, 
<a href="/search/cs?searchtype=author&query=Ezzerg%2C+A">Abdelhamid Ezzerg</a>, 
<a href="/search/cs?searchtype=author&query=Korzekwa%2C+D">Daniel Korzekwa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently normalizing flows have been gaining traction in text-to-speech (TTS)
and voice conversion (VC) due to their state-of-the-art (SOTA) performance.
Normalizing flows are unsupervised generative models. In this paper, we
introduce supervision to the training process of normalizing flows, without the
need for parallel data. We call this training paradigm AutoEncoder Normalizing
Flow (AE-Flow). It adds a reconstruction loss forcing the model to use
information from the conditioning to reconstruct an audio sample. Our goal is
to understand the impact of each component and find the right combination of
the negative log-likelihood (NLL) and the reconstruction loss in training
normalizing flows with coupling blocks. For that reason we will compare
flow-based mapping model trained with: (i) NLL loss, (ii) NLL and
reconstruction losses, as well as (iii) reconstruction loss only. Additionally,
we compare our model with SOTA VC baseline. The models are evaluated in terms
of naturalness, speaker similarity, intelligibility in many-to-many and
many-to-any VC settings. The results show that the proposed training paradigm
systematically improves speaker similarity and naturalness when compared to
regular training methods of normalizing flows. Furthermore, we show that our
method improves speaker similarity and intelligibility over the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16554" title="Abstract">arXiv:2312.16554</a> [<a href="/pdf/2312.16554" title="Download PDF">pdf</a>, <a href="/format/2312.16554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Analysis of Efficiency Constrained Utility-Privacy  Bi-Objective Optimization in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyuan Zhao</a> (2), 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuxing Han</a> (2), 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a> (1), 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a> (1), 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a> (1 and 3) ((1) WeBank, China, (2) Tsinghua University, China, (3) Hong Kong University of Science and Technology, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lixin Fan, Member, IEEE; Qiang Yang, Fellow, IEEE; Hanlin Gu and Xinyuan Zhao contribute equally in this paper; Yuxing Han is the corresponding author
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) enables multiple clients to collaboratively learn a
shared model without sharing their individual data. Concerns about utility,
privacy, and training efficiency in FL have garnered significant research
attention. Differential privacy has emerged as a prevalent technique in FL,
safeguarding the privacy of individual user data while impacting utility and
training efficiency. Within Differential Privacy Federated Learning (DPFL),
previous studies have primarily focused on the utility-privacy trade-off,
neglecting training efficiency, which is crucial for timely completion.
Moreover, differential privacy achieves privacy by introducing controlled
randomness (noise) on selected clients in each communication round. Previous
work has mainly examined the impact of noise level ($\sigma$) and communication
rounds ($T$) on the privacy-utility dynamic, overlooking other influential
factors like the sample ratio ($q$, the proportion of selected clients). This
paper systematically formulates an efficiency-constrained utility-privacy
bi-objective optimization problem in DPFL, focusing on $\sigma$, $T$, and $q$.
We provide a comprehensive theoretical analysis, yielding analytical solutions
for the Pareto front. Extensive empirical experiments verify the validity and
efficacy of our analysis, offering valuable guidance for low-cost parameter
design in DPFL.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16559" title="Abstract">arXiv:2312.16559</a> [<a href="/pdf/2312.16559" title="Download PDF">pdf</a>, <a href="/ps/2312.16559" title="Download PostScript">ps</a>, <a href="/format/2312.16559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Beamforming Structure and Efficient Optimization Algorithms for  Generalized Multi-Group Multicast Beamforming Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this work, we focus on solving non-smooth non-convex maximization problems
in multi-group multicast transmission. Leveraging Karush-Kuhn-Tucker (KKT)
optimality conditions and successive incumbent transcending (SIT) duality, we
thoroughly analyze the optimal beamforming structure for a set of optimization
problems characterized by a general utility-based objective function. By
exploiting the identified optimal structure, we further unveil inherent
low-dimensional beamforming structures within the problems, which are
asymptotically optimal in various regimes of transmit signal-to-noise ratios
(SNRs) or the number of transmit antennas. Building upon the discovered optimal
and low-dimensional beamforming structures, we then propose highly efficient
and toolbox-free optimization algorithms to solve a specific multi-group
multicast optimization problem based on the weighted sum rate (WSR) utility
function. The proposed algorithms first use the cyclic maximization (CM)
framework to decompose the problem into multiple subproblems, each has an
optimal or low-dimensional closed-form beamforming solution structure. Then, we
propose the projected adaptive gradient descent (PAGD) algorithm to compute the
optimal Lagrangian dual variables for each subproblem. Numerical results show
that the proposed algorithms maintain comparable or improved WSR performance
compared to baseline algorithms, while dramatically reducing the computational
complexity. Notably, the proposed ultra-low-complexity algorithms based on
low-dimensional beamforming structures achieve near optimal WSR performance
with extremely low computational complexity. This complexity remains
independent of the number of transmit antennas, making them promising and
practical for extremely large multiple-input multiple-output (XL-MIMO)
applications in 6G.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16560" title="Abstract">arXiv:2312.16560</a> [<a href="/pdf/2312.16560" title="Download PDF">pdf</a>, <a href="/format/2312.16560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Message Passing: A General Framework to Mitigate Oversmoothing,  Oversquashing, and Underreaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Errica%2C+F">Federico Errica</a>, 
<a href="/search/cs?searchtype=author&query=Christiansen%2C+H">Henrik Christiansen</a>, 
<a href="/search/cs?searchtype=author&query=Zaverkin%2C+V">Viktor Zaverkin</a>, 
<a href="/search/cs?searchtype=author&query=Maruyama%2C+T">Takashi Maruyama</a>, 
<a href="/search/cs?searchtype=author&query=Niepert%2C+M">Mathias Niepert</a>, 
<a href="/search/cs?searchtype=author&query=Alesiani%2C+F">Francesco Alesiani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Long-range interactions are essential for the correct description of complex
systems in many scientific fields. The price to pay for including them in the
calculations, however, is a dramatic increase in the overall computational
costs. Recently, deep graph networks have been employed as efficient,
data-driven surrogate models for predicting properties of complex systems
represented as graphs. These models rely on a local and iterative message
passing strategy that should, in principle, capture long-range information
without explicitly modeling the corresponding interactions. In practice, most
deep graph networks cannot really model long-range dependencies due to the
intrinsic limitations of (synchronous) message passing, namely oversmoothing,
oversquashing, and underreaching. This work proposes a general framework that
learns to mitigate these limitations: within a variational inference framework,
we endow message passing architectures with the ability to freely adapt their
depth and filter messages along the way. With theoretical and empirical
arguments, we show that this simple strategy better captures long-range
interactions, by surpassing the state of the art on five node and graph
prediction datasets suited for this problem. Our approach consistently improves
the performances of the baselines tested on these tasks. We complement the
exposition with qualitative analyses and ablations to get a deeper
understanding of the framework's inner workings.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16563" title="Abstract">arXiv:2312.16563</a> [<a href="/pdf/2312.16563" title="Download PDF">pdf</a>, <a href="/format/2312.16563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDGCL: Reaction-Diffusion Graph Contrastive Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chaejeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sung-Bae Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Jeongwhan Choi and Hyowon Wi are co-first authors with equal contributions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contrastive learning (CL) has emerged as a promising technique for improving
recommender systems, addressing the challenge of data sparsity by leveraging
self-supervised signals from raw data. Integration of CL with graph
convolutional network (GCN)-based collaborative filterings (CFs) has been
explored in recommender systems. However, current CL-based recommendation
models heavily rely on low-pass filters and graph augmentations. In this paper,
we propose a novel CL method for recommender systems called the
reaction-diffusion graph contrastive learning model (RDGCL). We design our own
GCN for CF based on both the diffusion, i.e., low-pass filter, and the
reaction, i.e., high-pass filter, equations. Our proposed CL-based training
occurs between reaction and diffusion-based embeddings, so there is no need for
graph augmentations. Experimental evaluation on 6 benchmark datasets
demonstrates that our proposed method outperforms state-of-the-art CL-based
recommendation models. By enhancing recommendation accuracy and diversity, our
method brings an advancement in CL for recommender systems.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16564" title="Abstract">arXiv:2312.16564</a> [<a href="/pdf/2312.16564" title="Download PDF">pdf</a>, <a href="/format/2312.16564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Priorities in Patrolling with Rabbit Walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katole%2C+R">Rugved Katole</a>, 
<a href="/search/cs?searchtype=author&query=Mallya%2C+D">Deepak Mallya</a>, 
<a href="/search/cs?searchtype=author&query=Vachhani%2C+L">Leena Vachhani</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Arpita Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In an environment with certain locations of higher priority, it is required
to patrol these locations as frequently as possible due to their importance.
However, the Non-Priority locations are often neglected during the task. It is
necessary to balance the patrols on both kinds of sites to avoid breaches in
security. We present a distributed online algorithm that assigns the routes to
agents that ensures a finite time visit to the Non-Priority locations along
with Priority Patrolling. The proposed algorithm generates offline patrol
routes (Rabbit Walks) with three segments (Hops) to explore non-priority
locations. The generated number of offline walks depends exponentially on a
parameter introduced in the proposed algorithm, thereby facilitating the
scalable implementation based on the onboard resources available on each
patrolling robot. A systematic performance evaluation through simulations and
experimental results validates the proportionately balanced visits and suggests
the proposed algorithm's versatile applicability in the implementation of
deterministic and non-deterministic scenarios.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16565" title="Abstract">arXiv:2312.16565</a> [<a href="/pdf/2312.16565" title="Download PDF">pdf</a>, <a href="/format/2312.16565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discontinuous Galerkin methods for 3D-1D systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Masri%2C+R">Rami Masri</a>, 
<a href="/search/math?searchtype=author&query=Kuchta%2C+M">Miroslav Kuchta</a>, 
<a href="/search/math?searchtype=author&query=Riviere%2C+B">Beatrice Riviere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose and analyze discontinuous Galerkin (dG) approximations to 3D-1D
coupled systems which model diffusion in a 3D domain containing a small
inclusion reduced to its 1D centerline. Convergence to weak solutions of a
steady state problem is established via deriving a posteriori error estimates
and bounds on residuals defined with suitable lift operators. For the time
dependent problem, a backward Euler dG formulation is also presented and
analysed. Further, we propose a dG method for networks embedded in 3D domains,
which is, up to jump terms, locally mass conservative on bifurcation points.
Numerical examples in idealized geometries portray our theoretical findings,
and simulations in realistic 1D networks show the robustness of our method.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16566" title="Abstract">arXiv:2312.16566</a> [<a href="/pdf/2312.16566" title="Download PDF">pdf</a>, <a href="/format/2312.16566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Reinforcement Learning with Unknown Reward Model based on  Structural Risk Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chendi Qu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianping He</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Inverse reinforcement learning (IRL) usually assumes the model of the reward
function is pre-specified and estimates the parameter only. However, how to
determine a proper reward model is nontrivial. A simplistic model is less
likely to contain the real reward function, while a model with high complexity
leads to substantial computation cost and risks overfitting. This paper
addresses this trade-off in IRL model selection by introducing the structural
risk minimization (SRM) method from statistical learning. SRM selects an
optimal reward function class from a hypothesis set minimizing both estimation
error and model complexity. To formulate an SRM scheme for IRL, we estimate
policy gradient by demonstration serving as empirical risk and establish the
upper bound of Rademacher complexity of hypothesis classes as model penalty.
The learning guarantee is further presented. In particular, we provide explicit
SRM for the common linear weighted sum setting in IRL. Simulations demonstrate
the performance and efficiency of our scheme.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16571" title="Abstract">arXiv:2312.16571</a> [<a href="/pdf/2312.16571" title="Download PDF">pdf</a>, <a href="/format/2312.16571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRSDet: Learning to Generate Local Reverse Samples for Few-shot Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hefei Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Taijin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shiyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Heqian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanman Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongliang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot object detection (FSOD) aims to achieve object detection only using
a few novel class training data. Most of the existing methods usually adopt a
transfer-learning strategy to construct the novel class distribution by
transferring the base class knowledge. However, this direct way easily results
in confusion between the novel class and other similar categories in the
decision space. To address the problem, we propose generating local reverse
samples (LRSamples) in Prototype Reference Frames to adaptively adjust the
center position and boundary range of the novel class distribution to learn
more discriminative novel class samples for FSOD. Firstly, we propose a Center
Calibration Variance Augmentation (CCVA) module, which contains the selection
rule of LRSamples, the generator of LRSamples, and augmentation on the
calibrated distribution centers. Specifically, we design an intra-class feature
converter (IFC) as the generator of CCVA to learn the selecting rule. By
transferring the knowledge of IFC from the base training to fine-tuning, the
IFC generates plentiful novel samples to calibrate the novel class
distribution. Moreover, we propose a Feature Density Boundary Optimization
(FDBO) module to adaptively adjust the importance of samples depending on their
distance from the decision boundary. It can emphasize the importance of the
high-density area of the similar class (closer decision boundary area) and
reduce the weight of the low-density area of the similar class (farther
decision boundary area), thus optimizing a clearer decision boundary for each
category. We conduct extensive experiments to demonstrate the effectiveness of
our proposed method. Our method achieves consistent improvement on the Pascal
VOC and MS COCO datasets based on DeFRCN and MFDC baselines.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16572" title="Abstract">arXiv:2312.16572</a> [<a href="/pdf/2312.16572" title="Download PDF">pdf</a>, <a href="/format/2312.16572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observation-based Optimal Control Law Learning with LQR Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qu%2C+C">Chendi Qu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+J">Jianping He</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Designing controllers to generate various trajectories has been studied for
years, while recently, recovering an optimal controller from trajectories
receives increasing attention. In this paper, we reveal that the inherent
linear quadratic regulator (LQR) problem of a moving agent can be reconstructed
based on its trajectory observations only, which enables one to learn the
optimal control law of the agent autonomously. Specifically, the reconstruction
of the optimization problem requires estimation of three unknown parameters
including the target state, weighting matrices in the objective function and
the control horizon. Our algorithm considers two types of objective function
settings and identifies the weighting matrices with proposed novel inverse
optimal control methods, providing the well-posedness and identifiability
proof. We obtain the optimal estimate of the control horizon using binary
search and finally reconstruct the LQR problem with above estimates. The
strength of learning control law with optimization problem recovery lies in
less computation consumption and strong generalization ability. We apply our
algorithm to the future control input prediction and the discrepancy loss is
further derived. Numerical simulations and hardware experiments on a
self-designed robot platform illustrate the effectiveness of our work.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16578" title="Abstract">arXiv:2312.16578</a> [<a href="/pdf/2312.16578" title="Download PDF">pdf</a>, <a href="/format/2312.16578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modality Affinity Inference for Weakly Supervised 3D Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X+L+Q+X+J+Z+T+Z+Q+Y+L+S+D">Xiawei Li Qingyuan Xu Jing Zhang Tianyi Zhang Qian Yu Lu Sheng Dong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D point cloud semantic segmentation has a wide range of applications.
Recently, weakly supervised point cloud segmentation methods have been
proposed, aiming to alleviate the expensive and laborious manual annotation
process by leveraging scene-level labels. However, these methods have not
effectively exploited the rich geometric information (such as shape and scale)
and appearance information (such as color and texture) present in RGB-D scans.
Furthermore, current approaches fail to fully leverage the point affinity that
can be inferred from the feature extraction network, which is crucial for
learning from weak scene-level labels. Additionally, previous work overlooks
the detrimental effects of the long-tailed distribution of point cloud data in
weakly supervised 3D semantic segmentation. To this end, this paper proposes a
simple yet effective scene-level weakly supervised point cloud segmentation
method with a newly introduced multi-modality point affinity inference module.
The point affinity proposed in this paper is characterized by features from
multiple modalities (e.g., point cloud and RGB), and is further refined by
normalizing the classifier weights to alleviate the detrimental effects of
long-tailed distribution without the need of the prior of category
distribution. Extensive experiments on the ScanNet and S3DIS benchmarks verify
the effectiveness of our proposed method, which outperforms the
state-of-the-art by ~4% to ~6% mIoU. Codes are released at
https://github.com/Sunny599/AAAI24-3DWSSG-MMA.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16580" title="Abstract">arXiv:2312.16580</a> [<a href="/pdf/2312.16580" title="Download PDF">pdf</a>, <a href="/format/2312.16580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLCounter: Text-aware VIsual Representation for Zero-Shot Object  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seunggu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+W">WonJun Moon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Euiyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Code is available at <a href="https://github.com/Seunggu0305/VLCounter">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-Shot Object Counting (ZSOC) aims to count referred instances of
arbitrary classes in a query image without human-annotated exemplars. To deal
with ZSOC, preceding studies proposed a two-stage pipeline: discovering
exemplars and counting. However, there remains a challenge of vulnerability to
error propagation of the sequentially designed two-stage process. In this work,
an one-stage baseline, Visual-Language Baseline (VLBase), exploring the
implicit association of the semantic-patch embeddings of CLIP is proposed.
Subsequently, the extension of VLBase to Visual-language Counter (VLCounter) is
achieved by incorporating three modules devised to tailor VLBase for object
counting. First, Semantic-conditioned Prompt Tuning (SPT) is introduced within
the image encoder to acquire target-highlighted representations. Second,
Learnable Affine Transformation (LAT) is employed to translate the
semantic-patch similarity map to be appropriate for the counting task. Lastly,
the layer-wisely encoded features are transferred to the decoder through
Segment-aware Skip Connection (SaSC) to keep the generalization capability for
unseen classes. Through extensive experiments on FSC147, CARPK, and PUCPR+, the
benefits of the end-to-end framework, VLCounter, are demonstrated.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16581" title="Abstract">arXiv:2312.16581</a> [<a href="/pdf/2312.16581" title="Download PDF">pdf</a>, <a href="/format/2312.16581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-time Autoencoders for Regular and Irregular Time Series  Imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sungpil Woo</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Sunhwan Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a WSDM'24 full paper (oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Time series imputation is one of the most fundamental tasks for time series.
Real-world time series datasets are frequently incomplete (or irregular with
missing observations), in which case imputation is strongly required. Many
different time series imputation methods have been proposed. Recent
self-attention-based methods show the state-of-the-art imputation performance.
However, it has been overlooked for a long time to design an imputation method
based on continuous-time recurrent neural networks (RNNs), i.e., neural
controlled differential equations (NCDEs). To this end, we redesign time series
(variational) autoencoders based on NCDEs. Our method, called continuous-time
autoencoder (CTA), encodes an input time series sample into a continuous hidden
path (rather than a hidden vector) and decodes it to reconstruct and impute the
input. In our experiments with 4 datasets and 19 baselines, our method shows
the best imputation performance in almost all cases.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16582" title="Abstract">arXiv:2312.16582</a> [<a href="/pdf/2312.16582" title="Download PDF">pdf</a>, <a href="/format/2312.16582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learnable Chamfer Distance for Point Cloud Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangrui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As point clouds are 3D signals with permutation invariance, most existing
works train their reconstruction networks by measuring shape differences with
the average point-to-point distance between point clouds matched with
predefined rules. However, the static matching rules may deviate from actual
shape differences. Although some works propose dynamically-updated learnable
structures to replace matching rules, they need more iterations to converge
well. In this work, we propose a simple but effective reconstruction loss,
named Learnable Chamfer Distance (LCD) by dynamically paying attention to
matching distances with different weight distributions controlled with a group
of learnable networks. By training with adversarial strategy, LCD learns to
search defects in reconstructed results and overcomes the weaknesses of static
matching rules, while the performances at low iterations can also be guaranteed
by the basic matching algorithm. Experiments on multiple reconstruction
networks confirm that LCD can help achieve better reconstruction performances
and extract more representative representations with faster convergence and
comparable training efficiency. The source codes are provided in
https://github.com/Tianxinhuang/LCDNet.git.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16585" title="Abstract">arXiv:2312.16585</a> [<a href="/pdf/2312.16585" title="Download PDF">pdf</a>, <a href="/ps/2312.16585" title="Download PostScript">ps</a>, <a href="/format/2312.16585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A highly efficient asymptotic preserving IMEX method for the quantum BGK  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+R">Ruo Li</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+Y">Yixiao Lu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yanli Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents an asymptotic preserving (AP) implicit-explicit (IMEX)
scheme for solving the quantum BGK equation using the Hermite spectral method.
The distribution function is expanded in a series of Hermite polynomials, with
the Gaussian function serving as the weight function. The main challenge in
this numerical scheme lies in efficiently expanding the quantum Maxwellian with
the Hermite basis functions. To overcome this, we simplify the problem to the
calculation of polylogarithms and propose an efficient algorithm to handle it,
utilizing the Gauss-Hermite quadrature. Several numerical simulations,
including a spatially 2D lid-driven cavity flow, demonstrate the AP property
and remarkable efficiency of this method.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16592" title="Abstract">arXiv:2312.16592</a> [<a href="/pdf/2312.16592" title="Download PDF">pdf</a>, <a href="/ps/2312.16592" title="Download PostScript">ps</a>, <a href="/format/2312.16592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Access and Backhaul via LEO Satellites with Inter-Satellite  Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+Z">Zaid Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Lagunas%2C+E">Eva Lagunas</a>, 
<a href="/search/cs?searchtype=author&query=Kisseleff%2C+S">Steven Kisseleff</a>, 
<a href="/search/cs?searchtype=author&query=Zeppenfeldt%2C+F">Frank Zeppenfeldt</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The third generation partnership project (3GPP) has recently defined two
frequency bands for direct access with satellites, which is a concrete step
toward realizing the anticipated space-air-ground integrated networks. In
addition, given the rapid increase in the numbers of satellites orbiting the
Earth and emerging satellites applications, non-terrestrial networks (NTNs)
might soon need to operate with integrated access and backhaul (IAB), which has
been standardized for terrestrial networks to enable low-cost, flexible and
scalable network densification. Therefore, this work investigates the
performance of satellite IAB, where the same spectrum resources at a low earth
orbit (LEO) satellite are utilized to provide access to a handheld user (UE)
and backhaul via inter-satellite links. The UE is assumed to operate with
frequency division duplex (FDD) as specified by the 3GPP, while both FDD and
time division duplex (TDD) are investigated for backhauling. Our analysis
demonstrate that the interference between access and backhaul links can
significantly affect the performance under TDD backhauling, especially when the
access link comes with a high quality-of-service demands.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16596" title="Abstract">arXiv:2312.16596</a> [<a href="/pdf/2312.16596" title="Download PDF">pdf</a>, <a href="/format/2312.16596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Traffic Flow Prediction using Outlier-Weighted AutoEncoders:  Handling Real-Time Changes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+H">Himanshu Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+M">Marwan Hassani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In today's urban landscape, traffic congestion poses a critical challenge,
especially during outlier scenarios. These outliers can indicate abrupt traffic
peaks, drops, or irregular trends, often arising from factors such as
accidents, events, or roadwork. Moreover, Given the dynamic nature of traffic,
the need for real-time traffic modeling also becomes crucial to ensure accurate
and up-to-date traffic predictions. To address these challenges, we introduce
the Outlier Weighted Autoencoder Modeling (OWAM) framework. OWAM employs
autoencoders for local outlier detection and generates correlation scores to
assess neighboring traffic's influence. These scores serve as a weighted factor
for neighboring sensors, before fusing them into the model. This information
enhances the traffic model's performance and supports effective real-time
updates, a crucial aspect for capturing dynamic traffic patterns. OWAM
demonstrates a favorable trade-off between accuracy and efficiency, rendering
it highly suitable for real-world applications. The research findings
contribute significantly to the development of more efficient and adaptive
traffic prediction models, advancing the field of transportation management for
the future. The code and datasets of our framework is publicly available under
https://github.com/himanshudce/OWAM.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16598" title="Abstract">arXiv:2312.16598</a> [<a href="/pdf/2312.16598" title="Download PDF">pdf</a>, <a href="/format/2312.16598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyView: Bringing Performance Profiles into Integrated Development  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qidong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chabbi%2C+M">Milind Chabbi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Dynamic program analysis (also known as profiling) is well-known for its
powerful capabilities of identifying performance inefficiencies in software
packages. Although a large number of dynamic program analysis techniques are
developed in academia and industry, very few of them are widely used by
software developers in their regular software developing activities. There are
three major reasons. First, the dynamic analysis tools (also known as
profilers) are disjoint from the coding environments such as IDEs and editors;
frequently switching focus between them significantly complicates the entire
cycle of software development. Second, mastering various tools to interpret
their analysis results requires substantial efforts; even worse, many tools
have their own design of graphical user interfaces (GUI) for data presentation,
which steepens the learning curves. Third, most existing tools expose few
interfaces to support user-defined analysis, which makes the tools less
customizable to fulfill diverse user demands. We develop EasyView, a general
solution to integrate the interpretation and visualization of various profiling
results in the coding environments, which bridges software developers with
profilers to provide easy and intuitive dynamic analysis during the code
development cycle. The novelty of EasyView is three-fold. First, we develop a
generic data format, which enables EasyView to support mainstream profilers for
different languages. Second, we develop a set of customizable schemes to
analyze and visualize the profiles in intuitive ways. Third, we tightly
integrate EasyView with popular coding environments, such as Microsoft Visual
Studio Code, with easy code exploration and user interaction. Our evaluation
shows that EasyView is able to support various profilers for different
languages and provide unique insights into performance inefficiencies in
different domains.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16599" title="Abstract">arXiv:2312.16599</a> [<a href="/pdf/2312.16599" title="Download PDF">pdf</a>, <a href="/ps/2312.16599" title="Download PostScript">ps</a>, <a href="/format/2312.16599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relationship between auditory and semantic entrainment using Deep Neural  Networks (DNN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kejriwal%2C+J">Jay Kejriwal</a>, 
<a href="/search/cs?searchtype=author&query=Be%C5%88u%C5%A1%2C+%C5%A0">&#x160;tefan Be&#x148;u&#x161;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The tendency of people to engage in similar, matching, or synchronized
behaviour when interacting is known as entrainment. Many studies examined
linguistic (syntactic and lexical structures) and paralinguistic (pitch,
intensity) entrainment, but less attention was given to finding the
relationship between them. In this study, we utilized state-of-the-art DNN
embeddings such as BERT and TRIpLet Loss network (TRILL) vectors to extract
features for measuring semantic and auditory similarities of turns within
dialogues in two comparable spoken corpora of two different languages. We found
people's tendency to entrain on semantic features more when compared to
auditory features. Additionally, we found that entrainment in semantic and
auditory linguistic features are positively correlated. The findings of this
study might assist in implementing the mechanism of entrainment in
human-machine interaction (HMI).
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16602" title="Abstract">arXiv:2312.16602</a> [<a href="/pdf/2312.16602" title="Download PDF">pdf</a>, <a href="/format/2312.16602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Instruction Tuning towards General-Purpose Multimodal Model: A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional computer vision generally solves each single task independently
by a dedicated model with the task instruction implicitly designed in the model
architecture, arising two limitations: (1) it leads to task-specific models,
which require multiple models for different tasks and restrict the potential
synergies from diverse tasks; (2) it leads to a pre-defined and fixed model
interface that has limited interactivity and adaptability in following user'
task instructions. To address them, Visual Instruction Tuning (VIT) has been
intensively studied recently, which finetunes a large vision model with
language as task instructions, aiming to learn from a wide range of vision
tasks described by language instructions a general-purpose multimodal model
that can follow arbitrary instructions and thus solve arbitrary tasks specified
by the user. This work aims to provide a systematic review of visual
instruction tuning, covering (1) the background that presents computer vision
task paradigms and the development of VIT; (2) the foundations of VIT that
introduce commonly used network architectures, visual instruction tuning
frameworks and objectives, and evaluation setups and tasks; (3) the commonly
used datasets in visual instruction tuning and evaluation; (4) the review of
existing VIT methods that categorizes them with a taxonomy according to both
the studied vision task and the method design and highlights the major
contributions, strengths, and shortcomings of them; (5) the comparison and
discussion of VIT methods over various instruction-following benchmarks; (6)
several challenges, open directions and possible future works in visual
instruction tuning research.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16603" title="Abstract">arXiv:2312.16603</a> [<a href="/pdf/2312.16603" title="Download PDF">pdf</a>, <a href="/format/2312.16603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Surface: Advanced Wash Trading Detection in Decentralized NFT  Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=To%C5%A1i%C4%87%2C+A">Aleksandar To&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Hrovatin%2C+N">Niki Hrovatin</a>, 
<a href="/search/cs?searchtype=author&query=Vi%C4%8Di%C4%8D%2C+J">Jernej Vi&#x10d;i&#x10d;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Wash trading in decentralized markets remains a significant concern magnified
by the pseudonymous and public nature of blockchains. In this paper we
introduce an innovative methodology designed to detect wash trading activities
beyond surface-level transactions. Our approach integrates NFT ownership traces
with the Ethereum Transaction Network, encompassing the complete historical
record of all Ethereum account normal transactions. By analyzing both networks,
our method offers a notable advancement over techniques proposed by existing
research. We analyzed the wash trading activity of 7 notable NFT collections.
Our results show that wash trading in unregulated NFT markets is an
underestimated concern and is much more widespread both in terms of frequency
as well as volume. Excluding the Meebits collection, which emerged as an
outlier, we found that wash trading constituted up to 25% of the total trading
volume. Specifically, for the Meebits collection, a staggering 93% of its total
trade volume was attributed to wash trading.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16604" title="Abstract">arXiv:2312.16604</a> [<a href="/pdf/2312.16604" title="Download PDF">pdf</a>, <a href="/format/2312.16604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twice Class Bias Correction for Imbalanced Semi-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+B">Bowen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-chuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Han-jia Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Differing from traditional semi-supervised learning, class-imbalanced
semi-supervised learning presents two distinct challenges: (1) The imbalanced
distribution of training samples leads to model bias towards certain classes,
and (2) the distribution of unlabeled samples is unknown and potentially
distinct from that of labeled samples, which further contributes to class bias
in the pseudo-labels during training. To address these dual challenges, we
introduce a novel approach called \textbf{T}wice \textbf{C}lass \textbf{B}ias
\textbf{C}orrection (\textbf{TCBC}). We begin by utilizing an estimate of the
class distribution from the participating training samples to correct the
model, enabling it to learn the posterior probabilities of samples under a
class-balanced prior. This correction serves to alleviate the inherent class
bias of the model. Building upon this foundation, we further estimate the class
bias of the current model parameters during the training process. We apply a
secondary correction to the model's pseudo-labels for unlabeled samples, aiming
to make the assignment of pseudo-labels across different classes of unlabeled
samples as equitable as possible. Through extensive experimentation on
CIFAR10/100-LT, STL10-LT, and the sizable long-tailed dataset SUN397, we
provide conclusive evidence that our proposed TCBC method reliably enhances the
performance of class-imbalanced semi-supervised learning.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16606" title="Abstract">arXiv:2312.16606</a> [<a href="/pdf/2312.16606" title="Download PDF">pdf</a>, <a href="/format/2312.16606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Swarm Robotics: Dynamic Subgoal-Based Path Formation and  Task Allocation for Exploration and Navigation in Unknown Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratnabala%2C+L">Lavanya Ratnabala</a>, 
<a href="/search/cs?searchtype=author&query=Peter%2C+R">Robinroy Peter</a>, 
<a href="/search/cs?searchtype=author&query=Charles%2C+E+Y+A">E.Y.A. Charles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This research paper addresses the challenges of exploration and navigation in
unknown environments from an evolutionary swarm robotics perspective. Path
formation plays a crucial role in enabling cooperative swarm robots to
accomplish these tasks. The paper presents a method called the sub-goal-based
path formation, which establishes a path between two different locations by
exploiting visually connected sub-goals. Simulation experiments conducted in
the Argos simulator demonstrate the successful formation of paths in the
majority of trials.
<br />Furthermore, the paper tackles the problem of inter-collision (traffic) among
a large number of robots engaged in path formation, which negatively impacts
the performance of the sub-goal-based method. To mitigate this issue, a task
allocation strategy is proposed, leveraging local communication protocols and
light signal-based communication. The strategy evaluates the distance between
points and determines the required number of robots for the path formation
task, reducing unwanted exploration and traffic congestion. The performance of
the sub-goal-based path formation and task allocation strategy is evaluated by
comparing path length, time, and resource reduction against the A* algorithm.
The simulation experiments demonstrate promising results, showcasing the
scalability, robustness, and fault tolerance characteristics of the proposed
approach.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16609" title="Abstract">arXiv:2312.16609</a> [<a href="/pdf/2312.16609" title="Download PDF">pdf</a>, <a href="/format/2312.16609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting hidden structures in non-convex games for convergence to Nash  equilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakos%2C+I">Iosif Sakos</a>, 
<a href="/search/cs?searchtype=author&query=Vlatakis-Gkaragkounis%2C+E">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, 
<a href="/search/cs?searchtype=author&query=Mertikopoulos%2C+P">Panayotis Mertikopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Piliouras%2C+G">Georgios Piliouras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A wide array of modern machine learning applications - from adversarial
models to multi-agent reinforcement learning - can be formulated as
non-cooperative games whose Nash equilibria represent the system's desired
operational states. Despite having a highly non-convex loss landscape, many
cases of interest possess a latent convex structure that could potentially be
leveraged to yield convergence to equilibrium. Driven by this observation, our
paper proposes a flexible first-order method that successfully exploits such
"hidden structures" and achieves convergence under minimal assumptions for the
transformation connecting the players' control variables to the game's latent,
convex-structured layer. The proposed method - which we call preconditioned
hidden gradient descent (PHGD) - hinges on a judiciously chosen gradient
preconditioning scheme related to natural gradient methods. Importantly, we
make no separability assumptions for the game's hidden structure, and we
provide explicit convergence rate guarantees for both deterministic and
stochastic environments.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16610" title="Abstract">arXiv:2312.16610</a> [<a href="/pdf/2312.16610" title="Download PDF">pdf</a>, <a href="/format/2312.16610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deweather Mixture-of-Experts with Uncertainty-aware  Feature-wise Linear Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yulin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huanrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gudovskiy%2C+D">Denis Gudovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Okuno%2C+T">Tomoyuki Okuno</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+Y">Yohei Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuan Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> aaai2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Mixture-of-Experts (MoE) approach has demonstrated outstanding
scalability in multi-task learning including low-level upstream tasks such as
concurrent removal of multiple adverse weather effects. However, the
conventional MoE architecture with parallel Feed Forward Network (FFN) experts
leads to significant parameter and computational overheads that hinder its
efficient deployment. In addition, the naive MoE linear router is suboptimal in
assigning task-specific features to multiple experts which limits its further
scalability. In this work, we propose an efficient MoE architecture with weight
sharing across the experts. Inspired by the idea of linear feature modulation
(FM), our architecture implicitly instantiates multiple experts via learnable
activation modulations on a single shared expert block. The proposed Feature
Modulated Expert (FME) serves as a building block for the novel
Mixture-of-Feature-Modulation-Experts (MoFME) architecture, which can scale up
the number of experts with low overhead. We further propose an
Uncertainty-aware Router (UaR) to assign task-specific features to different FM
modules with well-calibrated weights. This enables MoFME to effectively learn
diverse expert functions for multiple tasks. The conducted experiments on the
multi-deweather task show that our MoFME outperforms the baselines in the image
restoration quality by 0.1-0.2 dB and achieves SOTA-compatible performance
while saving more than 72% of parameters and 39% inference time over the
conventional MoE counterpart. Experiments on the downstream segmentation and
classification tasks further demonstrate the generalizability of MoFME to real
open-world applications.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16611" title="Abstract">arXiv:2312.16611</a> [<a href="/pdf/2312.16611" title="Download PDF">pdf</a>, <a href="/format/2312.16611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from small data sets: Patch-based regularizers in inverse  problems for image reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piening%2C+M">Moritz Piening</a>, 
<a href="/search/cs?searchtype=author&query=Altekr%C3%BCger%2C+F">Fabian Altekr&#xfc;ger</a>, 
<a href="/search/cs?searchtype=author&query=Hertrich%2C+J">Johannes Hertrich</a>, 
<a href="/search/cs?searchtype=author&query=Hagemann%2C+P">Paul Hagemann</a>, 
<a href="/search/cs?searchtype=author&query=Walther%2C+A">Andrea Walther</a>, 
<a href="/search/cs?searchtype=author&query=Steidl%2C+G">Gabriele Steidl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Probability (math.PR)

</div>
<p class="mathjax">The solution of inverse problems is of fundamental interest in medical and
astronomical imaging, geophysics as well as engineering and life sciences.
Recent advances were made by using methods from machine learning, in particular
deep neural networks. Most of these methods require a huge amount of (paired)
data and computer capacity to train the networks, which often may not be
available. Our paper addresses the issue of learning from small data sets by
taking patches of very few images into account. We focus on the combination of
model-based and data-driven methods by approximating just the image prior, also
known as regularizer in the variational model. We review two methodically
different approaches, namely optimizing the maximum log-likelihood of the patch
distribution, and penalizing Wasserstein-like discrepancies of whole empirical
patch distributions. From the point of view of Bayesian inverse problems, we
show how we can achieve uncertainty quantification by approximating the
posterior using Langevin Monte Carlo methods. We demonstrate the power of the
methods in computed tomography, image super-resolution, and inpainting. Indeed,
the approach provides also high-quality results in zero-shot super-resolution,
where only a low-resolution image is available. The paper is accompanied by a
GitHub repository containing implementations of all methods as well as data
examples so that the reader can get their own insight into the performance.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16612" title="Abstract">arXiv:2312.16612</a> [<a href="/pdf/2312.16612" title="Download PDF">pdf</a>, <a href="/format/2312.16612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring intra-task relations to improve meta-learning algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P">Prabhat Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shreya Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Meta-learning has emerged as an effective methodology to model several
real-world tasks and problems due to its extraordinary effectiveness in the
low-data regime. There are many scenarios ranging from the classification of
rare diseases to language modelling of uncommon languages where the
availability of large datasets is rare. Similarly, for more broader scenarios
like self-driving, an autonomous vehicle needs to be trained to handle every
situation well. This requires training the ML model on a variety of tasks with
good quality data. But often times, we find that the data distribution across
various tasks is skewed, i.e.the data follows a long-tail distribution. This
leads to the model performing well on some tasks and not performing so well on
others leading to model robustness issues. Meta-learning has recently emerged
as a potential learning paradigm which can effectively learn from one task and
generalize that learning to unseen tasks. In this study, we aim to exploit
external knowledge of task relations to improve training stability via
effective mini-batching of tasks. We hypothesize that selecting a diverse set
of tasks in a mini-batch will lead to a better estimate of the full gradient
and hence will lead to a reduction of noise in training.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16613" title="Abstract">arXiv:2312.16613</a> [<a href="/pdf/2312.16613" title="Download PDF">pdf</a>, <a href="/format/2312.16613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Pretraining for Robust Personalized Voice Activity  Detection in Adverse Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bovbjerg%2C+H+S">Holger Severin Bovbjerg</a> (1), 
<a href="/search/cs?searchtype=author&query=Jensen%2C+J">Jesper Jensen</a> (1, 2), 
<a href="/search/cs?searchtype=author&query=%C3%98stergaard%2C+J">Jan &#xd8;stergaard</a> (1), 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zheng-Hua Tan</a> (1, 3) ((1) Aalborg University, (2) Oticon, (3) Pioneer Centre for AI, Denmark)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at ICASSP2024, 14th of April 2024, Seoul, South Korea. Copyright (c) 2023 IEEE. 5 pages, 2, figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we propose the use of self-supervised pretraining on a large
unlabelled data set to improve the performance of a personalized voice activity
detection (VAD) model in adverse conditions. We pretrain a long short-term
memory (LSTM)-encoder using the autoregressive predictive coding (APC)
framework and fine-tune it for personalized VAD. We also propose a denoising
variant of APC, with the goal of improving the robustness of personalized VAD.
The trained models are systematically evaluated on both clean speech and speech
contaminated by various types of noise at different SNR-levels and compared to
a purely supervised model. Our experiments show that self-supervised
pretraining not only improves performance in clean conditions, but also yields
models which are more robust to adverse conditions compared to purely
supervised learning.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16616" title="Abstract">arXiv:2312.16616</a> [<a href="/pdf/2312.16616" title="Download PDF">pdf</a>, <a href="/ps/2312.16616" title="Download PostScript">ps</a>, <a href="/format/2312.16616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agnostically Learning Multi-index Models with Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+D+M">Daniel M. Kane</a>, 
<a href="/search/cs?searchtype=author&query=Kontonis%2C+V">Vasilis Kontonis</a>, 
<a href="/search/cs?searchtype=author&query=Tzamos%2C+C">Christos Tzamos</a>, 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+N">Nikos Zarifis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> abstract shortened due to arxiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the power of query access for the task of agnostic learning under
the Gaussian distribution. In the agnostic model, no assumptions are made on
the labels and the goal is to compute a hypothesis that is competitive with the
{\em best-fit} function in a known class, i.e., it achieves error
$\mathrm{opt}+\epsilon$, where $\mathrm{opt}$ is the error of the best function
in the class. We focus on a general family of Multi-Index Models (MIMs), which
are $d$-variate functions that depend only on few relevant directions, i.e.,
have the form $g(\mathbf{W} \mathbf{x})$ for an unknown link function $g$ and a
$k \times d$ matrix $\mathbf{W}$. Multi-index models cover a wide range of
commonly studied function classes, including constant-depth neural networks
with ReLU activations, and intersections of halfspaces.
<br />Our main result shows that query access gives significant runtime
improvements over random examples for agnostically learning MIMs. Under
standard regularity assumptions for the link function (namely, bounded
variation or surface area), we give an agnostic query learner for MIMs with
complexity $O(k)^{\mathrm{poly}(1/\epsilon)} \; \mathrm{poly}(d) $. In
contrast, algorithms that rely only on random examples inherently require
$d^{\mathrm{poly}(1/\epsilon)}$ samples and runtime, even for the basic problem
of agnostically learning a single ReLU or a halfspace.
<br />Our algorithmic result establishes a strong computational separation between
the agnostic PAC and the agnostic PAC+Query models under the Gaussian
distribution. Prior to our work, no such separation was known -- even for the
special case of agnostically learning a single halfspace, for which it was an
open problem first posed by Feldman. Our results are enabled by a general
dimension-reduction technique that leverages query access to estimate gradients
of (a smoothed version of) the underlying label function.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16619" title="Abstract">arXiv:2312.16619</a> [<a href="/pdf/2312.16619" title="Download PDF">pdf</a>, <a href="/format/2312.16619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the security of CRYSTALS-Dilithium in the quantum random  oracle model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+K+A">Kelsey A. Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+C+A">Carl A. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daochen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">In the wake of recent progress on quantum computing hardware, the National
Institute of Standards and Technology (NIST) is standardizing cryptographic
protocols that are resistant to attacks by quantum adversaries. The primary
digital signature scheme that NIST has chosen is CRYSTALS-Dilithium. The
hardness of this scheme is based on the hardness of three computational
problems: Module Learning with Errors (MLWE), Module Short Integer Solution
(MSIS), and SelfTargetMSIS. MLWE and MSIS have been well-studied and are widely
believed to be secure. However, SelfTargetMSIS is novel and, though classically
as hard as MSIS, its quantum hardness is unclear. In this paper, we provide the
first proof of the hardness of SelfTargetMSIS via a reduction from MLWE in the
Quantum Random Oracle Model (QROM). Our proof uses recently developed
techniques in quantum reprogramming and rewinding. A central part of our
approach is a proof that a certain hash function, derived from the MSIS
problem, is collapsing. From this approach, we deduce a new security proof for
Dilithium under appropriate parameter settings. Compared to the only other
rigorous security proof for a variant of Dilithium, Dilithium-QROM, our proof
has the advantage of being applicable under the condition q = 1 mod 2n, where q
denotes the modulus and n the dimension of the underlying algebraic ring. This
condition is part of the original Dilithium proposal and is crucial for the
efficient implementation of the scheme. We provide new secure parameter sets
for Dilithium under the condition q = 1 mod 2n, finding that our public key
sizes and signature sizes are about 2.5 to 2.8 times larger than those of
Dilithium-QROM for the same security levels.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16620" title="Abstract">arXiv:2312.16620</a> [<a href="/pdf/2312.16620" title="Download PDF">pdf</a>, <a href="/format/2312.16620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Driving using Residual Sensor Fusion and Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aghdasian%2C+A+J">Amin Jalal Aghdasian</a>, 
<a href="/search/eess?searchtype=author&query=Ardakani%2C+A+H">Amirhossein Heydarian Ardakani</a>, 
<a href="/search/eess?searchtype=author&query=Aqabakee%2C+K">Kianoush Aqabakee</a>, 
<a href="/search/eess?searchtype=author&query=Abdollahi%2C+F">Farzaneh Abdollahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper on International Conference on Robotics and Mechatronics (ICROM, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a novel approach by integrating sensor fusion with deep
reinforcement learning, specifically the Soft Actor-Critic (SAC) algorithm, to
develop an optimal control policy for self-driving cars. Our system employs a
two-branch fusion method for vehicle image and tracking sensor data, leveraging
the strengths of residual structures and identity mapping to enhance agent
training. Through comprehensive comparisons, we demonstrate the efficacy of
information fusion and establish the superiority of our selected algorithm over
alternative approaches. Our work advances the field of autonomous driving and
demonstrates the potential of reinforcement learning in enabling intelligent
vehicle decision-making.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16621" title="Abstract">arXiv:2312.16621</a> [<a href="/pdf/2312.16621" title="Download PDF">pdf</a>, <a href="/ps/2312.16621" title="Download PostScript">ps</a>, <a href="/format/2312.16621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Functional Artificial Noise (DFAN) Aided Robust Covert  Communications in Integrated Sensing and Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Runzhe Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Long Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lv Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates covert communications in an integrated sensing and
communications system, where a dual-functional base station (called Alice)
covertly transmits signals to a covert user (called Bob) while sensing multiple
targets, with one of them acting as a potential watcher (called Willie) and
maliciously eavesdropping on legitimate communications. To shelter the covert
communications, Alice transmits additional dual-functional artificial noise
(DFAN) with a varying power not only to create uncertainty at Willie's signal
reception to confuse Willie but also to sense the targets simultaneously. Based
on this framework, the weighted sum of the sensing beampattern means square
error (MSE) and cross correlation is minimized by jointly optimizing the covert
communication and DFAN signals subject to the minimum covert rate requirement.
The robust design considers both cases of imperfect Willie's CSI (WCSI) and
statistical WCSI. Under the worst-case assumption that Willie can adaptively
adjust the detection threshold to achieve the best detection performance, the
minimum detection error probability (DEP) at Willie is analytically derived in
the closed-form expression. The formulated covertness constrained optimization
problems are tackled by a feasibility-checking based difference-of-convex
relaxation (DC) algorithm utilizing the S-procedure, Bernstein-type inequality,
and the DC method. Simulation results validate the feasibility of the proposed
scheme and demonstrate the covertness performance gains achieved by our
proposed design over various benchmarks.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16623" title="Abstract">arXiv:2312.16623</a> [<a href="/pdf/2312.16623" title="Download PDF">pdf</a>, <a href="/format/2312.16623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make BERT-based Chinese Spelling Check Model Enhanced by Layerwise  Attention and Gaussian Mixture Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yongchang Cao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xinyu Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 2023 International Joint Conference on Neural Networks (IJCNN)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Joint Conference on Neural Networks (IJCNN),
  Gold Coast, Australia, 2023, pp. 1-9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">BERT-based models have shown a remarkable ability in the Chinese Spelling
Check (CSC) task recently. However, traditional BERT-based methods still suffer
from two limitations. First, although previous works have identified that
explicit prior knowledge like Part-Of-Speech (POS) tagging can benefit in the
CSC task, they neglected the fact that spelling errors inherent in CSC data can
lead to incorrect tags and therefore mislead models. Additionally, they ignored
the correlation between the implicit hierarchical information encoded by BERT's
intermediate layers and different linguistic phenomena. This results in
sub-optimal accuracy. To alleviate the above two issues, we design a
heterogeneous knowledge-infused framework to strengthen BERT-based CSC models.
To incorporate explicit POS knowledge, we utilize an auxiliary task strategy
driven by Gaussian mixture model. Meanwhile, to incorporate implicit
hierarchical linguistic knowledge within the encoder, we propose a novel form
of n-gram-based layerwise self-attention to generate a multilayer
representation. Experimental results show that our proposed framework yields a
stable performance boost over four strong baseline models and outperforms the
previous state-of-the-art methods on two datasets.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16626" title="Abstract">arXiv:2312.16626</a> [<a href="/pdf/2312.16626" title="Download PDF">pdf</a>, <a href="/format/2312.16626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorting of Smartphone Components for Recycling Through Convolutional  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+%C3%81+G">&#xc1;lvaro G. Becker</a>, 
<a href="/search/cs?searchtype=author&query=Cenci%2C+M+P">Marcelo P. Cenci</a>, 
<a href="/search/cs?searchtype=author&query=da+Silveira%2C+T+L+T">Thiago L. T. da Silveira</a>, 
<a href="/search/cs?searchtype=author&query=Veit%2C+H+M">Hugo M. Veit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recycling of waste electrical and electronic equipment is an essential
tool in allowing for a circular economy, presenting the potential for
significant environmental and economic gain. However, traditional material
separation techniques, based on physical and chemical processes, require
substantial investment and do not apply to all cases. In this work, we
investigate using an image classification neural network as a potential means
to control an automated material separation process in treating smartphone
waste, acting as a more efficient, less costly, and more widely applicable
alternative to existing tools. We produced a dataset with 1,127 images of
pyrolyzed smartphone components, which was then used to train and assess a
VGG-16 image classification model. The model achieved 83.33% accuracy, lending
credence to the viability of using such a neural network in material
separation.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16627" title="Abstract">arXiv:2312.16627</a> [<a href="/pdf/2312.16627" title="Download PDF">pdf</a>, <a href="/format/2312.16627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIM4DD: Mutual Information Maximization for Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Dataset distillation (DD) aims to synthesize a small dataset whose test
performance is comparable to a full dataset using the same model.
State-of-the-art (SoTA) methods optimize synthetic datasets primarily by
matching heuristic indicators extracted from two networks: one from real data
and one from synthetic data (see Fig.1, Left), such as gradients and training
trajectories. DD is essentially a compression problem that emphasizes
maximizing the preservation of information contained in the data. We argue that
well-defined metrics which measure the amount of shared information between
variables in information theory are necessary for success measurement but are
never considered by previous works. Thus, we introduce mutual information (MI)
as the metric to quantify the shared information between the synthetic and the
real datasets, and devise MIM4DD numerically maximizing the MI via a newly
designed optimizable objective within a contrastive learning framework to
update the synthetic dataset. Specifically, we designate the samples in
different datasets that share the same labels as positive pairs and vice versa
negative pairs. Then we respectively pull and push those samples in positive
and negative pairs into contrastive space via minimizing NCE loss. As a result,
the targeted MI can be transformed into a lower bound represented by feature
maps of samples, which is numerically feasible. Experiment results show that
MIM4DD can be implemented as an add-on module to existing SoTA DD methods.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16629" title="Abstract">arXiv:2312.16629</a> [<a href="/pdf/2312.16629" title="Download PDF">pdf</a>, <a href="/format/2312.16629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Docking Method via Non-linear Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saputra%2C+R+P">Roni Permana Saputra</a>, 
<a href="/search/cs?searchtype=author&query=Mirdanies%2C+M">Midriem Mirdanies</a>, 
<a href="/search/cs?searchtype=author&query=Pristianto%2C+E+J">Eko Joni Pristianto</a>, 
<a href="/search/cs?searchtype=author&query=Kurniawan%2C+D">Dayat Kurniawan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Conference on Radar, Antenna, Microwave,
  Electronics, and Telecommunications (ICRAMET), Bandung, Indonesia, 2023, pp.
  331-336
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a proposed method of autonomous control for docking tasks
of a single-seat personal mobility vehicle. We proposed a non-linear model
predictive control (NMPC) based visual servoing to achieves the desired
autonomous docking task. The proposed method is implemented on a four-wheel
electric wheelchair platform, with two independent rear driving wheels and two
front castor wheels. The NMPC-based visual servoing technique leverages the
information extracted from a visual sensor as a real-time feedback for the NMPC
to control the motion of the vehicle achieving the desired autonomous docking
task. To evaluate the performance of the proposed controller method, a number
of experiments both in simulation and in the actual setting. The controller
performance is then evaluated based on the controller design requirement. The
simulation results on autonomous docking experiments show that the proposed
controller has been successfully achieve the desired controller design
requirement to generate realtime trajectory for the vehicle performing
autonomous docking tasks in several different scenarios.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16633" title="Abstract">arXiv:2312.16633</a> [<a href="/pdf/2312.16633" title="Download PDF">pdf</a>, <a href="/ps/2312.16633" title="Download PostScript">ps</a>, <a href="/format/2312.16633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Participatory prompting: a user-centric research method for eliciting AI  assistance opportunities in knowledge workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Advait Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Drosos%2C+I">Ian Drosos</a>, 
<a href="/search/cs?searchtype=author&query=Deline%2C+R">Rob Deline</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+A+D">Andrew D. Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Negreanu%2C+C">Carina Negreanu</a>, 
<a href="/search/cs?searchtype=author&query=Rintel%2C+S">Sean Rintel</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+J">Jack Williams</a>, 
<a href="/search/cs?searchtype=author&query=Zorn%2C+B">Benjamin Zorn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 34th Annual Conference of the Psychology of Programming Interest Group (PPIG 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 34th Annual Conference of the Psychology of
  Programming Interest Group (PPIG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Generative AI, such as image generation models and large language models,
stands to provide tremendous value to end-user programmers in creative and
knowledge workflows. Current research methods struggle to engage end-users in a
realistic conversation that balances the actually existing capabilities of
generative AI with the open-ended nature of user workflows and the many
opportunities for the application of this technology. In this work-in-progress
paper, we introduce participatory prompting, a method for eliciting
opportunities for generative AI in end-user workflows. The participatory
prompting method combines a contextual inquiry and a researcher-mediated
interaction with a generative model, which helps study participants interact
with a generative model without having to develop prompting strategies of their
own. We discuss the ongoing development of a study whose aim will be to
identify end-user programming opportunities for generative AI in data analysis
workflows.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16634" title="Abstract">arXiv:2312.16634</a> [<a href="/pdf/2312.16634" title="Download PDF">pdf</a>, <a href="/ps/2312.16634" title="Download PostScript">ps</a>, <a href="/format/2312.16634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Gray Literature to Influence Software Engineering Curricula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiper%2C+J+D">James D Kiper</a>, 
<a href="/search/cs?searchtype=author&query=Sultana%2C+S">Simon Sultana</a>, 
<a href="/search/cs?searchtype=author&query=Auernheimer%2C+B">Brent Auernheimer</a>, 
<a href="/search/cs?searchtype=author&query=Walia%2C+G+S">Gursimran Singh Walia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Software engineering (SE) evolves rapidly, with changing technology and
industry expectations. The curriculum review bodies (e.g., ACM and IEEE-CS
working groups) respond well but can have refresh cycles measured in years. For
Computer Science and SE educators to be agile, predictive, and adapt to
changing technology trends, judicious use of gray literature (GL) can be
helpful. Other fields have found GL useful in bridging academic research and
industry needs. GL can be extended to SE to aid faculty preparing students for
industry.
<br />We address two questions: first, given the velocity of technical change, do
current curricular guidelines accurately reflect industry practice and need for
our graduates? Second, how can we track current and emerging trends to capture
relevant competencies? We argue a study of the scholarly literature will have a
limited impact on our understanding of current and emerging trends and
curriculum designers would do well to utilize GL. We close with recommendations
for SE educators.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16638" title="Abstract">arXiv:2312.16638</a> [<a href="/pdf/2312.16638" title="Download PDF">pdf</a>, <a href="/format/2312.16638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault-Tolerant Vertical Federated Learning on Dynamic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+S">Surojit Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zeyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>, 
<a href="/search/cs?searchtype=author&query=Inouye%2C+D+I">David I. Inouye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Vertical Federated learning (VFL) is a class of FL where each client shares
the same sample space but only holds a subset of the features. While VFL
tackles key privacy challenges of distributed learning, it often assumes
perfect hardware and communication capabilities. This assumption hinders the
broad deployment of VFL, particularly on edge devices, which are heterogeneous
in their in-situ capabilities and will connect/disconnect from the network over
time. To address this gap, we define Internet Learning (IL) including its data
splitting and network context and which puts good performance under extreme
dynamic condition of clients as the primary goal. We propose VFL as a naive
baseline and develop several extensions to handle the IL paradigm of learning.
Furthermore, we implement new methods, propose metrics, and extensively analyze
results based on simulating a sensor network. The results show that the
developed methods are more robust to changes in the network than VFL baseline.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16648" title="Abstract">arXiv:2312.16648</a> [<a href="/pdf/2312.16648" title="Download PDF">pdf</a>, <a href="/format/2312.16648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIP-Loc: LiDAR Image Pretraining for Cross-Modal Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puligilla%2C+S+S">Sai Shubodh Puligilla</a>, 
<a href="/search/cs?searchtype=author&query=Omama%2C+M">Mohammad Omama</a>, 
<a href="/search/cs?searchtype=author&query=Zaidi%2C+H">Husain Zaidi</a>, 
<a href="/search/cs?searchtype=author&query=Parihar%2C+U+S">Udit Singh Parihar</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+M">Madhava Krishna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at WACV-W 2024. Project page: <a href="https://shubodhs.ai/liploc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Global visual localization in LiDAR-maps, crucial for autonomous driving
applications, remains largely unexplored due to the challenging issue of
bridging the cross-modal heterogeneity gap. Popular multi-modal learning
approach Contrastive Language-Image Pre-Training (CLIP) has popularized
contrastive symmetric loss using batch construction technique by applying it to
multi-modal domains of text and image. We apply this approach to the domains of
2D image and 3D LiDAR points on the task of cross-modal localization. Our
method is explained as follows: A batch of N (image, LiDAR) pairs is
constructed so as to predict what is the right match between N X N possible
pairings across the batch by jointly training an image encoder and LiDAR
encoder to learn a multi-modal embedding space. In this way, the cosine
similarity between N positive pairings is maximized, whereas that between the
remaining negative pairings is minimized. Finally, over the obtained similarity
scores, a symmetric cross-entropy loss is optimized. To the best of our
knowledge, this is the first work to apply batched loss approach to a
cross-modal setting of image &amp; LiDAR data and also to show Zero-shot transfer
in a visual localization setting. We conduct extensive analyses on standard
autonomous driving datasets such as KITTI and KITTI-360 datasets. Our method
outperforms state-of-the-art recall@1 accuracy on the KITTI-360 dataset by
22.4%, using only perspective images, in contrast to the state-of-the-art
approach, which utilizes the more informative fisheye images. Additionally,
this superior performance is achieved without resorting to complex
architectures. Moreover, we demonstrate the zero-shot capabilities of our model
and we beat SOTA by 8% without even training on it. Furthermore, we establish
the first benchmark for cross-modal localization on the KITTI dataset.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16649" title="Abstract">arXiv:2312.16649</a> [<a href="/pdf/2312.16649" title="Download PDF">pdf</a>, <a href="/format/2312.16649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forgery-aware Adaptive Transformer for Generalizable Synthetic Image  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zichang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuangchuang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we study the problem of generalizable synthetic image
detection, aiming to detect forgery images from diverse generative methods,
e.g., GANs and diffusion models. Cutting-edge solutions start to explore the
benefits of pre-trained models, and mainly follow the fixed paradigm of solely
training an attached classifier, e.g., combining frozen CLIP-ViT with a
learnable linear layer in UniFD. However, our analysis shows that such a fixed
paradigm is prone to yield detectors with insufficient learning regarding
forgery representations. We attribute the key challenge to the lack of forgery
adaptation, and present a novel forgery-aware adaptive transformer approach,
namely FatFormer. Based on the pre-trained vision-language spaces of CLIP,
FatFormer introduces two core designs for the adaption to build generalized
forgery representations. First, motivated by the fact that both image and
frequency analysis are essential for synthetic image detection, we develop a
forgery-aware adapter to adapt image features to discern and integrate local
forgery traces within image and frequency domains. Second, we find that
considering the contrastive objectives between adapted image features and text
prompt embeddings, a previously overlooked aspect, results in a nontrivial
generalization improvement. Accordingly, we introduce language-guided alignment
to supervise the forgery adaptation with image and text prompts in FatFormer.
Experiments show that, by coupling these two designs, our approach tuned on
4-class ProGAN data attains a remarkable detection performance, achieving an
average of 98% accuracy to unseen GANs, and surprisingly generalizes to unseen
diffusion models with 95% accuracy.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16652" title="Abstract">arXiv:2312.16652</a> [<a href="/pdf/2312.16652" title="Download PDF">pdf</a>, <a href="/ps/2312.16652" title="Download PostScript">ps</a>, <a href="/format/2312.16652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant-based Program Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Bataineh%2C+O+I">Omar I. Al-Bataineh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 27th International Conference on Fundamental Approaches to Software Engineering (FASE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper describes a formal general-purpose automated program repair (APR)
framework based on the concept of program invariants. In the presented repair
framework, the execution traces of a defected program are dynamically analyzed
to infer specifications $\varphi_{correct}$ and $\varphi_{violated}$, where
$\varphi_{correct}$ represents the set of likely invariants (good patterns)
required for a run to be successful and $\varphi_{violated}$ represents the set
of likely suspicious invariants (bad patterns) that result in the bug in the
defected program. These specifications are then refined using rigorous program
analysis techniques, which are also used to drive the repair process towards
feasible patches and assess the correctness of generated patches.We demonstrate
the usefulness of leveraging invariants in APR by developing an invariant-based
repair system for performance bugs. The initial analysis shows the
effectiveness of invariant-based APR in handling performance bugs by producing
patches that ensure program's efficiency increase without adversely impacting
its functionality.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16653" title="Abstract">arXiv:2312.16653</a> [<a href="/pdf/2312.16653" title="Download PDF">pdf</a>, <a href="/format/2312.16653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Balanced Solutions for Large International Kidney Exchange  Schemes When Cycle Length Is Unbounded
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benedek%2C+M">M&#xe1;rton Benedek</a>, 
<a href="/search/cs?searchtype=author&query=Bir%C3%B3%2C+P">P&#xe9;ter Bir&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Cs%C3%A1ji%2C+G">Gergely Cs&#xe1;ji</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M">Matthew Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Paulusma%2C+D">Dani&#xeb;l Paulusma</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xin Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In kidney exchange programmes (KEP) patients may swap their incompatible
donors leading to cycles of kidney transplants. Nowadays, countries try to
merge their national patient-donor pools leading to international KEPs (IKEPs).
As shown in the literature, long-term stability of an IKEP can be achieved
through a credit-based system. In each round, every country is prescribed a
"fair" initial allocation of kidney transplants. The initial allocation, which
we obtain by using solution concepts from cooperative game theory, is adjusted
by incorporating credits from the previous round, yielding the target
allocation. The goal is to find, in each round, an optimal solution that
closely approximates this target allocation. There is a known polynomial-time
algorithm for finding an optimal solution that lexicographically minimizes the
country deviations from the target allocation if only $2$-cycles (matchings)
are permitted. In practice, kidney swaps along longer cycles may be performed.
However, the problem of computing optimal solutions for maximum cycle length
$\ell$ is NP-hard for every $\ell\geq 3$. This situation changes back to
polynomial time once we allow unbounded cycle length. However, in contrast to
the case where $\ell=2$, we show that for $\ell=\infty$, lexicographical
minimization is only polynomial-time solvable under additional conditions
(assuming P $\neq$ NP). Nevertheless, the fact that the optimal solutions
themselves can be computed in polynomial time if $\ell=\infty$ still enables us
to perform a large scale experimental study for showing how stability and total
social welfare are affected when we set $\ell=\infty$ instead of $\ell=2$.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16659" title="Abstract">arXiv:2312.16659</a> [<a href="/pdf/2312.16659" title="Download PDF">pdf</a>, <a href="/ps/2312.16659" title="Download PostScript">ps</a>, <a href="/format/2312.16659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large Language Model-based Computational Approach to Improve  Identity-Related Write-Ups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doboli%2C+A">Alex Doboli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Creating written products is essential to modern life, including writings
about one's identity and personal experiences. However, writing is often a
difficult activity that requires extensive effort to frame the central ideas,
the pursued approach to communicate the central ideas, e.g., using analogies,
metaphors, or other possible means, the needed presentation structure, and the
actual verbal expression. Large Language Models, a recently emerged approach in
Machine Learning, can offer a significant help in reducing the effort and
improving the quality of written products. This paper proposes a new
computational approach to explore prompts that given as inputs to a Large
Language Models can generate cues to improve the considered written products.
Two case studies on improving write-ups, one based on an analogy and one on a
metaphor, are also presented in the paper.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16682" title="Abstract">arXiv:2312.16682</a> [<a href="/pdf/2312.16682" title="Download PDF">pdf</a>, <a href="/format/2312.16682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some things are more CRINGE than others: Preference Optimization with  the Pairwise Cringe Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Andrew Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sukhbaatar%2C+S">Sainbayar Sukhbaatar</a>, 
<a href="/search/cs?searchtype=author&query=Weston%2C+J">Jason Weston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Practitioners commonly align large language models using pairwise
preferences, i.e., given labels of the type response A is preferred to response
B for a given input. Perhaps less commonly, methods have also been developed
for binary feedback, i.e. training models given labels of type response A is
good or bad. We show how an existing performant binary feedback method, the
Cringe Loss (Adolphs et al., 2022), can be generalized to the pairwise
preference setting using a simple soft margin extension. Pairwise Cringe Loss
is straightforward to implement and efficient to train, and we find it
outperforms state-of-the-art preference optimization algorithms such as PPO and
DPO on the AlpacaFarm benchmark.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16690" title="Abstract">arXiv:2312.16690</a> [<a href="/pdf/2312.16690" title="Download PDF">pdf</a>, <a href="/format/2312.16690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resonance based schemes for SPDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bruned%2C+Y">Yvain Bruned</a>, 
<a href="/search/math?searchtype=author&query=Armstrong-Goodall%2C+J">Jacob Armstrong-Goodall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Probability (math.PR)

</div>
<p class="mathjax">Resonance based numerical schemes are those in which cancellations in the
oscillatory components of the equation are taken advantage of in order to
reduce the regularity required of the initial data to achieve a particular
order of error and convergence. We investigate the potential for the derivation
of resonance based schemes in the context of nonlinear stochastic PDEs. By
comparing the regularity conditions required for error analysis to traditional
exponential schemes we demonstrate that at orders less than $ \mathcal{O}(t^2)
$, the techniques are successful and provide a significant gain on the
regularity of the initial data, while at orders greater than $ \mathcal{O}(t^2)
$, that the resonance based techniques does not achieve any gain. This is due
to limitations in the explicit path-wise analysis of stochastic integrals. As
examples of applications of the method, we present schemes for the Sch\"odinger
equation and Manakov system accompanied by local error and stability analysis
as well as proof of global convergence in both the strong and path-wise sense.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16693" title="Abstract">arXiv:2312.16693</a> [<a href="/pdf/2312.16693" title="Download PDF">pdf</a>, <a href="/format/2312.16693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I2V-Adapter: A General Image-to-Video Adapter for Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mingwu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yufan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zhengjun Zha</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haibin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the rapidly evolving domain of digital content generation, the focus has
shifted from text-to-image (T2I) models to more advanced video diffusion
models, notably text-to-video (T2V) and image-to-video (I2V). This paper
addresses the intricate challenge posed by I2V: converting static images into
dynamic, lifelike video sequences while preserving the original image fidelity.
Traditional methods typically involve integrating entire images into diffusion
processes or using pretrained encoders for cross attention. However, these
approaches often necessitate altering the fundamental weights of T2I models,
thereby restricting their reusability. We introduce a novel solution, namely
I2V-Adapter, designed to overcome such limitations. Our approach preserves the
structural integrity of T2I models and their inherent motion modules. The
I2V-Adapter operates by processing noised video frames in parallel with the
input image, utilizing a lightweight adapter module. This module acts as a
bridge, efficiently linking the input to the model's self-attention mechanism,
thus maintaining spatial details without requiring structural changes to the
T2I model. Moreover, I2V-Adapter requires only a fraction of the parameters of
conventional models and ensures compatibility with existing community-driven
T2I models and controlling tools. Our experimental results demonstrate
I2V-Adapter's capability to produce high-quality video outputs. This
performance, coupled with its versatility and reduced need for trainable
parameters, represents a substantial advancement in the field of AI-driven
video generation, particularly for creative applications.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16694" title="Abstract">arXiv:2312.16694</a> [<a href="/pdf/2312.16694" title="Download PDF">pdf</a>, <a href="/ps/2312.16694" title="Download PostScript">ps</a>, <a href="/format/2312.16694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denotational semantics for languages for inference: semirings, monads,  and tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matache%2C+C">Cristina Matache</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+S">Sean Moss</a>, 
<a href="/search/cs?searchtype=author&query=Staton%2C+S">Sam Staton</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+A+S">Ariadne Si Suo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, LAFI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL); Category Theory (math.CT)

</div>
<p class="mathjax">Computational effects are commonly modelled by monads, but often a monad can
be presented by an algebraic theory of operations and equations. This talk is
about monads and algebraic theories for languages for inference, and their
connections to semirings and tensors.
<br />A basic class of examples of algebraic theories comes from considering the
theory of modules for a semiring, e.g. the theory of unnormalized
distributions, where the semiring is that of the non-negative real numbers. We
propose that an interesting perspective is given by studying theories via
semirings, and to this end explore several examples of subtheories of module
theories, mostly relating to probability. Our main contribution concerns the
commutative combination of effects, as studied by Hyland, Plotkin and Power: we
observe that while the semiring tensor does not in general determine the tensor
of subtheories of module theories, it still does in several fundamental
probabilistic examples.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16695" title="Abstract">arXiv:2312.16695</a> [<a href="/pdf/2312.16695" title="Download PDF">pdf</a>, <a href="/format/2312.16695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Comparison of Session-based Recommendation Algorithms based  on GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shehzad%2C+F">Faisal Shehzad</a>, 
<a href="/search/cs?searchtype=author&query=Jannach%2C+D">Dietmar Jannach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In session-based recommendation settings, a recommender system has to base
its suggestions on the user interactions that are ob served in an ongoing
session. Since such sessions can consist of only a small set of interactions,
various approaches based on Graph Neural Networks (GNN) were recently proposed,
as they allow us to integrate various types of side information about the items
in a natural way. Unfortunately, a variety of evaluation settings are used in
the literature, e.g., in terms of protocols, metrics and baselines, making it
difficult to assess what represents the state of the art. In this work, we
present the results of an evaluation of eight recent GNN-based approaches that
were published in high-quality outlets. For a fair comparison, all models are
systematically tuned and tested under identical conditions using three common
datasets. We furthermore include k-nearest-neighbor and sequential rules-based
models as baselines, as such models have previously exhibited competitive
performance results for similar settings. To our surprise, the evaluation
showed that the simple models outperform all recent GNN models in terms of the
Mean Reciprocal Rank, which we used as an optimization criterion, and were only
outperformed in three cases in terms of the Hit Rate. Additional analyses
furthermore reveal that several other factors that are often not deeply
discussed in papers, e.g., random seeds, can markedly impact the performance of
GNN-based models. Our results therefore (a) point to continuing issues in the
community in terms of research methodology and (b) indicate that there is ample
room for improvement in session-based recommendation.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16697" title="Abstract">arXiv:2312.16697</a> [<a href="/pdf/2312.16697" title="Download PDF">pdf</a>, <a href="/format/2312.16697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-channel Sensor Network Construction, Data Fusion and Challenges  for Smart Home
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ananda%2C+R">Robin Ananda</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted by CHCHI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Both sensor networks and data fusion are essential foundations for developing
the smart home Internet of Things (IoT) and related fields. We proposed a
multi-channel sensor network construction method involving hardware,
acquisition, and synchronization in the smart home environment and a smart home
data fusion method (SHDFM) for multi-modal data (position, gait, voice, pose,
facial expression, temperature, and humidity) generated in the smart home
environment to address the configuration of a multi-channel sensor network,
improve the quality and efficiency of various human activities and
environmental data collection, and reduce the difficulty of multi-modal data
fusion in the smart home. SHDFM contains 5 levels, with inputs and outputs as
criteria to provide recommendations for multi-modal data fusion strategies in
the smart home. We built a real experimental environment using the proposed
method in this paper. To validate our method, we created a real experimental
environment - a physical setup in a home-like scenario where the multi-channel
sensor network and data fusion techniques were deployed and evaluated. The
acceptance and testing results show that the proposed construction and data
fusion methods can be applied to the examples with high robustness,
replicability, and scalability. Besides, we discuss how smart homes with
multi-channel sensor networks can support digital twins.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16702" title="Abstract">arXiv:2312.16702</a> [<a href="/pdf/2312.16702" title="Download PDF">pdf</a>, <a href="/format/2312.16702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Tabular Data Understanding with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown to be capable of various tasks, yet
their capability in interpreting and reasoning over tabular data remains an
underexplored area. In this context, this study investigates from three core
perspectives: the robustness of LLMs to structural perturbations in tables, the
comparative analysis of textual and symbolic reasoning on tables, and the
potential of boosting model performance through the aggregation of multiple
reasoning pathways. We discover that structural variance of tables presenting
the same content reveals a notable performance decline, particularly in
symbolic reasoning tasks. This prompts the proposal of a method for table
structure normalization. Moreover, textual reasoning slightly edges out
symbolic reasoning, and a detailed error analysis reveals that each exhibits
different strengths depending on the specific tasks. Notably, the aggregation
of textual and symbolic reasoning pathways, bolstered by a mix self-consistency
mechanism, resulted in achieving SOTA performance, with an accuracy of 73.6% on
WIKITABLEQUESTIONS, representing a substantial advancement over previous
existing table processing paradigms of LLMs.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16704" title="Abstract">arXiv:2312.16704</a> [<a href="/pdf/2312.16704" title="Download PDF">pdf</a>, <a href="/format/2312.16704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Granular Representation of Fuzzy Quantifier-Based Fuzzy Rough  Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theerens%2C+A">Adnan Theerens</a>, 
<a href="/search/cs?searchtype=author&query=Cornelis%2C+C">Chris Cornelis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Rough set theory is a well-known mathematical framework that can deal with
inconsistent data by providing lower and upper approximations of concepts. A
prominent property of these approximations is their granular representation:
that is, they can be written as unions of simple sets, called granules. The
latter can be identified with "if. . . , then. . . " rules, which form the
backbone of rough set rule induction. It has been shown previously that this
property can be maintained for various fuzzy rough set models, including those
based on ordered weighted average (OWA) operators. In this paper, we will focus
on some instances of the general class of fuzzy quantifier-based fuzzy rough
sets (FQFRS). In these models, the lower and upper approximations are evaluated
using binary and unary fuzzy quantifiers, respectively. One of the main targets
of this study is to examine the granular representation of different models of
FQFRS. The main findings reveal that Choquet-based fuzzy rough sets can be
represented granularly under the same conditions as OWA-based fuzzy rough sets,
whereas Sugeno-based FRS can always be represented granularly. This observation
highlights the potential of these models for resolving data inconsistencies and
managing noise.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16705" title="Abstract">arXiv:2312.16705</a> [<a href="/pdf/2312.16705" title="Download PDF">pdf</a>, <a href="/format/2312.16705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic model of tissue electroporation on the basis of biological  dispersion and Joule heating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guedert%2C+R">Raul Guedert</a> (1), 
<a href="/search/eess?searchtype=author&query=Andrade%2C+D+L+L+S">Daniella L.L.S. Andrade</a> (1), 
<a href="/search/eess?searchtype=author&query=Rodrigues%2C+J">J&#xe9;ssica Rodrigues</a> (1), 
<a href="/search/eess?searchtype=author&query=Pintarelli%2C+G+B">Guilherme B. Pintarelli</a> (2), 
<a href="/search/eess?searchtype=author&query=Suzuki%2C+D+O+H">Daniela O. H. Suzuki</a> (1) ((1) Institute of Biomedical Engineering, Federal University of Santa Catarina, (2) Department of Control, Automation and Computer Engineering, Federal University of Santa Catarina)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Electroporation is a complex, iterative and nonlinear phenomenon that is
often studied by numerical simulations. In recent years, simulations of tissue
electroporation have been performed using static model. However, the static
model simulation results are restrained to a fixed protocol signature of the
pulsed electric field. This paper describes a novel dynamic model of tissue
electroporation which also includes tissue dispersion and temperature. We
described the biological dispersion of potato tubers in a commercial finite
element method software. A cell electroporation model was adapted to account
for the increase in tissue conductivity. The model yielded twelve parameters,
divided into three dynamic states of electroporation. Thermal analysis
describes the dependence of tissue conductivity on temperature. The model
parameters were evaluated through experiments with vegetal tissue (Solanum
tuberosum) under electrochemotherapy protocols. The proposed model can
accurately predict the conductivity of tissue under electroporation from 10
kV/m to 100 kV/m. A negligible thermal effect was observed at 100 kV/m, with a
0.89 {\deg}C increase. We believe that the proposed model is suitable for
describing the electroporation current on a tissue scale and also a hint on the
cell membrane nanoscale effects.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16713" title="Abstract">arXiv:2312.16713</a> [<a href="/pdf/2312.16713" title="Download PDF">pdf</a>, <a href="/format/2312.16713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Enhanced Conditional Imputation for Healthcare Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Linglong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+Z">Zina Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+H+L">Hugh Logan Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuezhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dobson%2C+R">Richard Dobson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study presents a novel approach to addressing the challenge of missing
data in multivariate time series, with a particular focus on the complexities
of healthcare data. Our Conditional Self-Attention Imputation (CSAI) model,
grounded in a transformer-based framework, introduces a conditional hidden
state initialization tailored to the intricacies of medical time series data.
This methodology diverges from traditional imputation techniques by
specifically targeting the imbalance in missing data distribution, a crucial
aspect often overlooked in healthcare datasets. By integrating advanced
knowledge embedding and a non-uniform masking strategy, CSAI adeptly adjusts to
the distinct patterns of missing data in Electronic Health Records (EHRs).
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16714" title="Abstract">arXiv:2312.16714</a> [<a href="/pdf/2312.16714" title="Download PDF">pdf</a>, <a href="/ps/2312.16714" title="Download PostScript">ps</a>, <a href="/format/2312.16714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reversible Perspective on Petri Nets and Event Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melgratti%2C+H">Hern&#xe1;n Melgratti</a>, 
<a href="/search/cs?searchtype=author&query=Mezzina%2C+C+A">Claudio Antares Mezzina</a>, 
<a href="/search/cs?searchtype=author&query=Pinna%2C+G+M">G. Michele Pinna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Event structures have emerged as a foundational model for concurrent
computation, explaining computational processes by outlining the events and the
relationships that dictate their execution. They play a pivotal role in the
study of key aspects of concurrent computation models, such as causality and
independence, and have found applications across a broad range of languages and
models, spanning realms like persistence, probabilities, and quantum computing.
Recently, event structures have been extended to address reversibility, where
computational processes can undo previous computations. In this context,
reversible event structures provide abstract representations of processes
capable of both forward and backward steps in a computation. Since their
introduction, event structures have played a crucial role in bridging
operational models, traditionally exemplified by Petri nets and process
calculi, with denotational ones, i.e., algebraic domains. In this context, we
revisit the standard connection between Petri nets and event structures under
the lenses of reversibility. Specifically, we introduce a subset of contextual
Petri nets, dubbed reversible causal nets, that precisely correspond to
reversible prime event structures. The distinctive feature of reversible causal
nets lies in deriving causality from inhibitor arcs, departing from the
conventional dependence on the overlap between the post and preset of
transitions. In this way, we are able to operationally explain the full model
of reversible prime event structures.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16715" title="Abstract">arXiv:2312.16715</a> [<a href="/pdf/2312.16715" title="Download PDF">pdf</a>, <a href="/format/2312.16715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks on LoRa Device Identification and Rogue Signal  Detection with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagduyu%2C+Y+E">Yalin E. Sagduyu</a>, 
<a href="/search/cs?searchtype=author&query=Erpek%2C+T">Tugba Erpek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Low-Power Wide-Area Network (LPWAN) technologies, such as LoRa, have gained
significant attention for their ability to enable long-range, low-power
communication for Internet of Things (IoT) applications. However, the security
of LoRa networks remains a major concern, particularly in scenarios where
device identification and classification of legitimate and spoofed signals are
crucial. This paper studies a deep learning framework to address these
challenges, considering LoRa device identification and legitimate vs. rogue
LoRa device classification tasks. A deep neural network (DNN), either a
convolutional neural network (CNN) or feedforward neural network (FNN), is
trained for each task by utilizing real experimental I/Q data for LoRa signals,
while rogue signals are generated by using kernel density estimation (KDE) of
received signals by rogue devices. Fast Gradient Sign Method (FGSM)-based
adversarial attacks are considered for LoRa signal classification tasks using
deep learning models. The impact of these attacks is assessed on the
performance of two tasks, namely device identification and legitimate vs. rogue
device classification, by utilizing separate or common perturbations against
these signal classification tasks. Results presented in this paper quantify the
level of transferability of adversarial attacks on different LoRa signal
classification tasks as a major vulnerability and highlight the need to make
IoT applications robust to adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16717" title="Abstract">arXiv:2312.16717</a> [<a href="/pdf/2312.16717" title="Download PDF">pdf</a>, <a href="/format/2312.16717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Landslide Detection and Segmentation Using Remote Sensing Images and  Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cam Le</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+L">Lam Pham</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+J">Jasmin Lampert</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%B6gl%2C+M">Matthias Schl&#xf6;gl</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+A">Alexander Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Knowledge about historic landslide event occurrence is important for
supporting disaster risk reduction strategies. Building upon findings from 2022
Landslide4Sense Competition, we propose a deep neural network based system for
landslide detection and segmentation from multisource remote sensing image
input. We use a U-Net trained with Cross Entropy loss as baseline model. We
then improve the U-Net baseline model by leveraging a wide range of deep
learning techniques. In particular, we conduct feature engineering by
generating new band data from the original bands, which helps to enhance the
quality of remote sensing image input. Regarding the network architecture, we
replace traditional convolutional layers in the U-Net baseline by a
residual-convolutional layer. We also propose an attention layer which
leverages the multi-head attention scheme. Additionally, we generate multiple
output masks with three different resolutions, which creates an ensemble of
three outputs in the inference process to enhance the performance. Finally, we
propose a combined loss function which leverages Focal loss and IoU loss to
train the network. Our experiments on the development set of the
Landslide4Sense challenge achieve an F1 score and an mIoU score of 84.07 and
76.07, respectively. Our best model setup outperforms the challenge baseline
and the proposed U-Net baseline, improving the F1 score/mIoU score by 6.8/7.4
and 10.5/8.8, respectively.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16720" title="Abstract">arXiv:2312.16720</a> [<a href="/pdf/2312.16720" title="Download PDF">pdf</a>, <a href="/format/2312.16720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Expansion for Adaptive Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Siddhartha Datta</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+A">Alexander Ku</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+D">Deepak Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+P">Peter Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image generation models are powerful but difficult to use. Users
craft specific prompts to get better images, though the images can be
repetitive. This paper proposes a Prompt Expansion framework that helps users
generate high-quality, diverse images with less effort. The Prompt Expansion
model takes a text query as input and outputs a set of expanded text prompts
that are optimized such that when passed to a text-to-image model, generates a
wider variety of appealing images. We conduct a human evaluation study that
shows that images generated through Prompt Expansion are more aesthetically
pleasing and diverse than those generated by baseline methods. Overall, this
paper presents a novel and effective approach to improving the text-to-image
generation experience.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16724" title="Abstract">arXiv:2312.16724</a> [<a href="/pdf/2312.16724" title="Download PDF">pdf</a>, <a href="/format/2312.16724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A pipeline for multiple orange detection and tracking with 3-D fruit  relocalization and neural-net based yield regression in commercial citrus  orchards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+T+T">Thiago T. Santos</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+K+X+S">Kleber X. S. de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+J+C">Jo&#xe3;o Camargo Neto</a>, 
<a href="/search/cs?searchtype=author&query=Koenigkan%2C+L+V">Luciano V. Koenigkan</a>, 
<a href="/search/cs?searchtype=author&query=Moreira%2C+A+S">Al&#xe9;cio S. Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Ternes%2C+S">S&#xf4;nia Ternes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditionally, sweet orange crop forecasting has involved manually counting
fruits from numerous trees, which is a labor-intensive process. Automatic
systems for fruit counting, based on proximal imaging, computer vision, and
machine learning, have been considered a promising alternative or complement to
manual counting. These systems require data association components that prevent
multiple counting of the same fruit observed in different images. However,
there is a lack of work evaluating the accuracy of multiple fruit counting,
especially considering (i) occluded and re-entering green fruits on leafy
trees, and (ii) counting ground-truth data measured in the crop field. We
propose a non-invasive alternative that utilizes fruit counting from videos,
implemented as a pipeline. Firstly, we employ CNNs for the detection of visible
fruits. Inter-frame association techniques are then applied to track the fruits
across frames. To handle occluded and re-appeared fruit, we introduce a
relocalization component that employs 3-D estimation of fruit locations.
Finally, a neural network regressor is utilized to estimate the total number of
fruit, integrating image-based fruit counting with other tree data such as crop
variety and tree size. The results demonstrate that the performance of our
approach is closely tied to the quality of the field-collected videos. By
ensuring that at least 30% of the fruit is accurately detected, tracked, and
counted, our yield regressor achieves an impressive coefficient of
determination of 0.85. To the best of our knowledge, this study represents one
of the few endeavors in fruit estimation that incorporates manual fruit
counting as a reference point for evaluation. We also introduce annotated
datasets for multiple orange tracking (MOrangeT) and detection (OranDet),
publicly available to foster the development of novel methods for image-based
fruit counting.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16726" title="Abstract">arXiv:2312.16726</a> [<a href="/pdf/2312.16726" title="Download PDF">pdf</a>, <a href="/format/2312.16726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairCompass: Operationalising Fairness in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jessica Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+K+R">Kim-Kwang Raymond Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
<p class="mathjax">As artificial intelligence (AI) increasingly becomes an integral part of our
societal and individual activities, there is a growing imperative to develop
responsible AI solutions. Despite a diverse assortment of machine learning
fairness solutions is proposed in the literature, there is reportedly a lack of
practical implementation of these tools in real-world applications. Industry
experts have participated in thorough discussions on the challenges associated
with operationalising fairness in the development of machine learning-empowered
solutions, in which a shift toward human-centred approaches is promptly
advocated to mitigate the limitations of existing techniques. In this work, we
propose a human-in-the-loop approach for fairness auditing, presenting a mixed
visual analytical system (hereafter referred to as 'FairCompass'), which
integrates both subgroup discovery technique and the decision tree-based schema
for end users. Moreover, we innovatively integrate an Exploration, Guidance and
Informed Analysis loop, to facilitate the use of the Knowledge Generation Model
for Visual Analytics in FairCompass. We evaluate the effectiveness of
FairCompass for fairness auditing in a real-world scenario, and the findings
demonstrate the system's potential for real-world deployability. We anticipate
this work will address the current gaps in research for fairness and facilitate
the operationalisation of fairness in machine learning systems.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16729" title="Abstract">arXiv:2312.16729</a> [<a href="/pdf/2312.16729" title="Download PDF">pdf</a>, <a href="/ps/2312.16729" title="Download PostScript">ps</a>, <a href="/format/2312.16729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behavioural pseudometrics for continuous-time diffusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Clerc%2C+F">Florence Clerc</a>, 
<a href="/search/cs?searchtype=author&query=Panangaden%2C+P">Prakash Panangaden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Bisimulation is a concept that captures behavioural equivalence of states in
a variety of types of transition systems. It has been widely studied in a
discrete-time setting where the notion of a step is fundamental. In our setting
we are considering "flow"-processes emphasizing that they evolve in continuous
time. In such continuous-time settings, the concepts are not straightforward
adaptations of their discrete-time analogues and we restrict our study to
diffusions that do not lose mass over time and with additional regularity
constraints.
<br />In previous work we proposed different definitions of behavioural
equivalences for continuous-time stochastic processes where the evolution is a
flow through time. That work only addressed equivalences. In this work, we aim
at quantifying how differently processes behave. We present two pseudometrics
for diffusion-like processes. These pseudometrics are fixpoints of two
different functionals on the space of 1-bounded pseudometrics on the state
space. We also characterize these pseudometrics in terms of real-valued modal
logics; this is a quantitative analogue of the notion of logical
characterization of bisimulation. These real-valued modal logics indicate that
the two pseudometrics are different and thus yield different notions of
behavioural equivalence.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16730" title="Abstract">arXiv:2312.16730</a> [<a href="/pdf/2312.16730" title="Download PDF">pdf</a>, <a href="/format/2312.16730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations of Reinforcement Learning and Interactive Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foster%2C+D+J">Dylan J. Foster</a>, 
<a href="/search/cs?searchtype=author&query=Rakhlin%2C+A">Alexander Rakhlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">These lecture notes give a statistical perspective on the foundations of
reinforcement learning and interactive decision making. We present a unifying
framework for addressing the exploration-exploitation dilemma using frequentist
and Bayesian approaches, with connections and parallels between supervised
learning/estimation and decision making as an overarching theme. Special
attention is paid to function approximation and flexible model classes such as
neural networks. Topics covered include multi-armed and contextual bandits,
structured bandits, and reinforcement learning with high-dimensional feedback.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16731" title="Abstract">arXiv:2312.16731</a> [<a href="/pdf/2312.16731" title="Download PDF">pdf</a>, <a href="/format/2312.16731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Continual Learning: Separating Memory Edits from Model  Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dziadzio%2C+S">Sebastian Dziadzio</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+%C3%87">&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Ven%2C+G+M">Gido M. van de Ven</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The ability of machine learning systems to learn continually is hindered by
catastrophic forgetting, the tendency of neural networks to overwrite existing
knowledge when learning a new task. Existing continual learning methods
alleviate this problem through regularisation, parameter isolation, or
rehearsal, and are typically evaluated on benchmarks consisting of a handful of
tasks. We propose a novel conceptual approach to continual classification that
aims to disentangle class-specific information that needs to be memorised from
the class-agnostic knowledge that encapsulates generalization. We store the
former in a buffer that can be easily pruned or updated when new categories
arrive, while the latter is represented with a neural network that generalizes
across tasks. We show that the class-agnostic network does not suffer from
catastrophic forgetting and by leveraging it to perform classification, we
improve accuracy on past tasks over time. In addition, our approach supports
open-set classification and one-shot generalization. To test our conceptual
framework, we introduce Infinite dSprites, a tool for creating continual
classification and disentanglement benchmarks of arbitrary length with full
control over generative factors. We show that over a sufficiently long time
horizon all major types of continual learning methods break down, while our
approach enables continual learning over hundreds of tasks with explicit
control over memorization and forgetting.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16733" title="Abstract">arXiv:2312.16733</a> [<a href="/pdf/2312.16733" title="Download PDF">pdf</a>, <a href="/format/2312.16733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperServe: Fine-Grained Inference Serving for Unpredictable Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khare%2C+A">Alind Khare</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+D">Dhruv Garg</a>, 
<a href="/search/cs?searchtype=author&query=Kalra%2C+S">Sukrit Kalra</a>, 
<a href="/search/cs?searchtype=author&query=Grandhi%2C+S">Snigdha Grandhi</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>, 
<a href="/search/cs?searchtype=author&query=Tumanov%2C+A">Alexey Tumanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing deployment of ML models on the critical path of production
applications in both datacenter and the edge requires ML inference serving
systems to serve these models under unpredictable and bursty request arrival
rates. Serving models under such conditions requires these systems to strike a
careful balance between the latency and accuracy requirements of the
application and the overall efficiency of utilization of scarce resources.
State-of-the-art systems resolve this tension by either choosing a static point
in the latency-accuracy tradeoff space to serve all requests or load specific
models on the critical path of request serving. In this work, we instead
resolve this tension by simultaneously serving the entire-range of models
spanning the latency-accuracy tradeoff space. Our novel mechanism, SubNetAct,
achieves this by carefully inserting specialized operators in weight-shared
SuperNetworks. These operators enable SubNetAct to dynamically route requests
through the network to meet a latency and accuracy target. SubNetAct requires
upto 2.6x lower memory to serve a vastly-higher number of models than prior
state-of-the-art. In addition, SubNetAct's near-instantaneous actuation of
models unlocks the design space of fine-grained, reactive scheduling policies.
We explore the design of one such extremely effective policy, SlackFit and
instantiate both SubNetAct and SlackFit in a real system, SuperServe.
SuperServe achieves 4.67% higher accuracy for the same SLO attainment and 2.85x
higher SLO attainment for the same accuracy on a trace derived from the
real-world Microsoft Azure Functions workload and yields the best trade-offs on
a wide range of extremely-bursty synthetic traces automatically.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16735" title="Abstract">arXiv:2312.16735</a> [<a href="/pdf/2312.16735" title="Download PDF">pdf</a>, <a href="/format/2312.16735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flock: A Low-Cost Streaming Query Engine on FaaS Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gang%2C+L">Liao Gang</a>, 
<a href="/search/cs?searchtype=author&query=Amol%2C+D">Deshpande Amol</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+A">Abadi Daniel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A mirror of portions of Gang's PhD thesis. Not yet revised; read at your own discretion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this paper, we present Flock, a cloud-native streaming query engine that
leverages the on-demand elasticity of Function-as-a-Service (FaaS) platforms to
perform real-time data analytics. Traditional server-centric deployments often
suffer from resource under- or over-provisioning, leading to resource wastage
or performance degradation. Flock addresses these issues by providing more
fine-grained elasticity that can dynamically match the per-query basis with
continuous scaling, and its billing methods are more fine-grained with
millisecond granularity, making it a low-cost solution for stream processing.
Our approach, payload invocation, eliminates the need for external storage
services and eliminates the requirement for a query coordinator in the data
architecture. Our evaluation shows that Flock significantly outperforms
state-of-the-art systems in terms of cost, especially on ARM processors, making
it a promising solution for real-time data analytics on FaaS platforms.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16737" title="Abstract">arXiv:2312.16737</a> [<a href="/pdf/2312.16737" title="Download PDF">pdf</a>, <a href="/format/2312.16737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HMP: Hand Motion Priors for Pose and Shape Estimation from Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duran%2C+E">Enes Duran</a>, 
<a href="/search/cs?searchtype=author&query=Kocabas%2C+M">Muhammed Kocabas</a>, 
<a href="/search/cs?searchtype=author&query=Choutas%2C+V">Vasileios Choutas</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zicong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding how humans interact with the world necessitates accurate 3D
hand pose estimation, a task complicated by the hand's high degree of
articulation, frequent occlusions, self-occlusions, and rapid motions. While
most existing methods rely on single-image inputs, videos have useful cues to
address aforementioned issues. However, existing video-based 3D hand datasets
are insufficient for training feedforward models to generalize to in-the-wild
scenarios. On the other hand, we have access to large human motion capture
datasets which also include hand motions, e.g. AMASS. Therefore, we develop a
generative motion prior specific for hands, trained on the AMASS dataset which
features diverse and high-quality hand motions. This motion prior is then
employed for video-based 3D hand motion estimation following a latent
optimization approach. Our integration of a robust motion prior significantly
enhances performance, especially in occluded scenarios. It produces stable,
temporally consistent results that surpass conventional single-frame methods.
We demonstrate our method's efficacy via qualitative and quantitative
evaluations on the HO3D and DexYCB datasets, with special emphasis on an
occlusion-focused subset of HO3D. Code is available at
https://hmp.is.tue.mpg.de
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16738" title="Abstract">arXiv:2312.16738</a> [<a href="/pdf/2312.16738" title="Download PDF">pdf</a>, <a href="/format/2312.16738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lyapunov-Krasovskii Functionals of Robust Type for the Stability  Analysis in Time-Delay Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Scholl%2C+T+H">Tessina H. Scholl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Inspired by the widespread theory of complete-type Lyapunov-Krasovskii
functionals, the article considers an alternative class of Lyapunov-Krasovskii
functionals that intends to achieve less conservative robustness bounds. These
functionals share the same structure as the functionals of complete type, and
also they share to be defined via their derivative along solutions of the
nominal system. The defining equation for the derivative, however, is chosen
differently: the Lyapunov equation, which forms the template for the defining
equation of complete-type Lyapunov-Krasovskii functionals, is replaced by the
template of an algebraic Riccati equation. Properties of the proposed
Lyapunov-Krasovskii functionals of robust type are proven in the present
article. Moreover, existence conditions are derived from the
infinite-dimensional Kalman-Yakubovich-Popov lemma, combined with a splitting
approach. The concept is tailored to sector-based absolute stability problems,
and the obtainable robustness bounds are strongly related to the small-gain
theorem, the complex stability radius, passivity theorems, the circle
criterion, and integral quadratic constraints with constant multipliers, where,
however, the nominal system itself has a time delay.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16741" title="Abstract">arXiv:2312.16741</a> [<a href="/pdf/2312.16741" title="Download PDF">pdf</a>, <a href="/format/2312.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bin-picking of novel objects through category-agnostic-segmentation: RGB  matters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+P">Prem Raj</a>, 
<a href="/search/cs?searchtype=author&query=Bhadang%2C+S">Sachin Bhadang</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+G">Gaurav Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Behera%2C+L">Laxmidhar Behera</a>, 
<a href="/search/cs?searchtype=author&query=Sandhan%2C+T">Tushar Sandhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at IEEE International Conference on Robotic Computing (IRC), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper addresses category-agnostic instance segmentation for robotic
manipulation, focusing on segmenting objects independent of their class to
enable versatile applications like bin-picking in dynamic environments.
Existing methods often lack generalizability and object-specific information,
leading to grasp failures. We present a novel approach leveraging
object-centric instance segmentation and simulation-based training for
effective transfer to real-world scenarios. Notably, our strategy overcomes
challenges posed by noisy depth sensors, enhancing the reliability of learning.
Our solution accommodates transparent and semi-transparent objects which are
historically difficult for depth-based grasping methods. Contributions include
domain randomization for successful transfer, our collected dataset for
warehouse applications, and an integrated framework for efficient bin-picking.
Our trained instance segmentation model achieves state-of-the-art performance
over WISDOM public benchmark [1] and also over the custom-created dataset. In a
real-world challenging bin-picking setup our bin-picking framework method
achieves 98% accuracy for opaque objects and 97% accuracy for non-opaque
objects, outperforming the state-of-the-art baselines with a greater margin.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16750" title="Abstract">arXiv:2312.16750</a> [<a href="/pdf/2312.16750" title="Download PDF">pdf</a>, <a href="/format/2312.16750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Sensor Placement for Multi-source Localization of Pathogens in  Wastewater Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakkala%2C+K">Kalvik Jakkala</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+S">Srinivas Akella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computational Engineering, Finance, and Science (cs.CE); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Wastewater monitoring is an effective approach for the early detection of
viral and bacterial disease outbreaks. It has recently been used to identify
the presence of individuals infected with COVID-19. To monitor large
communities and accurately localize buildings with infected individuals with a
limited number of sensors, one must carefully choose the sampling locations in
wastewater networks. We also have to account for concentration requirements on
the collected wastewater samples to ensure reliable virus presence test
results. We model this as a sensor placement problem. Although sensor placement
for source localization arises in numerous problems, most approaches use
application-specific heuristics and fail to consider multiple source scenarios.
To address these limitations, we develop a novel approach that combines
Bayesian networks and discrete optimization to efficiently identify informative
sensor placements and accurately localize virus sources. Our approach also
takes into account concentration requirements on wastewater samples during
optimization. Our simulation experiments demonstrate the quality of our sensor
placements and the accuracy of our source localization approach. Furthermore,
we show the robustness of our approach to discrepancies between the virus
outbreak model and the actual outbreak rates.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16755" title="Abstract">arXiv:2312.16755</a> [<a href="/pdf/2312.16755" title="Download PDF">pdf</a>, <a href="/format/2312.16755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks for Antisocial Behavior Detection on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toshevska%2C+M">Martina Toshevska</a>, 
<a href="/search/cs?searchtype=author&query=Kalajdziski%2C+S">Slobodan Kalajdziski</a>, 
<a href="/search/cs?searchtype=author&query=Gievska%2C+S">Sonja Gievska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15th ICT Innovations International Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media resurgence of antisocial behavior has exerted a downward spiral
on stereotypical beliefs, and hateful comments towards individuals and social
groups, as well as false or distorted news. The advances in graph neural
networks employed on massive quantities of graph-structured data raise high
hopes for the future of mediating communication on social media platforms. An
approach based on graph convolutional data was employed to better capture the
dependencies between the heterogeneous types of data.
<br />Utilizing past and present experiences on the topic, we proposed and
evaluated a graph-based approach for antisocial behavior detection, with
general applicability that is both language- and context-independent. In this
research, we carried out an experimental validation of our graph-based approach
on several PAN datasets provided as part of their shared tasks, that enable the
discussion of the results obtained by the proposed solution.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16760" title="Abstract">arXiv:2312.16760</a> [<a href="/pdf/2312.16760" title="Download PDF">pdf</a>, <a href="/format/2312.16760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fourth International Verification of Neural Networks Competition  (VNN-COMP 2023): Summary and Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brix%2C+C">Christopher Brix</a>, 
<a href="/search/cs?searchtype=author&query=Bak%2C+S">Stanley Bak</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+T+T">Taylor T. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.10376">arXiv:2212.10376</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">This report summarizes the 4th International Verification of Neural Networks
Competition (VNN-COMP 2023), held as a part of the 6th Workshop on Formal
Methods for ML-Enabled Autonomous Systems (FoMLAS), that was collocated with
the 35th International Conference on Computer-Aided Verification (CAV).
VNN-COMP is held annually to facilitate the fair and objective comparison of
state-of-the-art neural network verification tools, encourage the
standardization of tool interfaces, and bring together the neural network
verification community. To this end, standardized formats for networks (ONNX)
and specification (VNN-LIB) were defined, tools were evaluated on equal-cost
hardware (using an automatic evaluation pipeline based on AWS instances), and
tool parameters were chosen by the participants before the final test sets were
made public. In the 2023 iteration, 7 teams participated on a diverse set of 10
scored and 4 unscored benchmarks. This report summarizes the rules, benchmarks,
participating tools, results, and lessons learned from this iteration of this
competition.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16767" title="Abstract">arXiv:2312.16767</a> [<a href="/pdf/2312.16767" title="Download PDF">pdf</a>, <a href="/format/2312.16767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large  Neighborhood Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Taoan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dilkina%2C+B">Bistra Dilkina</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+S">Sven Koenig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Anytime multi-agent path finding (MAPF) is a promising approach to scalable
path optimization in large-scale multi-agent systems. State-of-the-art anytime
MAPF is based on Large Neighborhood Search (LNS), where a fast initial solution
is iteratively optimized by destroying and repairing a fixed number of parts,
i.e., the neighborhood, of the solution, using randomized destroy heuristics
and prioritized planning. Despite their recent success in various MAPF
instances, current LNS-based approaches lack exploration and flexibility due to
greedy optimization with a fixed neighborhood size which can lead to low
quality solutions in general. So far, these limitations have been addressed
with extensive prior effort in tuning or offline machine learning beyond actual
planning. In this paper, we focus on online learning in LNS and propose
Bandit-based Adaptive LArge Neighborhood search Combined with Exploration
(BALANCE). BALANCE uses a bi-level multi-armed bandit scheme to adapt the
selection of destroy heuristics and neighborhood sizes on the fly during
search. We evaluate BALANCE on multiple maps from the MAPF benchmark set and
empirically demonstrate cost improvements of at least 50% compared to
state-of-the-art anytime MAPF in large-scale scenarios. We find that Thompson
Sampling performs particularly well compared to alternative multi-armed bandit
algorithms.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16771" title="Abstract">arXiv:2312.16771</a> [<a href="/pdf/2312.16771" title="Download PDF">pdf</a>, <a href="/format/2312.16771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-Aware Crowd Count Network with Annotation Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+Y">Yi-Kuan Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+J">Jun-Wei Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+Y">Yu-Chee Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+L">Li Xin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figues. arXiv admin note: text overlap with <a href="/abs/2211.06835">arXiv:2211.06835</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional crowd counting networks suffer from information loss when feature
maps are downsized through pooling layers, leading to inaccuracies in counting
crowds at a distance. Existing methods often assume correct annotations during
training, disregarding the impact of noisy annotations, especially in crowded
scenes. Furthermore, the use of a fixed Gaussian kernel fails to account for
the varying pixel distribution with respect to the camera distance. To overcome
these challenges, we propose a Scale-Aware Crowd Counting Network (SACC-Net)
that introduces a ``scale-aware'' architecture with error-correcting
capabilities of noisy annotations. For the first time, we {\bf simultaneously}
model labeling errors (mean) and scale variations (variance) by
spatially-varying Gaussian distributions to produce fine-grained heat maps for
crowd counting. Furthermore, the proposed adaptive Gaussian kernel variance
enables the model to learn dynamically with a low-rank approximation, leading
to improved convergence efficiency with comparable accuracy. The performance of
SACC-Net is extensively evaluated on four public datasets: UCF-QNRF, UCF CC 50,
NWPU, and ShanghaiTech A-B. Experimental results demonstrate that SACC-Net
outperforms all state-of-the-art methods, validating its effectiveness in
achieving superior crowd counting accuracy.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16778" title="Abstract">arXiv:2312.16778</a> [<a href="/pdf/2312.16778" title="Download PDF">pdf</a>, <a href="/format/2312.16778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Representation with Intra-Modal and Inter-Modal Graph  Contrastive Learning for Multimodal Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shou%2C+Y">Yuntao Shou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the release of increasing open-source emotion recognition datasets on
social media platforms and the rapid development of computing resources,
multimodal emotion recognition tasks (MER) have begun to receive widespread
research attention. The MER task extracts and fuses complementary semantic
information from different modalities, which can classify the speaker's
emotions. However, the existing feature fusion methods have usually mapped the
features of different modalities into the same feature space for information
fusion, which can not eliminate the heterogeneity between different modalities.
Therefore, it is challenging to make the subsequent emotion class boundary
learning. To tackle the above problems, we have proposed a novel Adversarial
Representation with Intra-Modal and Inter-Modal Graph Contrastive for
Multimodal Emotion Recognition (AR-IIGCN) method. Firstly, we input video,
audio, and text features into a multi-layer perceptron (MLP) to map them into
separate feature spaces. Secondly, we build a generator and a discriminator for
the three modal features through adversarial representation, which can achieve
information interaction between modalities and eliminate heterogeneity among
modalities. Thirdly, we introduce contrastive graph representation learning to
capture intra-modal and inter-modal complementary semantic information and
learn intra-class and inter-class boundary information of emotion categories.
Specifically, we construct a graph structure for three modal features and
perform contrastive representation learning on nodes with different emotions in
the same modality and the same emotion in different modalities, which can
improve the feature representation ability of nodes. Extensive experimental
works show that the ARL-IIGCN method can significantly improve emotion
recognition accuracy on IEMOCAP and MELD datasets.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16781" title="Abstract">arXiv:2312.16781</a> [<a href="/pdf/2312.16781" title="Download PDF">pdf</a>, <a href="/format/2312.16781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of Adaptive LLR-based AP selection for Grant-Free Random Access in  Cell-Free Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Renna%2C+R">R. Di Renna</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents an iterative detection and decoding scheme along with an
adaptive strategy to improve the selection of access points (APs) in a
grant-free uplink cell-free scenario. With the requirement for the APs to have
low-computational power in mind, we introduce a low-complexity scheme for local
activity and data detection. At the central processing unit (CPU) level, we
propose an adaptive technique based on local log-likelihood ratios (LLRs) to
select the list of APs that should be considered for each device. Simulation
results show that the proposed LLRs-based APs selection scheme outperforms the
existing techniques in the literature in terms of bit error rate (BER) while
requiring comparable fronthaul load.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16783" title="Abstract">arXiv:2312.16783</a> [<a href="/pdf/2312.16783" title="Download PDF">pdf</a>, <a href="/ps/2312.16783" title="Download PostScript">ps</a>, <a href="/format/2312.16783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meshfree method for solving the elliptic Monge-Ampere equation with  Dirichlet boundary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhiyong Liu</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Q">Qiuyan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.08806">arXiv:2306.08806</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We prove the convergence of meshfree method for solving the elliptic
Monge-Ampere equation with Dirichlet boundary on the bounded domain. L2 error
is obtained based on the kernel-based trial spaces generated by the compactly
supported radial basis functions. We obtain the convergence result when the
testing discretization is finer than the trial discretization. The convergence
rate depend on the regularity of the solution, the smoothness of the computing
domain, and the approximation of scaled kernel-based spaces. The presented
convergence theory covers a wide range of kernel-based trial spaces including
stationary approximation and non-stationary approximation. An extension to
non-Dirichlet boundary condition is in a forthcoming paper.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16784" title="Abstract">arXiv:2312.16784</a> [<a href="/pdf/2312.16784" title="Download PDF">pdf</a>, <a href="/format/2312.16784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Scalable Structural Representations for Link Prediction with  Bloom Signatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Haoteng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+R">Rongzhe Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Anshumali Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have shown great potential in learning on
graphs, but they are known to perform sub-optimally on link prediction tasks.
Existing GNNs are primarily designed to learn node-wise representations and
usually fail to capture pairwise relations between target nodes, which proves
to be crucial for link prediction. Recent works resort to learning more
expressive edge-wise representations by enhancing vanilla GNNs with structural
features such as labeling tricks and link prediction heuristics, but they
suffer from high computational overhead and limited scalability. To tackle this
issue, we propose to learn structural link representations by augmenting the
message-passing framework of GNNs with Bloom signatures. Bloom signatures are
hashing-based compact encodings of node neighborhoods, which can be efficiently
merged to recover various types of edge-wise structural features. We further
show that any type of neighborhood overlap-based heuristic can be estimated by
a neural network that takes Bloom signatures as input. GNNs with Bloom
signatures are provably more expressive than vanilla GNNs and also more
scalable than existing edge-wise models. Experimental results on five standard
link prediction benchmarks show that our proposed model achieves comparable or
better performance than existing edge-wise GNN models while being 3-200
$\times$ faster and more memory-efficient for online inference.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16787" title="Abstract">arXiv:2312.16787</a> [<a href="/pdf/2312.16787" title="Download PDF">pdf</a>, <a href="/ps/2312.16787" title="Download PostScript">ps</a>, <a href="/format/2312.16787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L-LO: Enhancing Pose Estimation Precision via a Landmark-Based LiDAR  Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feiya Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chunyun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dongye Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The majority of existing LiDAR odometry solutions are based on simple
geometric features such as points, lines or planes which cannot fully reflect
the characteristics of surrounding environments. In this study, we propose a
novel LiDAR odometry which effectively utilizes the overall exterior
characteristics of environmental landmarks. The vehicle pose estimation is
accomplished by means of two sequential pose estimation stages, namely,
horizontal pose estimation and vertical pose estimation. To achieve effective
landmark registration, a comprehensive index is proposed to evaluate the level
of similarity between landmarks. This index takes into account two crucial
aspects of landmarks, namely, dimension and shape in evaluating their
similarity. To assess the performance of the proposed algorithm, we utilize the
widely recognized KITTI dataset as well as experimental data collected by an
unmanned ground vehicle platform. Both graphical and numerical results indicate
that our algorithm outperforms leading LiDAR odometry solutions in terms of
positioning accuracy.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16788" title="Abstract">arXiv:2312.16788</a> [<a href="/pdf/2312.16788" title="Download PDF">pdf</a>, <a href="/format/2312.16788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Degree Biases in Message Passing Mechanism by Utilizing  Community Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+V+T">Van Thuy Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+O">O-Joun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This study utilizes community structures to address node degree biases in
message-passing (MP) via learnable graph augmentations and novel graph
transformers. Recent augmentation-based methods showed that MP neural networks
often perform poorly on low-degree nodes, leading to degree biases due to a
lack of messages reaching low-degree nodes. Despite their success, most methods
use heuristic or uniform random augmentations, which are non-differentiable and
may not always generate valuable edges for learning representations. In this
paper, we propose Community-aware Graph Transformers, namely CGT, to learn
degree-unbiased representations based on learnable augmentations and graph
transformers by extracting within community structures. We first design a
learnable graph augmentation to generate more within-community edges connecting
low-degree nodes through edge perturbation. Second, we propose an improved
self-attention to learn underlying proximity and the roles of nodes within the
community. Third, we propose a self-supervised learning task that could learn
the representations to preserve the global graph structure and regularize the
graph augmentations. Extensive experiments on various benchmark datasets showed
CGT outperforms state-of-the-art baselines and significantly improves the node
degree biases. The source code is available at
https://github.com/NSLab-CUK/Community-aware-Graph-Transformer.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16790" title="Abstract">arXiv:2312.16790</a> [<a href="/pdf/2312.16790" title="Download PDF">pdf</a>, <a href="/format/2312.16790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Dynamic Correlations and Mitigating Noise by Hierarchical  Convolution for Long-term Sequence Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liantao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasha Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junfeng Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning algorithms, especially Transformer-based models, have achieved
significant performance by capturing long-range dependencies and historical
information. However, the power of convolution has not been fully investigated.
Moreover, most existing works ignore the dynamic interaction among variables
and evolutionary noise in series. Addressing these issues, we propose a
Hierarchical Memorizing Network (HMNet). In particular, a hierarchical
convolution structure is introduced to extract the information from the series
at various scales. Besides, we propose a dynamic variable interaction module to
learn the varying correlation and an adaptive denoising module to search and
exploit similar patterns to alleviate noises. These modules can cooperate with
the hierarchical structure from the perspective of fine to coarse grain.
Experiments on five benchmarks demonstrate that HMNet significantly outperforms
the state-of-the-art models by 10.6% on MSE and 5.7% on MAE. Our code is
released at https://github.com/yzhHoward/HMNet.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16791" title="Abstract">arXiv:2312.16791</a> [<a href="/pdf/2312.16791" title="Download PDF">pdf</a>, <a href="/format/2312.16791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Propagation Analysis for Multithreaded Programs: An Empirical  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winter%2C+S">Stefan Winter</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">Abraham Chan</a>, 
<a href="/search/cs?searchtype=author&query=Saissi%2C+H">Habib Saissi</a>, 
<a href="/search/cs?searchtype=author&query=Pattabiraman%2C+K">Karthik Pattabiraman</a>, 
<a href="/search/cs?searchtype=author&query=Suri%2C+N">Neeraj Suri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of conference paper, originally published in the proceedings of ICST'17 (see: <a href="https://ieeexplore.ieee.org/document/7927974">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Fault injection is a technique to measure the robustness of a program to
errors by introducing faults into the program under test. Following a fault
injection experiment, Error Propagation Analysis (EPA) is deployed to
understand how errors affect a program's execution. EPA typically compares the
traces of a fault-free (golden) run with those from a faulty run of the
program. While this suffices for deterministic programs, EPA approaches are
unsound for multithreaded programs with non-deterministic golden runs. In this
paper, we propose Invariant Propagation Analysis (IPA) as the use of
automatically inferred likely invariants ("invariants" in the following) in
lieu of golden traces for conducting EPA in multithreaded programs. We evaluate
the stability and fault coverage of invariants derived by IPA through fault
injection experiments across six different fault types and six representative
programs that can be executed with varying numbers of threads. We find that
stable invariants can be inferred in all cases, but their fault coverage
depends on the application and the fault type. We also find that fault coverage
for multithreaded executions with IPA can be even higher than for traditional
singlethreaded EPA, which emphasizes that IPA results cannot be trivially
extrapolated from traditional EPA results.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16792" title="Abstract">arXiv:2312.16792</a> [<a href="/pdf/2312.16792" title="Download PDF">pdf</a>, <a href="/format/2312.16792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL-LOGO: Deep Reinforcement Learning Localization for Logo Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujitake%2C+M">Masato Fujitake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper proposes a novel logo image recognition approach incorporating a
localization technique based on reinforcement learning. Logo recognition is an
image classification task identifying a brand in an image. As the size and
position of a logo vary widely from image to image, it is necessary to
determine its position for accurate recognition. However, because there is no
annotation for the position coordinates, it is impossible to train and infer
the location of the logo in the image. Therefore, we propose a deep
reinforcement learning localization method for logo recognition (RL-LOGO). It
utilizes deep reinforcement learning to identify a logo region in images
without annotations of the positions, thereby improving classification
accuracy. We demonstrated a significant improvement in accuracy compared with
existing methods in several published benchmarks. Specifically, we achieved an
18-point accuracy improvement over competitive methods on the complex dataset
Logo-2K+. This demonstrates that the proposed method is a promising approach to
logo recognition in real-world applications.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16793" title="Abstract">arXiv:2312.16793</a> [<a href="/pdf/2312.16793" title="Download PDF">pdf</a>, <a href="/format/2312.16793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse PCA with Oracle Property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 table. In NIPS 2014
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study the estimation of the $k$-dimensional sparse
principal subspace of covariance matrix $\Sigma$ in the high-dimensional
setting. We aim to recover the oracle principal subspace solution, i.e., the
principal subspace estimator obtained assuming the true support is known a
priori. To this end, we propose a family of estimators based on the
semidefinite relaxation of sparse PCA with novel regularizations. In
particular, under a weak assumption on the magnitude of the population
projection matrix, one estimator within this family exactly recovers the true
support with high probability, has exact rank-$k$, and attains a $\sqrt{s/n}$
statistical rate of convergence with $s$ being the subspace sparsity level and
$n$ the sample size. Compared to existing support recovery results for sparse
PCA, our approach does not hinge on the spiked covariance model or the limited
correlation condition. As a complement to the first estimator that enjoys the
oracle property, we prove that, another estimator within the family achieves a
sharper statistical rate of convergence than the standard semidefinite
relaxation of sparse PCA, even when the previous assumption on the magnitude of
the projection matrix is violated. We validate the theoretical results by
numerical experiments on synthetic datasets.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16794" title="Abstract">arXiv:2312.16794</a> [<a href="/pdf/2312.16794" title="Download PDF">pdf</a>, <a href="/format/2312.16794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZONE: Zero-Shot Instruction-Guided Local Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bohan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sicheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Li Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in vision-language models like Stable Diffusion have shown
remarkable power in creative image synthesis and editing.However, most existing
text-to-image editing methods encounter two obstacles: First, the text prompt
needs to be carefully crafted to achieve good results, which is not intuitive
or user-friendly. Second, they are insensitive to local edits and can
irreversibly affect non-edited regions, leaving obvious editing traces. To
tackle these problems, we propose a Zero-shot instructiON-guided local image
Editing approach, termed ZONE. We first convert the editing intent from the
user-provided instruction (e.g., ``make his tie blue") into specific image
editing regions through InstructPix2Pix. We then propose a Region-IoU scheme
for precise image layer extraction from an off-the-shelf segment model. We
further develop an edge smoother based on FFT for seamless blending between the
layer and the image.Our method allows for arbitrary manipulation of a specific
region with a single instruction while preserving the rest. Extensive
experiments demonstrate that our ZONE achieves remarkable local editing results
and user-friendliness, outperforming state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16797" title="Abstract">arXiv:2312.16797</a> [<a href="/pdf/2312.16797" title="Download PDF">pdf</a>, <a href="/format/2312.16797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Prompts Learning with Cross-Modal Alignment for Attribute-based  Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yajing Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yawen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Da Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The fine-grained attribute descriptions can significantly supplement the
valuable semantic information for person image, which is vital to the success
of person re-identification (ReID) task. However, current ReID algorithms
typically failed to effectively leverage the rich contextual information
available, primarily due to their reliance on simplistic and coarse utilization
of image attributes. Recent advances in artificial intelligence generated
content have made it possible to automatically generate plentiful fine-grained
attribute descriptions and make full use of them. Thereby, this paper explores
the potential of using the generated multiple person attributes as prompts in
ReID tasks with off-the-shelf (large) models for more accurate retrieval
results. To this end, we present a new framework called Multi-Prompts ReID
(MP-ReID), based on prompt learning and language models, to fully dip fine
attributes to assist ReID task. Specifically, MP-ReID first learns to
hallucinate diverse, informative, and promptable sentences for describing the
query images. This procedure includes (i) explicit prompts of which attributes
a person has and furthermore (ii) implicit learnable prompts for
adjusting/conditioning the criteria used towards this person identity matching.
Explicit prompts are obtained by ensembling generation models, such as ChatGPT
and VQA models. Moreover, an alignment module is designed to fuse multi-prompts
(i.e., explicit and implicit ones) progressively and mitigate the cross-modal
gap. Extensive experiments on the existing attribute-involved ReID datasets,
namely, Market1501 and DukeMTMC-reID, demonstrate the effectiveness and
rationality of the proposed MP-ReID solution.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16799" title="Abstract">arXiv:2312.16799</a> [<a href="/pdf/2312.16799" title="Download PDF">pdf</a>, <a href="/format/2312.16799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Knowledge Distillation for Time-Sensitive Financial Services  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hongda Shen</a>, 
<a href="/search/cs?searchtype=author&query=Kurshan%2C+E">Eren Kurshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2101.01689">arXiv:2101.01689</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting anomalies has become an increasingly critical function in the
financial service industry. Anomaly detection is frequently used in key
compliance and risk functions such as financial crime detection fraud and
cybersecurity. The dynamic nature of the underlying data patterns especially in
adversarial environments like fraud detection poses serious challenges to the
machine learning models. Keeping up with the rapid changes by retraining the
models with the latest data patterns introduces pressures in balancing the
historical and current patterns while managing the training data size.
Furthermore the model retraining times raise problems in time-sensitive and
high-volume deployment systems where the retraining period directly impacts the
models ability to respond to ongoing attacks in a timely manner. In this study
we propose a temporal knowledge distillation-based label augmentation approach
(TKD) which utilizes the learning from older models to rapidly boost the latest
model and effectively reduces the model retraining times to achieve improved
agility. Experimental results show that the proposed approach provides
advantages in retraining times while improving the model performance.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16800" title="Abstract">arXiv:2312.16800</a> [<a href="/pdf/2312.16800" title="Download PDF">pdf</a>, <a href="/format/2312.16800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SR-LIVO: LiDAR-Inertial-Visual Odometry and Mapping with Sweep  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zikang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+R">Ruiye Ming</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+F">Fengtian Lang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, submitted to IEEE RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing LiDAR-inertial-visual odometry and mapping (LIV-SLAM) systems mainly
utilize the LiDAR-inertial odometry (LIO) module for structure reconstruction
and the visual-inertial odometry (VIO) module for color rendering. However, the
accuracy of VIO is often compromised by photometric changes, weak textures and
motion blur, unlike the more robust LIO. This paper introduces SR-LIVO, an
advanced and novel LIV-SLAM system employing sweep reconstruction to align
reconstructed sweeps with image timestamps. This allows the LIO module to
accurately determine states at all imaging moments, enhancing pose accuracy and
processing efficiency. Experimental results on two public datasets demonstrate
that: 1) our SRLIVO outperforms existing state-of-the-art LIV-SLAM systems in
both pose accuracy and time efficiency; 2) our LIO-based pose estimation prove
more accurate than VIO-based ones in several mainstream LIV-SLAM systems
(including ours). We have released our source code to contribute to the
community development in this field.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16805" title="Abstract">arXiv:2312.16805</a> [<a href="/pdf/2312.16805" title="Download PDF">pdf</a>, <a href="/format/2312.16805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DarkShot: Lighting Dark Images with Low-Compute and High-Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiazhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qiuping Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yangxing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Nighttime photography encounters escalating challenges in extremely low-light
conditions, primarily attributable to the ultra-low signal-to-noise ratio. For
real-world deployment, a practical solution must not only produce visually
appealing results but also require minimal computation. However, most existing
methods are either focused on improving restoration performance or employ
lightweight models at the cost of quality. This paper proposes a lightweight
network that outperforms existing state-of-the-art (SOTA) methods in low-light
enhancement tasks while minimizing computation. The proposed network
incorporates Siamese Self-Attention Block (SSAB) and Skip-Channel Attention
(SCA) modules, which enhance the model's capacity to aggregate global
information and are well-suited for high-resolution images. Additionally, based
on our analysis of the low-light image restoration process, we propose a
Two-Stage Framework that achieves superior results. Our model can restore a UHD
4K resolution image with minimal computation while keeping SOTA restoration
quality.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16807" title="Abstract">arXiv:2312.16807</a> [<a href="/pdf/2312.16807" title="Download PDF">pdf</a>, <a href="/format/2312.16807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Interference Graph Estimation via Concurrent Flooding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Haifeng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yichen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiani Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haorui Li</a>, 
<a href="/search/cs?searchtype=author&query=Pi%2C+Y">Yibo Pi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Embedded Wireless Systems and Networking 2023 (EWSN'23), 7 pages with 9 figures, equal contribution by Haifeng Jia and Yichen Wei
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Traditional wisdom for network management allocates network resources
separately for the measurement and data transmission tasks. Heavy measurement
tasks may take up resources for data transmission and significantly reduce
network performance. It is therefore challenging for interference graphs,
deemed as incurring heavy measurement overhead, to be used in practice in
wireless networks. To address this challenge in wireless sensor networks, we
propose to use power as a new dimension for interference graph estimation (IGE)
and integrate IGE with concurrent flooding such that IGE can be done
simultaneously with flooding using the same frequency-time resources. With
controlled and real-world experiments, we show that it is feasible to
efficiently achieve IGE via concurrent flooding on the commercial off-the-shelf
(COTS) devices by controlling the transmit powers of nodes. We believe that
efficient IGE would be a key enabler for the practical use of the existing
scheduling algorithms assuming known interference graphs.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16809" title="Abstract">arXiv:2312.16809</a> [<a href="/pdf/2312.16809" title="Download PDF">pdf</a>, <a href="/format/2312.16809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind System Identification in Linear Parameter-Varying Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moghaddam%2C+J+Z">Javad Zahedi Moghaddam</a>, 
<a href="/search/eess?searchtype=author&query=Momeni%2C+H">Hamidreza Momeni</a>, 
<a href="/search/eess?searchtype=author&query=Danesh%2C+M">Mojtaba Danesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Blind System Identification (BSI) is used to extract a system model whenever
input data is not attainable. Therefore, the input data and system model should
be estimated simultaneously. Because of nonlinearities in a large number of
systems, BSI problem is usually challenging to solve. In this paper, an
innovative solution is proposed to deal with the BSI problem in nonlinear
systems using the properties of the Linear Parameter-Varying (LPV) systems and
Hidden Markov Models (HMM). More specifically, assuming scheduling variable is
not measurable, the dynamic of the LPV system is approximated. To solve the BSI
problem in this context, LPV structure is modeled as an HMM network and a
modified Quasi-Static combination of Viterbi and Baum-Welch algorithms (QSVBW)
is proposed to estimate the nonlinear mappings and scheduling variable signal.
The applicability and the performance of the suggested QSVBW algorithm has been
justified by numerical studies.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16810" title="Abstract">arXiv:2312.16810</a> [<a href="/pdf/2312.16810" title="Download PDF">pdf</a>, <a href="/format/2312.16810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of Machine Learning Approaches for Diagnostics and Prognostics of  Industrial Systems Using Industrial Open Source Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hanqi Su</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jay Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been submitted to Computers in Industry (Under Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of Prognostics and Health Management (PHM), recent years have
witnessed a significant surge in the application of machine learning (ML).
Despite this growth, the field grapples with a lack of unified guidelines and
systematic approaches for effectively implementing these ML techniques and
comprehensive analysis regarding industrial open-source data across varied
scenarios. To address these gaps, this paper provides a comprehensive review of
machine learning approaches for diagnostics and prognostics of industrial
systems using open-source datasets from PHM Data Challenge Competitions held
between 2018 and 2023 by PHM Society and IEEE Reliability Society and
summarizes a unified ML framework. This review systematically categorizes and
scrutinizes the problems, challenges, methodologies, and advancements
demonstrated in these competitions, highlighting the evolving role of both
conventional machine learning and deep learning in tackling complex industrial
tasks related to detection, diagnosis, assessment, and prognosis. Moreover,
this paper delves into the common challenges in PHM data challenge competitions
by emphasizing both data-related and model-related issues and summarizes the
solutions that have been employed to address these challenges. Finally, we
identify key themes and potential directions for future research, providing
opportunities and prospects for ML further development in PHM.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16812" title="Abstract">arXiv:2312.16812</a> [<a href="/pdf/2312.16812" title="Download PDF">pdf</a>, <a href="/format/2312.16812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spacetime Gaussian Feature Splatting for Real-Time Dynamic View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://oppo-us-research.github.io/SpacetimeGaussians-website/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Novel view synthesis of dynamic scenes has been an intriguing yet challenging
problem. Despite recent advancements, simultaneously achieving high-resolution
photorealistic results, real-time rendering, and compact storage remains a
formidable task. To address these challenges, we propose Spacetime Gaussian
Feature Splatting as a novel dynamic scene representation, composed of three
pivotal components. First, we formulate expressive Spacetime Gaussians by
enhancing 3D Gaussians with temporal opacity and parametric motion/rotation.
This enables Spacetime Gaussians to capture static, dynamic, as well as
transient content within a scene. Second, we introduce splatted feature
rendering, which replaces spherical harmonics with neural features. These
features facilitate the modeling of view- and time-dependent appearance while
maintaining small size. Third, we leverage the guidance of training error and
coarse depth to sample new Gaussians in areas that are challenging to converge
with existing pipelines. Experiments on several established real-world datasets
demonstrate that our method achieves state-of-the-art rendering quality and
speed, while retaining compact storage. At 8K resolution, our lite-version
model can render at 60 FPS on an Nvidia RTX 4090 GPU.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16813" title="Abstract">arXiv:2312.16813</a> [<a href="/pdf/2312.16813" title="Download PDF">pdf</a>, <a href="/format/2312.16813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring Correlated Sources: AoI-based Scheduling is Nearly Optimal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramakanth%2C+R+V">R Vallabh Ramakanth</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+V">Vishrant Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Modiano%2C+E">Eytan Modiano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE INFOCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We study the design of scheduling policies to minimize monitoring error for a
collection of correlated sources, where only one source can be observed at any
given time. We model correlated sources as a discrete-time Wiener process,
where the increments are multivariate normal random variables, with a general
covariance matrix that captures the correlation structure between the sources.
Under a Kalman filter-based optimal estimation framework, we show that the
performance of all scheduling policies oblivious to instantaneous error, can be
lower and upper bounded by the weighted sum of Age of Information (AoI) across
the sources for appropriately chosen weights. We use this insight to design
scheduling policies that are only a constant factor away from optimality, and
make the rather surprising observation that AoI-based scheduling that ignores
correlation is sufficient to obtain performance guarantees. We also derive
scaling results that show that the optimal error scales roughly as the square
of the dimensionality of the system, even in the presence of correlation.
Finally, we provide simulation results to verify our claims.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16814" title="Abstract">arXiv:2312.16814</a> [<a href="/pdf/2312.16814" title="Download PDF">pdf</a>, <a href="/ps/2312.16814" title="Download PostScript">ps</a>, <a href="/format/2312.16814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Secrecy Performance of RIS-Assisted MISO Systems over Rician Channels  with Spatially Random Eavesdroppers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jindan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Swindlehurst%2C+A+L">A. Lee Swindlehurst</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chunming Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surface (RIS) technology is emerging as a
promising technique for performance enhancement for next-generation wireless
networks. This paper investigates the physical layer security of an
RIS-assisted multiple-antenna communication system in the presence of random
spatially distributed eavesdroppers. The RIS-to-ground channels are assumed to
experience Rician fading. Using stochastic geometry, exact distributions of the
received signal-to-noise-ratios (SNRs) at the legitimate user and the
eavesdroppers located according to a Poisson point process (PPP) are derived,
and closed-form expressions for the secrecy outage probability (SOP) and the
ergodic secrecy capacity (ESC) are obtained to provide insightful guidelines
for system design. First, the secrecy diversity order is obtained as
$\frac{2}{\alpha_2}$, where $\alpha_2$ denotes the path loss exponent of the
RIS-to-ground links. Then, it is revealed that the secrecy performance is
mainly affected by the number of RIS reflecting elements, $N$, and the impact
of the number of transmit antennas and transmit power at the base station is
marginal. In addition, when the locations of the randomly located eavesdroppers
are unknown, deploying the RIS closer to the legitimate user rather than to the
base station is shown to be more efficient. Moreover, it is also found that the
density of randomly located eavesdroppers, $\lambda_e$, has an additive effect
on the asymptotic ESC performance given by
$\log_2{\left({1}/{\lambda_e}\right)}$. Finally, numerical simulations are
conducted to verify the accuracy of these theoretical observations.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16818" title="Abstract">arXiv:2312.16818</a> [<a href="/pdf/2312.16818" title="Download PDF">pdf</a>, <a href="/ps/2312.16818" title="Download PostScript">ps</a>, <a href="/format/2312.16818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difficulties in Dynamic Analysis of Drone Firmware and Its Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yejun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kwangsoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungjoo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">With the advancement of Internet of Things (IoT) technology, its applications
span various sectors such as public, industrial, private and military. In
particular, the drone sector has gained significant attention for both
commercial and military purposes. As a result, there has been a surge in
research focused on vulnerability analysis of drones. However, most security
research to mitigate threats to IoT devices has focused primarily on networks,
firmware and mobile applications. Of these, the use of fuzzing to analyse the
security of firmware requires emulation of the firmware. However, when it comes
to drone firmware, the industry lacks emulation and automated fuzzing tools.
This is largely due to challenges such as limited input interfaces, firmware
encryption and signatures. While it may be tempting to assume that existing
emulators and automated analysers for IoT devices can be applied to drones,
practical applications have proven otherwise. In this paper, we discuss the
challenges of dynamically analysing drone firmware and propose potential
solutions. In addition, we demonstrate the effectiveness of our methodology by
applying it to DJI drones, which have the largest market share.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16819" title="Abstract">arXiv:2312.16819</a> [<a href="/pdf/2312.16819" title="Download PDF">pdf</a>, <a href="/ps/2312.16819" title="Download PostScript">ps</a>, <a href="/format/2312.16819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidden Minima in Two-Layer ReLU Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arjevani%2C+Y">Yossi Arjevani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">The optimization problem associated to fitting two-layer ReLU networks having
$d$~inputs, $k$~neurons, and labels generated by a target network, is
considered. Two categories of infinite families of minima, giving one minimum
per $d$ and $k$, were recently found. The loss at minima belonging to the first
category converges to zero as $d$ increases. In the second category, the loss
remains bounded away from zero. That being so, how may one avoid minima
belonging to the latter category? Fortunately, such minima are never detected
by standard optimization methods. Motivated by questions concerning the nature
of this phenomenon, we develop methods to study distinctive analytic properties
of hidden minima.
<br />By existing analyses, the Hessian spectrum of both categories agree modulus
$O(d^{-1/2})$-terms -- not promising. Thus, rather, our investigation proceeds
by studying curves along which the loss is minimized or maximized, referred to
as tangency arcs. We prove that pure, seemingly remote, group
representation-theoretic considerations concerning the arrangement of subspaces
invariant to the action of subgroups of $S_d$, the symmetry group over $d$
symbols, relative to ones fixed by the action yield a precise description of
all finitely many admissible types of tangency arcs. The general results
applied for the loss function reveal that arcs emanating from hidden minima
differ, characteristically, by their structure and symmetry, precisely on
account of the $O(d^{-1/2})$-eigenvalue terms absent in previous work,
indicating the subtly of the analysis. The theoretical results, stated and
proved for o-minimal structures, show that the set comprising all tangency arcs
is topologically sufficiently tame, permitting a numerical construction of
tangency arcs, and ultimately, a comparison of how minima from both categories
are positioned relative to adjacent critical points.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16820" title="Abstract">arXiv:2312.16820</a> [<a href="/pdf/2312.16820" title="Download PDF">pdf</a>, <a href="/format/2312.16820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catch Me if You Can: Effective Honeypot Placement in Dynamic AD Attack  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Huy Quang Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hung Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print to appear in IEEE INFOCOM 2024 - IEEE International Conference on Computer Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We study a Stackelberg game between an attacker and a defender on large
Active Directory (AD) attack graphs where the defender employs a set of
honeypots to stop the attacker from reaching high-value targets. Contrary to
existing works that focus on small and static attack graphs, AD graphs
typically contain hundreds of thousands of nodes and edges and constantly
change over time. We consider two types of attackers: a simple attacker who
cannot observe honeypots and a competent attacker who can. To jointly solve the
game, we propose a mixed-integer programming (MIP) formulation. We observed
that the optimal blocking plan for static graphs performs poorly in dynamic
graphs. To solve the dynamic graph problem, we re-design the mixed-integer
programming formulation by combining m MIP (dyMIP(m)) instances to produce a
near-optimal blocking plan. Furthermore, to handle a large number of dynamic
graph instances, we use a clustering algorithm to efficiently find the m-most
representative graph instances for a constant m (dyMIP(m)). We prove a lower
bound on the optimal blocking strategy for dynamic graphs and show that our
dyMIP(m) algorithms produce close to optimal results for a range of AD graphs
under realistic conditions.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16821" title="Abstract">arXiv:2312.16821</a> [<a href="/pdf/2312.16821" title="Download PDF">pdf</a>, <a href="/format/2312.16821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-level Distillation based Dense Passage Retrieval Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hai%2C+M">Mo Hai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Dong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Ranker and retriever are two important components in dense passage retrieval.
The retriever typically adopts a dual-encoder model, where queries and
documents are separately input into two pre-trained models, and the vectors
generated by the models are used for similarity calculation. The ranker often
uses a cross-encoder model, where the concatenated query-document pairs are
input into a pre-trained model to obtain word similarities. However, the
dual-encoder model lacks interaction between queries and documents due to its
independent encoding, while the cross-encoder model requires substantial
computational cost for attention calculation, making it difficult to obtain
real-time retrieval results. In this paper, we propose a dense retrieval model
called MD2PR based on multi-level distillation. In this model, we distill the
knowledge learned from the cross-encoder to the dual-encoder at both the
sentence level and word level. Sentence-level distillation enhances the
dual-encoder on capturing the themes and emotions of sentences. Word-level
distillation improves the dual-encoder in analysis of word semantics and
relationships. As a result, the dual-encoder can be used independently for
subsequent encoding and retrieval, avoiding the significant computational cost
associated with the participation of the cross-encoder. Furthermore, we propose
a simple dynamic filtering method, which updates the threshold during multiple
training iterations to ensure the effective identification of false negatives
and thus obtains a more comprehensive semantic representation space. The
experimental results over two standard datasets show our MD2PR outperforms 11
baseline models in terms of MRR and Recall metrics.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16823" title="Abstract">arXiv:2312.16823</a> [<a href="/pdf/2312.16823" title="Download PDF">pdf</a>, <a href="/format/2312.16823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer Attack Unlearning: Fast and Accurate Machine Unlearning via Layer  Level Attack and Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunjune Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recently, serious concerns have been raised about the privacy issues related
to training datasets in machine learning algorithms when including personal
data. Various regulations in different countries, including the GDPR grant
individuals to have personal data erased, known as 'the right to be forgotten'
or 'the right to erasure'. However, there has been less research on effectively
and practically deleting the requested personal data from the training set
while not jeopardizing the overall machine learning performance. In this work,
we propose a fast and novel machine unlearning paradigm at the layer level
called layer attack unlearning, which is highly accurate and fast compared to
existing machine unlearning algorithms. We introduce the Partial-PGD algorithm
to locate the samples to forget efficiently. In addition, we only use the last
layer of the model inspired by the Forward-Forward algorithm for unlearning
process. Lastly, we use Knowledge Distillation (KD) to reliably learn the
decision boundaries from the teacher using soft label information to improve
accuracy performance. We conducted extensive experiments with SOTA machine
unlearning models and demonstrated the effectiveness of our approach for
accuracy and end-to-end unlearning performance.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16828" title="Abstract">arXiv:2312.16828</a> [<a href="/pdf/2312.16828" title="Download PDF">pdf</a>, <a href="/format/2312.16828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GUITAR: Gradient Pruning toward Fast Neural Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shulong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With the continuous popularity of deep learning and representation learning,
fast vector search becomes a vital task in various ranking/retrieval based
applications, say recommendation, ads ranking and question answering. Neural
network based ranking is widely adopted due to its powerful capacity in
modeling complex relationships, such as between users and items, questions and
answers. However, it is usually exploited in offline or re-ranking manners for
it is time-consuming in computations. Online neural network ranking--so called
fast neural ranking--is considered challenging because neural network measures
are usually non-convex and asymmetric. Traditional Approximate Nearest Neighbor
(ANN) search which usually focuses on metric ranking measures, is not
applicable to these advanced measures.
<br />In this paper, we introduce a novel graph searching framework to accelerate
the searching in the fast neural ranking problem. The proposed graph searching
algorithm is bi-level: we first construct a probable candidate set; then we
only evaluate the neural network measure over the probable candidate set
instead of evaluating the neural network over all neighbors. Specifically, we
propose a gradient-based algorithm that approximates the rank of the neural
network matching score to construct the probable candidate set; and we present
an angle-based heuristic procedure to adaptively identify the proper size of
the probable candidate set. Empirical results on public data confirm the
effectiveness of our proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16830" title="Abstract">arXiv:2312.16830</a> [<a href="/pdf/2312.16830" title="Download PDF">pdf</a>, <a href="/format/2312.16830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contrastive Variational Graph Auto-Encoder for Node Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mrabah%2C+N">Nairouz Mrabah</a>, 
<a href="/search/cs?searchtype=author&query=Bouguessa%2C+M">Mohamed Bouguessa</a>, 
<a href="/search/cs?searchtype=author&query=Ksantini%2C+R">Riadh Ksantini</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Variational Graph Auto-Encoders (VGAEs) have been widely used to solve the
node clustering task. However, the state-of-the-art methods have numerous
challenges. First, existing VGAEs do not account for the discrepancy between
the inference and generative models after incorporating the clustering
inductive bias. Second, current models are prone to degenerate solutions that
make the latent codes match the prior independently of the input signal (i.e.,
Posterior Collapse). Third, existing VGAEs overlook the effect of the noisy
clustering assignments (i.e., Feature Randomness) and the impact of the strong
trade-off between clustering and reconstruction (i.e., Feature Drift). To
address these problems, we formulate a variational lower bound in a contrastive
setting. Our lower bound is a tighter approximation of the log-likelihood
function than the corresponding Evidence Lower BOund (ELBO). Thanks to a newly
identified term, our lower bound can escape Posterior Collapse and has more
flexibility to account for the difference between the inference and generative
models. Additionally, our solution has two mechanisms to control the trade-off
between Feature Randomness and Feature Drift. Extensive experiments show that
the proposed method achieves state-of-the-art clustering results on several
datasets. We provide strong evidence that this improvement is attributed to
four aspects: integrating contrastive learning and alleviating Feature
Randomness, Feature Drift, and Posterior Collapse.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16831" title="Abstract">arXiv:2312.16831</a> [<a href="/pdf/2312.16831" title="Download PDF">pdf</a>, <a href="/format/2312.16831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> METER: A Dynamic Concept Adaptation Framework for Online Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiaqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaofeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+F">Fang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Real-time analytics and decision-making require online anomaly detection
(OAD) to handle drifts in data streams efficiently and effectively.
Unfortunately, existing approaches are often constrained by their limited
detection capacity and slow adaptation to evolving data streams, inhibiting
their efficacy and efficiency in handling concept drift, which is a major
challenge in evolving data streams. In this paper, we introduce METER, a novel
dynamic concept adaptation framework that introduces a new paradigm for OAD.
METER addresses concept drift by first training a base detection model on
historical data to capture recurring central concepts, and then learning to
dynamically adapt to new concepts in data streams upon detecting concept drift.
Particularly, METER employs a novel dynamic concept adaptation technique that
leverages a hypernetwork to dynamically generate the parameter shift of the
base detection model, providing a more effective and efficient solution than
conventional retraining or fine-tuning approaches. Further, METER incorporates
a lightweight drift detection controller, underpinned by evidential deep
learning, to support robust and interpretable concept drift detection. We
conduct an extensive experimental evaluation, and the results show that METER
significantly outperforms existing OAD approaches in various application
scenarios.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16834" title="Abstract">arXiv:2312.16834</a> [<a href="/pdf/2312.16834" title="Download PDF">pdf</a>, <a href="/format/2312.16834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Aggregations for High-Dimensional Multiplex Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdous%2C+K">Kamel Abdous</a>, 
<a href="/search/cs?searchtype=author&query=Mrabah%2C+N">Nairouz Mrabah</a>, 
<a href="/search/cs?searchtype=author&query=Bouguessa%2C+M">Mohamed Bouguessa</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We investigate the problem of multiplex graph embedding, that is, graphs in
which nodes interact through multiple types of relations (dimensions). In
recent years, several methods have been developed to address this problem.
However, the need for more effective and specialized approaches grows with the
production of graph data with diverse characteristics. In particular,
real-world multiplex graphs may exhibit a high number of dimensions, making it
difficult to construct a single consensus representation. Furthermore,
important information can be hidden in complex latent structures scattered in
multiple dimensions. To address these issues, we propose HMGE, a novel
embedding method based on hierarchical aggregation for high-dimensional
multiplex graphs. Hierarchical aggregation consists of learning a hierarchical
combination of the graph dimensions and refining the embeddings at each
hierarchy level. Non-linear combinations are computed from previous ones, thus
uncovering complex information and latent structures hidden in the multiplex
graph dimensions. Moreover, we leverage mutual information maximization between
local patches and global summaries to train the model without supervision. This
allows to capture of globally relevant information present in diverse locations
of the graph. Detailed experiments on synthetic and real-world data illustrate
the suitability of our approach to downstream supervised tasks, including link
prediction and node classification.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16836" title="Abstract">arXiv:2312.16836</a> [<a href="/pdf/2312.16836" title="Download PDF">pdf</a>, <a href="/format/2312.16836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remixed2Remixed: Domain adaptation for speech enhancement by Noise2Noise  learning with Remixing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Seki%2C+S">Shogo Seki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes Remixed2Remixed, a domain adaptation method for speech
enhancement, which adopts Noise2Noise (N2N) learning to adapt models trained on
artificially generated (out-of-domain: OOD) noisy-clean pair data to better
separate real-world recorded (in-domain) noisy data. The proposed method uses a
teacher model trained on OOD data to acquire pseudo-in-domain speech and noise
signals, which are shuffled and remixed twice in each batch to generate two
bootstrapped mixtures. The student model is then trained by optimizing an
N2N-based cost function computed using these two bootstrapped mixtures. As the
training strategy is similar to the recently proposed RemixIT, we also
investigate the effectiveness of N2N-based loss as a regularization of RemixIT.
Experimental results on the CHiME-7 unsupervised domain adaptation for
conversational speech enhancement (UDASE) task revealed that the proposed
method outperformed the challenge baseline system, RemixIT, and reduced the
blurring of performance caused by teacher models.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16837" title="Abstract">arXiv:2312.16837</a> [<a href="/pdf/2312.16837" title="Download PDF">pdf</a>, <a href="/format/2312.16837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaption  by Combining 3D GANs and Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Biwen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Miaomiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-guided domain adaption and generation of 3D-aware portraits find many
applications in various fields. However, due to the lack of training data and
the challenges in handling the high variety of geometry and appearance, the
existing methods for these tasks suffer from issues like inflexibility,
instability, and low fidelity. In this paper, we propose a novel framework
DiffusionGAN3D, which boosts text-guided 3D domain adaption and generation by
combining 3D GANs and diffusion priors. Specifically, we integrate the
pre-trained 3D generative models (e.g., EG3D) and text-to-image diffusion
models. The former provides a strong foundation for stable and high-quality
avatar generation from text. And the diffusion models in turn offer powerful
priors and guide the 3D generator finetuning with informative direction to
achieve flexible and efficient text-guided domain adaption. To enhance the
diversity in domain adaption and the generation capability in text-to-avatar,
we introduce the relative distance loss and case-specific learnable triplane
respectively. Besides, we design a progressive texture refinement module to
improve the texture quality for both tasks above. Extensive experiments
demonstrate that the proposed framework achieves excellent results in both
domain adaption and text-to-avatar tasks, outperforming existing methods in
terms of generation quality and efficiency. The project homepage is at
https://younglbw.github.io/DiffusionGAN3D-homepage/.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16839" title="Abstract">arXiv:2312.16839</a> [<a href="/pdf/2312.16839" title="Download PDF">pdf</a>, <a href="/format/2312.16839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similar but Different: A Survey of Ground Segmentation and  Traversability Estimation for Terrestrial Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyungae Lim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+M">Minho Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Seunguk Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Myung%2C+H">Hyun Myung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the increasing demand for mobile robots and autonomous vehicles, several
approaches for long-term robot navigation have been proposed. Among these
techniques, ground segmentation and traversability estimation play important
roles in perception and path planning, respectively. Even though these two
techniques appear similar, their objectives are different. Ground segmentation
divides data into ground and non-ground elements; thus, it is used as a
preprocessing stage to extract objects of interest by rejecting ground points.
In contrast, traversability estimation identifies and comprehends areas in
which robots can move safely. Nevertheless, some researchers use these terms
without clear distinction, leading to misunderstanding the two concepts.
Therefore, in this study, we survey related literature and clearly distinguish
ground and traversable regions considering four aspects: a) maneuverability of
robot platforms, b) position of a robot in the surroundings, c) subset relation
of negative obstacles, and d) subset relation of deformable objects.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16840" title="Abstract">arXiv:2312.16840</a> [<a href="/pdf/2312.16840" title="Download PDF">pdf</a>, <a href="/ps/2312.16840" title="Download PostScript">ps</a>, <a href="/format/2312.16840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hiding in Plain Sight: Towards the Science of Linguistic Steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj-Sankar%2C+L">Leela Raj-Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+S+R">S. Raj Rajagopalan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Covert communication (also known as steganography) is the practice of
concealing a secret inside an innocuous-looking public object (cover) so that
the modified public object (covert code) makes sense to everyone but only
someone who knows the code can extract the secret (message). Linguistic
steganography is the practice of encoding a secret message in natural language
text such as spoken conversation or short public communications such as
tweets.. While ad hoc methods for covert communications in specific domains
exist ( JPEG images, Chinese poetry, etc), there is no general model for
linguistic steganography specifically. We present a novel mathematical
formalism for creating linguistic steganographic codes, with three parameters:
Decodability (probability that the receiver of the coded message will decode
the cover correctly), density (frequency of code words in a cover code), and
detectability (probability that an attacker can tell the difference between an
untampered cover compared to its steganized version). Verbal or linguistic
steganography is most challenging because of its lack of artifacts to hide the
secret message in. We detail a practical construction in Python of a
steganographic code for Tweets using inserted words to encode hidden digits
while using n-gram frequency distortion as the measure of detectability of the
insertions. Using the publicly accessible Stanford Sentiment Analysis dataset
we implemented the tweet steganization scheme -- a codeword (an existing word
in the data set) inserted in random positions in random existing tweets to find
the tweet that has the least possible n-gram distortion. We argue that this
approximates KL distance in a localized manner at low cost and thus we get a
linguistic steganography scheme that is both formal and practical and permits a
tradeoff between codeword density and detectability of the covert message.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16842" title="Abstract">arXiv:2312.16842</a> [<a href="/pdf/2312.16842" title="Download PDF">pdf</a>, <a href="/format/2312.16842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Appearance Modeling of Clothed 3D Human Avatars using a Single  Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hansol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Junuk Cha</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+Y">Yunhoe Ku</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J+S">Jae Shin Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungryul Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The appearance of a human in clothing is driven not only by the pose but also
by its temporal context, i.e., motion. However, such context has been largely
neglected by existing monocular human modeling methods whose neural networks
often struggle to learn a video of a person with large dynamics due to the
motion ambiguity, i.e., there exist numerous geometric configurations of
clothes that are dependent on the context of motion even for the same pose. In
this paper, we introduce a method for high-quality modeling of clothed 3D human
avatars using a video of a person with dynamic movements. The main challenge
comes from the lack of 3D ground truth data of geometry and its temporal
correspondences. We address this challenge by introducing a novel compositional
human modeling framework that takes advantage of both explicit and implicit
human modeling. For explicit modeling, a neural network learns to generate
point-wise shape residuals and appearance features of a 3D body model by
comparing its 2D rendering results and the original images. This explicit model
allows for the reconstruction of discriminative 3D motion features from UV
space by encoding their temporal correspondences. For implicit modeling, an
implicit network combines the appearance and 3D motion features to decode
high-fidelity clothed 3D human avatars with motion-dependent geometry and
texture. The experiments show that our method can generate a large variation of
secondary motion in a physically plausible way.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16845" title="Abstract">arXiv:2312.16845</a> [<a href="/pdf/2312.16845" title="Download PDF">pdf</a>, <a href="/format/2312.16845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Performance of Large Language Models for Spanish Language  in Undergraduate Admissions Exams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miranda%2C+S">Sabino Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Pichardo-Lagunas%2C+O">Obdulia Pichardo-Lagunas</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Seis%2C+B">Bella Mart&#xed;nez-Seis</a>, 
<a href="/search/cs?searchtype=author&query=Baldi%2C+P">Pierre Baldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure. Submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study evaluates the performance of large language models, specifically
GPT-3.5 and BARD (supported by Gemini Pro model), in undergraduate admissions
exams proposed by the National Polytechnic Institute in Mexico. The exams cover
Engineering/Mathematical and Physical Sciences, Biological and Medical
Sciences, and Social and Administrative Sciences. Both models demonstrated
proficiency, exceeding the minimum acceptance scores for respective academic
programs to up to 75% for some academic programs. GPT-3.5 outperformed BARD in
Mathematics and Physics, while BARD performed better in History and questions
related to factual information. Overall, GPT-3.5 marginally surpassed BARD with
scores of 60.94% and 60.42%, respectively.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16850" title="Abstract">arXiv:2312.16850</a> [<a href="/pdf/2312.16850" title="Download PDF">pdf</a>, <a href="/format/2312.16850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accent-VITS:accent transfer for end-to-end TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Linhan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongmao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Ziqian Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengcheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Accent transfer aims to transfer an accent from a source speaker to synthetic
speech in the target speaker's voice. The main challenge is how to effectively
disentangle speaker timbre and accent which are entangled in speech. This paper
presents a VITS-based end-to-end accent transfer model named Accent-VITS.Based
on the main structure of VITS, Accent-VITS makes substantial improvements to
enable effective and stable accent transfer.We leverage a hierarchical CVAE
structure to model accent pronunciation information and acoustic features,
respectively, using bottleneck features and mel spectrums as
constraints.Moreover, the text-to-wave mapping in VITS is decomposed into
text-to-accent and accent-to-wave mappings in Accent-VITS.In this way, the
disentanglement of accent and speaker timbre becomes be more stable and
effective.Experiments on multi-accent and Mandarin datasets show that
Accent-VITS achieves higher speaker similarity, accent similarity and speech
naturalness as compared with a strong baseline.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16852" title="Abstract">arXiv:2312.16852</a> [<a href="/pdf/2312.16852" title="Download PDF">pdf</a>, <a href="/format/2312.16852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensor Data Simulation for Anomaly Detection of the Elderly Living Alone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kai Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Kudo%2C+M">Mineichi Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Kimura%2C+K">Keigo Kimura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">With the increase of the number of elderly people living alone around the
world, there is a growing demand for sensor-based detection of anomalous
behaviors. Although smart homes with ambient sensors could be useful for
detecting such anomalies, there is a problem of lack of sufficient real data
for developing detection algorithms. For coping with this problem, several
sensor data simulators have been proposed, but they have not been able to model
appropriately the long-term transitions and correlations between anomalies that
exist in reality. In this paper, therefore, we propose a novel sensor data
simulator that can model these factors in generation of sensor data. Anomalies
considered in this study were classified into three types of \textit{state
anomalies}, \textit{activity anomalies}, and \textit{moving anomalies}. The
simulator produces 10 years data in 100 min. including six anomalies, two for
each type. Numerical evaluations show that this simulator is superior to the
past simulators in the sense that it simulates well day-to-day variations of
real data.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16854" title="Abstract">arXiv:2312.16854</a> [<a href="/pdf/2312.16854" title="Download PDF">pdf</a>, <a href="/format/2312.16854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRIAD: Automated Traceability Recovery based on Biterm-enhanced  Deduction of Transitive Links among Artifacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+H">Hongyu Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Assun%C3%A7%C3%A3o%2C+W+K+G">Wesley K. G. Assun&#xe7;&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Mayr-Dorn%2C+C">Christoph Mayr-Dorn</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+G">Guoping Rong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Egyed%2C+A">Alexander Egyed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 46th International Conference on Software Engineering (ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Traceability allows stakeholders to extract and comprehend the trace links
among software artifacts introduced across the software life cycle, to provide
significant support for software engineering tasks. Despite its proven
benefits, software traceability is challenging to recover and maintain
manually. Hence, plenty of approaches for automated traceability have been
proposed. Most rely on textual similarities among software artifacts, such as
those based on Information Retrieval (IR). However, artifacts in different
abstraction levels usually have different textual descriptions, which can
greatly hinder the performance of IR-based approaches (e.g., a requirement in
natural language may have a small textual similarity to a Java class). In this
work, we leverage the consensual biterms and transitive relationships (i.e.,
inner- and outer-transitive links) based on intermediate artifacts to improve
IR-based traceability recovery. We first extract and filter biterms from all
source, intermediate, and target artifacts. We then use the consensual biterms
from the intermediate artifacts to extend the biterms of both source and target
artifacts, and finally deduce outer and inner-transitive links to adjust text
similarities between source and target artifacts. We conducted a comprehensive
empirical evaluation based on five systems widely used in other literature to
show that our approach can outperform four state-of-the-art approaches, and how
its performance is affected by different conditions of source, intermediate,
and target artifacts. The results indicate that our approach can outperform
baseline approaches in AP over 15% and MAP over 10% on average.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16855" title="Abstract">arXiv:2312.16855</a> [<a href="/pdf/2312.16855" title="Download PDF">pdf</a>, <a href="/format/2312.16855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular Property Prediction Based on Graph Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bangyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weixia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jihong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuigeng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Molecular property prediction (MPP) is a fundamental but challenging task in
the computer-aided drug discovery process. More and more recent works employ
different graph-based models for MPP, which have made considerable progress in
improving prediction performance. However, current models often ignore
relationships between molecules, which could be also helpful for MPP. For this
sake, in this paper we propose a graph structure learning (GSL) based MPP
approach, called GSL-MPP. Specifically, we first apply graph neural network
(GNN) over molecular graphs to extract molecular representations. Then, with
molecular fingerprints, we construct a molecular similarity graph (MSG).
Following that, we conduct graph structure learning on the MSG (i.e.,
molecule-level graph structure learning) to get the final molecular embeddings,
which are the results of fusing both GNN encoded molecular representations and
the relationships among molecules, i.e., combining both intra-molecule and
inter-molecule information. Finally, we use these molecular embeddings to
perform MPP. Extensive experiments on seven various benchmark datasets show
that our method could achieve state-of-the-art performance in most cases,
especially on classification tasks. Further visualization studies also
demonstrate the good molecular representations of our method.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16860" title="Abstract">arXiv:2312.16860</a> [<a href="/pdf/2312.16860" title="Download PDF">pdf</a>, <a href="/format/2312.16860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble-based Interactive Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chicheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 59 figures, under review of AISTATS conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study interactive imitation learning, where a learner interactively
queries a demonstrating expert for action annotations, aiming to learn a policy
that has performance competitive with the expert, using as few annotations as
possible. We give an algorithmic framework named Ensemble-based Interactive
Imitation Learning (EIIL) that achieves this goal. Theoretically, we prove that
an oracle-efficient version of EIIL achieves sharp regret guarantee, given
access to samples from some ``explorative'' distribution over states.
Empirically, EIIL notably surpasses online and offline imitation learning
benchmarks in continuous control tasks. Our work opens up systematic
investigations on the benefit of using model ensembles for interactive
imitation learning.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16862" title="Abstract">arXiv:2312.16862</a> [<a href="/pdf/2312.16862" title="Download PDF">pdf</a>, <a href="/format/2312.16862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhengqing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaoxu Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In the era of advanced multimodel learning, multimodal large language models
(MLLMs) such as GPT-4V have made remarkable strides towards bridging language
and visual elements. However, the closed-source nature and considerable
computational demand present notable challenges for universal usage and
modifications. This is where open-source MLLMs like LLaVA and MiniGPT-4 come
in, presenting groundbreaking achievements across tasks. Despite these
accomplishments, computational efficiency remains an unresolved issue, as these
models, like LLaVA-v1.5-13B, require substantial resources. Addressing these
issues, we introduce TinyGPT-V, a new-wave model marrying impressive
performance with commonplace computational capacity. It stands out by requiring
merely a 24G GPU for training and an 8G GPU or CPU for inference. Built upon
Phi-2, TinyGPT-V couples an effective language backbone with pre-trained vision
modules from BLIP-2 or CLIP. TinyGPT-V's 2.8B parameters can undergo a unique
quantisation process, suitable for local deployment and inference tasks on 8G
various devices. Our work fosters further developments for designing
cost-effective, efficient, and high-performing MLLMs, expanding their
applicability in a broad array of real-world scenarios. Furthermore this paper
proposed a new paradigm of Multimodal Large Language Model via small backbones.
Our code and training weights are placed at:
https://github.com/DLYuanGod/TinyGPT-V and
https://huggingface.co/Tyrannosaurus/TinyGPT-V respectively.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16864" title="Abstract">arXiv:2312.16864</a> [<a href="/pdf/2312.16864" title="Download PDF">pdf</a>, <a href="/format/2312.16864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniDialog: An Omnipotent Pre-training Model for Task-Oriented Dialogue  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingtao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jinlan Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained conversation models (PCMs) have demonstrated remarkable results
in task-oriented dialogue (TOD) systems. Many PCMs focus predominantly on
dialogue management tasks like dialogue state tracking, dialogue generation
tasks like response generation, or both. However, the existing PCMs seldom
consider dialogue comprehension tasks, such as dialogue question answering and
summarization tasks. These tasks allow PCMs to glean dialogue context from
various angles. This observation naturally raises the question: Can the
performance of downstream dialogue tasks be enhanced if a PCM is pre-trained on
dialogue management, generation, and comprehension tasks?
<br />To investigate this, we proposed an Omnipotent Dialogue pre-training model
(OmniDialog). It unifies these three dialogue tasks into a monolithic framework
by multi-task learning, fostering inter-task communication. The pre-training
corpus of OmniDialog spans $\mathbf{7}$ dialogue-focused tasks, drawing from
$\mathbf{15}$ datasets and encompassing over $\mathbf{3.2}$ million dialogue
utterances. To our knowledge, OmniDialog is a pioneering PCM pre-trained across
dialogue management, generation, and comprehension domains. We evaluated its
performance across four tasks: dialogue summarization, end-to-end dialogue
modeling, dialogue state tracking, and intent classification. The results
underscore its efficacy in domain transfer learning, low-resource, and
full-dataset scenarios. Furthermore, to glean a nuanced understanding of
OmniDialog's strengths and potential pitfalls, we designed a fine-grained
analysis framework for dialogue-centric tasks. Experimental results show that
the OmniDialog is good at hard samples, such as long dialogues and lengthy
responses.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16867" title="Abstract">arXiv:2312.16867</a> [<a href="/pdf/2312.16867" title="Download PDF">pdf</a>, <a href="/format/2312.16867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualFluidNet: an Attention-based Dual-pipeline Network for Accurate and  Generalizable Fluid-solid Coupled Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Menglong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nianyi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Fluid motion can be considered as point cloud transformation when adopted by
a Lagrangian description. Compared to traditional numerical analysis methods,
using machine learning techniques to learn physics simulations can achieve near
accuracy, while significantly increasing efficiency. In this paper, we propose
an innovative approach for 3D fluid simulations utilizing an Attention-based
Dual-pipeline Network, which employs a dual-pipeline architecture, seamlessly
integrated with an Attention-based Feature Fusion Module. Unlike previous
single-pipeline approaches, we find that a well-designed dual-pipeline approach
achieves a better balance between global fluid control and physical law
constraints. Furthermore, we design a Type-aware Input Module to adaptively
recognize particles of different types and perform feature fusion afterward,
such that fluid-solid coupling issues can be better dealt with. The experiments
show that our approach significantly increases the accuracy of fluid simulation
predictions and enhances generalizability to previously unseen scenarios. We
demonstrate its superior performance over the state-of-the-art approaches
across various metrics.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16868" title="Abstract">arXiv:2312.16868</a> [<a href="/pdf/2312.16868" title="Download PDF">pdf</a>, <a href="/format/2312.16868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto-based Multi-Objective Recommender System with Forgetting Curve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jipeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiongwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems with cascading architecture play an increasingly
significant role in online recommendation platforms, where the approach to
dealing with negative feedback is a vital issue. For instance, in short video
platforms, users tend to quickly slip away from candidates that they feel
aversive, and recommender systems are expected to receive these explicit
negative feedbacks and make adjustments to avoid these recommendations.
Considering recency effect in memories, we propose a forgetting model based on
Ebbinghaus Forgetting Curve to cope with negative feedback. In addition, we
introduce a Pareto optimization solver to guarantee a better trade-off between
recency and model performance. In conclusion, we propose Pareto-based
Multi-Objective Recommender System with forgetting curve (PMORS), which can be
applied to any multi-objective recommendation and show sufficiently superiority
when facing explicit negative feedback. We have conducted evaluations of PMORS
and achieved favorable outcomes in short-video scenarios on both public dataset
and industrial dataset. After being deployed on an online short video platform
named WeChat Channels in May, 2023, PMORS has not only demonstrated promising
results for both consistency and recency but also achieved an improvement of up
to +1.45% GMV.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16870" title="Abstract">arXiv:2312.16870</a> [<a href="/pdf/2312.16870" title="Download PDF">pdf</a>, <a href="/format/2312.16870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ANKA: A Decentralized Blockchain-based Energy Marketplace for  Battery-powered Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahin%2C+B+C">Burak Can Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Zekiye%2C+A">Abdulrezzak Zekiye</a>, 
<a href="/search/cs?searchtype=author&query=Ozkasap%2C+O">Oznur Ozkasap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shorter version of this paper was presented as a poster paper in the Fifth ACM International Workshop on Blockchain-enabled Networked Sensor Systems (BlockSys)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">For the purpose of enabling, democratizing, and reducing the fees of
peer-to-peer energy trading for battery-powered devices, we propose ANKA as a
fully decentralized energy marketplace for peers with battery-powered devices.
ANKA utilizes state-of-the-art technologies, namely blockchain, smart
contracts, and decentralized applications. Within this marketplace, users who
possess surplus energy actively offer their excess energy for trading.
Concurrently, consumers can readily explore the energy options available and
make purchases according to their individual preferences while taking into
consideration the location of the offered energy and voltage compatibility. In
addition, we provide a comparison between a centralized traditional market and
our proposed solution, identifying that the cost of deploying and operating
ANKA is less than the centralized approach. We also position ANKA in comparison
to the recent blockchain-based decentralized energy marketplaces by considering
the metrics of blockchain type, scope, trading entities and the presence of
third parties.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16874" title="Abstract">arXiv:2312.16874</a> [<a href="/pdf/2312.16874" title="Download PDF">pdf</a>, <a href="/format/2312.16874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Surfaces for 6G: Emerging Hardware  Architectures, Applications, and Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>, 
<a href="/search/cs?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures, 54 references, IEEE Vehicular Technology Magazine - Invited Article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RISs) are rapidly gaining prominence in
the realm of fifth generation (5G)-Advanced, and predominantly, sixth
generation (6G) mobile networks, offering a revolutionary approach to
optimizing wireless communications. This article delves into the intricate
world of the RIS technology, exploring its diverse hardware architectures and
the resulting versatile operating modes. These include RISs with signal
reception and processing units, sensors, amplification units, transmissive
capability, multiple stacked components, and dynamic metasurface antennas.
Furthermore, we shed light on emerging RIS applications, such as index and
reflection modulation, non-coherent modulation, next generation multiple
access, integrated sensing and communications (ISAC), energy harvesting, as
well as aerial and vehicular networks. These exciting applications are set to
transform the way we will wirelessly connect in the upcoming era of 6G.
Finally, we review recent experimental RIS setups and present various open
problems of the overviewed RIS hardware architectures and their applications.
From enhancing network coverage to enabling new communication paradigms,
RIS-empowered connectivity is poised to play a pivotal role in shaping the
future of wireless networking. This article unveils the underlying principles
and potential impacts of RISs, focusing on cutting-edge developments of this
physical-layer smart connectivity technology.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16880" title="Abstract">arXiv:2312.16880</a> [<a href="/pdf/2312.16880" title="Download PDF">pdf</a>, <a href="/ps/2312.16880" title="Download PostScript">ps</a>, <a href="/format/2312.16880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks on Image Classification Models: Analysis and Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+J">Jaydip Sen</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+A">Abhiraj Sen</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Ananda Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the accepted version of the paper presented at the 10th International Conference on Business Analytics and Intelligence (ICBAI'24). The conference was organized by the Indian Institute of Science, Bangalore, India, from December 18 - 20, 2023. The paper is 10 pages long and it contains 14 tables and 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The notion of adversarial attacks on image classification models based on
convolutional neural networks (CNN) is introduced in this work. To classify
images, deep learning models called CNNs are frequently used. However, when the
networks are subject to adversarial attacks, extremely potent and previously
trained CNN models that perform quite effectively on image datasets for image
classification tasks may perform poorly. In this work, one well-known
adversarial attack known as the fast gradient sign method (FGSM) is explored
and its adverse effects on the performances of image classification models are
examined. The FGSM attack is simulated on three pre-trained image classifier
CNN architectures, ResNet-101, AlexNet, and RegNetY 400MF using randomly chosen
images from the ImageNet dataset. The classification accuracies of the models
are computed in the absence and presence of the attack to demonstrate the
detrimental effect of the attack on the performances of the classifiers.
Finally, a mechanism is proposed to defend against the FGSM attack based on a
modified defensive distillation-based approach. Extensive results are presented
for the validation of the proposed scheme.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16881" title="Abstract">arXiv:2312.16881</a> [<a href="/pdf/2312.16881" title="Download PDF">pdf</a>, <a href="/format/2312.16881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring 3D-aware Lifespan Face Aging via Disentangled Shape-Texture  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+Q">Qianrui Teng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peipei Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing face aging methods often focus on modeling either texture aging or
using an entangled shape-texture representation to achieve face aging. However,
shape and texture are two distinct factors that mutually affect the human face
aging process. In this paper, we propose 3D-STD, a novel 3D-aware Shape-Texture
Disentangled face aging network that explicitly disentangles the facial image
into shape and texture representations using 3D face reconstruction.
Additionally, to facilitate high-fidelity texture synthesis, we propose a novel
texture generation method based on Empirical Mode Decomposition (EMD).
Extensive qualitative and quantitative experiments show that our method
achieves state-of-the-art performance in terms of shape and texture
transformation. Moreover, our method supports producing plausible 3D face aging
results, which is rarely accomplished by current methods.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16882" title="Abstract">arXiv:2312.16882</a> [<a href="/pdf/2312.16882" title="Download PDF">pdf</a>, <a href="/ps/2312.16882" title="Download PostScript">ps</a>, <a href="/format/2312.16882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TypeEvalPy: A Micro-benchmarking Framework for Python Type Inference  Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+A+P+S">Ashwin Prasad Shivarpatna Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Sabu%2C+S">Samkutty Sabu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mir%2C+A+M">Amir M. Mir</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Bodden%2C+E">Eric Bodden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In light of the growing interest in type inference research for Python, both
researchers and practitioners require a standardized process to assess the
performance of various type inference techniques. This paper introduces
TypeEvalPy, a comprehensive micro-benchmarking framework for evaluating type
inference tools. TypeEvalPy contains 154 code snippets with 845 type
annotations across 18 categories that target various Python features. The
framework manages the execution of containerized tools, transforms inferred
types into a standardized format, and produces meaningful metrics for
assessment. Through our analysis, we compare the performance of six type
inference tools, highlighting their strengths and limitations. Our findings
provide a foundation for further research and optimization in the domain of
Python type inference.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16883" title="Abstract">arXiv:2312.16883</a> [<a href="/pdf/2312.16883" title="Download PDF">pdf</a>, <a href="/format/2312.16883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tail-Learning: Adaptive Learning Method for Mitigating Tail Latency in  Autonomous Edge Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yinuo Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hailiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlv Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the realm of edge computing, the increasing demand for high Quality of
Service (QoS), particularly in dynamic multimedia streaming applications (e.g.,
Augmented Reality/Virtual Reality and online gaming), has prompted the need for
effective solutions. Nevertheless, adopting an edge paradigm grounded in
distributed computing has exacerbated the issue of tail latency. Given a
limited variety of multimedia services supported by edge servers and the
dynamic nature of user requests, employing traditional queuing methods to model
tail latency in distributed edge computing is challenging, substantially
exacerbating head-of-line (HoL) blocking. In response to this challenge, we
have developed a learning-based scheduling method to mitigate the overall tail
latency, which adaptively selects appropriate edge servers for execution as
incoming distributed tasks vary with unknown size. To optimize the utilization
of the edge computing paradigm, we leverage Laplace transform techniques to
theoretically derive an upper bound for the response time of edge servers.
Subsequently, we integrate this upper bound into reinforcement learning to
facilitate tail learning and enable informed decisions for autonomous
distributed scheduling. The experiment results demonstrate the efficiency in
reducing tail latency compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16885" title="Abstract">arXiv:2312.16885</a> [<a href="/pdf/2312.16885" title="Download PDF">pdf</a>, <a href="/format/2312.16885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jeffreys divergence-based regularization of neural network output  distribution applied to speaker recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousquet%2C+P">Pierre-Michel Bousquet</a>, 
<a href="/search/cs?searchtype=author&query=Rouvier%2C+M">Mickael Rouvier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A new loss function for speaker recognition with deep neural network is
proposed, based on Jeffreys Divergence. Adding this divergence to the
cross-entropy loss function allows to maximize the target value of the output
distribution while smoothing the non-target values. This objective function
provides highly discriminative features. Beyond this effect, we propose a
theoretical justification of its effectiveness and try to understand how this
loss function affects the model, in particular the impact on dataset types
(i.e. in-domain or out-of-domain w.r.t the training corpus). Our experiments
show that Jeffreys loss consistently outperforms the state-of-the-art for
speaker recognition, especially on out-of-domain data, and helps limit false
alarms.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16886" title="Abstract">arXiv:2312.16886</a> [<a href="/pdf/2312.16886" title="Download PDF">pdf</a>, <a href="/format/2312.16886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileVLM : A Fast, Reproducible and Strong Vision Language Assistant  for Mobile Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Limeng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xinyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaolin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present MobileVLM, a competent multimodal vision language model (MMVLM)
targeted to run on mobile devices. It is an amalgamation of a myriad of
architectural designs and techniques that are mobile-oriented, which comprises
a set of language models at the scale of 1.4B and 2.7B parameters, trained from
scratch, a multimodal vision model that is pre-trained in the CLIP fashion,
cross-modality interaction via an efficient projector. We evaluate MobileVLM on
several typical VLM benchmarks. Our models demonstrate on par performance
compared with a few much larger models. More importantly, we measure the
inference speed on both a Qualcomm Snapdragon 888 CPU and an NVIDIA Jeston Orin
GPU, and we obtain state-of-the-art performance of 21.5 tokens and 65.3 tokens
per second, respectively. Our code will be made available at:
https://github.com/Meituan-AutoML/MobileVLM.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16890" title="Abstract">arXiv:2312.16890</a> [<a href="/pdf/2312.16890" title="Download PDF">pdf</a>, <a href="/format/2312.16890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffKG: Knowledge Graph Diffusion Model for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangqin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by WSDM'2024 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Knowledge Graphs (KGs) have emerged as invaluable resources for enriching
recommendation systems by providing a wealth of factual information and
capturing semantic relationships among items. Leveraging KGs can significantly
enhance recommendation performance. However, not all relations within a KG are
equally relevant or beneficial for the target recommendation task. In fact,
certain item-entity connections may introduce noise or lack informative value,
thus potentially misleading our understanding of user preferences. To bridge
this research gap, we propose a novel knowledge graph diffusion model for
recommendation, referred to as DiffKG. Our framework integrates a generative
diffusion model with a data augmentation paradigm, enabling robust knowledge
graph representation learning. This integration facilitates a better alignment
between knowledge-aware item semantics and collaborative relation modeling.
Moreover, we introduce a collaborative knowledge graph convolution mechanism
that incorporates collaborative signals reflecting user-item interaction
patterns, guiding the knowledge graph diffusion process. We conduct extensive
experiments on three publicly available datasets, consistently demonstrating
the superiority of our DiffKG compared to various competitive baselines. We
provide the source code repository of our proposed DiffKG model at the
following link: https://github.com/HKUDS/DiffKG.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16892" title="Abstract">arXiv:2312.16892</a> [<a href="/pdf/2312.16892" title="Download PDF">pdf</a>, <a href="/format/2312.16892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexSSL : A Generic and Efficient Framework for Semi-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huiling Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanxun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semi-supervised learning holds great promise for many real-world
applications, due to its ability to leverage both unlabeled and expensive
labeled data. However, most semi-supervised learning algorithms still heavily
rely on the limited labeled data to infer and utilize the hidden information
from unlabeled data. We note that any semi-supervised learning task under the
self-training paradigm also hides an auxiliary task of discriminating label
observability. Jointly solving these two tasks allows full utilization of
information from both labeled and unlabeled data, thus alleviating the problem
of over-reliance on labeled data. This naturally leads to a new generic and
efficient learning framework without the reliance on any domain-specific
information, which we call FlexSSL. The key idea of FlexSSL is to construct a
semi-cooperative "game", which forges cooperation between a main
self-interested semi-supervised learning task and a companion task that infers
label observability to facilitate main task training. We show with theoretical
derivation of its connection to loss re-weighting on noisy labels. Through
evaluations on a diverse range of tasks, we demonstrate that FlexSSL can
consistently enhance the performance of semi-supervised learning algorithms.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16893" title="Abstract">arXiv:2312.16893</a> [<a href="/pdf/2312.16893" title="Download PDF">pdf</a>, <a href="/format/2312.16893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BBScore: A Brownian Bridge Based Metric for Assessing Text Coherence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Z">Zhecheng Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongyeop Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Measuring the coherence of text is a vital aspect of evaluating the quality
of written content. Recent advancements in neural coherence modeling have
demonstrated their efficacy in capturing entity coreference and discourse
relations, thereby enhancing coherence evaluation. However, many existing
methods heavily depend on static embeddings or focus narrowly on nearby
context, constraining their capacity to measure the overarching coherence of
long texts. In this paper, we posit that coherent texts inherently manifest a
sequential and cohesive interplay among sentences, effectively conveying the
central theme, purpose, or standpoint. To explore this abstract relationship,
we introduce the "BBScore," a novel reference-free metric grounded in Brownian
bridge theory for assessing text coherence. Our findings showcase that when
synergized with a simple additional classification component, this metric
attains a performance level comparable to state-of-the-art techniques on
standard artificial discrimination tasks. We also establish in downstream tasks
that this metric effectively differentiates between human-written documents and
text generated by large language models under a specific domain. Furthermore,
we illustrate the efficacy of this approach in detecting written styles
attributed to diverse large language models, underscoring its potential for
generalizability. In summary, we present a novel Brownian bridge coherence
metric capable of measuring both local and global text coherence, while
circumventing the need for end-to-end model training. This flexibility allows
for its application in various downstream tasks.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16894" title="Abstract">arXiv:2312.16894</a> [<a href="/pdf/2312.16894" title="Download PDF">pdf</a>, <a href="/ps/2312.16894" title="Download PostScript">ps</a>, <a href="/format/2312.16894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chaurah: A Smart Raspberry Pi based Parking System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhaury%2C+S+R">Soumya Ranjan Choudhaury</a>, 
<a href="/search/cs?searchtype=author&query=Narendra%2C+A">Aditya Narendra</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Ashutosh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+I">Ipsit Misra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 Pages, 9 Figures, Accepted at ICCCT-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The widespread usage of cars and other large, heavy vehicles necessitates the
development of an effective parking infrastructure. Additionally, algorithms
for detection and recognition of number plates are often used to identify
automobiles all around the world where standardized plate sizes and fonts are
enforced, making recognition an effortless task. As a result, both kinds of
data can be combined to develop an intelligent parking system focuses on the
technology of Automatic Number Plate Recognition (ANPR). Retrieving characters
from an inputted number plate image is the sole purpose of ANPR which is a
costly procedure. In this article, we propose Chaurah, a minimal cost ANPR
system that relies on a Raspberry Pi 3 that was specifically created for
parking facilities. The system employs a dual-stage methodology, with the first
stage being an ANPR system which makes use of two convolutional neural networks
(CNNs). The primary locates and recognises license plates from a vehicle image,
while the secondary performs Optical Character Recognition (OCR) to identify
individualized numbers from the number plate. An application built with Flutter
and Firebase for database administration and license plate record comparison
makes up the second component of the overall solution. The application also
acts as an user-interface for the billing mechanism based on parking time
duration resulting in an all-encompassing software deployment of the study.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16895" title="Abstract">arXiv:2312.16895</a> [<a href="/pdf/2312.16895" title="Download PDF">pdf</a>, <a href="/format/2312.16895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLPlanner: Reinforcement Learning based Floorplanning for Chiplets with  Fast Thermal Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuanyuan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xingchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiping Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Leilai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolei Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Chiplet-based systems have gained significant attention in recent years due
to their low cost and competitive performance. As the complexity and
compactness of a chiplet-based system increase, careful consideration must be
given to microbump assignments, interconnect delays, and thermal limitations
during the floorplanning stage. This paper introduces RLPlanner, an efficient
early-stage floorplanning tool for chiplet-based systems with a novel fast
thermal evaluation method. RLPlanner employs advanced reinforcement learning to
jointly minimize total wirelength and temperature. To alleviate the
time-consuming thermal calculations, RLPlanner incorporates the developed fast
thermal evaluation method to expedite the iterations and optimizations.
Comprehensive experiments demonstrate that our proposed fast thermal evaluation
method achieves a mean absolute error (MAE) of 0.25 K and delivers over 120x
speed-up compared to the open-source thermal solver HotSpot. When integrated
with our fast thermal evaluation method, RLPlanner achieves an average
improvement of 20.28\% in minimizing the target objective (a combination of
wirelength and temperature), within a similar running time, compared to the
classic simulated annealing method with HotSpot.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16896" title="Abstract">arXiv:2312.16896</a> [<a href="/pdf/2312.16896" title="Download PDF">pdf</a>, <a href="/format/2312.16896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replication-proof Bandit Mechanism Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+S">Seyed Esmaeili</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Suho Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study a problem of designing replication-proof bandit mechanisms when
agents strategically register or replicate their own arms to maximize their
payoff. We consider Bayesian agents who are unaware of ex-post realization of
their own arms' mean rewards, which is the first to study Bayesian extension of
Shin et al. (2022). This extension presents significant challenges in analyzing
equilibrium, in contrast to the fully-informed setting by Shin et al. (2022)
under which the problem simply reduces to a case where each agent only has a
single arm. With Bayesian agents, even in a single-agent setting, analyzing the
replication-proofness of an algorithm becomes complicated. Remarkably, we first
show that the algorithm proposed by Shin et al. (2022), defined H-UCB, is no
longer replication-proof for any exploration parameters. Then, we provide
sufficient and necessary conditions for an algorithm to be replication-proof in
the single-agent setting. These results centers around several analytical
results in comparing the expected regret of multiple bandit instances, which
might be of independent interest. We further prove that exploration-then-commit
(ETC) algorithm satisfies these properties, whereas UCB does not, which in fact
leads to the failure of being replication-proof. We expand this result to
multi-agent setting, and provide a replication-proof algorithm for any problem
instance. The proof mainly relies on the single-agent result, as well as some
structural properties of ETC and the novel introduction of a restarting round,
which largely simplifies the analysis while maintaining the regret unchanged
(up to polylogarithmic factor). We finalize our result by proving its sublinear
regret upper bound, which matches that of H-UCB.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16902" title="Abstract">arXiv:2312.16902</a> [<a href="/pdf/2312.16902" title="Download PDF">pdf</a>, <a href="/format/2312.16902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Learning for Scattered Point Cloud Understanding with Hierarchical  Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Ming Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+P">Peiyuan Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review. Previously submitted to AAAI and got frustrated. Decisions: 1x weak reject, 2x weak accept, and 1 accept
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerous point-cloud understanding techniques focus on whole entities and
have succeeded in obtaining satisfactory results and limited sparsity
tolerance. However, these methods are generally sensitive to incomplete point
clouds that are scanned with flaws or large gaps. To address this issue, in
this paper, we propose an end-to-end architecture that compensates for and
identifies partial point clouds on the fly. First, we propose a cascaded
solution that integrates both the upstream and downstream networks
simultaneously, allowing the task-oriented downstream to identify the points
generated by the completion-oriented upstream. These two streams complement
each other, resulting in improved performance for both completion and
downstream-dependent tasks. Second, to explicitly understand the predicted
points' pattern, we introduce hierarchical self-distillation (HSD), which can
be applied to arbitrary hierarchy-based point cloud methods. HSD ensures that
the deepest classifier with a larger perceptual field and longer code length
provides additional regularization to intermediate ones rather than simply
aggregating the multi-scale features, and therefore maximizing the mutual
information between a teacher and students. We show the advantage of the
self-distillation process in the hyperspaces based on the information
bottleneck principle. On the classification task, our proposed method performs
competitively on the synthetic dataset and achieves superior results on the
challenging real-world benchmark when compared to the state-of-the-art models.
Additional experiments also demonstrate the superior performance and generality
of our framework on the part segmentation task.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16903" title="Abstract">arXiv:2312.16903</a> [<a href="/pdf/2312.16903" title="Download PDF">pdf</a>, <a href="/format/2312.16903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spike No More: Stabilizing the Pre-training of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takase%2C+S">Sho Takase</a>, 
<a href="/search/cs?searchtype=author&query=Kiyono%2C+S">Shun Kiyono</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+S">Sosuke Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+J">Jun Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The loss spike often occurs during pre-training of a large language model.
The spikes degrade the performance of a large language model, and sometimes
ruin the pre-training. Since the pre-training needs a vast computational
budget, we should avoid such spikes. To investigate a cause of loss spikes, we
focus on gradients of internal layers in this study. Through theoretical
analyses, we introduce two causes of the exploding gradients, and provide
requirements to prevent the explosion. In addition, we introduce the
combination of the initialization method and a simple modification to
embeddings as a method to satisfy the requirements. We conduct various
experiments to verify our theoretical analyses empirically. Experimental
results indicate that the combination is effective in preventing spikes during
pre-training.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16904" title="Abstract">arXiv:2312.16904</a> [<a href="/pdf/2312.16904" title="Download PDF">pdf</a>, <a href="/format/2312.16904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block Pruning for Enhanced Efficiency in Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cheng-En Wu</a>, 
<a href="/search/cs?searchtype=author&query=Davoodi%2C+A">Azadeh Davoodi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y+H">Yu Hen Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel approach to network pruning, targeting block
pruning in deep neural networks for edge computing environments. Our method
diverges from traditional techniques that utilize proxy metrics, instead
employing a direct block removal strategy to assess the impact on
classification accuracy. This hands-on approach allows for an accurate
evaluation of each block's importance. We conducted extensive experiments on
CIFAR-10, CIFAR-100, and ImageNet datasets using ResNet architectures. Our
results demonstrate the efficacy of our method, particularly on large-scale
datasets like ImageNet with ResNet50, where it excelled in reducing model size
while retaining high accuracy, even when pruning a significant portion of the
network. The findings underscore our method's capability in maintaining an
optimal balance between model size and performance, especially in
resource-constrained edge computing scenarios.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16907" title="Abstract">arXiv:2312.16907</a> [<a href="/pdf/2312.16907" title="Download PDF">pdf</a>, <a href="/format/2312.16907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOEPatch: Dynamically Optimized Ensemble Model for Adversarial Patches  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Wenyi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenxing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhunga Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quan Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection is a fundamental task in various applications ranging from
autonomous driving to intelligent security systems. However, recognition of a
person can be hindered when their clothing is decorated with carefully designed
graffiti patterns, leading to the failure of object detection. To achieve
greater attack potential against unknown black-box models, adversarial patches
capable of affecting the outputs of multiple-object detection models are
required. While ensemble models have proven effective, current research in the
field of object detection typically focuses on the simple fusion of the outputs
of all models, with limited attention being given to developing general
adversarial patches that can function effectively in the physical world. In
this paper, we introduce the concept of energy and treat the adversarial
patches generation process as an optimization of the adversarial patches to
minimize the total energy of the ``person'' category. Additionally, by adopting
adversarial training, we construct a dynamically optimized ensemble model.
During training, the weight parameters of the attacked target models are
adjusted to find the balance point at which the generated adversarial patches
can effectively attack all target models. We carried out six sets of
comparative experiments and tested our algorithm on five mainstream object
detection models. The adversarial patches generated by our algorithm can reduce
the recognition accuracy of YOLOv2 and YOLOv3 to 13.19\% and 29.20\%,
respectively. In addition, we conducted experiments to test the effectiveness
of T-shirts covered with our adversarial patches in the physical world and
could achieve that people are not recognized by the object detection model.
Finally, leveraging the Grad-CAM tool, we explored the attack mechanism of
adversarial patches from an energetic perspective.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16909" title="Abstract">arXiv:2312.16909</a> [<a href="/pdf/2312.16909" title="Download PDF">pdf</a>, <a href="/format/2312.16909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A GAN-based Semantic Communication for Text without CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Ke Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhijin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled Ben Letaief</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Recently, semantic communication (SC) has been regarded as one of the
potential paradigms of 6G. Current SC frameworks require channel state
information (CSI) to handle severe signal distortion induced by channel fading.
Since the channel estimation overhead for obtaining CSI cannot be neglected, we
therefore propose a generative adversarial network (GAN) based SC framework
(Ti-GSC) that doesn't require CSI. In Ti-GSC, two main modules, i.e., an
autoencoder-based encoder-decoder module (AEDM) and a GAN-based signal
distortion suppression module (GSDSM) are included where AEDM first encodes the
data at the source before transmission, and then GSDSM suppresses the
distortion of the received signals in both syntactic and semantic dimensions at
the destination. At last, AEDM decodes the distortion-suppressed signal at the
destination. To measure signal distortion, syntactic distortion and semantic
distortion terms are newly added to the total loss function. To achieve better
training results, joint optimization-based training (JOT) and alternating
optimization-based training (AOT) are designed for the proposed Ti-GSC.
Experimental results show that JOT is more efficient for Ti-GSC. Moreover,
without CSI, bilingual evaluation understudy (BLEU) score achieved by Ti-GSC is
about 40% and 62% higher than that achieved by existing SC frameworks in Rician
and Rayleigh fading, respectively. (*Due to the notification of arXiv "The
Abstract field cannot be longer than 1,920 characters", the appeared Abstract
is shortened. For the full Abstract, please download the Article.)
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16914" title="Abstract">arXiv:2312.16914</a> [<a href="/pdf/2312.16914" title="Download PDF">pdf</a>, <a href="/ps/2312.16914" title="Download PostScript">ps</a>, <a href="/format/2312.16914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROI-Aware Multiscale Cross-Attention Vision Transformer for Pest Image  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Ga-Eun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+C">Chang-Hwan Son</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The pests captured with imaging devices may be relatively small in size
compared to the entire images, and complex backgrounds have colors and textures
similar to those of the pests, which hinders accurate feature extraction and
makes pest identification challenging. The key to pest identification is to
create a model capable of detecting regions of interest (ROIs) and transforming
them into better ones for attention and discriminative learning. To address
these problems, we will study how to generate and update the ROIs via
multiscale cross-attention fusion as well as how to be highly robust to complex
backgrounds and scale problems. Therefore, we propose a novel ROI-aware
multiscale cross-attention vision transformer (ROI-ViT). The proposed ROI-ViT
is designed using dual branches, called Pest and ROI branches, which take
different types of maps as input: Pest images and ROI maps. To render such ROI
maps, ROI generators are built using soft segmentation and a class activation
map and then integrated into the ROI-ViT backbone. Additionally, in the dual
branch, complementary feature fusion and multiscale hierarchies are implemented
via a novel multiscale cross-attention fusion. The class token from the Pest
branch is exchanged with the patch tokens from the ROI branch, and vice versa.
The experimental results show that the proposed ROI-ViT achieves 81.81%,
99.64%, and 84.66% for IP102, D0, and SauTeg pest datasets, respectively,
outperforming state-of-the-art (SOTA) models, such as MViT, PVT, DeiT,
Swin-ViT, and EfficientNet. More importantly, for the new challenging dataset
IP102(CBSS) that contains only pest images with complex backgrounds and small
sizes, the proposed model can maintain high recognition accuracy, whereas that
of other SOTA models decrease sharply, demonstrating that our model is more
robust to complex background and scale problems.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16916" title="Abstract">arXiv:2312.16916</a> [<a href="/pdf/2312.16916" title="Download PDF">pdf</a>, <a href="/format/2312.16916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Res-Attn : An Enhanced Res-Tuning Approach with Lightweight Attention  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chaojie Mao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zeyinzi Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Res-Tuning introduces a flexible and efficient paradigm for model tuning,
showing that tuners decoupled from the backbone network can achieve performance
comparable to traditional methods. Existing methods commonly construct the
tuner as a set of trainable low-rank decomposition matrices, positing that a
low-rank subspace suffices for adapting pre-trained foundational models to new
scenarios. In this work, we present an advanced, efficient tuner augmented with
low-rank attention, termed Res-Attn , which also adheres to the Res-Tuning
framework. Res-Attn utilizes a parallel multi-head attention module equipped
with low-rank projections for query, key, and value to execute streamlined
attention operations. Through training this lightweight attention module,
Res-Attn facilitates adaptation to new scenarios. Our extensive experiments
across a range of discriminative and generative tasks showcase the superior
performance of our method when compared to existing alternatives
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16917" title="Abstract">arXiv:2312.16917</a> [<a href="/pdf/2312.16917" title="Download PDF">pdf</a>, <a href="/format/2312.16917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Lattice Graph Fusion for Chinese Named Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingjian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Integrating lexicon into character-level sequence has been proven effective
to leverage word boundary and semantic information in Chinese named entity
recognition (NER). However, prior approaches usually utilize feature weighting
and position coupling to integrate word information, but ignore the semantic
and contextual correspondence between the fine-grained semantic units in the
character-word space. To solve this issue, we propose a Unified Lattice Graph
Fusion (ULGF) approach for Chinese NER. ULGF can explicitly capture various
semantic and boundary relations across different semantic units with the
adjacency matrix by converting the lattice structure into a unified graph. We
stack multiple graph-based intra-source self-attention and inter-source
cross-gating fusion layers that iteratively carry out semantic interactions to
learn node representations. To alleviate the over-reliance on word information,
we further propose to leverage lexicon entity classification as an auxiliary
task. Experiments on four Chinese NER benchmark datasets demonstrate the
superiority of our ULGF approach.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16918" title="Abstract">arXiv:2312.16918</a> [<a href="/pdf/2312.16918" title="Download PDF">pdf</a>, <a href="/format/2312.16918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Surfaces Empowered Wireless Network:Recent Advances and The  Road to 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Beixiong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+X">Xiaodan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+W">Weidong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+B">Boya Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Intelligent surfaces (ISs) have emerged as a key technology to empower a wide
range of appealing applications for wireless networks, due to their low cost,
high energy efficiency, flexibility of deployment and capability of
constructing favorable wireless channels/radio environments. Moreover, the
recent advent of several new IS architectures further expanded their
electromagnetic functionalities from passive reflection to active
amplification, simultaneous reflection and refraction, as well as holographic
beamforming. However, the research on ISs is still in rapid progress and there
have been recent technological advances in ISs and their emerging applications
that are worthy of a timely review. Thus, we provide in this paper a
comprehensive survey on the recent development and advances of ISs aided
wireless networks. Specifically, we start with an overview on the anticipated
use cases of ISs in future wireless networks such as 6G, followed by a summary
of the recent standardization activities related to ISs. Then, the main design
issues of the commonly adopted reflection-based IS and their state-of-theart
solutions are presented in detail, including reflection optimization,
deployment, signal modulation, wireless sensing, and integrated sensing and
communications. Finally, recent progress and new challenges in advanced IS
architectures are discussed to inspire futrue research.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16926" title="Abstract">arXiv:2312.16926</a> [<a href="/pdf/2312.16926" title="Download PDF">pdf</a>, <a href="/ps/2312.16926" title="Download PostScript">ps</a>, <a href="/format/2312.16926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient High-Quality Clustering for Large Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Renchi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jieming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A paper accepted in SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A bipartite graph contains inter-set edges between two disjoint vertex sets,
and is widely used to model real-world data, such as user-item purchase
records, author-article publications, and biological interactions between drugs
and proteins. k-Bipartite Graph Clustering (k-BGC) is to partition the target
vertex set in a bipartite graph into k disjoint clusters. The clustering
quality is important to the utility of k-BGC in various applications like
social network analysis, recommendation systems, text mining, and
bioinformatics, to name a few. Existing approaches to k-BGC either output
clustering results with compromised quality due to inadequate exploitation of
high-order information between vertices, or fail to handle sizable bipartite
graphs with billions of edges.
<br />Motivated by this, this paper presents two efficient k-BGC solutions, HOPE
and HOPE+, which achieve state-of-the-art performance on large-scale bipartite
graphs. HOPE obtains high scalability and effectiveness through a new k-BGC
problem formulation based on the novel notion of high-order perspective (HOP)
vectors and an efficient technique for low-rank approximation of HOP vectors.
HOPE+ further elevates the k-BGC performance to another level with a judicious
problem transformation and a highly efficient two-stage optimization framework.
Two variants, HOPE+ (FNEM) and HOPE+ (SNEM) are designed when either the
Frobenius norm or spectral norm is applied in the transformation. Extensive
experiments, comparing HOPE and HOPE+ against 13 competitors on 10 real-world
datasets, exhibit that our solutions, especially HOPE+, are superior to
existing methods in terms of result quality, while being up to orders of
magnitude faster. On the largest dataset MAG with 1.1 billion edges, HOPE+ is
able to produce clusters with the highest clustering accuracy within 31
minutes, which is unmatched by any existing solution for k-BGC.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16928" title="Abstract">arXiv:2312.16928</a> [<a href="/pdf/2312.16928" title="Download PDF">pdf</a>, <a href="/format/2312.16928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systems of nonlocal balance laws For Dense multilane vehicular traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aggarwal%2C+A">Aekta Aggarwal</a>, 
<a href="/search/math?searchtype=author&query=Holden%2C+H">Helge Holden</a>, 
<a href="/search/math?searchtype=author&query=Vaidya%2C+G">Ganesh Vaidya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We discuss a class of coupled system of nonlocal balance laws modeling
multilane traffic, with the nonlocality present in both convective and source
terms. The uniqueness and existence of the entropy solution is proven via
doubling of the variables arguments and convergent finite volume
approximations, respectively. The numerical approximations are proven to
converge to the unique entropy solution of the system at the rate $\sqrt{\Delta
t}$. The applicability of the proven theory to a general class of systems of
nonlocal balance laws coupled strongly through the convective part and weakly
through the source part, is also indicated. Numerical simulations illustrating
the theory and the behavior of the entropy solution as the support of the
kernel goes to zero(nonlocal to local limit), are shown.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16930" title="Abstract">arXiv:2312.16930</a> [<a href="/pdf/2312.16930" title="Download PDF">pdf</a>, <a href="/format/2312.16930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoding categorical data: Is there yet anything &#x27;hotter&#x27; than one-hot  encoding?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poslavskaya%2C+E">Ekaterina Poslavskaya</a>, 
<a href="/search/cs?searchtype=author&query=Korolev%2C+A">Alexey Korolev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Categorical features are present in about 40% of real world problems,
highlighting the crucial role of encoding as a preprocessing component. Some
recent studies have reported benefits of the various target-based encoders over
classical target-agnostic approaches. However, these claims are not supported
by any statistical analysis, and are based on a single dataset or a very small
and heterogeneous sample of datasets. The present study explores the encoding
effects in an exhaustive sample of classification problems from OpenML
repository. We fitted linear mixed-effects models to the experimental data,
treating task ID as a random effect, and the encoding scheme and the various
characteristics of categorical features as fixed effects. We found that in
multiclass tasks, one-hot encoding and Helmert contrast coding outperform
target-based encoders. In binary tasks, there were no significant differences
across the encoding schemes; however, one-hot encoding demonstrated a
marginally positive effect on the outcome. Importantly, we found no significant
interactions between the encoding schemes and the characteristics of
categorical features. This suggests that our findings are generalizable to a
wide variety of problems across domains.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16931" title="Abstract">arXiv:2312.16931</a> [<a href="/pdf/2312.16931" title="Download PDF">pdf</a>, <a href="/format/2312.16931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeLR: Active Learning for Detection with Decoupled Localization and  Recognition Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R+C">Robert C. Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Active learning has been demonstrated effective to reduce labeling cost,
while most progress has been designed for image recognition, there still lacks
instance-level active learning for object detection. In this paper, we rethink
two key components, i.e., localization and recognition, for object detection,
and find that the correctness of them are highly related, therefore, it is not
necessary to annotate both boxes and classes if we are given pseudo annotations
provided with the trained model. Motivated by this, we propose an efficient
query strategy, termed as DeLR, that Decoupling the Localization and
Recognition for active query. In this way, we are probably free of class
annotations when the localization is correct, and able to assign the labeling
budget for more informative samples. There are two main differences in DeLR: 1)
Unlike previous methods mostly focus on image-level annotations, where the
queried samples are selected and exhausted annotated. In DeLR, the query is
based on region-level, and we only annotate the object region that is queried;
2) Instead of directly providing both localization and recognition annotations,
we separately query the two components, and thus reduce the recognition budget
with the pseudo class labels provided by the model. Experiments on several
benchmarks demonstrate its superiority. We hope our proposed query strategy
would shed light on researches in active learning in object detection.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16933" title="Abstract">arXiv:2312.16933</a> [<a href="/pdf/2312.16933" title="Download PDF">pdf</a>, <a href="/format/2312.16933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvPlug: Learn a Plug-and-Play Module for Event and Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jianping Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+P">Peiqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boxin Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Event cameras and RGB cameras exhibit complementary characteristics in
imaging: the former possesses high dynamic range (HDR) and high temporal
resolution, while the latter provides rich texture and color information. This
makes the integration of event cameras into middle- and high-level RGB-based
vision tasks highly promising. However, challenges arise in multi-modal fusion,
data annotation, and model architecture design. In this paper, we propose
EvPlug, which learns a plug-and-play event and image fusion module from the
supervision of the existing RGB-based model. The learned fusion module
integrates event streams with image features in the form of a plug-in, endowing
the RGB-based model to be robust to HDR and fast motion scenes while enabling
high temporal resolution inference. Our method only requires unlabeled
event-image pairs (no pixel-wise alignment required) and does not alter the
structure or weights of the RGB-based model. We demonstrate the superiority of
EvPlug in several vision tasks such as object detection, semantic segmentation,
and 3D hand pose estimation
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16936" title="Abstract">arXiv:2312.16936</a> [<a href="/pdf/2312.16936" title="Download PDF">pdf</a>, <a href="/format/2312.16936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A data-dependent regularization method based on the graph Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bianchi%2C+D">Davide Bianchi</a>, 
<a href="/search/math?searchtype=author&query=Evangelista%2C+D">Davide Evangelista</a>, 
<a href="/search/math?searchtype=author&query=Aleotti%2C+S">Stefano Aleotti</a>, 
<a href="/search/math?searchtype=author&query=Donatelli%2C+M">Marco Donatelli</a>, 
<a href="/search/math?searchtype=author&query=Piccolomini%2C+E+L">Elena Loli Piccolomini</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+W">Wenbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate a variational method for ill-posed problems, named
$\texttt{graphLa+}\Psi$, which embeds a graph Laplacian operator in the
regularization term. The novelty of this method lies in constructing the graph
Laplacian based on a preliminary approximation of the solution, which is
obtained using any existing reconstruction method $\Psi$ from the literature.
As a result, the regularization term is both dependent on and adaptive to the
observed data and noise. We demonstrate that $\texttt{graphLa+}\Psi$ is a
regularization method and rigorously establish both its convergence and
stability properties.
<br />We present selected numerical experiments in 2D computerized tomography,
wherein we integrate the $\texttt{graphLa+}\Psi$ method with various
reconstruction techniques $\Psi$, including Filter Back Projection
($\texttt{graphLa+FBP}$), standard Tikhonov ($\texttt{graphLa+Tik}$), Total
Variation ($\texttt{graphLa+TV}$), and a trained deep neural network
($\texttt{graphLa+Net}$). The $\texttt{graphLa+}\Psi$ approach significantly
enhances the quality of the approximated solutions for each method $\Psi$.
Notably, $\texttt{graphLa+Net}$ is outperforming, offering a robust and stable
application of deep neural networks in solving inverse problems.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16940" title="Abstract">arXiv:2312.16940</a> [<a href="/pdf/2312.16940" title="Download PDF">pdf</a>, <a href="/format/2312.16940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Signal Recovery and Graph Learning from Incomplete Time-Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javaheri%2C+A">Amirhossein Javaheri</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Arash Amini</a>, 
<a href="/search/cs?searchtype=author&query=Marvasti%2C+F">Farokh Marvasti</a>, 
<a href="/search/cs?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Learning a graph from data is the key to taking advantage of graph signal
processing tools. Most of the conventional algorithms for graph learning
require complete data statistics, which might not be available in some
scenarios. In this work, we aim to learn a graph from incomplete time-series
observations. From another viewpoint, we consider the problem of semi-blind
recovery of time-varying graph signals where the underlying graph model is
unknown. We propose an algorithm based on the method of block successive
upperbound minimization (BSUM), for simultaneous inference of the signal and
the graph from incomplete data.
<br />Simulation results on synthetic and real time-series demonstrate the
performance of the proposed method for graph learning and signal recovery.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16943" title="Abstract">arXiv:2312.16943</a> [<a href="/pdf/2312.16943" title="Download PDF">pdf</a>, <a href="/format/2312.16943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAR-Net: Multi-scale Direction-aware SAR Network via Global Information  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Mingxiang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jie Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daixun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning has driven significant progress in object detection using
Synthetic Aperture Radar (SAR) imagery. Existing methods, while achieving
promising results, often struggle to effectively integrate local and global
information, particularly direction-aware features. This paper proposes
SAR-Net, a novel framework specifically designed for global fusion of
direction-aware information in SAR object detection. SAR-Net leverages two key
innovations: the Unity Compensation Mechanism (UCM) and the Direction-aware
Attention Module (DAM). UCM facilitates the establishment of complementary
relationships among features across different scales, enabling efficient global
information fusion. Among them, Multi-scale Alignment Module (MAM) and distinct
Multi-level Fusion Module (MFM) enhance feature integration by capturing both
texture detail and semantic information. Then, Multi-feature Embedding Module
(MEM) feeds back global features into the primary branches, further improving
information transmission. Additionally, DAM, through bidirectional attention
polymerization, captures direction-aware information, effectively eliminating
background interference. Extensive experiments demonstrate the effectiveness of
SAR-Net, achieving state-of-the-art results on aircraft (SAR-AIRcraft-1.0) and
ship datasets (SSDD, HRSID), confirming its generalization capability and
robustness.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16944" title="Abstract">arXiv:2312.16944</a> [<a href="/pdf/2312.16944" title="Download PDF">pdf</a>, <a href="/format/2312.16944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple and efficient hybrid discretization approach to alleviate  membrane locking in isogeometric thin shells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sauer%2C+R+A">Roger A. Sauer</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhihui Zou</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+T+J+R">Thomas J.R. Hughes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 33 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work presents a new hybrid discretization approach to alleviate membrane
locking in isogeometric finite element formulations for Kirchhoff-Love shells.
The approach is simple, and requires no additional dofs and no static
condensation. It does not increase the bandwidth of the tangent matrix and is
effective for both linear and nonlinear problems. It combines isogeometric
surface discretizations with classical Lagrange-based surface discretizations,
and can thus be run with existing isogeometric finite element codes. Also, the
stresses can be recovered straightforwardly. The effectiveness of the proposed
approach in alleviating, if not eliminating, membrane locking is demonstrated
through the rigorous study of the convergence behavior of several classical
benchmark problems. Accuracy gains are particularly large in the membrane
stresses. The approach is formulated here for quadratic NURBS, but an extension
to other discretization types can be anticipated. The same applies to other
constraints and associated locking phenomena.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16954" title="Abstract">arXiv:2312.16954</a> [<a href="/pdf/2312.16954" title="Download PDF">pdf</a>, <a href="/format/2312.16954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-based Privacy-Preserving Public Key Searchable Encryption  with Strong Traceability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yue Han</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jinguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+W">Weizhi Meng</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jianchang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Ge Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Public key searchable encryption (PKSE) scheme allows data users to search
over encrypted data. To identify illegal users, many traceable PKSE schemes
have been proposed. However, existing schemes cannot trace the keywords which
illegal users searched and protect users' privacy simultaneously. In some
practical applications, tracing both illegal users' identities and the keywords
which they searched is quite important to against the abuse of data. It is a
challenge to bind users' identities and keywords while protecting their
privacy. Moreover, existing traceable PKSE schemes do not consider the
unforgeability and immutability of trapdoor query records, which can lead to
the occurrence of frame-up and denying. In this paper, to solve these problems,
we propose a blockchain-based privacy-preserving PKSE with strong traceability
(BP3KSEST) scheme. Our scheme provides the following features: (1) authorized
users can authenticate to trapdoor generation center and obtain trapdoors
without releasing their identities and keywords; (2) when data users misbehave
in the system, the trusted third party (TTP) can trace both their identities
and the keywords which they searched; (3) trapdoor query records are
unforgeable; (4) trapdoor query records are immutable because records are
stored in blockchain. Notably, this scheme is suitable to the scenarios where
privacy must be considered, e.g., electronic health record (EHR). We formalize
both the definition and security model of our BP3KSEST scheme, and present a
concrete construction. Furthermore, the security of the proposed scheme is
formally proven. Finally, the implementation and evaluation are conducted to
analyze its efficiency.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16957" title="Abstract">arXiv:2312.16957</a> [<a href="/pdf/2312.16957" title="Download PDF">pdf</a>, <a href="/ps/2312.16957" title="Download PostScript">ps</a>, <a href="/format/2312.16957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attack Tree Analysis for Adversarial Evasion Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+Y">Yuki Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Aoki%2C+T">Toshiaki Aoki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 28th IEEE Pacific Rim International Symposium on Dependable
  Computing (PRDC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">Recently, the evolution of deep learning has promoted the application of
machine learning (ML) to various systems. However, there are ML systems, such
as autonomous vehicles, that cause critical damage when they misclassify.
Conversely, there are ML-specific attacks called adversarial attacks based on
the characteristics of ML systems. For example, one type of adversarial attack
is an evasion attack, which uses minute perturbations called "adversarial
examples" to intentionally misclassify classifiers. Therefore, it is necessary
to analyze the risk of ML-specific attacks in introducing ML base systems. In
this study, we propose a quantitative evaluation method for analyzing the risk
of evasion attacks using attack trees. The proposed method consists of the
extension of the conventional attack tree to analyze evasion attacks and the
systematic construction method of the extension. In the extension of the
conventional attack tree, we introduce ML and conventional attack nodes to
represent various characteristics of evasion attacks. In the systematic
construction process, we propose a procedure to construct the attack tree. The
procedure consists of three steps: (1) organizing information about attack
methods in the literature to a matrix, (2) identifying evasion attack scenarios
from methods in the matrix, and (3) constructing the attack tree from the
identified scenarios using a pattern. Finally, we conducted experiments on
three ML image recognition systems to demonstrate the versatility and
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16960" title="Abstract">arXiv:2312.16960</a> [<a href="/pdf/2312.16960" title="Download PDF">pdf</a>, <a href="/format/2312.16960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Flip Graph Algorithm for Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arai%2C+Y">Yamato Arai</a>, 
<a href="/search/cs?searchtype=author&query=Ichikawa%2C+Y">Yuma Ichikawa</a>, 
<a href="/search/cs?searchtype=author&query=Hukushima%2C+K">Koji Hukushima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">This study proposes the "adaptive flip graph algorithm", which combines
adaptive searches with the flip graph algorithm for finding fast and efficient
methods for matrix multiplication. The adaptive flip graph algorithm addresses
the inherent limitations of exploration and inefficient search encountered in
the original flip graph algorithm, particularly when dealing with large matrix
multiplication. For the limitation of exploration, the proposed algorithm
adaptively transitions over the flip graph, introducing a flexibility that does
not strictly reduce the number of multiplications. Concerning the issue of
inefficient search in large instances, the proposed algorithm adaptively
constraints the search range instead of relying on a completely random search,
facilitating more effective exploration. Numerical experimental results
demonstrate the effectiveness of the adaptive flip graph algorithm, showing a
reduction in the number of multiplications for a $4\times 5$ matrix multiplied
by a $5\times 5$ matrix from $76$ to $73$, and that from $95$ to $94$ for a $5
\times 5$ matrix multiplied by another $5\times 5$ matrix. These results are
obtained in characteristic two.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16964" title="Abstract">arXiv:2312.16964</a> [<a href="/pdf/2312.16964" title="Download PDF">pdf</a>, <a href="/ps/2312.16964" title="Download PostScript">ps</a>, <a href="/format/2312.16964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Optimally Shifting Intervals under Intersection Graph  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Droguett%2C+N+H">Nicol&#xe1;s Honorato Droguett</a>, 
<a href="/search/cs?searchtype=author&query=Kurita%2C+K">Kazuhiro Kurita</a>, 
<a href="/search/cs?searchtype=author&query=Hanaka%2C+T">Tesshu Hanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+H">Hirotaka Ono</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We propose a new model for graph editing problems on intersection graphs. In
well-studied graph editing problems, adding and deleting vertices and edges are
used as graph editing operations. As a graph editing operation on intersection
graphs, we propose moving objects corresponding to vertices. In this paper, we
focus on interval graphs as an intersection graph. We give a linear-time
algorithm to find the total moving distance for transforming an interval graph
into a complete graph. The concept of this algorithm can be applied for (i)
transforming a unit square graph into a complete graph over $L_\infty$ distance
and (ii) attaining the existence of a $k$-clique on unit interval graphs. In
addition, we provide LP-formulations to achieve several properties in the
associated graph of unit intervals.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16965" title="Abstract">arXiv:2312.16965</a> [<a href="/pdf/2312.16965" title="Download PDF">pdf</a>, <a href="/format/2312.16965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement-based Display-size Selection for Frugal Satellite Image  Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahbi%2C+H">Hichem Sahbi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel interactive satellite image change detection algorithm
based on active learning. The proposed method is iterative and consists in
frugally probing the user (oracle) about the labels of the most critical
images, and according to the oracle's annotations, it updates change detection
results. First, we consider a probabilistic framework which assigns to each
unlabeled sample a relevance measure modeling how critical is that sample when
training change detection functions. We obtain these relevance measures by
minimizing an objective function mixing diversity, representativity and
uncertainty. These criteria when combined allow exploring different data modes
and also refining change detections. Then, we further explore the potential of
this objective function, by considering a reinforcement learning approach that
finds the best combination of diversity, representativity and uncertainty as
well as display-sizes through active learning iterations, leading to better
generalization as shown through experiments in interactive satellite image
change detection.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16971" title="Abstract">arXiv:2312.16971</a> [<a href="/pdf/2312.16971" title="Download PDF">pdf</a>, <a href="/format/2312.16971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Throughput Inter-Layer Connecting Strategy for Multi-Layer  Ultra-Dense Satellite Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Q">Qi Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Di Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+M">Min Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiandong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Multi-layer ultra-dense satellite networks (MLUDSNs) have soared this
meteoric to provide vast throughputd for globally diverse services. Differing
from traditional monolayer constellations, MLUDSNs emphasize the spatial
integration among layers, and its throughput may not be simply the sum of
throughput of each layer. The hop-count of cross-layer communication paths can
be reduced by deploying inter-layer connections (ILCs), augmenting MLUDSN's
throughput. Therefore, it remains an open issue how to deploy ILCs to optimize
the dynamic MLUDSN topology to dramatically raise throughput gains under
multi-layer collaboration. This paper designs an ILC deployment strategy to
enhance throughput by revealing the impacts of ILC distribution on reducing
hop-count. Since deploying ILCs burdens the satellite with extra communication
resource consumption, we model the ILC deployment problem as minimizing the
average hop with limited ILCs, to maximize throughput. The proposed problem is
a typical integer linear programming (ILP) problem, of which computational
complexity is exponential as the satellite scale expands and the time evolves.
Based on the symmetrical topology of each layer, we propose a two-phase
deployment scheme to halve the problem scale and prioritize stable ILCs to
reduce handover-count, which decreases the exponential complexity to a
polynomial one, with 1% estimation error: Simulation results based on realistic
megaconstellation information confirm that the optimal number of ILCs is less
than P.S/2, where P and S are orbits and satellites per orbit. Besides, these
ILCs deploy uniformly in each layer, which raises over 1.55x throughput than
isolated layers.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16973" title="Abstract">arXiv:2312.16973</a> [<a href="/pdf/2312.16973" title="Download PDF">pdf</a>, <a href="/ps/2312.16973" title="Download PostScript">ps</a>, <a href="/format/2312.16973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Live Objects All The Way Down: Removing the Barriers between  Applications and Virtual Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pim%C3%A1s%2C+J+E">Javier E. Pim&#xe1;s</a> (University of Buenos Aires, Argentina), 
<a href="/search/cs?searchtype=author&query=Marr%2C+S">Stefan Marr</a> (University of Kent, UK), 
<a href="/search/cs?searchtype=author&query=Garbervetsky%2C+D">Diego Garbervetsky</a> (University of Buenos Aires, Argentina)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 2, Article 5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Object-oriented languages often use virtual machines (VMs) that provide
mechanisms such as just-in-time (JIT) compilation and garbage collection (GC).
These VM components are typically implemented in a separate layer, isolating
them from the application. While this approach brings the software engineering
benefits of clear separation and decoupling, it introduces barriers for both
understanding VM behavior and evolving the VM implementation. For example, the
GC and JIT compiler are typically fixed at VM build time, limiting arbitrary
adaptation at run time. Furthermore, because of this separation, the
implementation of the VM cannot typically be inspected and debugged in the same
way as application code, enshrining a distinction in easy-to-work-with
application and hard-to-work-with VM code. These characteristics pose a barrier
for application developers to understand the engine on top of which their own
code runs, and fosters a knowledge gap that prevents application developers to
change the VM.
<br />We propose Live Metacircular Runtimes (LMRs) to overcome this problem. LMRs
are language runtime systems that seamlessly integrate the VM into the
application in live programming environments. Unlike classic metacircular
approaches, we propose to completely remove the separation between application
and VM. By systematically applying object-oriented design to VM components, we
can build live runtime systems that are small and flexible enough, where VM
engineers can benefit of live programming features such as short feedback
loops, and application developers with fewer VM expertise can benefit of the
stronger causal connections between their programs and the VM implementation.
<br />To evaluate our proposal, we implemented Bee/LMR, a live VM for a
Smalltalk-derivative environment in 22057 lines of code. We analyze case
studies on tuning the garbage collector, avoiding recompilations by the
just-in-time compiler, and adding support to optimize code with vector
instructions to demonstrate the trade-offs of extending exploratory programming
to VM development in the context of an industrial application used in
production. Based on the case studies, we illustrate how our approach
facilitates the daily development work of a small team of application
developers.
<br />Our approach enables VM developers to gain access to live programming tools
traditionally reserved for application developers, while application developers
can interact with the VM and modify it using the high-level tools they use
every day. Both application and VM developers can seamlessly inspect, debug,
understand, and modify the different parts of the VM with shorter feedback
loops and higher-level tools.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16975" title="Abstract">arXiv:2312.16975</a> [<a href="/pdf/2312.16975" title="Download PDF">pdf</a>, <a href="/ps/2312.16975" title="Download PostScript">ps</a>, <a href="/format/2312.16975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot learning for automated content analysis: Efficient coding of  arguments and claims in the debate on arms deliveries to Ukraine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rieger%2C+J">Jonas Rieger</a>, 
<a href="/search/cs?searchtype=author&query=Yanchenko%2C+K">Kostiantyn Yanchenko</a>, 
<a href="/search/cs?searchtype=author&query=Ruckdeschel%2C+M">Mattes Ruckdeschel</a>, 
<a href="/search/cs?searchtype=author&query=von+Nordheim%2C+G">Gerret von Nordheim</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6nigsl%C3%B6w%2C+K+K">Katharina Kleinen-von K&#xf6;nigsl&#xf6;w</a>, 
<a href="/search/cs?searchtype=author&query=Wiedemann%2C+G">Gregor Wiedemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Studies in Communication and Media
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Pre-trained language models (PLM) based on transformer neural networks
developed in the field of natural language processing (NLP) offer great
opportunities to improve automatic content analysis in communication science,
especially for the coding of complex semantic categories in large datasets via
supervised machine learning. However, three characteristics so far impeded the
widespread adoption of the methods in the applying disciplines: the dominance
of English language models in NLP research, the necessary computing resources,
and the effort required to produce training data to fine-tune PLMs. In this
study, we address these challenges by using a multilingual transformer model in
combination with the adapter extension to transformers, and few-shot learning
methods. We test our approach on a realistic use case from communication
science to automatically detect claims and arguments together with their stance
in the German news debate on arms deliveries to Ukraine. In three experiments,
we evaluate (1) data preprocessing strategies and model variants for this task,
(2) the performance of different few-shot learning methods, and (3) how well
the best setup performs on varying training set sizes in terms of validity,
reliability, replicability and reproducibility of the results. We find that our
proposed combination of transformer adapters with pattern exploiting training
provides a parameter-efficient and easily shareable alternative to fully
fine-tuning PLMs. It performs on par in terms of validity, while overall,
provides better properties for application in communication studies. The
results also show that pre-fine-tuning for a task on a near-domain dataset
leads to substantial improvement, in particular in the few-shot setting.
Further, the results indicate that it is useful to bias the dataset away from
the viewpoints of specific prominent individuals.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16977" title="Abstract">arXiv:2312.16977</a> [<a href="/pdf/2312.16977" title="Download PDF">pdf</a>, <a href="/ps/2312.16977" title="Download PostScript">ps</a>, <a href="/format/2312.16977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Fair Cooperative Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%A4hnle%2C+R">Reiner H&#xe4;hnle</a> (TU Darmstadt, Germany), 
<a href="/search/cs?searchtype=author&query=Henrio%2C+L">Ludovic Henrio</a> (Univ Lyon - EnsL - UCBL - CNRS - Inria - LIP, France)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 2, Article 6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The context of this work is cooperative scheduling, a concurrency paradigm,
where task execution is not arbitrarily preempted. Instead, language constructs
exist that let a task voluntarily yield the right to execute to another task.
<br />The inquiry is the design of provably fair schedulers and suitable notions of
fairness for cooperative scheduling languages. To the best of our knowledge,
this problem has not been addressed so far.
<br />Our approach is to study fairness independently from syntactic constructs or
environments, purely from the point of view of the semantics of programming
languages, i.e., we consider fairness criteria using the formal definition of a
program execution. We develop our concepts for classic structural operational
semantics (SOS) as well as for the recent locally abstract, globally concrete
(LAGC) semantics. The latter is a highly modular approach to semantics ensuring
the separation of concerns between local statement evaluation and scheduling
decisions.
<br />The new knowledge contributed by our work is threefold: first, we show that a
new fairness notion, called quiescent fairness, is needed to characterize
fairness adequately in the context of cooperative scheduling; second, we define
a provably fair scheduler for cooperative scheduling languages; third, a
qualitative comparison between the SOS and LAGC versions yields that the
latter, while taking higher initial effort, is more amenable to proving
fairness and scales better under language extensions than SOS.
<br />The grounding of our work is a detailed formal proof of quiescent fairness
for the scheduler defined in LAGC semantics.
<br />The importance of our work is that it provides a formal foundation for the
implementation of fair schedulers for cooperative scheduling languages, an
increasingly popular paradigm (for example: akka/Scala, JavaScript, async
Rust). Being based solely on semantics, our ideas are widely applicable.
Further, our work makes clear that the standard notion of fairness in
concurrent languages needs to be adapted for cooperative scheduling and, more
generally, for any language that combines atomic execution sequences with some
form of preemption.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16978" title="Abstract">arXiv:2312.16978</a> [<a href="/pdf/2312.16978" title="Download PDF">pdf</a>, <a href="/ps/2312.16978" title="Download PostScript">ps</a>, <a href="/format/2312.16978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A modified AAA algorithm for learning stable reduced-order models from  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bradde%2C+T">Tommaso Bradde</a>, 
<a href="/search/math?searchtype=author&query=Grivet-Talocia%2C+S">Stefano Grivet-Talocia</a>, 
<a href="/search/math?searchtype=author&query=Aumann%2C+Q">Quirin Aumann</a>, 
<a href="/search/math?searchtype=author&query=Gosea%2C+I+V">Ion Victor Gosea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">In recent years, the Adaptive Antoulas-Anderson AAA algorithm has established
itself as the method of choice for solving rational approximation problems.
Data-driven Model Order Reduction (MOR) of large-scale Linear Time-Invariant
(LTI) systems represents one of the many applications in which this algorithm
has proven to be successful since it typically generates reduced-order models
(ROMs) efficiently and in an automated way. Despite its effectiveness and
numerical reliability, the classical AAA algorithm is not guaranteed to return
a ROM that retains the same structural features of the underlying dynamical
system, such as the stability of the dynamics. In this paper, we propose a
novel algebraic characterization for the stability of ROMs with transfer
function obeying the AAA barycentric structure. We use this characterization to
formulate a set of convex constraints on the free coefficients of the AAA model
that, whenever verified, guarantee by construction the asymptotic stability of
the resulting ROM. We suggest how to embed such constraints within the AAA
optimization routine, and we validate experimentally the effectiveness of the
resulting algorithm, named stabAAA, over a set of relevant MOR applications.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16979" title="Abstract">arXiv:2312.16979</a> [<a href="/pdf/2312.16979" title="Download PDF">pdf</a>, <a href="/format/2312.16979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlackboxBench: A Comprehensive Benchmark of Black-box Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meixi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xuanchen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 29 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Adversarial examples are well-known tools to evaluate the vulnerability of
deep neural networks (DNNs). Although lots of adversarial attack algorithms
have been developed, it is still challenging in the practical scenario that the
model's parameters and architectures are inaccessible to the
attacker/evaluator, i.e., black-box adversarial attacks. Due to the practical
importance, there has been rapid progress from recent algorithms, reflected by
the quick increase in attack success rate and the quick decrease in query
numbers to the target model. However, there is a lack of thorough evaluations
and comparisons among these algorithms, causing difficulties of tracking the
real progress, analyzing advantages and disadvantages of different technical
routes, as well as designing future development roadmap of this field. Thus, in
this work, we aim at building a comprehensive benchmark of black-box
adversarial attacks, called BlackboxBench. It mainly provides: 1) a unified,
extensible and modular-based codebase, implementing 25 query-based attack
algorithms and 30 transfer-based attack algorithms; 2) comprehensive
evaluations: we evaluate the implemented algorithms against several
mainstreaming model architectures on 2 widely used datasets (CIFAR-10 and a
subset of ImageNet), leading to 14,106 evaluations in total; 3) thorough
analysis and new insights, as well analytical tools. The website and source
codes of BlackboxBench are available at https://blackboxbench.github.io/ and
https://github.com/SCLBD/BlackboxBench/, respectively.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16980" title="Abstract">arXiv:2312.16980</a> [<a href="/pdf/2312.16980" title="Download PDF">pdf</a>, <a href="/ps/2312.16980" title="Download PostScript">ps</a>, <a href="/format/2312.16980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DTINC: Time-Equivariant Non-Contrastive Learning for Predicting Disease  Progression from Longitudinal OCTs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emre%2C+T">Taha Emre</a>, 
<a href="/search/cs?searchtype=author&query=Chakravarty%2C+A">Arunava Chakravarty</a>, 
<a href="/search/cs?searchtype=author&query=Rivail%2C+A">Antoine Rivail</a>, 
<a href="/search/cs?searchtype=author&query=Lachinov%2C+D">Dmitrii Lachinov</a>, 
<a href="/search/cs?searchtype=author&query=Leingang%2C+O">Oliver Leingang</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+S">Sophie Riedl</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+J">Julia Mai</a>, 
<a href="/search/cs?searchtype=author&query=Scholl%2C+H+P+N">Hendrik P.N. Scholl</a>, 
<a href="/search/cs?searchtype=author&query=Sivaprasad%2C+S">Sobha Sivaprasad</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Lotery%2C+A">Andrew Lotery</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Erfurth%2C+U">Ursula Schmidt-Erfurth</a>, 
<a href="/search/cs?searchtype=author&query=Bogunovi%C4%87%2C+H">Hrvoje Bogunovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised learning (SSL) has emerged as a powerful technique for
improving the efficiency and effectiveness of deep learning models. Contrastive
methods are a prominent family of SSL that extract similar representations of
two augmented views of an image while pushing away others in the representation
space as negatives. However, the state-of-the-art contrastive methods require
large batch sizes and augmentations designed for natural images that are
impractical for 3D medical images. To address these limitations, we propose a
new longitudinal SSL method, 3DTINC, based on non-contrastive learning. It is
designed to learn perturbation-invariant features for 3D optical coherence
tomography (OCT) volumes, using augmentations specifically designed for OCT. We
introduce a new non-contrastive similarity loss term that learns temporal
information implicitly from intra-patient scans acquired at different times.
Our experiments show that this temporal information is crucial for predicting
progression of retinal diseases, such as age-related macular degeneration
(AMD). After pretraining with 3DTINC, we evaluated the learned representations
and the prognostic models on two large-scale longitudinal datasets of retinal
OCTs where we predict the conversion to wet-AMD within a six months interval.
Our results demonstrate that each component of our contributions is crucial for
learning meaningful representations useful in predicting disease progression
from longitudinal volumetric scans.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16983" title="Abstract">arXiv:2312.16983</a> [<a href="/pdf/2312.16983" title="Download PDF">pdf</a>, <a href="/format/2312.16983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PG-LBO: Enhancing High-Dimensional Bayesian Optimization with  Pseudo-Label and Gaussian Process Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taicai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yue Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Variational Autoencoder based Bayesian Optimization (VAE-BO) has demonstrated
its excellent performance in addressing high-dimensional structured
optimization problems. However, current mainstream methods overlook the
potential of utilizing a pool of unlabeled data to construct the latent space,
while only concentrating on designing sophisticated models to leverage the
labeled data. Despite their effective usage of labeled data, these methods
often require extra network structures, additional procedure, resulting in
computational inefficiency. To address this issue, we propose a novel method to
effectively utilize unlabeled data with the guidance of labeled data.
Specifically, we tailor the pseudo-labeling technique from semi-supervised
learning to explicitly reveal the relative magnitudes of optimization objective
values hidden within the unlabeled data. Based on this technique, we assign
appropriate training weights to unlabeled data to enhance the construction of a
discriminative latent space. Furthermore, we treat the VAE encoder and the
Gaussian Process (GP) in Bayesian optimization as a unified deep kernel
learning process, allowing the direct utilization of labeled data, which we
term as Gaussian Process guidance. This directly and effectively integrates the
goal of improving GP accuracy into the VAE training, thereby guiding the
construction of the latent space. The extensive experiments demonstrate that
our proposed method outperforms existing VAE-BO algorithms in various
optimization scenarios. Our code will be published at
https://github.com/TaicaiChen/PG-LBO.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16984" title="Abstract">arXiv:2312.16984</a> [<a href="/pdf/2312.16984" title="Download PDF">pdf</a>, <a href="/format/2312.16984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reformulation and generalisation of the air-gap element
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Gersem%2C+H">Herbert De Gersem</a>, 
<a href="/search/cs?searchtype=author&query=Weiland%2C+T">Thomas Weiland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in ICS Newsletter (International Compumag Society)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICS Newsletter, Vol. 12, No. 1, ISSN 1026-0854, 1 March 2005, pp.
  2-8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The air-gap macro element is reformulated such that rotation, rotor or stator
skewing and rotor eccentricity can be incorporated easily. The air-gap element
is evaluated using Fast Fourier Transforms which in combination with the
Conjugate Gradient algorithm leads to highly efficient and memory inexpensive
iterative solution scheme. The improved air-gap element features beneficial
approximation properties and is competitive to moving-band and sliding-surface
technique.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16987" title="Abstract">arXiv:2312.16987</a> [<a href="/pdf/2312.16987" title="Download PDF">pdf</a>, <a href="/ps/2312.16987" title="Download PostScript">ps</a>, <a href="/format/2312.16987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Quality, Uniformity and Computation Improvement of Compressive  Light Field Displays with U-Net
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiaodi Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 6 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We apply the U-Net model for compressive light field synthesis. Compared to
methods based on stacked CNN and iterative algorithms, this method offers
better image quality, uniformity and less computation.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16995" title="Abstract">arXiv:2312.16995</a> [<a href="/pdf/2312.16995" title="Download PDF">pdf</a>, <a href="/format/2312.16995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowDA: Unsupervised Domain Adaptive Framework for Optical Flow  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Miaojie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Longliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Hao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Collecting real-world optical flow datasets is a formidable challenge due to
the high cost of labeling. A shortage of datasets significantly constrains the
real-world performance of optical flow models. Building virtual datasets that
resemble real scenarios offers a potential solution for performance
enhancement, yet a domain gap separates virtual and real datasets. This paper
introduces FlowDA, an unsupervised domain adaptive (UDA) framework for optical
flow estimation. FlowDA employs a UDA architecture based on mean-teacher and
integrates concepts and techniques in unsupervised optical flow estimation.
Furthermore, an Adaptive Curriculum Weighting (ACW) module based on curriculum
learning is proposed to enhance the training effectiveness. Experimental
outcomes demonstrate that our FlowDA outperforms state-of-the-art unsupervised
optical flow estimation method SMURF by 21.6%, real optical flow dataset
generation method MPI-Flow by 27.8%, and optical flow estimation adaptive
method FlowSupervisor by 30.9%, offering novel insights for enhancing the
performance of optical flow estimation in real-world scenarios. The code will
be open-sourced after the publication of this paper.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16999" title="Abstract">arXiv:2312.16999</a> [<a href="/pdf/2312.16999" title="Download PDF">pdf</a>, <a href="/format/2312.16999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Tier Computing-Enabled Digital Twin in 6G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunlun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yongyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+T+Q">Trung Q. Duong</a>, 
<a href="/search/cs?searchtype=author&query=Khosravirad%2C+S+R">Saeed R. Khosravirad</a>, 
<a href="/search/cs?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="/search/cs?searchtype=author&query=Karagiannidis%2C+G+K">George K. Karagiannidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Digital twin (DT) is the recurrent and common feature in discussions about
future technologies, bringing together advanced communication, computation, and
artificial intelligence, to name a few. In the context of Industry 4.0,
industries such as manufacturing, automotive, and healthcare are rapidly
adopting DT-based development. The main challenges to date have been the high
demands on communication and computing resources, as well as privacy and
security concerns, arising from the large volumes of data exchanges. To achieve
low latency and high security services in the emerging DT, multi-tier computing
has been proposed by combining edge/fog computing and cloud computing.
Specifically, low latency data transmission, efficient resource allocation, and
validated security strategies of multi-tier computing systems are used to solve
the operational problems of the DT system. In this paper, we introduce the
architecture and applications of DT using examples from manufacturing, the
Internet-of-Vehicles and healthcare. At the same time, the architecture and
technology of multi-tier computing systems are studied to support DT. This
paper will provide valuable reference and guidance for the theory, algorithms,
and applications in collaborative multi-tier computing and DT.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17003" title="Abstract">arXiv:2312.17003</a> [<a href="/pdf/2312.17003" title="Download PDF">pdf</a>, <a href="/format/2312.17003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Battery model impact on time-optimal co-design for electric racing cars:  review and application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Riva%2C+G">Giorgio Riva</a>, 
<a href="/search/eess?searchtype=author&query=Radrizzani%2C+S">Stefano Radrizzani</a>, 
<a href="/search/eess?searchtype=author&query=Panzani%2C+G">Giulio Panzani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE Transactions on Transportation Electrification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The sustainable mobility trend touches the racing world as well, from the
hybridization of Formula 1 (F1) and Le Mans Hypercars to the fully electric
Formula E racing class. In this scenario, the research community is studying
how to push electric racing vehicles to their limit, combining vehicle dynamics
and energy management, to successfully solve the minimum lap time problem.
Recently, this class of problems has been enlarged towards optimal sizing, with
a particular interest in batteries, which represent the main bottleneck for
electric vehicle performance. In this work, starting from a thorough review of
literature approaches, we define a general optimization framework of minimum
lap and race time problems for electric vehicles, suitable to figure out the
impact of different modeling choices on both problem structure and optimal
variables profiles. Exploiting a case study on Generation 3 (Gen 3) of Formula
E cars, we delve into the impact of battery models' complexity on both optimal
sizing and optimal battery usage. We show how highly detailed models are
necessary to study the evolution of both battery and vehicle control variables
during the race, while, simple models are more than sufficient to address the
battery sizing problem.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17006" title="Abstract">arXiv:2312.17006</a> [<a href="/pdf/2312.17006" title="Download PDF">pdf</a>, <a href="/format/2312.17006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Models for Interconnected Impulsive Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alaoui%2C+S+B">Sadek Belamfedel Alaoui</a>, 
<a href="/search/eess?searchtype=author&query=Saoud%2C+A">Adnane Saoud</a>, 
<a href="/search/eess?searchtype=author&query=Jagtap%2C+P">Pushpak Jagtap</a>, 
<a href="/search/eess?searchtype=author&query=Swikir%2C+A">Abdalla Swikir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we present a compositional methodology for constructing
symbolic models of nonlinear interconnected impulsive systems. Our approach
relies on the concept of "alternating simulation function" to establish a
relationship between concrete subsystems and their symbolic models. Assuming
some small-gain type conditions, we develop an alternating simulation function
between the symbolic models of individual subsystems and those of the nonlinear
interconnected impulsive systems. To construct symbolic models of nonlinear
impulsive subsystems, we propose an approach that depends on incremental
input-to-state stability and forward completeness properties. Finally, we
demonstrate the advantages of our framework through a case study.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17007" title="Abstract">arXiv:2312.17007</a> [<a href="/pdf/2312.17007" title="Download PDF">pdf</a>, <a href="/ps/2312.17007" title="Download PostScript">ps</a>, <a href="/format/2312.17007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the rate of convergence of an over-parametrized Transformer  classifier learned by gradient descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohler%2C+M">Michael Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Krzyzak%2C+A">Adam Krzyzak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">One of the most recent and fascinating breakthroughs in artificial
intelligence is ChatGPT, a chatbot which can simulate human conversation.
ChatGPT is an instance of GPT4, which is a language model based on generative
gredictive gransformers. So if one wants to study from a theoretical point of
view, how powerful such artificial intelligence can be, one approach is to
consider transformer networks and to study which problems one can solve with
these networks theoretically. Here it is not only important what kind of models
these network can approximate, or how they can generalize their knowledge
learned by choosing the best possible approximation to a concrete data set, but
also how well optimization of such transformer network based on concrete data
set works. In this article we consider all these three different aspects
simultaneously and show a theoretical upper bound on the missclassification
probability of a transformer network fitted to the observed data. For
simplicity we focus in this context on transformer encoder networks which can
be applied to define an estimate in the context of a classification problem
involving natural language.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17010" title="Abstract">arXiv:2312.17010</a> [<a href="/pdf/2312.17010" title="Download PDF">pdf</a>, <a href="/ps/2312.17010" title="Download PostScript">ps</a>, <a href="/format/2312.17010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Multi-Modal Image Stitching for Improved Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Aritra Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Suseela%2C+D+G">Dr. G Suseela</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+A">Asmita Sood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-modal image stitching can be a difficult feat. That's why, in this
paper, we've devised a unique and comprehensive image-stitching pipeline that
taps into OpenCV's stitching module. Our approach integrates feature-based
matching, transformation estimation, and blending techniques to bring about
panoramic views that are of top-tier quality - irrespective of lighting, scale
or orientation differences between images. We've put our pipeline to the test
with a varied dataset and found that it's very effective in enhancing scene
understanding and finding real-world applications.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17012" title="Abstract">arXiv:2312.17012</a> [<a href="/pdf/2312.17012" title="Download PDF">pdf</a>, <a href="/format/2312.17012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalization of the Sugeno integral to aggregate Interval-valued  data: an application to Brain Computer Interface and Social Network Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fumanal-Idocin%2C+J">Javier Fumanal-Idocin</a>, 
<a href="/search/cs?searchtype=author&query=Takac%2C+Z">Zdenko Takac</a>, 
<a href="/search/cs?searchtype=author&query=Horanska%2C+L">Lubomira Horanska</a>, 
<a href="/search/cs?searchtype=author&query=da+Cruz+Asmus%2C+T">Thiago da Cruz Asmus</a>, 
<a href="/search/cs?searchtype=author&query=Vidaurre%2C+C">Carmen Vidaurre</a>, 
<a href="/search/cs?searchtype=author&query=Dimuro%2C+G">Gra&#xe7;aliz Dimuro</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+J">Javier Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Bustince%2C+H">Humberto Bustince</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Fuzzy Sets and Systems 451 (2022): 320-341
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Intervals are a popular way to represent the uncertainty related to data, in
which we express the vagueness of each observation as the width of the
interval. However, when using intervals for this purpose, we need to use the
appropriate set of mathematical tools to work with. This can be problematic due
to the scarcity and complexity of interval-valued functions in comparison with
the numerical ones. In this work, we propose to extend a generalization of the
Sugeno integral to work with interval-valued data. Then, we use this integral
to aggregate interval-valued data in two different settings: first, we study
the use of intervals in a brain-computer interface; secondly, we study how to
construct interval-valued relationships in a social network, and how to
aggregate their information. Our results show that interval-valued data can
effectively model some of the uncertainty and coalitions of the data in both
cases. For the case of brain-computer interface, we found that our results
surpassed the results of other interval-valued functions.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17013" title="Abstract">arXiv:2312.17013</a> [<a href="/pdf/2312.17013" title="Download PDF">pdf</a>, <a href="/format/2312.17013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perspectives of Global and Hong Kong&#x27;s Media on China&#x27;s Belt and Road  Initiative
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoo%2C+L+C">Le Cong Khoo</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Anwitaman Datta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures, 7 tables, 1 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This study delves into the media analysis of China's ambitious Belt and Road
Initiative (BRI), which, in a polarized world, and furthermore, owing to the
very polarizing nature of the initiative itself, has received both strong
criticisms and conversely positive coverage in media from across the world. In
that context, Hong Kong's dynamic media environment, with a particular focus on
its drastically changing press freedom before and after the implementation of
the National Security Law is of further interest.
<br />Leveraging data science techniques, this study employs Global Database of
Events, Language, and Tone (GDELT) to comprehensively collect and analyse
(English) news articles on the BRI. Through sentiment analysis, we uncover
patterns in media coverage over different periods from several countries across
the globe, and delve further to investigate the the media situation in the Hong
Kong region. This work thus provides valuable insights into how the Belt and
Road Initiative has been portrayed in the media and its evolving reception on
the global stage, with a specific emphasis on the unique media landscape of
Hong Kong.
<br />In an era characterised by increasing globalisation and inter-connectivity,
but also competition for influence, animosity and trade-wars, understanding the
perceptions and coverage of such significant international projects is crucial.
This work stands as an interdisciplinary endeavour merging geopolitical science
and data science to uncover the intricate dynamics of media coverage in
general, and with an added emphasis on Hong Kong.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17016" title="Abstract">arXiv:2312.17016</a> [<a href="/pdf/2312.17016" title="Download PDF">pdf</a>, <a href="/format/2312.17016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Promises and Challenges of Multimodal Foundation Models for  Geographical, Environmental, Agricultural, and Urban Planning Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chenjiao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jielu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huaqin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Nemin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinyue Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+L">Lilong Chai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changying Li</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+L">Lan Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+G">Gengchen Mai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 110 Pages; 61 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of large language models (LLMs) has heightened interest in their
potential for multimodal applications that integrate language and vision. This
paper explores the capabilities of GPT-4V in the realms of geography,
environmental science, agriculture, and urban planning by evaluating its
performance across a variety of tasks. Data sources comprise satellite imagery,
aerial photos, ground-level images, field images, and public datasets. The
model is evaluated on a series of tasks including geo-localization, textual
data extraction from maps, remote sensing image classification, visual question
answering, crop type identification, disease/pest/weed recognition, chicken
behavior analysis, agricultural object counting, urban planning knowledge
question answering, and plan generation. The results indicate the potential of
GPT-4V in geo-localization, land cover classification, visual question
answering, and basic image understanding. However, there are limitations in
several tasks requiring fine-grained recognition and precise counting. While
zero-shot learning shows promise, performance varies across problem domains and
image complexities. The work provides novel insights into GPT-4V's capabilities
and limitations for real-world geospatial, environmental, agricultural, and
urban planning challenges. Further research should focus on augmenting the
model's knowledge and reasoning for specialized domains through expanded
training. Overall, the analysis demonstrates foundational multimodal
intelligence, highlighting the potential of multimodal foundation models (FMs)
to advance interdisciplinary applications at the nexus of computer vision and
language.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17018" title="Abstract">arXiv:2312.17018</a> [<a href="/pdf/2312.17018" title="Download PDF">pdf</a>, <a href="/format/2312.17018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Spatially Collaged Fourier Bases for Implicit Neural  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J+C+L">Jason Chun Lok Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+N">Ngai Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 13 figures, Accepted at the 38th AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Existing approaches to Implicit Neural Representation (INR) can be
interpreted as a global scene representation via a linear combination of
Fourier bases of different frequencies. However, such universal basis functions
can limit the representation capability in local regions where a specific
component is unnecessary, resulting in unpleasant artifacts. To this end, we
introduce a learnable spatial mask that effectively dispatches distinct Fourier
bases into respective regions. This translates into collaging Fourier patches,
thus enabling an accurate representation of complex signals. Comprehensive
experiments demonstrate the superior reconstruction quality of the proposed
approach over existing baselines across various INR tasks, including image
fitting, video representation, and 3D shape representation. Our method
outperforms all other baselines, improving the image fitting PSNR by over 3dB
and 3D reconstruction to 98.81 IoU and 0.0011 Chamfer Distance.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17024" title="Abstract">arXiv:2312.17024</a> [<a href="/pdf/2312.17024" title="Download PDF">pdf</a>, <a href="/format/2312.17024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Run-Length Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xutan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dejia Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiafa Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at DCC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Run-Length Encoding (RLE) is one of the most fundamental tools in data
compression. However, its compression power drops significantly if there lacks
consecutive elements in the sequence. In extreme cases, the output of the
encoder may require more space than the input (aka size inflation). To
alleviate this issue, using combinatorics, we quantify RLE's space savings for
a given input distribution. With this insight, we develop the first algorithm
that automatically identifies suitable symbols, then selectively encodes these
symbols with RLE while directly storing the others without RLE. Through
experiments on real-world datasets of various modalities, we empirically
validate that our method, which maintains RLE's efficiency advantage, can
effectively mitigate the size inflation dilemma.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17025" title="Abstract">arXiv:2312.17025</a> [<a href="/pdf/2312.17025" title="Download PDF">pdf</a>, <a href="/format/2312.17025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experiential Co-Learning of Software-Developing Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yufan Dang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have brought significant
changes to various dimains, especially through LLM-driven autonomous agents.
These agents are now capable of collaborating seamlessly, splitting tasks and
enhancing accuracy, thus minimizing the need for human involvement. However,
these agents often approach a diverse range of tasks in isolation, without
benefiting from past experiences. This isolation can lead to repeated mistakes
and inefficient trials in task solving. To this end, this paper introduces
Experiential Co-Learning, a novel framework in which instructor and assistant
agents gather shortcut-oriented experiences from their historical trajectories
and use these past experiences for mutual reasoning. This paradigm, enriched
with previous experiences, equips agents to more effectively address unseen
tasks.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17029" title="Abstract">arXiv:2312.17029</a> [<a href="/pdf/2312.17029" title="Download PDF">pdf</a>, <a href="/format/2312.17029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSDD: Scalable and Diversity-enhanced Distillation for Model  Aggregation in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwan%2C+H+M">Ho Man Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shenghui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, innovative model aggregation methods based on knowledge
distillation (KD) have been proposed for federated learning (FL). These methods
not only improved the robustness of model aggregation over heterogeneous
learning environment, but also allowed training heterogeneous models on client
devices. However, the scalability of existing methods is not satisfactory,
because the training cost on the server increases with the number of clients,
which limits their application in large scale systems. Furthermore, the
ensemble of existing methods is built from a set of client models initialized
from the same checkpoint, causing low diversity. In this paper, we propose a
scalable and diversity-enhanced federated distillation scheme, FedSDD, which
decouples the training complexity from the number of clients to enhance the
scalability, and builds the ensemble from a set of aggregated models with
enhanced diversity. In particular, the teacher model in FedSDD is an ensemble
built by a small group of aggregated (global) models, instead of all client
models, such that the computation cost will not scale with the number of
clients. Furthermore, to enhance diversity, FedSDD only performs KD to enhance
one of the global models, i.e., the \textit{main global model}, which improves
the performance of both the ensemble and the main global model. While
partitioning client model into more groups allow building an ensemble with more
aggregated models, the convergence of individual aggregated models will be slow
down. We introduce the temporal ensembling which leverage the issues, and
provide significant improvement with the heterogeneous settings. Experiment
results show that FedSDD outperforms other FL methods, including FedAvg and
FedDF, on the benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17031" title="Abstract">arXiv:2312.17031</a> [<a href="/pdf/2312.17031" title="Download PDF">pdf</a>, <a href="/format/2312.17031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Mask-aware IoU for Anchor Assignment for Real-time Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87am%2C+B+C">Bar&#x131;&#x15f; Can &#xc7;am</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96ks%C3%BCz%2C+K">Kemal &#xd6;ks&#xfc;z</a>, 
<a href="/search/cs?searchtype=author&query=Kahraman%2C+F">Fehmi Kahraman</a>, 
<a href="/search/cs?searchtype=author&query=Baltac%C4%B1%2C+Z+S">Zeynep Sonat Baltac&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Kalkan%2C+S">Sinan Kalkan</a>, 
<a href="/search/cs?searchtype=author&query=Akba%C5%9F%2C+E">Emre Akba&#x15f;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces Generalized Mask-aware Intersection-over-Union (GmaIoU)
as a new measure for positive-negative assignment of anchor boxes during
training of instance segmentation methods. Unlike conventional IoU measure or
its variants, which only consider the proximity of anchor and ground-truth
boxes; GmaIoU additionally takes into account the segmentation mask. This
enables GmaIoU to provide more accurate supervision during training. We
demonstrate the effectiveness of GmaIoU by replacing IoU with our GmaIoU in
ATSS, a state-of-the-art (SOTA) assigner. Then, we train YOLACT, a real-time
instance segmentation method, using our GmaIoU-based ATSS assigner. The
resulting YOLACT based on the GmaIoU assigner outperforms (i) ATSS with IoU by
$\sim 1.0-1.5$ mask AP, (ii) YOLACT with a fixed IoU threshold assigner by
$\sim 1.5-2$ mask AP over different image sizes and (iii) decreases the
inference time by $25 \%$ owing to using less anchors. Taking advantage of this
efficiency, we further devise GmaYOLACT, a faster and $+7$ mask AP points more
accurate detector than YOLACT. Our best model achieves $38.7$ mask AP at $26$
fps on COCO test-dev establishing a new state-of-the-art for real-time instance
segmentation.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17040" title="Abstract">arXiv:2312.17040</a> [<a href="/pdf/2312.17040" title="Download PDF">pdf</a>, <a href="/format/2312.17040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Powered Road Network Prediction with Multi-Modal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gengec%2C+N+E">Necip Enes Gengec</a>, 
<a href="/search/cs?searchtype=author&query=Tari%2C+E">Ergin Tari</a>, 
<a href="/search/cs?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents an innovative approach for automatic road detection with
deep learning, by employing fusion strategies for utilizing both
lower-resolution satellite imagery and GPS trajectory data, a concept never
explored before. We rigorously investigate both early and late fusion
strategies, and assess deep learning based road detection performance using
different fusion settings. Our extensive ablation studies assess the efficacy
of our framework under diverse model architectures, loss functions, and
geographic domains (Istanbul and Montreal). For an unbiased and complete
evaluation of road detection results, we use both region-based and
boundary-based evaluation metrics for road segmentation. The outcomes reveal
that the ResUnet model outperforms U-Net and D-Linknet in road extraction
tasks, achieving superior results over the benchmark study using low-resolution
Sentinel-2 data. This research not only contributes to the field of automatic
road detection but also offers novel insights into the utilization of data
fusion methods in diverse applications.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17043" title="Abstract">arXiv:2312.17043</a> [<a href="/pdf/2312.17043" title="Download PDF">pdf</a>, <a href="/ps/2312.17043" title="Download PostScript">ps</a>, <a href="/format/2312.17043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collatz-Weyl Generators: High Quality and High Throughput Parameterized  Pseudorandom Number Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dzia%C5%82a%2C+T+R">Tomasz R. Dzia&#x142;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We introduce the Collatz-Weyl Generators, a family of uniform pseudorandom
number generators (PRNGs) which are based on generalized Collatz mappings,
derived from the Collatz conjecture and Weyl sequences. The high-quality
statistical properties of our generators is demonstrated by the fact that they
pass stringent randomness tests used by the research and standardization
community. The proposed Collatz-Weyl Generators have a number of important
properties, including solid mathematical foundations, enablement of high
throughput and low latency implementation, small code and/or ASIC size,
enablement of producing multiple independent streams and potential of support
of cryptographic applications.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17044" title="Abstract">arXiv:2312.17044</a> [<a href="/pdf/2312.17044" title="Download PDF">pdf</a>, <a href="/format/2312.17044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Length Extrapolation of Transformers: A Survey from the Perspective of  Position Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiachong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Transformer has taken the natural language processing (NLP) field by storm
since birth, owing to its superior ability to model complex dependencies in
sequences. Despite the great success of pretrained language models (PLMs) based
on Transformer across almost all NLP tasks, they all suffer from a preset
length limit and thus can hardly extend this success to longer sequences beyond
seen data, namely the length extrapolation problem. Length extrapolation has
aroused great interest among researchers, as it is the core feature of human
language capacity. To enhance length extrapolation of Transformers, a plethora
of methods have been proposed, mostly focusing on extrapolatable position
encodings. In this article, we provide an organized and systematical review of
these research efforts in a unified notation from a position encoding
perspective, aiming to enable the reader to gain a deep understanding of
existing methods and provide stimuli for future research.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17045" title="Abstract">arXiv:2312.17045</a> [<a href="/pdf/2312.17045" title="Download PDF">pdf</a>, <a href="/ps/2312.17045" title="Download PostScript">ps</a>, <a href="/format/2312.17045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Properties of Immersions for Systems with Multiple Limit Sets with  Implications to Learning Koopman Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zexiang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ozay%2C+N">Necmiye Ozay</a>, 
<a href="/search/eess?searchtype=author&query=Sontag%2C+E+D">Eduardo D. Sontag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">Linear immersions (or Koopman eigenmappings) of a nonlinear system have wide
applications in prediction and control. In this work, we study the
non-existence of one-to-one linear immersions for nonlinear systems with
multiple omega-limit sets. While previous research has indicated the
possibility of discontinuous one-to-one linear immersions for such systems, it
remained uncertain whether continuous one-to-one linear immersions are
attainable. Under mild conditions, we prove that any continuous one-to-one
immersion to a class of systems including linear systems cannot distinguish
different omega-limit sets, and thus cannot be one-to-one. Furthermore, we show
that this property is also shared by approximate linear immersions learned from
data as sample size increases and sampling interval decreases. Multiple
examples are studied to illustrate our results.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17046" title="Abstract">arXiv:2312.17046</a> [<a href="/pdf/2312.17046" title="Download PDF">pdf</a>, <a href="/format/2312.17046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing and Modeling Incoherent, Impossible and Incoherent Shapes  and Scenes with 2D Non-Conservative Vector Fields mapped on 2-Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gonen%2C+O">Ozgur Gonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this paper, we present a framework to represent mock 3D objects and
scenes, which are not 3D but appear 3D. In our framework, each mock-3D object
is represented using 2D non-conservative vector fields and thickness
information that are mapped on 2-complexes. Mock-3D scenes are simply scenes
consisting of more than one mock-3D object. We demonstrated that using this
representation, we can dynamically compute a 3D shape using rays emanating from
any given point in 3D. These mock-3D objects are view-dependent since their
computed shapes depend on the positions of ray centers. Using these dynamically
computed shapes, we can compute shadows, reflections, and refractions in real
time. This representation is mainly useful for 2D artistic applications to
model incoherent, inconsistent, and impossible objects. Using this
representation, it is possible to obtain expressive depictions with shadows and
global illumination effects. The representation can also be used to convert
existing 2D artworks into a Mock-3D form that can be interactively re-rendered.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17050" title="Abstract">arXiv:2312.17050</a> [<a href="/pdf/2312.17050" title="Download PDF">pdf</a>, <a href="/format/2312.17050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KeDuSR: Real-World Dual-Lens Super-Resolution via Kernel-Free Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zifan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures. Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dual-lens super-resolution (SR) is a practical scenario for reference (Ref)
based SR by utilizing the telephoto image (Ref) to assist the super-resolution
of the low-resolution wide-angle image (LR input). Different from general
RefSR, the Ref in dual-lens SR only covers the overlapped field of view (FoV)
area. However, current dual-lens SR methods rarely utilize these specific
characteristics and directly perform dense matching between the LR input and
Ref. Due to the resolution gap between LR and Ref, the matching may miss the
best-matched candidate and destroy the consistent structures in the overlapped
FoV area. Different from them, we propose to first align the Ref with the
center region (namely the overlapped FoV area) of the LR input by combining
global warping and local warping to make the aligned Ref be sharp and
consistent. Then, we formulate the aligned Ref and LR center as value-key
pairs, and the corner region of the LR is formulated as queries. In this way,
we propose a kernel-free matching strategy by matching between the LR-corner
(query) and LR-center (key) regions, and the corresponding aligned Ref (value)
can be warped to the corner region of the target. Our kernel-free matching
strategy avoids the resolution gap between LR and Ref, which makes our network
have better generalization ability. In addition, we construct a DuSR-Real
dataset with (LR, Ref, HR) triples, where the LR and HR are well aligned.
Experiments on three datasets demonstrate that our method outperforms the
second-best method by a large margin. Our code and dataset are available at
https://github.com/Craigie-Hill/KeDuSR.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17051" title="Abstract">arXiv:2312.17051</a> [<a href="/pdf/2312.17051" title="Download PDF">pdf</a>, <a href="/format/2312.17051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FILP-3D: Enhancing 3D Few-shot Class-incremental Learning with  Pre-trained Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+T">Tianyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanglei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot class-incremental learning (FSCIL) aims to mitigate the catastrophic
forgetting issue when a model is incrementally trained on limited data. While
the Contrastive Vision-Language Pre-Training (CLIP) model has been effective in
addressing 2D few/zero-shot learning tasks, its direct application to 3D FSCIL
faces limitations. These limitations arise from feature space misalignment and
significant noise in real-world scanned 3D data. To address these challenges,
we introduce two novel components: the Redundant Feature Eliminator (RFE) and
the Spatial Noise Compensator (SNC). RFE aligns the feature spaces of input
point clouds and their embeddings by performing a unique dimensionality
reduction on the feature space of pre-trained models (PTMs), effectively
eliminating redundant information without compromising semantic integrity. On
the other hand, SNC is a graph-based 3D model designed to capture robust
geometric information within point clouds, thereby augmenting the knowledge
lost due to projection, particularly when processing real-world scanned data.
Considering the imbalance in existing 3D datasets, we also propose new
evaluation metrics that offer a more nuanced assessment of a 3D FSCIL model.
Traditional accuracy metrics are proved to be biased; thus, our metrics focus
on the model's proficiency in learning new classes while maintaining the
balance between old and new classes. Experimental results on both established
3D FSCIL benchmarks and our dataset demonstrate that our approach significantly
outperforms existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17052" title="Abstract">arXiv:2312.17052</a> [<a href="/pdf/2312.17052" title="Download PDF">pdf</a>, <a href="/format/2312.17052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Attention Fusion Drowsy Driving Detection Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=QU%2C+S">Shulei QU</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhenguo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuanyuan Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Drowsy driving represents a major contributor to traffic accidents, and the
implementation of driver drowsy driving detection systems has been proven to
significantly reduce the occurrence of such accidents. Despite the development
of numerous drowsy driving detection algorithms, many of them impose specific
prerequisites such as the availability of complete facial images, optimal
lighting conditions, and the use of RGB images. In our study, we introduce a
novel approach called the Multi-Attention Fusion Drowsy Driving Detection Model
(MAF). MAF is aimed at significantly enhancing classification performance,
especially in scenarios involving partial facial occlusion and low lighting
conditions. It accomplishes this by capitalizing on the local feature
extraction capabilities provided by multi-attention fusion, thereby enhancing
the algorithm's overall robustness. To enhance our dataset, we collected
real-world data that includes both occluded and unoccluded faces captured under
nighttime and daytime lighting conditions. We conducted a comprehensive series
of experiments using both publicly available datasets and our self-built data.
The results of these experiments demonstrate that our proposed model achieves
an impressive driver drowsiness detection accuracy of 96.8%.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17055" title="Abstract">arXiv:2312.17055</a> [<a href="/pdf/2312.17055" title="Download PDF">pdf</a>, <a href="/format/2312.17055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving In-context Learning via Bidirectional Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wenhan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown impressive few-shot generalization on
many tasks via in-context learning (ICL). Despite their success in showing such
emergent abilities, the scale and complexity of larger models also lead to
unprecedentedly high computational demands and deployment challenges. In
reaction, researchers explore transferring the powerful capabilities of larger
models to more efficient and compact models by typically aligning the output of
smaller models with that of larger models. Existing methods either train
smaller models on the generated outputs of larger models or to imitate their
token-level probability distributions. However, these distillation methods pay
little to no attention to the input part, which also plays a crucial role in
ICL. Based on the finding that the performance of ICL is highly sensitive to
the selection of demonstration examples, we propose Bidirectional Alignment
(BiAlign) to fully leverage the models' preferences for ICL examples to improve
the ICL abilities of smaller models. Specifically, we introduce the alignment
of input preferences between smaller and larger models by incorporating a novel
ranking loss, in addition to aligning the token-level output distribution. With
extensive experiments and analysis, we demonstrate that BiAlign can
consistently outperform existing baselines on a variety of tasks including
language understanding, reasoning, and coding.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17058" title="Abstract">arXiv:2312.17058</a> [<a href="/pdf/2312.17058" title="Download PDF">pdf</a>, <a href="/ps/2312.17058" title="Download PostScript">ps</a>, <a href="/format/2312.17058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the optimality of Shapley mechanism under Sybil strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roig%2C+B+M">Bruno Mazorra Roig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In the realm of cost-sharing mechanisms, the vulnerability to Sybil
strategies, where agents can create fake identities to manipulate outcomes, has
not yet been studied. In this paper, we delve into the intricacies of different
cost-sharing mechanisms proposed in the literature highlighting its non
Sybil-resistance nature. Furthermore, we prove that under mild conditions, a
Sybil-proof cost-sharing mechanism for public excludable goods is at least
$(n/2+1)-$approximate. This finding reveals an actual exponential increase in
the worst-case social cost in environments where agents are restricted from
using Sybil strategies. We introduce the concept of \textit{Sybil Welfare
Invariant} mechanisms, where a mechanism maintains its worst-case welfare under
Sybil-strategies for every set of prior beliefs with full support even when the
mechanism is not Sybil-proof. Finally, we prove that the Shapley value
mechanism for public excludable goods holds this property, and so deduce that
the worst-case social cost of this mechanism is the $n$th harmonic number
$\mathcal H_n$ even under equilibrium of the game with Sybil strategies,
matching the worst-case social cost bound for cost-sharing mechanisms. This
finding carries important implications for decentralized autonomous
organizations (DAOs), indicating that they are capable of funding public
excludable goods efficiently, even when the total number of agents in the DAO
is unknown.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17071" title="Abstract">arXiv:2312.17071</a> [<a href="/pdf/2312.17071" title="Download PDF">pdf</a>, <a href="/format/2312.17071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCTNet: Single-Branch CNN with Transformer Semantic Information for  Real-Time Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengze Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changqian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent real-time semantic segmentation methods usually adopt an additional
semantic branch to pursue rich long-range context. However, the additional
branch incurs undesirable computational overhead and slows inference speed. To
eliminate this dilemma, we propose SCTNet, a single branch CNN with transformer
semantic information for real-time segmentation. SCTNet enjoys the rich
semantic representations of an inference-free semantic branch while retaining
the high efficiency of lightweight single branch CNN. SCTNet utilizes a
transformer as the training-only semantic branch considering its superb ability
to extract long-range context. With the help of the proposed transformer-like
CNN block CFBlock and the semantic information alignment module, SCTNet could
capture the rich semantic information from the transformer branch in training.
During the inference, only the single branch CNN needs to be deployed. We
conduct extensive experiments on Cityscapes, ADE20K, and COCO-Stuff-10K, and
the results show that our method achieves the new state-of-the-art performance.
The code and model is available at https://github.com/xzz777/SCTNet
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17072" title="Abstract">arXiv:2312.17072</a> [<a href="/pdf/2312.17072" title="Download PDF">pdf</a>, <a href="/format/2312.17072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Framework of Geographical Group-Specific Network on O2O  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Luo Ji</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiayu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hailong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y">Yunfei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, Accepted by ECIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Online to offline recommendation strongly correlates with the user and
service's spatiotemporal information, therefore calling for a higher degree of
model personalization. The traditional methodology is based on a uniform model
structure trained by collected centralized data, which is unlikely to capture
all user patterns over different geographical areas or time periods. To tackle
this challenge, we propose a geographical group-specific modeling method called
GeoGrouse, which simultaneously studies the common knowledge as well as
group-specific knowledge of user preferences. An automatic grouping paradigm is
employed and verified based on users' geographical grouping indicators. Offline
and online experiments are conducted to verify the effectiveness of our
approach, and substantial business improvement is achieved.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17076" title="Abstract">arXiv:2312.17076</a> [<a href="/pdf/2312.17076" title="Download PDF">pdf</a>, <a href="/format/2312.17076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimally-intrusive Navigation in Dense Crowds with Integrated Macro and  Micro-level Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Senmao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Cen%2C+G">Guangdu Cen</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Ziqi Zha</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+E">Erli Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaole Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In mobile robot navigation, despite advancements, the generation of optimal
paths often disrupts pedestrian areas. To tackle this, we propose three key
contributions to improve human-robot coexistence in shared spaces. Firstly, we
have established a comprehensive framework to understand disturbances at
individual and flow levels. Our framework provides specialized computational
strategies for in-depth studies of human-robot interactions from both micro and
macro perspectives. By employing novel penalty terms, namely Flow Disturbance
Penalty (FDP) and Individual Disturbance Penalty (IDP), our framework
facilitates a more nuanced assessment and analysis of the robot navigation's
impact on pedestrians. Secondly, we introduce an innovative sampling-based
navigation system that adeptly integrates a suite of safety measures with the
predictability of robotic movements. This system not only accounts for
traditional factors such as trajectory length and travel time but also actively
incorporates pedestrian awareness. Our navigation system aims to minimize
disturbances and promote harmonious coexistence by considering safety
protocols, trajectory clarity, and pedestrian engagement. Lastly, we validate
our algorithm's effectiveness and real-time performance through simulations and
real-world tests, demonstrating its ability to navigate with minimal pedestrian
disturbance in various environments.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17077" title="Abstract">arXiv:2312.17077</a> [<a href="/pdf/2312.17077" title="Download PDF">pdf</a>, <a href="/ps/2312.17077" title="Download PostScript">ps</a>, <a href="/format/2312.17077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected Langevin Monte Carlo algorithms in non-convex and super-linear  setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pang%2C+C">Chenxu Pang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yue Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">It is of significant interest in many applications to sample from a
high-dimensional target distribution $\pi$ with the density $\pi(\text{d} x)
\propto e^{-U(x)} (\text{d} x) $, based on the temporal discretization of the
Langevin stochastic differential equations (SDEs). In this paper, we propose an
explicit projected Langevin Monte Carlo (PLMC) algorithm with non-convex
potential $U$ and super-linear gradient of $U$ and investigate the
non-asymptotic analysis of its sampling error in total variation distance.
Equipped with time-independent regularity estimates for the corresponding
Kolmogorov equation, we derive the non-asymptotic bounds on the total variation
distance between the target distribution of the Langevin SDEs and the law
induced by the PLMC scheme with order $\mathcal{O}(h |\ln h|)$. Moreover, for a
given precision $\epsilon$, the smallest number of iterations of the classical
Langevin Monte Carlo (LMC) scheme with the non-convex potential $U$ and the
globally Lipshitz gradient of $U$ can be guaranteed by order
${\mathcal{O}}\big(\tfrac{d^{3/2}}{\epsilon} \cdot \ln (\tfrac{d}{\epsilon})
\cdot \ln (\tfrac{1}{\epsilon}) \big)$. Numerical experiments are provided to
confirm the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17080" title="Abstract">arXiv:2312.17080</a> [<a href="/pdf/2312.17080" title="Download PDF">pdf</a>, <a href="/format/2312.17080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenge LLMs to Reason About Reasoning: A Benchmark to Unveil  Cognitive Depth in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhongshen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haiyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/dvlab-research/DiagGSM8K">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work, we introduce a novel evaluation paradigm for Large Language
Models, one that challenges them to engage in meta-reasoning. This approach
addresses critical shortcomings in existing math problem-solving benchmarks,
traditionally used to evaluate the cognitive capabilities of agents. Our
paradigm shifts the focus from result-oriented assessments, which often
overlook the reasoning process, to a more holistic evaluation that effectively
differentiates the cognitive capabilities among models. For example, in our
benchmark, GPT-4 demonstrates a performance ten times more accurate than
GPT3-5. The significance of this new paradigm lies in its ability to reveal
potential cognitive deficiencies in LLMs that current benchmarks, such as
GSM8K, fail to uncover due to their saturation and lack of effective
differentiation among varying reasoning abilities. Our comprehensive analysis
includes several state-of-the-art math models from both open-source and
closed-source communities, uncovering fundamental deficiencies in their
training and evaluation approaches. This paper not only advocates for a
paradigm shift in the assessment of LLMs but also contributes to the ongoing
discourse on the trajectory towards Artificial General Intelligence (AGI). By
promoting the adoption of meta-reasoning evaluation methods similar to ours, we
aim to facilitate a more accurate assessment of the true cognitive abilities of
LLMs.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17081" title="Abstract">arXiv:2312.17081</a> [<a href="/pdf/2312.17081" title="Download PDF">pdf</a>, <a href="/format/2312.17081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based  Stackelberg Game for Vehicular Twins Migration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Helin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dongdong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+S">M. Shamim Hossain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Vehicular Metaverses represent emerging paradigms arising from the
convergence of vehicle road cooperation, Metaverse, and augmented intelligence
of things. Users engaging with Vehicular Metaverses (VMUs) gain entry by
consistently updating their Vehicular Twins (VTs), which are deployed on
RoadSide Units (RSUs) in proximity. The constrained RSU coverage and the
consistently moving vehicles necessitate the continuous migration of VTs
between RSUs through vehicle road cooperation, ensuring uninterrupted immersion
services for VMUs. Nevertheless, the VT migration process faces challenges in
obtaining adequate bandwidth resources from RSUs for timely migration, posing a
resource trading problem among RSUs. In this paper, we tackle this challenge by
formulating a game-theoretic incentive mechanism with multi-leader
multi-follower, incorporating insights from social-awareness and queueing
theory to optimize VT migration. To validate the existence and uniqueness of
the Stackelberg Equilibrium, we apply the backward induction method.
Theoretical solutions for this equilibrium are then obtained through the
Alternating Direction Method of Multipliers (ADMM) algorithm. Moreover, owing
to incomplete information caused by the requirements for privacy protection, we
proposed a multi-agent deep reinforcement learning algorithm named MALPPO.
MALPPO facilitates learning the Stackelberg Equilibrium without requiring
private information from others, relying solely on past experiences.
Comprehensive experimental results demonstrate that our MALPPO-based incentive
mechanism outperforms baseline approaches significantly, showcasing rapid
convergence and achieving the highest reward.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17090" title="Abstract">arXiv:2312.17090</a> [<a href="/pdf/2312.17090" title="Download PDF">pdf</a>, <a href="/format/2312.17090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Align: Teaching LMMs for Visual Scoring via Discrete Text-Defined  Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yixuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The explosion of visual content available online underscores the requirement
for an accurate machine assessor to robustly evaluate scores across diverse
types of visual contents. While recent studies have demonstrated the
exceptional potentials of large multi-modality models (LMMs) on a wide range of
related fields, in this work, we explore how to teach them for visual rating
aligned with human opinions. Observing that human raters only learn and judge
discrete text-defined levels in subjective studies, we propose to emulate this
subjective process and teach LMMs with text-defined rating levels instead of
scores. The proposed Q-Align achieves state-of-the-art performance on image
quality assessment (IQA), image aesthetic assessment (IAA), as well as video
quality assessment (VQA) tasks under the original LMM structure. With the
syllabus, we further unify the three tasks into one model, termed the OneAlign.
In our experiments, we demonstrate the advantage of the discrete-level-based
syllabus over direct-score-based variants for LMMs. Our code and the
pre-trained weights are released at https://github.com/Q-Future/Q-Align.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17097" title="Abstract">arXiv:2312.17097</a> [<a href="/pdf/2312.17097" title="Download PDF">pdf</a>, <a href="/ps/2312.17097" title="Download PostScript">ps</a>, <a href="/format/2312.17097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tighter List-Size Bounds for List-Decoding and Recovery of Folded  Reed-Solomon and Multiplicity Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamo%2C+I">Itzhak Tamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Folded Reed-Solomon (FRS) and univariate multiplicity codes are prominent
polynomial codes over finite fields, renowned for achieving list decoding
capacity. These codes have found a wide range of applications beyond the
traditional scope of coding theory. In this paper, we introduce improved bounds
on the list size for list decoding of these codes, achieved through a more
streamlined proof method. Additionally, we refine an existing randomized
algorithm to output the codewords on the list, enhancing its success
probability and reducing its running time. Lastly, we establish list-size
bounds for a fixed decoding parameter. Notably, our results demonstrate that
FRS codes asymptotically attain the generalized Singleton bound for a list of
size $2$ over a relatively small alphabet, marking the first explicit instance
of a code with this property.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17100" title="Abstract">arXiv:2312.17100</a> [<a href="/pdf/2312.17100" title="Download PDF">pdf</a>, <a href="/format/2312.17100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSPP: A Unified Benchmarking Tool for Time-series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C4%85czek%2C+J">Jan B&#x105;czek</a>, 
<a href="/search/cs?searchtype=author&query=Zhylko%2C+D">Dmytro Zhylko</a>, 
<a href="/search/cs?searchtype=author&query=Titericz%2C+G">Gilberto Titericz</a>, 
<a href="/search/cs?searchtype=author&query=Darabi%2C+S">Sajad Darabi</a>, 
<a href="/search/cs?searchtype=author&query=Puget%2C+J">Jean-Francois Puget</a>, 
<a href="/search/cs?searchtype=author&query=Putterman%2C+I">Izzy Putterman</a>, 
<a href="/search/cs?searchtype=author&query=Majchrowski%2C+D">Dawid Majchrowski</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anmol Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kranen%2C+K">Kyle Kranen</a>, 
<a href="/search/cs?searchtype=author&query=Morkisz%2C+P">Pawel Morkisz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently there has been increasing interest in developing and deploying deep
graph learning algorithms for many tasks, such as fraud detection and
recommender systems. Albeit, there is a limited number of publicly available
graph-structured datasets, most of which are tiny compared to production-sized
applications or are limited in their application domain. This work tackles this
shortcoming by proposing a scalable synthetic graph generation tool to scale
the datasets to production-size graphs with trillions of edges and billions of
nodes. The tool learns a series of parametric models from proprietary datasets
that can be released to researchers to study various graph methods on the
synthetic data increasing prototype development and novel applications. We
demonstrate the generalizability of the framework across a series of datasets,
mimicking structural and feature distributions as well as the ability to scale
them across varying sizes demonstrating their usefulness for benchmarking and
model development.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17106" title="Abstract">arXiv:2312.17106</a> [<a href="/pdf/2312.17106" title="Download PDF">pdf</a>, <a href="/format/2312.17106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Biased Transformer for Robust Multi-View 3D Human Pose  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moliner%2C+O">Olivier Moliner</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sangxia Huang</a>, 
<a href="/search/cs?searchtype=author&query=%C3%85str%C3%B6m%2C+K">Kalle &#xc5;str&#xf6;m</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted: 18th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address the challenges in estimating 3D human poses from multiple views
under occlusion and with limited overlapping views. We approach multi-view,
single-person 3D human pose reconstruction as a regression problem and propose
a novel encoder-decoder Transformer architecture to estimate 3D poses from
multi-view 2D pose sequences. The encoder refines 2D skeleton joints detected
across different views and times, fusing multi-view and temporal information
through global self-attention. We enhance the encoder by incorporating a
geometry-biased attention mechanism, effectively leveraging geometric
relationships between views. Additionally, we use detection scores provided by
the 2D pose detector to further guide the encoder's attention based on the
reliability of the 2D detections. The decoder subsequently regresses the 3D
pose sequence from these refined tokens, using pre-defined queries for each
joint. To enhance the generalization of our method to unseen scenes and improve
resilience to missing joints, we implement strategies including scene
centering, synthetic views, and token dropout. We conduct extensive experiments
on three benchmark public datasets, Human3.6M, CMU Panoptic and
Occlusion-Persons. Our results demonstrate the efficacy of our approach,
particularly in occluded scenes and when few views are available, which are
traditionally challenging scenarios for triangulation-based methods.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17107" title="Abstract">arXiv:2312.17107</a> [<a href="/pdf/2312.17107" title="Download PDF">pdf</a>, <a href="/format/2312.17107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Intelligence College in Europe (ICE): An Effort to Create a European  Intelligence Community
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borghoff%2C+U+M">Uwe M. Borghoff</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+L">Lars Berger</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+F">Fran&#xe7;ois Fischer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures. Our experience with the MISS (especially for the Master of Science degree) has shown that three aspects are important in ICE: first, transdisciplinarity; second, the integration of profound IT know-how; and third, the development and learning of methodological skills
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In fulfilling the European security commitment, the actors of the so-called
"Intelligence Community" play a central role. They provide political and
military decision-makers with important analyses and information. The
Intelligence College in Europe (ICE) is the first entity to offer professional
intelligence training as well as postgraduate level academic education in
intelligence and security studies at a pan-European level. In developing its
postgraduate provision, ICE has benefited from the experience of the German
Master of Intelligence and Security Studies (MISS), which is a joint effort of
the University of the Bundeswehr Munich and the Department of Intelligence at
the Federal University of Administrative Sciences in Berlin. As a main
contribution of this paper, the module Counterterrorism (adapted from the MISS)
is examined in more detail as a case study of how postgraduate modules can be
modified to speak to a pan-European audience of intelligence professionals.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17109" title="Abstract">arXiv:2312.17109</a> [<a href="/pdf/2312.17109" title="Download PDF">pdf</a>, <a href="/format/2312.17109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIVC: Multiple Instance Visual Component for Visual-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junzhou Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Vision-language models have been widely explored across a wide range of tasks
and achieve satisfactory performance. However, it's under-explored how to
consolidate entity understanding through a varying number of images and to
align it with the pre-trained language models for generative tasks. In this
paper, we propose MIVC, a general multiple instance visual component to bridge
the gap between various image inputs with off-the-shelf vision-language models
by aggregating visual representations in a permutation-invariant fashion
through a neural network. We show that MIVC could be plugged into the
visual-language models to improve the model performance consistently on visual
question answering, classification and captioning tasks on a public available
e-commerce dataset with multiple images per product. Furthermore, we show that
the component provides insight into the contribution of each image to the
downstream tasks.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17110" title="Abstract">arXiv:2312.17110</a> [<a href="/pdf/2312.17110" title="Download PDF">pdf</a>, <a href="/format/2312.17110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Semantic Scene Understanding for Fine-Grained 3D Modeling of  Plants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qadri%2C+M">Mohamad Qadri</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+H">Harry Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+E">Eric Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+G">George Kantor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Agricultural robotics is an active research area due to global population
growth and expectations of food and labor shortages. Robots can potentially
help with tasks such as pruning, harvesting, phenotyping, and plant modeling.
However, agricultural automation is hampered by the difficulty in creating high
resolution 3D semantic maps in the field that would allow for safe manipulation
and navigation. In this paper, we build toward solutions for this issue and
showcase how the use of semantics and environmental priors can help in
constructing accurate 3D maps for the target application of sorghum.
Specifically, we 1) use sorghum seeds as semantic landmarks to build a visual
Simultaneous Localization and Mapping (SLAM) system that enables us to map
78\\% of a sorghum range on average, compared to 38% with ORB-SLAM2; and 2) use
seeds as semantic features to improve 3D reconstruction of a full sorghum
panicle from images taken by a robotic in-hand camera.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17113" title="Abstract">arXiv:2312.17113</a> [<a href="/pdf/2312.17113" title="Download PDF">pdf</a>, <a href="/ps/2312.17113" title="Download PostScript">ps</a>, <a href="/format/2312.17113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kirchhoff-Law Johnson Noise Meets Web 3.0: A Statistical Physical Method  of Random Key Generation for Decentralized Identity Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chamon%2C+C">Christiana Chamon</a>, 
<a href="/search/cs?searchtype=author&query=Mohanasundar%2C+K">Kamalesh Mohanasundar</a>, 
<a href="/search/cs?searchtype=author&query=Flanery%2C+S+A">Sarah A. Flanery</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+F+K">Francis K. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.12268">arXiv:2312.12268</a>; text overlap with <a href="/abs/2110.03088">arXiv:2110.03088</a>, <a href="/abs/2112.09052">arXiv:2112.09052</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper presents a statistical physical generation of random keys for a
decentralized identity ecosystem that uses Web 3.0 protocols. Web 3.0 is driven
by secure keys, typically represented in hexadecimal, that are pseudo-randomly
generated by an initialization vector and complex computational algorithms. We
demonstrate that the statistical physical Kirchhoff-law-Johnson-noise (KLJN)
scheme eliminates the additional computational power by naturally generating
truly random binary keys to drive the creation of decentralized identifiers
(DIDs) that are appended to an Ethereum blockchain.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17115" title="Abstract">arXiv:2312.17115</a> [<a href="/pdf/2312.17115" title="Download PDF">pdf</a>, <a href="/format/2312.17115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Are We from Believable AI Agents? A Framework for Evaluating the  Believability of Human Behavior Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jinlan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Human behavior simulation of AI agents necessitates the agents to possess a
quality of believability, which is crucial as it facilitates users in
establishing trust toward the agents and streamlines the fulfillment of the
agents' goal. While recent advancements in Large Language Model (LLM) based
agents have improved human behavior simulation, challenges inherent to LLMs
(e.g., long context modeling) can undermine their believability. Consequently,
evaluating AI agent believability becomes imperative. Unfortunately, prior
research often neglects the negative impacts of LLM deficiencies. To address
these gaps, we introduce two metrics for assessing LLM-based agent
believability: consistency, and robustness, together with a benchmark,
SimulateBench, with which, we evaluate the consistency and robustness of agents
implemented with popular LLMs. We find that agents (i) struggle to accurately
depict character information when presented with lengthy profile inputs; (ii)
exhibit vulnerability to profile perturbations; and (iii) are significantly
affected by certain key factors that impact their overall believability. Code
and SimulateBench are public at https://github.com/GAIR-NLP/GPTMan.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17116" title="Abstract">arXiv:2312.17116</a> [<a href="/pdf/2312.17116" title="Download PDF">pdf</a>, <a href="/format/2312.17116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Visual Reinforcement Learning with Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhecheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page and code: <a href="https://yanjieze.com/SAM-G/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Learning policies that can generalize to unseen environments is a fundamental
challenge in visual reinforcement learning (RL). While most current methods
focus on acquiring robust visual representations through auxiliary supervision,
pre-training, or data augmentation, the potential of modern vision foundation
models remains underleveraged. In this work, we introduce Segment Anything
Model for Generalizable visual RL (SAM-G), a novel framework that leverages the
promptable segmentation ability of Segment Anything Model (SAM) to enhance the
generalization capabilities of visual RL agents. We utilize image features from
DINOv2 and SAM to find correspondence as point prompts to SAM, and then SAM
produces high-quality masked images for agents directly. Evaluated across 8
DMControl tasks and 3 Adroit tasks, SAM-G significantly improves the visual
generalization ability without altering the RL agents' architecture but merely
their observations. Notably, SAM-G achieves 44% and 29% relative improvements
on the challenging video hard setting on DMControl and Adroit respectively,
compared to state-of-the-art methods. Video and code:
https://yanjieze.com/SAM-G/
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17117" title="Abstract">arXiv:2312.17117</a> [<a href="/pdf/2312.17117" title="Download PDF">pdf</a>, <a href="/format/2312.17117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding-Prompter: Prompting LLM with Multimodal Information for  Temporal Sentence Grounding in Long Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Houlun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zihan Song</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jia Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Temporal Sentence Grounding (TSG), which aims to localize moments from videos
based on the given natural language queries, has attracted widespread
attention. Existing works are mainly designed for short videos, failing to
handle TSG in long videos, which poses two challenges: i) complicated contexts
in long videos require temporal reasoning over longer moment sequences, and ii)
multiple modalities including textual speech with rich information require
special designs for content understanding in long videos. To tackle these
challenges, in this work we propose a Grounding-Prompter method, which is
capable of conducting TSG in long videos through prompting LLM with multimodal
information. In detail, we first transform the TSG task and its multimodal
inputs including speech and visual, into compressed task textualization.
Furthermore, to enhance temporal reasoning under complicated contexts, a
Boundary-Perceptive Prompting strategy is proposed, which contains three folds:
i) we design a novel Multiscale Denoising Chain-of-Thought (CoT) to combine
global and local semantics with noise filtering step by step, ii) we set up
validity principles capable of constraining LLM to generate reasonable
predictions following specific formats, and iii) we introduce one-shot
In-Context-Learning (ICL) to boost reasoning through imitation, enhancing LLM
in TSG task understanding. Experiments demonstrate the state-of-the-art
performance of our Grounding-Prompter method, revealing the benefits of
prompting LLM with multimodal information for TSG in long videos.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17118" title="Abstract">arXiv:2312.17118</a> [<a href="/pdf/2312.17118" title="Download PDF">pdf</a>, <a href="/format/2312.17118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Sparse 3D Panoptic Occupancy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haisong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zetong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Occupancy prediction plays a pivotal role in the realm of autonomous driving.
Previous methods typically constructs a dense 3D volume, neglecting the
inherent sparsity of the scene, which results in a high computational cost.
Furthermore, these methods are limited to semantic occupancy and fail to
differentiate between distinct instances. To exploit the sparsity property and
ensure instance-awareness, we introduce a novel fully sparse panoptic occupancy
network, termed SparseOcc. SparseOcc initially reconstructs a sparse 3D
representation from visual inputs. Subsequently, it employs sparse instance
queries to predict each object instance from the sparse 3D representation.
These instance queries interact with 2D features via mask-guided sparse
sampling, thereby circumventing the need for costly dense features or global
attention. Additionally, we have established the first-ever vision-centric
panoptic occupancy benchmark. SparseOcc demonstrates its efficacy on the
Occ3D-nus dataset by achieving a mean Intersection over Union (mIoU) of 26.0,
while maintaining a real-time inference speed of 25.4 FPS. By incorporating
temporal modeling from the preceding 8 frames, SparseOcc further improves its
performance, achieving 30.9 mIoU without whistles and bells. Code will be made
available.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17120" title="Abstract">arXiv:2312.17120</a> [<a href="/pdf/2312.17120" title="Download PDF">pdf</a>, <a href="/format/2312.17120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Math: Part I -- MathPile: A Billion-Token-Scale  Pretraining Corpus for Math
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zengzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Rui Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages. Working in Progress. <a href="https://github.com/GAIR-NLP/MathPile/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">High-quality, large-scale corpora are the cornerstone of building foundation
models. In this work, we introduce \textsc{MathPile}, a diverse and
high-quality math-centric corpus comprising about 9.5 billion tokens.
Throughout its creation, we adhered to the principle of ``\emph{less is
more}'', firmly believing in the supremacy of data quality over quantity, even
in the pre-training phase. Our meticulous data collection and processing
efforts included a complex suite of preprocessing, prefiltering, language
identification, cleaning, filtering, and deduplication, ensuring the high
quality of our corpus. Furthermore, we performed data contamination detection
on downstream benchmark test sets to eliminate duplicates. We hope our
\textsc{MathPile} can help to enhance the mathematical reasoning abilities of
language models. We plan to open-source different versions of \mathpile with
the scripts used for processing, to facilitate future developments in this
field.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17122" title="Abstract">arXiv:2312.17122</a> [<a href="/pdf/2312.17122" title="Download PDF">pdf</a>, <a href="/format/2312.17122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model for Causal Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haitao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+L">Lin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuhe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown their success in language
understanding and reasoning on general topics. However, their capability to
inference based on user-specified structured data and knowledge in corpus-rare
concepts like causal decision-making is still limited. In this work, we explore
the possibility of fine-tuning an open-sourced LLM into LLM4Causal, which can
identify the causal task, execute a corresponding function, and interpret its
numerical results based on users' queries and the provided dataset. Meanwhile,
we propose a data generation process for more controllable GPT prompting and
present two instruction-tuning datasets: (1) Causal-Retrieval-Bench for causal
problem identification and input parameter extraction for causal function
calling and (2) Causal-Interpret-Bench for in-context causal interpretation.
With three case studies, we showed that LLM4Causal can deliver end-to-end
solutions for causal problems and provide easy-to-understand answers. Numerical
studies also reveal that it has a remarkable ability to identify the correct
causal task given a query.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17127" title="Abstract">arXiv:2312.17127</a> [<a href="/pdf/2312.17127" title="Download PDF">pdf</a>, <a href="/format/2312.17127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic programming interfaces for random graphs: Markov  categories, graphons, and nominal sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ackerman%2C+N+L">Nathanael L. Ackerman</a>, 
<a href="/search/cs?searchtype=author&query=Freer%2C+C+E">Cameron E. Freer</a>, 
<a href="/search/cs?searchtype=author&query=Kaddar%2C+Y">Younesse Kaddar</a>, 
<a href="/search/cs?searchtype=author&query=Karwowski%2C+J">Jacek Karwowski</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+S+K">Sean K. Moss</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D+M">Daniel M. Roy</a>, 
<a href="/search/cs?searchtype=author&query=Staton%2C+S">Sam Staton</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongseok Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for POPL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO); Probability (math.PR)

</div>
<p class="mathjax">We study semantic models of probabilistic programming languages over graphs,
and establish a connection to graphons from graph theory and combinatorics. We
show that every well-behaved equational theory for our graph probabilistic
programming language corresponds to a graphon, and conversely, every graphon
arises in this way.
<br />We provide three constructions for showing that every graphon arises from an
equational theory. The first is an abstract construction, using Markov
categories and monoidal indeterminates. The second and third are more concrete.
The second is in terms of traditional measure theoretic probability, which
covers 'black-and-white' graphons. The third is in terms of probability monads
on the nominal sets of Gabbay and Pitts. Specifically, we use a variation of
nominal sets induced by the theory of graphs, which covers Erd\H{o}s-R\'enyi
graphons. In this way, we build new models of graph probabilistic programming
from graphons.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17133" title="Abstract">arXiv:2312.17133</a> [<a href="/pdf/2312.17133" title="Download PDF">pdf</a>, <a href="/format/2312.17133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to  Describe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yifan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zeyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yihong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xing Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present ARTrackV2, which integrates two pivotal aspects of tracking:
determining where to look (localization) and how to describe (appearance
analysis) the target object across video frames. Building on the foundation of
its predecessor, ARTrackV2 extends the concept by introducing a unified
generative framework to "read out" object's trajectory and "retell" its
appearance in an autoregressive manner. This approach fosters a time-continuous
methodology that models the joint evolution of motion and visual features,
guided by previous estimates. Furthermore, ARTrackV2 stands out for its
efficiency and simplicity, obviating the less efficient intra-frame
autoregression and hand-tuned parameters for appearance updates. Despite its
simplicity, ARTrackV2 achieves state-of-the-art performance on prevailing
benchmark datasets while demonstrating remarkable efficiency improvement. In
particular, ARTrackV2 achieves AO score of 79.5\% on GOT-10k, and AUC of 86.1\%
on TrackingNet while being $3.6 \times$ faster than ARTrack. The code will be
released.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17135" title="Abstract">arXiv:2312.17135</a> [<a href="/pdf/2312.17135" title="Download PDF">pdf</a>, <a href="/format/2312.17135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InsActor: Instruction-driven Physics-based Characters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page is at <a href="https://jiawei-ren.github.io/projects/insactor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Robotics (cs.RO)

</div>
<p class="mathjax">Generating animation of physics-based characters with intuitive control has
long been a desirable task with numerous applications. However, generating
physically simulated animations that reflect high-level human instructions
remains a difficult problem due to the complexity of physical environments and
the richness of human language. In this paper, we present InsActor, a
principled generative framework that leverages recent advancements in
diffusion-based human motion models to produce instruction-driven animations of
physics-based characters. Our framework empowers InsActor to capture complex
relationships between high-level human instructions and character motions by
employing diffusion policies for flexibly conditioned motion planning. To
overcome invalid states and infeasible state transitions in planned motions,
InsActor discovers low-level skills and maps plans to latent skill sequences in
a compact latent space. Extensive experiments demonstrate that InsActor
achieves state-of-the-art results on various tasks, including
instruction-driven motion generation and instruction-driven waypoint heading.
Notably, the ability of InsActor to generate physically simulated animations
using high-level human instructions makes it a valuable tool, particularly in
executing long-horizon tasks with a rich set of instructions.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17140" title="Abstract">arXiv:2312.17140</a> [<a href="/pdf/2312.17140" title="Download PDF">pdf</a>, <a href="/format/2312.17140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Inapproximability of Reconfiguration Problems: PSPACE-Hardness and  some Tight NP-Hardness Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S.%2C+K+C">Karthik C. S.</a>, 
<a href="/search/cs?searchtype=author&query=Manurangsi%2C+P">Pasin Manurangsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The field of combinatorial reconfiguration studies search problems with a
focus on transforming one feasible solution into another.
<br />Recently, Ohsaka [STACS'23] put forth the Reconfiguration Inapproximability
Hypothesis (RIH), which roughly asserts that there is some $\varepsilon&gt;0$ such
that given as input a $k$-CSP instance (for some constant $k$) over some
constant sized alphabet, and two satisfying assignments $\psi_s$ and $\psi_t$,
it is PSPACE-hard to find a sequence of assignments starting from $\psi_s$ and
ending at $\psi_t$ such that every assignment in the sequence satisfies at
least $(1-\varepsilon)$ fraction of the constraints and also that every
assignment in the sequence is obtained by changing its immediately preceding
assignment (in the sequence) on exactly one variable. Assuming RIH, many
important reconfiguration problems have been shown to be PSPACE-hard to
approximate by Ohsaka [STACS'23; SODA'24].
<br />In this paper, we prove RIH, thus establishing the first (constant factor)
PSPACE-hardness of approximation results for many reconfiguration problems,
resolving an open question posed by Ito et al. [TCS'11]. Our proof uses known
constructions of Probabilistically Checkable Proofs of Proximity (in a
black-box manner) to create the gap.
<br />We also prove that the aforementioned $k$-CSP Reconfiguration problem is
NP-hard to approximate to within a factor of $1/2 + \varepsilon$ (for any
$\varepsilon&gt;0$) when $k=2$. We complement this with a $(1/2 -
\varepsilon)$-approximation polynomial time algorithm, which improves upon a
$(1/4 - \varepsilon)$-approximation algorithm of Ohsaka [2023] (again for any
$\varepsilon&gt;0$).
<br />Finally, we show that Set Cover Reconfiguration is NP-hard to approximate to
within a factor of $2 - \varepsilon$ for any constant $\varepsilon &gt; 0$, which
matches the simple linear-time 2-approximation algorithm by Ito et al.
[TCS'11].
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17141" title="Abstract">arXiv:2312.17141</a> [<a href="/pdf/2312.17141" title="Download PDF">pdf</a>, <a href="/format/2312.17141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Programming with Exact Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+D">Dario Stein</a>, 
<a href="/search/cs?searchtype=author&query=Staton%2C+S">Sam Staton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for JACM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO); Probability (math.PR)

</div>
<p class="mathjax">We spell out the paradigm of exact conditioning as an intuitive and powerful
way of conditioning on observations in probabilistic programs. This is
contrasted with likelihood-based scoring known from languages such as Stan. We
study exact conditioning in the cases of discrete and Gaussian probability,
presenting prototypical languages for each case and giving semantics to them.
We make use of categorical probability (namely Markov and CD categories) to
give a general account of exact conditioning which avoids limits and measure
theory, instead focusing on restructuring dataflow and program equations. The
correspondence between such categories and a class of programming languages is
made precise by defining the internal language of a CD category.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17142" title="Abstract">arXiv:2312.17142</a> [<a href="/pdf/2312.17142" title="Download PDF">pdf</a>, <a href="/format/2312.17142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamGaussian4D: Generative 4D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+A">Ang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Gang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Project page is at <a href="https://jiawei-ren.github.io/projects/dreamgaussian4d">this https URL</a> Code is at <a href="https://github.com/jiawei-ren/dreamgaussian4d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Remarkable progress has been made in 4D content generation recently. However,
existing methods suffer from long optimization time, lack of motion
controllability, and a low level of detail. In this paper, we introduce
DreamGaussian4D, an efficient 4D generation framework that builds on 4D
Gaussian Splatting representation. Our key insight is that the explicit
modeling of spatial transformations in Gaussian Splatting makes it more
suitable for the 4D generation setting compared with implicit representations.
DreamGaussian4D reduces the optimization time from several hours to just a few
minutes, allows flexible control of the generated 3D motion, and produces
animated meshes that can be efficiently rendered in 3D engines.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17147" title="Abstract">arXiv:2312.17147</a> [<a href="/pdf/2312.17147" title="Download PDF">pdf</a>, <a href="/format/2312.17147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk of Cascading Collisions in Network of Vehicles with Delayed  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+G">Guangyi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Somarakis%2C+C">Christoforos Somarakis</a>, 
<a href="/search/eess?searchtype=author&query=Motee%2C+N">Nader Motee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work explores cascading failures in networked control systems by
employing a platoon of vehicles that exchange information over a time-delayed
communication graph as a model. We study the roles of network connectivity,
system dynamics, communication time-delay, and uncertainty in the emergence of
these failure phenomena. Our results yield closed-form expressions for the
average value-at-risk (AV@R), which we utilize as a coherent risk measure to
quantify the cascading effect of vehicle collisions within a platoon. These
findings are further extended with several standard communication graphs with
symmetries to reveal the impact of graph design parameters on the risk of
cascading collisions. By presenting the boundedness of the steady-state
statistics of the inter-vehicle distances, we present the best achievable risk
of cascading collision with general graph topologies, which is further
specified for special communication graph such as the complete graph. Our
theoretical findings pave the way for the development of a robust framework
designed to mitigate the risk of cascading collisions in vehicle platoons by
exploring how platoon reacts to the various existing failures and the change of
communication links.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17149" title="Abstract">arXiv:2312.17149</a> [<a href="/pdf/2312.17149" title="Download PDF">pdf</a>, <a href="/format/2312.17149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-Demand JSON: A Better Way to Parse Documents?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keiser%2C+J">John Keiser</a>, 
<a href="/search/cs?searchtype=author&query=Lemire%2C+D">Daniel Lemire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Performance (cs.PF)

</div>
<p class="mathjax">JSON is a popular standard for data interchange on the Internet. Ingesting
JSON documents can be a performance bottleneck. A popular parsing strategy
consists in converting the input text into a tree-based data structure --
sometimes called a Document Object Model or DOM. We designed and implemented a
novel JSON parsing interface -- called On-Demand -- that appears to the
programmer like a conventional DOM-based approach. However, the underlying
implementation is a pointer iterating through the content, only materializing
the results (objects, arrays, strings, numbers) lazily.On recent commodity
processors, an implementation of our approach provides superior performance in
multiple benchmarks. To ensure reproducibility, our work is freely available as
open source software. Several systems use On Demand: e.g., Apache Doris, the
Node.js JavaScript runtime, Milvus, and Velox.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17156" title="Abstract">arXiv:2312.17156</a> [<a href="/pdf/2312.17156" title="Download PDF">pdf</a>, <a href="/format/2312.17156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEAST: Online Joint Beat and Downbeat Tracking Based on Streaming  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chih-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Li Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Many deep learning models have achieved dominant performance on the offline
beat tracking task. However, online beat tracking, in which only the past and
present input features are available, still remains challenging. In this paper,
we propose BEAt tracking Streaming Transformer (BEAST), an online joint beat
and downbeat tracking system based on the streaming Transformer. To deal with
online scenarios, BEAST applies contextual block processing in the Transformer
encoder. Moreover, we adopt relative positional encoding in the attention layer
of the streaming Transformer encoder to capture relative timing position which
is critically important information in music. Carrying out beat and downbeat
experiments on benchmark datasets for a low latency scenario with maximum
latency under 50 ms, BEAST achieves an F1-measure of 80.04% in beat and 52.73%
in downbeat, which is a substantial improvement of about 5 and 13 percentage
points over the state-of-the-art online beat and downbeat tracking model.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17159" title="Abstract">arXiv:2312.17159</a> [<a href="/pdf/2312.17159" title="Download PDF">pdf</a>, <a href="/format/2312.17159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replica Tree-based Federated Learning using Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghilea%2C+R">Ramona Ghilea</a>, 
<a href="/search/cs?searchtype=author&query=Rekik%2C+I">Islem Rekik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning from limited data has been extensively studied in machine learning,
considering that deep neural networks achieve optimal performance when trained
using a large amount of samples. Although various strategies have been proposed
for centralized training, the topic of federated learning with small datasets
remains largely unexplored. Moreover, in realistic scenarios, such as settings
where medical institutions are involved, the number of participating clients is
also constrained. In this work, we propose a novel federated learning
framework, named RepTreeFL. At the core of the solution is the concept of a
replica, where we replicate each participating client by copying its model
architecture and perturbing its local data distribution. Our approach enables
learning from limited data and a small number of clients by aggregating a
larger number of models with diverse data distributions. Furthermore, we
leverage the hierarchical structure of the client network (both original and
virtual), alongside the model diversity across replicas, and introduce a
diversity-based tree aggregation, where replicas are combined in a tree-like
manner and the aggregation weights are dynamically updated based on the model
discrepancy. We evaluated our method on two tasks and two types of data, graph
generation and image classification (binary and multi-class), with both
homogeneous and heterogeneous model architectures. Experimental results
demonstrate the effectiveness and outperformance of RepTreeFL in settings where
both data and clients are limited. Our code is available at
https://github.com/basiralab/RepTreeFL.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17161" title="Abstract">arXiv:2312.17161</a> [<a href="/pdf/2312.17161" title="Download PDF">pdf</a>, <a href="/format/2312.17161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restoration by Generation with Constrained Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuaner Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhihao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The inherent generative power of denoising diffusion models makes them
well-suited for image restoration tasks where the objective is to find the
optimal high-quality image within the generative space that closely resembles
the input image. We propose a method to adapt a pretrained diffusion model for
image restoration by simply adding noise to the input image to be restored and
then denoise. Our method is based on the observation that the space of a
generative model needs to be constrained. We impose this constraint by
finetuning the generative model with a set of anchor images that capture the
characteristics of the input image. With the constrained space, we can then
leverage the sampling strategy used for generation to do image restoration. We
evaluate against previous methods and show superior performances on multiple
real-world restoration datasets in preserving identity and image quality. We
also demonstrate an important and practical application on personalized
restoration, where we use a personal album as the anchor images to constrain
the generative space. This approach allows us to produce results that
accurately preserve high-frequency details, which previous works are unable to
do. Project webpage: https://gen2res.github.io.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17163" title="Abstract">arXiv:2312.17163</a> [<a href="/pdf/2312.17163" title="Download PDF">pdf</a>, <a href="/format/2312.17163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FENet: Focusing Enhanced Network for Lane Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liman Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hanyang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages including appendix. The website will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Inspired by human driving focus, this research pioneers networks augmented
with Focusing Sampling, Partial Field of View Evaluation, Enhanced FPN
architecture and Directional IoU Loss - targeted innovations addressing
obstacles to precise lane detection for autonomous driving. Experiments
demonstrate our Focusing Sampling strategy, emphasizing vital distant details
unlike uniform approaches, significantly boosts both benchmark and practical
curved/distant lane recognition accuracy essential for safety. While FENetV1
achieves state-of-the-art conventional metric performance via enhancements
isolating perspective-aware contexts mimicking driver vision, FENetV2 proves
most reliable on the proposed Partial Field analysis. Hence we specifically
recommend V2 for practical lane navigation despite fractional degradation on
standard entire-image measures. Future directions include collecting on-road
data and integrating complementary dual frameworks to further breakthroughs
guided by human perception principles. Code will be made available.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17164" title="Abstract">arXiv:2312.17164</a> [<a href="/pdf/2312.17164" title="Download PDF">pdf</a>, <a href="/format/2312.17164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing NextG Systems against Poisoning Attacks on Federated Learning:  A Game-Theoretic Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagduyu%2C+Y+E">Yalin E. Sagduyu</a>, 
<a href="/search/cs?searchtype=author&query=Erpek%2C+T">Tugba Erpek</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yi Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper studies the poisoning attack and defense interactions in a
federated learning (FL) system, specifically in the context of wireless signal
classification using deep learning for next-generation (NextG) communications.
FL collectively trains a global model without the need for clients to exchange
their data samples. By leveraging geographically dispersed clients, the trained
global model can be used for incumbent user identification, facilitating
spectrum sharing. However, in this distributed learning system, the presence of
malicious clients introduces the risk of poisoning the training data to
manipulate the global model through falsified local model exchanges. To address
this challenge, a proactive defense mechanism is employed in this paper to make
informed decisions regarding the admission or rejection of clients
participating in FL systems. Consequently, the attack-defense interactions are
modeled as a game, centered around the underlying admission and poisoning
decisions. First, performance bounds are established, encompassing the best and
worst strategies for attackers and defenders. Subsequently, the attack and
defense utilities are characterized within the Nash equilibrium, where no
player can unilaterally improve its performance given the fixed strategies of
others. The results offer insights into novel operational modes that safeguard
FL systems against poisoning attacks by quantifying the performance of both
attacks and defenses in the context of NextG communications.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17168" title="Abstract">arXiv:2312.17168</a> [<a href="/pdf/2312.17168" title="Download PDF">pdf</a>, <a href="/format/2312.17168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Active Sampling Reduce Causal Confusion in Offline Reinforcement  Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gunshi Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/cs?searchtype=author&query=McAllister%2C+R+T">Rowan Thomas McAllister</a>, 
<a href="/search/cs?searchtype=author&query=Gaidon%2C+A">Adrien Gaidon</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Proceedings of the 2nd Conference on Causal Learning and Reasoning (CLeaR 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Causal confusion is a phenomenon where an agent learns a policy that reflects
imperfect spurious correlations in the data. Such a policy may falsely appear
to be optimal during training if most of the training data contain such
spurious correlations. This phenomenon is particularly pronounced in domains
such as robotics, with potentially large gaps between the open- and closed-loop
performance of an agent. In such settings, causally confused models may appear
to perform well according to open-loop metrics during training but fail
catastrophically when deployed in the real world. In this paper, we study
causal confusion in offline reinforcement learning. We investigate whether
selectively sampling appropriate points from a dataset of demonstrations may
enable offline reinforcement learning agents to disambiguate the underlying
causal mechanisms of the environment, alleviate causal confusion in offline
reinforcement learning, and produce a safer model for deployment. To answer
this question, we consider a set of tailored offline reinforcement learning
datasets that exhibit causal ambiguity and assess the ability of active
sampling techniques to reduce causal confusion at evaluation. We provide
empirical evidence that uniform and active sampling techniques are able to
consistently reduce causal confusion as training progresses and that active
sampling is able to do so significantly more efficiently than uniform sampling.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17169" title="Abstract">arXiv:2312.17169</a> [<a href="/pdf/2312.17169" title="Download PDF">pdf</a>, <a href="/format/2312.17169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Code Reviewer Recommendation: Accuracy, Latency, Workload, and  Bystanders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigby%2C+P+C">Peter C. Rigby</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+S">Seth Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Saleem%2C+S">Sadruddin Saleem</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+P">Parth Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Suskin%2C+D">Daniel Suskin</a>, 
<a href="/search/cs?searchtype=author&query=Riggs%2C+P">Patrick Riggs</a>, 
<a href="/search/cs?searchtype=author&query=Maddila%2C+C">Chandra Maddila</a>, 
<a href="/search/cs?searchtype=author&query=Nagappan%2C+N">Nachiappan Nagappan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code review ensures that a peer engineer manually examines the code before it
is integrated and released into production. At Meta, we develop a wide range of
software at scale, from social networking to software development
infrastructure, such as calendar and meeting tools to continuous integration.
We are constantly improving our code review system, and in this work we
describe a series of experiments that were conducted across 10's of thousands
of engineers and 100's of thousands of reviews.
<br />We build upon the recommender that has been in production since 2018,
RevRecV1. We found that reviewers were being assigned based on prior authorship
of files. We reviewed the literature for successful features and experimented
with them with RevRecV2 in production. The most important feature in our new
model was the familiarity of the author and reviewer, we saw an overall
improvement in accuracy of 14 percentage points.
<br />Prior research has shown that reviewer workload is skewed. To balance
workload, we divide the reviewer score from RevRecV2 by each candidate
reviewers workload. We experimented with multiple types of workload to develop
RevRecWL. We find that reranking candidate reviewers by workload often leads to
a reviewers with lower workload being selected by authors.
<br />The bystander effect can occur when a team of reviewers is assigned the
review. We mitigate the bystander effect by randomly assigning one of the
recommended reviewers. Having an individual who is responsible for the review,
reduces the time take for reviews by -11%.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17172" title="Abstract">arXiv:2312.17172</a> [<a href="/pdf/2312.17172" title="Download PDF">pdf</a>, <a href="/format/2312.17172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,  Language, Audio, and Action
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiasen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+C">Christopher Clark</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+S">Savya Khosla</a>, 
<a href="/search/cs?searchtype=author&query=Marten%2C+R">Ryan Marten</a>, 
<a href="/search/cs?searchtype=author&query=Hoiem%2C+D">Derek Hoiem</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We present Unified-IO 2, the first autoregressive multimodal model that is
capable of understanding and generating image, text, audio, and action. To
unify different modalities, we tokenize inputs and outputs -- images, text,
audio, action, bounding boxes, etc., into a shared semantic space and then
process them with a single encoder-decoder transformer model. Since training
with such diverse modalities is challenging, we propose various architectural
improvements to stabilize model training. We train our model from scratch on a
large multimodal pre-training corpus from diverse sources with a multimodal
mixture of denoisers objective. To learn an expansive set of skills, such as
following multimodal instructions, we construct and finetune on an ensemble of
120 datasets with prompts and augmentations. With a single unified model,
Unified-IO 2 achieves state-of-the-art performance on the GRIT benchmark and
strong results in more than 35 benchmarks, including image generation and
understanding, natural language understanding, video and audio understanding,
and robotic manipulation. We release all our models to the research community.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17174" title="Abstract">arXiv:2312.17174</a> [<a href="/pdf/2312.17174" title="Download PDF">pdf</a>, <a href="/format/2312.17174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Explanations of Image-Text Representations via Multi-Modal  Information Bottleneck Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Advances in Neural Information Processing Systems 36 (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision-language pretrained models have seen remarkable success, but their
application to safety-critical settings is limited by their lack of
interpretability. To improve the interpretability of vision-language models
such as CLIP, we propose a multi-modal information bottleneck (M2IB) approach
that learns latent representations that compress irrelevant information while
preserving relevant visual and textual features. We demonstrate how M2IB can be
applied to attribution analysis of vision-language pretrained models,
increasing attribution accuracy and improving the interpretability of such
models when applied to safety-critical domains such as healthcare. Crucially,
unlike commonly used unimodal attribution methods, M2IB does not require ground
truth labels, making it possible to audit representations of vision-language
pretrained models when multiple modalities but no ground-truth data is
available. Using CLIP as an example, we demonstrate the effectiveness of M2IB
attribution and show that it outperforms gradient-based, perturbation-based,
and attention-based attribution methods both qualitatively and quantitatively.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17179" title="Abstract">arXiv:2312.17179</a> [<a href="/pdf/2312.17179" title="Download PDF">pdf</a>, <a href="/format/2312.17179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Going Green in RAN Slicing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phyu%2C+H+P">Hnin Pann Phyu</a>, 
<a href="/search/cs?searchtype=author&query=Stanica%2C+R">Razvan Stanica</a>, 
<a href="/search/cs?searchtype=author&query=Naboulsi%2C+D">Diala Naboulsi</a>, 
<a href="/search/cs?searchtype=author&query=Poitau%2C+G">Gwenael Poitau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Network slicing is essential for transforming future telecommunication
networks into versatile service platforms, but it also presents challenges for
sustainable network operations. While meeting the requirements of network
slices incurs additional energy consumption compared to non-sliced networks,
operators strive to offer diverse 5G and beyond services while maintaining
energy efficiency. In this study, we address the issue of slice
activation/deactivation to reduce energy consumption while maintaining the user
quality of service (QoS). We employ Deep Contextual Multi-Armed Bandit and
Thompson Sampling Contextual Multi-Armed Bandit agents to make
activation/deactivation decisions for individual clusters. Evaluations are
performed using the NetMob23 dataset, which captures the spatio-temporal
consumption of various mobile services in France. Our simulation results
demonstrate that our proposed solutions provide significant reductions in
network energy consumption while ensuring the QoS remains at a similar level
compared to a scenario where all slice instances are active.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17180" title="Abstract">arXiv:2312.17180</a> [<a href="/pdf/2312.17180" title="Download PDF">pdf</a>, <a href="/format/2312.17180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Scientific Companion for Synchrotron Beamlines: A Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potemkin%2C+D">Daniel Potemkin</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+C">Carlos Soto</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruipeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yager%2C+K">Kevin Yager</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+E">Esther Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The extraordinarily high X-ray flux and specialized instrumentation at
synchrotron beamlines have enabled versatile in-situ and high throughput
studies that are impossible elsewhere. Dexterous and efficient control of
experiments are thus crucial for efficient beamline operation. Artificial
intelligence and machine learning methods are constantly being developed to
enhance facility performance, but the full potential of these developments can
only be reached with efficient human-computer-interaction. Natural language is
the most intuitive and efficient way for humans to communicate. However, the
low credibility and reproducibility of existing large language models and tools
demand extensive development to be made for robust and reliable performance for
scientific purposes. In this work, we introduce the prototype of virtual
scientific companion (VISION) and demonstrate that it is possible to control
basic beamline operations through natural language with open-source language
model and the limited computational resources at beamline. The human-AI nature
of VISION leverages existing automation systems and data framework at
synchrotron beamlines.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17181" title="Abstract">arXiv:2312.17181</a> [<a href="/pdf/2312.17181" title="Download PDF">pdf</a>, <a href="/format/2312.17181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Guidance for the Deployment of Elastic Geodesic Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillwein%2C+S">Stefan Pillwein</a>, 
<a href="/search/cs?searchtype=author&query=Hentschel%2C+A">Alexander Hentschel</a>, 
<a href="/search/cs?searchtype=author&query=Lukacevic%2C+M">Markus Lukacevic</a>, 
<a href="/search/cs?searchtype=author&query=Musialski%2C+P">Przemyslaw Musialski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> journal preprint, 10 pages including appendix, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Elastic gridshells are advanced free-form structures enabling curved target
shapes and material-efficient large spans. This paper focuses on a novel type
of gridshells recently proposed employing a scissor-like deployment mechanism.
While recent form-finding advancements have produced fascinating outcomes, a
significant challenge arises when architecturally implementing such mechanisms:
for the realization of real-world structures, professional FEA is necessary.
However, performing Finite Element simulations of these structures proves
surprisingly complex due to the requirement of simulating the deployment -- a
task nearly unachievable using uninformed approaches. Therefore, geometric
guidance of the highly elastic gridshells while simulating the expansion is
essential. Present solutions to this predicament primarily involve rudimentary
trial-and-error methods, suitable only for the most basic shapes. We propose a
solution involving the provision of geometric guidance via sequences of linear
displacements synchronized with a universal time parameter. When applied to
chosen positions, this allows for multi-step gridshell deployment and
successfully avoids undesirable buckling issues. We conclude with successful
demonstrations of our method, anticipating our work to pave the way for further
quantitative explorations of these intriguing structures.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17192" title="Abstract">arXiv:2312.17192</a> [<a href="/pdf/2312.17192" title="Download PDF">pdf</a>, <a href="/format/2312.17192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HISR: Hybrid Implicit Surface Representation for Photorealistic 3D Human  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Angtian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanlu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sarafianos%2C+N">Nikolaos Sarafianos</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+R">Robert Maier</a>, 
<a href="/search/cs?searchtype=author&query=Boyer%2C+E">Edmond Boyer</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+T">Tony Tung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 main track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural reconstruction and rendering strategies have demonstrated
state-of-the-art performances due, in part, to their ability to preserve high
level shape details. Existing approaches, however, either represent objects as
implicit surface functions or neural volumes and still struggle to recover
shapes with heterogeneous materials, in particular human skin, hair or clothes.
To this aim, we present a new hybrid implicit surface representation to model
human shapes. This representation is composed of two surface layers that
represent opaque and translucent regions on the clothed human body. We segment
different regions automatically using visual cues and learn to reconstruct two
signed distance functions (SDFs). We perform surface-based rendering on opaque
regions (e.g., body, face, clothes) to preserve high-fidelity surface normals
and volume rendering on translucent regions (e.g., hair). Experiments
demonstrate that our approach obtains state-of-the-art results on 3D human
reconstructions, and also shows competitive performances on other objects.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17197" title="Abstract">arXiv:2312.17197</a> [<a href="/pdf/2312.17197" title="Download PDF">pdf</a>, <a href="/ps/2312.17197" title="Download PostScript">ps</a>, <a href="/format/2312.17197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Research Landscape of Decentralized Autonomous  Organizations: A Research Note and Agenda
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+C">Christian Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=DuPont%2C+Q">Quinn DuPont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This note and agenda serve as a cause for thought for scholars interested in
researching Decentralized Autonomous Organizations (DAOs), addressing both the
opportunities and challenges posed by this phenomenon. It covers key aspects of
data retrieval, data selection criteria, issues in data reliability and
validity such as governance token pricing complexities, discrepancy in
treasuries, Mainnet and Testnet data, understanding the variety of DAO types
and proposal categories, airdrops affecting governance, and the Sybil problem.
The agenda aims to equip scholars with the essential knowledge required to
conduct nuanced and rigorous academic studies on DAOs by illuminating these
various aspects and proposing directions for future research.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17205" title="Abstract">arXiv:2312.17205</a> [<a href="/pdf/2312.17205" title="Download PDF">pdf</a>, <a href="/format/2312.17205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EFHQ: Multi-purpose ExtremePose-Face-HQ dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dao%2C+T+T">Trung Tuan Dao</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D+H">Duc Hong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The existing facial datasets, while having plentiful images at near frontal
views, lack images with extreme head poses, leading to the downgraded
performance of deep learning models when dealing with profile or pitched faces.
This work aims to address this gap by introducing a novel dataset named Extreme
Pose Face High-Quality Dataset (EFHQ), which includes a maximum of 450k
high-quality images of faces at extreme poses. To produce such a massive
dataset, we utilize a novel and meticulous dataset processing pipeline to
curate two publicly available datasets, VFHQ and CelebV-HQ, which contain many
high-resolution face videos captured in various settings. Our dataset can
complement existing datasets on various facial-related tasks, such as facial
synthesis with 2D/3D-aware GAN, diffusion-based text-to-image face generation,
and face reenactment. Specifically, training with EFHQ helps models generalize
well across diverse poses, significantly improving performance in scenarios
involving extreme views, confirmed by extensive experiments. Additionally, we
utilize EFHQ to define a challenging cross-view face verification benchmark, in
which the performance of SOTA face recognition models drops 5-37\% compared to
frontal-to-frontal scenarios, aiming to stimulate studies on face recognition
under severe pose conditions in the wild.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17215" title="Abstract">arXiv:2312.17215</a> [<a href="/pdf/2312.17215" title="Download PDF">pdf</a>, <a href="/format/2312.17215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Barrier Function Based UAV Safety Controller in Autonomous  Airborne Tracking and Following Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panja%2C+P">Promit Panja</a>, 
<a href="/search/cs?searchtype=author&query=Hoagg%2C+J+B">Jesse B. Hoagg</a>, 
<a href="/search/cs?searchtype=author&query=Baidya%2C+S">Sabur Baidya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Safe operations of UAVs are of paramount importance for various
mission-critical and safety-critical UAV applications. In context of airborne
target tracking and following, UAVs need to track a flying target avoiding
collision and also closely follow its trajectory. The safety situation becomes
critical and more complex when the flying target is non-cooperative and has
erratic movements. This paper proposes a method for collision avoidance in an
autonomous fast moving dynamic quadrotor UAV tracking and following another
target UAV. This is achieved by designing a safety controller that minimally
modifies the control input from a trajectory tracking controller and guarantees
safety. This method enables pairing our proposed safety controller with already
existing flight controllers. Our safety controller uses a control barrier
function based quadratic program (CBF-QP) to produce an optimal control input
enabling safe operation while also follow the trajectory of the target closely.
We implement our solution on AirSim simulator over PX4 flight controller and
with numerical results, we validate our approach through several simulation
experiments with multiple scenarios and trajectories.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17220" title="Abstract">arXiv:2312.17220</a> [<a href="/pdf/2312.17220" title="Download PDF">pdf</a>, <a href="/format/2312.17220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timeliness: A New Design Metric and a New Attack Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaswan%2C+P">Priyanka Kaswan</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">As the landscape of time-sensitive applications gains prominence in 5G/6G
communications, timeliness of information updates at network nodes has become
crucial, which is popularly quantified in the literature by the age of
information metric. However, as we devise policies to improve age of
information of our systems, we inadvertently introduce a new vulnerability for
adversaries to exploit. In this article, we comprehensively discuss the diverse
threats that age-based systems are vulnerable to. We begin with discussion on
densely interconnected networks that employ gossiping between nodes to expedite
dissemination of dynamic information in the network, and show how the age-based
nature of gossiping renders these networks uniquely susceptible to threats such
as timestomping attacks, jamming attacks, and the propagation of
misinformation. Later, we survey adversarial works within simpler network
settings, specifically in one-hop and two-hop configurations, and delve into
adversarial robustness concerning challenges posed by jamming, timestomping,
and issues related to privacy leakage. We conclude this article with future
directions that aim to address challenges posed by more intelligent adversaries
and robustness of networks to them.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17221" title="Abstract">arXiv:2312.17221</a> [<a href="/pdf/2312.17221" title="Download PDF">pdf</a>, <a href="/ps/2312.17221" title="Download PostScript">ps</a>, <a href="/format/2312.17221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and automated Evaluation of Blue Team cyber posture in Cyber  Ranges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+F">Federica Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Bassetti%2C+E">Enrico Bassetti</a>, 
<a href="/search/cs?searchtype=author&query=Spognardi%2C+A">Angelo Spognardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cyber ranges are virtual training ranges that have emerged as indispensable
environments for conducting secure exercises and simulating real or
hypothetical scenarios. These complex computational infrastructures enable the
simulation of attacks, facilitating the evaluation of defense tools and
methodologies and developing novel countermeasures against threats. One of the
main challenges of cyber range scalability is the exercise evaluation that
often requires the manual intervention of human operators, the White team. This
paper proposes a novel approach that uses Blue and Red team reports and
well-known databases to automate the evaluation and assessment of the exercise
outcomes, overcoming the limitations of existing assessment models. Our
proposal encompasses evaluating various aspects and metrics, explicitly
emphasizing Blue Teams' actions and strategies and allowing the automated
generation of their cyber posture.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17223" title="Abstract">arXiv:2312.17223</a> [<a href="/pdf/2312.17223" title="Download PDF">pdf</a>, <a href="/format/2312.17223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity-Theoretic Implications of Multicalibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casacuberta%2C+S">S&#xed;lvia Casacuberta</a>, 
<a href="/search/cs?searchtype=author&query=Dwork%2C+C">Cynthia Dwork</a>, 
<a href="/search/cs?searchtype=author&query=Vadhan%2C+S">Salil Vadhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">We present connections between the recent literature on multigroup fairness
for prediction algorithms and classical results in computational complexity.
Multiaccurate predictors are correct in expectation on each member of an
arbitrary collection of pre-specified sets. Multicalibrated predictors satisfy
a stronger condition: they are calibrated on each set in the collection.
<br />Multiaccuracy is equivalent to a regularity notion for functions defined by
Trevisan, Tulsiani, and Vadhan (2009). They showed that, given a class $F$ of
(possibly simple) functions, an arbitrarily complex function $g$ can be
approximated by a low-complexity function $h$ that makes a small number of
oracle calls to members of $F$, where the notion of approximation requires that
$h$ cannot be distinguished from $g$ by members of $F$. This
complexity-theoretic Regularity Lemma is known to have implications in
different areas, including in complexity theory, additive number theory,
information theory, graph theory, and cryptography. Starting from the stronger
notion of multicalibration, we obtain stronger and more general versions of a
number of applications of the Regularity Lemma, including the Hardcore Lemma,
the Dense Model Theorem, and the equivalence of conditional pseudo-min-entropy
and unpredictability. For example, we show that every boolean function
(regardless of its hardness) has a small collection of disjoint hardcore sets,
where the sizes of those hardcore sets are related to how balanced the function
is on corresponding pieces of an efficient partition of the domain.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17225" title="Abstract">arXiv:2312.17225</a> [<a href="/pdf/2312.17225" title="Download PDF">pdf</a>, <a href="/format/2312.17225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuyang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vita-group.github.io/4DGen/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Aided by text-to-image and text-to-video diffusion models, existing 4D
content creation pipelines utilize score distillation sampling to optimize the
entire dynamic 3D scene. However, as these pipelines generate 4D content from
text or image inputs, they incur significant time and effort in prompt
engineering through trial and error. This work introduces 4DGen, a novel,
holistic framework for grounded 4D content creation that decomposes the 4D
generation task into multiple stages. We identify static 3D assets and
monocular video sequences as key components in constructing the 4D content. Our
pipeline facilitates conditional 4D generation, enabling users to specify
geometry (3D assets) and motion (monocular videos), thus offering superior
control over content creation. Furthermore, we construct our 4D representation
using dynamic 3D Gaussians, which permits efficient, high-resolution
supervision through rendering during training, thereby facilitating
high-quality 4D generation. Additionally, we employ spatial-temporal pseudo
labels on anchor frames, along with seamless consistency priors implemented
through 3D-aware score distillation sampling and smoothness regularizations.
Compared to existing baselines, our approach yields competitive results in
faithfully reconstructing input signals and realistically inferring renderings
from novel viewpoints and timesteps. Most importantly, our method supports
grounded generation, offering users enhanced control, a feature difficult to
achieve with previous methods. Project page:
https://vita-group.github.io/4DGen/
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17227" title="Abstract">arXiv:2312.17227</a> [<a href="/pdf/2312.17227" title="Download PDF">pdf</a>, <a href="/format/2312.17227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-based Planning with World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=V%2C+J+S">Jyothir S V</a>, 
<a href="/search/cs?searchtype=author&query=Jalagam%2C+S">Siddhartha Jalagam</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>, 
<a href="/search/cs?searchtype=author&query=Sobal%2C+V">Vlad Sobal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The enduring challenge in the field of artificial intelligence has been the
control of systems to achieve desired behaviours. While for systems governed by
straightforward dynamics equations, methods like Linear Quadratic Regulation
(LQR) have historically proven highly effective, most real-world tasks, which
require a general problem-solver, demand world models with dynamics that cannot
be easily described by simple equations. Consequently, these models must be
learned from data using neural networks. Most model predictive control (MPC)
algorithms designed for visual world models have traditionally explored
gradient-free population-based optimisation methods, such as Cross Entropy and
Model Predictive Path Integral (MPPI) for planning. However, we present an
exploration of a gradient-based alternative that fully leverages the
differentiability of the world model. In our study, we conduct a comparative
analysis between our method and other MPC-based alternatives, as well as
policy-based algorithms. In a sample-efficient setting, our method achieves on
par or superior performance compared to the alternative approaches in most
tasks. Additionally, we introduce a hybrid model that combines policy networks
and gradient-based MPC, which outperforms pure policy based methods thereby
holding promise for Gradient-based planning with world models in complex
real-world tasks.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17229" title="Abstract">arXiv:2312.17229</a> [<a href="/pdf/2312.17229" title="Download PDF">pdf</a>, <a href="/format/2312.17229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think Before You Duel: Understanding Complexities of Preference Learning  under Constrained Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deb%2C+R">Rohan Deb</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aadirupa Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of reward maximization in the dueling bandit setup
along with constraints on resource consumption. As in the classic dueling
bandits, at each round the learner has to choose a pair of items from a set of
$K$ items and observe a relative feedback for the current pair. Additionally,
for both items, the learner also observes a vector of resource consumptions.
The objective of the learner is to maximize the cumulative reward, while
ensuring that the total consumption of any resource is within the allocated
budget. We show that due to the relative nature of the feedback, the problem is
more difficult than its bandit counterpart and that without further assumptions
the problem is not learnable from a regret minimization perspective.
Thereafter, by exploiting assumptions on the available budget, we provide an
EXP3 based dueling algorithm that also considers the associated consumptions
and show that it achieves an
$\tilde{\mathcal{O}}\left({\frac{OPT^{(b)}}{B}}K^{1/3}T^{2/3}\right)$ regret,
where $OPT^{(b)}$ is the optimal value and $B$ is the available budget.
Finally, we provide numerical simulations to demonstrate the efficacy of our
proposed method.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17232" title="Abstract">arXiv:2312.17232</a> [<a href="/pdf/2312.17232" title="Download PDF">pdf</a>, <a href="/format/2312.17232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment3D: Learning Fine-Grained Class-Agnostic 3D Segmentation without  Manual Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Songyou Peng</a>, 
<a href="/search/cs?searchtype=author&query=Takmaz%2C+A">Ayca Takmaz</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Engelmann%2C+F">Francis Engelmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="http://segment3d.github.io">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current 3D scene segmentation methods are heavily dependent on manually
annotated 3D training datasets. Such manual annotations are labor-intensive,
and often lack fine-grained details. Importantly, models trained on this data
typically struggle to recognize object classes beyond the annotated classes,
i.e., they do not generalize well to unseen domains and require additional
domain-specific annotations. In contrast, 2D foundation models demonstrate
strong generalization and impressive zero-shot abilities, inspiring us to
incorporate these characteristics from 2D models into 3D models. Therefore, we
explore the use of image segmentation foundation models to automatically
generate training labels for 3D segmentation. We propose Segment3D, a method
for class-agnostic 3D scene segmentation that produces high-quality 3D
segmentation masks. It improves over existing 3D segmentation models
(especially on fine-grained masks), and enables easily adding new training data
to further boost the segmentation performance -- all without the need for
manual training labels.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17234" title="Abstract">arXiv:2312.17234</a> [<a href="/pdf/2312.17234" title="Download PDF">pdf</a>, <a href="/format/2312.17234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Restoration via Dual-Pivot Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chari%2C+P">Pradyumna Chari</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Sizhuo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ostashev%2C+D">Daniil Ostashev</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+G">Gurunandan Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative diffusion models can serve as a prior which ensures that solutions
of image restoration systems adhere to the manifold of natural images. However,
for restoring facial images, a personalized prior is necessary to accurately
represent and reconstruct unique facial features of a given individual. In this
paper, we propose a simple, yet effective, method for personalized restoration,
called Dual-Pivot Tuning - a two-stage approach that personalize a blind
restoration system while maintaining the integrity of the general prior and the
distinct role of each component. Our key observation is that for optimal
personalization, the generative model should be tuned around a fixed text
pivot, while the guiding network should be tuned in a generic
(non-personalized) manner, using the personalized generative model as a fixed
``pivot". This approach ensures that personalization does not interfere with
the restoration process, resulting in a natural appearance with high fidelity
to the person's identity and the attributes of the degraded image. We evaluated
our approach both qualitatively and quantitatively through extensive
experiments with images of widely recognized individuals, comparing it against
relevant baselines. Surprisingly, we found that our personalized prior not only
achieves higher fidelity to identity with respect to the person's identity, but
also outperforms state-of-the-art generic priors in terms of general image
quality. Project webpage: https://personalized-restoration.github.io
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17235" title="Abstract">arXiv:2312.17235</a> [<a href="/pdf/2312.17235" title="Download PDF">pdf</a>, <a href="/format/2312.17235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple LLM Framework for Long-Range Video Question-Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Taixi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md Mohaiminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shoubin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Bertasius%2C+G">Gedas Bertasius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present LLoVi, a language-based framework for long-range video
question-answering (LVQA). Unlike prior long-range video understanding methods,
which are often costly and require specialized long-range video modeling design
(e.g., memory queues, state-space layers, etc.), our approach uses a
frame/clip-level visual captioner (e.g., BLIP2, LaViLa, LLaVA) coupled with a
Large Language Model (GPT-3.5, GPT-4) leading to a simple yet surprisingly
effective LVQA framework. Specifically, we decompose short and long-range
modeling aspects of LVQA into two stages. First, we use a short-term visual
captioner to generate textual descriptions of short video clips (0.5-8s in
length) densely sampled from a long input video. Afterward, an LLM aggregates
the densely extracted short-term captions to perform long-range temporal
reasoning needed to understand the whole video and answer a question. To
analyze what makes our simple framework so effective, we thoroughly evaluate
various components of our system. Our empirical analysis reveals that the
choice of the visual captioner and LLM is critical for good LVQA performance.
Furthermore, we show that a specialized prompt that asks the LLM first to
summarize the noisy short-term visual captions and then answer a given input
question leads to a significant LVQA performance boost. On EgoSchema, which is
best known as a very long-form video question-answering benchmark, our method
achieves 50.3% accuracy, outperforming the previous best-performing approach by
18.1% (absolute gain). In addition, our approach outperforms the previous
state-of-the-art by 4.1% and 3.1% on NeXT-QA and IntentQA. We also extend LLoVi
to grounded LVQA and show that it outperforms all prior methods on the NeXT-GQA
dataset. We will release our code at https://github.com/CeeZh/LLoVi.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17236" title="Abstract">arXiv:2312.17236</a> [<a href="/pdf/2312.17236" title="Download PDF">pdf</a>, <a href="/format/2312.17236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factoring Expertise, Workload, and Turnover into Code Review  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajari%2C+F">Fahimeh Hajari</a>, 
<a href="/search/cs?searchtype=author&query=Malmir%2C+S">Samaneh Malmir</a>, 
<a href="/search/cs?searchtype=author&query=Mirsaeedi%2C+E">Ehsan Mirsaeedi</a>, 
<a href="/search/cs?searchtype=author&query=Rigby%2C+P+C">Peter C. Rigby</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Developer turnover is inevitable on software projects and leads to knowledge
loss, a reduction in productivity, and an increase in defects. Mitigation
strategies to deal with turnover tend to disrupt and increase workloads for
developers. In this work, we suggest that through code review recommendation we
can distribute knowledge and mitigate turnover while more evenly distributing
review workload.
<br />We conduct historical analyses to understand the natural concentration of
review workload and the degree of knowledge spreading that is inherent in code
review. Even though review workload is highly concentrated, we show that code
review natural spreads knowledge thereby reducing the files at risk to
turnover.
<br />Using simulation, we evaluate existing code review recommenders and develop
novel recommenders to understand their impact on the level of expertise during
review, the workload of reviewers, and the files at risk to turnover. Our
simulations use seeded random replacement of reviewers to allow us to compare
the reviewer recommenders without the confounding variation of different
reviewers being replaced for each recommender.
<br />Combining recommenders, we develop the SofiaWL recommender that suggests
experts with low active review workload when none of the files under review are
known by only one developer. In contrast, when knowledge is concentrated on one
developer, it sends the review to other reviewers to spread knowledge. For the
projects we study, we are able to globally increase expertise during reviews,
+3%, reduce workload concentration, -12%, and reduce the files at risk, -28%.
We make our scripts and data available in our replication package. Developers
can optimize for a particular outcome measure based on the needs of their
project, or use our GitHub bot to automatically balance the outcomes.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17238" title="Abstract">arXiv:2312.17238</a> [<a href="/pdf/2312.17238" title="Download PDF">pdf</a>, <a href="/format/2312.17238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Inference of Mixture-of-Experts Language Models with Offloading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eliseev%2C+A">Artyom Eliseev</a>, 
<a href="/search/cs?searchtype=author&query=Mazur%2C+D">Denis Mazur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">With the widespread adoption of Large Language Models (LLMs), many deep
learning practitioners are looking for strategies of running these models more
efficiently. One such strategy is to use sparse Mixture-of-Experts (MoE) - a
type of model architectures where only a fraction of model layers are active
for any given input. This property allows MoE-based language models to generate
tokens faster than their dense counterparts, but it also increases model size
due to having multiple experts. Unfortunately, this makes state-of-the-art MoE
language models difficult to run without high-end GPUs. In this work, we study
the problem of running large MoE language models on consumer hardware with
limited accelerator memory. We build upon parameter offloading algorithms and
propose a novel strategy that accelerates offloading by taking advantage of
innate properties of MoE LLMs. Using this strategy, we build can run
Mixtral-8x7B with mixed quantization on desktop hardware and free-tier Google
Colab instances.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17240" title="Abstract">arXiv:2312.17240</a> [<a href="/pdf/2312.17240" title="Download PDF">pdf</a>, <a href="/format/2312.17240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Baseline for Reasoning Segmentation with Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Senqiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+T">Tianyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+X">Xin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhuotao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bohao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While LISA effectively bridges the gap between segmentation and large
language models to enable reasoning segmentation, it poses certain limitations:
unable to distinguish different instances of the target region, and constrained
by the pre-defined textual response formats. In this work, we introduce LISA++,
an update to the existing LISA model, focusing on improving core
functionalities while keeping the base architecture intact. The main
enhancements in LISA++ include: \textbf{1) Enhanced Segmentation}: The instance
segmentation ability has been added, providing a more detailed scene analysis
along with the existing multi-region semantic segmentation. \textbf{2) More
Natural Conversation}: Improved capability for multi-turn dialogue, with the
ability to incorporate segmentation results directly into text responses, i.e.,
Segmentation in Dialogue (SiD). These improvements are achieved by curating the
existing samples of generic segmentation datasets, aimed specifically at
enhancing the segmentation and conversational skills without structural change
and additional data sources. Comparative analysis with the original LISA model
shows significant advancements in these areas, positioning LISA++ as a notable
upgrade in visual understanding and interaction. LISA++'s adaptability and
improved features highlight the versatility of the mask-as-embedding paradigm
proposed by LISA, and the potential as a foundational model for diverse
applications.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17241" title="Abstract">arXiv:2312.17241</a> [<a href="/pdf/2312.17241" title="Download PDF">pdf</a>, <a href="/format/2312.17241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Neural Graphics Primitives with Learned Hash Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takikawa%2C+T">Towaki Takikawa</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+T">Thomas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Nimier-David%2C+M">Merlin Nimier-David</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+A">Alex Evans</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+A">Alec Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+A">Alexander Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://research.nvidia.com/labs/toronto-ai/compact-ngp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural graphics primitives are faster and achieve higher quality when their
neural networks are augmented by spatial data structures that hold trainable
features arranged in a grid. However, existing feature grids either come with a
large memory footprint (dense or factorized grids, trees, and hash tables) or
slow performance (index learning and vector quantization). In this paper, we
show that a hash table with learned probes has neither disadvantage, resulting
in a favorable combination of size and speed. Inference is faster than unprobed
hash tables at equal quality while training is only 1.2-2.6x slower,
significantly outperforming prior index learning approaches. We arrive at this
formulation by casting all feature grids into a common framework: they each
correspond to a lookup function that indexes into a table of feature vectors.
In this framework, the lookup functions of existing data structures can be
combined by simple arithmetic combinations of their indices, resulting in
Pareto optimal compression and speed.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17242" title="Abstract">arXiv:2312.17242</a> [<a href="/pdf/2312.17242" title="Download PDF">pdf</a>, <a href="/format/2312.17242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Text in Arbitrary Writing Styles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aleem Khan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Andrew Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+S">Sophia Hager</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+N">Nicholas Andrews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Prior work in style-controlled text generation has focused on tasks such as
emulating the style of prolific literary authors, producing formal or informal
text, and the degree of toxicity of generated text. Plentiful demonstrations of
these styles are available, and as a result modern language models are often
able to emulate them, either via prompting or discriminative control. However,
in applications such as writing assistants, it is desirable for language models
to produce text in an author-specific style on the basis of a small writing
sample. We find that instruction-tuned language models can struggle to
reproduce author-specific style demonstrated in a prompt. Instead, we propose
to guide a language model to generate text in a target style using
contrastively-trained representations that capture stylometric features. A
central challenge in doing so is that an author's writing is characterized by
surprising token choices under a generic language model. To reconcile this
tension, we combine generative re-scoring to achieve an author-specific model,
with discriminative control to ensure style consistency at the sequence-level.
The combination of these approaches is found to be particularly effective at
adhering to an author-specific style in a variety of conditions, including
unconditional generation and style transfer, and is applicable to any
underlying language model without requiring fine-tuning.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17243" title="Abstract">arXiv:2312.17243</a> [<a href="/pdf/2312.17243" title="Download PDF">pdf</a>, <a href="/format/2312.17243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Universal Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+D">Dantong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xinyang Han</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+L">Long Lian</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+R">Roei Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Several unsupervised image segmentation approaches have been proposed which
eliminate the need for dense manually-annotated segmentation masks; current
models separately handle either semantic segmentation (e.g., STEGO) or
class-agnostic instance segmentation (e.g., CutLER), but not both (i.e.,
panoptic segmentation). We propose an Unsupervised Universal Segmentation model
(U2Seg) adept at performing various image segmentation tasks -- instance,
semantic and panoptic -- using a novel unified framework. U2Seg generates
pseudo semantic labels for these segmentation tasks via leveraging
self-supervised models followed by clustering; each cluster represents
different semantic and/or instance membership of pixels. We then self-train the
model on these pseudo semantic labels, yielding substantial performance gains
over specialized methods tailored to each task: a +2.6 AP$^{\text{box}}$ boost
vs. CutLER in unsupervised instance segmentation on COCO and a +7.0 PixelAcc
increase (vs. STEGO) in unsupervised semantic segmentation on COCOStuff.
Moreover, our method sets up a new baseline for unsupervised panoptic
segmentation, which has not been previously explored. U2Seg is also a strong
pretrained model for few-shot segmentation, surpassing CutLER by +5.0
AP$^{\text{mask}}$ when trained on a low-data regime, e.g., only 1% COCO
labels. We hope our simple yet effective method can inspire more research on
unsupervised universal image segmentation.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17244" title="Abstract">arXiv:2312.17244</a> [<a href="/pdf/2312.17244" title="Download PDF">pdf</a>, <a href="/format/2312.17244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The LLM Surgeon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Ouderaa%2C+T+F+A">Tycho F.A. van der Ouderaa</a>, 
<a href="/search/cs?searchtype=author&query=Nagel%2C+M">Markus Nagel</a>, 
<a href="/search/cs?searchtype=author&query=van+Baalen%2C+M">Mart van Baalen</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>, 
<a href="/search/cs?searchtype=author&query=Blankevoort%2C+T">Tijmen Blankevoort</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">State-of-the-art language models are becoming increasingly large in an effort
to achieve the highest performance on large corpora of available textual data.
However, the sheer size of the Transformer architectures makes it difficult to
deploy models within computational, environmental or device-specific
constraints. We explore data-driven compression of existing pretrained models
as an alternative to training smaller models from scratch. To do so, we scale
Kronecker-factored curvature approximations of the target loss landscape to
large language models. In doing so, we can compute both the dynamic allocation
of structures that can be removed as well as updates of remaining weights that
account for the removal. We provide a general framework for unstructured,
semi-structured and structured pruning and improve upon weight updates to
capture more correlations between weights, while remaining computationally
efficient. Experimentally, our method can prune rows and columns from a range
of OPT models and Llamav2-7B by 20%-30%, with a negligible loss in performance,
and achieve state-of-the-art results in unstructured and semi-structured
pruning of large language models.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17247" title="Abstract">arXiv:2312.17247</a> [<a href="/pdf/2312.17247" title="Download PDF">pdf</a>, <a href="/format/2312.17247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amodal Ground Truth and Completion in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+G">Guanqi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanxia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The problem we study in this paper is amodal image segmentation: predicting
entire object segmentation masks including both visible and invisible
(occluded) parts. In previous work, the amodal segmentation ground truth on
real images is usually predicted by manual annotaton and thus is subjective. In
contrast, we use 3D data to establish an automatic pipeline to determine
authentic ground truth amodal masks for partially occluded objects in real
images. This pipeline is used to construct an amodal completion evaluation
benchmark, MP3D-Amodal, consisting of a variety of object categories and
labels. To better handle the amodal completion task in the wild, we explore two
architecture variants: a two-stage model that first infers the occluder,
followed by amodal mask completion; and a one-stage model that exploits the
representation power of Stable Diffusion for amodal segmentation across many
categories. Without bells and whistles, our method achieves a new
state-of-the-art performance on Amodal segmentation datasets that cover a large
variety of objects, including COCOA and our new MP3D-Amodal dataset. The
dataset, model, and code are available at
https://www.robots.ox.ac.uk/~vgg/research/amodal/.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17248" title="Abstract">arXiv:2312.17248</a> [<a href="/pdf/2312.17248" title="Download PDF">pdf</a>, <a href="/format/2312.17248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Model-based, Policy-based, and Value-based Reinforcement  Learning via the Lens of Representation Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Guhao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Reinforcement Learning (RL) encompasses diverse paradigms, including
model-based RL, policy-based RL, and value-based RL, each tailored to
approximate the model, optimal policy, and optimal value function,
respectively. This work investigates the potential hierarchy of representation
complexity -- the complexity of functions to be represented -- among these RL
paradigms. We first demonstrate that, for a broad class of Markov decision
processes (MDPs), the model can be represented by constant-depth circuits with
polynomial size or Multi-Layer Perceptrons (MLPs) with constant layers and
polynomial hidden dimension. However, the representation of the optimal policy
and optimal value proves to be $\mathsf{NP}$-complete and unattainable by
constant-layer MLPs with polynomial size. This demonstrates a significant
representation complexity gap between model-based RL and model-free RL, which
includes policy-based RL and value-based RL. To further explore the
representation complexity hierarchy between policy-based RL and value-based RL,
we introduce another general class of MDPs where both the model and optimal
policy can be represented by constant-depth circuits with polynomial size or
constant-layer MLPs with polynomial size. In contrast, representing the optimal
value is $\mathsf{P}$-complete and intractable via a constant-layer MLP with
polynomial hidden dimension. This accentuates the intricate representation
complexity associated with value-based RL compared to policy-based RL. In
summary, we unveil a potential representation complexity hierarchy within RL --
representing the model emerges as the easiest task, followed by the optimal
policy, while representing the optimal value function presents the most
intricate challenge.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17249" title="Abstract">arXiv:2312.17249</a> [<a href="/pdf/2312.17249" title="Download PDF">pdf</a>, <a href="/format/2312.17249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Androids Know They&#x27;re Only Dreaming of Electric Sheep?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=CH-Wang%2C+S">Sky CH-Wang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>, 
<a href="/search/cs?searchtype=author&query=Kedzie%2C+C">Chris Kedzie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We design probes trained on the internal representations of a transformer
language model that are predictive of its hallucinatory behavior on in-context
generation tasks. To facilitate this detection, we create a span-annotated
dataset of organic and synthetic hallucinations over several tasks. We find
that probes trained on the force-decoded states of synthetic hallucinations are
generally ecologically invalid in organic hallucination detection. Furthermore,
hidden state information about hallucination appears to be task and
distribution-dependent. Intrinsic and extrinsic hallucination saliency varies
across layers, hidden state types, and tasks; notably, extrinsic hallucinations
tend to be more salient in a transformer's internal representations.
Outperforming multiple contemporary baselines, we show that probing is a
feasible and efficient alternative to language model hallucination evaluation
when model states are available.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17250" title="Abstract">arXiv:2312.17250</a> [<a href="/pdf/2312.17250" title="Download PDF">pdf</a>, <a href="/format/2312.17250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iFusion: Inverting Diffusion for Pose-Free Reconstruction from Sparse  Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chin-Hsuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Solarte%2C+B">Bolivar Solarte</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/chinhsuanwu/ifusion">this https URL</a>, Project page: <a href="https://chinhsuanwu.github.io/ifusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present iFusion, a novel 3D object reconstruction framework that requires
only two views with unknown camera poses. While single-view reconstruction
yields visually appealing results, it can deviate significantly from the actual
object, especially on unseen sides. Additional views improve reconstruction
fidelity but necessitate known camera poses. However, assuming the availability
of pose may be unrealistic, and existing pose estimators fail in sparse view
scenarios. To address this, we harness a pre-trained novel view synthesis
diffusion model, which embeds implicit knowledge about the geometry and
appearance of diverse objects. Our strategy unfolds in three steps: (1) We
invert the diffusion model for camera pose estimation instead of synthesizing
novel views. (2) The diffusion model is fine-tuned using provided views and
estimated poses, turned into a novel view synthesizer tailored for the target
object. (3) Leveraging registered views and the fine-tuned diffusion model, we
reconstruct the 3D object. Experiments demonstrate strong performance in both
pose estimation and novel view synthesis. Moreover, iFusion seamlessly
integrates with various reconstruction methods and enhances them.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 29 Dec 23</h3>
<dl>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16190" title="Abstract">arXiv:2312.16190</a> (cross-list from q-fin.ST) [<a href="/pdf/2312.16190" title="Download PDF">pdf</a>, <a href="/ps/2312.16190" title="Download PostScript">ps</a>, <a href="/format/2312.16190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hawkes-based cryptocurrency forecasting via Limit Order Book data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Cestari%2C+R+G">Raffaele Giuseppe Cestari</a>, 
<a href="/search/q-fin?searchtype=author&query=Barchi%2C+F">Filippo Barchi</a>, 
<a href="/search/q-fin?searchtype=author&query=Busetto%2C+R">Riccardo Busetto</a>, 
<a href="/search/q-fin?searchtype=author&query=Marazzina%2C+D">Daniele Marazzina</a>, 
<a href="/search/q-fin?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurately forecasting the direction of financial returns poses a formidable
challenge, given the inherent unpredictability of financial time series. The
task becomes even more arduous when applied to cryptocurrency returns, given
the chaotic and intricately complex nature of crypto markets. In this study, we
present a novel prediction algorithm using limit order book (LOB) data rooted
in the Hawkes model, a category of point processes. Coupled with a continuous
output error (COE) model, our approach offers a precise forecast of return
signs by leveraging predictions of future financial interactions. Capitalizing
on the non-uniformly sampled structure of the original time series, our
strategy surpasses benchmark models in both prediction accuracy and cumulative
profit when implemented in a trading environment. The efficacy of our approach
is validated through Monte Carlo simulations across 50 scenarios. The research
draws on LOB measurements from a centralized cryptocurrency exchange where the
stablecoin Tether is exchanged against the U.S. dollar.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16223" title="Abstract">arXiv:2312.16223</a> (cross-list from q-fin.ST) [<a href="/pdf/2312.16223" title="Download PDF">pdf</a>, <a href="/format/2312.16223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Increasing Profitability and Confidence by using Interpretable Model for  Investment Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Arshad%2C+S">Sahar Arshad</a>, 
<a href="/search/q-fin?searchtype=author&query=Latif%2C+S">Seemab Latif</a>, 
<a href="/search/q-fin?searchtype=author&query=Salman%2C+A">Ahmad Salman</a>, 
<a href="/search/q-fin?searchtype=author&query=Irfan%2C+S">Saadia Irfan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Financial forecasting plays an important role in making informed decisions
for financial stakeholders, specifically in the stock exchange market. In a
traditional setting, investors commonly rely on the equity research department
for valuable reports on market insights and investment recommendations. The
equity research department, however, faces challenges in effectuating
decision-making due to the demanding cognitive effort required for analyzing
the inherently volatile nature of market dynamics. Furthermore, financial
forecasting systems employed by analysts pose potential risks in terms of
interpretability and gaining the trust of all stakeholders. This paper presents
an interpretable decision-making model leveraging the SHAP-based explainability
technique to forecast investment recommendations. The proposed solution not
only provides valuable insights into the factors that influence forecasted
recommendations but also caters to investors of varying types, including those
interested in daily and short-term investment opportunities. To ascertain the
efficacy of the proposed model, a case study is devised that demonstrates a
notable enhancement in investor's portfolio value, employing our trading
strategies. The results highlight the significance of incorporating
interpretability in forecasting models to boost stakeholders' confidence and
foster transparency in the stock exchange domain.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16232" title="Abstract">arXiv:2312.16232</a> (cross-list from quant-ph) [<a href="/pdf/2312.16232" title="Download PDF">pdf</a>, <a href="/format/2312.16232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Methods for Quantum Spin Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Goodacre%2C+D">Danny Goodacre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This report is concerned with the efficiency of numerical methods for
simulating quantum spin systems, with the aim to implement an improved method
for simulation of a time-dependent Hamiltonian that displays chirped pulses at
a high frequency.
<br />Working in the density matrix formulation of quantum systems, we study
evolution under the Liouville-von Neumann equation, presenting analysis of and
benchmarking current numerical methods. The accuracy of existing techniques is
assessed in the presence of chirped pulses.
<br />We also discuss the Magnus expansion and detail how a truncation of it is
used to solve differential equations. The results of this work are implemented
in the Python package MagPy to provide a better error-to-cost ratio than
current approaches allow for time-dependent Hamiltonians.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16307" title="Abstract">arXiv:2312.16307</a> (cross-list from econ.EM) [<a href="/pdf/2312.16307" title="Download PDF">pdf</a>, <a href="/format/2312.16307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive-Aware Synthetic Control: Accurate Counterfactual Estimation  via Incentivized Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ngo%2C+D">Daniel Ngo</a>, 
<a href="/search/econ?searchtype=author&query=Harris%2C+K">Keegan Harris</a>, 
<a href="/search/econ?searchtype=author&query=Agarwal%2C+A">Anish Agarwal</a>, 
<a href="/search/econ?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>, 
<a href="/search/econ?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We consider a panel data setting in which one observes measurements of units
over time, under different interventions. Our focus is on the canonical family
of synthetic control methods (SCMs) which, after a pre-intervention time period
when all units are under control, estimate counterfactual outcomes for test
units in the post-intervention time period under control by using data from
donor units who have remained under control for the entire post-intervention
period. In order for the counterfactual estimate produced by synthetic control
for a test unit to be accurate, there must be sufficient overlap between the
outcomes of the donor units and the outcomes of the test unit. As a result, a
canonical assumption in the literature on SCMs is that the outcomes for the
test units lie within either the convex hull or the linear span of the outcomes
for the donor units. However despite their ubiquity, such overlap assumptions
may not always hold, as is the case when, e.g., units select their own
interventions and different subpopulations of units prefer different
interventions a priori.
<br />We shed light on this typically overlooked assumption, and we address this
issue by incentivizing units with different preferences to take interventions
they would not normally consider. Specifically, we provide a SCM for
incentivizing exploration in panel data settings which provides
incentive-compatible intervention recommendations to units by leveraging tools
from information design and online learning. Using our algorithm, we show how
to obtain valid counterfactual estimates using SCMs without the need for an
explicit overlap assumption on the unit outcomes.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16318" title="Abstract">arXiv:2312.16318</a> (cross-list from quant-ph) [<a href="/pdf/2312.16318" title="Download PDF">pdf</a>, <a href="/format/2312.16318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Secure Protocols for Multiparty Computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mohanty%2C+T">Tapaswini Mohanty</a>, 
<a href="/search/quant-ph?searchtype=author&query=Srivastava%2C+V">Vikas Srivastava</a>, 
<a href="/search/quant-ph?searchtype=author&query=Debnath%2C+S+K">Sumit Kumar Debnath</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stanica%2C+P">Pantelimon Stanica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Secure multiparty computation (MPC) schemes allow two or more parties to
conjointly compute a function on their private input sets while revealing
nothing but the output. Existing state-of-the-art number-theoretic-based
designs face the threat of attacks through quantum algorithms. In this context,
we present secure MPC protocols that can withstand quantum attacks. We first
present the design and analysis of an information-theoretic secure oblivious
linear evaluation (OLE), namely ${\sf qOLE}$ in the quantum domain, and show
that our ${\sf qOLE}$ is safe from external attacks. In addition, our scheme
satisfies all the security requirements of a secure OLE. We further utilize
${\sf qOLE}$ as a building block to construct a quantum-safe multiparty private
set intersection (MPSI) protocol.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16331" title="Abstract">arXiv:2312.16331</a> (cross-list from eess.IV) [<a href="/pdf/2312.16331" title="Download PDF">pdf</a>, <a href="/format/2312.16331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early and Accurate Detection of Tomato Leaf Diseases Using TomFormer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khan%2C+A">Asim Khan</a>, 
<a href="/search/eess?searchtype=author&query=Nawaz%2C+U">Umair Nawaz</a>, 
<a href="/search/eess?searchtype=author&query=Kshetrimayum%2C+L">Lochan Kshetrimayum</a>, 
<a href="/search/eess?searchtype=author&query=Seneviratne%2C+L">Lakmal Seneviratne</a>, 
<a href="/search/eess?searchtype=author&query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Figures and 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Tomato leaf diseases pose a significant challenge for tomato farmers,
resulting in substantial reductions in crop productivity. The timely and
precise identification of tomato leaf diseases is crucial for successfully
implementing disease management strategies. This paper introduces a
transformer-based model called TomFormer for the purpose of tomato leaf disease
detection. The paper's primary contributions include the following: Firstly, we
present a novel approach for detecting tomato leaf diseases by employing a
fusion model that combines a visual transformer and a convolutional neural
network. Secondly, we aim to apply our proposed methodology to the Hello
Stretch robot to achieve real-time diagnosis of tomato leaf diseases. Thirdly,
we assessed our method by comparing it to models like YOLOS, DETR, ViT, and
Swin, demonstrating its ability to achieve state-of-the-art outcomes. For the
purpose of the experiment, we used three datasets of tomato leaf diseases,
namely KUTomaDATA, PlantDoc, and PlanVillage, where KUTomaDATA is being
collected from a greenhouse in Abu Dhabi, UAE. Finally, we present a
comprehensive analysis of the performance of our model and thoroughly discuss
the limitations inherent in our approach. TomFormer performed well on the
KUTomaDATA, PlantDoc, and PlantVillage datasets, with mean average accuracy
(mAP) scores of 87%, 81%, and 83%, respectively. The comparative results in
terms of mAP demonstrate that our method exhibits robustness, accuracy,
efficiency, and scalability. Furthermore, it can be readily adapted to new
datasets. We are confident that our work holds the potential to significantly
influence the tomato industry by effectively mitigating crop losses and
enhancing crop yields.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16341" title="Abstract">arXiv:2312.16341</a> (cross-list from stat.ML) [<a href="/pdf/2312.16341" title="Download PDF">pdf</a>, <a href="/format/2312.16341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Federated Learning in Federated Contextual  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shi%2C+C">Chengshuai Shi</a>, 
<a href="/search/stat?searchtype=author&query=Zhou%2C+R">Ruida Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+C">Cong Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version appeared in the Multi-Agent Security Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Federated learning (FL) has demonstrated great potential in revolutionizing
distributed machine learning, and tremendous efforts have been made to extend
it beyond the original focus on supervised learning. Among many directions,
federated contextual bandits (FCB), a pivotal integration of FL and sequential
decision-making, has garnered significant attention in recent years. Despite
substantial progress, existing FCB approaches have largely employed their
tailored FL components, often deviating from the canonical FL framework.
Consequently, even renowned algorithms like FedAvg remain under-utilized in
FCB, let alone other FL advancements. Motivated by this disconnection, this
work takes one step towards building a tighter relationship between the
canonical FL study and the investigations on FCB. In particular, a novel FCB
design, termed FedIGW, is proposed to leverage a regression-based CB algorithm,
i.e., inverse gap weighting. Compared with existing FCB approaches, the
proposed FedIGW design can better harness the entire spectrum of FL
innovations, which is concretely reflected as (1) flexible incorporation of
(both existing and forthcoming) FL protocols; (2) modularized plug-in of FL
analyses in performance guarantees; (3) seamless integration of FL appendages
(such as personalization, robustness, and privacy). We substantiate these
claims through rigorous theoretical analyses and empirical evaluations.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16422" title="Abstract">arXiv:2312.16422</a> (cross-list from eess.AS) [<a href="/pdf/2312.16422" title="Download PDF">pdf</a>, <a href="/format/2312.16422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective-Memory Meta-Learning with Environment Representations for  Sound Event Localization and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+J">Jinbo Hu</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yin Cao</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+M">Ming Wu</a>, 
<a href="/search/eess?searchtype=author&query=Kong%2C+Q">Qiuqiang Kong</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+F">Feiran Yang</a>, 
<a href="/search/eess?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jun Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Environment shifts and conflicts present significant challenges for
learning-based sound event localization and detection (SELD) methods. SELD
systems, when trained in particular acoustic settings, often show restricted
generalization capabilities for diverse acoustic environments. Furthermore, it
is notably costly to obtain annotated samples for spatial sound events.
Deploying a SELD system in a new environment requires extensive time for
re-training and fine-tuning. To overcome these challenges, we propose
environment-adaptive Meta-SELD, designed for efficient adaptation to new
environments using minimal data. Our method specifically utilizes
computationally synthesized spatial data and employs Model-Agnostic
Meta-Learning (MAML) on a pre-trained, environment-independent model. The
method then utilizes fast adaptation to unseen real-world environments using
limited samples from the respective environments. Inspired by the
Learning-to-Forget approach, we introduce the concept of selective memory as a
strategy for resolving conflicts across environments. This approach involves
selectively memorizing target-environment-relevant information and adapting to
the new environments through the selective attenuation of model parameters. In
addition, we introduce environment representations to characterize different
acoustic settings, enhancing the adaptability of our attenuation approach to
various environments. We evaluate our proposed method on the development set of
the Sony-TAU Realistic Spatial Soundscapes 2023 (STARSS23) dataset and
computationally synthesized scenes. Experimental results demonstrate the
superior performance of the proposed method compared to conventional supervised
learning methods, particularly in localization.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16448" title="Abstract">arXiv:2312.16448</a> (cross-list from q-fin.PM) [<a href="/pdf/2312.16448" title="Download PDF">pdf</a>, <a href="/format/2312.16448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Signature Methods in Optimal Portfolio Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Akyildirim%2C+E">Erdinc Akyildirim</a>, 
<a href="/search/q-fin?searchtype=author&query=Gambara%2C+M">Matteo Gambara</a>, 
<a href="/search/q-fin?searchtype=author&query=Teichmann%2C+J">Josef Teichmann</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhou%2C+S">Syang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Pricing of Securities (q-fin.PR)

</div>
<p class="mathjax">We present convincing empirical results on the application of Randomized
Signature Methods for non-linear, non-parametric drift estimation for a
multi-variate financial market. Even though drift estimation is notoriously ill
defined due to small signal to noise ratio, one can still try to learn optimal
non-linear maps from data to future returns for the purposes of portfolio
optimization. Randomized Signatures, in contrast to classical signatures, allow
for high dimensional market dimension and provide features on the same scale.
We do not contribute to the theory of Randomized Signatures here, but rather
present our empirical findings on portfolio selection in real world settings
including real market data and transaction costs.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16449" title="Abstract">arXiv:2312.16449</a> (cross-list from eess.AS) [<a href="/pdf/2312.16449" title="Download PDF">pdf</a>, <a href="/ps/2312.16449" title="Download PostScript">ps</a>, <a href="/format/2312.16449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Similarity-and-Independence-Aware Beamformer for Low-latency  Target Sound Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hiroe%2C+A">Atsuo Hiroe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Open Journal of Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">This study describes an online target sound extraction (TSE) process, derived
from the iterative batch algorithm using the similarity-and-independence-aware
beamformer (SIBF), to achieve both latency reduction and extraction accuracy
maintenance. The SIBF is a linear method that estimates the target more
accurately compared with a reference, an approximate magnitude spectrogram of
the target. Evidently, deriving the online algorithm from the iterative batch
algorithm reduces the latency of the SIBF; however, this process presents two
challenges: 1) the derivation may degrade the accuracy, and 2) the conventional
post-process, meant for scaling the estimated target, may increase the accuracy
gap between the two algorithms. To maintain the best possible accuracy, herein,
an approach that minimizes this gap during post-processing is adopted, and a
novel scaling method based on the single-channel Wiener filter (SWF-based
scaling) is proposed. To improve the accuracy further, the
time-frequency-varying variance generalized Gaussian (TV GG) distribution is
employed as a source model to represent the joint probability between the
target and reference. Thus, experiments using the CHiME-3 dataset confirm that
1) the online algorithm reduces latency; 2) SWF-based scaling eliminates the
gap between the two algorithms while improving the accuracy; 3) TV GG model
achieves the best accuracy when it corresponds to the Laplacian model; and 4)
our online SIBF outperforms the conventional linear TSE, including the minimum
mean square error beamformer. These findings can contribute to the fields of
beamforming and blind source separation.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16455" title="Abstract">arXiv:2312.16455</a> (cross-list from eess.IV) [<a href="/pdf/2312.16455" title="Download PDF">pdf</a>, <a href="/format/2312.16455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn From Orientation Prior for Radiograph Super-Resolution:  Orientation Operator Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yongsong Huang</a>, 
<a href="/search/eess?searchtype=author&query=Miyazaki%2C+T">Tomo Miyazaki</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+K">Kaiyuan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Z">Zhengmi Tang</a>, 
<a href="/search/eess?searchtype=author&query=Omachi%2C+S">Shinichiro Omachi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Computer Methods and Programs in Biomedicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Background and objective: High-resolution radiographic images play a pivotal
role in the early diagnosis and treatment of skeletal muscle-related diseases.
It is promising to enhance image quality by introducing single-image
super-resolution (SISR) model into the radiology image field. However, the
conventional image pipeline, which can learn a mixed mapping between SR and
denoising from the color space and inter-pixel patterns, poses a particular
challenge for radiographic images with limited pattern features. To address
this issue, this paper introduces a novel approach: Orientation Operator
Transformer - $O^{2}$former. Methods: We incorporate an orientation operator in
the encoder to enhance sensitivity to denoising mapping and to integrate
orientation prior. Furthermore, we propose a multi-scale feature fusion
strategy to amalgamate features captured by different receptive fields with the
directional prior, thereby providing a more effective latent representation for
the decoder. Based on these innovative components, we propose a
transformer-based SISR model, i.e., $O^{2}$former, specifically designed for
radiographic images. Results: The experimental results demonstrate that our
method achieves the best or second-best performance in the objective metrics
compared with the competitors at $\times 4$ upsampling factor. For qualitative,
more objective details are observed to be recovered. Conclusions: In this
study, we propose a novel framework called $O^{2}$former for radiological image
super-resolution tasks, which improves the reconstruction model's performance
by introducing an orientation operator and multi-scale feature fusion strategy.
Our approach is promising to further promote the radiographic image enhancement
field.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16471" title="Abstract">arXiv:2312.16471</a> (cross-list from eess.IV) [<a href="/pdf/2312.16471" title="Download PDF">pdf</a>, <a href="/ps/2312.16471" title="Download PostScript">ps</a>, <a href="/format/2312.16471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Super Resolution for video Enhancement Using GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maity%2C+A">Ankush Maity</a>, 
<a href="/search/eess?searchtype=author&query=Pious%2C+R">Roshan Pious</a>, 
<a href="/search/eess?searchtype=author&query=Lenka%2C+S+K">Sourabh Kumar Lenka</a>, 
<a href="/search/eess?searchtype=author&query=Choudhary%2C+V">Vishal Choudhary</a>, 
<a href="/search/eess?searchtype=author&query=Lokande%2C+P+S">Prof.Sharyau Lokande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">This compilation of various research paper highlights provides a
comprehensive overview of recent developments in super-resolution image and
video using deep learning algorithms such as Generative Adversarial Networks.
The studies covered in these summaries provide fresh techniques to addressing
the issues of improving image and video quality, such as recursive learning for
video super-resolution, novel loss functions, frame-rate enhancement, and
attention model integration. These approaches are frequently evaluated using
criteria such as PSNR, SSIM, and perceptual indices. These advancements, which
aim to increase the visual clarity and quality of low-resolution video, have
tremendous potential in a variety of sectors ranging from surveillance
technology to medical imaging. In addition, this collection delves into the
wider field of Generative Adversarial Networks, exploring their principles,
training approaches, and applications across a broad range of domains, while
also emphasizing the challenges and opportunities for future research in this
rapidly advancing and changing field of artificial intelligence.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16512" title="Abstract">arXiv:2312.16512</a> (cross-list from stat.ME) [<a href="/pdf/2312.16512" title="Download PDF">pdf</a>, <a href="/format/2312.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degrees-of-freedom penalized piecewise regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Volz%2C+S">Stefan Volz</a>, 
<a href="/search/stat?searchtype=author&query=Storath%2C+M">Martin Storath</a>, 
<a href="/search/stat?searchtype=author&query=Weinmann%2C+A">Andreas Weinmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 11 figures, submitted to "Information and Inference: a Journal of the IMA"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Many popular piecewise regression models rely on minimizing a cost function
on the model fit with a linear penalty on the number of segments. However, this
penalty does not take into account varying complexities of the model functions
on the segments potentially leading to overfitting when models with varying
complexities, such as polynomials of different degrees, are used. In this work,
we enhance on this approach by instead using a penalty on the sum of the
degrees of freedom over all segments, called degrees-of-freedom penalized
piecewise regression (DofPPR). We show that the solutions of the resulting
minimization problem are unique for almost all input data in a least squares
setting. We develop a fast algorithm which does not only compute a minimizer
but also determines an optimal hyperparameter -- in the sense of rolling cross
validation with the one standard error rule -- exactly. This eliminates manual
hyperparameter selection. Our method supports optional user parameters for
incorporating domain knowledge. We provide an open-source Python/Rust code for
the piecewise polynomial least squares case which can be extended to further
models. We demonstrate the practical utility through a simulation study and by
applications to real data. A constrained variant of the proposed method gives
state-of-the-art results in the Turing benchmark for unsupervised changepoint
detection.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16519" title="Abstract">arXiv:2312.16519</a> (cross-list from eess.IV) [<a href="/pdf/2312.16519" title="Download PDF">pdf</a>, <a href="/format/2312.16519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Restoration by Denoising Diffusion Models with Iteratively  Preconditioned Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Garber%2C+T">Tomer Garber</a>, 
<a href="/search/eess?searchtype=author&query=Tirer%2C+T">Tom Tirer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code can be found at: <a href="https://github.com/tirer-lab/DDPG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Training deep neural networks has become a common approach for addressing
image restoration problems. An alternative for training a "task-specific"
network for each observation model is to use pretrained deep denoisers for
imposing only the signal's prior within iterative algorithms, without
additional training. Recently, a sampling-based variant of this approach has
become popular with the rise of diffusion/score-based generative models. Using
denoisers for general purpose restoration requires guiding the iterations to
ensure agreement of the signal with the observations. In low-noise settings,
guidance that is based on back-projection (BP) has been shown to be a promising
strategy (used recently also under the names "pseudoinverse" or
"range/null-space" guidance). However, the presence of noise in the
observations hinders the gains from this approach. In this paper, we propose a
novel guidance technique, based on preconditioning that allows traversing from
BP-based guidance to least squares based guidance along the restoration scheme.
The proposed approach is robust to noise while still having much simpler
implementation than alternative methods (e.g., it does not require SVD or a
large number of iterations). We use it within both an optimization scheme and a
sampling-based scheme, and demonstrate its advantages over existing methods for
image deblurring and super-resolution.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16531" title="Abstract">arXiv:2312.16531</a> (cross-list from stat.ML) [<a href="/pdf/2312.16531" title="Download PDF">pdf</a>, <a href="/ps/2312.16531" title="Download PostScript">ps</a>, <a href="/format/2312.16531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fl RDT based ultimate lowering of the negative spherical perceptron  capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.00073">arXiv:2312.00073</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">We consider the classical \emph{spherical} perceptrons and study their
capacities. The famous zero-threshold case was solved in the sixties of the
last century (see, \cite{Wendel62,Winder,Cover65}) through the high-dimensional
combinatorial considerations. The general threshold, $\kappa$, case though
turned out to be much harder and stayed out of reach for the following several
decades. A substantial progress was then made in \cite{SchTir02} and
\cite{StojnicGardGen13} where the \emph{positive} threshold ($\kappa\geq 0$)
scenario was finally fully settled. While the negative counterpart ($\kappa\leq
0$) remained out of reach, \cite{StojnicGardGen13} did show that the random
duality theory (RDT) is still powerful enough to provide excellent upper
bounds. Moreover, in \cite{StojnicGardSphNeg13}, a \emph{partially lifted} RDT
variant was considered and it was shown that the upper bounds of
\cite{StojnicGardGen13} can be lowered. After recent breakthroughs in studying
bilinearly indexed (bli) random processes in
\cite{Stojnicsflgscompyx23,Stojnicnflgscompyx23}, \emph{fully lifted} random
duality theory (fl RDT) was developed in \cite{Stojnicflrdt23}. We here first
show that the \emph{negative spherical perceptrons} can be fitted into the
frame of the fl RDT and then employ the whole fl RDT machinery to characterize
the capacity. To be fully practically operational, the fl RDT requires a
substantial numerical work. We, however, uncover remarkable closed form
analytical relations among key lifting parameters. Such a discovery enables
performing the needed numerical calculations to obtain concrete capacity
values. We also observe that an excellent convergence (with the relative
improvement $\sim 0.1\%$) is achieved already on the third (second non-trivial)
level of the \emph{stationarized} full lifting.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16557" title="Abstract">arXiv:2312.16557</a> (cross-list from stat.ML) [<a href="/pdf/2312.16557" title="Download PDF">pdf</a>, <a href="/format/2312.16557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint empirical risk minimization for instance-dependent  positive-unlabeled data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rejchel%2C+W">Wojciech Rejchel</a>, 
<a href="/search/stat?searchtype=author&query=Teisseyre%2C+P">Pawe&#x142; Teisseyre</a>, 
<a href="/search/stat?searchtype=author&query=Mielniczuk%2C+J">Jan Mielniczuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning from positive and unlabeled data (PU learning) is actively
researched machine learning task. The goal is to train a binary classification
model based on a training dataset containing part of positives which are
labeled, and unlabeled instances. Unlabeled set includes remaining part of
positives and all negative observations. An important element in PU learning is
modeling of the labeling mechanism, i.e. labels' assignment to positive
observations. Unlike in many prior works, we consider a realistic setting for
which probability of label assignment, i.e. propensity score, is
instance-dependent. In our approach we investigate minimizer of an empirical
counterpart of a joint risk which depends on both posterior probability of
inclusion in a positive class as well as on a propensity score. The non-convex
empirical risk is alternately optimised with respect to parameters of both
functions. In the theoretical analysis we establish risk consistency of the
minimisers using recently derived methods from the theory of empirical
processes. Besides, the important development here is a proposed novel
implementation of an optimisation algorithm, for which sequential approximation
of a set of positive observations among unlabeled ones is crucial. This relies
on modified technique of 'spies' as well as on a thresholding rule based on
conditional probabilities. Experiments conducted on 20 data sets for various
labeling scenarios show that the proposed method works on par or more
effectively than state-of-the-art methods based on propensity function
estimation.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16569" title="Abstract">arXiv:2312.16569</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.16569" title="Download PDF">pdf</a>, <a href="/format/2312.16569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citizen science for social physics: Digital tools and participation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Perell%C3%B3%2C+J">J. Perell&#xf3;</a>, 
<a href="/search/physics?searchtype=author&query=Larroya%2C+F">F. Larroya</a>, 
<a href="/search/physics?searchtype=author&query=Bonhoure%2C+I">I. Bonhoure</a>, 
<a href="/search/physics?searchtype=author&query=Peter%2C+F">F. Peter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Social physics is an active and diverse field in which many scientists with
formal training in physics study a broad class of complex social phenomena.
Social physics investigates societal problems but most often does not count on
the active and conscious participation of the citizens. We here want to support
the idea that citizen science, and more particularly citizen social science,
can contribute to the broad field of social physics. We do so by sharing some
of our own experiences during the last decade. We first describe several human
mobility experiments in urban contexts with the participation of concerned
young students, old women or other different groups of neighbours. We second
share how we have studied community mental health care provision in
collaboration with a civil society organisation and with the intense
involvement of persons with lived experience in mental health. In both cases,
we narrow down the discussion to digital tools being used and the involved
participatory dynamics. In this way, we share key learnings to enhance a
synergistic relationship between social physics and citizen science and with
the aim increase the societal impact of the research on complex social
phenomena.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16576" title="Abstract">arXiv:2312.16576</a> (cross-list from math.OA) [<a href="/pdf/2312.16576" title="Download PDF">pdf</a>, <a href="/format/2312.16576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative Entropy for Quantum Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+Z">Zishuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operator Algebras (math.OA)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph); Functional Analysis (math.FA)

</div>
<p class="mathjax">We introduce an quantum entropy for bimodule quantum channels on finite von
Neumann algebras, generalizing the remarkable Pimsner-Popa entropy. The
relative entropy for Fourier multipliers of bimodule quantum channels
establishes an upper bound of the quantum entropy. Additionally, we present the
Araki relative entropy for bimodule quantum channels, revealing its equivalence
to the relative entropy for Fourier multipliers and demonstrating its
left/right monotonicities and convexity. Notably, the quantum entropy attains
its maximum if there is a downward Jones basic construction. By considering
R\'{e}nyi entropy for Fourier multipliers, we find a continuous bridge between
the logarithm of the Pimsner-Popa index and the Pimsner-Popa entropy. As a
consequence, the R\'{e}nyi entropy at $1/2$ serves a criterion for the
existence of a downward Jones basic construction.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16600" title="Abstract">arXiv:2312.16600</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.16600" title="Download PDF">pdf</a>, <a href="/format/2312.16600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> scRNA-seq Data Clustering by Cluster-aware Iterative Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+W">Weikang Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+J">Jinxian Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Guan%2C+J">Jihong Guan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+S">Shuigeng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Single-cell RNA sequencing (scRNA-seq) enables researchers to analyze gene
expression at single-cell level. One important task in scRNA-seq data analysis
is unsupervised clustering, which helps identify distinct cell types, laying
down the foundation for other downstream analysis tasks. In this paper, we
propose a novel method called Cluster-aware Iterative Contrastive Learning
(CICL in short) for scRNA-seq data clustering, which utilizes an iterative
representation learning and clustering framework to progressively learn the
clustering structure of scRNA-seq data with a cluster-aware contrastive loss.
CICL consists of a Transformer encoder, a clustering head, a projection head
and a contrastive loss module. First, CICL extracts the feature vectors of the
original and augmented data by the Transformer encoder. Then, it computes the
clustering centroids by K-means and employs the student t-distribution to
assign pseudo-labels to all cells in the clustering head. The projection-head
uses a Multi-Layer Perceptron (MLP) to obtain projections of the augmented
data. At last, both pseudo-labels and projections are used in the contrastive
loss to guide the model training. Such a process goes iteratively so that the
clustering result becomes better and better. Extensive experiments on 25 real
world scRNA-seq datasets show that CICL outperforms the SOTA methods.
Concretely, CICL surpasses the existing methods by from 14% to 280%, and from
5% to 133% on average in terms of performance metrics ARI and NMI respectively.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16607" title="Abstract">arXiv:2312.16607</a> (cross-list from eess.IV) [<a href="/pdf/2312.16607" title="Download PDF">pdf</a>, <a href="/format/2312.16607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Polarization and Radiomics Feature Fusion Network for the  Classification of Hepatocellular Carcinoma and Intrahepatic  Cholangiocarcinoma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dong%2C+J">Jia Dong</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Liyan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+Y">Yang Dong</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+J">Jiachen Wan</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+R">Ran Peng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+H">Hui Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Classifying hepatocellular carcinoma (HCC) and intrahepatic
cholangiocarcinoma (ICC) is a critical step in treatment selection and
prognosis evaluation for patients with liver diseases. Traditional
histopathological diagnosis poses challenges in this context. In this study, we
introduce a novel polarization and radiomics feature fusion network, which
combines polarization features obtained from Mueller matrix images of liver
pathological samples with radiomics features derived from corresponding
pathological images to classify HCC and ICC. Our fusion network integrates a
two-tier fusion approach, comprising early feature-level fusion and late
classification-level fusion. By harnessing the strengths of polarization
imaging techniques and image feature-based machine learning, our proposed
fusion network significantly enhances classification accuracy. Notably, even at
reduced imaging resolutions, the fusion network maintains robust performance
due to the additional information provided by polarization features, which may
not align with human visual perception. Our experimental results underscore the
potential of this fusion network as a powerful tool for computer-aided
diagnosis of HCC and ICC, showcasing the benefits and prospects of integrating
polarization imaging techniques into the current image-intensive digital
pathological diagnosis. We aim to contribute this innovative approach to
top-tier journals, offering fresh insights and valuable tools in the fields of
medical imaging and cancer diagnosis. By introducing polarization imaging into
liver cancer classification, we demonstrate its interdisciplinary potential in
addressing challenges in medical image analysis, promising advancements in
medical imaging and cancer diagnosis.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16624" title="Abstract">arXiv:2312.16624</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.16624" title="Download PDF">pdf</a>, <a href="/format/2312.16624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOSA-MO: Dual-stage Optimizer for Systematic overestimation Adjustment  in Multi-Objective problems improves biomarker discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Cattelani%2C+L">Luca Cattelani</a>, 
<a href="/search/q-bio?searchtype=author&query=Fortino%2C+V">Vittorio Fortino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The challenge in biomarker discovery and validation using machine learning
from omics data lies in the abundance of molecular features but scarcity of
samples. Most machine learning-based feature selection methods necessitate of
hyperparameter tuning, typically performed by evaluating numerous alternatives
on a validation set. Every evaluation has a performance estimation error and
when the selection takes place between many models the best ones are almost
certainly overestimated. Biomarker identification is a typical multi-objective
problem with trade-offs between the predictive ability and the parsimony in the
number of molecular features. Genetic algorithms are a popular tool for
multi-objective optimization but they evolve numerous solutions and are prone
to overestimation. Methods have been proposed to reduce the overestimation
after a model has already been selected in single-objective problems, but to
the best of our knowledge no algorithm existed that was capable of reducing the
overestimation during the optimization, leading to a better model selection, or
that had been applied in the more general domain of multi-objective problems.
We propose DOSA-MO, a novel multi-objective optimization wrapper algorithm that
learns how the original estimation, its variance, and the feature set size of
the solutions predict the overestimation, and adjusts the expectation of the
performance during the optimization, improving the composition of the solution
set. We verify that DOSA-MO improves the performance of a state-of-the-art
genetic algorithm on left-out or external sample sets, when predicting cancer
subtypes and/or patient overall survival, using three transcriptomics datasets
for kidney and breast cancer.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16636" title="Abstract">arXiv:2312.16636</a> (cross-list from math.OC) [<a href="/pdf/2312.16636" title="Download PDF">pdf</a>, <a href="/format/2312.16636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Boundary Stabilization of Stochastic Hyperbolic PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yihuai Zhang</a>, 
<a href="/search/math?searchtype=author&query=Auriol%2C+J">Jean Auriol</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+H">Huan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.15547">arXiv:2310.15547</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">This paper proposes a backstepping boundary control design for robust
stabilization of linear first-order coupled hyperbolic partial differential
equations (PDEs) with Markov-jumping parameters. The PDE system consists of 4 X
4 coupled hyperbolic PDEs whose first three characteristic speeds are positive
and the last one is negative. We first design a full-state feedback boundary
control law for a nominal, deterministic system using the backstepping method.
Then, by applying Lyapunov analysis methods, we prove that the nominal
backstepping control law can stabilize the PDE system with Markov jumping
parameters if the nominal parameters are sufficiently close to the stochastic
ones on average. The mean-square exponential stability conditions are
theoretically derived and then validated via numerical simulations.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16644" title="Abstract">arXiv:2312.16644</a> (cross-list from math.OC) [<a href="/pdf/2312.16644" title="Download PDF">pdf</a>, <a href="/format/2312.16644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact asymptotic order for generalised adaptive approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kesseb%C3%B6hmer%2C+M">Marc Kesseb&#xf6;hmer</a>, 
<a href="/search/math?searchtype=author&query=Niemann%2C+A">Aljoscha Niemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures. arXiv admin note: text overlap with <a href="/abs/2202.05247">arXiv:2202.05247</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT); Functional Analysis (math.FA); Probability (math.PR)

</div>
<p class="mathjax">In this note, we present an abstract approach to study asymptotic orders for
adaptive approximations with respect to a monotone set function $\mathfrak{J}$
defined on dyadic cubes. We determine the exact upper order in terms of the
critical value of the corresponding $\mathfrak{J}$-partition function, and we
are able to provide upper and lower bounds in term of fractal-geometric
quantities. With properly chosen $\mathfrak{J}$, our new approach has
applications in many different areas of mathematics, including the spectral
theory of Krein-Feller operators, quantization dimensions of compactly
supported probability measures, and the exact asymptotic order for Kolmogorov,
Gelfand and linear widths for Sobolev embeddings into $L_{\mu}^p$-spaces.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16657" title="Abstract">arXiv:2312.16657</a> (cross-list from math.NT) [<a href="/pdf/2312.16657" title="Download PDF">pdf</a>, <a href="/format/2312.16657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a finite sum of cosecants appearing in various problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blagouchine%2C+I+V">Iaroslav V. Blagouchine</a>, 
<a href="/search/math?searchtype=author&query=Moreau%2C+E">Eric Moreau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Classical Analysis and ODEs (math.CA); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper we investigate the finite sum of cosecants
$\sum\csc\big(\varphi+a\pi l/n\big),$ where the index $l$ runs through 1 to
$n-1$ and $\varphi$ and $a$ are arbitrary parameters, as well as several
closely related sums, such as similar sums of a series of secants, of tangents
and of cotangents. These trigonometric sums appear in various problems in
mathematics, physics, and a variety of related disciplines. Their particular
cases were fragmentarily considered in previous works, and it was noted that
even a simple particular case $\sum\csc\big(\pi l/n\big)$ does not have a
closed-form, i.e.~a compact summation formula. In the paper, we derive several
alternative representations for the above-mentioned sums, study their
properties, relate them to many other finite and infinite sums, obtain their
complete asymptotic expansions for large $n$ and provide accurate upper and
lower bounds (e.g. the typical relative error for the upper bound is lesser
than $2\times10^{-9}$ for $n\geqslant10$ and lesser than $7\times10^{-14}$ for
$n\geqslant50$, which is much better than the bounds we could find in previous
works). Our researches reveal that these sums are deeply related to several
special numbers and functions, especially to the digamma function (furthermore,
as a by-product, we obtain several interesting summations formulae for the
digamma function). Asymptotical studies show that these sums may have
qualitatively different behaviour depending on the choice of $\varphi$ and $a$;
in particular, as $n$ increases some of them may become sporadically large.
Finally, we also provide several historical remarks related to various sums
considered in the paper. We show that some results in the field either were
rediscovered several times or can easily be deduced from various known
formulae, including some formulae dating back to the XIIXth century.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16665" title="Abstract">arXiv:2312.16665</a> (cross-list from math.CO) [<a href="/pdf/2312.16665" title="Download PDF">pdf</a>, <a href="/ps/2312.16665" title="Download PostScript">ps</a>, <a href="/format/2312.16665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A small morphism giving Abelian repetition threshold less than 2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Currie%2C+J+D">James D. Currie</a>, 
<a href="/search/math?searchtype=author&query=Rampersad%2C+N">Narad Rampersad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">It is known that there are infinite words over finite alphabets with Abelian
repetition threshold arbitrarily close to 1; however, the construction
previously used involves huge alphabets. In this note we give a short cyclic
morphism (length 13) over an 8-letter alphabet yielding an Abelian repetition
threshold less than 1.8.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16672" title="Abstract">arXiv:2312.16672</a> (cross-list from math.RT) [<a href="/pdf/2312.16672" title="Download PDF">pdf</a>, <a href="/ps/2312.16672" title="Download PostScript">ps</a>, <a href="/format/2312.16672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Even grade generic skew-symmetric matrix polynomials with bounded rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=De+Ter%C3%A1n%2C+F">Fernando De Ter&#xe1;n</a>, 
<a href="/search/math?searchtype=author&query=Dmytryshyn%2C+A">Andrii Dmytryshyn</a>, 
<a href="/search/math?searchtype=author&query=Dopico%2C+F+M">Froil&#xe1;n M. Dopico</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. arXiv admin note: substantial text overlap with <a href="/abs/1703.05797">arXiv:1703.05797</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Representation Theory (math.RT)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We show that the set of $m \times m$ complex skew-symmetric matrix
polynomials of even grade $d$, i.e., of degree at most $d$, and (normal) rank
at most $2r$ is the closure of the single set of matrix polynomials with
certain, explicitly described, complete eigenstructure. This complete
eigenstructure corresponds to the most generic $m \times m$ complex
skew-symmetric matrix polynomials of even grade $d$ and rank at most $2r$. The
analogous problem for the case of skew-symmetric matrix polynomials of odd
grade is solved in [Linear Algebra Appl., 536:1-18, 2018].
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16699" title="Abstract">arXiv:2312.16699</a> (cross-list from math.OC) [<a href="/pdf/2312.16699" title="Download PDF">pdf</a>, <a href="/format/2312.16699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Tradeoffs of Optimization-Based Bound Tightening in ReLU  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Badilla%2C+F">Fabian Badilla</a>, 
<a href="/search/math?searchtype=author&query=Goycoolea%2C+M">Marcos Goycoolea</a>, 
<a href="/search/math?searchtype=author&query=Mu%C3%B1oz%2C+G">Gonzalo Mu&#xf1;oz</a>, 
<a href="/search/math?searchtype=author&query=Serra%2C+T">Thiago Serra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The use of Mixed-Integer Linear Programming (MILP) models to represent neural
networks with Rectified Linear Unit (ReLU) activations has become increasingly
widespread in the last decade. This has enabled the use of MILP technology to
test-or stress-their behavior, to adversarially improve their training, and to
embed them in optimization models leveraging their predictive power. Many of
these MILP models rely on activation bounds. That is, bounds on the input
values of each neuron. In this work, we explore the tradeoff between the
tightness of these bounds and the computational effort of solving the resulting
MILP models. We provide guidelines for implementing these models based on the
impact of network structure, regularization, and rounding.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16701" title="Abstract">arXiv:2312.16701</a> (cross-list from math-ph) [<a href="/pdf/2312.16701" title="Download PDF">pdf</a>, <a href="/format/2312.16701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integral formulation of Dirac singular waveguides
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Bal%2C+G">Guillaume Bal</a>, 
<a href="/search/math-ph?searchtype=author&query=Hoskins%2C+J">Jeremy Hoskins</a>, 
<a href="/search/math-ph?searchtype=author&query=Quinn%2C+S">Solomon Quinn</a>, 
<a href="/search/math-ph?searchtype=author&query=Rachh%2C+M">Manas Rachh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper concerns a boundary integral formulation for the two-dimensional
massive Dirac equation. The mass term is assumed to jump across a
one-dimensional interface, which models a transition between two insulating
materials. This jump induces surface waves that propagate outward along the
interface but decay exponentially in the transverse direction. After providing
a derivation of our integral equation, we prove that it has a unique solution
for almost all choices of parameters using holomorphic perturbation theory. We
then extend these results to a Dirac equation with two interfaces. Finally, we
implement a fast numerical method for solving our boundary integral equations
and present several numerical examples of solutions and scattering effects.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16707" title="Abstract">arXiv:2312.16707</a> (cross-list from econ.EM) [<a href="/pdf/2312.16707" title="Download PDF">pdf</a>, <a href="/format/2312.16707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Systemic Risk: A Time-Varying Nonparametric Causal Inference  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Etesami%2C+J">Jalal Etesami</a>, 
<a href="/search/econ?searchtype=author&query=Habibnia%2C+A">Ali Habibnia</a>, 
<a href="/search/econ?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Applications (stat.AP)

</div>
<p class="mathjax">We propose a nonparametric and time-varying directed information graph
(TV-DIG) framework to estimate the evolving causal structure in time series
networks, thereby addressing the limitations of traditional econometric models
in capturing high-dimensional, nonlinear, and time-varying interconnections
among series. This framework employs an information-theoretic measure rooted in
a generalized version of Granger-causality, which is applicable to both linear
and nonlinear dynamics. Our framework offers advancements in measuring systemic
risk and establishes meaningful connections with established econometric
models, including vector autoregression and switching models. We evaluate the
efficacy of our proposed model through simulation experiments and empirical
analysis, reporting promising results in recovering simulated time-varying
networks with nonlinear and multivariate structures. We apply this framework to
identify and monitor the evolution of interconnectedness and systemic risk
among major assets and industrial sectors within the financial network. We
focus on cryptocurrencies' potential systemic risks to financial stability,
including spillover effects on other sectors during crises like the COVID-19
pandemic and the Federal Reserve's 2020 emergency response. Our findings
reveals significant, previously underrecognized pre-2020 influences of
cryptocurrencies on certain financial sectors, highlighting their potential
systemic risks and offering a systematic approach in tracking evolving
cross-sector interactions within financial networks.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16712" title="Abstract">arXiv:2312.16712</a> (cross-list from math.OC) [<a href="/pdf/2312.16712" title="Download PDF">pdf</a>, <a href="/ps/2312.16712" title="Download PostScript">ps</a>, <a href="/format/2312.16712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Load Redistribution Attacks in Integrated Electricity-Gas  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+R">Rong-Peng Liu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaozhe Wang</a>, 
<a href="/search/math?searchtype=author&query=Zeng%2C+B">Bo Zeng</a>, 
<a href="/search/math?searchtype=author&query=Zgheib%2C+R">Rawad Zgheib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We investigate load redistribution (LR) attacks on integrated electricity-gas
systems (IEGSs) and proposes a bilevel mixed-integer model to identify the most
severe LR attack from an economic perspective. Under a mild assumption, we
prove that the proposed model does not exclude any possible upper-level attack.
A modified reformulation and decomposition (R&amp;D) algorithm is developed to
solve this model in a master-subproblem framework. Particularly, we design a
subproblem to address infeasibility issues in the master problem. Accordingly,
two types of cuts are added to the master problem for ensuring algorithm
feasibility and solution optimality.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16719" title="Abstract">arXiv:2312.16719</a> (cross-list from math.OC) [<a href="/pdf/2312.16719" title="Download PDF">pdf</a>, <a href="/ps/2312.16719" title="Download PostScript">ps</a>, <a href="/format/2312.16719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in the Theory of Control Barrier Functions: Addressing  Practical Challenges in Safe Control Synthesis for Autonomous and Robotic  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Garg%2C+K">Kunal Garg</a>, 
<a href="/search/math?searchtype=author&query=Usevitch%2C+J">James Usevitch</a>, 
<a href="/search/math?searchtype=author&query=Breeden%2C+J">Joseph Breeden</a>, 
<a href="/search/math?searchtype=author&query=Black%2C+M">Mitchell Black</a>, 
<a href="/search/math?searchtype=author&query=Agrawal%2C+D">Devansh Agrawal</a>, 
<a href="/search/math?searchtype=author&query=Parwana%2C+H">Hardik Parwana</a>, 
<a href="/search/math?searchtype=author&query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Annual Reviews in Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This tutorial paper presents recent work of the authors that extends the
theory of Control Barrier Functions (CBFs) to address practical challenges in
the synthesis of safe controllers for autonomous systems and robots. We present
novel CBFs and methods that handle safety constraints (i) with time and input
constraints under disturbances, (ii) with high-relative degree under
disturbances and input constraints, and (iii) that are affected by adversarial
inputs and sampled-data effects. We then present novel CBFs and adaptation
methods that prevent loss of validity of the CBF, as well as methods to tune
the parameters of the CBF online to reduce conservatism in the system response.
We also address the pointwise-only optimal character of CBF-induced control
inputs by introducing a CBF formulation that accounts for future trajectories,
as well as implementation challenges such as how to preserve safety when using
output feedback control and zero-order-hold control. Finally we consider how to
synthesize non-smooth CBFs when discontinuous inputs and multiple constraints
are present.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16752" title="Abstract">arXiv:2312.16752</a> (cross-list from math.OC) [<a href="/pdf/2312.16752" title="Download PDF">pdf</a>, <a href="/ps/2312.16752" title="Download PostScript">ps</a>, <a href="/format/2312.16752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relationships Between Necessary Conditions for Feedback Stabilizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kvalheim%2C+M+D">Matthew D. Kvalheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Algebraic Topology (math.AT); Differential Geometry (math.DG)

</div>
<p class="mathjax">The author's extensions of Brockett's and Coron's necessary conditions for
stabilizability are shown to be independent in the fiber bundle picture of
control, but the latter is stronger in the vector bundle picture if the state
space is orientable and the Cech-Euler characteristic of the set to be
stabilized is nonzero.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16762" title="Abstract">arXiv:2312.16762</a> (cross-list from math.OC) [<a href="/pdf/2312.16762" title="Download PDF">pdf</a>, <a href="/format/2312.16762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Operator Approximations of Backstepping Kernels for $2\times 2$  Hyperbolic PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>, 
<a href="/search/math?searchtype=author&query=Diagne%2C+M">Mamadou Diagne</a>, 
<a href="/search/math?searchtype=author&query=Krsti%C4%87%2C+M">Miroslav Krsti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Deep neural network approximation of nonlinear operators, commonly referred
to as DeepONet, has so far proven capable of approximating PDE backstepping
designs in which a single Goursat-form PDE governs a single feedback gain
function. In boundary control of coupled PDEs, coupled Goursat-form PDEs govern
two or more gain kernels - a PDE structure unaddressed thus far with DeepONet.
In this note we open the subject of approximating systems of gain kernel PDEs
for hyperbolic PDE plants by considering a simple counter-convecting $2\times
2$ coupled system in whose control a $2\times 2$ Goursat form kernel PDE system
arises. Such a coupled kernel PDE problem arises in several canonical $2\times
2$ hyperbolic PDE problems: oil drilling, Saint-Venant model of shallow water
waves, and Aw-Rascle model of stop-and-go instability in congested traffic
flow. In this paper, we establish the continuity of the mapping from (a total
of five) plant PDE functional coefficients to the kernel PDE solutions, prove
the existence of an arbitrarily close DeepONet approximation to the kernel
PDEs, and establish that the DeepONet-approximated gains guarantee
stabilization when replacing the exact backstepping gain kernels. The DeepONet
operator speeds the computation of the controller gains by multiple orders of
magnitude and its theoretically proven stabilizing capability is illustrated by
simulations.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16763" title="Abstract">arXiv:2312.16763</a> (cross-list from eess.AS) [<a href="/pdf/2312.16763" title="Download PDF">pdf</a>, <a href="/format/2312.16763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Machine Learning for Joint Speaker  Diarization and Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=McKnight%2C+S+W">Simon W. McKnight</a>, 
<a href="/search/eess?searchtype=author&query=Hogg%2C+A+O+T">Aidan O. T. Hogg</a>, 
<a href="/search/eess?searchtype=author&query=Neo%2C+V+W">Vincent W. Neo</a>, 
<a href="/search/eess?searchtype=author&query=Naylor%2C+P+A">Patrick A. Naylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">This paper studies modulation spectrum features ($\Phi$) and mel-frequency
cepstral coefficients ($\Psi$) in joint speaker diarization and identification
(JSID). JSID is important as speaker diarization on its own to distinguish
speakers is insufficient for many applications, it is often necessary to
identify speakers as well. Machine learning models are set up using
convolutional neural networks (CNNs) on $\Phi$ and recurrent neural networks
$\unicode{x2013}$ long short-term memory (LSTMs) on $\Psi$, then concatenating
into fully connected layers.
<br />Experiment 1 shows models on both $\Phi$ and $\Psi$ have better diarization
error rates (DERs) than models on either alone; a CNN on $\Phi$ has DER
29.09\%, compared to 27.78\% for a LSTM on $\Psi$ and 19.44\% for a model on
both. Experiment 1 also investigates aleatoric uncertainties and shows the
model on both $\Phi$ and $\Psi$ has mean entropy 0.927~bits (out of 4~bits) for
correct predictions compared to 1.896~bits for incorrect predictions which,
along with entropy histogram shapes, shows the model helpfully indicates where
it is uncertain.
<br />Experiment 2 investigates epistemic uncertainties as well as aleatoric using
Monte Carlo dropout (MCD). It compares models on both $\Phi$ and $\Psi$ with
models trained on x-vectors ($X$), before applying Kalman filter smoothing on
epistemic uncertainties for resegmentation and model ensembles. While the two
models on $X$ (DERs 10.23\% and 9.74\%) outperform those on $\Phi$ and $\Psi$
(DER 17.85\%) after their individual Kalman filter smoothing, combining them
using a Kalman filter smoothing method improves the DER to 9.29\%. Aleatoric
uncertainties are higher for incorrect predictions.
<br />Both Experiments show models on $\Phi$ do not distinguish overlapping
speakers as well as anticipated. However, Experiment 2 shows model ensembles do
better with overlapping speakers than individual models do.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16765" title="Abstract">arXiv:2312.16765</a> (cross-list from quant-ph) [<a href="/pdf/2312.16765" title="Download PDF">pdf</a>, <a href="/format/2312.16765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation algorithms for noncommutative constraint satisfaction  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Culf%2C+E">Eric Culf</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mousavi%2C+H">Hamoon Mousavi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Spirig%2C+T">Taro Spirig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 74 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We study operator - or noncommutative - variants of constraint satisfaction
problems (CSPs). These higher-dimensional variants are a core topic of
investigation in quantum information, where they arise as nonlocal games and
entangled multiprover interactive proof systems (MIP*). The idea of
higher-dimensional relaxations of CSPs is also important in the classical
literature. For example since the celebrated work of Goemans and Williamson on
Max-Cut, higher dimensional vector relaxations have been central in the design
of approximation algorithms for classical CSPs.
<br />We introduce a framework for designing approximation algorithms for
noncommutative CSPs. Prior to this work Max-$2$-Lin$(k)$ was the only family of
noncommutative CSPs known to be efficiently solvable. This work is the first to
establish approximation ratios for a broader class of noncommutative CSPs.
<br />In the study of classical CSPs, $k$-ary decision variables are often
represented by $k$-th roots of unity, which generalise to the noncommutative
setting as order-$k$ unitary operators. In our framework, using representation
theory, we develop a way of constructing unitary solutions from SDP
relaxations, extending the pioneering work of Tsirelson on XOR games. Then, we
introduce a novel rounding scheme to transform these solutions to order-$k$
unitaries. Our main technical innovation here is a theorem guaranteeing that,
for any set of unitary operators, there exists a set of order-$k$ unitaries
that closely mimics it. As an integral part of the rounding scheme, we prove a
random matrix theory result that characterises the distribution of the relative
angles between eigenvalues of random unitaries using tools from free
probability.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16772" title="Abstract">arXiv:2312.16772</a> (cross-list from eess.IV) [<a href="/pdf/2312.16772" title="Download PDF">pdf</a>, <a href="/format/2312.16772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupversied feature correlation model to predict breast abnormal  variation maps in longitudinal mammograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+J">Jun Bai</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+A">Annie Jin</a>, 
<a href="/search/eess?searchtype=author&query=Adams%2C+M">Madison Adams</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Clifford Yang</a>, 
<a href="/search/eess?searchtype=author&query=Nabavi%2C+S">Sheida Nabavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Breast cancer continues to be a significant cause of mortality among women
globally. Timely identification and precise diagnosis of breast abnormalities
are critical for enhancing patient prognosis. In this study, we focus on
improving the early detection and accurate diagnosis of breast abnormalities,
which is crucial for improving patient outcomes and reducing the mortality rate
of breast cancer. To address the limitations of traditional screening methods,
a novel unsupervised feature correlation network was developed to predict maps
indicating breast abnormal variations using longitudinal 2D mammograms. The
proposed model utilizes the reconstruction process of current year and prior
year mammograms to extract tissue from different areas and analyze the
differences between them to identify abnormal variations that may indicate the
presence of cancer. The model is equipped with a feature correlation module, an
attention suppression gate, and a breast abnormality detection module that work
together to improve the accuracy of the prediction. The proposed model not only
provides breast abnormal variation maps, but also distinguishes between normal
and cancer mammograms, making it more advanced compared to the state-of the-art
baseline models. The results of the study show that the proposed model
outperforms the baseline models in terms of Accuracy, Sensitivity, Specificity,
Dice score, and cancer detection rate.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16775" title="Abstract">arXiv:2312.16775</a> (cross-list from math.OC) [<a href="/pdf/2312.16775" title="Download PDF">pdf</a>, <a href="/ps/2312.16775" title="Download PostScript">ps</a>, <a href="/format/2312.16775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error bounds, PL condition, and quadratic growth for weakly convex  functions, and linear convergences of proximal point methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liao%2C+F">Feng-Yi Liao</a>, 
<a href="/search/math?searchtype=author&query=Ding%2C+L">Lijun Ding</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages and 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Many machine learning problems lack strong convexity properties. Fortunately,
recent studies have revealed that first-order algorithms also enjoy linear
convergences under various weaker regularity conditions. While the relationship
among different conditions for convex and smooth functions is well understood,
it is not the case for the nonsmooth setting. In this paper, we go beyond
convexity and smoothness, and clarify the connections among common regularity
conditions (including $\textit{strong convexity, restricted secant inequality,
subdifferential error bound, Polyak-{\L}ojasiewicz inequality, and quadratic
growth}$) in the class of weakly convex functions. In addition, we present a
simple and modular proof for the linear convergence of the $\textit{proximal
point method}$ (PPM) for convex (possibly nonsmooth) optimization using these
regularity conditions. The linear convergence also holds when the subproblems
of PPM are solved inexactly with a proper control of inexactness.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16789" title="Abstract">arXiv:2312.16789</a> (cross-list from econ.TH) [<a href="/pdf/2312.16789" title="Download PDF">pdf</a>, <a href="/ps/2312.16789" title="Download PostScript">ps</a>, <a href="/format/2312.16789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring with Rich Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Frick%2C+M">Mira Frick</a>, 
<a href="/search/econ?searchtype=author&query=Iijima%2C+R">Ryota Iijima</a>, 
<a href="/search/econ?searchtype=author&query=Ishii%2C+Y">Yuhta Ishii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We consider moral hazard problems where a principal has access to rich
monitoring data about an agent's action. Rather than focusing on optimal
contracts (which are known to in general be complicated), we characterize the
optimal rate at which the principal's payoffs can converge to the first-best
payoff as the amount of data grows large. Our main result suggests a novel
rationale for the widely observed binary wage schemes, by showing that such
simple contracts achieve the optimal convergence rate. Notably, in order to
attain the optimal convergence rate, the principal must set a lenient cutoff
for when the agent receives a high vs. low wage. In contrast, we find that
other common contracts where wages vary more finely with observed data (e.g.,
linear contracts) approximate the first-best at a highly suboptimal rate.
Finally, we show that the optimal convergence rate depends only on a simple
summary statistic of the monitoring technology. This yields a detail-free
ranking over monitoring technologies that quantifies their value for incentive
provision in data-rich settings and applies regardless of the agent's specific
utility or cost functions.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16815" title="Abstract">arXiv:2312.16815</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.16815" title="Download PDF">pdf</a>, <a href="/format/2312.16815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence and Causality in Complex Systems: A Survey on Causal Emergence  and Related Quantitative Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yuan%2C+B">Bing Yuan</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+Z">Zhang Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Lyu%2C+A">Aobo Lyu</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+J">Jiayun Wu</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+M">Mingzhe Yang</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+K">Kaiwei Liu</a>, 
<a href="/search/physics?searchtype=author&query=Mou%2C+M">Muyun Mou</a>, 
<a href="/search/physics?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages, 19 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">Emergence and causality are two fundamental concepts for understanding
complex systems. They are interconnected. On one hand, emergence refers to the
phenomenon where macroscopic properties cannot be solely attributed to the
cause of individual properties. On the other hand, causality can exhibit
emergence, meaning that new causal laws may arise as we increase the level of
abstraction. Causal emergence theory aims to bridge these two concepts and even
employs measures of causality to quantify emergence. This paper provides a
comprehensive review of recent advancements in quantitative theories and
applications of causal emergence. Two key problems are addressed: quantifying
causal emergence and identifying it in data. Addressing the latter requires the
use of machine learning techniques, thus establishing a connection between
causal emergence and artificial intelligence. We highlighted that the
architectures used for identifying causal emergence are shared by causal
representation learning, causal model abstraction, and world model-based
reinforcement learning. Consequently, progress in any of these areas can
benefit the others. Potential applications and future perspectives are also
discussed in the final section of the review.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16826" title="Abstract">arXiv:2312.16826</a> (cross-list from eess.AS) [<a href="/pdf/2312.16826" title="Download PDF">pdf</a>, <a href="/format/2312.16826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VOT: Revolutionizing Speaker Verification with Memory and Attention  Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Speaker verification is essentially the process of identifying unknown
speakers within an 'open set'. Our objective is to create optimal embeddings
that condense information into concise speech-level representations, ensuring
short distances within the same speaker and long distances between different
speakers. Despite the prevalence of self-attention and convolution methods in
speaker verification, they grapple with the challenge of high computational
complexity.In order to surmount the limitations posed by the Transformer in
extracting local features and the computational intricacies of multilayer
convolution, we introduce the Memory-Attention framework. This framework
incorporates a deep feed-forward temporal memory network (DFSMN) into the
self-attention mechanism, capturing long-term context by stacking multiple
layers and enhancing the modeling of local dependencies. Building upon this, we
design a novel model called VOT, utilizing a parallel variable weight summation
structure and introducing an attention-based statistical pooling layer.To
address the hard sample mining problem, we enhance the AM-Softmax loss function
and propose a new loss function named AM-Softmax-Focal. Experimental results on
the VoxCeleb1 dataset not only showcase a significant improvement in system
performance but also surpass the majority of mainstream models, validating the
importance of local information in the speaker verification task. The code will
be available on GitHub.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16835" title="Abstract">arXiv:2312.16835</a> (cross-list from eess.IV) [<a href="/pdf/2312.16835" title="Download PDF">pdf</a>, <a href="/format/2312.16835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RimSet: Quantitatively Identifying and Characterizing Chronic Active  Multiple Sclerosis Lesion on Quantitative Susceptibility Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T+D">Thanh D. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jinwei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+R">Renjiu Hu</a>, 
<a href="/search/eess?searchtype=author&query=Gauthier%2C+S+A">Susan A. Gauthier</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Background: Rim+ lesions in multiple sclerosis (MS), detectable via
Quantitative Susceptibility Mapping (QSM), correlate with increased disability.
Existing literature lacks quantitative analysis of these lesions. We introduce
RimSet for quantitative identification and characterization of rim+ lesions on
QSM. Methods: RimSet combines RimSeg, an unsupervised segmentation method using
level-set methodology, and radiomic measurements with Local Binary Pattern
texture descriptors. We validated RimSet using simulated QSM images and an in
vivo dataset of 172 MS subjects with 177 rim+ and 3986 rim-lesions. Results:
RimSeg achieved a 78.7% Dice score against the ground truth, with challenges in
partial rim lesions. RimSet detected rim+ lesions with a partial ROC AUC of
0.808 and PR AUC of 0.737, surpassing existing methods. QSMRim-Net showed the
lowest mean square error (0.85) and high correlation (0.91; 95% CI: 0.88, 0.93)
with expert annotations at the subject level.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16858" title="Abstract">arXiv:2312.16858</a> (cross-list from math.AG) [<a href="/pdf/2312.16858" title="Download PDF">pdf</a>, <a href="/ps/2312.16858" title="Download PostScript">ps</a>, <a href="/format/2312.16858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing superspecial hyperelliptic curves of genus 4 with automorphism  group properly containing the Klein 4-group
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ohashi%2C+R">Ryo Ohashi</a>, 
<a href="/search/math?searchtype=author&query=Kudo%2C+M">Momonari Kudo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, and comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Symbolic Computation (cs.SC); Number Theory (math.NT)

</div>
<p class="mathjax">In algebraic geometry, enumerating or finding superspecial curves in positive
characteristic $p$ is important both in theory and in computation. In this
paper, we propose feasible algorithms to enumerate or find superspecial
hyperelliptic curves of genus $4$ with automorphism group properly containing
the Klein $4$-group. Executing the algorithms on Magma, we succeeded in
enumerating such superspecial curves for every $p$ with $19 \leq p &lt; 500$, and
in finding a single one for every $p$ with $19 \leq p &lt; 7000$.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16877" title="Abstract">arXiv:2312.16877</a> (cross-list from quant-ph) [<a href="/pdf/2312.16877" title="Download PDF">pdf</a>, <a href="/ps/2312.16877" title="Download PostScript">ps</a>, <a href="/format/2312.16877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Circuit for Random Forest Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Safina%2C+L">Liliia Safina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khadieva%2C+K">Kamil Khadieva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zinnatullina%2C+I">Ilnar Zinnatullina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khadieva%2C+A">Aliya Khadieva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we present a quantum circuit for a binary classification
prediction algorithm using a random forest model. The quantum prediction
algorithm is presented in our previous works. We construct a circuit and
implement it using qiskit tools (python module for quantum programming). One of
our goals is reducing the number of basic quantum gates (elementary gates). The
set of basic quantum gates which we use in this work consists of single-qubit
gates and a controlled NOT gate. The number of CNOT gates in our circuit is
estimated by $O(2^{n+2h+1})$ , when trivial circuit decomposition techniques
give $O(4^{|X|+n+h+2})$ CNOT gates, where $n$ is the number of trees in a
random forest model, $h$ is a tree height and $|X|$ is the length of attributes
of an input object $X$. The prediction process returns an index of the
corresponding class for the input $X$.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16878" title="Abstract">arXiv:2312.16878</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.16878" title="Download PDF">pdf</a>, <a href="/format/2312.16878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voting power in the Council of the European Union: A comprehensive  sensitivity analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Petr%C3%B3czy%2C+D+G">D&#xf3;ra Gr&#xe9;ta Petr&#xf3;czy</a>, 
<a href="/search/physics?searchtype=author&query=Csat%C3%B3%2C+L">L&#xe1;szl&#xf3; Csat&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">The Council of the European Union (EU) is one of the main decision-making
bodies of the EU. Many decisions require a qualified majority: the support of
55% of the member states (currently 15) that represent at least 65% of the
total population. We investigate how the power distribution, based on the
Shapley-Shubik index, and the proportion of winning coalitions change if these
criteria are modified within reasonable bounds. The influence of the two
countries with about 4% of the total population each is found to be almost
flat. The level of decisiveness decreases if the population criterion is above
68% or the states criterion is at least 17. The proportion of winning
coalitions can be increased from 13.2% to 20.8% (30.1%) such that the maximal
relative change in the Shapley--Shubik indices remains below 3.5% (5.5%). Our
results are indispensable to evaluate any proposal for reforming the qualified
majority voting system.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16884" title="Abstract">arXiv:2312.16884</a> (cross-list from eess.AS) [<a href="/pdf/2312.16884" title="Download PDF">pdf</a>, <a href="/ps/2312.16884" title="Download PostScript">ps</a>, <a href="/format/2312.16884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binaural recording methods with analysis on inter-aural time, level, and  phase differences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tan%2C+J+K+A">Johann Kay Ann Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Binaural recordings are a form of stereophonic recording method that
replicates how human ears perceive sound, these types of recordings create a 3D
aural image around the listener and are extremely immersive when well recorded
and listened to appropriately with headphones. It has wide applications in
video, podcast, and gaming formats -- allowing the listener to feel like they
are there. Although binaural formats are seldom used for music applications,
they have also been utilized in music ranging from Rock, Jazz, Acoustic, and
Classical. In this paper, we will investigate the acoustical phenomenon that
produces the binaural effect in audio recordings -- including the ITD
(Inter-aural time difference), the ILD (inter-aural level difference), IPD
(inter-aural phase difference) as well as the monaural spectral difference that
occurs between two ears so we can better understand the replication of human
hearing in binaural recordings. Binaural recordings differ from regular
stereophonic recordings as they are arranged in a specific way to account for
HRTF (Head-related transfer function). The most common method of binaural
recordings is with two high-quality omni-directional microphones affixed on a
dummy head where the ears are located, although other methods exist without the
use of a full dummy head.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16887" title="Abstract">arXiv:2312.16887</a> (cross-list from stat.AP) [<a href="/pdf/2312.16887" title="Download PDF">pdf</a>, <a href="/format/2312.16887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Scoring of Cognition Drawings: Assessing the Quality of  Machine-Based Scores Against a Gold Standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bethmann%2C+A">Arne Bethmann</a>, 
<a href="/search/stat?searchtype=author&query=Aoki%2C+M">Marina Aoki</a>, 
<a href="/search/stat?searchtype=author&query=Hunsicker%2C+C">Charlotte Hunsicker</a>, 
<a href="/search/stat?searchtype=author&query=Weileder%2C+C">Claudia Weileder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Figure drawing is often used as part of dementia screening protocols. The
Survey of Health Aging and Retirement in Europe (SHARE) has adopted three
drawing tests from Addenbrooke's Cognitive Examination III as part of its
questionnaire module on cognition. While the drawings are usually scored by
trained clinicians, SHARE uses the face-to-face interviewers who conduct the
interviews to score the drawings during fieldwork. This may pose a risk to data
quality, as interviewers may be less consistent in their scoring and more
likely to make errors due to their lack of clinical training. This paper
therefore reports a first proof of concept and evaluates the feasibility of
automating scoring using deep learning. We train several different
convolutional neural network (CNN) models using about 2,000 drawings from the
8th wave of the SHARE panel in Germany and the corresponding interviewer
scores, as well as self-developed 'gold standard' scores. The results suggest
that this approach is indeed feasible. Compared to training on interviewer
scores, models trained on the gold standard data improve prediction accuracy by
about 10 percentage points. The best performing model, ConvNeXt Base, achieves
an accuracy of about 85%, which is 5 percentage points higher than the accuracy
of the interviewers. While this is a promising result, the models still
struggle to score partially correct drawings, which are also problematic for
interviewers. This suggests that more and better training data is needed to
achieve production-level prediction accuracy. We therefore discuss possible
next steps to improve the quality and quantity of training examples.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16908" title="Abstract">arXiv:2312.16908</a> (cross-list from math.NT) [<a href="/pdf/2312.16908" title="Download PDF">pdf</a>, <a href="/ps/2312.16908" title="Download PostScript">ps</a>, <a href="/format/2312.16908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A classification of permutation binomials of the form $x^i+ax$ over  $\mathbb{F}_{2^n}$ for dimensions up to 8
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/math?searchtype=author&query=Feng%2C+X">Xiutao Feng</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Information Theory (cs.IT); Combinatorics (math.CO)

</div>
<p class="mathjax">Permutation polynomials with few terms (especially permutation binomials)
attract many people due to their simple algebraic structure. Despite the great
interests in the study of permutation binomials, a complete characterization of
permutation binomials is still unknown. In this paper, we give a classification
of permutation binomials of the form $x^i+ax$ over $\mathbb{F}_{2^n}$, where
$n\leq 8$ by characterizing three new classes of permutation binomials. In
particular one of them has relatively large index $\frac{q^2+q+1}{3}$ over
$\mathbb{F}_{q^3}$.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16946" title="Abstract">arXiv:2312.16946</a> (cross-list from eess.SP) [<a href="/pdf/2312.16946" title="Download PDF">pdf</a>, <a href="/format/2312.16946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEO Satellite and RIS: Two Keys to Seamless Indoor and Outdoor  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zheng%2C+P">Pinjun Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xing Liu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+J">Jiguang He</a>, 
<a href="/search/eess?searchtype=author&query=Seco-Granados%2C+G">Gonzalo Seco-Granados</a>, 
<a href="/search/eess?searchtype=author&query=Al-Naffouri%2C+T+Y">Tareq Y. Al-Naffouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The contemporary landscape of wireless technology underscores the critical
role of precise localization services. Traditional global navigation satellite
systems (GNSS)-based solutions, however, fall short when it comes to indoor
environments, and existing indoor localization techniques such as
electromagnetic fingerprinting methods face challenges of high implementation
costs and limited coverage. This article explores an innovative solution that
seamlessly blends low Earth orbit (LEO) satellites with reconfigurable
intelligent surfaces (RISs), unlocking its potential for realizing
uninterrupted indoor and outdoor localization with global coverage. By
leveraging the strong signal reception of the LEO satellite signals and
capitalizing on the radio environment-reshaping capability of RISs, the
integration of these two technologies presents a vision of a future where
localization services transcend existing constraints. After a comprehensive
review of the distinctive attributes of LEO satellites and RISs, we evaluate
the localization error bounds for the proposed collaborative system, showcasing
their promising performance on simultaneous indoor and outdoor localization. To
conclude, we engage in a discussion on open problems and future research
directions for LEO satellite and RIS-enabled localization.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16959" title="Abstract">arXiv:2312.16959</a> (cross-list from eess.IV) [<a href="/pdf/2312.16959" title="Download PDF">pdf</a>, <a href="/format/2312.16959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Physics-Based Learned Reconstruction Methods for Real-Time 3D  Near-Field MIMO Radar Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Manisali%2C+I">Irfan Manisali</a>, 
<a href="/search/eess?searchtype=author&query=Oral%2C+O">Okyanus Oral</a>, 
<a href="/search/eess?searchtype=author&query=Oktem%2C+F+S">Figen S. Oktem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 17 figures. Accepted for publication in Digital Signal Processing, see DOI below. The source codes and the dataset are made available at <a href="https://github.com/METU-SPACE-Lab/Efficient-Learned-3D-Near-Field-MIMO-Imaging">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Digital Signal Processing, Volume 144, January 2024, 104274
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Near-field multiple-input multiple-output (MIMO) radar imaging systems have
recently gained significant attention. In this paper, we develop novel
non-iterative deep learning-based reconstruction methods for real-time
near-field MIMO imaging. The goal is to achieve high image quality with low
computational cost at compressive settings. The developed approaches have two
stages. In the first approach, physics-based initial stage performs adjoint
operation to back-project the measurements to the image-space, and deep neural
network (DNN)-based second stage converts the 3D backprojected measurements to
a magnitude-only reflectivity image. Since scene reflectivities often have
random phase, DNN processes directly the magnitude of the adjoint result. As
DNN, 3D U-Net is used to jointly exploit range and cross-range correlations. To
comparatively evaluate the significance of exploiting physics in a
learning-based approach, two additional approaches that replace the
physics-based first stage with fully connected layers are also developed as
purely learning-based methods. The performance is also analyzed by changing the
DNN architecture for the second stage to include complex-valued processing
(instead of magnitude-only processing), 2D convolution kernels (instead of 3D),
and ResNet architecture (instead of U-Net). Moreover, we develop a synthesizer
to generate large-scale dataset for training with 3D extended targets. We
illustrate the performance through experimental data and extensive simulations.
The results show the effectiveness of the developed physics-based learned
reconstruction approach in terms of both run-time and image quality at highly
compressive settings. Our source codes and dataset are made available at
GitHub.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16963" title="Abstract">arXiv:2312.16963</a> (cross-list from eess.IV) [<a href="/pdf/2312.16963" title="Download PDF">pdf</a>, <a href="/format/2312.16963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FFCA-Net: Stereo Image Compression via Fast Cascade Alignment of Side  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yichong Xia</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yujun Huang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-view compression technology, especially Stereo Image Compression (SIC),
plays a crucial role in car-mounted cameras and 3D-related applications.
Interestingly, the Distributed Source Coding (DSC) theory suggests that
efficient data compression of correlated sources can be achieved through
independent encoding and joint decoding. This motivates the rapidly developed
deep-distributed SIC methods in recent years. However, these approaches neglect
the unique characteristics of stereo-imaging tasks and incur high decoding
latency. To address this limitation, we propose a Feature-based Fast Cascade
Alignment network (FFCA-Net) to fully leverage the side information on the
decoder. FFCA adopts a coarse-to-fine cascaded alignment approach. In the
initial stage, FFCA utilizes a feature domain patch-matching module based on
stereo priors. This module reduces redundancy in the search space of trivial
matching methods and further mitigates the introduction of noise. In the
subsequent stage, we utilize an hourglass-based sparse stereo refinement
network to further align inter-image features with a reduced computational
cost. Furthermore, we have devised a lightweight yet high-performance feature
fusion network, called a Fast Feature Fusion network (FFF), to decode the
aligned features. Experimental results on InStereo2K, KITTI, and Cityscapes
datasets demonstrate the significant superiority of our approach over
traditional and learning-based SIC methods. In particular, our approach
achieves significant gains in terms of 3 to 10-fold faster decoding speed than
other methods.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16969" title="Abstract">arXiv:2312.16969</a> (cross-list from eess.SP) [<a href="/pdf/2312.16969" title="Download PDF">pdf</a>, <a href="/ps/2312.16969" title="Download PostScript">ps</a>, <a href="/format/2312.16969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Bloodless Potassium Measurement from ECG using Neuro-Fuzzy  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Samandari%2C+Z">Zeynab Samandari</a>, 
<a href="/search/eess?searchtype=author&query=Molaeezadeh%2C+S+F">Seyyedeh Fatemeh Molaeezadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, and 4 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Potassium disorders are generally asymptomatic, potentially lethal, and
common in patients with renal or cardiac disease. The morphology of the
electrocardiogram (ECG) signal is very sensitive to the changes in potassium
ions, so ECG has a high potential for detecting dyskalemias before laboratory
results. In this regard, this paper introduces a new system for ECG-based
potassium measurement. The proposed system consists of three main steps. First,
cohort selection &amp; data labeling were carried out by using a 5- minute interval
between ECGs and potassium measurements and defining three labels: hypokalemia,
normal, and hyperkalemia. After that, feature extraction &amp; selection were
performed. The extracted features are RR interval, PR interval, QRS duration,
QT interval, QTc interval, P axis, QRS axis, T axis, and ACCI. Kruskal-Wallis
technique was also used to assess the importance of the features and to select
discriminative ones. Finally, an ANFIS model based on FCM clustering
(FCM-ANFIS) was designed based on the selected features. The used database is
ECG-ViEW II. Results showed that T axis compared with other features has a
significant relationship with potassium levels (P&lt;0.01, r=0.62). The absolute
error of FCM-ANFIS is 0.4+-0.3 mM, its mean absolute percentage error (MAPE) is
9.99%, and its r-squared value is 0.74. Its classification accuracy is 85.71%.
In detecting hypokalemia and hyperkalemia, the sensitivities are 60% and 80%,
respectively, and the specificities are 100% and 97.3%, respectively. This
research has shed light on the design of noninvasive instruments to measure
potassium concentration and to detect dyskalemias, thereby reducing cardiac
events.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16998" title="Abstract">arXiv:2312.16998</a> (cross-list from eess.IV) [<a href="/pdf/2312.16998" title="Download PDF">pdf</a>, <a href="/format/2312.16998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Unfolding Network with Spatial Alignment for multi-modal MRI  reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Jun Shi</a>, 
<a href="/search/eess?searchtype=author&query=Ying%2C+S">Shihui Ying</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+Z">Zhijie Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-modal Magnetic Resonance Imaging (MRI) offers complementary diagnostic
information, but some modalities are limited by the long scanning time. To
accelerate the whole acquisition process, MRI reconstruction of one modality
from highly undersampled k-space data with another fully-sampled reference
modality is an efficient solution. However, the misalignment between
modalities, which is common in clinic practice, can negatively affect
reconstruction quality. Existing deep learning-based methods that account for
inter-modality misalignment perform better, but still share two main common
limitations: (1) The spatial alignment task is not adaptively integrated with
the reconstruction process, resulting in insufficient complementarity between
the two tasks; (2) the entire framework has weak interpretability. In this
paper, we construct a novel Deep Unfolding Network with Spatial Alignment,
termed DUN-SA, to appropriately embed the spatial alignment task into the
reconstruction process. Concretely, we derive a novel joint
alignment-reconstruction model with a specially designed cross-modal spatial
alignment term. By relaxing the model into cross-modal spatial alignment and
multi-modal reconstruction tasks, we propose an effective algorithm to solve
this model alternatively. Then, we unfold the iterative steps of the proposed
algorithm and design corresponding network modules to build DUN-SA with
interpretability. Through end-to-end training, we effectively compensate for
spatial misalignment using only reconstruction loss, and utilize the
progressively aligned reference modality to provide inter-modality prior to
improve the reconstruction of the target modality. Comprehensive experiments on
three real datasets demonstrate that our method exhibits superior
reconstruction performance compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17004" title="Abstract">arXiv:2312.17004</a> (cross-list from eess.IV) [<a href="/pdf/2312.17004" title="Download PDF">pdf</a>, <a href="/format/2312.17004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning in Medical Imaging Analysis: A Comprehensive Review  of Recent Advancements and Future Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kumari%2C+P">Pratibha Kumari</a>, 
<a href="/search/eess?searchtype=author&query=Chauhan%2C+J">Joohi Chauhan</a>, 
<a href="/search/eess?searchtype=author&query=Bozorgpour%2C+A">Afshin Bozorgpour</a>, 
<a href="/search/eess?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/eess?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Medical imaging analysis has witnessed remarkable advancements even
surpassing human-level performance in recent years, driven by the rapid
development of advanced deep-learning algorithms. However, when the inference
dataset slightly differs from what the model has seen during one-time training,
the model performance is greatly compromised. The situation requires restarting
the training process using both the old and the new data which is
computationally costly, does not align with the human learning process, and
imposes storage constraints and privacy concerns. Alternatively, continual
learning has emerged as a crucial approach for developing unified and
sustainable deep models to deal with new classes, tasks, and the drifting
nature of data in non-stationary environments for various application areas.
Continual learning techniques enable models to adapt and accumulate knowledge
over time, which is essential for maintaining performance on evolving datasets
and novel tasks. This systematic review paper provides a comprehensive overview
of the state-of-the-art in continual learning techniques applied to medical
imaging analysis. We present an extensive survey of existing research, covering
topics including catastrophic forgetting, data drifts, stability, and
plasticity requirements. Further, an in-depth discussion of key components of a
continual learning framework such as continual learning scenarios, techniques,
evaluation schemes, and metrics is provided. Continual learning techniques
encompass various categories, including rehearsal, regularization,
architectural, and hybrid strategies. We assess the popularity and
applicability of continual learning categories in various medical sub-fields
like radiology and histopathology...
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17019" title="Abstract">arXiv:2312.17019</a> (cross-list from quant-ph) [<a href="/pdf/2312.17019" title="Download PDF">pdf</a>, <a href="/format/2312.17019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Learning of Long-Range and Equivariant Quantum Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=%C5%A0m%C3%ADd%2C+%C5%A0">&#x160;t&#x11b;p&#xe1;n &#x160;m&#xed;d</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bondesan%2C+R">Roberto Bondesan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we consider a fundamental task in quantum many-body physics -
finding and learning ground states of quantum Hamiltonians and their
properties. Recent works have studied the task of predicting the ground state
expectation value of sums of geometrically local observables by learning from
data. For short-range gapped Hamiltonians, a sample complexity that is
logarithmic in the number of qubits and quasipolynomial in the error was
obtained. Here we extend these results beyond the local requirements on both
Hamiltonians and observables, motivated by the relevance of long-range
interactions in molecular and atomic systems. For interactions decaying as a
power law with exponent greater than twice the dimension of the system, we
recover the same efficient logarithmic scaling with respect to the number of
qubits, but the dependence on the error worsens to exponential. Further, we
show that learning algorithms equivariant under the automorphism group of the
interaction hypergraph achieve a sample complexity reduction, leading in
particular to a constant number of samples for learning sums of local
observables in systems with periodic boundary conditions. We demonstrate the
efficient scaling in practice by learning from DMRG simulations of $1$D
long-range and disordered systems with up to $128$ qubits. Finally, we provide
an analysis of the concentration of expectation values of global observables
stemming from central limit theorem, resulting in increased prediction
accuracy.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17023" title="Abstract">arXiv:2312.17023</a> (cross-list from math.CT) [<a href="/pdf/2312.17023" title="Download PDF">pdf</a>, <a href="/format/2312.17023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensorial structure of the lifting doctrine in constructive domain  theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sterling%2C+J">Jonathan Sterling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We present a survey of the two-dimensional and tensorial structure of the
lifting doctrine in constructive domain theory. We establish the universal
property of lifting of directed-complete partial orders (dcpos) as the
Sierpi\'nski cone, from which we deduce (1) that lifting forms a
Kock-Z\"oberlein doctrine, (2) that lifting algebras, pointed dcpos, and
inductive partial orders form canonically equivalent locally posetal
2-categories, and (3) that the category of lifting algebras is cocomplete, with
connected colimits created by the forgetful functor to dcpos. Finally we deduce
the symmetric monoidal closure of the Eilenberg-Moore resolution of the lifting
2-monad by means of smash products; these are shown to classify both bilinear
maps and strict maps, which we prove to coincide in the constructive setting.
We provide several concrete computations of the smash product as dcpo
coequalisers and lifting algebra coequalisers, and compare these with the more
abstract results of Seal. Although all these results are well-known
classically, the existing proofs do not apply in a constructive setting;
indeed, the classical analysis of the Eilenberg-Moore category of the lifting
monad relies on the fact that all lifting algebras are free, a condition that
is not known to hold constructively.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17030" title="Abstract">arXiv:2312.17030</a> (cross-list from eess.IV) [<a href="/pdf/2312.17030" title="Download PDF">pdf</a>, <a href="/format/2312.17030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multi-axis Representation in Frequency Domain for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruan%2C+J">Jiacheng Ruan</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jingsheng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+M">Mingye Xie</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2210.14007">arXiv:2210.14007</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, Visual Transformer (ViT) has been extensively used in medical image
segmentation (MIS) due to applying self-attention mechanism in the spatial
domain to modeling global knowledge. However, many studies have focused on
improving models in the spatial domain while neglecting the importance of
frequency domain information. Therefore, we propose Multi-axis External Weights
UNet (MEW-UNet) based on the U-shape architecture by replacing self-attention
in ViT with our Multi-axis External Weights block. Specifically, our block
performs a Fourier transform on the three axes of the input features and
assigns the external weight in the frequency domain, which is generated by our
External Weights Generator. Then, an inverse Fourier transform is performed to
change the features back to the spatial domain. We evaluate our model on four
datasets, including Synapse, ACDC, ISIC17 and ISIC18 datasets, and our approach
demonstrates competitive performance, owing to its effective utilization of
frequency domain information.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17033" title="Abstract">arXiv:2312.17033</a> (cross-list from math.CT) [<a href="/pdf/2312.17033" title="Download PDF">pdf</a>, <a href="/ps/2312.17033" title="Download PostScript">ps</a>, <a href="/format/2312.17033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boolean TQFTs with accumulating defects, sofic systems, and automata for  infinite words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gustafson%2C+P">Paul Gustafson</a>, 
<a href="/search/math?searchtype=author&query=Im%2C+M+S">Mee Seong Im</a>, 
<a href="/search/math?searchtype=author&query=Khovanov%2C+M">Mikhail Khovanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Formal Languages and Automata Theory (cs.FL); Mathematical Physics (math-ph); Dynamical Systems (math.DS); Quantum Algebra (math.QA)

</div>
<p class="mathjax">Any finite state automaton gives rise to a Boolean one-dimensional TQFT with
defects and inner endpoints of cobordisms. This paper extends the
correspondence to Boolean TQFTs where defects accumulate toward inner
endpoints, relating such TQFTs and topological theories to sofic systems and
$\omega$-automata.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17047" title="Abstract">arXiv:2312.17047</a> (cross-list from math.ST) [<a href="/pdf/2312.17047" title="Download PDF">pdf</a>, <a href="/format/2312.17047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inconsistency of cross-validation for structure learning in Gaussian  graphical models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lyu%2C+Z">Zhao Lyu</a>, 
<a href="/search/math?searchtype=author&query=Tai%2C+W+M">Wai Ming Tai</a>, 
<a href="/search/math?searchtype=author&query=Kolar%2C+M">Mladen Kolar</a>, 
<a href="/search/math?searchtype=author&query=Aragam%2C+B">Bryon Aragam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version; 47 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Despite numerous years of research into the merits and trade-offs of various
model selection criteria, obtaining robust results that elucidate the behavior
of cross-validation remains a challenging endeavor. In this paper, we highlight
the inherent limitations of cross-validation when employed to discern the
structure of a Gaussian graphical model. We provide finite-sample bounds on the
probability that the Lasso estimator for the neighborhood of a node within a
Gaussian graphical model, optimized using a prediction oracle, misidentifies
the neighborhood. Our results pertain to both undirected and directed acyclic
graphs, encompassing general, sparse covariance structures. To support our
theoretical findings, we conduct an empirical investigation of this
inconsistency by contrasting our outcomes with other commonly used information
criteria through an extensive simulation study. Given that many algorithms
designed to learn the structure of graphical models require hyperparameter
selection, the precise calibration of this hyperparameter is paramount for
accurately estimating the inherent structure. Consequently, our observations
shed light on this widely recognized practical challenge.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17057" title="Abstract">arXiv:2312.17057</a> (cross-list from quant-ph) [<a href="/pdf/2312.17057" title="Download PDF">pdf</a>, <a href="/format/2312.17057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logical Error Rates of XZZX and Rotated Quantum Surface Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Forlivesi%2C+D">Diego Forlivesi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Valentini%2C+L">Lorenzo Valentini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chiani%2C+M">Marco Chiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE Journal on Selected Areas in Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Surface codes are versatile quantum error-correcting codes known for their
planar geometry, making them ideal for practical implementations. While the
original proposal used Pauli $X$ or Pauli $Z$ operators in a square structure,
these codes can be improved by rotating the lattice or incorporating a mix of
generators in the XZZX variant. However, a comprehensive theoretical analysis
of the logical error rate for these variants has been lacking. To address this
gap, we present theoretical formulas based on recent advancements in
understanding the weight distribution of stabilizer codes. For example, over an
asymmetric channel with asymmetry $A=10$ and a physical error rate $p \to 0$,
we observe that the logical error rate asymptotically approaches $p_\mathrm{L}
\to 10 p^2$ for the rotated $[[9,1,3]]$ XZZX code and $p_\mathrm{L} \to 18.3
p^2$ for the $[[13,1,3]]$ surface code. Additionally, we observe a particular
behavior regarding rectangular lattices in the presence of asymmetric channels.
Our findings demonstrate that implementing both rotation and XZZX modifications
simultaneously can lead to suboptimal performance. Thus, in scenarios involving
a rectangular lattice, it is advisable to avoid using both modifications
simultaneously. This research enhances our theoretical understanding of the
logical error rates for XZZX and rotated surface codes, providing valuable
insights into their performance under different conditions.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17065" title="Abstract">arXiv:2312.17065</a> (cross-list from stat.ME) [<a href="/pdf/2312.17065" title="Download PDF">pdf</a>, <a href="/format/2312.17065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CluBear: A Subsampling Package for Interactive Statistical Analysis with  Massive Data on A Single Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Y">Yingqiu Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+Y">Yijing Liu</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+H">Hansheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Software Engineering (cs.SE); Applications (stat.AP)

</div>
<p class="mathjax">This article introduces CluBear, a Python-based open-source package for
interactive massive data analysis. The key feature of CluBear is that it
enables users to conduct convenient and interactive statistical analysis of
massive data with only a traditional single-computer system. Thus, CluBear
provides a cost-effective solution when mining large-scale datasets. In
addition, the CluBear package integrates many commonly used statistical and
graphical tools, which are useful for most commonly encountered data analysis
tasks.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17093" title="Abstract">arXiv:2312.17093</a> (cross-list from math.AT) [<a href="/pdf/2312.17093" title="Download PDF">pdf</a>, <a href="/format/2312.17093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Persistent Homology: Persistence Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Van+Huffel%2C+M+E">Michael Etienne Van Huffel</a>, 
<a href="/search/math?searchtype=author&query=Palo%2C+M">Matteo Palo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we present a novel family of descriptors for persistence
diagrams, reconceptualizing them as signals in $\mathbb R^2_+$. This marks a
significant advancement in Topological Data Analysis. Our methodology
transforms persistence diagrams into a finite-dimensional vector space through
functionals of the discrete measures induced by these diagrams. While our focus
is primarily on frequency-based transformations, we do not restrict our
approach exclusively to this types of techniques. We term this family of
transformations as $Persistence$ $Signals$ and prove stability for some members
of this family against the 1-$Kantorovitch$-$Rubinstein$ metric, ensuring its
responsiveness to subtle data variations. Extensive comparative analysis
reveals that our descriptor performs competitively with the current
state-of-art from the topological data analysis literature, and often
surpasses, the existing methods. This research not only introduces a
groundbreaking perspective for data scientists but also establishes a
foundation for future innovations in applying persistence diagrams in data
analysis and machine learning.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17111" title="Abstract">arXiv:2312.17111</a> (cross-list from stat.ML) [<a href="/pdf/2312.17111" title="Download PDF">pdf</a>, <a href="/format/2312.17111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Tensor Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wen%2C+X">Xin Wen</a> (1), 
<a href="/search/stat?searchtype=author&query=Sun%2C+W+W">Will Wei Sun</a> (2), 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Y">Yichen Zhang</a> (2) ((1) University of Science and Technology of China, (2) Purdue University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Recent technological advances have led to contemporary applications that
demand real-time processing and analysis of sequentially arriving tensor data.
Traditional offline learning, involving the storage and utilization of all data
in each computational iteration, becomes impractical for high-dimensional
tensor data due to its voluminous size. Furthermore, existing low-rank tensor
methods lack the capability for statistical inference in an online fashion,
which is essential for real-time predictions and informed decision-making. This
paper addresses these challenges by introducing a novel online inference
framework for low-rank tensor learning. Our approach employs Stochastic
Gradient Descent (SGD) to enable efficient real-time data processing without
extensive memory requirements, thereby significantly reducing computational
demands. We establish a non-asymptotic convergence result for the online
low-rank SGD estimator, nearly matches the minimax optimal rate of estimation
error in offline models that store all historical data. Building upon this
foundation, we propose a simple yet powerful online debiasing approach for
sequential statistical inference in low-rank tensor learning. The entire online
procedure, covering both estimation and inference, eliminates the need for data
splitting or storing historical data, making it suitable for on-the-fly
hypothesis testing. Given the sequential nature of our data collection,
traditional analyses relying on offline methods and sample splitting are
inadequate. In our analysis, we control the sum of constructed
super-martingales to ensure estimates along the entire solution path remain
within the benign region. Additionally, a novel spectral representation tool is
employed to address statistical dependencies among iterative estimates,
establishing the desired asymptotic normality.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17162" title="Abstract">arXiv:2312.17162</a> (cross-list from stat.ML) [<a href="/pdf/2312.17162" title="Download PDF">pdf</a>, <a href="/format/2312.17162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function-Space Regularization in Neural Networks: A Probabilistic  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/stat?searchtype=author&query=Kapoor%2C+S">Sanyam Kapoor</a>, 
<a href="/search/stat?searchtype=author&query=Qiu%2C+S">Shikai Qiu</a>, 
<a href="/search/stat?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Proceedings of the 40th International Conference on Machine Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Parameter-space regularization in neural network optimization is a
fundamental tool for improving generalization. However, standard
parameter-space regularization methods make it challenging to encode explicit
preferences about desired predictive functions into neural network training. In
this work, we approach regularization in neural networks from a probabilistic
perspective and show that by viewing parameter-space regularization as
specifying an empirical prior distribution over the model parameters, we can
derive a probabilistically well-motivated regularization technique that allows
explicitly encoding information about desired predictive functions into neural
network training. This method -- which we refer to as function-space empirical
Bayes (FSEB) -- includes both parameter- and function-space regularization, is
mathematically simple, easy to implement, and incurs only minimal computational
overhead compared to standard regularization techniques. We evaluate the
utility of this regularization technique empirically and demonstrate that the
proposed method leads to near-perfect semantic shift detection,
highly-calibrated predictive uncertainty estimates, successful task adaption
from pre-trained models, and improved generalization under covariate shift.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17167" title="Abstract">arXiv:2312.17167</a> (cross-list from econ.TH) [<a href="/pdf/2312.17167" title="Download PDF">pdf</a>, <a href="/format/2312.17167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Gatekeeper Effect: The Implications of Pre-Screening,  Self-selection, and Bias for Hiring Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Koren%2C+M">Moran Koren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We study the problem of screening in decision-making processes under
uncertainty, focusing on the impact of adding an additional screening stage,
commonly known as a 'gatekeeper.' While our primary analysis is rooted in the
context of job market hiring, the principles and findings are broadly
applicable to areas such as educational admissions, healthcare patient
selection, and financial loan approvals. The gatekeeper's role is to assess
applicants' suitability before significant investments are made. Our study
reveals that while gatekeepers are designed to streamline the selection process
by filtering out less likely candidates, they can sometimes inadvertently
affect the candidates' own decision-making process. We explore the conditions
under which the introduction of a gatekeeper can enhance or impede the
efficiency of these processes. Additionally, we consider how adjusting
gatekeeping strategies might impact the accuracy of selection decisions. Our
research also extends to scenarios where gatekeeping is influenced by
historical biases, particularly in competitive settings like hiring. We
discover that candidates confronted with a statistically biased gatekeeping
process are more likely to withdraw from applying, thereby perpetuating the
previously mentioned historical biases. The study suggests that measures such
as affirmative action can be effective in addressing these biases. While
centered on hiring, the insights and methodologies from our study have
significant implications for a wide range of fields where screening and
gatekeeping are integral.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17173" title="Abstract">arXiv:2312.17173</a> (cross-list from stat.ML) [<a href="/pdf/2312.17173" title="Download PDF">pdf</a>, <a href="/format/2312.17173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Vacuous Generalization Bounds for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lotfi%2C+S">Sanae Lotfi</a>, 
<a href="/search/stat?searchtype=author&query=Finzi%2C+M">Marc Finzi</a>, 
<a href="/search/stat?searchtype=author&query=Kuang%2C+Y">Yilun Kuang</a>, 
<a href="/search/stat?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/stat?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/stat?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern language models can contain billions of parameters, raising the
question of whether they can generalize beyond the training data or simply
regurgitate their training corpora. We provide the first non-vacuous
generalization bounds for pretrained large language models (LLMs), indicating
that language models are capable of discovering regularities that generalize to
unseen data. In particular, we derive a compression bound that is valid for the
unbounded log-likelihood loss using prediction smoothing, and we extend the
bound to handle subsampling, accelerating bound computation on massive
datasets. To achieve the extreme level of compression required for non-vacuous
generalization bounds, we devise SubLoRA, a low-dimensional non-linear
parameterization. Using this approach, we find that larger models have better
generalization bounds and are more compressible than smaller models.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17183" title="Abstract">arXiv:2312.17183</a> (cross-list from eess.IV) [<a href="/pdf/2312.17183" title="Download PDF">pdf</a>, <a href="/format/2312.17183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Model to Rule them All: Towards Universal Segmentation for Medical  Images with Text Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Ziheng Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this study, we focus on building up a model that can Segment Anything in
medical scenarios, driven by Text prompts, termed as SAT. Our main
contributions are three folds: (i) on data construction, we combine multiple
knowledge sources to construct a multi-modal medical knowledge tree; Then we
build up a large-scale segmentation dataset for training, by collecting over
11K 3D medical image scans from 31 segmentation datasets with careful
standardization on both visual scans and label space; (ii) on model training,
we formulate a universal segmentation model, that can be prompted by inputting
medical terminologies in text form. We present a knowledge-enhanced
representation learning framework, and a series of strategies for effectively
training on the combination of a large number of datasets; (iii) on model
evaluation, we train a SAT-Nano with only 107M parameters, to segment 31
different segmentation datasets with text prompt, resulting in 362 categories.
We thoroughly evaluate the model from three aspects: averaged by body regions,
averaged by classes, and average by datasets, demonstrating comparable
performance to 36 specialist nnUNets, i.e., we train nnUNet models on each
dataset/subset, resulting in 36 nnUNets with around 1000M parameters for the 31
datasets. We will release all the codes, and models used in this report, i.e.,
SAT-Nano. Moreover, we will offer SAT-Ultra in the near future, which is
trained with model of larger size, on more diverse datasets. Webpage URL:
https://zhaoziheng.github.io/MedUniSeg.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17194" title="Abstract">arXiv:2312.17194</a> (cross-list from math.OC) [<a href="/pdf/2312.17194" title="Download PDF">pdf</a>, <a href="/format/2312.17194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Constrained Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ding%2C+D">Dongsheng Ding</a>, 
<a href="/search/math?searchtype=author&query=Huan%2C+Z">Zhengyan Huan</a>, 
<a href="/search/math?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 25 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We study a class of constrained reinforcement learning (RL) problems in which
multiple constraint specifications are not identified before training. It is
challenging to identify appropriate constraint specifications due to the
undefined trade-off between the reward maximization objective and the
constraint satisfaction, which is ubiquitous in constrained decision-making. To
tackle this issue, we propose a new constrained RL approach that searches for
policy and constraint specifications together. This method features the
adaptation of relaxing the constraint according to a relaxation cost introduced
in the learning objective. Since this feature mimics how ecological systems
adapt to disruptions by altering operation, our approach is termed as resilient
constrained RL. Specifically, we provide a set of sufficient conditions that
balance the constraint satisfaction and the reward maximization in notion of
resilient equilibrium, propose a tractable formulation of resilient constrained
policy optimization that takes this equilibrium as an optimal solution, and
advocate two resilient constrained policy search algorithms with non-asymptotic
convergence guarantees on the optimality gap and constraint satisfaction.
Furthermore, we demonstrate the merits and the effectiveness of our approach in
computational experiments.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17199" title="Abstract">arXiv:2312.17199</a> (cross-list from stat.ML) [<a href="/pdf/2312.17199" title="Download PDF">pdf</a>, <a href="/format/2312.17199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tractable Function-Space Variational Inference in Bayesian Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Z">Zonghao Chen</a>, 
<a href="/search/stat?searchtype=author&query=Teh%2C+Y+W">Yee Whye Teh</a>, 
<a href="/search/stat?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Advances in Neural Information Processing Systems 35 (NeurIPS 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reliable predictive uncertainty estimation plays an important role in
enabling the deployment of neural networks to safety-critical settings. A
popular approach for estimating the predictive uncertainty of neural networks
is to define a prior distribution over the network parameters, infer an
approximate posterior distribution, and use it to make stochastic predictions.
However, explicit inference over neural network parameters makes it difficult
to incorporate meaningful prior information about the data-generating process
into the model. In this paper, we pursue an alternative approach. Recognizing
that the primary object of interest in most settings is the distribution over
functions induced by the posterior distribution over neural network parameters,
we frame Bayesian inference in neural networks explicitly as inferring a
posterior distribution over functions and propose a scalable function-space
variational inference method that allows incorporating prior information and
results in reliable predictive uncertainty estimates. We show that the proposed
method leads to state-of-the-art uncertainty estimation and predictive
performance on a range of prediction tasks and demonstrate that it performs
well on a challenging safety-critical medical diagnosis task in which reliable
uncertainty estimation is essential.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17210" title="Abstract">arXiv:2312.17210</a> (cross-list from stat.ML) [<a href="/pdf/2312.17210" title="Download PDF">pdf</a>, <a href="/format/2312.17210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning via Sequential Function-Space Variational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/stat?searchtype=author&query=Smith%2C+F+B">Freddie Bickford Smith</a>, 
<a href="/search/stat?searchtype=author&query=Feng%2C+Q">Qixuan Feng</a>, 
<a href="/search/stat?searchtype=author&query=Teh%2C+Y+W">Yee Whye Teh</a>, 
<a href="/search/stat?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Proceedings of the 39th International Conference on Machine Learning (ICML 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Sequential Bayesian inference over predictive functions is a natural
framework for continual learning from streams of data. However, applying it to
neural networks has proved challenging in practice. Addressing the drawbacks of
existing techniques, we propose an optimization objective derived by
formulating continual learning as sequential function-space variational
inference. In contrast to existing methods that regularize neural network
parameters directly, this objective allows parameters to vary widely during
training, enabling better adaptation to new tasks. Compared to objectives that
directly regularize neural network predictions, the proposed objective allows
for more flexible variational distributions and more effective regularization.
We demonstrate that, across a range of task sequences, neural networks trained
via sequential function-space variational inference achieve better predictive
accuracy than networks trained with related methods while depending less on
maintaining a set of representative points from previous tasks.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17216" title="Abstract">arXiv:2312.17216</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.17216" title="Download PDF">pdf</a>, <a href="/format/2312.17216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparseProp: Efficient Event-Based Simulation and Training of Sparse  Recurrent Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Engelken%2C+R">Rainer Engelken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, accepted at NeurIPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) are biologically-inspired models that are
capable of processing information in streams of action potentials. However,
simulating and training SNNs is computationally expensive due to the need to
solve large systems of coupled differential equations. In this paper, we
introduce SparseProp, a novel event-based algorithm for simulating and training
sparse SNNs. Our algorithm reduces the computational cost of both the forward
and backward pass operations from O(N) to O(log(N)) per network spike, thereby
enabling numerically exact simulations of large spiking networks and their
efficient training using backpropagation through time. By leveraging the
sparsity of the network, SparseProp eliminates the need to iterate through all
neurons at each spike, employing efficient state updates instead. We
demonstrate the efficacy of SparseProp across several classical
integrate-and-fire neuron models, including a simulation of a sparse SNN with
one million LIF neurons. This results in a speed-up exceeding four orders of
magnitude relative to previous event-based implementations. Our work provides
an efficient and exact solution for training large-scale spiking neural
networks and opens up new possibilities for building more sophisticated
brain-inspired models.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 29 Dec 23</h3>
<dl>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1804.06311" title="Abstract">arXiv:1804.06311</a> (replaced) [<a href="/pdf/1804.06311" title="Download PDF">pdf</a>, <a href="/format/1804.06311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Statistical Multi-Agent Online Planning with Emergent Value  Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Belzner%2C+L">Lenz Belzner</a>, 
<a href="/search/cs?searchtype=author&query=Gabor%2C+T">Thomas Gabor</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+K">Kyrill Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAMAS 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1901.09269" title="Abstract">arXiv:1901.09269</a> (replaced) [<a href="/pdf/1901.09269" title="Download PDF">pdf</a>, <a href="/format/1901.09269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Learning with Compressed Gradient Differences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishchenko%2C+K">Konstantin Mishchenko</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>, 
<a href="/search/cs?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages; Changes in V3: writing, presentation, and numerical experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1905.11027" title="Abstract">arXiv:1905.11027</a> (replaced) [<a href="/pdf/1905.11027" title="Download PDF">pdf</a>, <a href="/format/1905.11027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Geometric Modeling of Occam&#x27;s Razor in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+F">Frank Nielsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work first appeared under the former title "Lightlike Neuromanifolds, Occam's Razor and Deep Learning"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.05861" title="Abstract">arXiv:1907.05861</a> (replaced) [<a href="/pdf/1907.05861" title="Download PDF">pdf</a>, <a href="/format/1907.05861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Thompson Sampling Stacks for Memory Bounded Open-Loop Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Gabor%2C+T">Thomas Gabor</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R">Robert M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Roch%2C+C">Christoph Roch</a>, 
<a href="/search/cs?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IJCAI 2019. arXiv admin note: substantial text overlap with <a href="/abs/1905.04020">arXiv:1905.04020</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1912.11939" title="Abstract">arXiv:1912.11939</a> (replaced) [<a href="/pdf/1912.11939" title="Download PDF">pdf</a>, <a href="/format/1912.11939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Principle of Least Symmetry Breaking in Shallow ReLU Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arjevani%2C+Y">Yossi Arjevani</a>, 
<a href="/search/cs?searchtype=author&query=Field%2C+M">Michael Field</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.04117" title="Abstract">arXiv:2003.04117</a> (replaced) [<a href="/pdf/2003.04117" title="Download PDF">pdf</a>, <a href="/format/2003.04117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Utility of Feature Reuse: Transfer Learning in Data-Starved Regimes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shadman%2C+R">Rashik Shadman</a>, 
<a href="/search/cs?searchtype=author&query=Murshed%2C+M+G+S">M.G. Sarwar Murshed</a>, 
<a href="/search/cs?searchtype=author&query=Verenich%2C+E">Edward Verenich</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">Alvaro Velasquez</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+F">Faraz Hussain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figure, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.10642" title="Abstract">arXiv:2007.10642</a> (replaced) [<a href="/pdf/2007.10642" title="Download PDF">pdf</a>, <a href="/format/2007.10642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gasper: GrAph Signal ProcEssing in R
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Loynes%2C+B">Basile de Loynes</a>, 
<a href="/search/eess?searchtype=author&query=Navarro%2C+F">Fabien Navarro</a>, 
<a href="/search/eess?searchtype=author&query=Olivier%2C+B">Baptiste Olivier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.06197" title="Abstract">arXiv:2102.06197</a> (replaced) [<a href="/pdf/2102.06197" title="Download PDF">pdf</a>, <a href="/format/2102.06197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating a Directed Tree for Extremes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tran%2C+N+M">Ngoc Mai Tran</a>, 
<a href="/search/stat?searchtype=author&query=Buck%2C+J">Johannes Buck</a>, 
<a href="/search/stat?searchtype=author&query=Kl%C3%BCppelberg%2C+C">Claudia Kl&#xfc;ppelberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extensive Revision. 54 pages, 26 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.12682" title="Abstract">arXiv:2102.12682</a> (replaced) [<a href="/pdf/2102.12682" title="Download PDF">pdf</a>, <a href="/format/2102.12682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axomorphic Perspective Projection Model for Immersive Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fober%2C+J+M">Jakub Maksymilian Fober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 16 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.06234" title="Abstract">arXiv:2103.06234</a> (replaced) [<a href="/pdf/2103.06234" title="Download PDF">pdf</a>, <a href="/format/2103.06234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry Breaking in Symmetric Tensor Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arjevani%2C+Y">Yossi Arjevani</a>, 
<a href="/search/math?searchtype=author&query=Bruna%2C+J">Joan Bruna</a>, 
<a href="/search/math?searchtype=author&query=Field%2C+M">Michael Field</a>, 
<a href="/search/math?searchtype=author&query=Kileel%2C+J">Joe Kileel</a>, 
<a href="/search/math?searchtype=author&query=Trager%2C+M">Matthew Trager</a>, 
<a href="/search/math?searchtype=author&query=Williams%2C+F">Francis Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.03932" title="Abstract">arXiv:2104.03932</a> (replaced) [<a href="/pdf/2104.03932" title="Download PDF">pdf</a>, <a href="/ps/2104.03932" title="Download PostScript">ps</a>, <a href="/format/2104.03932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universally-Optimal Distributed Algorithms for Known Topologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haeupler%2C+B">Bernhard Haeupler</a>, 
<a href="/search/cs?searchtype=author&query=Wajc%2C+D">David Wajc</a>, 
<a href="/search/cs?searchtype=author&query=Zuzic%2C+G">Goran Zuzic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of extended abstract in STOC 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.00613" title="Abstract">arXiv:2105.00613</a> (replaced) [<a href="/pdf/2105.00613" title="Download PDF">pdf</a>, <a href="/ps/2105.00613" title="Download PostScript">ps</a>, <a href="/format/2105.00613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A C++17 Thread Pool for High-Performance Scientific Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shoshany%2C+B">Barak Shoshany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, source code available at <a href="https://github.com/bshoshany/thread-pool">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.09133" title="Abstract">arXiv:2107.09133</a> (replaced) [<a href="/pdf/2107.09133" title="Download PDF">pdf</a>, <a href="/format/2107.09133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Limiting Dynamics of SGD: Modified Loss, Phase Space Oscillations,  and Anomalous Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunin%2C+D">Daniel Kunin</a>, 
<a href="/search/cs?searchtype=author&query=Sagastuy-Brena%2C+J">Javier Sagastuy-Brena</a>, 
<a href="/search/cs?searchtype=author&query=Gillespie%2C+L">Lauren Gillespie</a>, 
<a href="/search/cs?searchtype=author&query=Margalit%2C+E">Eshed Margalit</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+H">Hidenori Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+S">Surya Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Yamins%2C+D+L+K">Daniel L. K. Yamins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 pages, 9 figures, Neural Computation 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Computation (2024) 36 (1) 151-174
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.10859" title="Abstract">arXiv:2108.10859</a> (replaced) [<a href="/pdf/2108.10859" title="Download PDF">pdf</a>, <a href="/ps/2108.10859" title="Download PostScript">ps</a>, <a href="/format/2108.10859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cumulative Regret Analysis of the Piyavskii--Shubert Algorithm and Its  Variants for Global Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gokcesu%2C+K">Kaan Gokcesu</a>, 
<a href="/search/cs?searchtype=author&query=Gokcesu%2C+H">Hakan Gokcesu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00145" title="Abstract">arXiv:2201.00145</a> (replaced) [<a href="/pdf/2201.00145" title="Download PDF">pdf</a>, <a href="/format/2201.00145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Decomposition and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+J">Jun Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2107.02579">arXiv:2107.02579</a>, <a href="/abs/2105.04240">arXiv:2105.04240</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07366" title="Abstract">arXiv:2201.07366</a> (replaced) [<a href="/pdf/2201.07366" title="Download PDF">pdf</a>, <a href="/format/2201.07366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TriCoLo: Trimodal Contrastive Loss for Text to Shape Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Y">Yue Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Han-Hung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.08832" title="Abstract">arXiv:2201.08832</a> (replaced) [<a href="/pdf/2201.08832" title="Download PDF">pdf</a>, <a href="/format/2201.08832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occupancy Information Ratio: Infinite-Horizon, Information-Directed,  Parameterized Policy Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suttle%2C+W+A">Wesley A. Suttle</a>, 
<a href="/search/cs?searchtype=author&query=Koppel%2C+A">Alec Koppel</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04876" title="Abstract">arXiv:2204.04876</a> (replaced) [<a href="/pdf/2204.04876" title="Download PDF">pdf</a>, <a href="/format/2204.04876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lyapunov-Guided Representation of Recurrent Neural Network Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vogt%2C+R">Ryan Vogt</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shlizerman%2C+E">Eli Shlizerman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.13809" title="Abstract">arXiv:2204.13809</a> (replaced) [<a href="/pdf/2204.13809" title="Download PDF">pdf</a>, <a href="/ps/2204.13809" title="Download PostScript">ps</a>, <a href="/format/2204.13809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated player identification and indexing using two-stage deep  learning network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Aderon%2C+C">Colin Aderon</a>, 
<a href="/search/cs?searchtype=author&query=Wagon%2C+N">Noah Wagon</a>, 
<a href="/search/cs?searchtype=author&query=Bamba%2C+A+L">Abdul Latif Bamba</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueshen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huapu Liu</a>, 
<a href="/search/cs?searchtype=author&query=MacCall%2C+S">Steven MacCall</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yu Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15677" title="Abstract">arXiv:2205.15677</a> (replaced) [<a href="/pdf/2205.15677" title="Download PDF">pdf</a>, <a href="/format/2205.15677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentation-Aware Self-Supervision for Data-Efficient GAN Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yige Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Songtao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Siyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05148" title="Abstract">arXiv:2206.05148</a> (replaced) [<a href="/pdf/2206.05148" title="Download PDF">pdf</a>, <a href="/format/2206.05148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-supervised segmentation using inherently-explainable  classification models and their application to brain tumour classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chatterjee%2C+S">Soumick Chatterjee</a>, 
<a href="/search/eess?searchtype=author&query=Yassin%2C+H">Hadya Yassin</a>, 
<a href="/search/eess?searchtype=author&query=Dubost%2C+F">Florian Dubost</a>, 
<a href="/search/eess?searchtype=author&query=N%C3%BCrnberger%2C+A">Andreas N&#xfc;rnberger</a>, 
<a href="/search/eess?searchtype=author&query=Speck%2C+O">Oliver Speck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05434" title="Abstract">arXiv:2206.05434</a> (replaced) [<a href="/pdf/2206.05434" title="Download PDF">pdf</a>, <a href="/format/2206.05434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewindable Quantum Computation and Its Equivalence to Cloning and  Adaptive Postselection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hiromasa%2C+R">Ryo Hiromasa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mizutani%2C+A">Akihiro Mizutani</a>, 
<a href="/search/quant-ph?searchtype=author&query=Takeuchi%2C+Y">Yuki Takeuchi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tani%2C+S">Seiichiro Tani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures, v2: Added Result 3 and improved Result 4, v3: Revised Theorem 34, reflected TQC review comments, and added minor revisions
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 18th Conference on the Theory of Quantum
  Computation, Communication and Cryptography (TQC 2023), pp. 9:1-9:23, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02346" title="Abstract">arXiv:2207.02346</a> (replaced) [<a href="/pdf/2207.02346" title="Download PDF">pdf</a>, <a href="/format/2207.02346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Many-body localized hidden generative models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhong%2C+W">Weishun Zhong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gao%2C+X">Xun Gao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yelin%2C+S+F">Susanne F. Yelin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Najafi%2C+K">Khadijeh Najafi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures; added references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03512" title="Abstract">arXiv:2207.03512</a> (replaced) [<a href="/pdf/2207.03512" title="Download PDF">pdf</a>, <a href="/ps/2207.03512" title="Download PostScript">ps</a>, <a href="/format/2207.03512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of smooth parametrizations on nonconvex optimization  landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Levin%2C+E">Eitan Levin</a>, 
<a href="/search/math?searchtype=author&query=Kileel%2C+J">Joe Kileel</a>, 
<a href="/search/math?searchtype=author&query=Boumal%2C+N">Nicolas Boumal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07038" title="Abstract">arXiv:2207.07038</a> (replaced) [<a href="/pdf/2207.07038" title="Download PDF">pdf</a>, <a href="/format/2207.07038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHAP-XRT: The Shapley Value Meets Conditional Independence Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teneggi%2C+J">Jacopo Teneggi</a>, 
<a href="/search/cs?searchtype=author&query=Bharti%2C+B">Beepul Bharti</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+Y">Yaniv Romano</a>, 
<a href="/search/cs?searchtype=author&query=Sulam%2C+J">Jeremias Sulam</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14370" title="Abstract">arXiv:2207.14370</a> (replaced) [<a href="/pdf/2207.14370" title="Download PDF">pdf</a>, <a href="/format/2207.14370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot News Recommendation via Cross-lingual Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Taicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shihada%2C+B">Basem Shihada</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01549" title="Abstract">arXiv:2209.01549</a> (replaced) [<a href="/pdf/2209.01549" title="Download PDF">pdf</a>, <a href="/format/2209.01549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Broken Windows Theory Applies to Technical Debt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lev%C3%A9n%2C+W">William Lev&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Broman%2C+H">Hampus Broman</a>, 
<a href="/search/cs?searchtype=author&query=Besker%2C+T">Terese Besker</a>, 
<a href="/search/cs?searchtype=author&query=Torkar%2C+R">Richard Torkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Empirical Software Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05193" title="Abstract">arXiv:2209.05193</a> (replaced) [<a href="/pdf/2209.05193" title="Download PDF">pdf</a>, <a href="/format/2209.05193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust parallel nonlinear solvers for implicit time discretizations of  the Bidomain equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barnafi%2C+N+A">Nicol&#xe1;s A. Barnafi</a>, 
<a href="/search/math?searchtype=author&query=Huynh%2C+N+M+M">Ngoc Mai Monica Huynh</a>, 
<a href="/search/math?searchtype=author&query=Pavarino%2C+L+F">Luca F. Pavarino</a>, 
<a href="/search/math?searchtype=author&query=Scacchi%2C+S">Simone Scacchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08263" title="Abstract">arXiv:2209.08263</a> (replaced) [<a href="/pdf/2209.08263" title="Download PDF">pdf</a>, <a href="/format/2209.08263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable SoftGroup for 3D Instance Segmentation on Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Thang Vu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kookhoi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+T+M">Tung M. Luu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI. Extension of <a href="/abs/2203.01509">arXiv:2203.01509</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09141" title="Abstract">arXiv:2209.09141</a> (replaced) [<a href="/pdf/2209.09141" title="Download PDF">pdf</a>, <a href="/format/2209.09141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Guess what I&#x27;m doing&quot;: Extending legibility to sequential decision  tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faria%2C+M">Miguel Faria</a>, 
<a href="/search/cs?searchtype=author&query=Melo%2C+F+S">Francisco S. Melo</a>, 
<a href="/search/cs?searchtype=author&query=Paiva%2C+A">Ana Paiva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15224" title="Abstract">arXiv:2209.15224</a> (replaced) [<a href="/pdf/2209.15224" title="Download PDF">pdf</a>, <a href="/format/2209.15224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Unsupervised Multi-task and Transfer Learning on Gaussian Mixture  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tian%2C+Y">Ye Tian</a>, 
<a href="/search/stat?searchtype=author&query=Weng%2C+H">Haolei Weng</a>, 
<a href="/search/stat?searchtype=author&query=Feng%2C+Y">Yang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 145 pages, 15 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04410" title="Abstract">arXiv:2210.04410</a> (replaced) [<a href="/pdf/2210.04410" title="Download PDF">pdf</a>, <a href="/format/2210.04410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the Delivery of Data Services over Uncertain Mobile  Crowdsensing Ecosystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liwang%2C+M">Minghui Liwang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhipeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuhan Su</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05491" title="Abstract">arXiv:2210.05491</a> (replaced) [<a href="/pdf/2210.05491" title="Download PDF">pdf</a>, <a href="/ps/2210.05491" title="Download PostScript">ps</a>, <a href="/format/2210.05491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong negation in the theory of computable functionals TCF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%B6pp%2C+N">Nils K&#xf6;pp</a>, 
<a href="/search/math?searchtype=author&query=Petrakis%2C+I">Iosif Petrakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08303" title="Abstract">arXiv:2210.08303</a> (replaced) [<a href="/pdf/2210.08303" title="Download PDF">pdf</a>, <a href="/format/2210.08303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Radiology Summarization with Radiograph and Anatomy Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinpeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+T">Tsung-Hui Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, ACL2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10136" title="Abstract">arXiv:2210.10136</a> (replaced) [<a href="/pdf/2210.10136" title="Download PDF">pdf</a>, <a href="/ps/2210.10136" title="Download PostScript">ps</a>, <a href="/format/2210.10136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discipline Reputation Evaluation Based on PhD Exchange Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hua Jiang</a> (1), 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shudong Yang</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengbo Liu</a> (1) ((1) Dalian University of Technology)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02647" title="Abstract">arXiv:2211.02647</a> (replaced) [<a href="/pdf/2211.02647" title="Download PDF">pdf</a>, <a href="/format/2211.02647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Grasp Distance Fields for Robot Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Thomas Weng</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+F">Franziska Meier</a>, 
<a href="/search/cs?searchtype=author&query=Mukadam%2C+M">Mustafa Mukadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03447" title="Abstract">arXiv:2211.03447</a> (replaced) [<a href="/pdf/2211.03447" title="Download PDF">pdf</a>, <a href="/format/2211.03447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Set Covering to Generate Databases for Holistic Steganalysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abecidan%2C+R">Rony Abecidan</a> (CRIStAL, CNRS), 
<a href="/search/cs?searchtype=author&query=Itier%2C+V">Vincent Itier</a> (CRIStAL, IMT Nord Europe, CNRS), 
<a href="/search/cs?searchtype=author&query=Boulanger%2C+J">J&#xe9;r&#xe9;mie Boulanger</a> (CRIStAL, CNRS), 
<a href="/search/cs?searchtype=author&query=Bas%2C+P">Patrick Bas</a> (CRIStAL, CNRS), 
<a href="/search/cs?searchtype=author&query=Pevn%C3%BD%2C+T">Tom&#xe1;&#x161; Pevn&#xfd;</a> (CTU)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Workshop on Information Forensics and Security (WIFS 2022), Dec 2022, Shanghai, China
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08843" title="Abstract">arXiv:2211.08843</a> (replaced) [<a href="/pdf/2211.08843" title="Download PDF">pdf</a>, <a href="/format/2211.08843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Speech Emotion Recognition with Unsupervised Speaking Style  Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Leyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+P">Pengcheng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11394" title="Abstract">arXiv:2212.11394</a> (replaced) [<a href="/pdf/2212.11394" title="Download PDF">pdf</a>, <a href="/format/2212.11394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skefl: Single-Key Homomorphic Encryption for Secure Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongfang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00062" title="Abstract">arXiv:2301.00062</a> (replaced) [<a href="/pdf/2301.00062" title="Download PDF">pdf</a>, <a href="/ps/2301.00062" title="Download PostScript">ps</a>, <a href="/format/2301.00062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIPS Compliant Quantum Secure Communication using Quantum Permutation  Pad
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=He%2C+A">Alex He</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lou%2C+D">Dafu Lou</a>, 
<a href="/search/quant-ph?searchtype=author&query=She%2C+E">Eric She</a>, 
<a href="/search/quant-ph?searchtype=author&query=Guo%2C+S">Shangjie Guo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Watson%2C+H">Hareesh Watson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Weng%2C+S">Sibyl Weng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perepechaenko%2C+M">Maria Perepechaenko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kuang%2C+R">Rand Kuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, to be submitted for a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00462" title="Abstract">arXiv:2301.00462</a> (replaced) [<a href="/pdf/2301.00462" title="Download PDF">pdf</a>, <a href="/format/2301.00462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Latent Space Correlation-Aware Autoencoder for Anomaly Detection in  Skewed Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Padmaksha Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00812" title="Abstract">arXiv:2301.00812</a> (replaced) [<a href="/pdf/2301.00812" title="Download PDF">pdf</a>, <a href="/ps/2301.00812" title="Download PostScript">ps</a>, <a href="/format/2301.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot domain adaptation in video-based assessment of surgical skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yanik%2C+E">Erim Yanik</a>, 
<a href="/search/cs?searchtype=author&query=Schwaitzberg%2C+S">Steven Schwaitzberg</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gene Yang</a>, 
<a href="/search/cs?searchtype=author&query=Intes%2C+X">Xavier Intes</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+S">Suvranu De</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages (+9 pages of Supplementary Materials), 4 figures (+2 Supplementary Figures), 2 tables (+5 Supplementary Tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02288" title="Abstract">arXiv:2301.02288</a> (replaced) [<a href="/pdf/2301.02288" title="Download PDF">pdf</a>, <a href="/format/2301.02288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gRoMA: a Tool for Measuring the Global Robustness of Deep Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levy%2C+N">Natan Levy</a>, 
<a href="/search/cs?searchtype=author&query=Yerushalmi%2C+R">Raz Yerushalmi</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+G">Guy Katz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04027" title="Abstract">arXiv:2301.04027</a> (replaced) [<a href="/pdf/2301.04027" title="Download PDF">pdf</a>, <a href="/ps/2301.04027" title="Download PostScript">ps</a>, <a href="/format/2301.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable modeling to unify machine learning and physical models  and advance Geosciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chaopeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Appling%2C+A+P">Alison P. Appling</a>, 
<a href="/search/cs?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>, 
<a href="/search/cs?searchtype=author&query=Bandai%2C+T">Toshiyuki Bandai</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+H">Hoshin Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tartakovsky%2C+A">Alexandre Tartakovsky</a>, 
<a href="/search/cs?searchtype=author&query=Baity-Jesi%2C+M">Marco Baity-Jesi</a>, 
<a href="/search/cs?searchtype=author&query=Fenicia%2C+F">Fabrizio Fenicia</a>, 
<a href="/search/cs?searchtype=author&query=Kifer%2C+D">Daniel Kifer</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+C+J">Ciaran J. Harman</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+M">Martyn Clark</a>, 
<a href="/search/cs?searchtype=author&query=Farthing%2C+M">Matthew Farthing</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dapeng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Praveen Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Aboelyazeed%2C+D">Doaa Aboelyazeed</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+F">Farshid Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Beck%2C+H+E">Hylke E. Beck</a>, 
<a href="/search/cs?searchtype=author&query=Bindas%2C+T">Tadd Bindas</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+D">Dipankar Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kuai Fang</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6ge%2C+M">Marvin H&#xf6;ge</a>, 
<a href="/search/cs?searchtype=author&query=Rackauckas%2C+C">Chris Rackauckas</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+T">Tirthankar Roy</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chonggang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mohanty%2C+B">Binayak Mohanty</a>, 
<a href="/search/cs?searchtype=author&query=Lawson%2C+K">Kathryn Lawson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat Rev Earth Environ 4, 552-567 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Atmospheric and Oceanic Physics (physics.ao-ph); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07629" title="Abstract">arXiv:2301.07629</a> (replaced) [<a href="/pdf/2301.07629" title="Download PDF">pdf</a>, <a href="/format/2301.07629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalisation Through Negation and Predicate Invention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerna%2C+D+M">David M. Cerna</a>, 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11572" title="Abstract">arXiv:2301.11572</a> (replaced) [<a href="/pdf/2301.11572" title="Download PDF">pdf</a>, <a href="/format/2301.11572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noncontact Haptic Rendering of Static Contact with Convex Surface Using  Circular Movement of Ultrasound Focus on a Finger Pad
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morisaki%2C+T">Tao Morisaki</a>, 
<a href="/search/cs?searchtype=author&query=Fujiwara%2C+M">Masahiro Fujiwara</a>, 
<a href="/search/cs?searchtype=author&query=Makino%2C+Y">Yasutoshi Makino</a>, 
<a href="/search/cs?searchtype=author&query=Shinoda%2C+H">Hiroyuki Shinoda</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Haptics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00209" title="Abstract">arXiv:2302.00209</a> (replaced) [<a href="/pdf/2302.00209" title="Download PDF">pdf</a>, <a href="/format/2302.00209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Large Certified Radius in Randomized Smoothing using  Quasiconcave Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kung%2C+B">Bo-Han Kung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shang-Tse Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03791" title="Abstract">arXiv:2302.03791</a> (replaced) [<a href="/pdf/2302.03791" title="Download PDF">pdf</a>, <a href="/format/2302.03791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Trust Your Diffusion Model: A Convex Optimization Approach to  Conformal Risk Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Teneggi%2C+J">Jacopo Teneggi</a>, 
<a href="/search/stat?searchtype=author&query=Tivnan%2C+M">Matthew Tivnan</a>, 
<a href="/search/stat?searchtype=author&query=Stayman%2C+J+W">J. Webster Stayman</a>, 
<a href="/search/stat?searchtype=author&query=Sulam%2C+J">Jeremias Sulam</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Machine Learning (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04668" title="Abstract">arXiv:2302.04668</a> (replaced) [<a href="/pdf/2302.04668" title="Download PDF">pdf</a>, <a href="/format/2302.04668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Equations in the Time Warp Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Gool%2C+S">Sam van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Guatto%2C+A">Adrien Guatto</a>, 
<a href="/search/cs?searchtype=author&query=Metcalfe%2C+G">George Metcalfe</a>, 
<a href="/search/cs?searchtype=author&query=Santschi%2C+S">Simon Santschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06504" title="Abstract">arXiv:2302.06504</a> (replaced) [<a href="/pdf/2302.06504" title="Download PDF">pdf</a>, <a href="/format/2302.06504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preconditioned Score-based Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hengyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianfeng Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11048" title="Abstract">arXiv:2302.11048</a> (replaced) [<a href="/pdf/2302.11048" title="Download PDF">pdf</a>, <a href="/format/2302.11048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Model for Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+M">Mohak Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tengyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Ching-An Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Neural Information Processing Systems (NeurIPS), 2023. Mohak Bhardwaj and Tengyang Xie contributed equally to this work. arXiv admin note: text overlap with <a href="/abs/2211.04538">arXiv:2211.04538</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13390" title="Abstract">arXiv:2302.13390</a> (replaced) [<a href="/pdf/2302.13390" title="Download PDF">pdf</a>, <a href="/format/2302.13390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDF-Net for abnormality detection by fusing X-rays with clinical data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hsieh%2C+C">Chihcheng Hsieh</a>, 
<a href="/search/eess?searchtype=author&query=Nobre%2C+I+B">Isabel Blanco Nobre</a>, 
<a href="/search/eess?searchtype=author&query=Sousa%2C+S+C">Sandra Costa Sousa</a>, 
<a href="/search/eess?searchtype=author&query=Ouyang%2C+C">Chun Ouyang</a>, 
<a href="/search/eess?searchtype=author&query=Brereton%2C+M">Margot Brereton</a>, 
<a href="/search/eess?searchtype=author&query=Nascimento%2C+J+C">Jacinto C. Nascimento</a>, 
<a href="/search/eess?searchtype=author&query=Jorge%2C+J">Joaquim Jorge</a>, 
<a href="/search/eess?searchtype=author&query=Moreira%2C+C">Catarina Moreira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14298" title="Abstract">arXiv:2302.14298</a> (replaced) [<a href="/pdf/2302.14298" title="Download PDF">pdf</a>, <a href="/format/2302.14298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIWO: Lidar-Inertial-Wheel Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zikang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+F">Fengtian Lang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianle Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, has published on IROS 2023. arXiv admin note: substantial text overlap with <a href="/abs/2210.10424">arXiv:2210.10424</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00328" title="Abstract">arXiv:2303.00328</a> (replaced) [<a href="/pdf/2303.00328" title="Download PDF">pdf</a>, <a href="/format/2303.00328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Total Matching Polytope of Complete Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faenza%2C+Y">Yuri Faenza</a>, 
<a href="/search/cs?searchtype=author&query=Ferrarini%2C+L">Luca Ferrarini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01234" title="Abstract">arXiv:2303.01234</a> (replaced) [<a href="/pdf/2303.01234" title="Download PDF">pdf</a>, <a href="/format/2303.01234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frauds Bargain Attack: Generating Adversarial Text Samples via Word  Manipulation Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+M">Mingze Ni</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhensu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01325" title="Abstract">arXiv:2303.01325</a> (replaced) [<a href="/pdf/2303.01325" title="Download PDF">pdf</a>, <a href="/format/2303.01325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pathway Towards Responsible AI Generated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lingjuan Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01633" title="Abstract">arXiv:2303.01633</a> (replaced) [<a href="/pdf/2303.01633" title="Download PDF">pdf</a>, <a href="/format/2303.01633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Future Connectivity: A Contemporary Survey on  AI-empowered Satellite-based Non-Terrestrial Networks in 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahboob%2C+S">Shadab Mahboob</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 20 Figures, 10 Tables, Survey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02392" title="Abstract">arXiv:2303.02392</a> (replaced) [<a href="/pdf/2303.02392" title="Download PDF">pdf</a>, <a href="/format/2303.02392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Quality Assessment for User Generated Content: Database and  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yuqin Cao</a>, 
<a href="/search/eess?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaoping Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02862" title="Abstract">arXiv:2303.02862</a> (replaced) [<a href="/pdf/2303.02862" title="Download PDF">pdf</a>, <a href="/format/2303.02862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jianping Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahe Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaoming Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boxin Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03379" title="Abstract">arXiv:2303.03379</a> (replaced) [<a href="/pdf/2303.03379" title="Download PDF">pdf</a>, <a href="/format/2303.03379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUREL+: Moving from Walks to Sets for Scalable Subgraph-based Graph  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Haoteng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianguo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of the full paper that appeared in PVLDB 16.11(VLDB 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03428" title="Abstract">arXiv:2303.03428</a> (replaced) [<a href="/pdf/2303.03428" title="Download PDF">pdf</a>, <a href="/format/2303.03428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards provably efficient quantum algorithms for large-scale  machine-learning models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+M">Minzhao Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Jin-Peng Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ye%2C+Z">Ziyu Ye</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Yunfei Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alexeev%2C+Y">Yuri Alexeev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eisert%2C+J">Jens Eisert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+L">Liang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7+40 pages, 3+10 figures, replaced with final version providing substantial detail
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07884" title="Abstract">arXiv:2303.07884</a> (replaced) [<a href="/pdf/2303.07884" title="Download PDF">pdf</a>, <a href="/format/2303.07884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed least square solution method to linear algebraic equations  over multiagent networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pham%2C+V+H">Viet Hoang Pham</a>, 
<a href="/search/eess?searchtype=author&query=Ahn%2C+H">Hyo-Sung Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I need to correct some unclear points in the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08336" title="Abstract">arXiv:2303.08336</a> (replaced) [<a href="/pdf/2303.08336" title="Download PDF">pdf</a>, <a href="/ps/2303.08336" title="Download PostScript">ps</a>, <a href="/format/2303.08336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Frame Patching for FoV-based Point Cloud Video Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+T">Tongyu Zong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yixiang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09287" title="Abstract">arXiv:2303.09287</a> (replaced) [<a href="/pdf/2303.09287" title="Download PDF">pdf</a>, <a href="/format/2303.09287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semitopology: a survey of a topological approach to distributed  collaborative action
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabbay%2C+M">Murdoch Gabbay</a>, 
<a href="/search/cs?searchtype=author&query=Losa%2C+G">Giuliano Losa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See also <a href="/abs/2310.00956">arXiv:2310.00956</a>, which takes a point-free algebraic approach ("semiframes")
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); General Topology (math.GN); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10526" title="Abstract">arXiv:2303.10526</a> (replaced) [<a href="/pdf/2303.10526" title="Download PDF">pdf</a>, <a href="/format/2303.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient deadlock avoidance for 2D mesh NoCs that use OQ or VOQ routers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papaphilippou%2C+P">Philippos Papaphilippou</a>, 
<a href="/search/cs?searchtype=author&query=Van+Chu%2C+T">Thiem Van Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14582" title="Abstract">arXiv:2303.14582</a> (replaced) [<a href="/pdf/2303.14582" title="Download PDF">pdf</a>, <a href="/format/2303.14582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Negative Transfers in Multitask Learning Using  Surrogate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+L">Huy L. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H+R">Hongyang R. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages. Appeared in TMLR'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04027" title="Abstract">arXiv:2304.04027</a> (replaced) [<a href="/pdf/2304.04027" title="Download PDF">pdf</a>, <a href="/format/2304.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeBLa: Neural Beer-Lambert for 3D Reconstruction of Oral Structures from  Panoramic Radiographs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+S">Sihwa Park</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Seongjun Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kwon%2C+D">Doeyoung Kwon</a>, 
<a href="/search/eess?searchtype=author&query=Jang%2C+Y">Yohan Jang</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+I">In-Seok Song</a>, 
<a href="/search/eess?searchtype=author&query=Baek%2C+S">Seungjun Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05430" title="Abstract">arXiv:2304.05430</a> (replaced) [<a href="/pdf/2304.05430" title="Download PDF">pdf</a>, <a href="/format/2304.05430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning Across Heterogeneous Features For Efficient Tensor  Program Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+G">Gaurav Verma</a>, 
<a href="/search/cs?searchtype=author&query=Raskar%2C+S">Siddhisanket Raskar</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+A+M">Abid M Malik</a>, 
<a href="/search/cs?searchtype=author&query=Emani%2C+M">Murali Emani</a>, 
<a href="/search/cs?searchtype=author&query=Chapman%2C+B">Barbara Chapman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05977" title="Abstract">arXiv:2304.05977</a> (replaced) [<a href="/pdf/2304.05977" title="Download PDF">pdf</a>, <a href="/format/2304.05977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImageReward: Learning and Evaluating Human Preferences for Text-to-Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiazheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yuxuan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinkai Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08009" title="Abstract">arXiv:2304.08009</a> (replaced) [<a href="/pdf/2304.08009" title="Download PDF">pdf</a>, <a href="/ps/2304.08009" title="Download PostScript">ps</a>, <a href="/format/2304.08009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel higher-order numerical method for parabolic integro-fractional  differential equations based on wavelets and $L2$-$1_&#x3c3;$ scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Santra%2C+S">Sudarshan Santra</a>, 
<a href="/search/math?searchtype=author&query=Behera%2C+R">Ratikanta Behera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08818" title="Abstract">arXiv:2304.08818</a> (replaced) [<a href="/pdf/2304.08818" title="Download PDF">pdf</a>, <a href="/format/2304.08818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align your Latents: High-Resolution Video Synthesis with Latent  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blattmann%2C+A">Andreas Blattmann</a>, 
<a href="/search/cs?searchtype=author&query=Rombach%2C+R">Robin Rombach</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Huan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Dockhorn%2C+T">Tim Dockhorn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+W">Seung Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+K">Karsten Kreis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Computer Vision and Pattern Recognition (CVPR) 2023. Project page: <a href="https://research.nvidia.com/labs/toronto-ai/VideoLDM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09870" title="Abstract">arXiv:2304.09870</a> (replaced) [<a href="/pdf/2304.09870" title="Download PDF">pdf</a>, <a href="/format/2304.09870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yifan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Kuba%2C+J+G">Jakub Grudzien Kuba</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiaming Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14530" title="Abstract">arXiv:2304.14530</a> (replaced) [<a href="/pdf/2304.14530" title="Download PDF">pdf</a>, <a href="/format/2304.14530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating images of rare concepts using pre-trained diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samuel%2C+D">Dvir Samuel</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Ari%2C+R">Rami Ben-Ari</a>, 
<a href="/search/cs?searchtype=author&query=Raviv%2C+S">Simon Raviv</a>, 
<a href="/search/cs?searchtype=author&query=Darshan%2C+N">Nir Darshan</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+G">Gal Chechik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00140" title="Abstract">arXiv:2305.00140</a> (replaced) [<a href="/pdf/2305.00140" title="Download PDF">pdf</a>, <a href="/format/2305.00140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space reduction techniques for the $3$-wise Kemeny problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phung%2C+X+K">Xuan Kien Phung</a>, 
<a href="/search/cs?searchtype=author&query=Hamel%2C+S">Sylvie Hamel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> several improvements included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01420" title="Abstract">arXiv:2305.01420</a> (replaced) [<a href="/pdf/2305.01420" title="Download PDF">pdf</a>, <a href="/format/2305.01420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Subquadratic Bound for Online Bisection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bienkowski%2C+M">Marcin Bienkowski</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03236" title="Abstract">arXiv:2305.03236</a> (replaced) [<a href="/pdf/2305.03236" title="Download PDF">pdf</a>, <a href="/format/2305.03236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Out-of-Distribution Detection in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lang%2C+H">Hao Lang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05121" title="Abstract">arXiv:2305.05121</a> (replaced) [<a href="/pdf/2305.05121" title="Download PDF">pdf</a>, <a href="/format/2305.05121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Solutions to Large-Graph MST Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhalla%2C+A">Arjun Bhalla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08559" title="Abstract">arXiv:2305.08559</a> (replaced) [<a href="/pdf/2305.08559" title="Download PDF">pdf</a>, <a href="/format/2305.08559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Discontinuities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferwana%2C+I">Ibtihal Ferwana</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Suyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ting-Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version is accepted in Neural Compression ICML Worksop July 19th, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08777" title="Abstract">arXiv:2305.08777</a> (replaced) [<a href="/pdf/2305.08777" title="Download PDF">pdf</a>, <a href="/format/2305.08777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question-Answering System Extracts Information on Injection Drug Use  from Clinical Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahbub%2C+M">Maria Mahbub</a>, 
<a href="/search/cs?searchtype=author&query=Goethert%2C+I">Ian Goethert</a>, 
<a href="/search/cs?searchtype=author&query=Danciu%2C+I">Ioana Danciu</a>, 
<a href="/search/cs?searchtype=author&query=Knight%2C+K">Kathryn Knight</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Sudarshan Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Tamang%2C+S">Suzanne Tamang</a>, 
<a href="/search/cs?searchtype=author&query=Rozenberg-Ben-Dror%2C+K">Karine Rozenberg-Ben-Dror</a>, 
<a href="/search/cs?searchtype=author&query=Solares%2C+H">Hugo Solares</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+S">Susana Martins</a>, 
<a href="/search/cs?searchtype=author&query=Trafton%2C+J">Jodie Trafton</a>, 
<a href="/search/cs?searchtype=author&query=Begoli%2C+E">Edmon Begoli</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+G">Gregory Peterson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 11 tables, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09480" title="Abstract">arXiv:2305.09480</a> (replaced) [<a href="/pdf/2305.09480" title="Download PDF">pdf</a>, <a href="/format/2305.09480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Gate MLP with Protein Complex Invariant Embedding is A One-Shot  Antibody Designer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/q-bio?searchtype=author&query=Zheng%2C+J">Jiangbin Zheng</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+B">Bozhen Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12066" title="Abstract">arXiv:2305.12066</a> (replaced) [<a href="/pdf/2305.12066" title="Download PDF">pdf</a>, <a href="/format/2305.12066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Models Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+K">Kaleel Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hui Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12467" title="Abstract">arXiv:2305.12467</a> (replaced) [<a href="/pdf/2305.12467" title="Download PDF">pdf</a>, <a href="/format/2305.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Multi-phase Optimization Dynamics and Rich Nonlinear  Behaviors of ReLU Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 94 pages, NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13033" title="Abstract">arXiv:2305.13033</a> (replaced) [<a href="/pdf/2305.13033" title="Download PDF">pdf</a>, <a href="/format/2305.13033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards generalizing deep-audio fake detection networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gasenzer%2C+K">Konstantin Gasenzer</a> (1), 
<a href="/search/cs?searchtype=author&query=Wolter%2C+M">Moritz Wolter</a> (1) ((1) High Performance Computing and Analytics Lab, Universit&#xe4;t Bonn, Germany)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15581" title="Abstract">arXiv:2305.15581</a> (replaced) [<a href="/pdf/2305.15581" title="Download PDF">pdf</a>, <a href="/format/2305.15581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Semantic Correspondence Using Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hedlin%2C+E">Eric Hedlin</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gopal Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+S">Shweta Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Isack%2C+H">Hossam Isack</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+A">Abhishek Kar</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://github.com/ubc-vision/LDM_correspondences">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17214" title="Abstract">arXiv:2305.17214</a> (replaced) [<a href="/pdf/2305.17214" title="Download PDF">pdf</a>, <a href="/format/2305.17214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast, Attend and Diffuse to Decode High-Resolution Images from Brain  Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18365" title="Abstract">arXiv:2305.18365</a> (replaced) [<a href="/pdf/2305.18365" title="Download PDF">pdf</a>, <a href="/format/2305.18365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What can Large Language Models do in chemistry? A comprehensive  benchmark on eight tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Taicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kehan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+B">Bozhao Nan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhenwen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhichun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Wiest%2C+O">Olaf Wiest</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19082" title="Abstract">arXiv:2305.19082</a> (replaced) [<a href="/pdf/2305.19082" title="Download PDF">pdf</a>, <a href="/format/2305.19082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding Inequalities for Barron-type Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19442" title="Abstract">arXiv:2305.19442</a> (replaced) [<a href="/pdf/2305.19442" title="Download PDF">pdf</a>, <a href="/format/2305.19442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimFBO: Towards Simple, Flexible and Communication-efficient Federated  Bilevel Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Peiyao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaiyi Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19926" title="Abstract">arXiv:2305.19926</a> (replaced) [<a href="/pdf/2305.19926" title="Download PDF">pdf</a>, <a href="/format/2305.19926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Reliability of Psychological Scales on Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+M+H">Man Ho Lam</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E+J">Eric John Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. Added more comprehensive experiments and analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00789" title="Abstract">arXiv:2306.00789</a> (replaced) [<a href="/pdf/2306.00789" title="Download PDF">pdf</a>, <a href="/ps/2306.00789" title="Download PostScript">ps</a>, <a href="/format/2306.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Lingual Transfer Learning for Low-Resource Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khurana%2C+S">Sameer Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Dawalatabad%2C+N">Nauman Dawalatabad</a>, 
<a href="/search/cs?searchtype=author&query=Laurent%2C+A">Antoine Laurent</a>, 
<a href="/search/cs?searchtype=author&query=Vicente%2C+L">Luis Vicente</a>, 
<a href="/search/cs?searchtype=author&query=Gimeno%2C+P">Pablo Gimeno</a>, 
<a href="/search/cs?searchtype=author&query=Mingote%2C+V">Victoria Mingote</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+J+L">Jonathan Le Roux</a>, 
<a href="/search/cs?searchtype=author&query=Glass%2C+J">James Glass</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03502" title="Abstract">arXiv:2306.03502</a> (replaced) [<a href="/pdf/2306.03502" title="Download PDF">pdf</a>, <a href="/format/2306.03502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Russo-Ukrainian War: Prediction and explanation of Twitter suspension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shevtsov%2C+A">Alexander Shevtsov</a>, 
<a href="/search/cs?searchtype=author&query=Antonakaki%2C+D">Despoina Antonakaki</a>, 
<a href="/search/cs?searchtype=author&query=Lamprou%2C+I">Ioannis Lamprou</a>, 
<a href="/search/cs?searchtype=author&query=Kontogiorgakis%2C+I">Ioannis Kontogiorgakis</a>, 
<a href="/search/cs?searchtype=author&query=Pratikakis%2C+P">Polyvios Pratikakis</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S">Sotiris Ioannidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04047" title="Abstract">arXiv:2306.04047</a> (replaced) [<a href="/pdf/2306.04047" title="Download PDF">pdf</a>, <a href="/format/2306.04047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual  Navigation in Noisy Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiulong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Sudipta Paul</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+M">Moitreya Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Cherian%2C+A">Anoop Cherian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04487" title="Abstract">arXiv:2306.04487</a> (replaced) [<a href="/pdf/2306.04487" title="Download PDF">pdf</a>, <a href="/format/2306.04487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Vague Preference Policy Learning for Multi-round Conversational  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gangyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaojie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongshen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhuozhi Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sulong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04990" title="Abstract">arXiv:2306.04990</a> (replaced) [<a href="/pdf/2306.04990" title="Download PDF">pdf</a>, <a href="/format/2306.04990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Architecture Multi-Expert Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yunsung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin-Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Go%2C+H">Hyojun Go</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Myeongho Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Shinhyeok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seungtaek Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the AAAI 2024 Proceedings Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05246" title="Abstract">arXiv:2306.05246</a> (replaced) [<a href="/pdf/2306.05246" title="Download PDF">pdf</a>, <a href="/format/2306.05246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Task-driven Network for Mesh Classification and Semantic Part  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiujie Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xiaoran Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuangmin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+S">Shiqing Xin</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Changhe Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08659" title="Abstract">arXiv:2306.08659</a> (replaced) [<a href="/pdf/2306.08659" title="Download PDF">pdf</a>, <a href="/format/2306.08659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore In-Context Learning for 3D Point Cloud Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhongbin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>, 
<a href="/search/cs?searchtype=author&query=Buhmann%2C+J+M">Joachim M. Buhmann</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/fanglaosi/Point-In-Context">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08832" title="Abstract">arXiv:2306.08832</a> (replaced) [<a href="/pdf/2306.08832" title="Download PDF">pdf</a>, <a href="/format/2306.08832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to  Enhance Visio-Linguistic Compositional Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Awal%2C+R">Rabiul Awal</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Aishwarya Agrawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11203" title="Abstract">arXiv:2306.11203</a> (replaced) [<a href="/pdf/2306.11203" title="Download PDF">pdf</a>, <a href="/format/2306.11203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVOIDDS: Aircraft Vision-based Intruder Detection Dataset and Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smyers%2C+E+Q">Elysia Q. Smyers</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+S+M">Sydney M. Katz</a>, 
<a href="/search/cs?searchtype=author&query=Corso%2C+A+L">Anthony L. Corso</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to and presented at NeurIPS 2023, Datasets and Benchmarks Track; fixed link formatting in the abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11975" title="Abstract">arXiv:2306.11975</a> (replaced) [<a href="/pdf/2306.11975" title="Download PDF">pdf</a>, <a href="/format/2306.11975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGEMM on Integer Matrix Multiplication Unit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ootomo%2C+H">Hiroyuki Ootomo</a>, 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+K">Katsuhisa Ozaki</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+R">Rio Yokota</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12835" title="Abstract">arXiv:2306.12835</a> (replaced) [<a href="/pdf/2306.12835" title="Download PDF">pdf</a>, <a href="/format/2306.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microscopic, kinetic and hydrodynamic hybrid models of collective  motions withchemotaxis: a numerical study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Menci%2C+M">Marta Menci</a> ( UCBM), 
<a href="/search/math?searchtype=author&query=Natalini%2C+R">Roberto Natalini</a> (IAC), 
<a href="/search/math?searchtype=author&query=Paul%2C+T">Thierry Paul</a> (LJLL (UMR\_7598), LYSM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14731" title="Abstract">arXiv:2306.14731</a> (replaced) [<a href="/pdf/2306.14731" title="Download PDF">pdf</a>, <a href="/format/2306.14731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Locality and Robustness to Achieve Massively Scalable  Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Allison%2C+R">Robert Allison</a>, 
<a href="/search/stat?searchtype=author&query=Stephenson%2C+A">Anthony Stephenson</a>, 
<a href="/search/stat?searchtype=author&query=F%2C+S">Samuel F</a>, 
<a href="/search/stat?searchtype=author&query=Pyzer-Knapp%2C+E">Edward Pyzer-Knapp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17052" title="Abstract">arXiv:2306.17052</a> (replaced) [<a href="/pdf/2306.17052" title="Download PDF">pdf</a>, <a href="/format/2306.17052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jusup%2C+M">Matej Jusup</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A1sztor%2C+B">Barna P&#xe1;sztor</a>, 
<a href="/search/cs?searchtype=author&query=Janik%2C+T">Tadeusz Janik</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kenan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Corman%2C+F">Francesco Corman</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/cs?searchtype=author&query=Bogunovic%2C+I">Ilija Bogunovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 26 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17648" title="Abstract">arXiv:2306.17648</a> (replaced) [<a href="/pdf/2306.17648" title="Download PDF">pdf</a>, <a href="/format/2306.17648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing training of physics-informed neural networks using  domain-decomposition based preconditioning strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kopani%C4%8D%C3%A1kov%C3%A1%2C+A">Alena Kopani&#x10d;&#xe1;kov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Kothari%2C+H">Hardik Kothari</a>, 
<a href="/search/math?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+R">Rolf Krause</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17778" title="Abstract">arXiv:2306.17778</a> (replaced) [<a href="/pdf/2306.17778" title="Download PDF">pdf</a>, <a href="/format/2306.17778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look, Remember and Reason: Grounded reasoning in videos with language  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+A">Apratim Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Panchal%2C+S">Sunny Panchal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pourreza%2C+R">Reza Pourreza</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+P">Pulkit Madan</a>, 
<a href="/search/cs?searchtype=author&query=Memisevic%2C+R">Roland Memisevic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03952" title="Abstract">arXiv:2307.03952</a> (replaced) [<a href="/pdf/2307.03952" title="Download PDF">pdf</a>, <a href="/format/2307.03952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT a Good Personality Recognizer? A Preliminary Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04087" title="Abstract">arXiv:2307.04087</a> (replaced) [<a href="/pdf/2307.04087" title="Download PDF">pdf</a>, <a href="/format/2307.04087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVIT: Scaling up Visual Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boya Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Muyang He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06104" title="Abstract">arXiv:2307.06104</a> (replaced) [<a href="/pdf/2307.06104" title="Download PDF">pdf</a>, <a href="/format/2307.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning for dynamic graphs: models and benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gravina%2C+A">Alessio Gravina</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06535" title="Abstract">arXiv:2307.06535</a> (replaced) [<a href="/pdf/2307.06535" title="Download PDF">pdf</a>, <a href="/ps/2307.06535" title="Download PostScript">ps</a>, <a href="/format/2307.06535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Rectangular Matrix Multiplication by Combination Loss Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gall%2C+F+L">Fran&#xe7;ois Le Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages; v2: minor corrections; accepted to SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08202" title="Abstract">arXiv:2307.08202</a> (replaced) [<a href="/pdf/2307.08202" title="Download PDF">pdf</a>, <a href="/format/2307.08202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Next-Generation Urban Connectivity: Is Integrated  HAPS-Terrestrial Network a Solution?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shamsabadi%2C+A+A">Afsoon Alidadi Shamsabadi</a>, 
<a href="/search/eess?searchtype=author&query=Yadav%2C+A">Animesh Yadav</a>, 
<a href="/search/eess?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages singlecolumn, 4 figures, under review in IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09259" title="Abstract">arXiv:2307.09259</a> (replaced) [<a href="/pdf/2307.09259" title="Download PDF">pdf</a>, <a href="/format/2307.09259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Topological Feature via Persistent Homology: Filtration  Learning for Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishikawa%2C+N">Naoki Nishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Ike%2C+Y">Yuichi Ike</a>, 
<a href="/search/cs?searchtype=author&query=Yamanishi%2C+K">Kenji Yamanishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages with 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09334" title="Abstract">arXiv:2307.09334</a> (replaced) [<a href="/pdf/2307.09334" title="Download PDF">pdf</a>, <a href="/format/2307.09334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating nonlinear functions with latent boundaries in low-rank  excitatory-inhibitory spiking networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Podlaski%2C+W+F">William F. Podlaski</a>, 
<a href="/search/q-bio?searchtype=author&query=Machens%2C+C+K">Christian K. Machens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Neural Computation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10422" title="Abstract">arXiv:2307.10422</a> (replaced) [<a href="/pdf/2307.10422" title="Download PDF">pdf</a>, <a href="/format/2307.10422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreDiff: Precipitation Nowcasting with Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhihan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xingjian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Boran Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaoyong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Maddix%2C+D">Danielle Maddix</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023. Camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11306" title="Abstract">arXiv:2307.11306</a> (replaced) [<a href="/pdf/2307.11306" title="Download PDF">pdf</a>, <a href="/ps/2307.11306" title="Download PostScript">ps</a>, <a href="/format/2307.11306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Guessing Under Log-Loss Distortion Allowing Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saito%2C+S">Shota Saito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11351" title="Abstract">arXiv:2307.11351</a> (replaced) [<a href="/pdf/2307.11351" title="Download PDF">pdf</a>, <a href="/format/2307.11351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded P-values in Parametric Programming-based Selective Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shiraishi%2C+T">Tomohiro Shiraishi</a>, 
<a href="/search/stat?searchtype=author&query=Miwa%2C+D">Daiki Miwa</a>, 
<a href="/search/stat?searchtype=author&query=Duy%2C+V+N+L">Vo Nguyen Le Duy</a>, 
<a href="/search/stat?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48pages, 14figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12448" title="Abstract">arXiv:2307.12448</a> (replaced) [<a href="/pdf/2307.12448" title="Download PDF">pdf</a>, <a href="/format/2307.12448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Consistent Hashing in Constant Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leu%2C+E">Eric Leu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures. U.S. Patent No. 11,429,452 was granted on August 30, 2022, for the invention
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13165" title="Abstract">arXiv:2307.13165</a> (replaced) [<a href="/pdf/2307.13165" title="Download PDF">pdf</a>, <a href="/format/2307.13165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Robustness of Sequential Recommender Systems Against  Training Data Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Betello%2C+F">Filippo Betello</a>, 
<a href="/search/cs?searchtype=author&query=Siciliano%2C+F">Federico Siciliano</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Pushkar Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14406" title="Abstract">arXiv:2307.14406</a> (replaced) [<a href="/pdf/2307.14406" title="Download PDF">pdf</a>, <a href="/format/2307.14406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Code Snippets in Code Reviews: A Study of the OpenStack and  Qt Communities and A Practitioner Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Liming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiaxin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 9 images, 16 tables, Manuscript submitted to a Journal (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16082" title="Abstract">arXiv:2307.16082</a> (replaced) [<a href="/pdf/2307.16082" title="Download PDF">pdf</a>, <a href="/format/2307.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnrichEvent: Enriching Social Data with Contextual Information for  Emerging Event Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esfahani%2C+M+S">Mohammadali Sefidi Esfahani</a>, 
<a href="/search/cs?searchtype=author&query=Akbari%2C+M">Mohammad Akbari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03549" title="Abstract">arXiv:2308.03549</a> (replaced) [<a href="/pdf/2308.03549" title="Download PDF">pdf</a>, <a href="/format/2308.03549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language  Model through Expert Feedback and Real-world Multi-turn Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songhua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Senbin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guangyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuxiang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zan%2C+H">Hongying Zan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10220" title="Abstract">arXiv:2308.10220</a> (replaced) [<a href="/pdf/2308.10220" title="Download PDF">pdf</a>, <a href="/format/2308.10220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing and Evaluating Presentation Strategies for Fact-Checked  Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hettiachchi%2C+D">Danula Hettiachchi</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+J">Jenny Kennedy</a>, 
<a href="/search/cs?searchtype=author&query=McCosker%2C+A">Anthony McCosker</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+M">Mark Sanderson</a>, 
<a href="/search/cs?searchtype=author&query=Scholer%2C+F">Falk Scholer</a>, 
<a href="/search/cs?searchtype=author&query=Spina%2C+D">Damiano Spina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10253" title="Abstract">arXiv:2308.10253</a> (replaced) [<a href="/pdf/2308.10253" title="Download PDF">pdf</a>, <a href="/format/2308.10253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized  Image-Dialogue Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanda Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/icoz69/StableLLAVA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11234" title="Abstract">arXiv:2308.11234</a> (replaced) [<a href="/pdf/2308.11234" title="Download PDF">pdf</a>, <a href="/format/2308.11234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Harabor%2C+D">Daniel Harabor</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Stuckey%2C+P+J">Peter J. Stuckey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11940" title="Abstract">arXiv:2308.11940</a> (replaced) [<a href="/pdf/2308.11940" title="Download PDF">pdf</a>, <a href="/format/2308.11940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Generation with Multiple Conditional Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhifang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jianguo Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Rui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Long Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ouchi%2C+K">Kazushige Ouchi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13074" title="Abstract">arXiv:2308.13074</a> (replaced) [<a href="/pdf/2308.13074" title="Download PDF">pdf</a>, <a href="/format/2308.13074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influences of Displaying Permission-related Information on Web Single  Sign-On Login Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morkonda%2C+S+G">Srivathsan G. Morkonda</a>, 
<a href="/search/cs?searchtype=author&query=Chiasson%2C+S">Sonia Chiasson</a>, 
<a href="/search/cs?searchtype=author&query=van+Oorschot%2C+P+C">Paul C. van Oorschot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13568" title="Abstract">arXiv:2308.13568</a> (replaced) [<a href="/pdf/2308.13568" title="Download PDF">pdf</a>, <a href="/format/2308.13568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Region-Disentangled Diffusion Model for High-Fidelity PPG-to-ECG  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shome%2C+D">Debaditya Shome</a>, 
<a href="/search/eess?searchtype=author&query=Sarkar%2C+P">Pritam Sarkar</a>, 
<a href="/search/eess?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14165" title="Abstract">arXiv:2308.14165</a> (replaced) [<a href="/pdf/2308.14165" title="Download PDF">pdf</a>, <a href="/format/2308.14165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Off-Policy Evaluation for Slate Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+S">Shreyas Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Arbour%2C+D">David Arbour</a>, 
<a href="/search/cs?searchtype=author&query=Theocharous%2C+G">Georgios Theocharous</a>, 
<a href="/search/cs?searchtype=author&query=Vlassis%2C+N">Nikos Vlassis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in The 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14512" title="Abstract">arXiv:2308.14512</a> (replaced) [<a href="/pdf/2308.14512" title="Download PDF">pdf</a>, <a href="/ps/2308.14512" title="Download PostScript">ps</a>, <a href="/format/2308.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A time-causal and time-recursive analogue of the Gabor transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lindeberg%2C+T">Tony Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15030" title="Abstract">arXiv:2308.15030</a> (replaced) [<a href="/pdf/2308.15030" title="Download PDF">pdf</a>, <a href="/format/2308.15030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwapMoE: Efficient Memory-Constrained Serving of Large Sparse MoE Models  via Dynamic Expert Pruning and Swapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+R">Rui Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qingtian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15366" title="Abstract">arXiv:2308.15366</a> (replaced) [<a href="/pdf/2308.15366" title="Download PDF">pdf</a>, <a href="/format/2308.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnomalyGPT: Detecting Industrial Anomalies Using Large Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaopeng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bingke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guibo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024; Project page: <a href="https://anomalygpt.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15478" title="Abstract">arXiv:2308.15478</a> (replaced) [<a href="/pdf/2308.15478" title="Download PDF">pdf</a>, <a href="/format/2308.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Tangent Feature Perspective of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=LeJeune%2C+D">Daniel LeJeune</a>, 
<a href="/search/cs?searchtype=author&query=Alemohammad%2C+S">Sina Alemohammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures. To appear at the First Conference on Parsimony and Learning (CPAL 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15645" title="Abstract">arXiv:2308.15645</a> (replaced) [<a href="/pdf/2308.15645" title="Download PDF">pdf</a>, <a href="/format/2308.15645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AskIt: Unified Programming Interface for Programming with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okuda%2C+K">Katsumi Okuda</a>, 
<a href="/search/cs?searchtype=author&query=Amarasinghe%2C+S">Saman Amarasinghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in 2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15736" title="Abstract">arXiv:2308.15736</a> (replaced) [<a href="/pdf/2308.15736" title="Download PDF">pdf</a>, <a href="/ps/2308.15736" title="Download PostScript">ps</a>, <a href="/format/2308.15736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerability of Machine Learning Approaches Applied in IoT-based Smart  Grid: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruilong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+M">Mo-Yuen Chow</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15920" title="Abstract">arXiv:2308.15920</a> (replaced) [<a href="/pdf/2308.15920" title="Download PDF">pdf</a>, <a href="/ps/2308.15920" title="Download PostScript">ps</a>, <a href="/format/2308.15920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saving temporary exhibitions in virtual environments: the Digital  Renaissance of Ulisse Aldrovandi -- acquisition and digitisation of cultural  heritage objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balzani%2C+R">Roberto Balzani</a>, 
<a href="/search/cs?searchtype=author&query=Barzaghi%2C+S">Sebastian Barzaghi</a>, 
<a href="/search/cs?searchtype=author&query=Bitelli%2C+G">Gabriele Bitelli</a>, 
<a href="/search/cs?searchtype=author&query=Bonifazi%2C+F">Federica Bonifazi</a>, 
<a href="/search/cs?searchtype=author&query=Bordignon%2C+A">Alice Bordignon</a>, 
<a href="/search/cs?searchtype=author&query=Cipriani%2C+L">Luca Cipriani</a>, 
<a href="/search/cs?searchtype=author&query=Colitti%2C+S">Simona Colitti</a>, 
<a href="/search/cs?searchtype=author&query=Collina%2C+F">Federica Collina</a>, 
<a href="/search/cs?searchtype=author&query=Daquino%2C+M">Marilena Daquino</a>, 
<a href="/search/cs?searchtype=author&query=Fabbri%2C+F">Francesca Fabbri</a>, 
<a href="/search/cs?searchtype=author&query=Fanini%2C+B">Bruno Fanini</a>, 
<a href="/search/cs?searchtype=author&query=Fantini%2C+F">Filippo Fantini</a>, 
<a href="/search/cs?searchtype=author&query=Ferdani%2C+D">Daniele Ferdani</a>, 
<a href="/search/cs?searchtype=author&query=Fiorini%2C+G">Giulia Fiorini</a>, 
<a href="/search/cs?searchtype=author&query=Formia%2C+E">Elena Formia</a>, 
<a href="/search/cs?searchtype=author&query=Forte%2C+A">Anna Forte</a>, 
<a href="/search/cs?searchtype=author&query=Giacomini%2C+F">Federica Giacomini</a>, 
<a href="/search/cs?searchtype=author&query=Girelli%2C+V+A">Valentina Alena Girelli</a>, 
<a href="/search/cs?searchtype=author&query=Gualandi%2C+B">Bianca Gualandi</a>, 
<a href="/search/cs?searchtype=author&query=Heibi%2C+I">Ivan Heibi</a>, 
<a href="/search/cs?searchtype=author&query=Iannucci%2C+A">Alessandro Iannucci</a>, 
<a href="/search/cs?searchtype=author&query=Del+F%C3%A0%2C+R+M">Rachele Manganelli Del F&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Massari%2C+A">Arcangelo Massari</a>, 
<a href="/search/cs?searchtype=author&query=Moretti%2C+A">Arianna Moretti</a>, 
<a href="/search/cs?searchtype=author&query=Peroni%2C+S">Silvio Peroni</a>, 
<a href="/search/cs?searchtype=author&query=Pescarin%2C+S">Sofia Pescarin</a>, 
<a href="/search/cs?searchtype=author&query=Renda%2C+G">Giulia Renda</a>, 
<a href="/search/cs?searchtype=author&query=Ronchi%2C+D">Diego Ronchi</a>, 
<a href="/search/cs?searchtype=author&query=Sullini%2C+M">Mattia Sullini</a>, 
<a href="/search/cs?searchtype=author&query=Tini%2C+M+A">Maria Alessandra Tini</a>, 
<a href="/search/cs?searchtype=author&query=Tomasi%2C+F">Francesca Tomasi</a>, 
<a href="/search/cs?searchtype=author&query=Travaglini%2C+L">Laura Travaglini</a>, 
<a href="/search/cs?searchtype=author&query=Vittuari%2C+L">Luca Vittuari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02772" title="Abstract">arXiv:2309.02772</a> (replaced) [<a href="/pdf/2309.02772" title="Download PDF">pdf</a>, <a href="/format/2309.02772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hot or Cold? Adaptive Temperature Sampling for Code Generation with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">YunFei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hong Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02842" title="Abstract">arXiv:2309.02842</a> (replaced) [<a href="/pdf/2309.02842" title="Download PDF">pdf</a>, <a href="/format/2309.02842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Postprocessing for Combinatorial Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morita%2C+K">Keisuke Morita</a>, 
<a href="/search/cs?searchtype=author&query=Nishikawa%2C+Y">Yoshihiko Nishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Ohzeki%2C+M">Masayuki Ohzeki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Phys. Soc. Jpn. 92, 123801 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04223" title="Abstract">arXiv:2309.04223</a> (replaced) [<a href="/pdf/2309.04223" title="Download PDF">pdf</a>, <a href="/format/2309.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HITA: An Architecture for System-level Testing of Healthcare IoT  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sartaj%2C+H">Hassan Sartaj</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Gj%C3%B8by%2C+J+M">Julie Marie Gj&#xf8;by</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the 17th European Conference on Software Architecture (ECSA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04672" title="Abstract">arXiv:2309.04672</a> (replaced) [<a href="/pdf/2309.04672" title="Download PDF">pdf</a>, <a href="/format/2309.04672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Renqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+J">Jingjing Luo</a>, 
<a href="/search/eess?searchtype=author&query=Nian%2C+F">Fan Nian</a>, 
<a href="/search/eess?searchtype=author&query=Cen%2C+Y">Yuhui Cen</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yiheng Peng</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zekuan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06014" title="Abstract">arXiv:2309.06014</a> (replaced) [<a href="/pdf/2309.06014" title="Download PDF">pdf</a>, <a href="/format/2309.06014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can large-scale vocoded spoofed data improve speech spoofing  countermeasure with a self-supervised front end?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yamagishi%2C+J">Junichi Yamagishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICASSP 2024. code on github: <a href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/project/10-asvspoof-vocoded-trn-ssl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07707" title="Abstract">arXiv:2309.07707</a> (replaced) [<a href="/pdf/2309.07707" title="Download PDF">pdf</a>, <a href="/format/2309.07707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLLD: Contrastive Layer-to-layer Distillation for Compressing  Multilingual Pre-trained Speech Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Heng-Jui Chang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Ning Dong</a>, 
<a href="/search/cs?searchtype=author&query=Mavlyutov%2C+R">Ruslan Mavlyutov</a>, 
<a href="/search/cs?searchtype=author&query=Popuri%2C+S">Sravya Popuri</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+Y">Yu-An Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08140" title="Abstract">arXiv:2309.08140</a> (replaced) [<a href="/pdf/2309.08140" title="Download PDF">pdf</a>, <a href="/format/2309.08140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech  Using Natural Language Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shimizu%2C+R">Reo Shimizu</a>, 
<a href="/search/eess?searchtype=author&query=Yamamoto%2C+R">Ryuichi Yamamoto</a>, 
<a href="/search/eess?searchtype=author&query=Kawamura%2C+M">Masaya Kawamura</a>, 
<a href="/search/eess?searchtype=author&query=Shirahata%2C+Y">Yuma Shirahata</a>, 
<a href="/search/eess?searchtype=author&query=Doi%2C+H">Hironori Doi</a>, 
<a href="/search/eess?searchtype=author&query=Komatsu%2C+T">Tatsuya Komatsu</a>, 
<a href="/search/eess?searchtype=author&query=Tachibana%2C+K">Kentaro Tachibana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08551" title="Abstract">arXiv:2309.08551</a> (replaced) [<a href="/pdf/2309.08551" title="Download PDF">pdf</a>, <a href="/format/2309.08551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting conformers with structured state-space sequence models for  online speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Haozhe Shan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Albert Gu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choromanski%2C+K">Krzysztof Choromanski</a>, 
<a href="/search/cs?searchtype=author&query=Sainath%2C+T">Tara Sainath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11646" title="Abstract">arXiv:2309.11646</a> (replaced) [<a href="/pdf/2309.11646" title="Download PDF">pdf</a>, <a href="/format/2309.11646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation of Machine Learning Approaches for Early Diagnosis of  Autism Spectrum Disorder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasul%2C+R+A">Rownak Ara Rasul</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+P">Promy Saha</a>, 
<a href="/search/cs?searchtype=author&query=Bala%2C+D">Diponkor Bala</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+S+M+R+U">S M Rakib Ul Karim</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+M+I">Md. Ibrahim Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+B">Bishwajit Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11820" title="Abstract">arXiv:2309.11820</a> (replaced) [<a href="/pdf/2309.11820" title="Download PDF">pdf</a>, <a href="/format/2309.11820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Endoscopic Ultrasound Station Recognition with Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramesh%2C+A">Abhijit Ramesh</a>, 
<a href="/search/eess?searchtype=author&query=Nandanan%2C+A">Anantha Nandanan</a>, 
<a href="/search/eess?searchtype=author&query=Boggavarapu%2C+N">Nikhil Boggavarapu</a>, 
<a href="/search/eess?searchtype=author&query=MD%2C+P+N">Priya Nair MD</a>, 
<a href="/search/eess?searchtype=author&query=Gressel%2C+G">Gilad Gressel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13108" title="Abstract">arXiv:2309.13108</a> (replaced) [<a href="/pdf/2309.13108" title="Download PDF">pdf</a>, <a href="/format/2309.13108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data is often loadable in short depth: Quantum circuits from tensor  networks for finance, images, fluids, and proteins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jumade%2C+R">Raghav Jumade</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sawaya%2C+N+P">Nicolas PD Sawaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13504" title="Abstract">arXiv:2309.13504</a> (replaced) [<a href="/pdf/2309.13504" title="Download PDF">pdf</a>, <a href="/format/2309.13504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Is All You Need For Blind Room Volume Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chunxi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+M">Maoshen Jia</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Meiran Li</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+C">Changchun Bao</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+W">Wenyu Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, to be published in proceedings of ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15556" title="Abstract">arXiv:2309.15556</a> (replaced) [<a href="/pdf/2309.15556" title="Download PDF">pdf</a>, <a href="/format/2309.15556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dense Flow Field for Highly-accurate Cross-view Camera  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenbo Song</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+X">Xianghui Ze</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yujiao Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00265" title="Abstract">arXiv:2310.00265</a> (replaced) [<a href="/pdf/2310.00265" title="Download PDF">pdf</a>, <a href="/ps/2310.00265" title="Download PostScript">ps</a>, <a href="/format/2310.00265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Describing weighted safety with weighted LTL over product  $&#x3c9;$-valuation monoids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandrali%2C+E">Eleni Mandrali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00806" title="Abstract">arXiv:2310.00806</a> (replaced) [<a href="/pdf/2310.00806" title="Download PDF">pdf</a>, <a href="/format/2310.00806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Design Principles for Frequentist Sequential Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunbei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeevi%2C+A">Assaf Zeevi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01824" title="Abstract">arXiv:2310.01824</a> (replaced) [<a href="/pdf/2310.01824" title="Download PDF">pdf</a>, <a href="/format/2310.01824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon  Decision-Making in Embodied AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+E">Emily Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhuoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Mart%C3%ADn%2C+R">Roberto Mart&#xed;n-Mart&#xed;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02508" title="Abstract">arXiv:2310.02508</a> (replaced) [<a href="/pdf/2310.02508" title="Download PDF">pdf</a>, <a href="/format/2310.02508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ophiuchus: Scalable Modeling of Protein Structures through Hierarchical  Coarse-graining SO(3)-Equivariant Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costa%2C+A+d+S">Allan dos Santos Costa</a>, 
<a href="/search/cs?searchtype=author&query=Mitnikov%2C+I">Ilan Mitnikov</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+M">Mario Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Ponnapati%2C+M">Manvitha Ponnapati</a>, 
<a href="/search/cs?searchtype=author&query=Smidt%2C+T">Tess Smidt</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+J">Joseph Jacobson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02911" title="Abstract">arXiv:2310.02911</a> (replaced) [<a href="/pdf/2310.02911" title="Download PDF">pdf</a>, <a href="/format/2310.02911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering the Crypto-shopper: Knowledge and Preferences of Consumers  Using Cryptocurrencies for Purchases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silenzi%2C+M">Massimiliano Silenzi</a>, 
<a href="/search/cs?searchtype=author&query=Cabuk%2C+U+C">Umut Can Cabuk</a>, 
<a href="/search/cs?searchtype=author&query=Karaarslan%2C+E">Enis Karaarslan</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+O">Omer Aydin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Cryptorefills Labs Research Paper. 13 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03149" title="Abstract">arXiv:2310.03149</a> (replaced) [<a href="/pdf/2310.03149" title="Download PDF">pdf</a>, <a href="/format/2310.03149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attributing Learned Concepts in Neural Networks to Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konz%2C+N">Nicholas Konz</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+C">Charles Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+M">Madelyn Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Jonathan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D">Davis Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ATTRIB Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03704" title="Abstract">arXiv:2310.03704</a> (replaced) [<a href="/pdf/2310.03704" title="Download PDF">pdf</a>, <a href="/format/2310.03704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose-Free Generalizable Rendering Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+P">Panwang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hanwen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04829" title="Abstract">arXiv:2310.04829</a> (replaced) [<a href="/pdf/2310.04829" title="Download PDF">pdf</a>, <a href="/format/2310.04829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How To Effectively Train An Ensemble Of Faster R-CNN Object Detectors To  Quantify Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akola%2C+D+M">Denis Mbey Akola</a>, 
<a href="/search/cs?searchtype=author&query=Franchi%2C+G">Gianni Franchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05305" title="Abstract">arXiv:2310.05305</a> (replaced) [<a href="/pdf/2310.05305" title="Download PDF">pdf</a>, <a href="/format/2310.05305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Equitable Ride-sharing Car Distribution in a Congested Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rastgoftar%2C+H">Hossein Rastgoftar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05858" title="Abstract">arXiv:2310.05858</a> (replaced) [<a href="/pdf/2310.05858" title="Download PDF">pdf</a>, <a href="/format/2310.05858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSAC-T: Distributional Soft Actor-Critic with Three Refinements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jingliang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Liming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07141" title="Abstract">arXiv:2310.07141</a> (replaced) [<a href="/pdf/2310.07141" title="Download PDF">pdf</a>, <a href="/ps/2310.07141" title="Download PostScript">ps</a>, <a href="/format/2310.07141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time and Frequency Offset Estimation and Intercarrier Interference  Cancellation for AFDM Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuankun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Anjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Miaowen Wen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+F">Fei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinming Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Wireless Communications and Networking Conference (WCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08095" title="Abstract">arXiv:2310.08095</a> (replaced) [<a href="/pdf/2310.08095" title="Download PDF">pdf</a>, <a href="/format/2310.08095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Satellite Cooperative Networks: Joint Hybrid Beamforming and User  Scheduling Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Meixia Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures. arXiv admin note: substantial text overlap with <a href="/abs/2301.03888">arXiv:2301.03888</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08475" title="Abstract">arXiv:2310.08475</a> (replaced) [<a href="/pdf/2310.08475" title="Download PDF">pdf</a>, <a href="/format/2310.08475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Edit Multimodal Large Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingbin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09594" title="Abstract">arXiv:2310.09594</a> (replaced) [<a href="/pdf/2310.09594" title="Download PDF">pdf</a>, <a href="/ps/2310.09594" title="Download PostScript">ps</a>, <a href="/format/2310.09594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuITO: Numerical software for constrained nonlinear optimal control  problems -- extended version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ganguly%2C+S">Siddhartha Ganguly</a>, 
<a href="/search/math?searchtype=author&query=Randad%2C+N">Nakul Randad</a>, 
<a href="/search/math?searchtype=author&query=D%27Silva%2C+R+A">Rihan Aaron D&#x27;Silva</a>, 
<a href="/search/math?searchtype=author&query=Raj%2C+M+S">Mukesh S Raj</a>, 
<a href="/search/math?searchtype=author&query=Chatterjee%2C+D">Debasish Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, published in SoftwareX
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09772" title="Abstract">arXiv:2310.09772</a> (replaced) [<a href="/pdf/2310.09772" title="Download PDF">pdf</a>, <a href="/format/2310.09772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Relation Classification with Graph Meaning Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Li Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dingyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Malu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hershcovich%2C+D">Daniel Hershcovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09828" title="Abstract">arXiv:2310.09828</a> (replaced) [<a href="/pdf/2310.09828" title="Download PDF">pdf</a>, <a href="/format/2310.09828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-K Pooling with Patch Contrastive Learning for Weakly-Supervised  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wangyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tianhong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jimin Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10062" title="Abstract">arXiv:2310.10062</a> (replaced) [<a href="/pdf/2310.10062" title="Download PDF">pdf</a>, <a href="/format/2310.10062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Evaluation of Tool-Assisted Generation Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacovi%2C+A">Alon Jacovi</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Bohnet%2C+B">Bernd Bohnet</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10213" title="Abstract">arXiv:2310.10213</a> (replaced) [<a href="/pdf/2310.10213" title="Download PDF">pdf</a>, <a href="/format/2310.10213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Multi-Connectivity in Beyond 5G Non-Terrestrial Networks:  Challenges and Possible Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majamaa%2C+M">Mikko Majamaa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10477" title="Abstract">arXiv:2310.10477</a> (replaced) [<a href="/pdf/2310.10477" title="Download PDF">pdf</a>, <a href="/format/2310.10477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11077" title="Abstract">arXiv:2310.11077</a> (replaced) [<a href="/pdf/2310.11077" title="Download PDF">pdf</a>, <a href="/format/2310.11077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> United We Stand: Using Epoch-wise Agreement of Ensembles to Combat  Overfit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stern%2C+U">Uri Stern</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz%2C+D">Daniel Shwartz</a>, 
<a href="/search/cs?searchtype=author&query=Weinshall%2C+D">Daphna Weinshall</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings: 38th Annual AAAI Conference on Artificial
  Intelligence, Feb 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11094" title="Abstract">arXiv:2310.11094</a> (replaced) [<a href="/pdf/2310.11094" title="Download PDF">pdf</a>, <a href="/format/2310.11094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relearning Forgotten Knowledge: on Forgetting, Overfit and Training-Free  Ensembles of DNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stern%2C+U">Uri Stern</a>, 
<a href="/search/cs?searchtype=author&query=Weinshall%2C+D">Daphna Weinshall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12035" title="Abstract">arXiv:2310.12035</a> (replaced) [<a href="/pdf/2310.12035" title="Download PDF">pdf</a>, <a href="/ps/2310.12035" title="Download PostScript">ps</a>, <a href="/format/2310.12035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking dynamic flow: Decoding flow fluctuations through performance in  a fine motor control task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bohao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kaiping Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dangxiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14628" title="Abstract">arXiv:2310.14628</a> (replaced) [<a href="/pdf/2310.14628" title="Download PDF">pdf</a>, <a href="/format/2310.14628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tengxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qipeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiangkun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15081" title="Abstract">arXiv:2310.15081</a> (replaced) [<a href="/pdf/2310.15081" title="Download PDF">pdf</a>, <a href="/format/2310.15081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E4S: Fine-grained Face Swapping via Editing With Regional GAN Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Maomao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+G">Ge Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cairong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yongwei Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://e4s2023.github.io/">this https URL</a> ;. arXiv admin note: text overlap with <a href="/abs/2211.14068">arXiv:2211.14068</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15202" title="Abstract">arXiv:2310.15202</a> (replaced) [<a href="/pdf/2310.15202" title="Download PDF">pdf</a>, <a href="/ps/2310.15202" title="Download PostScript">ps</a>, <a href="/format/2310.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Transcription Factor Binding Sites using Transformer based  Capsule Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ghosh%2C+N">Nimisha Ghosh</a>, 
<a href="/search/q-bio?searchtype=author&query=Santoni%2C+D">Daniele Santoni</a>, 
<a href="/search/q-bio?searchtype=author&query=Saha%2C+I">Indrajit Saha</a>, 
<a href="/search/q-bio?searchtype=author&query=Felici%2C+G">Giovanni Felici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15310" title="Abstract">arXiv:2310.15310</a> (replaced) [<a href="/pdf/2310.15310" title="Download PDF">pdf</a>, <a href="/format/2310.15310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A direct solution to the interpolative inverse non-uniform fast Fourier  transform problem, for spectral analyses of non-equidistant time-series data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Armstrong%2C+M+S">Michael Sorochan Armstrong</a>, 
<a href="/search/math?searchtype=author&query=P%C3%A9rez-Gir%C3%B3n%2C+J+C">Jos&#xe9; Carlos P&#xe9;rez-Gir&#xf3;n</a>, 
<a href="/search/math?searchtype=author&query=Camacho%2C+J">Jos&#xe9; Camacho</a>, 
<a href="/search/math?searchtype=author&query=Zamora%2C+R">Regino Zamora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15976" title="Abstract">arXiv:2310.15976</a> (replaced) [<a href="/pdf/2310.15976" title="Download PDF">pdf</a>, <a href="/format/2310.15976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhishuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Pan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16221" title="Abstract">arXiv:2310.16221</a> (replaced) [<a href="/pdf/2310.16221" title="Download PDF">pdf</a>, <a href="/format/2310.16221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scholten%2C+Y">Yan Scholten</a>, 
<a href="/search/cs?searchtype=author&query=Schuchardt%2C+J">Jan Schuchardt</a>, 
<a href="/search/cs?searchtype=author&query=Bojchevski%2C+A">Aleksandar Bojchevski</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17646" title="Abstract">arXiv:2310.17646</a> (replaced) [<a href="/pdf/2310.17646" title="Download PDF">pdf</a>, <a href="/format/2310.17646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Graph Neural Networks Dream of Landau Damping? Insights from Kinetic  Simulations of a Plasma Sheet Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Carvalho%2C+D+D">Diogo D Carvalho</a>, 
<a href="/search/physics?searchtype=author&query=Ferreira%2C+D+R">Diogo R Ferreira</a>, 
<a href="/search/physics?searchtype=author&query=Silva%2C+L+O">Luis O Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18446" title="Abstract">arXiv:2310.18446</a> (replaced) [<a href="/pdf/2310.18446" title="Download PDF">pdf</a>, <a href="/format/2310.18446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hu Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20704" title="Abstract">arXiv:2310.20704</a> (replaced) [<a href="/pdf/2310.20704" title="Download PDF">pdf</a>, <a href="/format/2310.20704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srijan Das</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+T">Tanmay Jain</a>, 
<a href="/search/cs?searchtype=author&query=Reilly%2C+D">Dominick Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+P">Pranav Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Karmakar%2C+S">Soumyajit Karmakar</a>, 
<a href="/search/cs?searchtype=author&query=Marjit%2C+S">Shyam Marjit</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhijit Das</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02594" title="Abstract">arXiv:2311.02594</a> (replaced) [<a href="/pdf/2311.02594" title="Download PDF">pdf</a>, <a href="/format/2311.02594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> scBeacon: single-cell biomarker extraction via identifying paired cell  clusters across biological conditions with contrastive siamese networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+C">Chenyu Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Kweon%2C+Y+J">Yong Jin Kweon</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+J">Jun Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03489" title="Abstract">arXiv:2311.03489</a> (replaced) [<a href="/pdf/2311.03489" title="Download PDF">pdf</a>, <a href="/format/2311.03489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging High-Level Synthesis and Large Language Models to Generate,  Simulate, and Deploy a Uniform Random Number Generator Hardware Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meech%2C+J+T">James T. Meech</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04787" title="Abstract">arXiv:2311.04787</a> (replaced) [<a href="/pdf/2311.04787" title="Download PDF">pdf</a>, <a href="/ps/2311.04787" title="Download PostScript">ps</a>, <a href="/format/2311.04787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Do Probabilistic Clinical Models Fail To Transport Between Sites?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lasko%2C+T+A">Thomas A. Lasko</a>, 
<a href="/search/cs?searchtype=author&query=Strobl%2C+E+V">Eric V. Strobl</a>, 
<a href="/search/cs?searchtype=author&query=Stead%2C+W+W">William W. Stead</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05348" title="Abstract">arXiv:2311.05348</a> (replaced) [<a href="/pdf/2311.05348" title="Download PDF">pdf</a>, <a href="/format/2311.05348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> u-LLaVA: Unifying Multi-Modal Tasks via Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yanchun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi-Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaqian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05705" title="Abstract">arXiv:2311.05705</a> (replaced) [<a href="/pdf/2311.05705" title="Download PDF">pdf</a>, <a href="/format/2311.05705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Maximum Utilization in Optimal Time for Learning or  Convergence in the Kolkata Paise Restaurant Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Aniruddha Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Antika Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+B+K">Bikas K. Chakrabarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures included in manuscript; submitted to Indian Journal of Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05739" title="Abstract">arXiv:2311.05739</a> (replaced) [<a href="/pdf/2311.05739" title="Download PDF">pdf</a>, <a href="/format/2311.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prune-Deprune: Adaptive Compression-Aware Split Learning and Inference  for Enhanced Network Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudvari%2C+A">Akrit Mudvari</a>, 
<a href="/search/cs?searchtype=author&query=Vainio%2C+A">Antero Vainio</a>, 
<a href="/search/cs?searchtype=author&query=Ofeidis%2C+I">Iason Ofeidis</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06281" title="Abstract">arXiv:2311.06281</a> (replaced) [<a href="/pdf/2311.06281" title="Download PDF">pdf</a>, <a href="/format/2311.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Parallelization of a Ubiquitous Sequential Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heinsen%2C+F+A">Franz A. Heinsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code for replicating our results is available online at <a href="https://github.com/glassroom/heinsen_sequence">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10319" title="Abstract">arXiv:2311.10319</a> (replaced) [<a href="/pdf/2311.10319" title="Download PDF">pdf</a>, <a href="/format/2311.10319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shifting to Machine Supervision: Annotation-Efficient Semi and  Self-Supervised Learning for Automatic Medical Image Segmentation and  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pranav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chukkapalli%2C+R">Raviteja Chukkapalli</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+S">Shravan Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Luoyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinqian Pan</a>, 
<a href="/search/cs?searchtype=author&query=Smuda%2C+C">Craig Smuda</a>, 
<a href="/search/cs?searchtype=author&query=Cirrone%2C+J">Jacopo Cirrone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Seventeen pages (incl. references), five figures, and one table. (Under Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10384" title="Abstract">arXiv:2311.10384</a> (replaced) [<a href="/pdf/2311.10384" title="Download PDF">pdf</a>, <a href="/format/2311.10384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval Augmented Generation of Symbolic Music with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jonason%2C+N">Nicolas Jonason</a>, 
<a href="/search/cs?searchtype=author&query=Casini%2C+L">Luca Casini</a>, 
<a href="/search/cs?searchtype=author&query=Thom%C3%A9%2C+C">Carl Thom&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sturm%2C+B+L+T">Bob L.T. Sturm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LBD @ ISMIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12893" title="Abstract">arXiv:2311.12893</a> (replaced) [<a href="/pdf/2311.12893" title="Download PDF">pdf</a>, <a href="/format/2311.12893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with  Dynamic Obstacle Trajectory Prediction and Its Application with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jiageng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zihang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haoran Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12914" title="Abstract">arXiv:2311.12914</a> (replaced) [<a href="/pdf/2311.12914" title="Download PDF">pdf</a>, <a href="/format/2311.12914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Deficit is Ordered! Fooling Deformable Vision Transformers  with Collaborative Adversarial Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+Q+M">Quazi Mishkatul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Tarchoun%2C+B">Bilel Tarchoun</a>, 
<a href="/search/cs?searchtype=author&query=Alouani%2C+I">Ihsen Alouani</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12990" title="Abstract">arXiv:2311.12990</a> (replaced) [<a href="/pdf/2311.12990" title="Download PDF">pdf</a>, <a href="/format/2311.12990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NERIF: GPT-4V for Automatic Scoring of Drawn Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13326" title="Abstract">arXiv:2311.13326</a> (replaced) [<a href="/pdf/2311.13326" title="Download PDF">pdf</a>, <a href="/format/2311.13326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Learning and Imitation Learning for Model-free Control on  Financial Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+W">Woosung Koh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+I">Insu Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yuntae Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Gimin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+C">Woo Chang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 AI4TS Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Portfolio Management (q-fin.PM)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14773" title="Abstract">arXiv:2311.14773</a> (replaced) [<a href="/pdf/2311.14773" title="Download PDF">pdf</a>, <a href="/format/2311.14773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set Features for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+N">Niv Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Tzachor%2C+I">Issar Tzachor</a>, 
<a href="/search/cs?searchtype=author&query=Hoshen%2C+Y">Yedid Hoshen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.12245">arXiv:2302.12245</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16487" title="Abstract">arXiv:2311.16487</a> (replaced) [<a href="/pdf/2311.16487" title="Download PDF">pdf</a>, <a href="/format/2311.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Decision-Focused Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhat%2C+Y">Yehya Farhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 45 figures, submitted to AAAI artificial intelligence for operations research workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16509" title="Abstract">arXiv:2311.16509</a> (replaced) [<a href="/pdf/2311.16509" title="Download PDF">pdf</a>, <a href="/ps/2311.16509" title="Download PostScript">ps</a>, <a href="/format/2311.16509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleCap: Automatic Speaking-Style Captioning from Speech Based on  Speech and Language Self-supervised Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamauchi%2C+K">Kazuki Yamauchi</a>, 
<a href="/search/cs?searchtype=author&query=Ijima%2C+Y">Yusuke Ijima</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuki Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17336" title="Abstract">arXiv:2311.17336</a> (replaced) [<a href="/pdf/2311.17336" title="Download PDF">pdf</a>, <a href="/format/2311.17336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Neural Controlled Differential Equations for Modeling of  Path-dependent Material Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yangzi He</a>, 
<a href="/search/cs?searchtype=author&query=Semnani%2C+S+J">Shabnam J. Semnani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17532" title="Abstract">arXiv:2311.17532</a> (replaced) [<a href="/pdf/2311.17532" title="Download PDF">pdf</a>, <a href="/format/2311.17532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech  Gesture Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xingqun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiahao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+X">Xiaowei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and dataset will be released as soon as possible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17812" title="Abstract">arXiv:2311.17812</a> (replaced) [<a href="/pdf/2311.17812" title="Download PDF">pdf</a>, <a href="/format/2311.17812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAP: Domain-aware Prompt Learning for Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wansen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. arXiv admin note: substantial text overlap with <a href="/abs/2309.03661">arXiv:2309.03661</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17929" title="Abstract">arXiv:2311.17929</a> (replaced) [<a href="/pdf/2311.17929" title="Download PDF">pdf</a>, <a href="/format/2311.17929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Online Communities: Graph Deep Learning on Anonymous Voting Networks  to Identify Sybils in Polycentric Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DuPont%2C+Q">Quinn DuPont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18433" title="Abstract">arXiv:2311.18433</a> (replaced) [<a href="/pdf/2311.18433" title="Download PDF">pdf</a>, <a href="/format/2311.18433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2PNet: Event to Point Cloud Registration with Spatio-Temporal  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiuhong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Changjie Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Siqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yu Zang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+X">Xuesheng Bian</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Matthias M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, accepted by Thirty-seventh Conference on Neural Information Processing Systems(NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00085" title="Abstract">arXiv:2312.00085</a> (replaced) [<a href="/pdf/2312.00085" title="Download PDF">pdf</a>, <a href="/format/2312.00085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-Dreamer: Creating High-quality 3D Content by Bridging the Domain Gap  Between Text-to-2D and Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yiwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yijun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiayi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guannan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+A">Annan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00201" title="Abstract">arXiv:2312.00201</a> (replaced) [<a href="/pdf/2312.00201" title="Download PDF">pdf</a>, <a href="/ps/2312.00201" title="Download PostScript">ps</a>, <a href="/format/2312.00201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An integrated framework for developing and evaluating an automated  lecture style assessment system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dimitriadou%2C+E">Eleni Dimitriadou</a>, 
<a href="/search/cs?searchtype=author&query=Lanitis%2C+A">Andreas Lanitis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01632" title="Abstract">arXiv:2312.01632</a> (replaced) [<a href="/pdf/2312.01632" title="Download PDF">pdf</a>, <a href="/format/2312.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianHead: Impressive Head Avatars with Learnable Gaussian Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiu-Cheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hao Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01697" title="Abstract">arXiv:2312.01697</a> (replaced) [<a href="/pdf/2312.01697" title="Download PDF">pdf</a>, <a href="/format/2312.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hulk: A Universal Knowledge Translator for Human-Centric Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Weizhen He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01880" title="Abstract">arXiv:2312.01880</a> (replaced) [<a href="/pdf/2312.01880" title="Download PDF">pdf</a>, <a href="/ps/2312.01880" title="Download PostScript">ps</a>, <a href="/format/2312.01880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing popularity in linear time via maximum matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A9rczi-Kov%C3%A1cs%2C+E">Erika B&#xe9;rczi-Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Kosztol%C3%A1nyi%2C+K">Kata Kosztol&#xe1;nyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02197" title="Abstract">arXiv:2312.02197</a> (replaced) [<a href="/pdf/2312.02197" title="Download PDF">pdf</a>, <a href="/format/2312.02197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Diffusion Priors for All-in-One Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gou%2C+Y">Yuanbiao Gou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xinyan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02225" title="Abstract">arXiv:2312.02225</a> (replaced) [<a href="/pdf/2312.02225" title="Download PDF">pdf</a>, <a href="/format/2312.02225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Histopathology with Graph Neural Networks: Concepts and  Explanations for Clinicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=di+Villaforesta%2C+A+F">Alessandro Farace di Villaforesta</a>, 
<a href="/search/physics?searchtype=author&query=Magister%2C+L+C">Lucie Charlotte Magister</a>, 
<a href="/search/physics?searchtype=author&query=Barbiero%2C+P">Pietro Barbiero</a>, 
<a href="/search/physics?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02366" title="Abstract">arXiv:2312.02366</a> (replaced) [<a href="/pdf/2312.02366" title="Download PDF">pdf</a>, <a href="/format/2312.02366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General Purpose Vision Foundation Models for Medical Image  Analysis: An Experimental Study of DINOv2 on Radiology Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baharoon%2C+M">Mohammed Baharoon</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+W">Waseem Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jiahong Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Aljouie%2C+A">Abdulrhman Aljouie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03719" title="Abstract">arXiv:2312.03719</a> (replaced) [<a href="/pdf/2312.03719" title="Download PDF">pdf</a>, <a href="/ps/2312.03719" title="Download PostScript">ps</a>, <a href="/format/2312.03719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing AI Chatbots Performance in Comprehensive Standardized Test  Preparation; A Case Study with GRE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Haifa%2C+M">Mohammad Abu-Haifa</a>, 
<a href="/search/cs?searchtype=author&query=Etawi%2C+B">Bara&#x27;a Etawi</a>, 
<a href="/search/cs?searchtype=author&query=Alkhatatbeh%2C+H">Huthaifa Alkhatatbeh</a>, 
<a href="/search/cs?searchtype=author&query=Ababneh%2C+A">Ayman Ababneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 Pages, 6 figures, and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04316" title="Abstract">arXiv:2312.04316</a> (replaced) [<a href="/pdf/2312.04316" title="Download PDF">pdf</a>, <a href="/format/2312.04316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Knowledge-driven Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yeqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Licheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuemeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04487" title="Abstract">arXiv:2312.04487</a> (replaced) [<a href="/pdf/2312.04487" title="Download PDF">pdf</a>, <a href="/format/2312.04487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Maximum Linear Arrangement Problem for Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alemany-Puig%2C+L">Llu&#xed;s Alemany-Puig</a>, 
<a href="/search/cs?searchtype=author&query=Esteban%2C+J+L">Juan Luis Esteban</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer-i-Cancho%2C+R">Ramon Ferrer-i-Cancho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05654" title="Abstract">arXiv:2312.05654</a> (replaced) [<a href="/pdf/2312.05654" title="Download PDF">pdf</a>, <a href="/format/2312.05654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral methods for Neural Integral Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zappala%2C+E">Emanuele Zappala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures and 2 tables. v2: Various typos fixed. Additional details to a proof added and minor wording problems fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05715" title="Abstract">arXiv:2312.05715</a> (replaced) [<a href="/pdf/2312.05715" title="Download PDF">pdf</a>, <a href="/format/2312.05715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Micro-Macro Consistency in Multiscale Modeling: Score-Based Model  Assisted Sampling of Fast/Slow Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crabtree%2C+E+R">Ellis R. Crabtree</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Rivas%2C+J+M">Juan M. Bello-Rivas</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06528" title="Abstract">arXiv:2312.06528</a> (replaced) [<a href="/pdf/2312.06528" title="Download PDF">pdf</a>, <a href="/format/2312.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers Implement Functional Gradient Descent to Learn Non-Linear  Functions In Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sra%2C+S">Suvrit Sra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06681" title="Abstract">arXiv:2312.06681</a> (replaced) [<a href="/pdf/2312.06681" title="Download PDF">pdf</a>, <a href="/format/2312.06681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Llama 2 via Contrastive Activation Addition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimsky%2C+N">Nina Rimsky</a>, 
<a href="/search/cs?searchtype=author&query=Gabrieli%2C+N">Nick Gabrieli</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+J">Julian Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=Hubinger%2C+E">Evan Hubinger</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+A+M">Alexander Matt Turner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06704" title="Abstract">arXiv:2312.06704</a> (replaced) [<a href="/pdf/2312.06704" title="Download PDF">pdf</a>, <a href="/format/2312.06704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIFU: Side-view Conditioned Implicit Function for Real-world Usable  Clothed Human Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zechuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page <a href="https://river-zhang.github.io/SIFU-projectpage/">this https URL</a> ;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06709" title="Abstract">arXiv:2312.06709</a> (replaced) [<a href="/pdf/2312.06709" title="Download PDF">pdf</a>, <a href="/format/2312.06709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AM-RADIO: Agglomerative Model -- Reduce All Domains Into One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranzinger%2C+M">Mike Ranzinger</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+G">Greg Heinrich</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 2: Added more acknowledgements and updated table 7 with more recent results. Ensured that the link in the abstract to our code is working properly Version 3: Fix broken hyperlinks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06721" title="Abstract">arXiv:2312.06721</a> (replaced) [<a href="/pdf/2312.06721" title="Download PDF">pdf</a>, <a href="/format/2312.06721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual World Modeling for Physical Dynamics Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+R">Rahul Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honglin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feigelis%2C+K">Kevin Feigelis</a>, 
<a href="/search/cs?searchtype=author&query=Bear%2C+D+M">Daniel M. Bear</a>, 
<a href="/search/cs?searchtype=author&query=Jedoui%2C+K">Khaled Jedoui</a>, 
<a href="/search/cs?searchtype=author&query=Kotar%2C+K">Klemen Kotar</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+F">Felix Binder</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wanhee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sherry Liu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+A">Kevin A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J+E">Judith E. Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yamins%2C+D+L+K">Daniel L. K. Yamins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07010" title="Abstract">arXiv:2312.07010</a> (replaced) [<a href="/pdf/2312.07010" title="Download PDF">pdf</a>, <a href="/ps/2312.07010" title="Download PostScript">ps</a>, <a href="/format/2312.07010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized lattice Boltzmann method based maximum principle and energy  stability preserving finite-difference scheme for the Allen-Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xi Liu</a>, 
<a href="/search/math?searchtype=author&query=Chai%2C+Z">Zhenhua Chai</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+B">Baochang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07492" title="Abstract">arXiv:2312.07492</a> (replaced) [<a href="/pdf/2312.07492" title="Download PDF">pdf</a>, <a href="/format/2312.07492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in  Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagireddy%2C+M">Manish Nagireddy</a>, 
<a href="/search/cs?searchtype=author&query=Chiazor%2C+L">Lamogha Chiazor</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Moninder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+I">Ioana Baldini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07935" title="Abstract">arXiv:2312.07935</a> (replaced) [<a href="/pdf/2312.07935" title="Download PDF">pdf</a>, <a href="/ps/2312.07935" title="Download PostScript">ps</a>, <a href="/format/2312.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing YOLOv8 and Mask RCNN for object segmentation in complex  orchard environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapkota%2C+R">Ranjan Sapkota</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+D">Dawood Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Karkee%2C+M">Manoj Karkee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08078" title="Abstract">arXiv:2312.08078</a> (replaced) [<a href="/pdf/2312.08078" title="Download PDF">pdf</a>, <a href="/format/2312.08078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Image-Text Alignment in Medical Imaging Enables Cyclic  Image-Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08532" title="Abstract">arXiv:2312.08532</a> (replaced) [<a href="/pdf/2312.08532" title="Download PDF">pdf</a>, <a href="/format/2312.08532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Learning for Cost-Adaptive Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xingli Fang</a>, 
<a href="/search/cs?searchtype=author&query=Bradford%2C+R">Richard Bradford</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jung-Eun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08563" title="Abstract">arXiv:2312.08563</a> (replaced) [<a href="/pdf/2312.08563" title="Download PDF">pdf</a>, <a href="/format/2312.08563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient-NeRF2NeRF: Streamlining Text-Driven 3D Editing with Multiview  Correspondence-Enhanced Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liangchen Song</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liangliang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiatao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://lsongx.github.io/projects/en2n.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08820" title="Abstract">arXiv:2312.08820</a> (replaced) [<a href="/pdf/2312.08820" title="Download PDF">pdf</a>, <a href="/format/2312.08820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Raise a Robot -- A Case for Neuro-Symbolic AI in Constrained Task  Planning for Humanoid Assistive Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemken%2C+N">Niklas Hemken</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+F">Florian Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Peller-Konrad%2C+F">Fabian Peller-Konrad</a>, 
<a href="/search/cs?searchtype=author&query=Kartmann%2C+R">Rainer Kartmann</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>, 
<a href="/search/cs?searchtype=author&query=Hartenstein%2C+H">Hannes Hartenstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, follow-up extended version of our SACMAT 2023 poster abstract: "Poster: How to Raise a Robot - Beyond Access Control Constraints in Assistive Humanoid Robots" <a href="https://dl.acm.org/doi/abs/10.1145/3589608.3595078">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08935" title="Abstract">arXiv:2312.08935</a> (replaced) [<a href="/pdf/2312.08935" title="Download PDF">pdf</a>, <a href="/format/2312.08935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhihong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R+X">R.X. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Damai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Y.Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add Step-by-Step reinforcement learning results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09507" title="Abstract">arXiv:2312.09507</a> (replaced) [<a href="/pdf/2312.09507" title="Download PDF">pdf</a>, <a href="/format/2312.09507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WAVER: Writing-style Agnostic Video Retrieval via Distilling  Vision-Language Models Through Open-Vocabulary Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Huy Le</a>, 
<a href="/search/cs?searchtype=author&query=Kieu%2C+T">Tung Kieu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09785" title="Abstract">arXiv:2312.09785</a> (replaced) [<a href="/pdf/2312.09785" title="Download PDF">pdf</a>, <a href="/format/2312.09785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RJUA-QA: A Comprehensive QA Dataset for Urology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shiwei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Chenfei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hongbo Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoyan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xianguo Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fangzhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaowei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiran Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An initial version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09939" title="Abstract">arXiv:2312.09939</a> (replaced) [<a href="/pdf/2312.09939" title="Download PDF">pdf</a>, <a href="/format/2312.09939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Generative Adversarial Networks: Bridging Classical and Quantum  Realms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nokhwal%2C+S">Sahil Nokhwal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nokhwal%2C+S">Suman Nokhwal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pahune%2C+S">Saurabh Pahune</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chaudhary%2C+A">Ankit Chaudhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10024" title="Abstract">arXiv:2312.10024</a> (replaced) [<a href="/pdf/2312.10024" title="Download PDF">pdf</a>, <a href="/format/2312.10024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Neural Network Training: A Brief Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nokhwal%2C+S">Sahil Nokhwal</a>, 
<a href="/search/cs?searchtype=author&query=Chilakalapudi%2C+P">Priyanka Chilakalapudi</a>, 
<a href="/search/cs?searchtype=author&query=Donekal%2C+P">Preeti Donekal</a>, 
<a href="/search/cs?searchtype=author&query=Nokhwal%2C+S">Suman Nokhwal</a>, 
<a href="/search/cs?searchtype=author&query=Pahune%2C+S">Saurabh Pahune</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+A">Ankit Chaudhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10297" title="Abstract">arXiv:2312.10297</a> (replaced) [<a href="/pdf/2312.10297" title="Download PDF">pdf</a>, <a href="/format/2312.10297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shedding Light on Software Engineering-specific Metaphors and Idioms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+M">Mia Mohammad Imran</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Preetha Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Damevski%2C+K">Kostadin Damevski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10572" title="Abstract">arXiv:2312.10572</a> (replaced) [<a href="/pdf/2312.10572" title="Download PDF">pdf</a>, <a href="/format/2312.10572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Anonymous Multi-Agent Path Finding Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+Z+A">Zain Alabedeen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yakovlev%2C+K">Konstantin Yakovlev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10835" title="Abstract">arXiv:2312.10835</a> (replaced) [<a href="/pdf/2312.10835" title="Download PDF">pdf</a>, <a href="/format/2312.10835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Student is Better Than Expected: Adaptive Teacher-Student  Collaboration for Text-Conditional Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Starodubcev%2C+N">Nikita Starodubcev</a>, 
<a href="/search/cs?searchtype=author&query=Fedorov%2C+A">Artem Fedorov</a>, 
<a href="/search/cs?searchtype=author&query=Babenko%2C+A">Artem Babenko</a>, 
<a href="/search/cs?searchtype=author&query=Baranchuk%2C+D">Dmitry Baranchuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated Fig.3(c) and added a few notes to eliminate potential confusions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10967" title="Abstract">arXiv:2312.10967</a> (replaced) [<a href="/pdf/2312.10967" title="Download PDF">pdf</a>, <a href="/format/2312.10967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs and Pre-trained Language Models enhanced Representation  Learning for Conversational Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhangchi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Ye Tao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+A+W">Alan Wee-Chung Liew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11176" title="Abstract">arXiv:2312.11176</a> (replaced) [<a href="/pdf/2312.11176" title="Download PDF">pdf</a>, <a href="/format/2312.11176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Neural Operators with Automatically Encoded  Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yiming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Kl%C3%B6wer%2C+M">Milan Kl&#xf6;wer</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11193" title="Abstract">arXiv:2312.11193</a> (replaced) [<a href="/pdf/2312.11193" title="Download PDF">pdf</a>, <a href="/ps/2312.11193" title="Download PostScript">ps</a>, <a href="/format/2312.11193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Paraphrasing The Original Text&quot; Makes High Accuracy Long-Context QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijiong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chinese version of this paper can be downloaded from (<a href="https://cloud.tsinghua.edu.cn/d/5894ec4442e54a6aac96/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11285" title="Abstract">arXiv:2312.11285</a> (replaced) [<a href="/pdf/2312.11285" title="Download PDF">pdf</a>, <a href="/format/2312.11285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adv-Diffusion: Imperceptible Adversarial Face Identity Attack via Latent  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11508" title="Abstract">arXiv:2312.11508</a> (replaced) [<a href="/pdf/2312.11508" title="Download PDF">pdf</a>, <a href="/format/2312.11508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Instruction Quality: LIFT is What You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yongqiang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yufan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengnan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maoquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+N">Neel Sundaresan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11974" title="Abstract">arXiv:2312.11974</a> (replaced) [<a href="/pdf/2312.11974" title="Download PDF">pdf</a>, <a href="/format/2312.11974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ms-senet: Enhancing Speech Emotion Recognition Through Multi-scale  Feature Fusion With Squeeze-and-excitation Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuanzhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dichucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Haojun Fei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12343" title="Abstract">arXiv:2312.12343</a> (replaced) [<a href="/pdf/2312.12343" title="Download PDF">pdf</a>, <a href="/format/2312.12343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatestEval: Addressing Data Contamination in Language Model Evaluation  through Dynamic and Time-Sensitive Test Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guerin%2C+F">Frank Guerin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12679" title="Abstract">arXiv:2312.12679</a> (replaced) [<a href="/pdf/2312.12679" title="Download PDF">pdf</a>, <a href="/format/2312.12679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Verification of Quantized Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Pei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Daukantas%2C+I">Ieva Daukantas</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+C">Clark Barrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13156" title="Abstract">arXiv:2312.13156</a> (replaced) [<a href="/pdf/2312.13156" title="Download PDF">pdf</a>, <a href="/format/2312.13156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AccidentGPT: Accident Analysis and Prevention from V2X Environmental  Perception with Multi-modal Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lening Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiyong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yilong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuesong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanchu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Helai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinhai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13271" title="Abstract">arXiv:2312.13271</a> (replaced) [<a href="/pdf/2312.13271" title="Download PDF">pdf</a>, <a href="/format/2312.13271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repaint123: Fast and High-quality One Image to 3D Generation with  Progressive Controllable 2D Repainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhenyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yatian Pang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yida Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://pku-yuangroup.github.io/repaint123/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14149" title="Abstract">arXiv:2312.14149</a> (replaced) [<a href="/pdf/2312.14149" title="Download PDF">pdf</a>, <a href="/format/2312.14149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TagAlign: Improving Vision-Language Alignment with Multi-Tag  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Z">Zhan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14183" title="Abstract">arXiv:2312.14183</a> (replaced) [<a href="/pdf/2312.14183" title="Download PDF">pdf</a>, <a href="/format/2312.14183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Early Detection of Hallucinations in Factual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snyder%2C+B">Ben Snyder</a>, 
<a href="/search/cs?searchtype=author&query=Moisescu%2C+M">Marius Moisescu</a>, 
<a href="/search/cs?searchtype=author&query=Zafar%2C+M+B">Muhammad Bilal Zafar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14206" title="Abstract">arXiv:2312.14206</a> (replaced) [<a href="/pdf/2312.14206" title="Download PDF">pdf</a>, <a href="/format/2312.14206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4VG: Large Language Models Evaluation for Video Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zihan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14232" title="Abstract">arXiv:2312.14232</a> (replaced) [<a href="/pdf/2312.14232" title="Download PDF">pdf</a>, <a href="/format/2312.14232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parrot Captions Teach CLIP to Spot Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+J">Alex Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://linyq17.github.io/CLIP-Parrot-Bias/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14238" title="Abstract">arXiv:2312.14238</a> (replaced) [<a href="/pdf/2312.14238" title="Download PDF">pdf</a>, <a href="/format/2312.14238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternVL: Scaling up Vision Foundation Models and Aligning for Generic  Visual-Linguistic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiannan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weijie Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+S">Sen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Muyan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinglong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures, 28 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14276" title="Abstract">arXiv:2312.14276</a> (replaced) [<a href="/pdf/2312.14276" title="Download PDF">pdf</a>, <a href="/ps/2312.14276" title="Download PostScript">ps</a>, <a href="/format/2312.14276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Networks and Finite Elements of Any Order on Arbitrary  Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+J">Juncai He</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+J">Jinchao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14852" title="Abstract">arXiv:2312.14852</a> (replaced) [<a href="/pdf/2312.14852" title="Download PDF">pdf</a>, <a href="/format/2312.14852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACO: Topics in Algorithmic COde generation dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongao Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo-Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chen Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14998" title="Abstract">arXiv:2312.14998</a> (replaced) [<a href="/pdf/2312.14998" title="Download PDF">pdf</a>, <a href="/format/2312.14998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic images aid the recognition of human-made art forgeries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ostmeyer%2C+J">Johann Ostmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Schaerf%2C+L">Ludovica Schaerf</a>, 
<a href="/search/cs?searchtype=author&query=Buividovich%2C+P">Pavel Buividovich</a>, 
<a href="/search/cs?searchtype=author&query=Charles%2C+T">Tessa Charles</a>, 
<a href="/search/cs?searchtype=author&query=Postma%2C+E">Eric Postma</a>, 
<a href="/search/cs?searchtype=author&query=Popovici%2C+C">Carina Popovici</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 + 10 pages, 9 figures, 14 tables; van Gogh dataset available, DOI: <a href="https://doi.org/10.5281/zenodo.10276928">this https URL</a>; accepted for publication in PLOS ONE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15291" title="Abstract">arXiv:2312.15291</a> (replaced) [<a href="/pdf/2312.15291" title="Download PDF">pdf</a>, <a href="/format/2312.15291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reverse Multi-Choice Dialogue Commonsense Inference with  Graph-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Li Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bobo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lizi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Donghong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chong Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24, FEBRUARY 20-27, 2024, VANCOUVER, CANADA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15342" title="Abstract">arXiv:2312.15342</a> (replaced) [<a href="/pdf/2312.15342" title="Download PDF">pdf</a>, <a href="/format/2312.15342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High Order Geometry Conforming Immersed Finite Element for Elliptic  Interface Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adjerid%2C+S">Slimane Adjerid</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Tao Lin</a>, 
<a href="/search/math?searchtype=author&query=Meghaichi%2C+H">Haroun Meghaichi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V1: 29 pages. V2: 25 pages (changed font from 11pt to the default 10pt)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15345" title="Abstract">arXiv:2312.15345</a> (replaced) [<a href="/pdf/2312.15345" title="Download PDF">pdf</a>, <a href="/format/2312.15345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboFiSense: Attention-Based Robotic Arm Activity Recognition with WiFi  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zandi%2C+R">Rojin Zandi</a>, 
<a href="/search/cs?searchtype=author&query=Behzad%2C+K">Kian Behzad</a>, 
<a href="/search/cs?searchtype=author&query=Motamedi%2C+E">Elaheh Motamedi</a>, 
<a href="/search/cs?searchtype=author&query=Salehinejad%2C+H">Hojjat Salehinejad</a>, 
<a href="/search/cs?searchtype=author&query=Siami%2C+M">Milad Siami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15405" title="Abstract">arXiv:2312.15405</a> (replaced) [<a href="/pdf/2312.15405" title="Download PDF">pdf</a>, <a href="/format/2312.15405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Computation Pushdown for Cloud OLAP Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiangyao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Serafini%2C+M">Marco Serafini</a>, 
<a href="/search/cs?searchtype=author&query=Aboulnaga%2C+A">Ashraf Aboulnaga</a>, 
<a href="/search/cs?searchtype=author&query=Stonebraker%2C+M">Michael Stonebraker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15459" title="Abstract">arXiv:2312.15459</a> (replaced) [<a href="/pdf/2312.15459" title="Download PDF">pdf</a>, <a href="/format/2312.15459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Least-Squares versus Partial Least-Squares Finite Element Methods:  Robust A Priori and A Posteriori Error Estimates of Augmented Mixed Finite  Element Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liang%2C+Y">Yuxiang Liang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15516" title="Abstract">arXiv:2312.15516</a> (replaced) [<a href="/e-print/2312.15516" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-SDM: Accelerating Stable Diffusion through Redundancy Removal and  Performance Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaobing Tu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Siyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Since the experimental part has not been added, we wish to withdraw the manuscript, and we hope to submit it after the experiment has been verified
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15566" title="Abstract">arXiv:2312.15566</a> (replaced) [<a href="/pdf/2312.15566" title="Download PDF">pdf</a>, <a href="/format/2312.15566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Copula-Based Survival Analysis for Dependent Censoring with  Identifiability Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+W">Weijia Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Ling%2C+C+K">Chun Kai Ling</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+X">Xuanhui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15640" title="Abstract">arXiv:2312.15640</a> (replaced) [<a href="/pdf/2312.15640" title="Download PDF">pdf</a>, <a href="/format/2312.15640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Report of the DOE/NSF Workshop on Correctness in Scientific Computing,  June 2023, Orlando, FL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gokhale%2C+M">Maya Gokhale</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Mayo%2C+J">Jackson Mayo</a>, 
<a href="/search/cs?searchtype=author&query=Nagarakatte%2C+S">Santosh Nagarakatte</a>, 
<a href="/search/cs?searchtype=author&query=Rubio-Gonz%C3%A1lez%2C+C">Cindy Rubio-Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+S+F">Stephen F. Siegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages. DOE/NSF Workshop on Correctness in Scientific Computing (CSC 2023) was a PLDI 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15646" title="Abstract">arXiv:2312.15646</a> (replaced) [<a href="/pdf/2312.15646" title="Download PDF">pdf</a>, <a href="/ps/2312.15646" title="Download PostScript">ps</a>, <a href="/format/2312.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A graph-based multimodal framework to predict gentrification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eshtiyagh%2C+J">Javad Eshtiyagh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baotong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yujing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Linhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Urban Informatics 2023 - Best Paper
  Award 3rd Place
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15661" title="Abstract">arXiv:2312.15661</a> (replaced) [<a href="/pdf/2312.15661" title="Download PDF">pdf</a>, <a href="/format/2312.15661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Potential of Large Language Models for Explainable  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yucong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingyue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15692" title="Abstract">arXiv:2312.15692</a> (replaced) [<a href="/pdf/2312.15692" title="Download PDF">pdf</a>, <a href="/format/2312.15692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Fusion: Advancing Prompt Evolution through Hybridization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weidong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiuding Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaitong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhuwei Rao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+D">Di Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15707" title="Abstract">arXiv:2312.15707</a> (replaced) [<a href="/pdf/2312.15707" title="Download PDF">pdf</a>, <a href="/format/2312.15707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Diffusion-based Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guoqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15725" title="Abstract">arXiv:2312.15725</a> (replaced) [<a href="/pdf/2312.15725" title="Download PDF">pdf</a>, <a href="/format/2312.15725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notes on Information Propagation in Noisy Multichannel Data Models:  Insights into Sensor Selection and Fusion in Multimodal Biomedical  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sameni%2C+R">Reza Sameni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15731" title="Abstract">arXiv:2312.15731</a> (replaced) [<a href="/pdf/2312.15731" title="Download PDF">pdf</a>, <a href="/format/2312.15731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinagyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haoran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianxiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15824" title="Abstract">arXiv:2312.15824</a> (replaced) [<a href="/pdf/2312.15824" title="Download PDF">pdf</a>, <a href="/ps/2312.15824" title="Download PostScript">ps</a>, <a href="/format/2312.15824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Few-Shot Bird Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moummad%2C+I">Ilyass Moummad</a>, 
<a href="/search/cs?searchtype=author&query=Serizel%2C+R">Romain Serizel</a>, 
<a href="/search/cs?searchtype=author&query=Farrugia%2C+N">Nicolas Farrugia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15840" title="Abstract">arXiv:2312.15840</a> (replaced) [<a href="/pdf/2312.15840" title="Download PDF">pdf</a>, <a href="/format/2312.15840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Contrastive Reconstruction for Cross-modal Medical Image-Report  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K">Kai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiuzhuang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15890" title="Abstract">arXiv:2312.15890</a> (replaced) [<a href="/pdf/2312.15890" title="Download PDF">pdf</a>, <a href="/format/2312.15890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Multimodal Prompting With Missing Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jaehyuk Jang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yooseung Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15969" title="Abstract">arXiv:2312.15969</a> (replaced) [<a href="/pdf/2312.15969" title="Download PDF">pdf</a>, <a href="/ps/2312.15969" title="Download PostScript">ps</a>, <a href="/format/2312.15969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting the capacity of deep networks only at training stage for  nonlinear black-box system identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eivaghi%2C+V+M">Vahid MohammadZadeh Eivaghi</a>, 
<a href="/search/cs?searchtype=author&query=Shooredeli%2C+M+A">Mahdi Aliyari Shooredeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15985" title="Abstract">arXiv:2312.15985</a> (replaced) [<a href="/pdf/2312.15985" title="Download PDF">pdf</a>, <a href="/ps/2312.15985" title="Download PostScript">ps</a>, <a href="/format/2312.15985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Messages Improve Communication Efficiency among Isolated  Intelligent Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yuchuan Jang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Weijie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Meo%2C+C">Cristian Meo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16148" title="Abstract">arXiv:2312.16148</a> (replaced) [<a href="/pdf/2312.16148" title="Download PDF">pdf</a>, <a href="/format/2312.16148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Media Bias Taxonomy: A Systematic Literature Review on the Forms and  Automated Detection of Media Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spinde%2C+T">Timo Spinde</a>, 
<a href="/search/cs?searchtype=author&query=Hinterreiter%2C+S">Smilla Hinterreiter</a>, 
<a href="/search/cs?searchtype=author&query=Haak%2C+F">Fabian Haak</a>, 
<a href="/search/cs?searchtype=author&query=Ruas%2C+T">Terry Ruas</a>, 
<a href="/search/cs?searchtype=author&query=Giese%2C+H">Helge Giese</a>, 
<a href="/search/cs?searchtype=author&query=Meuschke%2C+N">Norman Meuschke</a>, 
<a href="/search/cs?searchtype=author&query=Gipp%2C+B">Bela Gipp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16151" title="Abstract">arXiv:2312.16151</a> (replaced) [<a href="/pdf/2312.16151" title="Download PDF">pdf</a>, <a href="/format/2312.16151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Long-tailed Disease Diagnosis on Radiology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qiaoyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weike Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16154" title="Abstract">arXiv:2312.16154</a> (replaced) [<a href="/pdf/2312.16154" title="Download PDF">pdf</a>, <a href="/format/2312.16154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustered Orienteering Problem with Subgroups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+L+E">Luciano E. Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Macharet%2C+D+G">Douglas G. Macharet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item414">Cross-lists</a></li>
<li><a href="#item484">Replacements</a></li>
</ul>
<small>[ total of 754 entries:  <b>1-754</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
