<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 29 Nov 23  to  Thu 30 Nov 23, announced Fri,  1 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item386">Cross-lists</a></li>
<li><a href="#item454">Replacements</a></li>
</ul>
<small>[ total of 696 entries:  <b>1-696</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri,  1 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17924" title="Abstract">arXiv:2311.17924</a> [<a href="/pdf/2311.17924" title="Download PDF">pdf</a>, <a href="/format/2311.17924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unrolling Virtual Worlds for Immersive Experiences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tikhonov%2C+A">Alexey Tikhonov</a>, 
<a href="/search/cs?searchtype=author&query=Repushko%2C+A">Anton Repushko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for NeurIPS 2023 Workshop on Machine Learning for Creativity and Design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">This research pioneers a method for generating immersive worlds, drawing
inspiration from elements of vintage adventure games like Myst and employing
modern text-to-image models. We explore the intricate conversion of 2D
panoramas into 3D scenes using equirectangular projections, addressing the
distortions in perception that occur as observers navigate within the
encompassing sphere. Our approach employs a technique similar to "inpainting"
to rectify distorted projections, enabling the smooth construction of locally
coherent worlds. This provides extensive insight into the interrelation of
technology, perception, and experiential reality within human-computer
interaction.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17926" title="Abstract">arXiv:2311.17926</a> [<a href="/pdf/2311.17926" title="Download PDF">pdf</a>, <a href="/ps/2311.17926" title="Download PostScript">ps</a>, <a href="/format/2311.17926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grid-Forming Control of Power Converters: Equivalence Proof through  Simplified Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhetessov%2C+A">Aidar Zhetessov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This work establishes the equivalence of selected grid-forming control
algorithms within the context of simplified theoretical models. Considered
algorithms are droop control, Virtual Synchronous Machine (VSM) and matching
control. It is shown that nodal and network dynamics under those regulators
boil down to the same equations near the selected (trivial) nominal operating
point. Finally, some practical insights on each regulator dynamics and an
outlook are provided.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17927" title="Abstract">arXiv:2311.17927</a> [<a href="/pdf/2311.17927" title="Download PDF">pdf</a>, <a href="/format/2311.17927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed-Loop Ramp-Comparison Current Regulator for an Induction Machine  with a PWM Voltage-Source Inverter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhetessov%2C+A">Aidar Zhetessov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses the closed-loop ramp comparison current regulation in an
induction machine fed by a pulse width modulated voltage source inverter. The
regulator is implemented in a synchronous frame, serving as a foundation for an
overarching vector control of the induction machine. First, the effect of PI
regulator gains on the controller performance is analyzed both theoretically
and numerically using the developed Simulink model of the system. Next, the
paper deals with high speed and/or low-voltage operating conditions of the
machine, introducing the concept of overmodulation and analyzing its impact on
the regulator performance. Obtained simulation results coincide with
model-based theoretical predictions and literature findings. Finally, the work
proposes an outlook for the high-speed system enhancements in terms of power
electronics topology, control and modulation.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17929" title="Abstract">arXiv:2311.17929</a> [<a href="/pdf/2311.17929" title="Download PDF">pdf</a>, <a href="/format/2311.17929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Online Communities: Graph Deep Learning on Anonymous Voting Networks  to Identify Sybils in Polycentric Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DuPont%2C+Q">Quinn DuPont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This research examines the polycentric governance of digital assets in
Decentralized Autonomous Organizations (DAOs). It offers a theoretical
framework and addresses a critical challenge facing decentralized governance by
developing a method to identify sybils, or spurious identities. The method uses
graph deep learning techniques to identify sybil activity in a DAO governance
dataset (snapshot.org). Specifically, a Graph Convolutional Neural Network
(GCNN) learned voting behaviours and a fast k-means vector clustering algorithm
(FAISS) used the high dimensional embeddings to identify similar nodes in a
graph. The results reveal that deep learning can effectively identify sybils,
reducing the voting graph by 2-5%. This research underscores the importance of
sybil resistance in DAOs and offers a novel perspective on decentralized
governance, informing future policy, regulation, and governance practices.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17935" title="Abstract">arXiv:2311.17935</a> [<a href="/pdf/2311.17935" title="Download PDF">pdf</a>, <a href="/format/2311.17935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Workforce Planning in Crowdsourced Delivery with Hybrid Driver  Fleets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luy%2C+J">Julius Luy</a>, 
<a href="/search/eess?searchtype=author&query=Hiermann%2C+G">Gerhard Hiermann</a>, 
<a href="/search/eess?searchtype=author&query=Schiffer%2C+M">Maximilian Schiffer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Nowadays, logistics service providers (LSPs) increasingly consider using a
crowdsourced workforce on the last mile to fulfill customers' expectations
regarding same-day or on-demand delivery at reduced costs. The crowdsourced
workforce's availability is, however, uncertain. Therefore, LSPs often hire
additional fixed employees to perform deliveries when the availability of
crowdsourced drivers is low. In this context, the reliability versus
flexibility trade-off which LSPs face over a longer period, e.g., a year,
remains unstudied. Against this background, we jointly study a workforce
planning problem that considers fixed drivers (FDs) and the temporal
development of the crowdsourced driver (CD) fleet over a long-term time
horizon. We consider two types of CDs, gigworkers (GWs) and occasional drivers
(ODs). While GWs are not sensitive to the request's destination and typically
exhibit high availability, ODs only serve requests whose origin and destination
coincide with their own private route's origin and destination. Moreover, to
account for time horizon-specific dynamics, we consider stochastic turnover for
both FDs and CDs as well as stochastic CD fleet growth. We formulate the
resulting workforce planning problem as a Markov decision process (MDP) whose
reward function reflects total costs, i.e., wages and operational costs arising
from serving demand with FDs and CDs, and solve it via approximate dynamic
programming (ADP). Applying our approach to an environment based on real-world
demand data from GrubHub, we find that in fleets consisting of FDs and CDs,
ADP-based hiring policies can outperform myopic hiring policies by up to 19% in
total costs. In the studied setting, we observed that GWs reduce the LSP's
total costs more than ODs. When we account for CDs' increased resignation
probability when not being matched with enough requests, the amount of required
FDs increases.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17936" title="Abstract">arXiv:2311.17936</a> [<a href="/pdf/2311.17936" title="Download PDF">pdf</a>, <a href="/ps/2311.17936" title="Download PostScript">ps</a>, <a href="/format/2311.17936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnostics Algorithms in Nuclear Plant Cyber Attack Analysis Toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Patel%2C+J+K">Japan K. Patel</a>, 
<a href="/search/eess?searchtype=author&query=Varuttamaseni%2C+A">Athi Varuttamaseni</a>, 
<a href="/search/eess?searchtype=author&query=Youngblood%2C+R+W">Robert W. Youngblood III</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Junjie Guo</a>, 
<a href="/search/eess?searchtype=author&query=Wacker%2C+S">Steven Wacker</a>, 
<a href="/search/eess?searchtype=author&query=Barbosa%2C+R+P">Rafael Pires Barbosa</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J+C">John C. Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper has been submitted to Physor 2024 for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A Python interface is developed for the GPWR Simulator to automatically
simulate cyber-spoofing of different steam generator parameters and plant
operation. Specifically, steam generator water level, feedwater flowrate, steam
flowrate, valve position, and steam generator controller parameters, including
controller gain and time constant, can be directly attacked using command
inject, denial of service, and man-in-the-middle type attacks. Plant operation
can be initialized to any of the initial conditions provided by the GPWR
simulator. Several different diagnostics algorithms have been implemented for
anomaly detection, including physics-based diagnostics with Kalman filtering,
data-driven diagnostics, noise profiling, and online sensor validation.
Industry-standard safety analysis code RELAP5 is also available as a part of
the toolkit. Diagnostics algorithms are analyzed based on accuracy and
efficiency. Our observations indicate that physics-based diagnostics with
Kalman filtering are the most robust. An experimental quantum kernel has been
added to the framework for preliminary testing. Our first impressions suggest
that while quantum kernels can be accurate, just like any other kernels, their
applicability is problem/data dependent, and can be prone to overfitting.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17937" title="Abstract">arXiv:2311.17937</a> [<a href="/pdf/2311.17937" title="Download PDF">pdf</a>, <a href="/format/2311.17937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Spatial Comprehension in Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derakhshani%2C+M+M">Mohammad Mahdi Derakhshani</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Menglin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Behl%2C+H">Harkirat Behl</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BChle%2C+V">Victor R&#xfc;hle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose CompFuser, an image generation pipeline that enhances spatial
comprehension and attribute assignment in text-to-image generative models. Our
pipeline enables the interpretation of instructions defining spatial
relationships between objects in a scene, such as `An image of a gray cat on
the left of an orange dog', and generate corresponding images. This is
especially important in order to provide more control to the user. CompFuser
overcomes the limitation of existing text-to-image diffusion models by decoding
the generation of multiple objects into iterative steps: first generating a
single object and then editing the image by placing additional objects in their
designated positions. To create training data for spatial comprehension and
attribute assignment we introduce a synthetic data generation process, that
leverages a frozen large language model and a frozen layout-based diffusion
model for object placement. We compare our approach to strong baselines and
show that our model outperforms state-of-the-art image generation models in
spatial comprehension and attribute assignment, despite being 3x to 5x smaller
in parameters.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17938" title="Abstract">arXiv:2311.17938</a> [<a href="/pdf/2311.17938" title="Download PDF">pdf</a>, <a href="/format/2311.17938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP  Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianxiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaoying Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ying Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Active recognition, which allows intelligent agents to explore observations
for better recognition performance, serves as a prerequisite for various
embodied AI tasks, such as grasping, navigation and room arrangements. Given
the evolving environment and the multitude of object classes, it is impractical
to include all possible classes during the training stage. In this paper, we
aim at advancing active open-vocabulary recognition, empowering embodied agents
to actively perceive and classify arbitrary objects. However, directly adopting
recent open-vocabulary classification models, like Contrastive Language Image
Pretraining (CLIP), poses its unique challenges. Specifically, we observe that
CLIP's performance is heavily affected by the viewpoint and occlusions,
compromising its reliability in unconstrained embodied perception scenarios.
Further, the sequential nature of observations in agent-environment
interactions necessitates an effective method for integrating features that
maintains discriminative strength for open-vocabulary classification. To
address these issues, we introduce a novel agent for active open-vocabulary
recognition. The proposed method leverages inter-frame and inter-concept
similarities to navigate agent movements and to fuse features, without relying
on class-specific knowledge. Compared to baseline CLIP model with 29.6%
accuracy on ShapeNet dataset, the proposed agent could achieve 53.3% accuracy
for open-vocabulary recognition, without any fine-tuning to the equipped CLIP
model. Additional experiments conducted with the Habitat simulator further
affirm the efficacy of our method.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17939" title="Abstract">arXiv:2311.17939</a> [<a href="/pdf/2311.17939" title="Download PDF">pdf</a>, <a href="/ps/2311.17939" title="Download PostScript">ps</a>, <a href="/format/2311.17939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proofs of Equalities NP = coNP = PSPACE: Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gordeev%2C+L">Lev Gordeev</a>, 
<a href="/search/cs?searchtype=author&query=Haeusler%2C+E+H">Edward Hermann Haeusler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2012.04437">arXiv:2012.04437</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper we present simplified proofs of our results NP = coNP = PSPACE.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17940" title="Abstract">arXiv:2311.17940</a> [<a href="/pdf/2311.17940" title="Download PDF">pdf</a>, <a href="/format/2311.17940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene Summarization: Clustering Scene Videos into Spatially Diverse  Frames
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingzhi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+P">Ankush Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F+J">Felix Juefei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose scene summarization as a new video-based scene understanding task.
It aims to summarize a long video walkthrough of a scene into a small set of
frames that are spatially diverse in the scene, which has many impotant
applications, such as in surveillance, real estate, and robotics. It stems from
video summarization but focuses on long and continuous videos from moving
cameras, instead of user-edited fragmented video clips that are more commonly
studied in existing video summarization works. Our solution to this task is a
two-stage self-supervised pipeline named SceneSum. Its first stage uses
clustering to segment the video sequence. Our key idea is to combine visual
place recognition (VPR) into this clustering process to promote spatial
diversity. Its second stage needs to select a representative keyframe from each
cluster as the summary while respecting resource constraints such as memory and
disk space limits. Additionally, if the ground truth image trajectory is
available, our method can be easily augmented with a supervised loss to enhance
the clustering and keyframe selection. Extensive experiments on both real-world
and simulated datasets show our method outperforms common video summarization
baselines by 50%
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17941" title="Abstract">arXiv:2311.17941</a> [<a href="/pdf/2311.17941" title="Download PDF">pdf</a>, <a href="/format/2311.17941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Attack-Resilient Scheduling of Integrated Energy Systems with  Demand Response via Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+W">Wenjie Ma</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuanzheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sen Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimally scheduling multi-energy flow is an effective method to utilize
renewable energy sources (RES) and improve the stability and economy of
integrated energy systems (IES). However, the stable demand-supply of IES faces
challenges from uncertainties that arise from RES and loads, as well as the
increasing impact of cyber-attacks with advanced information and communication
technologies adoption. To address these challenges, this paper proposes an
innovative model-free resilience scheduling method based on state-adversarial
deep reinforcement learning (DRL) for integrated demand response (IDR)-enabled
IES. The proposed method designs an IDR program to explore the interaction
ability of electricity-gas-heat flexible loads. Additionally, a
state-adversarial Markov decision process (SA-MDP) model characterizes the
energy scheduling problem of IES under cyber-attack. The state-adversarial soft
actor-critic (SA-SAC) algorithm is proposed to mitigate the impact of
cyber-attacks on the scheduling strategy. Simulation results demonstrate that
our method is capable of adequately addressing the uncertainties resulting from
RES and loads, mitigating the impact of cyber-attacks on the scheduling
strategy, and ensuring a stable demand supply for various energy sources.
Moreover, the proposed method demonstrates resilience against cyber-attacks.
Compared to the original soft actor-critic (SAC) algorithm, it achieves a 10\%
improvement in economic performance under cyber-attack scenarios.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17942" title="Abstract">arXiv:2311.17942</a> [<a href="/pdf/2311.17942" title="Download PDF">pdf</a>, <a href="/format/2311.17942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-based (yet Class-agnostic) Video Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+D">Dantong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Bar%2C+A">Amir Bar</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+R">Roei Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Rohrbach%2C+A">Anna Rohrbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing video-based action recognition systems typically require dense
annotation and struggle in environments when there is significant distribution
shift relative to the training data. Current methods for video domain
adaptation typically fine-tune the model using fully annotated data on a subset
of target domain data or align the representation of the two domains using
bootstrapping or adversarial learning. Inspired by the pivotal role of objects
in recent supervised object-centric action recognition models, we present
Object-based (yet Class-agnostic) Video Domain Adaptation (ODAPT), a simple yet
effective framework for adapting the existing action recognition systems to new
domains by utilizing a sparse set of frames with class-agnostic object
annotations in a target domain. Our model achieves a +6.5 increase when
adapting across kitchens in Epic-Kitchens and a +3.1 increase adapting between
Epic-Kitchens and the EGTEA dataset. ODAPT is a general framework that can also
be combined with previous unsupervised methods, offering a +5.0 boost when
combined with the self-supervised multi-modal method MMSADA and a +1.7 boost
when added to the adversarial-based method TA$^3$N on Epic-Kitchens.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17943" title="Abstract">arXiv:2311.17943</a> [<a href="/pdf/2311.17943" title="Download PDF">pdf</a>, <a href="/format/2311.17943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LayerCollapse: Adaptive compression of neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shabgahi%2C+S+Z">Soheil Zibakhsh Shabgahi</a>, 
<a href="/search/cs?searchtype=author&query=Shariff%2C+M+S">Mohammad Soheil Shariff</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Handling the ever-increasing scale of contemporary deep learning and
transformer-based models poses a significant challenge. Although great strides
have been made in optimizing model compression techniques such as model
architecture search and knowledge distillation, the availability of data and
computational resources remains a considerable hurdle for these optimizations.
This paper introduces LayerCollapse, a novel alternative adaptive model
compression methodology. LayerCollapse works by eliminating non-linearities
within the network and collapsing two consecutive fully connected layers into a
single linear transformation. This approach simultaneously reduces both the
number of layers and the parameter count, thereby enhancing model efficiency.
We also introduce a compression aware regularizer, which compresses the model
in alignment with the dataset quality and model expressiveness, consequently
reducing overfitting across tasks. Our results demonstrate LayerCollapse's
effective compression and regularization capabilities in multiple fine-grained
classification benchmarks, achieving up to 74% post training compression with
minimal accuracy loss. We compare this method with knowledge distillation on
the same target network, showcasing a five-fold increase in computational
efficiency and 8% improvement in overall accuracy on the ImageNet dataset.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17944" title="Abstract">arXiv:2311.17944</a> [<a href="/pdf/2311.17944" title="Download PDF">pdf</a>, <a href="/format/2311.17944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LALM: Long-Term Action Anticipation with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Daoji Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yongqin Xian</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding human activity is a crucial yet intricate task in egocentric
vision, a field that focuses on capturing visual perspectives from the camera
wearer's viewpoint. While traditional methods heavily rely on representation
learning trained on extensive video data, there exists a significant
limitation: obtaining effective video representations proves challenging due to
the inherent complexity and variability in human activities.Furthermore,
exclusive dependence on video-based learning may constrain a model's capability
to generalize across long-tail classes and out-of-distribution scenarios.
<br />In this study, we introduce a novel approach for long-term action
anticipation using language models (LALM), adept at addressing the complex
challenges of long-term activity understanding without the need for extensive
training. Our method incorporates an action recognition model to track previous
action sequences and a vision-language model to articulate relevant
environmental details. By leveraging the context provided by these past events,
we devise a prompting strategy for action anticipation using large language
models (LLMs). Moreover, we implement Maximal Marginal Relevance for example
selection to facilitate in-context learning of the LLMs. Our experimental
results demonstrate that LALM surpasses the state-of-the-art methods in the
task of long-term action anticipation on the Ego4D benchmark. We further
validate LALM on two additional benchmarks, affirming its capacity for
generalization across intricate activities with different sets of taxonomies.
These are achieved without specific fine-tuning.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17945" title="Abstract">arXiv:2311.17945</a> [<a href="/pdf/2311.17945" title="Download PDF">pdf</a>, <a href="/format/2311.17945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Vision-Language Alignment Makes Efficient Instruction  Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lizhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tianhang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhuangwei Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Liuren Yin</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 pages for main paper, 7 pages for supplementary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the task of extending the large language model (LLM) into a
vision-language instruction-following model. This task is crucial but
challenging since the LLM is trained on text modality only, making it hard to
effectively digest the visual modality. To address this, existing methods
typically train a visual adapter to align the representation between a
pre-trained vision transformer (ViT) and the LLM by a generative image
captioning loss. However, we find that the generative objective can only
produce weak alignment for vision and language, making the aligned
vision-language model very hungry for the instruction fine-tuning data. In this
paper, we propose CG-VLM that applies both Contrastive and Generative alignment
objectives to effectively align the representation of ViT and LLM. Different
from image level and sentence level alignment in common contrastive learning
settings, CG-VLM aligns the image-patch level features and text-token level
embeddings, which, however, is very hard to achieve as no explicit grounding
patch-token relation provided in standard image captioning datasets. To address
this issue, we propose to maximize the averaged similarity between pooled
image-patch features and text-token embeddings. Extensive experiments
demonstrate that the proposed CG-VLM produces strong vision-language alignment
and is an efficient instruction learner. For example, using only 10%
instruction tuning data, we reach 95% performance of state-of-the-art method
LLaVA [29] on the zero-shot ScienceQA-Image benchmark.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17946" title="Abstract">arXiv:2311.17946</a> [<a href="/pdf/2311.17946" title="Download PDF">pdf</a>, <a href="/format/2311.17946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamSync: Aligning Text-to-Image Generation with Image Understanding  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Deqing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yushi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Su Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rassin%2C+R">Royi Rassin</a>, 
<a href="/search/cs?searchtype=author&query=Juan%2C+D">Da-Cheng Juan</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+D">Dana Alon</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=van+Steenkiste%2C+S">Sjoerd van Steenkiste</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Rashtchian%2C+C">Cyrus Rashtchian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Despite their wide-spread success, Text-to-Image models (T2I) still struggle
to produce images that are both aesthetically pleasing and faithful to the
user's input text. We introduce DreamSync, a model-agnostic training algorithm
by design that improves T2I models to be faithful to the text input. DreamSync
builds off a recent insight from TIFA's evaluation framework -- that large
vision-language models (VLMs) can effectively identify the fine-grained
discrepancies between generated images and the text inputs. DreamSync uses this
insight to train T2I models without any labeled data; it improves T2I models
using its own generations. First, it prompts the model to generate several
candidate images for a given input text. Then, it uses two VLMs to select the
best generation: a Visual Question Answering model that measures the alignment
of generated images to the text, and another that measures the generation's
aesthetic quality. After selection, we use LoRA to iteratively finetune the T2I
model to guide its generation towards the selected best generations. DreamSync
does not need any additional human annotation. model architecture changes, or
reinforcement learning. Despite its simplicity, DreamSync improves both the
semantic alignment and aesthetic appeal of two diffusion-based T2I models,
evidenced by multiple benchmarks (+1.7% on TIFA, +2.9% on DSG1K, +3.4% on VILA
aesthetic) and human evaluation.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17947" title="Abstract">arXiv:2311.17947</a> [<a href="/pdf/2311.17947" title="Download PDF">pdf</a>, <a href="/format/2311.17947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Reduction of a Piecewise Linear Flexible Mechanical Oscillator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhattacharyya%2C+S">Suparno Bhattacharyya</a>, 
<a href="/search/eess?searchtype=author&query=Cusumano%2C+J+P">Joseph. P. Cusumano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 9 figures. Source code available at <a href="https://tinyurl.com/kicked-oscillator-code">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Chaotic Dynamics (nlin.CD); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">We study the reduced order modeling of a nonlinear flexible oscillator in
which a Bernoulli-Euler beam with a permanent tip magnet is subjected to a
position-triggered electromagnetic kick force. This results in non-smooth
boundary conditions capable of exciting many degrees of freedom. The system is
modeled as piecewise linear with the different boundary conditions determining
different regions of a hybrid phase space. With kick strength as parameter, its
bifurcation diagram is found to exhibit a range of periodic and chaotic
behaviors. Proper orthogonal decomposition (POD) is used to estimate the
system's intrinsic dimensionality. However, conventional POD's purely
statistical analysis of spatial covariance does not guarantee accuracy of
reduced order models (ROMs). We therefore augment POD by employing a
previously-developed energy closure criterion that selects ROM dimension by
ensuring approximate energy balance on the reduced subspace. This physics-based
criterion yields accurate ROMs with 8 degrees of freedom. Remarkably, we show
that ROMs formulated at particular values of the kick strength can nevertheless
reconstruct the entire bifurcation structure of the original system. Our
results demonstrate that energy closure analysis outperforms variance-based
estimates of effective dimension for nonlinear structural systems, and is
capable of providing ROMs that are robust even across stability transitions.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17948" title="Abstract">arXiv:2311.17948</a> [<a href="/pdf/2311.17948" title="Download PDF">pdf</a>, <a href="/format/2311.17948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action-slot: Visual Action-centric Representations for Multi-label  Atomic Activity Recognition in Traffic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kung%2C+C">Chi-Hsi Kung</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shu-Wei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we study multi-label atomic activity recognition. Despite the
notable progress in action recognition, it is still challenging to recognize
atomic activities due to a deficiency in a holistic understanding of both
multiple road users' motions and their contextual information. In this paper,
we introduce Action-slot, a slot attention-based approach that learns visual
action-centric representations, capturing both motion and contextual
information. Our key idea is to design action slots that are capable of paying
attention to regions where atomic activities occur, without the need for
explicit perception guidance. To further enhance slot attention, we introduce a
background slot that competes with action slots, aiding the training process in
avoiding unnecessary focus on background regions devoid of activities. Yet, the
imbalanced class distribution in the existing dataset hampers the assessment of
rare activities. To address the limitation, we collect a synthetic dataset
called TACO, which is four times larger than OATS and features a balanced
distribution of atomic activities. To validate the effectiveness of our method,
we conduct comprehensive experiments and ablation studies against various
action recognition baselines. We also show that the performance of multi-label
atomic activity recognition on real-world datasets can be improved by
pretraining representations on TACO. We will release our source code and
dataset. See the videos of visualization on the project page:
https://hcis-lab.github.io/Action-slot/
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17949" title="Abstract">arXiv:2311.17949</a> [<a href="/pdf/2311.17949" title="Download PDF">pdf</a>, <a href="/format/2311.17949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Retrieval: Augmenting Pre-trained Models with Search Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damirchi%2C+H">Hamed Damirchi</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Opazo%2C+C">Cristian Rodr&#xed;guez-Opazo</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J+Q">Javen Qinfeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+S">Stephen Gould</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large pre-trained models can dramatically reduce the amount of task-specific
data required to solve a problem, but they often fail to capture
domain-specific nuances out of the box. The Web likely contains the information
necessary to excel on any specific application, but identifying the right data
a priori is challenging. This paper shows how to leverage recent advances in
NLP and multi-modal learning to augment a pre-trained model with search engine
retrieval. We propose to retrieve useful data from the Web at test time based
on test cases that the model is uncertain about. Different from existing
retrieval-augmented approaches, we then update the model to address this
underlying uncertainty. We demonstrate substantial improvements in zero-shot
performance, e.g. a remarkable increase of 15 percentage points in accuracy on
the Stanford Cars and Flowers datasets. We also present extensive experiments
that explore the impact of noisy retrieval and different learning strategies.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17950" title="Abstract">arXiv:2311.17950</a> [<a href="/pdf/2311.17950" title="Download PDF">pdf</a>, <a href="/format/2311.17950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Large-Scale Data Condensation via Various Backbone and  Statistical Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shitong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zeyuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Muxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xindong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The lightweight "local-match-global" matching introduced by SRe2L
successfully creates a distilled dataset with comprehensive information on the
full 224x224 ImageNet-1k. However, this one-sided approach is limited to a
particular backbone, layer, and statistics, which limits the improvement of the
generalization of a distilled dataset. We suggest that sufficient and various
"local-match-global" matching are more precise and effective than a single one
and has the ability to create a distilled dataset with richer information and
better generalization. We call this perspective "generalized matching" and
propose Generalized Various Backbone and Statistical Matching (G-VBSM) in this
work, which aims to create a synthetic dataset with densities, ensuring
consistency with the complete dataset across various backbones, layers, and
statistics. As experimentally demonstrated, G-VBSM is the first algorithm to
obtain strong performance across both small-scale and large-scale datasets.
Specifically, G-VBSM achieves a performance of 38.7% on CIFAR-100 with
128-width ConvNet, 47.6% on Tiny-ImageNet with ResNet18, and 31.4% on the full
224x224 ImageNet-1k with ResNet18, under images per class (IPC) 10, 50, and 10,
respectively. These results surpass all SOTA methods by margins of 3.9%, 6.5%,
and 10.1%, respectively.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17951" title="Abstract">arXiv:2311.17951</a> [<a href="/pdf/2311.17951" title="Download PDF">pdf</a>, <a href="/format/2311.17951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C3Net: Compound Conditioned ControlNet for Multimodal Content Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juntao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuehuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present Compound Conditioned ControlNet, C3Net, a novel generative neural
architecture taking conditions from multiple modalities and synthesizing
multimodal contents simultaneously (e.g., image, text, audio). C3Net adapts the
ControlNet architecture to jointly train and make inferences on a
production-ready diffusion model and its trainable copies. Specifically, C3Net
first aligns the conditions from multi-modalities to the same semantic latent
space using modality-specific encoders based on contrastive training. Then, it
generates multimodal outputs based on the aligned latent space, whose semantic
information is combined using a ControlNet-like architecture called Control
C3-UNet. Correspondingly, with this system design, our model offers an improved
solution for joint-modality generation through learning and explaining
multimodal conditions instead of simply taking linear interpolations on the
latent space. Meanwhile, as we align conditions to a unified latent space,
C3Net only requires one trainable Control C3-UNet to work on multimodal
semantic information. Furthermore, our model employs unimodal pretraining on
the condition alignment stage, outperforming the non-pretrained alignment even
on relatively scarce training data and thus demonstrating high-quality compound
condition generation. We contribute the first high-quality tri-modal validation
set to validate quantitatively that C3Net outperforms or is on par with first
and contemporary state-of-the-art multimodal generation. Our codes and
tri-modal dataset will be released.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17952" title="Abstract">arXiv:2311.17952</a> [<a href="/pdf/2311.17952" title="Download PDF">pdf</a>, <a href="/format/2311.17952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronizing Vision and Language: Bidirectional Token-Masking  AutoEncoder for Referring Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minhyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dogyoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Suhwan Cho</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Heeseung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Ig-Jae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyoun Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring Image Segmentation (RIS) aims to segment target objects expressed
in natural language within a scene at the pixel level. Various recent RIS
models have achieved state-of-the-art performance by generating contextual
tokens to model multimodal features from pretrained encoders and effectively
fusing them using transformer-based cross-modal attention. While these methods
match language features with image features to effectively identify likely
target objects, they often struggle to correctly understand contextual
information in complex and ambiguous sentences and scenes. To address this
issue, we propose a novel bidirectional token-masking autoencoder (BTMAE)
inspired by the masked autoencoder (MAE). The proposed model learns the context
of image-to-language and language-to-image by reconstructing missing features
in both image and language features at the token level. In other words, this
approach involves mutually complementing across the features of images and
language, with a focus on enabling the network to understand interconnected
deep contextual information between the two modalities. This learning method
enhances the robustness of RIS performance in complex sentences and scenes. Our
BTMAE achieves state-of-the-art performance on three popular datasets, and we
demonstrate the effectiveness of the proposed method through various ablation
studies.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17953" title="Abstract">arXiv:2311.17953</a> [<a href="/pdf/2311.17953" title="Download PDF">pdf</a>, <a href="/format/2311.17953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Image Editing Detection in the Era of Generative AI  Revolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Haipeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danding Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Juan Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The accelerated advancement of generative AI significantly enhance the
viability and effectiveness of generative regional editing methods. This
evolution render the image manipulation more accessible, thereby intensifying
the risk of altering the conveyed information within original images and even
propagating misinformation. Consequently, there exists a critical demand for
robust capable of detecting the edited images. However, the lack of
comprehensive dataset containing images edited with abundant and advanced
generative regional editing methods poses a substantial obstacle to the
advancement of corresponding detection methods.
<br />We endeavor to fill the vacancy by constructing the GRE dataset, a
large-scale generative regional editing dataset with the following advantages:
1) Collection of real-world original images, focusing on two frequently edited
scenarios. 2) Integration of a logical and simulated editing pipeline,
leveraging multiple large models in various modalities. 3) Inclusion of various
editing approaches with distinct architectures. 4) Provision of comprehensive
analysis tasks. We perform comprehensive experiments with proposed three tasks:
edited image classification, edited method attribution and edited region
localization, providing analysis of distinct editing methods and evaluation of
detection methods in related fields. We expect that the GRE dataset can promote
further research and exploration in the field of generative region editing
detection.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17954" title="Abstract">arXiv:2311.17954</a> [<a href="/pdf/2311.17954" title="Download PDF">pdf</a>, <a href="/format/2311.17954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-empowered Multi-modal Item Embedding for Enhanced Image  Search in E-Commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+P">Peng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Anxiang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over the past decade, significant advances have been made in the field of
image search for e-commerce applications. Traditional image-to-image retrieval
models, which focus solely on image details such as texture, tend to overlook
useful semantic information contained within the images. As a result, the
retrieved products might possess similar image details, but fail to fulfil the
user's search goals. Moreover, the use of image-to-image retrieval models for
products containing multiple images results in significant online product
feature storage overhead and complex mapping implementations. In this paper, we
report the design and deployment of the proposed Multi-modal Item Embedding
Model (MIEM) to address these limitations. It is capable of utilizing both
textual information and multiple images about a product to construct meaningful
product features. By leveraging semantic information from images, MIEM
effectively supplements the image search process, improving the overall
accuracy of retrieval results. MIEM has become an integral part of the Shopee
image search platform. Since its deployment in March 2023, it has achieved a
remarkable 9.90% increase in terms of clicks per user and a 4.23% boost in
terms of orders per user for the image search feature on the Shopee e-commerce
platform.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17955" title="Abstract">arXiv:2311.17955</a> [<a href="/pdf/2311.17955" title="Download PDF">pdf</a>, <a href="/format/2311.17955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEAN: A Diffusion-based Prior-Enhanced Attention Network for Scene Text  Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zuoyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+P">Pengfei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hui Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene text image super-resolution (STISR) aims at simultaneously increasing
the resolution and readability of low-resolution scene text images, thus
boosting the performance of the downstream recognition task. Two factors in
scene text images, semantic information and visual structure, affect the
recognition performance significantly. To mitigate the effects from these
factors, this paper proposes a Prior-Enhanced Attention Network (PEAN).
Specifically, a diffusion-based module is developed to enhance the text prior,
hence offering better guidance for the SR network to generate SR images with
higher semantic accuracy. Meanwhile, the proposed PEAN leverages an
attention-based modulation module to understand scene text images by neatly
perceiving the local and global dependence of images, despite the shape of the
text. A multi-task learning paradigm is employed to optimize the network,
enabling the model to generate legible SR images. As a result, PEAN establishes
new SOTA results on the TextZoom benchmark. Experiments are also conducted to
analyze the importance of the enhanced text prior as a means of improving the
performance of the SR network. Code will be made available at
https://github.com/jdfxzzy/PEAN.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17956" title="Abstract">arXiv:2311.17956</a> [<a href="/pdf/2311.17956" title="Download PDF">pdf</a>, <a href="/format/2311.17956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuadraNet: Improving High-Order Neural Interaction Efficiency with  Hardware-Aware Quadratic Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenhui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fuxun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zirui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jinjun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASP-DAC 2024 Best Paper Nomination
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Recent progress in computer vision-oriented neural network designs is mostly
driven by capturing high-order neural interactions among inputs and features.
And there emerged a variety of approaches to accomplish this, such as
Transformers and its variants. However, these interactions generate a large
amount of intermediate state and/or strong data dependency, leading to
considerable memory consumption and computing cost, and therefore compromising
the overall runtime performance. To address this challenge, we rethink the
high-order interactive neural network design with a quadratic computing
approach. Specifically, we propose QuadraNet -- a comprehensive model design
methodology from neuron reconstruction to structural block and eventually to
the overall neural network implementation. Leveraging quadratic neurons'
intrinsic high-order advantages and dedicated computation optimization schemes,
QuadraNet could effectively achieve optimal cognition and computation
performance. Incorporating state-of-the-art hardware-aware neural architecture
search and system integration techniques, QuadraNet could also be well
generalized in different hardware constraint settings and deployment scenarios.
The experiment shows thatQuadraNet achieves up to 1.5$\times$ throughput, 30%
less memory footprint, and similar cognition performance, compared with the
state-of-the-art high-order approaches.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17957" title="Abstract">arXiv:2311.17957</a> [<a href="/pdf/2311.17957" title="Download PDF">pdf</a>, <a href="/format/2311.17957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandRefiner: Refining Malformed Hands in Generated Images by  Diffusion-based Conditional Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenquan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yufei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have achieved remarkable success in generating realistic
images but suffer from generating accurate human hands, such as incorrect
finger counts or irregular shapes. This difficulty arises from the complex task
of learning the physical structure and pose of hands from training images,
which involves extensive deformations and occlusions. For correct hand
generation, our paper introduces a lightweight post-processing solution called
$\textbf{HandRefiner}$. HandRefiner employs a conditional inpainting approach
to rectify malformed hands while leaving other parts of the image untouched. We
leverage the hand mesh reconstruction model that consistently adheres to the
correct number of fingers and hand shape, while also being capable of fitting
the desired hand pose in the generated image. Given a generated failed image
due to malformed hands, we utilize ControlNet modules to re-inject such correct
hand information. Additionally, we uncover a phase transition phenomenon within
ControlNet as we vary the control strength. It enables us to take advantage of
more readily available synthetic data without suffering from the domain gap
between realistic and synthetic hands. Experiments demonstrate that HandRefiner
can significantly improve the generation quality quantitatively and
qualitatively. The code is available at
https://github.com/wenquanlu/HandRefiner .
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17958" title="Abstract">arXiv:2311.17958</a> [<a href="/pdf/2311.17958" title="Download PDF">pdf</a>, <a href="/format/2311.17958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CommunityAI: Towards Community-based Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murturi%2C+I">Ilir Murturi</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has emerged as a promising paradigm to train machine
learning models collaboratively while preserving data privacy. However, its
widespread adoption faces several challenges, including scalability,
heterogeneous data and devices, resource constraints, and security concerns.
Despite its promise, FL has not been specifically adapted for community
domains, primarily due to the wide-ranging differences in data types and
context, devices and operational conditions, environmental factors, and
stakeholders. In response to these challenges, we present a novel framework for
Community-based Federated Learning called CommunityAI. CommunityAI enables
participants to be organized into communities based on their shared interests,
expertise, or data characteristics. Community participants collectively
contribute to training and refining learning models while maintaining data and
participant privacy within their respective groups. Within this paper, we
discuss the conceptual architecture, system requirements, processes, and future
challenges that must be solved. Finally, our goal within this paper is to
present our vision regarding enabling a collaborative learning process within
various communities.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17959" title="Abstract">arXiv:2311.17959</a> [<a href="/pdf/2311.17959" title="Download PDF">pdf</a>, <a href="/ps/2311.17959" title="Download PostScript">ps</a>, <a href="/format/2311.17959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Based Model for Predicting Rapid Impact Compaction Outcomes:  A Case Study of Utapao International Airport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youwai%2C+S">Sompote Youwai</a>, 
<a href="/search/cs?searchtype=author&query=Detcheewa%2C+S">Sirasak Detcheewa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a novel deep learning approach to predict the
engineering properties of the ground improved by Rapid Impact Compaction (RIC),
which is a ground improvement technique that uses a drop hammer to compact the
soil and fill layers. The proposed approach uses transformer-based neural
networks to capture the complex nonlinear relationships between the input
features, such as the hammer energy, drop height, and number of blows, and the
output variables, such as the cone resistance. The approach is applied to a
real-world dataset from a trial test section for the new apron construction of
the Utapao International Airport in Thailand. The results show that the
proposed approach outperforms the existing methods in terms of prediction
accuracy and efficiency and provides interpretable attention maps that reveal
the importance of different features for RIC prediction. The paper also
discusses the limitations and future directions of applying deep learning
methods to RIC prediction.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17960" title="Abstract">arXiv:2311.17960</a> [<a href="/pdf/2311.17960" title="Download PDF">pdf</a>, <a href="/format/2311.17960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Prompting in SAM for Weakly Supervised Cell Segmentation in  Histopathological Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+A+K">Aayush Kumar Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+V">Vaibhav Mishra</a>, 
<a href="/search/cs?searchtype=author&query=P.%2C+P+A">Prathosh A.P.</a>, 
<a href="/search/cs?searchtype=author&query=Mausam">Mausam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cell segmentation in histopathological images plays a crucial role in
understanding, diagnosing, and treating many diseases. However, data annotation
for this is expensive since there can be a large number of cells per image, and
expert pathologists are needed for labelling images. Instead, our paper focuses
on using weak supervision -- annotation from related tasks -- to induce a
segmenter. Recent foundation models, such as Segment Anything (SAM), can use
prompts to leverage additional supervision during inference. SAM has performed
remarkably well in natural image segmentation tasks; however, its applicability
to cell segmentation has not been explored.
<br />In response, we investigate guiding the prompting procedure in SAM for weakly
supervised cell segmentation when only bounding box supervision is available.
We develop two workflows: (1) an object detector's output as a test-time prompt
to SAM (D-SAM), and (2) SAM as pseudo mask generator over training data to
train a standalone segmentation model (SAM-S). On finding that both workflows
have some complementary strengths, we develop an integer programming-based
approach to reconcile the two sets of segmentation masks, achieving yet higher
performance. We experiment on three publicly available cell segmentation
datasets namely, ConSep, MoNuSeg, and TNBC, and find that all SAM-based
solutions hugely outperform existing weakly supervised image segmentation
models, obtaining 9-15 pt Dice gains.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17963" title="Abstract">arXiv:2311.17963</a> [<a href="/pdf/2311.17963" title="Download PDF">pdf</a>, <a href="/format/2311.17963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatIllusion: Efficient-Aligning Interleaved Generation ability with  Visual Instruction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+X">Xiaowei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yijiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengkai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Ziyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chaoyou Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As the capabilities of Large-Language Models (LLMs) become widely recognized,
there is an increasing demand for human-machine chat applications. Human
interaction with text often inherently invokes mental imagery, an aspect that
existing LLM-based chatbots like GPT-4 do not currently emulate, as they are
confined to generating text-only content. To bridge this gap, we introduce
ChatIllusion, an advanced Generative multimodal large language model (MLLM)
that combines the capabilities of LLM with not only visual comprehension but
also creativity. Specifically, ChatIllusion integrates Stable Diffusion XL and
Llama, which have been fine-tuned on modest image-caption data, to facilitate
multiple rounds of illustrated chats. The central component of ChatIllusion is
the "GenAdapter," an efficient approach that equips the multimodal language
model with capabilities for visual representation, without necessitating
modifications to the foundational model. Extensive experiments validate the
efficacy of our approach, showcasing its ability to produce diverse and
superior-quality image outputs Simultaneously, it preserves semantic
consistency and control over the dialogue, significantly enhancing the overall
user's quality of experience (QoE). The code is available at
https://github.com/litwellchi/ChatIllusion.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17967" title="Abstract">arXiv:2311.17967</a> [<a href="/pdf/2311.17967" title="Download PDF">pdf</a>, <a href="/format/2311.17967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Galaxy Features via Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haowen Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zishi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kempe%2C+J">Julia Kempe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS Workshop on Machine Learning and the Physical Sciences, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">In many applications, Neural Nets (NNs) have classification performance on
par or even exceeding human capacity. Moreover, it is likely that NNs leverage
underlying features that might differ from those humans perceive to classify.
Can we "reverse-engineer" pertinent features to enhance our scientific
understanding? Here, we apply this idea to the notoriously difficult task of
galaxy classification: NNs have reached high performance for this task, but
what does a neural net (NN) "see" when it classifies galaxies? Are there
morphological features that the human eye might overlook that could help with
the task and provide new insights? Can we visualize tracers of early evolution,
or additionally incorporated spectral data? We present a novel way to summarize
and visualize galaxy morphology through the lens of neural networks, leveraging
Dataset Distillation, a recent deep-learning methodology with the primary
objective to distill knowledge from a large dataset and condense it into a
compact synthetic dataset, such that a model trained on this synthetic dataset
achieves performance comparable to a model trained on the full dataset. We
curate a class-balanced, medium-size high-confidence version of the Galaxy Zoo
2 dataset, and proceed with dataset distillation from our accurate
NN-classifier to create synthesized prototypical images of galaxy morphological
features, demonstrating its effectiveness. Of independent interest, we
introduce a self-adaptive version of the state-of-the-art Matching Trajectory
algorithm to automate the distillation process, and show enhanced performance
on computer vision benchmarks.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17971" title="Abstract">arXiv:2311.17971</a> [<a href="/pdf/2311.17971" title="Download PDF">pdf</a>, <a href="/format/2311.17971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and  Consistent 3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Baorui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haoge Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junsheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Shen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and Demo: <a href="https://github.com/baaivision/Uni3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-3D generation by distilling pretrained large-scale text-to-image
diffusion models has shown great promise but still suffers from inconsistent 3D
geometric structures (Janus problems) and severe artifacts. The aforementioned
problems mainly stem from 2D diffusion models lacking 3D awareness during the
lifting. In this work, we present GeoDream, a novel method that incorporates
explicit generalized 3D priors with 2D diffusion priors to enhance the
capability of obtaining unambiguous 3D consistent geometric structures without
sacrificing diversity or fidelity. Specifically, we first utilize a multi-view
diffusion model to generate posed images and then construct cost volume from
the predicted image, which serves as native 3D geometric priors, ensuring
spatial consistency in 3D space. Subsequently, we further propose to harness 3D
geometric priors to unlock the great potential of 3D awareness in 2D diffusion
priors via a disentangled design. Notably, disentangling 2D and 3D priors
allows us to refine 3D geometric priors further. We justify that the refined 3D
geometric priors aid in the 3D-aware capability of 2D diffusion priors, which
in turn provides superior guidance for the refinement of 3D geometric priors.
Our numerical and visual comparisons demonstrate that GeoDream generates more
3D consistent textured meshes with high-resolution realistic renderings (i.e.,
1024 $\times$ 1024) and adheres more closely to semantic coherence.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17972" title="Abstract">arXiv:2311.17972</a> [<a href="/pdf/2311.17972" title="Download PDF">pdf</a>, <a href="/format/2311.17972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Infilling Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces a general code generation framework that incorporates
infilling operations into auto-regressive decoding. Our approach capitalizes on
the observation that recent code language models with infilling capabilities
can perform \emph{self-infilling}: whereas infilling operations aim to fill in
the middle based on a predefined prefix and suffix, self-infilling sequentially
generates both such surrounding context and the infilled content. We utilize
this feature to develop an infilling-augmented decoding process that
facilitates non-monotonic generation. This approach allows for postponing the
generation of uncertain code snippets until a definitive suffix is established,
leading to improved control over the generation sequence. In addition, it
facilitates a looping mechanism, which can iteratively update and synchronize
each piece of generation in a cyclic manner. Extensive experiments are
conducted to demonstrate that our proposed decoding process is effective in
enhancing regularity and quality across several code generation benchmarks.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17973" title="Abstract">arXiv:2311.17973</a> [<a href="/pdf/2311.17973" title="Download PDF">pdf</a>, <a href="/format/2311.17973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogeneous Artificial Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polyakov%2C+A">Andrey Polyakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">The paper proposes an artificial neural network (ANN) being a global
approximator for a special class of functions, which are known as generalized
homogeneous. The homogeneity means a symmetry of a function with respect to a
group of transformations having topological characterization of a dilation. In
this paper, a class of the so-called linear dilations is considered. A
homogeneous universal approximation theorem is proven. Procedures for an
upgrade of an existing ANN to a homogeneous one are developed. Theoretical
results are supported by examples from the various domains (computer science,
systems theory and automatic control).
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17975" title="Abstract">arXiv:2311.17975</a> [<a href="/pdf/2311.17975" title="Download PDF">pdf</a>, <a href="/format/2311.17975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoDeformer: Geometric Deformable Transformer for Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jinhui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiaming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junwei Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Including geometric transformations into ViT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision transformers have recently emerged as an effective alternative to
convolutional networks for action recognition. However, vision transformers
still struggle with geometric variations prevalent in video data. This paper
proposes a novel approach, GeoDeformer, designed to capture the variations
inherent in action video by integrating geometric comprehension directly into
the ViT architecture. Specifically, at the core of GeoDeformer is the Geometric
Deformation Predictor, a module designed to identify and quantify potential
spatial and temporal geometric deformations within the given video. Spatial
deformations adjust the geometry within individual frames, while temporal
deformations capture the cross-frame geometric dynamics, reflecting motion and
temporal progression. To demonstrate the effectiveness of our approach, we
incorporate it into the established MViTv2 framework, replacing the standard
self-attention blocks with GeoDeformer blocks. Our experiments at UCF101,
HMDB51, and Mini-K200 achieve significant increases in both Top-1 and Top-5
accuracy, establishing new state-of-the-art results with only a marginal
increase in computational cost. Additionally, visualizations affirm that
GeoDeformer effectively manifests explicit geometric deformations and minimizes
geometric variations. Codes and checkpoints will be released.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17977" title="Abstract">arXiv:2311.17977</a> [<a href="/pdf/2311.17977" title="Download PDF">pdf</a>, <a href="/format/2311.17977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianShader: 3D Gaussian Splatting with Shading Functions for  Reflective Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yingwenqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Jiadong Tu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, refrences added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advent of neural 3D Gaussians has recently brought about a revolution in
the field of neural rendering, facilitating the generation of high-quality
renderings at real-time speeds. However, the explicit and discrete
representation encounters challenges when applied to scenes featuring
reflective surfaces. In this paper, we present GaussianShader, a novel method
that applies a simplified shading function on 3D Gaussians to enhance the
neural rendering in scenes with reflective surfaces while preserving the
training and rendering efficiency. The main challenge in applying the shading
function lies in the accurate normal estimation on discrete 3D Gaussians.
Specifically, we proposed a novel normal estimation framework based on the
shortest axis directions of 3D Gaussians with a delicately designed loss to
make the consistency between the normals and the geometries of Gaussian
spheres. Experiments show that GaussianShader strikes a commendable balance
between efficiency and visual quality. Our method surpasses Gaussian Splatting
in PSNR on specular object datasets, exhibiting an improvement of 1.57dB. When
compared to prior works handling reflective surfaces, such as Ref-NeRF, our
optimization time is significantly accelerated (23h vs. 0.58h). Please click on
our project website to see more results.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17978" title="Abstract">arXiv:2311.17978</a> [<a href="/pdf/2311.17978" title="Download PDF">pdf</a>, <a href="/ps/2311.17978" title="Download PostScript">ps</a>, <a href="/format/2311.17978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutArch: An AI-assisted workflow for object detection and automated  recording in archaeological catalogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+K">Kevin Klein</a>, 
<a href="/search/cs?searchtype=author&query=Wohde%2C+A">Alyssa Wohde</a>, 
<a href="/search/cs?searchtype=author&query=Gorelik%2C+A+V">Alexander V. Gorelik</a>, 
<a href="/search/cs?searchtype=author&query=Heyd%2C+V">Volker Heyd</a>, 
<a href="/search/cs?searchtype=author&query=Diekmann%2C+Y">Yoan Diekmann</a>, 
<a href="/search/cs?searchtype=author&query=Brami%2C+M">Maxime Brami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Compiling large datasets from published resources, such as archaeological
find catalogues presents fundamental challenges: identifying relevant content
and manually recording it is a time-consuming, repetitive and error-prone task.
For the data to be useful, it must be of comparable quality and adhere to the
same recording standards, which is hardly ever the case in archaeology. Here,
we present a new data collection method exploiting recent advances in
Artificial Intelligence. Our software uses an object detection neural network
combined with further classification networks to speed up, automate, and
standardise data collection from legacy resources, such as archaeological
drawings and photographs in large unsorted PDF files. The AI-assisted workflow
detects common objects found in archaeological catalogues, such as graves,
skeletons, ceramics, ornaments, stone tools and maps, and spatially relates and
analyses these objects on the page to extract real-life attributes, such as the
size and orientation of a grave based on the north arrow and the scale. A
graphical interface allows for and assists with manual validation. We
demonstrate the benefits of this approach by collecting a range of shapes and
numerical attributes from richly-illustrated archaeological catalogues, and
benchmark it in a real-world experiment with ten users. Moreover, we record
geometric whole-outlines through contour detection, an alternative to
landmark-based geometric morphometrics not achievable by hand.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17981" title="Abstract">arXiv:2311.17981</a> [<a href="/pdf/2311.17981" title="Download PDF">pdf</a>, <a href="/format/2311.17981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing the Generation and Transmission Capacity of Offshore Wind  Parks under Weather Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kr%C3%B6ger%2C+D">David Kr&#xf6;ger</a>, 
<a href="/search/eess?searchtype=author&query=Peper%2C+J">Jan Peper</a>, 
<a href="/search/eess?searchtype=author&query=Offermann%2C+N">Nils Offermann</a>, 
<a href="/search/eess?searchtype=author&query=Rehtanz%2C+C">Christian Rehtanz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; General Economics (econ.GN); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Offshore wind power in the North Sea is considered a main pillar in Europe's
future energy system. A key challenge lies in determining the optimal spatial
capacity allocation of offshore wind parks in combination with the dimensioning
and layout of the connecting high-voltage direct current grid infrastructure.
To determine economically cost optimal configurations, we apply an integrated
capacity and transmission expansion problem within a pan-European electricity
market and transmission grid model with a high spatial and temporal
granularity. By conducting scenario analysis for the year 2030 with a gradually
increasing CO2 price, possible offshore expansion paths are derived and
presented. Special emphasis is laid on the effects of weather uncertainty by
incorporating data from 21 historical weather years in the analysis. Two key
findings are (i) an expansion in addition to the existing offshore wind
capacity of 0 GW (136 EUR/tCO2), 12 GW (159 EUR/tCO2) and 30 GW (186 EUR/tCO2)
dependent on the underlying CO2 price. (ii) A strong sensitivity of the results
towards the underlying weather data highlighting the importance of
incorporating multiple weather years.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17982" title="Abstract">arXiv:2311.17982</a> [<a href="/pdf/2311.17982" title="Download PDF">pdf</a>, <a href="/format/2311.17982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VBench: Comprehensive Benchmark Suite for Video Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yinan He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiashuo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenyang Si</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qingyang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chanpaisit%2C+N">Nattapol Chanpaisit</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Equal contributions from first four authors. Project page: <a href="https://vchitect.github.io/VBench-project/">this https URL</a> Code: <a href="https://github.com/Vchitect/VBench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video generation has witnessed significant advancements, yet evaluating these
models remains a challenge. A comprehensive evaluation benchmark for video
generation is indispensable for two reasons: 1) Existing metrics do not fully
align with human perceptions; 2) An ideal evaluation system should provide
insights to inform future developments of video generation. To this end, we
present VBench, a comprehensive benchmark suite that dissects "video generation
quality" into specific, hierarchical, and disentangled dimensions, each with
tailored prompts and evaluation methods. VBench has three appealing properties:
1) Comprehensive Dimensions: VBench comprises 16 dimensions in video generation
(e.g., subject identity inconsistency, motion smoothness, temporal flickering,
and spatial relationship, etc). The evaluation metrics with fine-grained levels
reveal individual models' strengths and weaknesses. 2) Human Alignment: We also
provide a dataset of human preference annotations to validate our benchmarks'
alignment with human perception, for each evaluation dimension respectively. 3)
Valuable Insights: We look into current models' ability across various
evaluation dimensions, and various content types. We also investigate the gaps
between video and image generation models. We will open-source VBench,
including all prompts, evaluation methods, generated videos, and human
preference annotations, and also include more video generation models in VBench
to drive forward the field of video generation.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17983" title="Abstract">arXiv:2311.17983</a> [<a href="/pdf/2311.17983" title="Download PDF">pdf</a>, <a href="/format/2311.17983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Faithfulness for Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lijie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+M">Mengdi Huai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Transformers (ViTs) have achieved state-of-the-art performance for
various vision tasks. One reason behind the success lies in their ability to
provide plausible innate explanations for the behavior of neural architectures.
However, ViTs suffer from issues with explanation faithfulness, as their focal
points are fragile to adversarial attacks and can be easily changed with even
slight perturbations on the input image. In this paper, we propose a rigorous
approach to mitigate these issues by introducing Faithful ViTs (FViTs). Briefly
speaking, an FViT should have the following two properties: (1) The top-$k$
indices of its self-attention vector should remain mostly unchanged under input
perturbation, indicating stable explanations; (2) The prediction distribution
should be robust to perturbations. To achieve this, we propose a new method
called Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing
and diffusion-based denoising. We theoretically prove that processing ViTs
directly with DDS can turn them into FViTs. We also show that Gaussian noise is
nearly optimal for both $\ell_2$ and $\ell_\infty$-norm cases. Finally, we
demonstrate the effectiveness of our approach through comprehensive experiments
and evaluations. Specifically, we compare our FViTs with other baselines
through visual interpretation and robustness accuracy under adversarial
attacks. Results show that FViTs are more robust against adversarial attacks
while maintaining the explainability of attention, indicating higher
faithfulness.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17984" title="Abstract">arXiv:2311.17984</a> [<a href="/pdf/2311.17984" title="Download PDF">pdf</a>, <a href="/format/2311.17984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+S">Sherwin Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Skorokhodov%2C+I">Ivan Skorokhodov</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+V">Victor Rong</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+J">Jeong Joon Park</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Lindell%2C+D+B">David B. Lindell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://sherwinbahmani.github.io/4dfy">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent breakthroughs in text-to-4D generation rely on pre-trained
text-to-image and text-to-video models to generate dynamic 3D scenes. However,
current text-to-4D methods face a three-way tradeoff between the quality of
scene appearance, 3D structure, and motion. For example, text-to-image models
and their 3D-aware variants are trained on internet-scale image datasets and
can be used to produce scenes with realistic appearance and 3D structure -- but
no motion. Text-to-video models are trained on relatively smaller video
datasets and can produce scenes with motion, but poorer appearance and 3D
structure. While these models have complementary strengths, they also have
opposing weaknesses, making it difficult to combine them in a way that
alleviates this three-way tradeoff. Here, we introduce hybrid score
distillation sampling, an alternating optimization procedure that blends
supervision signals from multiple pre-trained diffusion models and incorporates
benefits of each for high-fidelity text-to-4D generation. Using hybrid SDS, we
demonstrate synthesis of 4D scenes with compelling appearance, 3D structure,
and motion.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18009" title="Abstract">arXiv:2311.18009</a> [<a href="/pdf/2311.18009" title="Download PDF">pdf</a>, <a href="/format/2311.18009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration and evaluation of a motion measurement system for PET  imaging studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ti Wu</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I+I">Iulian I. Iordachita</a>, 
<a href="/search/cs?searchtype=author&query=Kazanzides%2C+P">Peter Kazanzides</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2311.17863">arXiv:2311.17863</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Medical Robotics Research, vol.08, n.01n02, p.2340003,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Positron Emission Tomography (PET) enables functional imaging of deep brain
structures, but the bulk and weight of current systems preclude their use
during many natural human activities, such as locomotion. The proposed
long-term solution is to construct a robotic system that can support an imaging
system surrounding the subject's head, and then move the system to accommodate
natural motion. This requires a system to measure the motion of the head with
respect to the imaging ring, for use by both the robotic system and the image
reconstruction software. We report here the design, calibration, and
experimental evaluation of a parallel string encoder mechanism for sensing this
motion. Our results indicate that with kinematic calibration, the measurement
system can achieve accuracy within 0.5mm, especially for small motions.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18020" title="Abstract">arXiv:2311.18020</a> [<a href="/pdf/2311.18020" title="Download PDF">pdf</a>, <a href="/ps/2311.18020" title="Download PostScript">ps</a>, <a href="/format/2311.18020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Regulation of Dynamical Systems to Solutions of Constrained  Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yiting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cothren%2C+L">Liliaokeawawa Cothren</a>, 
<a href="/search/eess?searchtype=author&query=Cortes%2C+J">Jorge Cortes</a>, 
<a href="/search/eess?searchtype=author&query=Dall%27Anese%2C+E">Emiliano Dall&#x27;Anese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication on IEEE Control Systems Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper considers the problem of regulating a dynamical system to
equilibria that are defined as solutions of an input- and state-constrained
optimization problem. To solve this regulation task, we design a state feedback
controller based on a continuous approximation of the projected gradient flow.
We first show that the equilibria of the interconnection between the plant and
the proposed controller correspond to critical points of the constrained
optimization problem. We then derive sufficient conditions to ensure that, for
the closed-loop system, isolated locally optimal solutions of the optimization
problem are locally exponentially stable and show that input constraints are
satisfied at all times by identifying an appropriate forward-invariant set.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18021" title="Abstract">arXiv:2311.18021</a> [<a href="/pdf/2311.18021" title="Download PDF">pdf</a>, <a href="/format/2311.18021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Improving In-Context Learning on Vision-language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhen Han</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bailan He</a>, 
<a href="/search/cs?searchtype=author&query=Buckley%2C+M">Mark Buckley</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, in-context learning (ICL) on large language models (LLMs) has
received great attention, and this technique can also be applied to
vision-language models (VLMs) built upon LLMs. These VLMs can respond to
queries by conditioning responses on a series of multimodal demonstrations,
which comprise images, queries, and answers. Though ICL has been extensively
studied on LLMs, its research on VLMs remains limited. The inclusion of
additional visual information in the demonstrations motivates the following
research questions: which of the two modalities in the demonstration is more
significant? How can we select effective multimodal demonstrations to enhance
ICL performance? This study investigates the significance of both visual and
language information. Our findings indicate that ICL in VLMs is predominantly
driven by the textual information in the demonstrations whereas the visual
information in the demonstrations barely affects the ICL performance.
Subsequently, we provide an understanding of the findings by analyzing the
model information flow and comparing model inner states given different ICL
settings. Motivated by our analysis, we propose a simple yet effective
approach, termed Mixed Modality In-Context Example Selection (MMICES), which
considers both visual and language modalities when selecting demonstrations and
shows better ICL performance. Extensive experiments are conducted to support
our findings, understanding, and improvement of the ICL performance of VLMs.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18022" title="Abstract">arXiv:2311.18022</a> [<a href="/pdf/2311.18022" title="Download PDF">pdf</a>, <a href="/format/2311.18022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A trainable manifold for accurate approximation with ReLU Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milkert%2C+M">Max Milkert</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+F">Forrest Laine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a novel technique for exercising greater control of the weights of
ReLU activated neural networks to produce more accurate function
approximations. Many theoretical works encode complex operations into ReLU
networks using smaller base components. In these works, a common base component
is a constant width approximation to x^2, which has exponentially decaying
error with respect to depth. We extend this block to represent a greater range
of convex one-dimensional functions. We derive a manifold of weights such that
the output of these new networks utilizes exponentially many piecewise-linear
segments. This manifold guides their training process to overcome drawbacks
associated with random initialization and unassisted gradient descent. We train
these networks to approximate functions which do not necessarily lie on the
manifold, showing a significant reduction of error values over conventional
approaches.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18025" title="Abstract">arXiv:2311.18025</a> [<a href="/pdf/2311.18025" title="Download PDF">pdf</a>, <a href="/format/2311.18025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Probabilistic Method to Predict Classifier Accuracy on Larger Datasets  given Small Pilot Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harvey%2C+E">Ethan Harvey</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wansu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kent%2C+D+M">David M. Kent</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+M+C">Michael C. Hughes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Practitioners building classifiers often start with a smaller pilot dataset
and plan to grow to larger data in the near future. Such projects need a
toolkit for extrapolating how much classifier accuracy may improve from a 2x,
10x, or 50x increase in data size. While existing work has focused on finding a
single "best-fit" curve using various functional forms like power laws, we
argue that modeling and assessing the uncertainty of predictions is critical
yet has seen less attention. In this paper, we propose a Gaussian process model
to obtain probabilistic extrapolations of accuracy or similar performance
metrics as dataset size increases. We evaluate our approach in terms of error,
likelihood, and coverage across six datasets. Though we focus on medical tasks
and image modalities, our open source approach generalizes to any kind of
classifier.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18028" title="Abstract">arXiv:2311.18028</a> [<a href="/pdf/2311.18028" title="Download PDF">pdf</a>, <a href="/format/2311.18028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filtered Semi-Markov CRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaratiana%2C+U">Urchade Zaratiana</a>, 
<a href="/search/cs?searchtype=author&query=Tomeh%2C+N">Nadi Tomeh</a>, 
<a href="/search/cs?searchtype=author&query=Khbir%2C+N+E">Niama El Khbir</a>, 
<a href="/search/cs?searchtype=author&query=Holat%2C+P">Pierre Holat</a>, 
<a href="/search/cs?searchtype=author&query=Charnois%2C+T">Thierry Charnois</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Semi-Markov CRF has been proposed as an alternative to the traditional Linear
Chain CRF for text segmentation tasks such as Named Entity Recognition (NER).
Unlike CRF, which treats text segmentation as token-level prediction, Semi-CRF
considers segments as the basic unit, making it more expressive. However,
Semi-CRF suffers from two major drawbacks: (1) quadratic complexity over
sequence length, as it operates on every span of the input sequence, and (2)
inferior performance compared to CRF for sequence labeling tasks like NER. In
this paper, we introduce Filtered Semi-Markov CRF, a variant of Semi-CRF that
addresses these issues by incorporating a filtering step to eliminate
irrelevant segments, reducing complexity and search space. Our approach is
evaluated on several NER benchmarks, where it outperforms both CRF and Semi-CRF
while being significantly faster. The implementation of our method is available
on \href{https://github.com/urchade/Filtered-Semi-Markov-CRF}{Github}.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18029" title="Abstract">arXiv:2311.18029</a> [<a href="/pdf/2311.18029" title="Download PDF">pdf</a>, <a href="/format/2311.18029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bag of Receptive Fields for Time Series Extrinsic Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spinnato%2C+F">Francesco Spinnato</a>, 
<a href="/search/cs?searchtype=author&query=Guidotti%2C+R">Riccardo Guidotti</a>, 
<a href="/search/cs?searchtype=author&query=Monreale%2C+A">Anna Monreale</a>, 
<a href="/search/cs?searchtype=author&query=Nanni%2C+M">Mirco Nanni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">High-dimensional time series data poses challenges due to its dynamic nature,
varying lengths, and presence of missing values. This kind of data requires
extensive preprocessing, limiting the applicability of existing Time Series
Classification and Time Series Extrinsic Regression techniques. For this
reason, we propose BORF, a Bag-Of-Receptive-Fields model, which incorporates
notions from time series convolution and 1D-SAX to handle univariate and
multivariate time series with varying lengths and missing values. We evaluate
BORF on Time Series Classification and Time Series Extrinsic Regression tasks
using the full UEA and UCR repositories, demonstrating its competitive
performance against state-of-the-art methods. Finally, we outline how this
representation can naturally provide saliency and feature-based explanations.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18034" title="Abstract">arXiv:2311.18034</a> [<a href="/pdf/2311.18034" title="Download PDF">pdf</a>, <a href="/format/2311.18034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen-Yi%2C+A+W">Andrea W Wen-Yi</a>, 
<a href="/search/cs?searchtype=author&query=Mimno%2C+D">David Mimno</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Cross-lingual transfer learning is an important property of multilingual
large language models (LLMs). But how do LLMs represent relationships between
languages? Every language model has an input layer that maps tokens to vectors.
This ubiquitous layer of language models is often overlooked. We find that
similarities between these input embeddings are highly interpretable and that
the geometry of these embeddings differs between model families. In one case
(XLM-RoBERTa), embeddings encode language: tokens in different writing systems
can be linearly separated with an average of 99.2% accuracy. Another family
(mT5) represents cross-lingual semantic similarity: the 50 nearest neighbors
for any token represent an average of 7.61 writing systems, and are frequently
translations. This result is surprising given that there is no explicit
parallel cross-lingual training corpora and no explicit incentive for
translations in pre-training objectives. Our research opens the door for
investigations in 1) The effect of pre-training and model architectures on
representations of languages and 2) The applications of cross-lingual
representations embedded in language models.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18035" title="Abstract">arXiv:2311.18035</a> [<a href="/pdf/2311.18035" title="Download PDF">pdf</a>, <a href="/format/2311.18035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransOpt: Transformer-based Representation Learning for Optimization  Problem Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cenikj%2C+G">Gjorgjina Cenikj</a>, 
<a href="/search/cs?searchtype=author&query=Petelin%2C+G">Ga&#x161;per Petelin</a>, 
<a href="/search/cs?searchtype=author&query=Eftimov%2C+T">Tome Eftimov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a representation of optimization problem instances using a
transformer-based neural network architecture trained for the task of problem
classification of the 24 problem classes from the Black-box Optimization
Benchmarking (BBOB) benchmark. We show that transformer-based methods can be
trained to recognize problem classes with accuracies in the range of 70\%-80\%
for different problem dimensions, suggesting the possible application of
transformer architectures in acquiring representations for black-box
optimization problems.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18036" title="Abstract">arXiv:2311.18036</a> [<a href="/pdf/2311.18036" title="Download PDF">pdf</a>, <a href="/format/2311.18036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven, Non-Linear, Parameterized Reduced Order Model of Metal 3D  Printing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brown%2C+A+L">Aaron L. Brown</a>, 
<a href="/search/math?searchtype=author&query=Chin%2C+E+B">Eric B. Chin</a>, 
<a href="/search/math?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>, 
<a href="/search/math?searchtype=author&query=Khairallah%2C+S+A">Saad A. Khairallah</a>, 
<a href="/search/math?searchtype=author&query=McKeown%2C+J+T">Joseph T. McKeown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Directed energy deposition (DED) is a promising metal additive manufacturing
technology capable of 3D printing metal parts with complex geometries at lower
cost compared to traditional manufacturing. The technology is most effective
when process parameters like laser scan speed and power are optimized for a
particular geometry and alloy. To accelerate optimization, we apply a
data-driven, parameterized, non-linear reduced-order model (ROM) called
Gaussian Process Latent Space Dynamics Identification (GPLaSDI) to
physics-based DED simulation data. With an appropriate choice of
hyperparameters, GPLaSDI is an effective ROM for this application, with a
worst-case error of about 8% and a speed-up of about 1,000,000x with respect to
the corresponding physics-based data.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18040" title="Abstract">arXiv:2311.18040</a> [<a href="/pdf/2311.18040" title="Download PDF">pdf</a>, <a href="/format/2311.18040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Trustworthiness of AI-Enabled Decision Support Systems:  Validation of the Multisource AI Scorecard Table (MAST)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salehi%2C+P">Pouria Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+Y">Yang Ba</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Nayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mosallanezhad%2C+A">Ahmadreza Mosallanezhad</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Anna Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+M+C">Myke C. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieqiong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bhatti%2C+S">Shawaiz Bhatti</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+J">James Sung</a>, 
<a href="/search/cs?searchtype=author&query=Blasch%2C+E">Erik Blasch</a>, 
<a href="/search/cs?searchtype=author&query=Mancenido%2C+M+V">Michelle V. Mancenido</a>, 
<a href="/search/cs?searchtype=author&query=Chiou%2C+E+K">Erin K. Chiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The Multisource AI Scorecard Table (MAST) is a checklist tool based on
analytic tradecraft standards to inform the design and evaluation of
trustworthy AI systems. In this study, we evaluate whether MAST is associated
with people's trust perceptions in AI-enabled decision support systems
(AI-DSSs). Evaluating trust in AI-DSSs poses challenges to researchers and
practitioners. These challenges include identifying the components,
capabilities, and potential of these systems, many of which are based on the
complex deep learning algorithms that drive DSS performance and preclude
complete manual inspection. We developed two interactive, AI-DSS test
environments using the MAST criteria. One emulated an identity verification
task in security screening, and another emulated a text summarization system to
aid in an investigative reporting task. Each test environment had one version
designed to match low-MAST ratings, and another designed to match high-MAST
ratings, with the hypothesis that MAST ratings would be positively related to
the trust ratings of these systems. A total of 177 subject matter experts were
recruited to interact with and evaluate these systems. Results generally show
higher MAST ratings for the high-MAST conditions compared to the low-MAST
groups, and that measures of trust perception are highly correlated with the
MAST ratings. We conclude that MAST can be a useful tool for designing and
evaluating systems that will engender high trust perceptions, including AI-DSS
that may be used to support visual screening and text summarization tasks.
However, higher MAST ratings may not translate to higher joint performance.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18041" title="Abstract">arXiv:2311.18041</a> [<a href="/pdf/2311.18041" title="Download PDF">pdf</a>, <a href="/format/2311.18041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Conversational Summarization Evaluations with small Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manuvinakurike%2C+R">Ramesh Manuvinakurike</a>, 
<a href="/search/cs?searchtype=author&query=Sahay%2C+S">Saurav Sahay</a>, 
<a href="/search/cs?searchtype=author&query=Manepalli%2C+S">Sangeeta Manepalli</a>, 
<a href="/search/cs?searchtype=author&query=Nachman%2C+L">Lama Nachman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at RoF0Mo workshop at Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) exhibit powerful summarization abilities.
However, their capabilities on conversational summarization remains under
explored. In this work we evaluate LLMs (approx. 10 billion parameters) on
conversational summarization and showcase their performance on various prompts.
We show that the summaries generated by models depend on the instructions and
the performance of LLMs vary with different instructions sometimes resulting
steep drop in ROUGE scores if prompts are not selected carefully. We also
evaluate the models with human evaluations and discuss the limitations of the
models on conversational summarization
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18044" title="Abstract">arXiv:2311.18044</a> [<a href="/pdf/2311.18044" title="Download PDF">pdf</a>, <a href="/format/2311.18044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning in Robotics: An Upcoming Breakthrough? A Review of  Promises and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaquier%2C+N">No&#xe9;mie Jaquier</a>, 
<a href="/search/cs?searchtype=author&query=Welle%2C+M+C">Michael C. Welle</a>, 
<a href="/search/cs?searchtype=author&query=Gams%2C+A">Andrej Gams</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kunpeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Fichera%2C+B">Bernardo Fichera</a>, 
<a href="/search/cs?searchtype=author&query=Billard%2C+A">Aude Billard</a>, 
<a href="/search/cs?searchtype=author&query=Ude%2C+A">Ale&#x161; Ude</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>, 
<a href="/search/cs?searchtype=author&query=Kragi%C4%87%2C+D">Danica Kragi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning is a conceptually-enticing paradigm in pursuit of truly
intelligent embodied agents. The core concept -- reusing prior knowledge to
learn in and from novel situations -- is successfully leveraged by humans to
handle novel situations. In recent years, transfer learning has received
renewed interest from the community from different perspectives, including
imitation learning, domain adaptation, and transfer of experience from
simulation to the real world, among others. In this paper, we unify the concept
of transfer learning in robotics and provide the first taxonomy of its kind
considering the key concepts of robot, task, and environment. Through a review
of the promises and challenges in the field, we identify the need of
transferring at different abstraction levels, the need of quantifying the
transfer gap and the quality of transfer, as well as the dangers of negative
transfer. Via this position paper, we hope to channel the effort of the
community towards the most significant roadblocks to realize the full potential
of transfer learning in robotics.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18046" title="Abstract">arXiv:2311.18046</a> [<a href="/pdf/2311.18046" title="Download PDF">pdf</a>, <a href="/format/2311.18046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Data Work Count
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandhiramowuli%2C+S">Srravya Chandhiramowuli</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+A">Alex Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Heitlinger%2C+S">Sara Heitlinger</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Ding Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at CSCW 2024. Forthcoming in the Proceedings of the ACM on Human-Computer Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">In this paper, we examine the work of data annotation. Specifically, we focus
on the role of counting or quantification in organising annotation work. Based
on an ethnographic study of data annotation in two outsourcing centres in
India, we observe that counting practices and its associated logics are an
integral part of day-to-day annotation activities. In particular, we call
attention to the presumption of total countability observed in annotation - the
notion that everything, from tasks, datasets and deliverables, to workers, work
time, quality and performance, can be managed by applying the logics of
counting. To examine this, we draw on sociological and socio-technical
scholarship on quantification and develop the lens of a 'regime of counting'
that makes explicit the specific counts, practices, actors and structures that
underpin the pervasive counting in annotation. We find that within the AI
supply chain and data work, counting regimes aid the assertion of authority by
the AI clients (also called requesters) over annotation processes, constituting
them as reductive, standardised, and homogenous. We illustrate how this has
implications for i) how annotation work and workers get valued, ii) the role
human discretion plays in annotation, and iii) broader efforts to introduce
accountable and more just practices in AI. Through these implications, we
illustrate the limits of operating within the logic of total countability.
Instead, we argue for a view of counting as partial - located in distinct
geographies, shaped by specific interests and accountable in only limited ways.
This, we propose, sets the stage for a fundamentally different orientation to
counting and what counts in data annotation.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18047" title="Abstract">arXiv:2311.18047</a> [<a href="/pdf/2311.18047" title="Download PDF">pdf</a>, <a href="/ps/2311.18047" title="Download PostScript">ps</a>, <a href="/format/2311.18047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validation of Collision Detection and Avoidance Methods for Urban Air  Mobility through Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panchal%2C+I">Isha Panchal</a>, 
<a href="/search/cs?searchtype=author&query=Armanini%2C+S+F">Sophie F. Armanini</a>, 
<a href="/search/cs?searchtype=author&query=Metz%2C+I+C">Isabel C. Metz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Urban Air Mobility is a new concept of regional aviation that has been
growing in popularity as a solution to the issue of ever-increasing ground
traffic. Electric vehicles with vertical take-off and landing capabilities are
being developed by numerous market companies as a result of the push toward
environmentally sustainable aviation. The next stage in the eVTOL development
process would be to define the concept of operation of these conceptual
aircraft and then to integrate them with the existing airspace once they are
airborne. In addition to coordinating with conventional air traffic and other
Urban Air Mobility (UAM) vehicles, collision avoidance with uncooperative
airspace users has to be addressed. Birds and drones of all sizes could be
dangerous for these low-flying aircraft. Innovative collision detection and
avoidance techniques need to be employed due to the uncooperative nature of
these airspace users and different performance characteristics of urban air
mobility vehicles compared to classical fixed-wing aircraft. The aim of this
study is to validate one such system by means of fast-time solutions. This
system uses a decision tree and safety envelopes to prevent collisions with
non-cooperative airspace members. The system is designed to work with different
aircraft configurations used for Urban Air Mobility (UAM) operations. Various
scenarios are modelled by varying intruder type, location, flight path among
others. Changes in flight time and closest point of approach are assessed to
evaluate the system with regard to safety and efficiency.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18048" title="Abstract">arXiv:2311.18048</a> [<a href="/pdf/2311.18048" title="Download PDF">pdf</a>, <a href="/format/2311.18048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Interventional Perspective on Identifiability in Gaussian LTI Systems  with Independent Component Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+G">Goutham Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Reizinger%2C+P">Patrik Reizinger</a>, 
<a href="/search/cs?searchtype=author&query=Brendel%2C+W">Wieland Brendel</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY); Methodology (stat.ME)

</div>
<p class="mathjax">We investigate the relationship between system identification and
intervention design in dynamical systems. While previous research demonstrated
how identifiable representation learning methods, such as Independent Component
Analysis (ICA), can reveal cause-effect relationships, it relied on a passive
perspective without considering how to collect data. Our work shows that in
Gaussian Linear Time-Invariant (LTI) systems, the system parameters can be
identified by introducing diverse intervention signals in a multi-environment
setting. By harnessing appropriate diversity assumptions motivated by the ICA
literature, our findings connect experiment design and representational
identifiability in dynamical systems. We corroborate our findings on synthetic
and (simulated) physical data. Additionally, we show that Hidden Markov Models,
in general, and (Gaussian) LTI systems, in particular, fulfil a generalization
of the Causal de Finetti theorem with continuous parameters.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18054" title="Abstract">arXiv:2311.18054</a> [<a href="/pdf/2311.18054" title="Download PDF">pdf</a>, <a href="/format/2311.18054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Know You Did Not Write That! A Sampling Based Watermarking Method for  Identifying Machine Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kele%C5%9F%2C+K+E">Kaan Efe Kele&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrb%C3%BCz%2C+%C3%96+K">&#xd6;mer Kaan G&#xfc;rb&#xfc;z</a>, 
<a href="/search/cs?searchtype=author&query=Kutlu%2C+M">Mucahid Kutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Potential harms of Large Language Models such as mass misinformation and
plagiarism can be partially mitigated if there exists a reliable way to detect
machine generated text. In this paper, we propose a new watermarking method to
detect machine-generated texts. Our method embeds a unique pattern within the
generated text, ensuring that while the content remains coherent and natural to
human readers, it carries distinct markers that can be identified
algorithmically. Specifically, we intervene with the token sampling process in
a way which enables us to trace back our token choices during the detection
phase. We show how watermarking affects textual quality and compare our
proposed method with a state-of-the-art watermarking method in terms of
robustness and detectability. Through extensive experiments, we demonstrate the
effectiveness of our watermarking scheme in distinguishing between watermarked
and non-watermarked text, achieving high detection rates while maintaining
textual quality.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18055" title="Abstract">arXiv:2311.18055</a> [<a href="/pdf/2311.18055" title="Download PDF">pdf</a>, <a href="/ps/2311.18055" title="Download PostScript">ps</a>, <a href="/format/2311.18055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Hierarchical Origami Metastructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Di+Lallo%2C+A">Antonio Di Lallo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junxi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yinding Chi</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jie Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Geometric Topology (math.GT); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Shape-morphing capabilities are crucial for enabling multifunctionality in
both biological and artificial systems. Various strategies for shape morphing
have been proposed for applications in metamaterials and robotics. However, few
of these approaches have achieved the ability to seamlessly transform into a
multitude of volumetric shapes post-fabrication using a relatively simple
actuation and control mechanism. Taking inspiration from thick origami and
hierarchies in nature, we present a new hierarchical construction method based
on polyhedrons to create an extensive library of compact origami
metastructures. We show that a single hierarchical origami structure can
autonomously adapt to over 103 versatile architectural configurations, achieved
with the utilization of fewer than 3 actuation degrees of freedom and employing
simple transition kinematics. We uncover the fundamental principles governing
theses shape transformation through theoretical models. Furthermore, we also
demonstrate the wide-ranging potential applications of these transformable
hierarchical structures. These include their uses as untethered and autonomous
robotic transformers capable of various gait-shifting and multidirectional
locomotion, as well as rapidly self-deployable and self-reconfigurable
architecture, exemplifying its scalability up to the meter scale. Lastly, we
introduce the concept of multitask reconfigurable and deployable space robots
and habitats, showcasing the adaptability and versatility of these
metastructures.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18056" title="Abstract">arXiv:2311.18056</a> [<a href="/pdf/2311.18056" title="Download PDF">pdf</a>, <a href="/format/2311.18056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLU-QP: A GPU-Accelerated Quadratic Programming Solver for  Model-Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bishop%2C+A+L">Arun L. Bishop</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Z">John Z. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gurumurthy%2C+S">Swaminathan Gurumurthy</a>, 
<a href="/search/cs?searchtype=author&query=Tracy%2C+K">Kevin Tracy</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+Z">Zachary Manchester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present ReLU-QP, a GPU-accelerated solver for quadratic programs (QPs)
that is capable of solving high-dimensional control problems at real-time
rates. ReLU-QP is derived by exactly reformulating the Alternating Direction
Method of Multipliers (ADMM) algorithm for solving QPs as a deep, weight-tied
neural network with rectified linear unit (ReLU) activations. This
reformulation enables the deployment of ReLU-QP on GPUs using standard
machine-learning toolboxes. We evaluate the performance of ReLU-QP across three
model-predictive control (MPC) benchmarks: stabilizing random linear dynamical
systems with control limits, balancing an Atlas humanoid robot on a single
foot, and tracking whole-body reference trajectories on a quadruped equipped
with a six-degree-of-freedom arm. These benchmarks indicate that ReLU-QP is
competitive with state-of-the-art CPU-based solvers for small-to-medium-scale
problems and offers order-of-magnitude speed improvements for larger-scale
problems.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18057" title="Abstract">arXiv:2311.18057</a> [<a href="/pdf/2311.18057" title="Download PDF">pdf</a>, <a href="/ps/2311.18057" title="Download PostScript">ps</a>, <a href="/format/2311.18057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non Linear Software Documentation with Interactive Code Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nassif%2C+M">Mathieu Nassif</a>, 
<a href="/search/cs?searchtype=author&query=Robillard%2C+M+P">Martin P. Robillard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Documentation enables sharing knowledge between the developers of a
technology and its users. Creating quality documents, however, is challenging:
Documents must satisfy the needs of a large audience without being overwhelming
for individuals. We address this challenge with a new document format, named
Casdoc. Casdoc documents are interactive resources centered around code
examples for programmers. Explanations of the code elements are presented as
annotations that the readers reveal based on their needs. We evaluated Casdoc
in a field study with over 300 participants who used 126 documents as part of a
software design course. The majority of participants adopted Casdoc instead of
a baseline format during the study. We observed that interactive documents can
contain more information than static documents without being distracting to
readers. We also gathered insights into five aspects of Casdoc that can be
applied to other formats, and propose five guidelines to improve navigability
in online documents.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18061" title="Abstract">arXiv:2311.18061</a> [<a href="/pdf/2311.18061" title="Download PDF">pdf</a>, <a href="/format/2311.18061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural  Architecture Search in Time Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haq%2C+I+U">Ijaz Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages , 4 figures, It will submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The surge in real-time data collection across various industries has
underscored the need for advanced anomaly detection in both univariate and
multivariate time series data. Traditional methods, while comprehensive, often
struggle to capture the complex interdependencies in such data. This paper
introduces TransNAS-TSAD, a novel framework that synergizes transformer
architecture with neural architecture search (NAS), enhanced through NSGA-II
algorithm optimization. This innovative approach effectively tackles the
complexities of both univariate and multivariate time series, balancing
computational efficiency with detection accuracy. Our evaluation reveals that
TransNAS-TSAD surpasses conventional anomaly detection models, demonstrating
marked improvements in diverse data scenarios. We also propose the
Efficiency-Accuracy-Complexity Score (EACS) as a new metric for assessing model
performance, emphasizing the crucial balance between accuracy and computational
resources. TransNAS-TSAD sets a new benchmark in time series anomaly detection,
offering a versatile, efficient solution for complex real-world applications.
This research paves the way for future developments in the field, highlighting
its potential in a wide range of industry applications.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18062" title="Abstract">arXiv:2311.18062</a> [<a href="/pdf/2311.18062" title="Download PDF">pdf</a>, <a href="/format/2311.18062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Your Agent: Leveraging Large Language Models for Behavior  Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Stepputtis%2C+S">Simon Stepputtis</a>, 
<a href="/search/cs?searchtype=author&query=Sycara%2C+K">Katia Sycara</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+J">Joseph Campbell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Intelligent agents such as robots are increasingly deployed in real-world,
safety-critical settings. It is vital that these agents are able to explain the
reasoning behind their decisions to human counterparts; however, their behavior
is often produced by uninterpretable models such as deep neural networks. We
propose an approach to generate natural language explanations for an agent's
behavior based only on observations of states and actions, thus making our
method independent from the underlying model's representation. For such models,
we first learn a behavior representation and subsequently use it to produce
plausible explanations with minimal hallucination while affording user
interaction with a pre-trained large language model. We evaluate our method in
a multi-agent search-and-rescue environment and demonstrate the effectiveness
of our explanations for agents executing various behaviors. Through user
studies and empirical experiments, we show that our approach generates
explanations as helpful as those produced by a human domain expert while
enabling beneficial interactions such as clarification and counterfactual
queries.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18063" title="Abstract">arXiv:2311.18063</a> [<a href="/pdf/2311.18063" title="Download PDF">pdf</a>, <a href="/format/2311.18063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TurkishBERTweet: Fast and Reliable Large Language Model for Social Media  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Najafi%2C+A">Ali Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Varol%2C+O">Onur Varol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Turkish is one of the most popular languages in the world. Wide us of this
language on social media platforms such as Twitter, Instagram, or Tiktok and
strategic position of the country in the world politics makes it appealing for
the social network researchers and industry. To address this need, we introduce
TurkishBERTweet, the first large scale pre-trained language model for Turkish
social media built using almost 900 million tweets. The model shares the same
architecture as base BERT model with smaller input length, making
TurkishBERTweet lighter than BERTurk and can have significantly lower inference
time. We trained our model using the same approach for RoBERTa model and
evaluated on two text classification tasks: Sentiment Classification and Hate
Speech Detection. We demonstrate that TurkishBERTweet outperforms the other
available alternatives on generalizability and its lower inference time gives
significant advantage to process large-scale datasets. We also compared our
models with the commercial OpenAI solutions in terms of cost and performance to
demonstrate TurkishBERTweet is scalable and cost-effective solution. As part of
our research, we released TurkishBERTweet and fine-tuned LoRA adapters for the
mentioned tasks under the MIT License to facilitate future research and
applications on Turkish social media. Our TurkishBERTweet model is available
at: https://github.com/ViralLab/TurkishBERTweet
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18064" title="Abstract">arXiv:2311.18064</a> [<a href="/pdf/2311.18064" title="Download PDF">pdf</a>, <a href="/format/2311.18064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GELDA: A generative language annotation framework to reveal visual  biases in datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabra%2C+K">Krish Kabra</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+K+M">Kathleen M. Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+G">Guha Balakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 15 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Bias analysis is a crucial step in the process of creating fair datasets for
training and evaluating computer vision models. The bottleneck in dataset
analysis is annotation, which typically requires: (1) specifying a list of
attributes relevant to the dataset domain, and (2) classifying each
image-attribute pair. While the second step has made rapid progress in
automation, the first has remained human-centered, requiring an experimenter to
compile lists of in-domain attributes. However, an experimenter may have
limited foresight leading to annotation "blind spots," which in turn can lead
to flawed downstream dataset analyses. To combat this, we propose GELDA, a
nearly automatic framework that leverages large generative language models
(LLMs) to propose and label various attributes for a domain. GELDA takes a
user-defined domain caption (e.g., "a photo of a bird," "a photo of a living
room") and uses an LLM to hierarchically generate attributes. In addition,
GELDA uses the LLM to decide which of a set of vision-language models (VLMs) to
use to classify each attribute in images. Results on real datasets show that
GELDA can generate accurate and diverse visual attribute suggestions, and
uncover biases such as confounding between class labels and background
features. Results on synthetic datasets demonstrate that GELDA can be used to
evaluate the biases of text-to-image diffusion models and generative
adversarial networks. Overall, we show that while GELDA is not accurate enough
to replace human annotators, it can serve as a complementary tool to help
humans analyze datasets in a cheap, low-effort, and flexible manner.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18068" title="Abstract">arXiv:2311.18068</a> [<a href="/pdf/2311.18068" title="Download PDF">pdf</a>, <a href="/format/2311.18068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALSTER: A Local Spatio-Temporal Expert for Online 3D Semantic  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weder%2C+S">Silvan Weder</a>, 
<a href="/search/cs?searchtype=author&query=Engelmann%2C+F">Francis Engelmann</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nberger%2C+J+L">Johannes L. Sch&#xf6;nberger</a>, 
<a href="/search/cs?searchtype=author&query=Seki%2C+A">Akihito Seki</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose an online 3D semantic segmentation method that incrementally
reconstructs a 3D semantic map from a stream of RGB-D frames. Unlike offline
methods, ours is directly applicable to scenarios with real-time constraints,
such as robotics or mixed reality. To overcome the inherent challenges of
online methods, we make two main contributions. First, to effectively extract
information from the input RGB-D video stream, we jointly estimate geometry and
semantic labels per frame in 3D. A key focus of our approach is to reason about
semantic entities both in the 2D input and the local 3D domain to leverage
differences in spatial context and network architectures. Our method predicts
2D features using an off-the-shelf segmentation network. The extracted 2D
features are refined by a lightweight 3D network to enable reasoning about the
local 3D structure. Second, to efficiently deal with an infinite stream of
input RGB-D frames, a subsequent network serves as a temporal expert predicting
the incremental scene updates by leveraging 2D, 3D, and past information in a
learned manner. These updates are then integrated into a global scene
representation. Using these main contributions, our method can enable scenarios
with real-time constraints and can scale to arbitrary scene sizes by processing
and updating the scene only in a local region defined by the new measurement.
Our experiments demonstrate improved results compared to existing online
methods that purely operate in local regions and show that complementary
sources of information can boost the performance. We provide a thorough
ablation study on the benefits of different architectural as well as
algorithmic design decisions. Our method yields competitive results on the
popular ScanNet benchmark and SceneNN dataset.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18070" title="Abstract">arXiv:2311.18070</a> [<a href="/pdf/2311.18070" title="Download PDF">pdf</a>, <a href="/format/2311.18070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LoRa communication for Urban VANETs: Feasibility and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karunathilake%2C+T">Thenuka Karunathilake</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+A">Anna F&#xf6;rster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Vehicular Ad-Hoc Networks (VANETs) were introduced mainly to increase
vehicular safety by enabling communication between vehicles and infrastructure
to improve overall awareness. The vehicles in a VANET are expected to exchange
numerous messages generated by multiple applications, but mainly, these
applications can be subdivided into safety and non-safety. The main
communication technologies designed for VANETs, DSRC (Dedicated Short Range
Communication) and C-V2X (Cellular V2X), mainly focus on delay-sensitive
safety-related applications. However, sharing the same bandwidth for safety and
non-safety applications will increase the burden on the communication channel
and can cause an increase in the overall latencies. Therefore, this work
analyses the feasibility of using LoRa communication for non-safety-related
urban VANET applications. We conducted multiple real-world experiments to
analyse the performance of LoRa communication in various urban VANET scenarios.
Our results show that LoRa communication handles the Dopper shifts caused by
the urban VANET speeds with both Spreading Factor (SF) 7 and 12. However,
higher SF was more vulnerable to Doppler shifts than lower SF. Furthermore, the
results illustrate that the Line-of-Sight (LoS) condition significantly affects
the LoRa communication, especially in the case of lower SF.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18071" title="Abstract">arXiv:2311.18071</a> [<a href="/pdf/2311.18071" title="Download PDF">pdf</a>, <a href="/format/2311.18071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turn Down the Noise: Leveraging Diffusion Models for Test-time  Adaptation via Pseudo-label Ensembling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+M">Mrigank Raman</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rohan Shah</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+A">Akash Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+P">Pranit Chawla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Workshop on Distribution Shifts: New Frontiers with Foundation Models at Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of test-time adaptation is to adapt a source-pretrained model to a
continuously changing target domain without relying on any source data.
Typically, this is either done by updating the parameters of the model (model
adaptation) using inputs from the target domain or by modifying the inputs
themselves (input adaptation). However, methods that modify the model suffer
from the issue of compounding noisy updates whereas methods that modify the
input need to adapt to every new data point from scratch while also struggling
with certain domain shifts. We introduce an approach that leverages a
pre-trained diffusion model to project the target domain images closer to the
source domain and iteratively updates the model via pseudo-label ensembling.
Our method combines the advantages of model and input adaptations while
mitigating their shortcomings. Our experiments on CIFAR-10C demonstrate the
superiority of our approach, outperforming the strongest baseline by an average
of 1.7% across 15 diverse corruptions and surpassing the strongest input
adaptation baseline by an average of 18%.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18072" title="Abstract">arXiv:2311.18072</a> [<a href="/pdf/2311.18072" title="Download PDF">pdf</a>, <a href="/format/2311.18072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Large-Scale Preventive Security Constrained  DC Optimal Power Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonho Park</a>, 
<a href="/search/cs?searchtype=author&query=Van+Hentenryck%2C+P">Pascal Van Hentenryck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Power Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Security-Constrained Optimal Power Flow (SCOPF) plays a crucial role in power
grid stability but becomes increasingly complex as systems grow. This paper
introduces PDL-SCOPF, a self-supervised end-to-end primal-dual learning
framework for producing near-optimal solutions to large-scale SCOPF problems in
milliseconds. Indeed, PDL-SCOPF remedies the limitations of supervised
counterparts that rely on training instances with their optimal solutions,
which becomes impractical for large-scale SCOPF problems. PDL-SCOPF mimics an
Augmented Lagrangian Method (ALM) for training primal and dual networks that
learn the primal solutions and the Lagrangian multipliers, respectively, to the
unconstrained optimizations. In addition, PDL-SCOPF incorporates a repair layer
to ensure the feasibility of the power balance in the nominal case, and a
binary search layer to compute, using the Automatic Primary Response (APR), the
generator dispatches in the contingencies. The resulting differentiable program
can then be trained end-to-end using the objective function of the SCOPF and
the power balance constraints of the contingencies. Experimental results
demonstrate that the PDL-SCOPF delivers accurate feasible solutions with
minimal optimality gaps. The framework underlying PDL-SCOPF aims at bridging
the gap between traditional optimization methods and machine learning,
highlighting the potential of self-supervised end-to-end primal-dual learning
for large-scale optimization tasks.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18074" title="Abstract">arXiv:2311.18074</a> [<a href="/pdf/2311.18074" title="Download PDF">pdf</a>, <a href="/format/2311.18074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Projection and Robustness for Game-Theoretic Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mushuang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tseng%2C+H+E">H. Eric Tseng</a>, 
<a href="/search/eess?searchtype=author&query=Filev%2C+D">Dimitar Filev</a>, 
<a href="/search/eess?searchtype=author&query=Girard%2C+A">Anouck Girard</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Game-theoretic approaches are envisioned to bring human-like reasoning skills
and decision-making processes for autonomous vehicles (AVs). However,
challenges including game complexity and incomplete information still remain to
be addressed before they can be sufficiently practical for real-world use. Game
complexity refers to the difficulties of solving a multi-player game, which
include solution existence, algorithm convergence, and scalability. To address
these difficulties, a potential game based framework was developed in our
recent work. However, conditions on cost function design need to be enforced to
make the game a potential game. This paper relaxes the conditions and makes the
potential game approach applicable to more general scenarios, even including
the ones that cannot be molded as a potential game. Incomplete information
refers to the ego vehicle's lack of knowledge of other traffic agents' cost
functions. Cost function deviations between the ego vehicle estimated/learned
other agents' cost functions and their actual ones are often inevitable. This
motivates us to study the robustness of a game-theoretic solution. This paper
defines the robustness margin of a game solution as the maximum magnitude of
cost function deviations that can be accommodated in a game without changing
the optimality of the game solution. With this definition, closed-form
robustness margins are derived. Numerical studies using highway lane-changing
scenarios are reported.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18075" title="Abstract">arXiv:2311.18075</a> [<a href="/pdf/2311.18075" title="Download PDF">pdf</a>, <a href="/format/2311.18075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bevel-Tip Needle Deflection Modeling, Simulation, and Validation in  Multi-Layer Tissues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Al-Zogbi%2C+L">Lidia Al-Zogbi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanyun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tokuda%2C+J">Junichi Tokuda</a>, 
<a href="/search/cs?searchtype=author&query=Krieger%2C+A">Axel Krieger</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I">Iulian Iordachita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Percutaneous needle insertions are commonly performed for diagnostic and
therapeutic purposes as an effective alternative to more invasive surgical
procedures. However, the outcome of needle-based approaches relies heavily on
the accuracy of needle placement, which remains a challenge even with robot
assistance and medical imaging guidance due to needle deflection caused by
contact with soft tissues. In this paper, we present a novel mechanics-based 2D
bevel-tip needle model that can account for the effect of nonlinear
strain-dependent behavior of biological soft tissues under compression.
Real-time finite element simulation allows multiple control inputs along the
length of the needle with full three-degree-of-freedom (DOF) planar needle
motions. Cross-validation studies using custom-designed multi-layer tissue
phantoms as well as heterogeneous chicken breast tissues result in less than
1mm in-plane errors for insertions reaching depths of up to 61 mm,
demonstrating the validity and generalizability of the proposed method.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18076" title="Abstract">arXiv:2311.18076</a> [<a href="/pdf/2311.18076" title="Download PDF">pdf</a>, <a href="/format/2311.18076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nystr&#xf6;m method with missing distances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lichtenberg%2C+S">Samuel Lichtenberg</a>, 
<a href="/search/cs?searchtype=author&query=Tasissa%2C+A">Abiy Tasissa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Signal Processing (eess.SP)

</div>
<p class="mathjax">We study the problem of determining the configuration of $n$ points, referred
to as mobile nodes, by utilizing pairwise distances to $m$ fixed points known
as anchor nodes. In the standard setting, we have information about the
distances between anchors (anchor-anchor) and between anchors and mobile nodes
(anchor-mobile), but the distances between mobile nodes (mobile-mobile) are not
known. For this setup, the Nystr\"om method is a viable technique for
estimating the positions of the mobile nodes. This study focuses on the setting
where the anchor-mobile block of the distance matrix contains only partial
distance information. First, we establish a relationship between the columns of
the anchor-mobile block in the distance matrix and the columns of the
corresponding block in the Gram matrix via a graph Laplacian. Exploiting this
connection, we introduce a novel sampling model that frames the position
estimation problem as low-rank recovery of an inner product matrix, given a
subset of its expansion coefficients in a special non-orthogonal basis. This
basis and its dual basis--the central elements of our model--are explicitly
derived. Our analysis is grounded in a specific centering of the points that is
unique to the Nystr\"om method. With this in mind, we extend previous work in
Euclidean distance geometry by providing a general dual basis approach for
points centered anywhere.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18077" title="Abstract">arXiv:2311.18077</a> [<a href="/pdf/2311.18077" title="Download PDF">pdf</a>, <a href="/format/2311.18077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-based Outdoor Crowd Management for Smart Campus on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yitao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gundu%2C+K">Krishna Gundu</a>, 
<a href="/search/cs?searchtype=author&query=Zaidi%2C+Z">Zohair Zaidi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Ming Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Crowd management is crucial for a smart campus. Popular methods are
camera-based. However, conventional camera-based approaches may leak users'
personally identifiable features, jeopardizing user's privacy, which limits its
application. In this work, we investigate using affordable light detection and
ranging (LiDAR) technology to perform outdoor crowd management leveraging edge
computing. Specifically, we aim to count the number of people on a walkway of a
university campus. Besides privacy protection, LiDAR sensors are superior to
cameras since their performance will not be compromised when the campus is not
well-illuminated. We deploy LiDAR sensors on light poles to collect data from
the crowd on the campus and leverage edge accelerators to process data locally.
We proposed two different methodologies in this work: 1) a non-convolutional
neural network (CNN)-based approach, using clustering and autoencoder, and 2) a
CNN-based approach that first projects point clouds to 2D planes and then
processes the projection with conventional CNNs. Our first approach relies on
careful feature engineering, whereas our second approach does not require such
effort. However, the CNN-based approach requires more computational power than
our non-CNN-based approach. We evaluate both approaches comprehensively with
our hand-labeled real-life data collected from campus. Our evaluation results
show that the first method achieves an accuracy of 85.4%, whereas the second
method achieves 95.8%. Our CNN-based method outperforms existing solutions
significantly. We also deploy our two models on an edge accelerator, TPU, to
measure the speedup, leveraging this specialized accelerator.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18078" title="Abstract">arXiv:2311.18078</a> [<a href="/pdf/2311.18078" title="Download PDF">pdf</a>, <a href="/ps/2311.18078" title="Download PostScript">ps</a>, <a href="/format/2311.18078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Forecastability of Underlying Building Electricity Demand from Time  Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalil%2C+M">Mohamad Khalil</a>, 
<a href="/search/cs?searchtype=author&query=McGough%2C+A+S">A. Stephen McGough</a>, 
<a href="/search/cs?searchtype=author&query=Kazmi%2C+H">Hussain Kazmi</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+S">Sara Walker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Forecasting building energy consumption has become a promising solution in
Building Energy Management Systems for energy saving and optimization.
Furthermore, it can play an important role in the efficient management of the
operation of a smart grid. Different data-driven approaches to forecast the
future energy demand of buildings at different scale, and over various time
horizons, can be found in the scientific literature, including extensive
Machine Learning and Deep Learning approaches. However, the identification of
the most accurate forecaster model which can be utilized to predict the energy
demand of such a building is still challenging.In this paper, the design and
implementation of a data-driven approach to predict how forecastable the future
energy demand of a building is, without first utilizing a data-driven
forecasting model, is presented. The investigation utilizes a historical
electricity consumption time series data set with a half-hour interval that has
been collected from a group of residential buildings located in the City of
London, United Kingdom
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18082" title="Abstract">arXiv:2311.18082</a> [<a href="/pdf/2311.18082" title="Download PDF">pdf</a>, <a href="/format/2311.18082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zooming Out on Zooming In: Advancing Super-Resolution for Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolters%2C+P">Piper Wolters</a>, 
<a href="/search/cs?searchtype=author&query=Bastani%2C+F">Favyen Bastani</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Super-Resolution for remote sensing has the potential for huge impact on
planet monitoring by producing accurate and realistic high resolution imagery
on a frequent basis and a global scale. Despite a lot of attention, several
inconsistencies and challenges have prevented it from being deployed in
practice. These include the lack of effective metrics, fragmented and
relatively small-scale datasets for training, insufficient comparisons across a
suite of methods, and unclear evidence for the use of super-resolution outputs
for machine consumption. This work presents a new metric for super-resolution,
CLIPScore, that corresponds far better with human judgments than previous
metrics on an extensive study. We use CLIPScore to evaluate four standard
methods on a new large-scale dataset, S2-NAIP, and three existing benchmark
datasets, and find that generative adversarial networks easily outperform more
traditional L2 loss-based models and are more semantically accurate than modern
diffusion models. We also find that using CLIPScore as an auxiliary loss can
speed up the training of GANs by 18x and lead to improved outputs, resulting in
an effective model in diverse geographies across the world which we will
release publicly. The dataset, pre-trained model weights, and code are
available at https://github.com/allenai/satlas-super-resolution/.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18083" title="Abstract">arXiv:2311.18083</a> [<a href="/pdf/2311.18083" title="Download PDF">pdf</a>, <a href="/format/2311.18083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Co-Training: Two Views are Better than One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rothenberger%2C+J+C">Jay C. Rothenberger</a>, 
<a href="/search/cs?searchtype=author&query=Diochnos%2C+D+I">Dimitrios I. Diochnos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 14 figures, 10 tables, for implementation see <a href="https://github.com/JayRothenberger/Meta-Co-Training">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In many practical computer vision scenarios unlabeled data is plentiful, but
labels are scarce and difficult to obtain. As a result, semi-supervised
learning which leverages unlabeled data to boost the performance of supervised
classifiers have received significant attention in recent literature. One major
class of semi-supervised algorithms is co-training. In co-training two
different models leverage different independent and sufficient "views" of the
data to jointly make better predictions. During co-training each model creates
pseudo labels on unlabeled points which are used to improve the other model. We
show that in the common case when independent views are not available we can
construct such views inexpensively using pre-trained models. Co-training on the
constructed views yields a performance improvement over any of the individual
views we construct and performance comparable with recent approaches in
semi-supervised learning, but has some undesirable properties. To alleviate the
issues present with co-training we present Meta Co-Training which is an
extension of the successful Meta Pseudo Labels approach to multiple views. Our
method achieves new state-of-the-art performance on ImageNet-10% with very few
training resources, as well as outperforming prior semi-supervised work on
several other fine-grained image classification datasets.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18085" title="Abstract">arXiv:2311.18085</a> [<a href="/pdf/2311.18085" title="Download PDF">pdf</a>, <a href="/format/2311.18085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging a Randomized Key Matrix to Enhance the Security of Symmetric  Substitution Ciphers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+S">Shubham Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Khare%2C+O">Om Khare</a>, 
<a href="/search/cs?searchtype=author&query=Dravid%2C+M">Mihika Dravid</a>, 
<a href="/search/cs?searchtype=author&query=Sanghvi%2C+M">Mihika Sanghvi</a>, 
<a href="/search/cs?searchtype=author&query=Mane%2C+S">Sunil Mane</a>, 
<a href="/search/cs?searchtype=author&query=Gajaralwar%2C+A">Aadesh Gajaralwar</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+S">Saloni Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 10th IEEE Asia-Pacific Conference on Computer Science and Data Engineering 2023 (CSDE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">An innovative strategy to enhance the security of symmetric substitution
ciphers is presented, through the implementation of a randomized key matrix
suitable for various file formats, including but not limited to binary and text
files. Despite their historical relevance, symmetric substitution ciphers have
been limited by vulnerabilities to cryptanalytic methods like frequency
analysis and known plaintext attacks. The aim of our research is to mitigate
these vulnerabilities by employing a polyalphabetic substitution strategy that
incorporates a distinct randomized key matrix. This matrix plays a pivotal role
in generating a unique random key, comprising characters, encompassing both
uppercase and lowercase letters, numeric, and special characters, to derive the
corresponding ciphertext. The effectiveness of the proposed methodology in
enhancing the security of conventional substitution methods for file encryption
and decryption is supported by comprehensive testing and analysis, which
encompass computational speed, frequency analysis, keyspace examination,
Kasiski test, entropy analysis, and the utilization of a large language model.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18096" title="Abstract">arXiv:2311.18096</a> [<a href="/pdf/2311.18096" title="Download PDF">pdf</a>, <a href="/format/2311.18096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Kalman Filter using Maximum Likelihood Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duan%2C+P">Peihu Duan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+Y">Yu Xing</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper investigates the state estimation problem for unknown linear
systems with process and measurement noise. A novel data-driven Kalman filter
(DDKF) that combines model identification with state estimation is developed
using pre-collected input-output data and uncertain initial state information
of the unknown system. Specifically, the state estimation problem is first
formulated as a non-convex maximum likelihood (ML) optimization problem. Then,
to reduce the computational complexity, the optimization problem is broken down
into a series of sub-problems in a recursive manner. Based on the optimal
solutions to the sub-problems, a closed-form DDKF is designed for the unknown
system, which can estimate the state of a physically meaningful state-space
realization, rather than these up to an unknown similarity transformation. The
performance gap between the DDKF and the traditional Kalman filter with
accurate system matrices is quantified through a sample complexity bound. In
particular, when the number of the pre-collected trajectories tends to
infinity, this gap converges to zero. Moreover, the DDKF is used to facilitate
data-driven control design. A data-driven linear quadratic Gaussian controller
is defined and its closed-loop performance is characterized. Finally, the
effectiveness of the theoretical results is illustrated by numerical
simulations.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18098" title="Abstract">arXiv:2311.18098</a> [<a href="/pdf/2311.18098" title="Download PDF">pdf</a>, <a href="/format/2311.18098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Early Exiting for Collaborative Inference over Noisy Wireless  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jankowski%2C+M">Mikolaj Jankowski</a>, 
<a href="/search/cs?searchtype=author&query=Gunduz%2C+D">Deniz Gunduz</a>, 
<a href="/search/cs?searchtype=author&query=Mikolajczyk%2C+K">Krystian Mikolajczyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Collaborative inference systems are one of the emerging solutions for
deploying deep neural networks (DNNs) at the wireless network edge. Their main
idea is to divide a DNN into two parts, where the first is shallow enough to be
reliably executed at edge devices of limited computational power, while the
second part is executed at an edge server with higher computational
capabilities. The main advantage of such systems is that the input of the DNN
gets compressed as the subsequent layers of the shallow part extract only the
information necessary for the task. As a result, significant communication
savings can be achieved compared to transmitting raw input samples. In this
work, we study early exiting in the context of collaborative inference, which
allows obtaining inference results at the edge device for certain samples,
without the need to transmit the partially processed data to the edge server at
all, leading to further communication savings. The central part of our system
is the transmission-decision (TD) mechanism, which, given the information from
the early exit, and the wireless channel conditions, decides whether to keep
the early exit prediction or transmit the data to the edge server for further
processing. In this paper, we evaluate various TD mechanisms and show
experimentally, that for an image classification task over the wireless edge,
proper utilization of early exits can provide both performance gains and
significant communication savings.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18102" title="Abstract">arXiv:2311.18102</a> [<a href="/pdf/2311.18102" title="Download PDF">pdf</a>, <a href="/format/2311.18102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PatchBMI-Net: Lightweight Facial Patch-based Ensemble for BMI Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aarotale%2C+P+N">Parshuram N. Aarotale</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+T">Twyla Hill</a>, 
<a href="/search/cs?searchtype=author&query=Rattani%2C+A">Ajita Rattani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Due to an alarming trend related to obesity affecting 93.3 million adults in
the United States alone, body mass index (BMI) and body weight have drawn
significant interest in various health monitoring applications. Consequently,
several studies have proposed self-diagnostic facial image-based BMI prediction
methods for healthy weight monitoring. These methods have mostly used
convolutional neural network (CNN) based regression baselines, such as VGG19,
ResNet50, and Efficient-NetB0, for BMI prediction from facial images. However,
the high computational requirement of these heavy-weight CNN models limits
their deployment to resource-constrained mobile devices, thus deterring weight
monitoring using smartphones. This paper aims to develop a lightweight facial
patch-based ensemble (PatchBMI-Net) for BMI prediction to facilitate the
deployment and weight monitoring using smartphones. Extensive experiments on
BMI-annotated facial image datasets suggest that our proposed PatchBMI-Net
model can obtain Mean Absolute Error (MAE) in the range [3.58, 6.51] with a
size of about 3.3 million parameters. On cross-comparison with heavyweight
models, such as ResNet-50 and Xception, trained for BMI prediction from facial
images, our proposed PatchBMI-Net obtains equivalent MAE along with the model
size reduction of about 5.4x and the average inference time reduction of about
3x when deployed on Apple-14 smartphone. Thus, demonstrating performance
efficiency as well as low latency for on-device deployment and weight
monitoring using smartphone applications.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18107" title="Abstract">arXiv:2311.18107</a> [<a href="/pdf/2311.18107" title="Download PDF">pdf</a>, <a href="/format/2311.18107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic-Geometrical Framework for Object Pose Estimation based on  Mixture Models Avoiding the Correspondence Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoegele%2C+W">Wolfgang Hoegele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Background: Pose estimation of rigid objects is a practical challenge in
optical metrology and computer vision. In this paper a novel
stochastic-geometrical modeling framework for object pose estimation is
presented based on observing multiple feature points. Methods: This
stochastic-geometrical framework utilizes mixture models for the feature point
densities in object space as well as for interpreting real measurements. Direct
advantages of this approach are the avoidance to resolve individual feature
correspondences and to incorporate correct stochastic dependencies in
multi-view applications. First, the general modeling framework is presented,
second, a general algorithm for pose estimation is derived, and third, two
example models for a camera setup as well as a lateration setup are presented.
Results: The numerical experiments show the effectiveness of this modeling and
general algorithm by investigating four simulation scenarios for three
different observation systems, including the dependence on measurement
resolution, object deformations as well as strong measurement noise. It can be
concluded that the probabilistic modeling of pose estimation based on mixture
models can lead to accurate and robust pose estimations.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18110" title="Abstract">arXiv:2311.18110</a> [<a href="/pdf/2311.18110" title="Download PDF">pdf</a>, <a href="/format/2311.18110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing the shape and material parameters of dissipative  obstacles using an impedance model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Askham%2C+T">Travis Askham</a>, 
<a href="/search/math?searchtype=author&query=Borges%2C+C">Carlos Borges</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In inverse scattering problems, a model that allows for the simultaneous
recovery of both the domain shape and an impedance boundary condition covers a
wide range of problems with impenetrable domains, including recovering the
shape of sound-hard and sound-soft obstacles and obstacles with thin coatings.
This work develops an optimization framework for recovering the shape and
material parameters of a penetrable, dissipative obstacle in the multifrequency
setting, using a constrained class of curvature-dependent impedance function
models proposed by Antoine, Barucq, and Vernhet. We find that this constrained
model improves the robustness of the recovery problem, compared to more general
models, and provides meaningfully better obstacle recovery than simpler models.
We explore the effectiveness of the model for varying levels of dissipation,
for noise-corrupted data, and for limited aperture data in the numerical
examples.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18113" title="Abstract">arXiv:2311.18113</a> [<a href="/pdf/2311.18113" title="Download PDF">pdf</a>, <a href="/format/2311.18113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+T">Thomas Wimmer</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>, 
<a href="/search/cs?searchtype=author&query=Ovsjanikov%2C+M">Maks Ovsjanikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://wimmerth.github.io/back-to-3d.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">With the immense growth of dataset sizes and computing resources in recent
years, so-called foundation models have become popular in NLP and vision tasks.
In this work, we propose to explore foundation models for the task of keypoint
detection on 3D shapes. A unique characteristic of keypoint detection is that
it requires semantic and geometric awareness while demanding high localization
accuracy. To address this problem, we propose, first, to back-project features
from large pre-trained 2D vision models onto 3D shapes and employ them for this
task. We show that we obtain robust 3D features that contain rich semantic
information and analyze multiple candidate features stemming from different 2D
foundation models. Second, we employ a keypoint candidate optimization module
which aims to match the average observed distribution of keypoints on the shape
and is guided by the back-projected features. The resulting approach achieves a
new state of the art for few-shot keypoint detection on the KeyPointNet
dataset, almost doubling the performance of the previous best methods.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18114" title="Abstract">arXiv:2311.18114</a> [<a href="/pdf/2311.18114" title="Download PDF">pdf</a>, <a href="/format/2311.18114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composition of Nondeterministic and Stochastic Services for LTLf Task  Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Giacomo%2C+G">Giuseppe De Giacomo</a>, 
<a href="/search/cs?searchtype=author&query=Favorito%2C+M">Marco Favorito</a>, 
<a href="/search/cs?searchtype=author&query=Silo%2C+L">Luciana Silo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we study the composition of services so as to obtain runs
satisfying a task specification in Linear Temporal Logic on finite traces
(LTLf). We study the problem in the case services are nondeterministic and the
LTLf specification can be exactly met, and in the case services are stochastic,
where we are interested in maximizing the probability of satisfaction of the
LTLf specification and, simultaneously, minimizing the utilization cost of the
services. To do so, we combine techniques from LTLf synthesis, service
composition \`a la Roman Model, reactive synthesis, and bi-objective
lexicographic optimization on MDPs. This framework has several interesting
applications, including Smart Manufacturing and Digital Twins.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18115" title="Abstract">arXiv:2311.18115</a> [<a href="/pdf/2311.18115" title="Download PDF">pdf</a>, <a href="/format/2311.18115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Effects of Using Parsons Problems to Scaffold Code  Writing for Students with Varying CS Self-Efficacy Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinying Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+B+J">Barbara J. Ericson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-Reviewed, Accepted for publication in the proceedings of the 2023 ACM Koli Calling International Conference on Computing Education Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Introductory programming courses aim to teach students to write code
independently. However, transitioning from studying worked examples to
generating their own code is often difficult and frustrating for students,
especially those with lower CS self-efficacy in general. Therefore, we
investigated the impact of using Parsons problems as a code-writing scaffold
for students with varying levels of CS self-efficacy. Parsons problems are
programming tasks where students arrange mixed-up code blocks in the correct
order. We conducted a between-subjects study with undergraduate students (N=89)
on a topic where students have limited code-writing expertise. Students were
randomly assigned to one of two conditions. Students in one condition practiced
writing code without any scaffolding, while students in the other condition
were provided with scaffolding in the form of an equivalent Parsons problem. We
found that, for students with low CS self-efficacy levels, those who received
scaffolding achieved significantly higher practice performance and in-practice
problem-solving efficiency compared to those without any scaffolding.
Furthermore, when given Parsons problems as scaffolding during practice,
students with lower CS self-efficacy were more likely to solve them. In
addition, students with higher pre-practice knowledge on the topic were more
likely to effectively use the Parsons scaffolding. This study provides evidence
for the benefits of using Parsons problems to scaffold students' write-code
activities. It also has implications for optimizing the Parsons scaffolding
experience for students, including providing personalized and adaptive Parsons
problems based on the student's current problem-solving status.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18116" title="Abstract">arXiv:2311.18116</a> [<a href="/pdf/2311.18116" title="Download PDF">pdf</a>, <a href="/ps/2311.18116" title="Download PostScript">ps</a>, <a href="/format/2311.18116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-round Dynamic Group Decision Making Method On 2-Dimension  Uncertain Linguistic Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yukun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The language evaluation information of the interactive group decision method
at present is based on the one-dimension language variable. At the same time,
multi-attribute group decision making method based on two-dimension linguistic
information only use single-stage and static evaluation method. In this paper,
we propose a dynamic group decision making method based on two-dimension
linguistic information, combining dynamic interactive group decision making
methods with two-dimensional language evaluation information The method first
use Two-Dimensional Uncertain Linguistic Generalized Weighted Aggregation
(DULGWA) Operators to aggregate the preference information of each decision
maker, then adopting dynamic information entropy method to obtain weights of
attributes at each stage. Finally we propose the group consistency index to
quantify the termination conditions of group interaction. One example is given
to verify the developed approach and to demonstrate its effectiveness.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18118" title="Abstract">arXiv:2311.18118</a> [<a href="/pdf/2311.18118" title="Download PDF">pdf</a>, <a href="/format/2311.18118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnonPSI: An Anonymity Assessment Framework for PSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jian Du</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiang Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Private Set Intersection (PSI) is a widely used protocol that enables two
parties to securely compute a function over the intersected part of their
shared datasets and has been a significant research focus over the years.
However, recent studies have highlighted its vulnerability to Set Membership
Inference Attacks (SMIA), where an adversary might deduce an individual's
membership by invoking multiple PSI protocols. This presents a considerable
risk, even in the most stringent versions of PSI, which only return the
cardinality of the intersection. This paper explores the evaluation of
anonymity within the PSI context. Initially, we highlight the reasons why
existing works fall short in measuring privacy leakage, and subsequently
propose two attack strategies that address these deficiencies. Furthermore, we
provide theoretical guarantees on the performance of our proposed methods. In
addition to these, we illustrate how the integration of auxiliary information,
such as the sum of payloads associated with members of the intersection
(PSI-SUM), can enhance attack efficiency. We conducted a comprehensive
performance evaluation of various attack strategies proposed utilizing two real
datasets. Our findings indicate that the methods we propose markedly enhance
attack efficiency when contrasted with previous research endeavors. {The
effective attacking implies that depending solely on existing PSI protocols may
not provide an adequate level of privacy assurance. It is recommended to
combine privacy-enhancing technologies synergistically to enhance privacy
protection even further.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18126" title="Abstract">arXiv:2311.18126</a> [<a href="/pdf/2311.18126" title="Download PDF">pdf</a>, <a href="/format/2311.18126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DisMech: A Discrete Differential Geometry-based Physical Simulator for  Soft Robots and Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+A">Andrew Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+R">Ran Jing</a>, 
<a href="/search/cs?searchtype=author&query=Sabelhaus%2C+A">Andrew Sabelhaus</a>, 
<a href="/search/cs?searchtype=author&query=Jawed%2C+M+K">Mohammad Khalid Jawed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Fast, accurate, and generalizable simulations are a key enabler of modern
advances in robot design and control. However, existing simulation frameworks
in robotics either model rigid environments and mechanisms only, or if they
include flexible or soft structures, suffer significantly in one or more of
these performance areas. To close this "sim2real" gap, we introduce DisMech, a
simulation environment that models highly dynamic motions of rod-like soft
continuum robots and structures, quickly and accurately, with arbitrary
connections between them. Our methodology combines a fully implicit discrete
differential geometry-based physics solver with fast and accurate contact
handling, all in an intuitive software interface. Crucially, we propose a
gradient descent approach to easily map the motions of hardware robot
prototypes to control inputs in DisMech. We validate DisMech through several
highly-nuanced soft robot simulations while demonstrating an order of magnitude
speed increase over previous state of the art. Our real2sim validation shows
high physical accuracy versus hardware, even with complicated soft actuation
mechanisms such as shape memory alloy wires. With its low computational cost,
physical accuracy, and ease of use, DisMech can accelerate translation of
sim-based control for both soft robotics and deformable object manipulation.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18128" title="Abstract">arXiv:2311.18128</a> [<a href="/pdf/2311.18128" title="Download PDF">pdf</a>, <a href="/format/2311.18128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A  Computational Approach for High-Dimensional Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ata%2C+B">Bar&#x131;&#x15f; Ata</a>, 
<a href="/search/eess?searchtype=author&query=Ka%C5%9F%C4%B1karalar%2C+E">Ebru Ka&#x15f;&#x131;karalar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP); Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider a multi-class queueing model of a telephone call center, in which
a system manager dynamically allocates available servers to customer calls.
Calls can terminate through either service completion or customer abandonment,
and the manager strives to minimize the expected total of holding costs plus
abandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy
traffic regime, we derive an approximating diffusion control problem, and
building on earlier work by Han et al. (2018), develop a simulation-based
computational method for solution of such problems, one that relies heavily on
deep neural network technology. Using this computational method, we propose a
policy for the original (pre-limit) call center scheduling problem. Finally,
the performance of this policy is assessed using test problems based on
publicly available call center data. For the test problems considered so far,
our policy does as well as the best benchmark we could find. Moreover, our
method is computationally feasible at least up to dimension 100, that is, for
call centers with 100 or more distinct customer classes.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18129" title="Abstract">arXiv:2311.18129</a> [<a href="/pdf/2311.18129" title="Download PDF">pdf</a>, <a href="/format/2311.18129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Precision Quantization for Federated Learning on  Resource-Constrained Heterogeneous Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huancheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vikalo%2C+H">Haris Vikalo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">While federated learning (FL) systems often utilize quantization to battle
communication and computational bottlenecks, they have heretofore been limited
to deploying fixed-precision quantization schemes. Meanwhile, the concept of
mixed-precision quantization (MPQ), where different layers of a deep learning
model are assigned varying bit-width, remains unexplored in the FL settings. We
present a novel FL algorithm, FedMPQ, which introduces mixed-precision
quantization to resource-heterogeneous FL systems. Specifically, local models,
quantized so as to satisfy bit-width constraint, are trained by optimizing an
objective function that includes a regularization term which promotes reduction
of precision in some of the layers without significant performance degradation.
The server collects local model updates, de-quantizes them into full-precision
models, and then aggregates them into a global model. To initialize the next
round of local training, the server relies on the information learned in the
previous training round to customize bit-width assignments of the models
delivered to different clients. In extensive benchmarking experiments on
several model architectures and different datasets in both iid and non-iid
settings, FedMPQ outperformed the baseline FL schemes that utilize
fixed-precision quantization while incurring only a minor computational
overhead on the participating devices.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18130" title="Abstract">arXiv:2311.18130</a> [<a href="/pdf/2311.18130" title="Download PDF">pdf</a>, <a href="/format/2311.18130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Trifecta: Three simple techniques for training deeper  Forward-Forward networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dooms%2C+T">Thomas Dooms</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+J">Ing Jyh Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Oramas%2C+J">Jose Oramas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Modern machine learning models are able to outperform humans on a variety of
non-trivial tasks. However, as the complexity of the models increases, they
consume significant amounts of power and still struggle to generalize
effectively to unseen data. Local learning, which focuses on updating subsets
of a model's parameters at a time, has emerged as a promising technique to
address these issues. Recently, a novel local learning algorithm, called
Forward-Forward, has received widespread attention due to its innovative
approach to learning. Unfortunately, its application has been limited to
smaller datasets due to scalability issues. To this end, we propose The
Trifecta, a collection of three simple techniques that synergize exceptionally
well and drastically improve the Forward-Forward algorithm on deeper networks.
Our experiments demonstrate that our models are on par with similarly
structured, backpropagation-based models in both training speed and test
accuracy on simple datasets. This is achieved by the ability to learn
representations that are informative locally, on a layer-by-layer basis, and
retain their informativeness when propagated to deeper layers in the
architecture. This leads to around 84\% accuracy on CIFAR-10, a notable
improvement (25\%) over the original FF algorithm. These results highlight the
potential of Forward-Forward as a genuine competitor to backpropagation and as
a promising research avenue.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18138" title="Abstract">arXiv:2311.18138</a> [<a href="/pdf/2311.18138" title="Download PDF">pdf</a>, <a href="/format/2311.18138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Persuasion Through Simulation: Information Design in the Age  of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harris%2C+K">Keegan Harris</a>, 
<a href="/search/cs?searchtype=author&query=Immorlica%2C+N">Nicole Immorlica</a>, 
<a href="/search/cs?searchtype=author&query=Lucier%2C+B">Brendan Lucier</a>, 
<a href="/search/cs?searchtype=author&query=Slivkins%2C+A">Aleksandrs Slivkins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">How can an informed sender persuade a receiver, having only limited
information about the receiver's beliefs? Motivated by research showing
generative AI can simulate economic agents, we initiate the study of
information design with an oracle. We assume the sender can learn more about
the receiver by querying this oracle, e.g., by simulating the receiver's
behavior. Aside from AI motivations such as general-purpose Large Language
Models (LLMs) and problem-specific machine learning models, alternate
motivations include customer surveys and querying a small pool of live users.
<br />Specifically, we study Bayesian Persuasion where the sender has a
second-order prior over the receiver's beliefs. After a fixed number of queries
to an oracle to refine this prior, the sender commits to an information
structure. Upon receiving the message, the receiver takes a payoff-relevant
action maximizing her expected utility given her posterior beliefs. We design
polynomial-time querying algorithms that optimize the sender's expected utility
in this Bayesian Persuasion game. As a technical contribution, we show that
queries form partitions of the space of receiver beliefs that can be used to
quantify the sender's knowledge.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18140" title="Abstract">arXiv:2311.18140</a> [<a href="/pdf/2311.18140" title="Download PDF">pdf</a>, <a href="/format/2311.18140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROBBIE: Robust Bias Evaluation of Large Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esiobu%2C+D">David Esiobu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiaoqing Tan</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+S">Saghar Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Ung%2C+M">Megan Ung</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+J">Jude Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi-Yu%2C+J">Jane Dwivedi-Yu</a>, 
<a href="/search/cs?searchtype=author&query=Presani%2C+E">Eleonora Presani</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+E+M">Eric Michael Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As generative large language models (LLMs) grow more performant and
prevalent, we must develop comprehensive enough tools to measure and improve
their fairness. Different prompt-based datasets can be used to measure social
bias across multiple text domains and demographic axes, meaning that testing
LLMs on more datasets can potentially help us characterize their biases more
fully, and better ensure equal and equitable treatment of marginalized
demographic groups. In this work, our focus is two-fold:
<br />(1) Benchmarking: a comparison of 6 different prompt-based bias and toxicity
metrics across 12 demographic axes and 5 families of generative LLMs. Out of
those 6 metrics, AdvPromptSet and HolisticBiasR are novel datasets proposed in
the paper. The comparison of those benchmarks gives us insights about the bias
and toxicity of the compared models. Therefore, we explore the frequency of
demographic terms in common LLM pre-training corpora and how this may relate to
model biases.
<br />(2) Mitigation: we conduct a comprehensive study of how well 3 bias/toxicity
mitigation techniques perform across our suite of measurements. ROBBIE aims to
provide insights for practitioners while deploying a model, emphasizing the
need to not only measure potential harms, but also understand how they arise by
characterizing the data, mitigate harms once found, and balance any trade-offs.
We open-source our analysis code in hopes of encouraging broader measurements
of bias in future LLMs.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18141" title="Abstract">arXiv:2311.18141</a> [<a href="/pdf/2311.18141" title="Download PDF">pdf</a>, <a href="/format/2311.18141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDMA-Based Algorithms for Sparse Matrix Multiplication on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brock%2C+B">Benjamin Brock</a>, 
<a href="/search/cs?searchtype=author&query=Bulu%C3%A7%2C+A">Ayd&#x131;n Bulu&#xe7;</a>, 
<a href="/search/cs?searchtype=author&query=Yelick%2C+K">Katherine Yelick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Sparse matrix multiplication is an important kernel for large-scale graph
processing and other data-intensive applications. In this paper, we implement
various asynchronous, RDMA-based sparse times dense (SpMM) and sparse times
sparse (SpGEMM) algorithms, evaluating their performance running in a
distributed memory setting on GPUs. Our RDMA-based implementations use the
NVSHMEM communication library for direct, asynchronous one-sided communication
between GPUs. We compare our asynchronous implementations to state-of-the-art
bulk synchronous GPU libraries as well as a CUDA-aware MPI implementation of
the SUMMA algorithm. We find that asynchronous RDMA-based implementations are
able to offer favorable performance compared to bulk synchronous
implementations, while also allowing for the straightforward implementation of
novel work stealing algorithms.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18145" title="Abstract">arXiv:2311.18145</a> [<a href="/pdf/2311.18145" title="Download PDF">pdf</a>, <a href="/ps/2311.18145" title="Download PostScript">ps</a>, <a href="/format/2311.18145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsifying generalized linear models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jambulapati%2C+A">Arun Jambulapati</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+R">James R. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">We consider the sparsification of sums $F : \mathbb{R}^n \to \mathbb{R}$
where $F(x) = f_1(\langle a_1,x\rangle) + \cdots + f_m(\langle a_m,x\rangle)$
for vectors $a_1,\ldots,a_m \in \mathbb{R}^n$ and functions $f_1,\ldots,f_m :
\mathbb{R} \to \mathbb{R}_+$. We show that $(1+\varepsilon)$-approximate
sparsifiers of $F$ with support size $\frac{n}{\varepsilon^2} (\log
\frac{n}{\varepsilon})^{O(1)}$ exist whenever the functions $f_1,\ldots,f_m$
are symmetric, monotone, and satisfy natural growth bounds. Additionally, we
give efficient algorithms to compute such a sparsifier assuming each $f_i$ can
be evaluated efficiently.
<br />Our results generalize the classic case of $\ell_p$ sparsification, where
$f_i(z) = |z|^p$, for $p \in (0, 2]$, and give the first near-linear size
sparsifiers in the well-studied setting of the Huber loss function and its
generalizations, e.g., $f_i(z) = \min\{|z|^p, |z|^2\}$ for $0 &lt; p \leq 2$. Our
sparsification algorithm can be applied to give near-optimal reductions for
optimizing a variety of generalized linear models including $\ell_p$ regression
for $p \in (1, 2]$ to high accuracy, via solving $(\log n)^{O(1)}$ sparse
regression instances with $m \le n(\log n)^{O(1)}$, plus runtime proportional
to the number of nonzero entries in the vectors $a_1, \dots, a_m$.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18147" title="Abstract">arXiv:2311.18147</a> [<a href="/pdf/2311.18147" title="Download PDF">pdf</a>, <a href="/format/2311.18147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DisCGen: A Framework for Discourse-Informed Counterspeech Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+S">Sabit Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Alikhani%2C+M">Malihe Alikhani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCNLP-AACL, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Counterspeech can be an effective method for battling hateful content on
social media. Automated counterspeech generation can aid in this process.
Generated counterspeech, however, can be viable only when grounded in the
context of topic, audience and sensitivity as these factors influence both the
efficacy and appropriateness. In this work, we propose a novel framework based
on theories of discourse to study the inferential links that connect counter
speeches to the hateful comment. Within this framework, we propose: i) a
taxonomy of counterspeech derived from discourse frameworks, and ii)
discourse-informed prompting strategies for generating contextually-grounded
counterspeech. To construct and validate this framework, we present a process
for collecting an in-the-wild dataset of counterspeech from Reddit. Using this
process, we manually annotate a dataset of 3.9k Reddit comment pairs for the
presence of hatespeech and counterspeech. The positive pairs are annotated for
10 classes in our proposed taxonomy. We annotate these pairs with paraphrased
counterparts to remove offensiveness and first-person references. We show that
by using our dataset and framework, large language models can generate
contextually-grounded counterspeech informed by theories of discourse.
According to our human evaluation, our approaches can act as a safeguard
against critical failures of discourse-agnostic models.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18149" title="Abstract">arXiv:2311.18149</a> [<a href="/pdf/2311.18149" title="Download PDF">pdf</a>, <a href="/format/2311.18149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STF: Spatial Temporal Fusion for Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengqian Han</a>, 
<a href="/search/cs?searchtype=author&query=Roop%2C+P">Partha Roop</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+T">Tianzhe Bao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Trajectory prediction is a challenging task that aims to predict the future
trajectory of vehicles or pedestrians over a short time horizon based on their
historical positions. The main reason is that the trajectory is a kind of
complex data, including spatial and temporal information, which is crucial for
accurate prediction. Intuitively, the more information the model can capture,
the more precise the future trajectory can be predicted. However, previous
works based on deep learning methods processed spatial and temporal information
separately, leading to inadequate spatial information capture, which means they
failed to capture the complete spatial information. Therefore, it is of
significance to capture information more fully and effectively on vehicle
interactions. In this study, we introduced an integrated 3D graph that
incorporates both spatial and temporal edges. Based on this, we proposed the
integrated 3D graph, which considers the cross-time interaction information. In
specific, we design a Spatial-Temporal Fusion (STF) model including Multi-layer
perceptions (MLP) and Graph Attention (GAT) to capture the spatial and temporal
information historical trajectories simultaneously on the 3D graph. Our
experiment on the ApolloScape Trajectory Datasets shows that the proposed STF
outperforms several baseline methods, especially on the long-time-horizon
trajectory prediction.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18151" title="Abstract">arXiv:2311.18151</a> [<a href="/pdf/2311.18151" title="Download PDF">pdf</a>, <a href="/format/2311.18151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Guided Global Memory Improves Multi-Hop Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagirova%2C+A">Alsu Sagirova</a>, 
<a href="/search/cs?searchtype=author&query=Burtsev%2C+M">Mikhail Burtsev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures. EMNLP 2023. Our code is available at <a href="https://github.com/Aloriosa/GEMFormer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Transformers have become the gold standard for many natural language
processing tasks and, in particular, for multi-hop question answering (MHQA).
This task includes processing a long document and reasoning over the multiple
parts of it. The landscape of MHQA approaches can be classified into two
primary categories. The first group focuses on extracting supporting evidence,
thereby constraining the QA model's context to predicted facts. Conversely, the
second group relies on the attention mechanism of the long input encoding model
to facilitate multi-hop reasoning. However, attention-based token
representations lack explicit global contextual information to connect
reasoning steps. To address these issues, we propose GEMFormer, a two-stage
method that first collects relevant information over the entire document to the
memory and then combines it with local context to solve the task. Our
experimental results show that fine-tuning a pre-trained model with
memory-augmented input, including the most certain global elements, improves
the model's performance on three MHQA datasets compared to the baseline. We
also found that the global explicit memory contains information from supporting
facts required for the correct answer.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18154" title="Abstract">arXiv:2311.18154</a> [<a href="/pdf/2311.18154" title="Download PDF">pdf</a>, <a href="/ps/2311.18154" title="Download PostScript">ps</a>, <a href="/format/2311.18154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Shape Sensing in Continuum Manipulators via Sliding  Resistive Flex Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shaopeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Joshua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Amit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Armand%2C+M">Mehran Armand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We introduce a novel shape-sensing method using Resistive Flex Sensors (RFS)
embedded in cable-driven Continuum Dexterous Manipulators (CDMs). The RFS is
predominantly sensitive to deformation rather than direct forces, making it a
distinctive tool for shape sensing. The RFS unit we designed is a considerably
less expensive and robust alternative, offering comparable accuracy and
real-time performance to existing shape sensing methods used for the CDMs
proposed for minimally-invasive surgery. Our design allows the RFS to move
along and inside the CDM conforming to its curvature, offering the ability to
capture resistance metrics from various bending positions without the need for
elaborate sensor setups. The RFS unit is calibrated using an overhead camera
and a ResNet machine learning framework. Experiments using a 3D printed
prototype of the CDM achieved an average shape estimation error of 0.968 mm
with a standard error of 0.275 mm. The response time of the model was
approximately 1.16 ms, making real-time shape sensing feasible. While this
preliminary study successfully showed the feasibility of our approach for
C-shape CDM deformations with non-constant curvatures, we are currently
extending the results to show the feasibility for adapting to more complex CDM
configurations such as S-shape created in obstructed environments or in
presence of the external forces.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18157" title="Abstract">arXiv:2311.18157</a> [<a href="/pdf/2311.18157" title="Download PDF">pdf</a>, <a href="/format/2311.18157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Smallest Witnesses for Conjunctive Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sintos%2C+S">Stavros Sintos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">A witness is a sub-database that preserves the query results of the original
database but of much smaller size. It has wide applications in query rewriting
and debugging, query explanation, IoT analytics, multi-layer network routing,
etc. In this paper, we study the smallest witness problem (SWP) for the class
of conjunctive queries (CQs) without self-joins.
<br />We first establish the dichotomy that SWP for a CQ can be computed in
polynomial time if and only if it has {\em head-cluster property}, unless
$\texttt{P} = \texttt{NP}$. We next turn to the approximated version by
relaxing the size of a witness from being minimum. We surprisingly find that
the {\em head-domination} property - that has been identified for the deletion
propagation problem \cite{kimelfeld2012maximizing} - can also precisely capture
the hardness of the approximated smallest witness problem. In polynomial time,
SWP for any CQ with head-domination property can be approximated within a
constant factor, while SWP for any CQ without such a property cannot be
approximated within a logarithmic factor, unless $\texttt{P} = \texttt{NP}$.
<br />We further explore efficient approximation algorithms for CQs without
head-domination property: (1) we show a trivial algorithm which achieves a
polynomially large approximation ratio for general CQs; (2) for any CQ with
only one non-output attribute, such as star CQs, we show a greedy algorithm
with a logarithmic approximation ratio; (3) for line CQs, which contain at
least two non-output attributes, we relate SWP problem to the directed steiner
forest problem, whose algorithms can be applied to line CQs directly.
Meanwhile, we establish a much higher lower bound, exponentially larger than
the logarithmic lower bound obtained above. It remains open to close the gap
between the lower and upper bound of the approximated SWP for CQs without
head-domination property.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18158" title="Abstract">arXiv:2311.18158</a> [<a href="/pdf/2311.18158" title="Download PDF">pdf</a>, <a href="/format/2311.18158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiPA: Enabling One-Step Text-to-Image Diffusion Models via  High-Frequency-Promoting Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have revolutionized text-to-image generation, but their
real-world applications are hampered by the extensive time needed for hundreds
of diffusion steps. Although progressive distillation has been proposed to
speed up diffusion sampling to 2-8 steps, it still falls short in one-step
generation, and necessitates training multiple student models, which is highly
parameter-extensive and time-consuming. To overcome these limitations, we
introduce High-frequency-Promoting Adaptation (HiPA), a parameter-efficient
approach to enable one-step text-to-image diffusion. Grounded in the insight
that high-frequency information is essential but highly lacking in one-step
diffusion, HiPA focuses on training one-step, low-rank adaptors to specifically
enhance the under-represented high-frequency abilities of advanced diffusion
models. The learned adaptors empower these diffusion models to generate
high-quality images in just a single step. Compared with progressive
distillation, HiPA achieves much better performance in one-step text-to-image
generation (37.3 $\rightarrow$ 23.8 in FID-5k on MS-COCO 2017) and 28.6x
training speed-up (108.8 $\rightarrow$ 3.8 A100 GPU days), requiring only 0.04%
training parameters (7,740 million $\rightarrow$ 3.3 million). We also
demonstrate HiPA's effectiveness in text-guided image editing, inpainting and
super-resolution tasks, where our adapted models consistently deliver
high-quality outputs in just one diffusion step. The source code will be
released.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18159" title="Abstract">arXiv:2311.18159</a> [<a href="/pdf/2311.18159" title="Download PDF">pdf</a>, <a href="/format/2311.18159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact3D: Compressing Gaussian Splat Radiance Field Models with Vector  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navaneet%2C+K">KL Navaneet</a>, 
<a href="/search/cs?searchtype=author&query=Meibodi%2C+K+P">Kossar Pourahmadi Meibodi</a>, 
<a href="/search/cs?searchtype=author&query=Koohpayegani%2C+S+A">Soroush Abbasi Koohpayegani</a>, 
<a href="/search/cs?searchtype=author&query=Pirsiavash%2C+H">Hamed Pirsiavash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/UCDvision/compact3d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D Gaussian Splatting is a new method for modeling and rendering 3D radiance
fields that achieves much faster learning and rendering time compared to SOTA
NeRF methods. However, it comes with a drawback in the much larger storage
demand compared to NeRF methods since it needs to store the parameters for
several 3D Gaussians. We notice that many Gaussians may share similar
parameters, so we introduce a simple vector quantization method based on
\kmeans algorithm to quantize the Gaussian parameters. Then, we store the small
codebook along with the index of the code for each Gaussian. Moreover, we
compress the indices further by sorting them and using a method similar to
run-length encoding. We do extensive experiments on standard benchmarks as well
as a new benchmark which is an order of magnitude larger than the standard
benchmarks. We show that our simple yet effective method can reduce the storage
cost for the original 3D Gaussian Splatting method by a factor of almost
$20\times$ with a very small drop in the quality of rendered images.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18165" title="Abstract">arXiv:2311.18165</a> [<a href="/pdf/2311.18165" title="Download PDF">pdf</a>, <a href="/ps/2311.18165" title="Download PostScript">ps</a>, <a href="/format/2311.18165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variations in Web of Science and Scopus Journal Coverage, Visibility and  Prestige between 2001 and 2020
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asubiaro%2C+T+V">Toluwase Victor Asubiaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Purpose: This study focuses on the changes in differences in the journal
coverage, visibility and prestige of journals from top twenty countries in Web
of Science and Scopus in the twenty-year timeframe-2001-2020. Methodology:
Using Web of Science and Scopus journal data from Journal Citation Reports and
Scimago Journal Rank, respectively, top twenty countries by number of journals
indexed in the two databases were identified. Analysis of the changes that
occurred in the number of journals from the top twenty countries, the citations
they received and their prestige were analyzed. Findings: USA and UK continued
their dominance of the journals indexed in Web of Science and Scopus, but their
dominance waned gradually in the course of the twenty-year period. The rate of
growth of journals indexed by the databases is steeper among the countries
outside the top. In Web of Science, journals from the UK were the most
prestigious until 2010 when China emerged as the most prestigious journals. USA
continues to take the leading spot in terms of most prestigious journals in
Scopus, followed by UK. Research Limitations: This investigation relied on
third-party datasets sourced from the Scimago Journal Rank repository for the
compilation of the Scopus journal list. Practical implications: This study
suggests an inclination towards diversity by Web of Science and Scopus, though
North America and Europe continue to dominate journal coverage. However, the
gulf in the prestige and visibility of journals from North America, Europe and
other parts of the world remains, suggesting the researchers from the
peripheral may continue to gravitate towards the core. Originality/Value: While
studies have provided singular-year analyses of journal coverages of Web of
Science and Scopus, this study provides an analysis of 20 years.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18166" title="Abstract">arXiv:2311.18166</a> [<a href="/pdf/2311.18166" title="Download PDF">pdf</a>, <a href="/format/2311.18166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-Scan2BIM: Assistive Scan to Building Information Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Weilian Song</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jieliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dale Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chin-Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Furukawa%2C+Y">Yasutaka Furukawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023, order evaluation updated after fixing evaluation bug
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes an assistive system for architects that converts a
large-scale point cloud into a standardized digital representation of a
building for Building Information Modeling (BIM) applications. The process is
known as Scan-to-BIM, which requires many hours of manual work even for a
single building floor by a professional architect. Given its challenging
nature, the paper focuses on helping architects on the Scan-to-BIM process,
instead of replacing them. Concretely, we propose an assistive Scan-to-BIM
system that takes the raw sensor data and edit history (including the current
BIM model), then auto-regressively predicts a sequence of model editing
operations as APIs of a professional BIM software (i.e., Autodesk Revit). The
paper also presents the first building-scale Scan2BIM dataset that contains a
sequence of model editing operations as the APIs of Autodesk Revit. The dataset
contains 89 hours of Scan2BIM modeling processes by professional architects
over 16 scenes, spanning over 35,000 m^2. We report our system's reconstruction
quality with standard metrics, and we introduce a novel metric that measures
how natural the order of reconstructed operations is. A simple modification to
the reconstruction module helps improve performance, and our method is far
superior to two other baselines in the order metric. We will release data,
code, and models at a-scan2bim.github.io.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18167" title="Abstract">arXiv:2311.18167</a> [<a href="/pdf/2311.18167" title="Download PDF">pdf</a>, <a href="/format/2311.18167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Throughput Maximization for Intelligent Refracting Surface Assisted  mmWave High-Speed Train Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruisi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sheng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With the increasing demands from passengers for data-intensive services,
millimeter-wave (mmWave) communication is considered as an effective technique
to release the transmission pressure on high speed train (HST) networks.
However, mmWave signals ncounter severe losses when passing through the
carriage, which decreases the quality of services on board. In this paper, we
investigate an intelligent refracting surface (IRS)-assisted HST communication
system. Herein, an IRS is deployed on the train window to dynamically
reconfigure the propagation environment, and a hybrid time division multiple
access-nonorthogonal multiple access scheme is leveraged for interference
mitigation. We aim to maximize the overall throughput while taking into account
the constraints imposed by base station beamforming, IRS discrete phase shifts
and transmit power. To obtain a practical solution, we employ an alternating
optimization method and propose a two-stage algorithm. In the first stage, the
successive convex approximation method and branch and bound algorithm are
leveraged for IRS phase shift design. In the second stage, the Lagrangian
multiplier method is utilized for power allocation. Simulation results
demonstrate the benefits of IRS adoption and power allocation for throughput
improvement in mmWave HST networks.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18168" title="Abstract">arXiv:2311.18168</a> [<a href="/pdf/2311.18168" title="Download PDF">pdf</a>, <a href="/format/2311.18168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks,  Methods, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K+D">Karren D. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+A">Anurag Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+R">Jen-Hao Rick Chang</a>, 
<a href="/search/cs?searchtype=author&query=Vemulapalli%2C+R">Raviteja Vemulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Tuzel%2C+O">Oncel Tuzel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We consider the task of animating 3D facial geometry from speech signal.
Existing works are primarily deterministic, focusing on learning a one-to-one
mapping from speech signal to 3D face meshes on small datasets with limited
speakers. While these models can achieve high-quality lip articulation for
speakers in the training set, they are unable to capture the full and diverse
distribution of 3D facial motions that accompany speech in the real world.
Importantly, the relationship between speech and facial motion is one-to-many,
containing both inter-speaker and intra-speaker variations and necessitating a
probabilistic approach. In this paper, we identify and address key challenges
that have so far limited the development of probabilistic models: lack of
datasets and metrics that are suitable for training and evaluating them, as
well as the difficulty of designing a model that generates diverse results
while remaining faithful to a strong conditioning signal as speech. We first
propose large-scale benchmark datasets and metrics suitable for probabilistic
modeling. Then, we demonstrate a probabilistic model that achieves both
diversity and fidelity to speech, outperforming other methods across the
proposed benchmarks. Finally, we showcase useful applications of probabilistic
models trained on these large-scale datasets: we can generate diverse
speech-driven 3D facial motion that matches unseen speaker styles extracted
from reference clips; and our synthetic meshes can be used to improve the
performance of downstream audio-visual models.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18169" title="Abstract">arXiv:2311.18169</a> [<a href="/pdf/2311.18169" title="Download PDF">pdf</a>, <a href="/format/2311.18169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Image Generation via Style Adaptation and Content Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaosheng He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training a generative model with limited data (e.g., 10) is a very
challenging task. Many works propose to fine-tune a pre-trained GAN model.
However, this can easily result in overfitting. In other words, they manage to
adapt the style but fail to preserve the content, where \textit{style} denotes
the specific properties that defines a domain while \textit{content} denotes
the domain-irrelevant information that represents diversity. Recent works try
to maintain a pre-defined correspondence to preserve the content, however, the
diversity is still not enough and it may affect style adaptation. In this work,
we propose a paired image reconstruction approach for content preservation. We
propose to introduce an image translation module to GAN transferring, where the
module teaches the generator to separate style and content, and the generator
provides training data to the translation module in return. Qualitative and
quantitative experiments show that our method consistently surpasses the
state-of-the-art methods in few shot setting.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18170" title="Abstract">arXiv:2311.18170</a> [<a href="/pdf/2311.18170" title="Download PDF">pdf</a>, <a href="/format/2311.18170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Odor Intensity Shift Keying (OISK) and Channel Capacity of Odor-based  Molecular Communications in Internet of Everything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Powari%2C+A">Aditya Powari</a>, 
<a href="/search/cs?searchtype=author&query=Akan%2C+O+B">Ozgur B. Akan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Molecular communication is a new, active area of research that has created a
paradigm shift in the way a communication system is perceived. An artificial
molecular communication network is created using biological molecules for
encoding, transmitting and decoding the symbols to convey information. In
addition to typical biological molecules, we are also exploring other classes
of molecules that possess unique distinctive features which can be potentially
exploited for establishing reliable communications. Odor molecules are one such
class of molecules which possess several distinctive features such as
Intensity, Headonic tone which provides a basis to convey the information in an
olfactory communication system. In our work, we investigate the ICT
(information and communication theory) perspective of the olfactory
communications by evaluating the channel capacity of an odor molecular
communication (OMC) system with the help of a novel modulation scheme viz. odor
intensity shift keying (OISK), where information is being conveyed from the
intensity level of an odor. Furthermore, we also analyse the effects of
critical parameters like temperature and noise on the achievable channel
capacity to provide an insight about the resilience of the proposed OMC system
towards any such anomaly faced by it.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18172" title="Abstract">arXiv:2311.18172</a> [<a href="/pdf/2311.18172" title="Download PDF">pdf</a>, <a href="/format/2311.18172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Rate Variable-Length CSI Compression for FDD Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Bumsu Park</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+H">Heedong Do</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namyoon Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">For frequency-division-duplexing (FDD) systems, channel state information
(CSI) should be fed back from the user terminal to the base station. This
feedback overhead becomes problematic as the number of antennas grows. To
alleviate this issue, we propose a flexible CSI compression method using
variational autoencoder (VAE) with an entropy bottleneck structure, which can
support multi-rate and variable-length operation. Numerical study confirms that
the proposed method outperforms the existing CSI compression techniques in
terms of normalized mean squared error.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18174" title="Abstract">arXiv:2311.18174</a> [<a href="/pdf/2311.18174" title="Download PDF">pdf</a>, <a href="/format/2311.18174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Packrat: Automatic Reconfiguration for Latency Minimization in CPU-based  DNN Serving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+A">Ankit Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Phanishayee%2C+A">Amar Phanishayee</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+D">Deepak Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Tarta%2C+M">Mihail Tarta</a>, 
<a href="/search/cs?searchtype=author&query=Stutsman%2C+R">Ryan Stutsman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we investigate how to push the performance limits of serving
Deep Neural Network (DNN) models on CPU-based servers. Specifically, we observe
that while intra-operator parallelism across multiple threads is an effective
way to reduce inference latency, it provides diminishing returns. Our primary
insight is that instead of running a single instance of a model with all
available threads on a server, running multiple instances each with smaller
batch sizes and fewer threads for intra-op parallelism can provide lower
inference latency. However, the right configuration is hard to determine
manually since it is workload- (DNN model and batch size used by the serving
system) and deployment-dependent (number of CPU cores on server). We present
Packrat, a new serving system for online inference that given a model and batch
size ($B$) algorithmically picks the optimal number of instances ($i$), the
number of threads each should be allocated ($t$), and the batch sizes each
should operate on ($b$) that minimizes latency. Packrat is built as an
extension to TorchServe and supports online reconfigurations to avoid serving
downtime. Averaged across a range of batch sizes, Packrat improves inference
latency by 1.43$\times$ to 1.83$\times$ on a range of commonly used DNNs.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18175" title="Abstract">arXiv:2311.18175</a> [<a href="/pdf/2311.18175" title="Download PDF">pdf</a>, <a href="/ps/2311.18175" title="Download PostScript">ps</a>, <a href="/format/2311.18175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STL4IoT: A Statechart Template Library for IoT System Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rempillo%2C+C">Clyde Rempillo</a>, 
<a href="/search/cs?searchtype=author&query=Mustafiz%2C+S">Sadaf Mustafiz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The engineering of IoT systems brings about various challenges due to the
inherent complexities associated with such heterogeneous systems. In this
paper, we propose a library of statechart templates, STL4IoT, for designing
complex IoT systems. We have developed atomic statechart components modelling
the heterogeneous aspects of IoT systems including sensors, actuators, physical
entities, network, and controller. Base system units for smart systems have
also been designed. A component for calculating power usage is available in the
library. Additionally, a smart hub template that controls interactions among
multiple IoT systems and manages power consumption has also been proposed. The
templates aim to facilitate the modelling and simulation of IoT systems. Our
work is demonstrated with a smart home system consisting of a smart hub of
lights, a smart microwave, a smart TV, and a smart fire alarm system. We have
created a multi statechart with itemis CREATE based on the proposed templates
and components. A smart home simulator has been developed by generating
controller code from the statechart and integrating it with a user interface.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18177" title="Abstract">arXiv:2311.18177</a> [<a href="/pdf/2311.18177" title="Download PDF">pdf</a>, <a href="/format/2311.18177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Effective Universal Polynomial Basis for Spectral Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Keke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Spectral Graph Neural Networks (GNNs), also referred to as graph filters have
gained increasing prevalence for heterophily graphs. Optimal graph filters rely
on Laplacian eigendecomposition for Fourier transform. In an attempt to avert
the prohibitive computations, numerous polynomial filters by leveraging
distinct polynomials have been proposed to approximate the desired graph
filters. However, polynomials in the majority of polynomial filters are
predefined and remain fixed across all graphs, failing to accommodate the
diverse heterophily degrees across different graphs. To tackle this issue, we
first investigate the correlation between polynomial bases of desired graph
filters and the degrees of graph heterophily via a thorough theoretical
analysis. Afterward, we develop an adaptive heterophily basis by incorporating
graph heterophily degrees. Subsequently, we integrate this heterophily basis
with the homophily basis, creating a universal polynomial basis UniBasis. In
consequence, we devise a general polynomial filter UniFilter. Comprehensive
experiments on both real-world and synthetic datasets with varying heterophily
degrees significantly support the superiority of UniFilter, demonstrating the
effectiveness and generality of UniBasis, as well as its promising capability
as a new method for graph analysis.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18182" title="Abstract">arXiv:2311.18182</a> [<a href="/pdf/2311.18182" title="Download PDF">pdf</a>, <a href="/format/2311.18182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEOPLEx: PEdestrian Opportunistic Positioning LEveraging IMU, UWB, BLE  and WiFi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lajoie%2C+P">Pierre-Yves Lajoie</a>, 
<a href="/search/cs?searchtype=author&query=Baghi%2C+B+H">Bobak Hamed Baghi</a>, 
<a href="/search/cs?searchtype=author&query=Herath%2C+S">Sachini Herath</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper advances the field of pedestrian localization by introducing a
unifying framework for opportunistic positioning based on nonlinear factor
graph optimization. While many existing approaches assume constant availability
of one or multiple sensing signals, our methodology employs IMU-based
pedestrian inertial navigation as the backbone for sensor fusion,
opportunistically integrating Ultra-Wideband (UWB), Bluetooth Low Energy (BLE),
and WiFi signals when they are available in the environment. The proposed
PEOPLEx framework is designed to incorporate sensing data as it becomes
available, operating without any prior knowledge about the environment (e.g.
anchor locations, radio frequency maps, etc.). Our contributions are twofold:
1) we introduce an opportunistic multi-sensor and real-time pedestrian
positioning framework fusing the available sensor measurements; 2) we develop
novel factors for adaptive scaling and coarse loop closures, significantly
improving the precision of indoor positioning. Experimental validation confirms
that our approach achieves accurate localization estimates in real indoor
scenarios using commercial smartphones.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18189" title="Abstract">arXiv:2311.18189</a> [<a href="/pdf/2311.18189" title="Download PDF">pdf</a>, <a href="/format/2311.18189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-based Visual Inertial Velometer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiuyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaojie Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Neuromorphic event-based cameras are bio-inspired visual sensors with
asynchronous pixels and extremely high temporal resolution. Such favorable
properties make them an excellent choice for solving state estimation tasks
under aggressive ego motion. However, failures of camera pose tracking are
frequently witnessed in state-of-the-art event-based visual odometry systems
when the local map cannot be updated in time. One of the biggest roadblocks for
this specific field is the absence of efficient and robust methods for data
association without imposing any assumption on the environment. This problem
seems, however, unlikely to be addressed as in standard vision due to the
motion-dependent observability of event data. Therefore, we propose a
mapping-free design for event-based visual-inertial state estimation in this
paper. Instead of estimating the position of the event camera, we find that
recovering the instantaneous linear velocity is more consistent with the
differential working principle of event cameras. The proposed event-based
visual-inertial velometer leverages a continuous-time formulation that
incrementally fuses the heterogeneous measurements from a stereo event camera
and an inertial measurement unit. Experiments on the synthetic dataset
demonstrate that the proposed method can recover instantaneous linear velocity
in metric scale with low latency.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18190" title="Abstract">arXiv:2311.18190</a> [<a href="/pdf/2311.18190" title="Download PDF">pdf</a>, <a href="/format/2311.18190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward the Tradeoffs between Privacy, Fairness and Utility in Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kangkang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gaolei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianhua Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Learning (FL) is a novel privacy-protection distributed machine
learning paradigm that guarantees user privacy and prevents the risk of data
leakage due to the advantage of the client's local training. Researchers have
struggled to design fair FL systems that ensure fairness of results. However,
the interplay between fairness and privacy has been less studied. Increasing
the fairness of FL systems can have an impact on user privacy, while an
increase in user privacy can affect fairness. In this work, on the client side,
we use fairness metrics, such as Demographic Parity (DemP), Equalized Odds
(EOs), and Disparate Impact (DI), to construct the local fair model. To protect
the privacy of the client model, we propose a privacy-protection fairness FL
method. The results show that the accuracy of the fair model with privacy
increases because privacy breaks the constraints of the fairness metrics. In
our experiments, we conclude the relationship between privacy, fairness and
utility, and there is a tradeoff between these.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18193" title="Abstract">arXiv:2311.18193</a> [<a href="/pdf/2311.18193" title="Download PDF">pdf</a>, <a href="/format/2311.18193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persistent Test-time Adaptation in Episodic Testing Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Trung-Hieu Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+D+M">Duc Minh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M+N">Minh N. Do</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current test-time adaptation (TTA) approaches aim to adapt to environments
that change continuously. Yet, when the environments not only change but also
recur in a correlated manner over time, such as in the case of day-night
surveillance cameras, it is unclear whether the adaptability of these methods
is sustained after a long run. This study aims to examine the error
accumulation of TTA models when they are repeatedly exposed to previous testing
environments, proposing a novel testing setting called episodic TTA. To study
this phenomenon, we design a simulation of TTA process on a simple yet
representative $\epsilon$-perturbed Gaussian Mixture Model Classifier and
derive the theoretical findings revealing the dataset- and algorithm-dependent
factors that contribute to the gradual degeneration of TTA methods through
time. Our investigation has led us to propose a method, named persistent TTA
(PeTTA). PeTTA senses the model divergence towards a collapsing and adjusts the
adaptation strategy of TTA, striking a balance between two primary objectives:
adaptation and preventing model collapse. The stability of PeTTA in the face of
episodic TTA scenarios has been demonstrated through a set of comprehensive
experiments on various benchmarks.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18194" title="Abstract">arXiv:2311.18194</a> [<a href="/pdf/2311.18194" title="Download PDF">pdf</a>, <a href="/format/2311.18194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positional Information Matters for Invariant In-Context Learning: A Case  Study of Simple Function Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Binghui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiwen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Y">Yatao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">James Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing work; preliminary version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In-context learning (ICL) refers to the ability of a model to condition on a
few in-context demonstrations (input-output examples of the underlying task) to
generate the answer for a new query input, without updating parameters. Despite
the impressive ICL ability of LLMs, it has also been found that ICL in LLMs is
sensitive to input demonstrations and limited to short context lengths. To
understand the limitations and principles for successful ICL, we conduct an
investigation with ICL linear regression of transformers. We characterize
several Out-of-Distribution (OOD) cases for ICL inspired by realistic LLM ICL
failures and compare transformers with DeepSet, a simple yet powerful
architecture for ICL. Surprisingly, DeepSet outperforms transformers across a
variety of distribution shifts, implying that preserving permutation invariance
symmetry to input demonstrations is crucial for OOD ICL. The phenomenon
specifies a fundamental requirement by ICL, which we termed as ICL invariance.
Nevertheless, the positional encodings in LLMs will break ICL invariance. To
this end, we further evaluate transformers with identical positional encodings
and find preserving ICL invariance in transformers achieves state-of-the-art
performance across various ICL distribution shifts
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18195" title="Abstract">arXiv:2311.18195</a> [<a href="/pdf/2311.18195" title="Download PDF">pdf</a>, <a href="/format/2311.18195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 Vaccine Misinformation in Middle Income Countries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Back%2C+B+R">Byeo Rhee Back</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Aditya Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wirtz%2C+V+J">Veronika J. Wirtz</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+T">Traci Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+D">Derry Wijaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Main conference), 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This paper introduces a multilingual dataset of COVID-19 vaccine
misinformation, consisting of annotated tweets from three middle-income
countries: Brazil, Indonesia, and Nigeria. The expertly curated dataset
includes annotations for 5,952 tweets, assessing their relevance to COVID-19
vaccines, presence of misinformation, and the themes of the misinformation. To
address challenges posed by domain specificity, the low-resource setting, and
data imbalance, we adopt two approaches for developing COVID-19 vaccine
misinformation detection models: domain-specific pre-training and text
augmentation using a large language model. Our best misinformation detection
models demonstrate improvements ranging from 2.7 to 15.9 percentage points in
macro F1-score compared to the baseline models. Additionally, we apply our
misinformation detection models in a large-scale study of 19 million unlabeled
tweets from the three countries between 2020 and 2022, showcasing the practical
application of our dataset and models for detecting and analyzing vaccine
misinformation in multiple countries and languages. Our analysis indicates that
percentage changes in the number of new COVID-19 cases are positively
associated with COVID-19 vaccine misinformation rates in a staggered manner for
Brazil and Indonesia, and there are significant positive associations between
the misinformation rates across the three countries.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18198" title="Abstract">arXiv:2311.18198</a> [<a href="/pdf/2311.18198" title="Download PDF">pdf</a>, <a href="/format/2311.18198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-T CRF: Spatial-Temporal Conditional Random Field for Human Trajectory  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengqian Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jialing He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Song Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yanni Tang</a>, 
<a href="/search/cs?searchtype=author&query=Roop%2C+P">Partha Roop</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Trajectory prediction is of significant importance in computer vision.
Accurate pedestrian trajectory prediction benefits autonomous vehicles and
robots in planning their motion. Pedestrians' trajectories are greatly
influenced by their intentions. Prior studies having introduced various deep
learning methods only pay attention to the spatial and temporal information of
trajectory, overlooking the explicit intention information. In this study, we
introduce a novel model, termed the \textbf{S-T CRF}:
\textbf{S}patial-\textbf{T}emporal \textbf{C}onditional \textbf{R}andom
\textbf{F}ield, which judiciously incorporates intention information besides
spatial and temporal information of trajectory. This model uses a Conditional
Random Field (CRF) to generate a representation of future intentions, greatly
improving the prediction of subsequent trajectories when combined with
spatial-temporal representation. Furthermore, the study innovatively devises a
space CRF loss and a time CRF loss, meticulously designed to enhance
interaction constraints and temporal dynamics, respectively. Extensive
experimental evaluations on dataset ETH/UCY and SDD demonstrate that the
proposed method surpasses existing baseline approaches.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18199" title="Abstract">arXiv:2311.18199</a> [<a href="/pdf/2311.18199" title="Download PDF">pdf</a>, <a href="/format/2311.18199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hy-Tracker: A Novel Framework for Enhancing Efficiency and Accuracy of  Object Tracking in Hyperspectral Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+A">Mohammad Aminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wangzhi Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yongsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Paliwal%2C+K+K">Kuldip K. Paliwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hyperspectral object tracking has recently emerged as a topic of great
interest in the remote sensing community. The hyperspectral image, with its
many bands, provides a rich source of material information of an object that
can be effectively used for object tracking. While most hyperspectral trackers
are based on detection-based techniques, no one has yet attempted to employ
YOLO for detecting and tracking the object. This is due to the presence of
multiple spectral bands, the scarcity of annotated hyperspectral videos, and
YOLO's performance limitation in managing occlusions, and distinguishing object
in cluttered backgrounds. Therefore, in this paper, we propose a novel
framework called Hy-Tracker, which aims to bridge the gap between hyperspectral
data and state-of-the-art object detection methods to leverage the strengths of
YOLOv7 for object tracking in hyperspectral videos. Hy-Tracker not only
introduces YOLOv7 but also innovatively incorporates a refined tracking module
on top of YOLOv7. The tracker refines the initial detections produced by
YOLOv7, leading to improved object-tracking performance. Furthermore, we
incorporate Kalman-Filter into the tracker, which addresses the challenges
posed by scale variation and occlusion. The experimental results on
hyperspectral benchmark datasets demonstrate the effectiveness of Hy-Tracker in
accurately tracking objects across frames.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18200" title="Abstract">arXiv:2311.18200</a> [<a href="/pdf/2311.18200" title="Download PDF">pdf</a>, <a href="/format/2311.18200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INarIG: Iterative Non-autoregressive Instruct Generation Model For  Word-Level Auto Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+H">Hengchao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Daimeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+L">Lizhi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Computer-aided translation (CAT) aims to enhance human translation efficiency
and is still important in scenarios where machine translation cannot meet
quality requirements. One fundamental task within this field is Word-Level Auto
Completion (WLAC). WLAC predicts a target word given a source sentence,
translation context, and a human typed character sequence. Previous works
either employ word classification models to exploit contextual information from
both sides of the target word or directly disregarded the dependencies from the
right-side context. Furthermore, the key information, i.e. human typed
sequences, is only used as prefix constraints in the decoding module. In this
paper, we propose the INarIG (Iterative Non-autoregressive Instruct Generation)
model, which constructs the human typed sequence into Instruction Unit and
employs iterative decoding with subwords to fully utilize input information
given in the task. Our model is more competent in dealing with low-frequency
words (core scenario of this task), and achieves state-of-the-art results on
the WMT22 and benchmark datasets, with a maximum increase of over 10%
prediction accuracy.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18206" title="Abstract">arXiv:2311.18206</a> [<a href="/pdf/2311.18206" title="Download PDF">pdf</a>, <a href="/format/2311.18206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCOPE-RL: A Python Library for Offline Reinforcement Learning and  Off-Policy Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiyohara%2C+H">Haruka Kiyohara</a>, 
<a href="/search/cs?searchtype=author&query=Kishimoto%2C+R">Ren Kishimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kawakami%2C+K">Kosuke Kawakami</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Ken Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+K">Kazuhide Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuta Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, open-source software: <a href="https://github.com/hakuhodo-technologies/scope-rl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces SCOPE-RL, a comprehensive open-source Python software
designed for offline reinforcement learning (offline RL), off-policy evaluation
(OPE), and selection (OPS). Unlike most existing libraries that focus solely on
either policy learning or evaluation, SCOPE-RL seamlessly integrates these two
key aspects, facilitating flexible and complete implementations of both offline
RL and OPE processes. SCOPE-RL put particular emphasis on its OPE modules,
offering a range of OPE estimators and robust evaluation-of-OPE protocols. This
approach enables more in-depth and reliable OPE compared to other packages. For
instance, SCOPE-RL enhances OPE by estimating the entire reward distribution
under a policy rather than its mere point-wise expected value. Additionally,
SCOPE-RL provides a more thorough evaluation-of-OPE by presenting the
risk-return tradeoff in OPE results, extending beyond mere accuracy evaluations
in existing OPE literature. SCOPE-RL is designed with user accessibility in
mind. Its user-friendly APIs, comprehensive documentation, and a variety of
easy-to-follow examples assist researchers and practitioners in efficiently
implementing and experimenting with various offline RL methods and OPE
estimators, tailored to their specific problem contexts. The documentation of
SCOPE-RL is available at https://scope-rl.readthedocs.io/en/latest/.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18207" title="Abstract">arXiv:2311.18207</a> [<a href="/pdf/2311.18207" title="Download PDF">pdf</a>, <a href="/format/2311.18207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiyohara%2C+H">Haruka Kiyohara</a>, 
<a href="/search/cs?searchtype=author&query=Kishimoto%2C+R">Ren Kishimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kawakami%2C+K">Kosuke Kawakami</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Ken Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+K">Kazuhide Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuta Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Off-Policy Evaluation (OPE) aims to assess the effectiveness of
counterfactual policies using only offline logged data and is often used to
identify the top-k promising policies for deployment in online A/B tests.
Existing evaluation metrics for OPE estimators primarily focus on the
"accuracy" of OPE or that of downstream policy selection, neglecting
risk-return tradeoff in the subsequent online policy deployment. To address
this issue, we draw inspiration from portfolio evaluation in finance and
develop a new metric, called SharpeRatio@k, which measures the risk-return
tradeoff of policy portfolios formed by an OPE estimator under varying online
evaluation budgets (k). We validate our metric in two example scenarios,
demonstrating its ability to effectively distinguish between low-risk and
high-risk estimators and to accurately identify the most efficient estimator.
This efficient estimator is characterized by its capability to form the most
advantageous policy portfolios, maximizing returns while minimizing risks
during online deployment, a nuance that existing metrics typically overlook. To
facilitate a quick, accurate, and consistent evaluation of OPE via
SharpeRatio@k, we have also integrated this metric into an open-source
software, SCOPE-RL. Employing SharpeRatio@k and SCOPE-RL, we conduct
comprehensive benchmarking experiments on various estimators and RL tasks,
focusing on their risk-return tradeoff. These experiments offer several
interesting directions and suggestions for future OPE research.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18208" title="Abstract">arXiv:2311.18208</a> [<a href="/pdf/2311.18208" title="Download PDF">pdf</a>, <a href="/format/2311.18208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMaRt: Improving GANs with Score Matching Regularity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Mengfei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Ran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-jin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Generative adversarial networks (GANs) usually struggle in learning from
highly diverse data, whose underlying manifold is complex. In this work, we
revisit the mathematical foundations of GANs, and theoretically reveal that the
native adversarial loss for GAN training is insufficient to fix the problem of
subsets with positive Lebesgue measure of the generated data manifold lying out
of the real data manifold. Instead, we find that score matching serves as a
valid solution to this issue thanks to its capability of persistently pushing
the generated data points towards the real data manifold. We thereby propose to
improve the optimization of GANs with score matching regularity (SMaRt).
Regarding the empirical evidences, we first design a toy example to show that
training GANs by the aid of a ground-truth score function can help reproduce
the real data distribution more accurately, and then confirm that our approach
can consistently boost the synthesis performance of various state-of-the-art
GANs on real-world datasets with pre-trained diffusion models acting as the
approximate score function. For instance, when training Aurora on the ImageNet
64x64 dataset, we manage to improve FID from 8.87 to 7.11, on par with the
performance of one-step consistency model. The source code will be made public.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18212" title="Abstract">arXiv:2311.18212</a> [<a href="/pdf/2311.18212" title="Download PDF">pdf</a>, <a href="/format/2311.18212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whole-body Dynamic Collision Avoidance with Time-varying Control Barrier  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+X">Xuemin Chi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hongye Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recently, there has been increasing attention in robot research towards the
whole-body collision avoidance. In this paper, we propose a safety-critical
controller that utilizes time-varying control barrier functions (time varying
CBFs) constructed by Robo-centric Euclidean Signed Distance Field (RC-ESDF) to
achieve dynamic collision avoidance. The RC-ESDF is constructed in the robot
body frame and solely relies on the robot's shape, eliminating the need for
real-time updates to save computational resources. Additionally, we design two
control Lyapunov functions (CLFs) to ensure that the robot can reach its
destination. To enable real-time application, our safety-critical controller
which incorporates CLFs and CBFs as constraints is formulated as a quadratic
program (QP) optimization problem. We conducted numerical simulations on two
different dynamics of an L-shaped robot to verify the effectiveness of our
proposed approach.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18213" title="Abstract">arXiv:2311.18213</a> [<a href="/pdf/2311.18213" title="Download PDF">pdf</a>, <a href="/format/2311.18213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Two-Tower Matching: Learning Sparse Retrievable  Cross-Interactions for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Liangcai Su</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+F">Fan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoyi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenhua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIGIR 2023. Code will be available at <a href="https://reczoo.github.io/SparCode">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Two-tower models are a prevalent matching framework for recommendation, which
have been widely deployed in industrial applications. The success of two-tower
matching attributes to its efficiency in retrieval among a large number of
items, since the item tower can be precomputed and used for fast Approximate
Nearest Neighbor (ANN) search. However, it suffers two main challenges,
including limited feature interaction capability and reduced accuracy in online
serving. Existing approaches attempt to design novel late interactions instead
of dot products, but they still fail to support complex feature interactions or
lose retrieval efficiency. To address these challenges, we propose a new
matching paradigm named SparCode, which supports not only sophisticated feature
interactions but also efficient retrieval. Specifically, SparCode introduces an
all-to-all interaction module to model fine-grained query-item interactions.
Besides, we design a discrete code-based sparse inverted index jointly trained
with the model to achieve effective and efficient model inference. Extensive
experiments have been conducted on open benchmark datasets to demonstrate the
superiority of our framework. The results show that SparCode significantly
improves the accuracy of candidate item matching while retaining the same level
of retrieval efficiency with two-tower models. Our source code will be
available at MindSpore/models.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18215" title="Abstract">arXiv:2311.18215</a> [<a href="/pdf/2311.18215" title="Download PDF">pdf</a>, <a href="/format/2311.18215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Construction of a Korean Toxic Instruction Dataset for Ethical  Tuning of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Byun%2C+S">Sungjoo Byun</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+D">Dongjun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+H">Hyemi Jo</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hyopil Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Caution: this paper may include material that could be offensive or
distressing.
<br />The advent of Large Language Models (LLMs) necessitates the development of
training approaches that mitigate the generation of unethical language and
aptly manage toxic user queries. Given the challenges related to human labor
and the scarcity of data, we present KoTox, comprising 39K unethical
instruction-output pairs. This collection of automatically generated toxic
instructions refines the training of LLMs and establishes a foundational
framework for improving LLMs' ethical awareness and response to various toxic
inputs, promoting more secure and responsible interactions in Natural Language
Processing (NLP) applications.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18216" title="Abstract">arXiv:2311.18216</a> [<a href="/pdf/2311.18216" title="Download PDF">pdf</a>, <a href="/format/2311.18216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FS-BAND: A Frequency-Sensitive Banding Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ru Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fangfang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.17752">arXiv:2311.17752</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Banding artifact, as known as staircase-like contour, is a common quality
annoyance that happens in compression, transmission, etc. scenarios, which
largely affects the user's quality of experience (QoE). The banding distortion
typically appears as relatively small pixel-wise variations in smooth
backgrounds, which is difficult to analyze in the spatial domain but easily
reflected in the frequency domain. In this paper, we thereby study the banding
artifact from the frequency aspect and propose a no-reference banding detection
model to capture and evaluate banding artifacts, called the Frequency-Sensitive
BANding Detector (FS-BAND). The proposed detector is able to generate a
pixel-wise banding map with a perception correlated quality score. Experimental
results show that the proposed FS-BAND method outperforms state-of-the-art
image quality assessment (IQA) approaches with higher accuracy in banding
classification task.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18220" title="Abstract">arXiv:2311.18220</a> [<a href="/pdf/2311.18220" title="Download PDF">pdf</a>, <a href="/ps/2311.18220" title="Download PostScript">ps</a>, <a href="/format/2311.18220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifting query complexity to time-space complexity for two-way finite  automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shenggen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Minghua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gruska%2C+J">Jozef Gruska</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lvzhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Time-space tradeoff has been studied in a variety of models, such as Turing
machines, branching programs, and finite automata, etc. While communication
complexity as a technique has been applied to study finite automata, it seems
it has not been used to study time-space tradeoffs of finite automata. We
design a new technique showing that separations of query complexity can be
lifted, via communication complexity, to separations of time-space complexity
of two-way finite automata. As an application, one of our main results exhibits
the first example of a language $L$ such that the time-space complexity of
two-way probabilistic finite automata with a bounded error (2PFA) is
$\widetilde{\Omega}(n^2)$, while of exact two-way quantum finite automata with
classical states (2QCFA) is $\widetilde{O}(n^{5/3})$, that is, we demonstrate
for the first time that exact quantum computing has an advantage in time-space
complexity comparing to classical computing.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18224" title="Abstract">arXiv:2311.18224</a> [<a href="/pdf/2311.18224" title="Download PDF">pdf</a>, <a href="/format/2311.18224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reasoning with the Theory of Mind for Pragmatic Semantic Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Strinati%2C+E+C">Emilio Calvanese Strinati</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, a pragmatic semantic communication framework that enables
effective goal-oriented information sharing between two-intelligent agents is
proposed. In particular, semantics is defined as the causal state that
encapsulates the fundamental causal relationships and dependencies among
different features extracted from data. The proposed framework leverages the
emerging concept in machine learning (ML) called theory of mind (ToM). It
employs a dynamic two-level (wireless and semantic) feedback mechanism to
continuously fine-tune neural network components at the transmitter. Thanks to
the ToM, the transmitter mimics the actual mental state of the receiver's
reasoning neural network operating semantic interpretation. Then, the estimated
mental state at the receiver is dynamically updated thanks to the proposed
dynamic two-level feedback mechanism. At the lower level, conventional channel
quality metrics are used to optimize the channel encoding process based on the
wireless communication channel's quality, ensuring an efficient mapping of
semantic representations to a finite constellation. Additionally, a semantic
feedback level is introduced, providing information on the receiver's perceived
semantic effectiveness with minimal overhead. Numerical evaluations demonstrate
the framework's ability to achieve efficient communication with a reduced
amount of bits while maintaining the same semantics, outperforming conventional
systems that do not exploit the ToM-based reasoning.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18231" title="Abstract">arXiv:2311.18231</a> [<a href="/pdf/2311.18231" title="Download PDF">pdf</a>, <a href="/format/2311.18231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCP:Textual-based Class-aware Prompt tuning for Visual-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hantao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt tuning represents a valuable technique for adapting pre-trained
visual-language models (VLM) to various downstream tasks. Recent advancements
in CoOp-based methods propose a set of learnable domain-shared or
image-conditional textual tokens to facilitate the generation of task-specific
textual classifiers. However, those textual tokens have a limited
generalization ability regarding unseen domains, as they cannot dynamically
adjust to the distribution of testing classes. To tackle this issue, we present
a novel Textual-based Class-aware Prompt tuning(TCP) that explicitly
incorporates prior knowledge about classes to enhance their discriminability.
The critical concept of TCP involves leveraging Textual Knowledge Embedding
(TKE) to map the high generalizability of class-level textual knowledge into
class-aware textual tokens. By seamlessly integrating these class-aware prompts
into the Text Encoder, a dynamic class-aware classifier is generated to enhance
discriminability for unseen domains. During inference, TKE dynamically
generates class-aware prompts related to the unseen classes. Comprehensive
evaluations demonstrate that TKE serves as a plug-and-play module effortlessly
combinable with existing methods. Furthermore, TCP consistently achieves
superior performance while demanding less training time.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18232" title="Abstract">arXiv:2311.18232</a> [<a href="/pdf/2311.18232" title="Download PDF">pdf</a>, <a href="/format/2311.18232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulhai%2C+M">Marwa Abdulhai</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+I">Isadora White</a>, 
<a href="/search/cs?searchtype=author&query=Snell%2C+C">Charlie Snell</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Charles Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Joey Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kelvin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) provide excellent text-generation capabilities,
but standard prompting and generation methods generally do not lead to
intentional or goal-directed agents and might necessitate considerable prompt
tuning. This becomes particularly apparent in multi-turn conversations: even
the best current LLMs rarely ask clarifying questions, engage in explicit
information gathering, or take actions now that lead to better decisions after
multiple turns. Reinforcement learning has the potential to leverage the
powerful modeling capabilities of LLMs, as well as their internal
representation of textual interactions, to create capable goal-directed
language agents. This can enable intentional and temporally extended
interactions, such as with humans, through coordinated persuasion and carefully
crafted questions, or in goal-directed play through text games to bring about
desired final outcomes. However, enabling this requires the community to
develop stable and reliable reinforcement learning algorithms that can
effectively train LLMs. Developing such algorithms requires tasks that can
gauge progress on algorithm design, provide accessible and reproducible
evaluations for multi-turn interactions, and cover a range of task properties
and challenges in improving reinforcement learning algorithms. Our paper
introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs,
together with an open-source research framework containing a basic toolkit for
getting started on multi-turn RL with offline value-based and policy-based RL
methods. Our benchmark consists of 8 different language tasks, which require
multiple rounds of language interaction and cover a range of tasks in
open-ended dialogue and text games.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18233" title="Abstract">arXiv:2311.18233</a> [<a href="/pdf/2311.18233" title="Download PDF">pdf</a>, <a href="/format/2311.18233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Bound and Multi Types, Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Accattoli%2C+B">Beniamino Accattoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CSL 2024 paper with Appendix. arXiv admin note: text overlap with <a href="/abs/2104.13979">arXiv:2104.13979</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Intersection types are a standard tool in operational and semantical studies
of the lambda calculus. De Carvalho showed how multi types, a quantitative
variant of intersection types providing a handy presentation of the relational
denotational model, allows one to extract precise bounds on the number of
$\beta$-steps and the size of normal forms.
<br />In the last few years, de Carvalho's work has been extended and adapted to a
number of lambda calculi, evaluation strategies, and abstract machines. These
works, however, only adapt the first part of his work, that extracts bounds
from multi type derivations, while never consider the second part, which deals
with extracting bounds from the multi types themselves. The reason is that this
second part is more technical, and requires to reason up to type substitutions.
It is however also the most interesting, because it shows that the bounding
power is inherent to the relational model (which is induced by the types,
without the derivations), independently of its presentation as a type system.
<br />Here we dissect and clarify the second part of de Carvalho's work,
establishing a link with principal multi types, and isolating a key property
independent of type substitutions.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18237" title="Abstract">arXiv:2311.18237</a> [<a href="/pdf/2311.18237" title="Download PDF">pdf</a>, <a href="/format/2311.18237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-efficient Training of Small Task-specific Models by Leveraging  Vision Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vemulapalli%2C+R">Raviteja Vemulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Pouransari%2C+H">Hadi Pouransari</a>, 
<a href="/search/cs?searchtype=author&query=Faghri%2C+F">Fartash Faghri</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S">Sachin Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Farajtabar%2C+M">Mehrdad Farajtabar</a>, 
<a href="/search/cs?searchtype=author&query=Rastegari%2C+M">Mohammad Rastegari</a>, 
<a href="/search/cs?searchtype=author&query=Tuzel%2C+O">Oncel Tuzel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Vision Foundation Models (VFMs) pretrained on massive datasets exhibit
impressive performance on various downstream tasks, especially with limited
labeled target data. However, due to their high memory and compute
requirements, these models cannot be deployed in resource constrained settings.
This raises an important question: How can we utilize the knowledge from a
large VFM to train a small task-specific model for a new target task with
limited labeled training data? In this work, we answer this question by
proposing a simple and highly effective task-oriented knowledge transfer
approach to leverage pretrained VFMs for effective training of small
task-specific models. Our experimental results on four target tasks under
limited labeled data settings show that the proposed knowledge transfer
approach outperforms task-agnostic VFM distillation, web-scale CLIP pretraining
and supervised ImageNet pretraining by 1-10.5%, 2-22% and 2-14%, respectively.
We also show that the dataset used for transferring knowledge has a significant
effect on the final target task performance, and propose an image
retrieval-based approach for curating effective transfer sets.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18241" title="Abstract">arXiv:2311.18241</a> [<a href="/pdf/2311.18241" title="Download PDF">pdf</a>, <a href="/ps/2311.18241" title="Download PostScript">ps</a>, <a href="/format/2311.18241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLVMs4Protest: Harnessing the Power of Large Language and Vision Models  for Deciphering Protests in the News
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongjun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language and vision models have transformed how social movements
scholars identify protest and extract key protest attributes from multi-modal
data such as texts, images, and videos. This article documents how we
fine-tuned two large pretrained transformer models, including longformer and
swin-transformer v2, to infer potential protests in news articles using textual
and imagery data. First, the longformer model was fine-tuned using the Dynamic
of Collective Action (DoCA) Corpus. We matched the New York Times articles with
the DoCA database to obtain a training dataset for downstream tasks. Second,
the swin-transformer v2 models was trained on UCLA-protest imagery data.
UCLA-protest project contains labeled imagery data with information such as
protest, violence, and sign. Both fine-tuned models will be available via
\url{https://github.com/Joshzyj/llvms4protest}. We release this short technical
report for social movement scholars who are interested in using LLVMs to infer
protests in textual and imagery data.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18243" title="Abstract">arXiv:2311.18243</a> [<a href="/pdf/2311.18243" title="Download PDF">pdf</a>, <a href="/format/2311.18243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DKiS: Decay weight invertible image steganography with private key
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yitian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuhua Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Image steganography, the practice of concealing information within another
image, traditionally faces security challenges when its methods become publicly
known. To counteract this, we introduce a novel private key-based image
steganography technique. This approach ensures the security of hidden
information, requiring a corresponding private key for access, irrespective of
the public knowledge of the steganography method. We present experimental
evidence demonstrating our method's effectiveness, showcasing its real-world
applicability. Additionally, we identified a critical challenge in the
invertible image steganography process: the transfer of non-essential, or
`garbage', information from the secret to the host pipeline. To address this,
we introduced the decay weight to control the information transfer, filtering
out irrelevant data and enhancing the performance of image steganography. Our
code is publicly accessible at https://github.com/yanghangAI/DKiS, and a
practical demonstration is available at <a href="http://yanghang.site/hidekey.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18244" title="Abstract">arXiv:2311.18244</a> [<a href="/pdf/2311.18244" title="Download PDF">pdf</a>, <a href="/format/2311.18244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisoning Attacks Against Contrastive Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junliang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Min Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+S">Shazia Sadiq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14pages,6 figures,5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contrastive learning (CL) has recently gained significant popularity in the
field of recommendation. Its ability to learn without heavy reliance on labeled
data is a natural antidote to the data sparsity issue. Previous research has
found that CL can not only enhance recommendation accuracy but also
inadvertently exhibit remarkable robustness against noise. However, this paper
identifies a vulnerability of CL-based recommender systems: Compared with their
non-CL counterparts, they are even more susceptible to poisoning attacks that
aim to promote target items. Our analysis points to the uniform dispersion of
representations led by the CL loss as the very factor that accounts for this
vulnerability. We further theoretically and empirically demonstrate that the
optimization of CL loss can lead to smooth spectral values of representations.
Based on these insights, we attempt to reveal the potential poisoning attacks
against CL-based recommender systems. The proposed attack encompasses a
dual-objective framework: One that induces a smoother spectral value
distribution to amplify the CL loss's inherent dispersion effect, named
dispersion promotion; and the other that directly elevates the visibility of
target items, named rank promotion. We validate the destructiveness of our
attack model through extensive experimentation on four datasets. By shedding
light on these vulnerabilities, we aim to facilitate the development of more
robust CL-based recommender systems.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18246" title="Abstract">arXiv:2311.18246</a> [<a href="/pdf/2311.18246" title="Download PDF">pdf</a>, <a href="/format/2311.18246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined Scheduling, Memory Allocation and Tensor Replacement for  Minimizing Off-Chip Data Accesses of DNN Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aarti Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+S">Sharad Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Specialized hardware accelerators have been extensively used for Deep Neural
Networks (DNNs) to provide power/performance benefits. These accelerators
contain specialized hardware that supports DNN operators, and scratchpad memory
for storing the tensor operands. Often, the size of the scratchpad is
insufficient to store all the tensors needed for the computation, and
additional data accesses are needed to move tensors back and forth from host
memory during the computation with significant power/performance overhead. The
volume of these additional data accesses depends on the operator schedule, and
memory allocation (specific locations selected for the tensors in the
scratchpad). We propose an optimization framework, named COSMA, for mapping
DNNs to an accelerator that finds the optimal operator schedule, memory
allocation and tensor replacement that minimizes the additional data accesses.
COSMA provides an Integer Linear Programming (ILP) formulation to generate the
optimal solution for mapping a DNN to the accelerator for a given scratchpad
size. We demonstrate that, using an off-the-shelf ILP solver, COSMA obtains the
optimal solution in seconds for a wide-range of state-of-the-art DNNs for
different applications. Further, it out-performs existing methods by reducing
on average 84% of the non-compulsory data accesses. We further propose a
divide-and-conquer heuristic to scale up to certain complex DNNs generated by
Neural Architecture Search, and this heuristic solution reduces on average 85%
data accesses compared with other works.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18248" title="Abstract">arXiv:2311.18248</a> [<a href="/pdf/2311.18248" title="Download PDF">pdf</a>, <a href="/format/2311.18248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yaya Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiabo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, the strong text creation ability of Large Language Models(LLMs) has
given rise to many tools for assisting paper reading or even writing. However,
the weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit
their application scenarios, especially for scientific academic paper writing.
In this work, towards a more versatile copilot for academic paper writing, we
mainly focus on strengthening the multi-modal diagram analysis ability of
Multimodal LLMs. By parsing Latex source files of high-quality papers, we
carefully build a multi-modal diagram understanding dataset M-Paper. By
aligning diagrams in the paper with related paragraphs, we construct
professional diagram analysis samples for training and evaluation. M-Paper is
the first dataset to support joint comprehension of multiple scientific
diagrams, including figures and tables in the format of images or Latex codes.
Besides, to better align the copilot with the user's intention, we introduce
the `outline' as the control signal, which could be directly given by the user
or revised based on auto-generated ones. Comprehensive experiments with a
state-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows
stronger scientific diagram understanding performance, including diagram
captioning, diagram analysis, and outline recommendation. The dataset, code,
and model are available at
https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18251" title="Abstract">arXiv:2311.18251</a> [<a href="/pdf/2311.18251" title="Download PDF">pdf</a>, <a href="/format/2311.18251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Be Good Companions? An LLM-Based Eyewear  System with Conversational Common Ground
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenyu Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hailin Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhouyang Lu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yingying Zhao</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui Zhu</a> (2), 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujiang Wang</a> (3), 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mingzhi Dong</a> (1), 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yuhu Chang</a> (1), 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qin Lv</a> (4), 
<a href="/search/cs?searchtype=author&query=Dick%2C+R+P">Robert P. Dick</a> (5), 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a> (6), 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a> (1), 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a> (1), 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Li Shang</a> (1) ((1) Fudan University, School of Computer Science, (2) University of London, Bayes Business School, (3) Oxford Suzhou Centre for Advanced Research, (4) University of Colorado Boulder, Department of Computer Science, (5) University of Michigan, Department of Electrical Engineering and Computer Science, (6) Fudan University, School of Microelectronics)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 25 figures, Under review at ACM IMWUT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Developing chatbots as personal companions has long been a goal of artificial
intelligence researchers. Recent advances in Large Language Models (LLMs) have
delivered a practical solution for endowing chatbots with anthropomorphic
language capabilities. However, it takes more than LLMs to enable chatbots that
can act as companions. Humans use their understanding of individual
personalities to drive conversations. Chatbots also require this capability to
enable human-like companionship. They should act based on personalized,
real-time, and time-evolving knowledge of their owner. We define such essential
knowledge as the \textit{common ground} between chatbots and their owners, and
we propose to build a common-ground-aware dialogue system from an LLM-based
module, named \textit{OS-1}, to enable chatbot companionship. Hosted by
eyewear, OS-1 can sense the visual and audio signals the user receives and
extract real-time contextual semantics. Those semantics are categorized and
recorded to formulate historical contexts from which the user's profile is
distilled and evolves over time, i.e., OS-1 gradually learns about its user.
OS-1 combines knowledge from real-time semantics, historical contexts, and
user-specific profiles to produce a common-ground-aware prompt input into the
LLM module. The LLM's output is converted to audio, spoken to the wearer when
appropriate.We conduct laboratory and in-field studies to assess OS-1's ability
to build common ground between the chatbot and its user. The technical
feasibility and capabilities of the system are also evaluated. OS-1, with its
common-ground awareness, can significantly improve user satisfaction and
potentially lead to downstream tasks such as personal emotional support and
assistance.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18252" title="Abstract">arXiv:2311.18252</a> [<a href="/pdf/2311.18252" title="Download PDF">pdf</a>, <a href="/format/2311.18252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Privacy and Copyright Challenges Across the Data Lifecycle of  Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Boming Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thong Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Staples%2C+M">Mark Staples</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of Generative AI has marked a significant milestone in artificial
intelligence, demonstrating remarkable capabilities in generating realistic
images, texts, and data patterns. However, these advancements come with
heightened concerns over data privacy and copyright infringement, primarily due
to the reliance on vast datasets for model training. Traditional approaches
like differential privacy, machine unlearning, and data poisoning only offer
fragmented solutions to these complex issues. Our paper delves into the
multifaceted challenges of privacy and copyright protection within the data
lifecycle. We advocate for integrated approaches that combines technical
innovation with ethical foresight, holistically addressing these concerns by
investigating and devising solutions that are informed by the lifecycle
perspective. This work aims to catalyze a broader discussion and inspire
concerted efforts towards data privacy and copyright integrity in Generative
AI.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18254" title="Abstract">arXiv:2311.18254</a> [<a href="/pdf/2311.18254" title="Download PDF">pdf</a>, <a href="/format/2311.18254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch Input Method Editor: A Comprehensive Dataset and Methodology for  Systematic Input Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guangming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qing Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kelong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the recent surge in the use of touchscreen devices, free-hand sketching
has emerged as a promising modality for human-computer interaction. While
previous research has focused on tasks such as recognition, retrieval, and
generation of familiar everyday objects, this study aims to create a Sketch
Input Method Editor (SketchIME) specifically designed for a professional C4I
system. Within this system, sketches are utilized as low-fidelity prototypes
for recommending standardized symbols in the creation of comprehensive
situation maps. This paper also presents a systematic dataset comprising 374
specialized sketch types, and proposes a simultaneous recognition and
segmentation architecture with multilevel supervision between recognition and
segmentation to improve performance and enhance interpretability. By
incorporating few-shot domain adaptation and class-incremental learning, the
network's ability to adapt to new users and extend to new task-specific classes
is significantly enhanced. Results from experiments conducted on both the
proposed dataset and the SPG dataset illustrate the superior performance of the
proposed architecture. Our dataset and code are publicly available at
https://github.com/Anony517/SketchIME.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18257" title="Abstract">arXiv:2311.18257</a> [<a href="/pdf/2311.18257" title="Download PDF">pdf</a>, <a href="/format/2311.18257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models Without Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J+N">Jing Nathan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiatao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Rush%2C+A+M">Alexander M. Rush</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent advancements in high-fidelity image generation, Denoising Diffusion
Probabilistic Models (DDPMs) have emerged as a key player. However, their
application at high resolutions presents significant computational challenges.
Current methods, such as patchifying, expedite processes in UNet and
Transformer architectures but at the expense of representational capacity.
Addressing this, we introduce the Diffusion State Space Model (DiffuSSM), an
architecture that supplants attention mechanisms with a more scalable state
space model backbone. This approach effectively handles higher resolutions
without resorting to global compression, thus preserving detailed image
representation throughout the diffusion process. Our focus on FLOP-efficient
architectures in diffusion training marks a significant step forward.
Comprehensive evaluations on both ImageNet and LSUN datasets at two resolutions
demonstrate that DiffuSSMs are on par or even outperform existing diffusion
models with attention modules in FID and Inception Score metrics while
significantly reducing total FLOP usage.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18259" title="Abstract">arXiv:2311.18259</a> [<a href="/pdf/2311.18259" title="Download PDF">pdf</a>, <a href="/format/2311.18259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ego-Exo4D: Understanding Skilled Human Activity from First- and  Third-Person Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>, 
<a href="/search/cs?searchtype=author&query=Westbury%2C+A">Andrew Westbury</a>, 
<a href="/search/cs?searchtype=author&query=Torresani%2C+L">Lorenzo Torresani</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Afouras%2C+T">Triantafyllos Afouras</a>, 
<a href="/search/cs?searchtype=author&query=Ashutosh%2C+K">Kumar Ashutosh</a>, 
<a href="/search/cs?searchtype=author&query=Baiyya%2C+V">Vijay Baiyya</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Siddhant Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Boote%2C+B">Bikram Boote</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+E">Eugene Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Chavis%2C+Z">Zach Chavis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Joya Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Feng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+F">Fu-Jen Chu</a>, 
<a href="/search/cs?searchtype=author&query=Crane%2C+S">Sean Crane</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+A">Avijit Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Escobar%2C+M">Maria Escobar</a>, 
<a href="/search/cs?searchtype=author&query=Forigua%2C+C">Cristhian Forigua</a>, 
<a href="/search/cs?searchtype=author&query=Gebreselasie%2C+A">Abrham Gebreselasie</a>, 
<a href="/search/cs?searchtype=author&query=Haresh%2C+S">Sanjay Haresh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md Mohaiminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Suyog Jain</a>, 
<a href="/search/cs?searchtype=author&query=Khirodkar%2C+R">Rawal Khirodkar</a>, 
<a href="/search/cs?searchtype=author&query=Kukreja%2C+D">Devansh Kukreja</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K+J">Kevin J Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+S">Sagnik Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongsen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+M">Miguel Martin</a>, 
<a href="/search/cs?searchtype=author&query=Mavroudi%2C+E">Effrosyni Mavroudi</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+T">Tushar Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Ragusa%2C+F">Francesco Ragusa</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+S+K">Santhosh Kumar Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Seminara%2C+L">Luigi Seminara</a>, 
<a href="/search/cs?searchtype=author&query=Somayazulu%2C+A">Arjun Somayazulu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yale Song</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shan Su</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zihui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Edward Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+A">Angela Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinzhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+R">Ryosuke Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+C">Cristina Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Prince Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiabo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Khoo%2C+W">Weslie Khoo</a>,  et al. (48 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present Ego-Exo4D, a diverse, large-scale multimodal multiview video
dataset and benchmark challenge. Ego-Exo4D centers around
simultaneously-captured egocentric and exocentric video of skilled human
activities (e.g., sports, music, dance, bike repair). More than 800
participants from 13 cities worldwide performed these activities in 131
different natural scene contexts, yielding long-form captures from 1 to 42
minutes each and 1,422 hours of video combined. The multimodal nature of the
dataset is unprecedented: the video is accompanied by multichannel audio, eye
gaze, 3D point clouds, camera poses, IMU, and multiple paired language
descriptions -- including a novel "expert commentary" done by coaches and
teachers and tailored to the skilled-activity domain. To push the frontier of
first-person video understanding of skilled human activity, we also present a
suite of benchmark tasks and their annotations, including fine-grained activity
understanding, proficiency estimation, cross-view translation, and 3D hand/body
pose. All resources will be open sourced to fuel new research in the community.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18261" title="Abstract">arXiv:2311.18261</a> [<a href="/pdf/2311.18261" title="Download PDF">pdf</a>, <a href="/format/2311.18261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Exactly Linearizable Deep Dynamics Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moriyasu%2C+R">Ryuta Moriyasu</a>, 
<a href="/search/eess?searchtype=author&query=Kusunoki%2C+M">Masayuki Kusunoki</a>, 
<a href="/search/eess?searchtype=author&query=Kashima%2C+K">Kenji Kashima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Research on control using models based on machine-learning methods has now
shifted to the practical engineering stage. Achieving high performance and
theoretically guaranteeing the safety of the system is critical for such
applications. In this paper, we propose a learning method for exactly
linearizable dynamical models that can easily apply various control theories to
ensure stability, reliability, etc., and to provide a high degree of freedom of
expression. As an example, we present a design that combines simple linear
control and control barrier functions. The proposed model is employed for the
real-time control of an automotive engine, and the results demonstrate good
predictive performance and stable control under constraints.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18265" title="Abstract">arXiv:2311.18265</a> [<a href="/pdf/2311.18265" title="Download PDF">pdf</a>, <a href="/format/2311.18265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCI Detection using fMRI time series embeddings of Recurrence plots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aithal%2C+N">Ninad Aithal</a>, 
<a href="/search/cs?searchtype=author&query=Pradeep%2C+C+S">Chakka Sai Pradeep</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+N">Neelam Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The human brain can be conceptualized as a dynamical system. Utilizing
resting state fMRI time series imaging, we can study the underlying dynamics at
ear-marked Regions of Interest (ROIs) to understand structure or lack thereof.
This differential behavior could be key to understanding the neurodegeneration
and also to classify between healthy and Mild Cognitive Impairment (MCI)
subjects. In this study, we consider 6 brain networks spanning over 160 ROIs
derived from Dosenbach template, where each network consists of 25-30 ROIs.
Recurrence plot, extensively used to understand evolution of time series, is
employed. Representative time series at each ROI is converted to its
corresponding recurrence plot visualization, which is subsequently condensed to
low-dimensional feature embeddings through Autoencoders. The performance of the
proposed method is shown on fMRI volumes of 100 subjects (balanced data), taken
from publicly available ADNI dataset. Results obtained show peak classification
accuracy of 93% among the 6 brain networks, mean accuracy of 89.3% thereby
illustrating promise in the proposed approach.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18266" title="Abstract">arXiv:2311.18266</a> [<a href="/pdf/2311.18266" title="Download PDF">pdf</a>, <a href="/format/2311.18266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-Based Exemplar Super-Compression and Regeneration for  Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+R">Ruxiao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaoyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieneng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/KerryDRX/ESCORT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Replay-based methods in class-incremental learning (CIL) have attained
remarkable success, as replaying the exemplars of old classes can significantly
mitigate catastrophic forgetting. Despite their effectiveness, the inherent
memory restrictions of CIL result in saving a limited number of exemplars with
poor diversity, leading to data imbalance and overfitting issues. In this
paper, we introduce a novel exemplar super-compression and regeneration method,
ESCORT, which substantially increases the quantity and enhances the diversity
of exemplars. Rather than storing past images, we compress images into visual
and textual prompts, e.g., edge maps and class tags, and save the prompts
instead, reducing the memory usage of each exemplar to 1/24 of the original
size. In subsequent learning phases, diverse high-resolution exemplars are
generated from the prompts by a pre-trained diffusion model, e.g., ControlNet.
To minimize the domain gap between generated exemplars and real images, we
propose partial compression and diffusion-based data augmentation, allowing us
to utilize an off-the-shelf diffusion model without fine-tuning it on the
target dataset. Therefore, the same diffusion model can be downloaded whenever
it is needed, incurring no memory consumption. Comprehensive experiments
demonstrate that our method significantly improves model performance across
multiple CIL benchmarks, e.g., 5.0 percentage points higher than the previous
state-of-the-art on 10-phase Caltech-256 dataset.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18268" title="Abstract">arXiv:2311.18268</a> [<a href="/pdf/2311.18268" title="Download PDF">pdf</a>, <a href="/ps/2311.18268" title="Download PostScript">ps</a>, <a href="/format/2311.18268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explorative Study on Document Type Assignment of Review Articles in  Web of Science, Scopus and Journals&#x27; Website
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Manman Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xinyue Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fuyou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liying Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhesi Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Accurately assigning the document type of review articles in citation index
databases like Web of Science(WoS) and Scopus is important. This study aims to
investigate the document type assignation of review articles in web of Science,
Scopus and Journals' website in a large scale. 27,616 papers from 160 journals
from 10 review journal series indexed in SCI are analyzed. The document types
of these papers labeled on journals' website, and assigned by WoS and Scopus
are retrieved and compared to determine the assigning accuracy and identify the
possible reasons of wrongly assigning. For the document type labeled on the
website, we further differentiate them into explicit review and implicit review
based on whether the website directly indicating it is review or not. We find
that WoS and Scopus performed similarly, with an average precision of about 99%
and recall of about 80%. However, there were some differences between WoS and
Scopus across different journal series and within the same journal series. The
assigning accuracy of WoS and Scopus for implicit reviews dropped
significantly. This study provides a reference for the accuracy of document
type assigning of review articles in WoS and Scopus, and the identified pattern
for assigning implicit reviews may be helpful to better labeling on website,
WoS and Scopus.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18270" title="Abstract">arXiv:2311.18270</a> [<a href="/pdf/2311.18270" title="Download PDF">pdf</a>, <a href="/format/2311.18270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Entropy: Style Transfer Guided Single Image Continual Test-Time  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Younggeol Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngrae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongman Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Continual test-time adaptation (cTTA) methods are designed to facilitate the
continual adaptation of models to dynamically changing real-world environments
where computational resources are limited. Due to this inherent limitation,
existing approaches fail to simultaneously achieve accuracy and efficiency. In
detail, when using a single image, the instability caused by batch
normalization layers and entropy loss significantly destabilizes many existing
methods in real-world cTTA scenarios. To overcome these challenges, we present
BESTTA, a novel single image continual test-time adaptation method guided by
style transfer, which enables stable and efficient adaptation to the target
environment by transferring the style of the input image to the source style.
To implement the proposed method, we devise BeIN, a simple yet powerful
normalization method, along with the style-guided losses. We demonstrate that
BESTTA effectively adapts to the continually changing target environment,
leveraging only a single image on both semantic segmentation and image
classification tasks. Remarkably, despite training only two parameters in a
BeIN layer consuming the least memory, BESTTA outperforms existing
state-of-the-art methods in terms of performance.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18273" title="Abstract">arXiv:2311.18273</a> [<a href="/pdf/2311.18273" title="Download PDF">pdf</a>, <a href="/format/2311.18273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HKUST at SemEval-2023 Task 1: Visual Word Sense Disambiguation with  Context Augmentation and Visual Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhuohao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Visual Word Sense Disambiguation (VWSD) is a multi-modal task that aims to
select, among a batch of candidate images, the one that best entails the target
word's meaning within a limited context. In this paper, we propose a
multi-modal retrieval framework that maximally leverages pretrained
Vision-Language models, as well as open knowledge bases and datasets. Our
system consists of the following key components: (1) Gloss matching: a
pretrained bi-encoder model is used to match contexts with proper senses of the
target words; (2) Prompting: matched glosses and other textual information,
such as synonyms, are incorporated using a prompting template; (3) Image
retrieval: semantically matching images are retrieved from large open datasets
using prompts as queries; (4) Modality fusion: contextual information from
different modalities are fused and used for prediction. Although our system
does not produce the most competitive results at SemEval-2023 Task 1, we are
still able to beat nearly half of the teams. More importantly, our experiments
reveal acute insights for the field of Word Sense Disambiguation (WSD) and
multi-modal learning. Our code is available on GitHub.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18285" title="Abstract">arXiv:2311.18285</a> [<a href="/pdf/2311.18285" title="Download PDF">pdf</a>, <a href="/format/2311.18285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-speech gestures for human-robot collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ekrekli%2C+A">A. Ekrekli</a>, 
<a href="/search/cs?searchtype=author&query=Angleraud%2C+A">A. Angleraud</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">G. Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Pieters%2C+R">R. Pieters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, accepted to IEEE International Conference on Robotics Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Collaboration between human and robot requires effective modes of
communication to assign robot tasks and coordinate activities. As communication
can utilize different modalities, a multi-modal approach can be more expressive
than single modal models alone. In this work we propose a co-speech gesture
model that can assign robot tasks for human-robot collaboration. Human gestures
and speech, detected by computer vision and speech recognition, can thus refer
to objects in the scene and apply robot actions to them. We present an
experimental evaluation of the multi-modal co-speech model with a real-world
industrial use case. Results demonstrate that multi-modal communication is easy
to achieve and can provide benefits for collaboration with respect to single
modal tools.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18286" title="Abstract">arXiv:2311.18286</a> [<a href="/pdf/2311.18286" title="Download PDF">pdf</a>, <a href="/format/2311.18286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimulFlow: Simultaneously Extracting Feature and Identifying Target for  Unsupervised Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shuyong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">WenQiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised video object segmentation (UVOS) aims at detecting the primary
objects in a given video sequence without any human interposing. Most existing
methods rely on two-stream architectures that separately encode the appearance
and motion information before fusing them to identify the target and generate
object masks. However, this pipeline is computationally expensive and can lead
to suboptimal performance due to the difficulty of fusing the two modalities
properly. In this paper, we propose a novel UVOS model called SimulFlow that
simultaneously performs feature extraction and target identification, enabling
efficient and effective unsupervised video object segmentation. Concretely, we
design a novel SimulFlow Attention mechanism to bridege the image and motion by
utilizing the flexibility of attention operation, where coarse masks predicted
from fused feature at each stage are used to constrain the attention operation
within the mask area and exclude the impact of noise. Because of the
bidirectional information flow between visual and optical flow features in
SimulFlow Attention, no extra hand-designed fusing module is required and we
only adopt a light decoder to obtain the final prediction. We evaluate our
method on several benchmark datasets and achieve state-of-the-art results. Our
proposed approach not only outperforms existing methods but also addresses the
computational complexity and fusion difficulties caused by two-stream
architectures. Our models achieve 87.4% J &amp; F on DAVIS-16 with the highest
speed (63.7 FPS on a 3090) and the lowest parameters (13.7 M). Our SimulFlow
also obtains competitive results on video salient object detection datasets.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18288" title="Abstract">arXiv:2311.18288</a> [<a href="/pdf/2311.18288" title="Download PDF">pdf</a>, <a href="/format/2311.18288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CosAvatar: Consistent and Animatable Portrait Video Tuning with Text  Prompt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Haiyao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chenglai Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yudong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ustc3dv.github.io/CosAvatar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, text-guided digital portrait editing has attracted more and more
attentions. However, existing methods still struggle to maintain consistency
across time, expression, and view or require specific data prerequisites. To
solve these challenging problems, we propose CosAvatar, a high-quality and
user-friendly framework for portrait tuning. With only monocular video and text
instructions as input, we can produce animatable portraits with both temporal
and 3D consistency. Different from methods that directly edit in the 2D domain,
we employ a dynamic NeRF-based 3D portrait representation to model both the
head and torso. We alternate between editing the video frames' dataset and
updating the underlying 3D portrait until the edited frames reach 3D
consistency. Additionally, we integrate the semantic portrait priors to enhance
the edited results, allowing precise modifications in specified semantic areas.
Extensive results demonstrate that our proposed method can not only accurately
edit portrait styles or local attributes based on text instructions but also
support expressive animation driven by a source video.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18291" title="Abstract">arXiv:2311.18291</a> [<a href="/pdf/2311.18291" title="Download PDF">pdf</a>, <a href="/format/2311.18291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLDR: Text Based Last-layer Retraining for Debiasing Image Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Juhyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seokhyeon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+T">Taesup Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A classifier may depend on incidental features stemming from a strong
correlation between the feature and the classification target in the training
dataset. Recently, Last Layer Retraining (LLR) with group-balanced datasets is
known to be efficient in mitigating the spurious correlation of classifiers.
However, the acquisition of group-balanced datasets is costly, which hinders
the applicability of the LLR method. In this work, we propose to perform LLR
based on text datasets built with large language models for a general image
classifier. We demonstrate that text can be a proxy for its corresponding image
beyond the image-text joint embedding space, such as CLIP. Based on this, we
use generated texts to train the final layer in the embedding space of the
arbitrary image classifier. In addition, we propose a method of filtering the
generated words to get rid of noisy, imprecise words, which reduces the effort
of inspecting each word. We dub these procedures as TLDR (\textbf{T}ext-based
\textbf{L}ast layer retraining for \textbf{D}ebiasing image
classifie\textbf{R}s) and show our method achieves the performance that is
comparable to those of the LLR methods that also utilize group-balanced image
dataset for retraining. Furthermore, TLDR outperforms other baselines that
involve training the last linear layer without a group annotated dataset.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18295" title="Abstract">arXiv:2311.18295</a> [<a href="/pdf/2311.18295" title="Download PDF">pdf</a>, <a href="/format/2311.18295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost-Linear Time Algorithms for Incremental Graphs: Cycle Detection,  SCCs, $s$-$t$ Shortest Path, and Minimum-Cost Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kyng%2C+R">Rasmus Kyng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meierhans%2C+S">Simon Meierhans</a>, 
<a href="/search/cs?searchtype=author&query=Gutenberg%2C+M+P">Maximilian Probst Gutenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We give the first almost-linear time algorithms for several problems in
incremental graphs including cycle detection, strongly connected component
maintenance, $s$-$t$ shortest path, maximum flow, and minimum-cost flow. To
solve these problems, we give a deterministic data structure that returns a
$m^{o(1)}$-approximate minimum-ratio cycle in fully dynamic graphs in amortized
$m^{o(1)}$ time per update. Combining this with the interior point method
framework of Brand-Liu-Sidford (STOC 2023) gives the first almost-linear time
algorithm for deciding the first update in an incremental graph after which the
cost of the minimum-cost flow attains value at most some given threshold $F$.
By rather direct reductions to minimum-cost flow, we are then able to solve the
problems in incremental graphs mentioned above.
<br />At a high level, our algorithm dynamizes the $\ell_1$ oblivious routing of
Rozho\v{n}-Grunau-Haeupler-Zuzic-Li (STOC 2022), and develops a method to
extract an approximate minimum ratio cycle from the structure of the oblivious
routing. To maintain the oblivious routing, we use tools from concurrent work
of Kyng-Meierhans-Probst Gutenberg which designed vertex sparsifiers for
shortest paths, in order to maintain a sparse neighborhood cover in fully
dynamic graphs.
<br />To find a cycle, we first show that an approximate minimum ratio cycle can be
represented as a fundamental cycle on a small set of trees resulting from the
oblivious routing. Then, we find a cycle whose quality is comparable to the
best tree cycle. This final cycle query step involves vertex and edge
sparsification procedures reminiscent of previous works, but crucially requires
a more powerful dynamic spanner which can handle far more edge insertions. We
build such a spanner via a construction that hearkens back to the classic
greedy spanner algorithm.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18296" title="Abstract">arXiv:2311.18296</a> [<a href="/pdf/2311.18296" title="Download PDF">pdf</a>, <a href="/format/2311.18296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Group Tokenizer: Building Perception with Iterative Grouping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human visual recognition system shows astonishing capability of compressing
visual information into a set of tokens containing rich representations without
label supervision. One critical driving principle behind it is perceptual
grouping. Despite being widely used in computer vision in the early 2010s, it
remains a mystery whether perceptual grouping can be leveraged to derive a
neural visual recognition backbone that generates as powerful representations.
In this paper, we propose the Perceptual Group Tokenizer, a model that entirely
relies on grouping operations to extract visual features and perform
self-supervised representation learning, where a series of grouping operations
are used to iteratively hypothesize the context for pixels or superpixels to
refine feature representations. We show that the proposed model can achieve
competitive performance compared to state-of-the-art vision architectures, and
inherits desirable properties including adaptive computation without
re-training, and interpretability. Specifically, Perceptual Group Tokenizer
achieves 80.3% on ImageNet-1K self-supervised learning benchmark with linear
probe evaluation, marking a new progress under this paradigm.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18297" title="Abstract">arXiv:2311.18297</a> [<a href="/pdf/2311.18297" title="Download PDF">pdf</a>, <a href="/format/2311.18297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrustMark: Universal Watermarking for Arbitrary Resolution Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+T">Tu Bui</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shruti Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Collomosse%2C+J">John Collomosse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Imperceptible digital watermarking is important in copyright protection,
misinformation prevention, and responsible generative AI. We propose TrustMark
- a GAN-based watermarking method with novel design in architecture and
spatio-spectra losses to balance the trade-off between watermarked image
quality with the watermark recovery accuracy. Our model is trained with
robustness in mind, withstanding various in- and out-place perturbations on the
encoded image. Additionally, we introduce TrustMark-RM - a watermark remover
method useful for re-watermarking. Our methods achieve state-of-art performance
on 3 benchmarks comprising arbitrary resolution images.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18299" title="Abstract">arXiv:2311.18299</a> [<a href="/pdf/2311.18299" title="Download PDF">pdf</a>, <a href="/format/2311.18299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing the normal and shape at specularities in endoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makki%2C+K">Karim Makki</a>, 
<a href="/search/cs?searchtype=author&query=Bartoli%2C+A">Adrien Bartoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Specularities are numerous in endoscopic images. They occur as many white
small elliptic spots, which are generally ruled out as nuisance in image
analysis and computer vision methods. Instead, we propose to use specularities
as cues for 3D perception. Specifically, we propose a new method to
reconstruct, at each specularity, the observed tissue's normal direction (i.e.,
its orientation) and shape (i.e., its curvature) from a single image. We show
results on simulated and real interventional images.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18300" title="Abstract">arXiv:2311.18300</a> [<a href="/pdf/2311.18300" title="Download PDF">pdf</a>, <a href="/format/2311.18300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label Annotation for Visual Multi-Task Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">G. Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Angleraud%2C+A">A. Angleraud</a>, 
<a href="/search/cs?searchtype=author&query=Pieters%2C+R">R. Pieters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, accepted to IEEE International Conference on Robotic Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deep learning requires large amounts of data, and a well-defined pipeline for
labeling and augmentation. Current solutions support numerous computer vision
tasks with dedicated annotation types and formats, such as bounding boxes,
polygons, and key points. These annotations can be combined into a single data
format to benefit approaches such as multi-task models. However, to our
knowledge, no available labeling tool supports the export functionality for a
combined benchmark format, and no augmentation library supports transformations
for the combination of all. In this work, these functionalities are presented,
with visual data annotation and augmentation to train a multi-task model
(object detection, segmentation, and key point extraction). The tools are
demonstrated in two robot perception use cases.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18303" title="Abstract">arXiv:2311.18303</a> [<a href="/pdf/2311.18303" title="Download PDF">pdf</a>, <a href="/format/2311.18303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniMotionGPT: Animal Motion Generation with Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhangsihao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+M">Mengyi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bingbing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Z">Ziwei Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+M">Mitch Hill</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Junjie Bai</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guo-Jun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yalin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project page is at <a href="https://zshyang.github.io/omgpt-website/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our paper aims to generate diverse and realistic animal motion sequences from
textual descriptions, without a large-scale animal text-motion dataset. While
the task of text-driven human motion synthesis is already extensively studied
and benchmarked, it remains challenging to transfer this success to other
skeleton structures with limited data. In this work, we design a model
architecture that imitates Generative Pretraining Transformer (GPT), utilizing
prior knowledge learned from human data to the animal domain. We jointly train
motion autoencoders for both animal and human motions and at the same time
optimize through the similarity scores among human motion encoding, animal
motion encoding, and text CLIP embedding. Presenting the first solution to this
problem, we are able to generate animal motions with high diversity and
fidelity, quantitatively and qualitatively outperforming the results of
training human motion generation baselines on animal data. Additionally, we
introduce AnimalML3D, the first text-animal motion dataset with 1240 animation
sequences spanning 36 different animal identities. We hope this dataset would
mediate the data scarcity problem in text-driven animal motion generation,
providing a new playground for the research community.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18305" title="Abstract">arXiv:2311.18305</a> [<a href="/pdf/2311.18305" title="Download PDF">pdf</a>, <a href="/format/2311.18305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Gearhart-Koshy acceleration is a Krylov space method of a  new type
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hegland%2C+M">Markus Hegland</a>, 
<a href="/search/math?searchtype=author&query=Rieger%2C+J">Janosch Rieger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Gearhart-Koshy acceleration for the Kaczmarz method for linear systems is
a line-search with the unusual property that it does not minimize the residual,
but the error. Recently one of the authors generalized the this acceleration
from a line-search to a search in affine subspaces.
<br />In this paper, we demonstrate that the affine search is a Krylov space method
that is neither a CG-type nor a MINRES-type method, and we prove that it is
mathematically equivalent with a more canonical Gram-Schmidt-based method. We
also investigate what abstract property of the Kaczmarz method enables this
type of algorithm, and we conclude with a simple numerical example.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18307" title="Abstract">arXiv:2311.18307</a> [<a href="/pdf/2311.18307" title="Download PDF">pdf</a>, <a href="/format/2311.18307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical Traffic Transformer: Interpretable and Diverse Behavior  Prediction with Tokenized Latent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tonkens%2C+S">Sander Tonkens</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Adept traffic models are critical to both planning and closed-loop simulation
for autonomous vehicles (AV), and key design objectives include accuracy,
diverse multimodal behaviors, interpretability, and downstream compatibility.
Recently, with the advent of large language models (LLMs), an additional
desirable feature for traffic models is LLM compatibility. We present
Categorical Traffic Transformer (CTT), a traffic model that outputs both
continuous trajectory predictions and tokenized categorical predictions (lane
modes, homotopies, etc.). The most outstanding feature of CTT is its fully
interpretable latent space, which enables direct supervision of the latent
variable from the ground truth during training and avoids mode collapse
completely. As a result, CTT can generate diverse behaviors conditioned on
different latent modes with semantic meanings while beating SOTA on prediction
accuracy. In addition, CTT's ability to input and output tokens enables
integration with LLMs for common-sense reasoning and zero-shot generalization.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18311" title="Abstract">arXiv:2311.18311</a> [<a href="/pdf/2311.18311" title="Download PDF">pdf</a>, <a href="/format/2311.18311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic Neural Representation Learning for High-Quality Neural  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Y.Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">J. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Y. Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Y. Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural radiance fields (NeRFs) have achieved impressive view synthesis
results by learning an implicit volumetric representation from multi-view
images. To project the implicit representation into an image, NeRF employs
volume rendering that approximates the continuous integrals of rays as an
accumulation of the colors and densities of the sampled points. Although this
approximation enables efficient rendering, it ignores the direction information
in point intervals, resulting in ambiguous features and limited reconstruction
quality. In this paper, we propose an anisotropic neural representation
learning method that utilizes learnable view-dependent features to improve
scene representation and reconstruction. We model the volumetric function as
spherical harmonic (SH)-guided anisotropic features, parameterized by
multilayer perceptrons, facilitating ambiguity elimination while preserving the
rendering efficiency. To achieve robust scene reconstruction without anisotropy
overfitting, we regularize the energy of the anisotropic features during
training. Our method is flexiable and can be plugged into NeRF-based
frameworks. Extensive experiments show that the proposed representation can
boost the rendering quality of various NeRFs and achieve state-of-the-art
rendering performance on both synthetic and real-world scenes.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18316" title="Abstract">arXiv:2311.18316</a> [<a href="/pdf/2311.18316" title="Download PDF">pdf</a>, <a href="/format/2311.18316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning for Semantic Knowledge Base-Guided Online Feature Transmission  in Dynamic Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiangyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yaping Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dongyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaodong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the proliferation of edge computing, efficient AI inference on edge
devices has become essential for intelligent applications such as autonomous
vehicles and VR/AR. In this context, we address the problem of efficient remote
object recognition by optimizing feature transmission between mobile devices
and edge servers. We propose an online optimization framework to address the
challenge of dynamic channel conditions and device mobility in an end-to-end
communication system. Our approach builds upon existing methods by leveraging a
semantic knowledge base to drive multi-level feature transmission, accounting
for temporal factors and dynamic elements throughout the transmission process.
To solve the online optimization problem, we design a novel soft
actor-critic-based deep reinforcement learning system with a carefully designed
reward function for real-time decision-making, overcoming the optimization
difficulty of the NP-hard problem and achieving the minimization of semantic
loss while respecting latency constraints. Numerical results showcase the
superiority of our approach compared to traditional greedy methods under
various system setups.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18318" title="Abstract">arXiv:2311.18318</a> [<a href="/pdf/2311.18318" title="Download PDF">pdf</a>, <a href="/ps/2311.18318" title="Download PostScript">ps</a>, <a href="/format/2311.18318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unclonable Cryptography with Unbounded Collusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87akan%2C+A">Alper &#xc7;akan</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vipul Goyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Quantum no-cloning theorem gives rise to the intriguing possibility of
quantum copy protection where we encode a program in a quantum state such that
a user in possession of k such states cannot create k + 1 working copies.
Introduced by Aaronson (CCC 09) over a decade ago, copy protection has proven
to be notoriously hard to achieve.
<br />In this work, we construct public-key encryption and functional encryption
schemes whose secret keys are copy-protected against unbounded collusions in
the plain model (i.e. without any idealized oracles), assuming (post-quantum)
subexponentially secure iO, one-way functions and LWE. This resolves a
long-standing open question of constructing fully collusion-resistant
copy-protected functionalities raised by multiple previous works.
<br />Prior to our work, copy-protected functionalities were known only in
restricted collusion models where either an a-priori bound on the collusion
size was needed, in the plain model with the same assumptions as ours (Liu,
Liu, Qian, Zhandry [TCC 22]), or adversary was only prevented from doubling
their number of working programs, in a structured quantum oracle model
(Aaronson [CCC 09]).
<br />We obtain our results through a novel technique which uses identity-based
encryption to construct unbounded collusion resistant copy-protection schemes
from 1-to-2 secure schemes. This is analogous to the technique of using digital
signatures to construct full-fledged quantum money from single banknote
schemes1 (Lutomirski et al. [ICS 09], Farhi et al. [ITCS 12], Aaronson and
Christiano [STOC 12]). We believe our technique is of independent interest.
<br />Along the way, we also construct a puncturable functional encryption scheme
whose master secret key can be punctured at all functions f such that f (m0) !=
f (m1). This might also be of independent interest.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18327" title="Abstract">arXiv:2311.18327</a> [<a href="/pdf/2311.18327" title="Download PDF">pdf</a>, <a href="/ps/2311.18327" title="Download PostScript">ps</a>, <a href="/format/2311.18327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning Based Optimal Energy Management of  Multi-energy Microgrids with Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+Y">Yang Cui</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yijian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+X">Xinpeng Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CSEE Journal of Power and Energy Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Multi-energy microgrid (MEMG) offers an effective approach to deal with
energy demand diversification and new energy consumption on the consumer side.
In MEMG, it is critical to deploy an energy management system (EMS) for
efficient utilization of energy and reliable operation of the system. To help
EMS formulate optimal dispatching schemes, a deep reinforcement learning
(DRL)-based MEMG energy management scheme with renewable energy source (RES)
uncertainty is proposed in this paper. To accurately describe the operating
state of the MEMG, the off-design performance model of energy conversion
devices is considered in scheduling. The nonlinear optimal dispatching model is
expressed as a Markov decision process (MDP) and is then addressed by the twin
delayed deep deterministic policy gradient (TD3) algorithm. In addition, to
accurately describe the uncertainty of RES, the conditional-least squares
generative adversarial networks (C-LSGANs) method based on RES forecast power
is proposed to construct the scenarios set of RES power generation. The
generated data of RES is used for scheduling to obtain caps and floors for the
purchase of electricity and natural gas. Based on this, the superior energy
supply sector can formulate solutions in advance to tackle the uncertainty of
RES. Finally, the simulation analysis demonstrates the validity and superiority
of the method.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18328" title="Abstract">arXiv:2311.18328</a> [<a href="/pdf/2311.18328" title="Download PDF">pdf</a>, <a href="/format/2311.18328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in 3D Neural Stylization: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingshu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+G">Guocheng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+K+C">Ka Chun Shum</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Modern artificial intelligence provides a novel way of producing digital art
in styles. The expressive power of neural networks enables the realm of visual
style transfer methods, which can be used to edit images, videos, and 3D data
to make them more artistic and diverse. This paper reports on recent advances
in neural stylization for 3D data. We provide a taxonomy for neural stylization
by considering several important design choices, including scene
representation, guidance data, optimization strategies, and output styles.
Building on such taxonomy, our survey first revisits the background of neural
stylization on 2D images, and then provides in-depth discussions on recent
neural stylization methods for 3D data, where we also provide a mini-benchmark
on artistic stylization methods. Based on the insights gained from the survey,
we then discuss open challenges, future research, and potential applications
and impacts of neural stylization.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18329" title="Abstract">arXiv:2311.18329</a> [<a href="/pdf/2311.18329" title="Download PDF">pdf</a>, <a href="/format/2311.18329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instructing Hierarchical Tasks to Robots by Verbal Commands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Telkes%2C+P">P. Telkes</a>, 
<a href="/search/cs?searchtype=author&query=Angleraud%2C+A">A. Angleraud</a>, 
<a href="/search/cs?searchtype=author&query=Pieters%2C+R">R. Pieters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, accepted to 16th IEEE/SICE International Symposium on System Integration
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Natural language is an effective tool for communication, as information can
be expressed in different ways and at different levels of complexity. Verbal
commands, utilized for instructing robot tasks, can therefor replace
traditional robot programming techniques, and provide a more expressive means
to assign actions and enable collaboration. However, the challenge of utilizing
speech for robot programming is how actions and targets can be grounded to
physical entities in the world. In addition, to be time-efficient, a balance
needs to be found between fine- and course-grained commands and natural
language phrases. In this work we provide a framework for instructing tasks to
robots by verbal commands. The framework includes functionalities for single
commands to actions and targets, as well as longer-term sequences of actions,
thereby providing a hierarchical structure to the robot tasks. Experimental
evaluation demonstrates the functionalities of the framework by human
collaboration with a robot in different tasks, with different levels of
complexity. The tools are provided open-source at
https://petim44.github.io/voice-jogger/
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18331" title="Abstract">arXiv:2311.18331</a> [<a href="/pdf/2311.18331" title="Download PDF">pdf</a>, <a href="/format/2311.18331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with  Multi-Resolution Feature Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udupa%2C+S">Sumanth Udupa</a>, 
<a href="/search/cs?searchtype=author&query=Gurunath%2C+P">Prajwal Gurunath</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+A">Aniruddh Sikdar</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+S">Suresh Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural networks have shown exemplary performance on semantic scene
understanding tasks on source domains, but due to the absence of style
diversity during training, enhancing performance on unseen target domains using
only single source domain data remains a challenging task. Generation of
simulated data is a feasible alternative to retrieving large style-diverse
real-world datasets as it is a cumbersome and budget-intensive process.
However, the large domain-specific inconsistencies between simulated and
real-world data pose a significant generalization challenge in semantic
segmentation. In this work, to alleviate this problem, we propose a novel
MultiResolution Feature Perturbation (MRFP) technique to randomize
domain-specific fine-grained features and perturb style of coarse features. Our
experimental results on various urban-scene segmentation datasets clearly
indicate that, along with the perturbation of style-information, perturbation
of fine-feature components is paramount to learn domain invariant robust
feature maps for semantic segmentation models. MRFP is a simple and
computationally efficient, transferable module with no additional learnable
parameters or objective functions, that helps state-of-the-art deep neural
networks to learn robust domain invariant features for simulation-to-real
semantic segmentation.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18332" title="Abstract">arXiv:2311.18332</a> [<a href="/pdf/2311.18332" title="Download PDF">pdf</a>, <a href="/format/2311.18332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Saliency-Guided Self-Supervised Learning for Image Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jianjian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chunzhi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Anomaly detection (AD) is a fundamental task in computer vision. It aims to
identify incorrect image data patterns which deviate from the normal ones.
Conventional methods generally address AD by preparing augmented negative
samples to enforce self-supervised learning. However, these techniques
typically do not consider semantics during augmentation, leading to the
generation of unrealistic or invalid negative samples. Consequently, the
feature extraction network can be hindered from embedding critical features. In
this study, inspired by visual attention learning approaches, we propose
CutSwap, which leverages saliency guidance to incorporate semantic cues for
augmentation. Specifically, we first employ LayerCAM to extract multilevel
image features as saliency maps and then perform clustering to obtain multiple
centroids. To fully exploit saliency guidance, on each map, we select a pixel
pair from the cluster with the highest centroid saliency to form a patch pair.
Such a patch pair includes highly similar context information with dense
semantic correlations. The resulting negative sample is created by swapping the
locations of the patch pair. Compared to prior augmentation methods, CutSwap
generates more subtle yet realistic negative samples to facilitate quality
feature learning. Extensive experimental and ablative evaluations demonstrate
that our method achieves state-of-the-art AD performance on two mainstream AD
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18333" title="Abstract">arXiv:2311.18333</a> [<a href="/pdf/2311.18333" title="Download PDF">pdf</a>, <a href="/format/2311.18333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spherical Designs for Function Approximation and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiao%2C+Y">Yuchen Xiao</a>, 
<a href="/search/math?searchtype=author&query=Zhuang%2C+X">Xiaosheng Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 9 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we compare two optimization algorithms using full Hessian and
approximation Hessian to obtain numerical spherical designs through their
variational characterization. Based on the obtained spherical design point
sets, we investigate the approximation of smooth and non-smooth functions by
spherical harmonics with spherical designs. Finally, we use spherical framelets
for denoising Wendland functions as an application, which shows the great
potential of spherical designs in spherical data processing.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18334" title="Abstract">arXiv:2311.18334</a> [<a href="/pdf/2311.18334" title="Download PDF">pdf</a>, <a href="/format/2311.18334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Field Beamfocusing with Polarized Antennas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agustin%2C+A">Adrian Agustin</a>, 
<a href="/search/cs?searchtype=author&query=Mestre%2C+X">Xavier Mestre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for conference publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">One of the most relevant challenges in future 6G wireless networks is how to
support a massive spatial multiplexing of a large number of user terminals.
Recently, extremely large antenna arrays (ELAAs), also referred to as
extra-large MIMO (XL-MIMO), have emerged as an potential enabler of this type
of spatially multiplexed transmission. These massive configurations
substantially increase the number of available spatial degrees of freedom
(transmission modes) while also enabling to spatially focus the transmitted
energy into a very small region, thanks to the properties of near-field
propagation and the large number of transmitters. This work explores whether
multiplexing of multiple orthogonal polarizations can enhance the system
performance in the near-field. We concentrate on a simple scenario consisting
of a Uniform Linear Array (ULA) and a single antenna element user equipment
(UE). We demonstrate that the number of spatial degrees of freedom can be as
large as 3 in the near-field of a Line of Sight (LoS) channel when both
transmitter and receiver employ three orthogonal linear polarizations. In the
far-field, however, the maximum number of spatial degrees of freedom tends to
be only 2, due to the fact that the equivalent MIMO channel becomes rank
deficient. We provide an analytical approximation to the achievable rate, which
allows us to derive approximations to the optimal antenna spacing and array
size that maximize the achievable rate
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18339" title="Abstract">arXiv:2311.18339</a> [<a href="/pdf/2311.18339" title="Download PDF">pdf</a>, <a href="/format/2311.18339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Bounds for The Price of Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yifeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yichuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Granot%2C+D">Daniel Granot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">A central decision maker (CDM), who seeks an efficient allocation of scarce
resources among a finite number of players, often has to incorporate fairness
criteria to avoid unfair outcomes. Indeed, the Price of Fairness (POF), a term
coined in Bertsimas et al. (2011), refers to the efficiency loss due to the
incorporation of fairness criteria into the allocation method. Quantifying the
POF would help the CDM strike an appropriate balance between efficiency and
fairness. In this paper we improve upon existing results in the literature, by
providing tight bounds for the POF for the proportional fairness criterion for
any $n$, when the maximum achievable utilities of the players are equal or are
not equal. Further, while Bertsimas et al. (2011) have already derived a tight
bound for the max-min fairness criterion for the case that all players have
equal maximum achievable utilities, we also provide a tight bound in scenarios
where these utilities are not equal. Finally, we investigate the sensitivity of
our bounds and Bertsimas et al. (2011) bounds for the POF to the variability of
the maximum achievable utilities.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18340" title="Abstract">arXiv:2311.18340</a> [<a href="/pdf/2311.18340" title="Download PDF">pdf</a>, <a href="/format/2311.18340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Incremental on-chip Learning with Hebbian Weight  Consolidation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zifan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaojin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wangzi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tielin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">As next-generation implantable brain-machine interfaces become pervasive on
edge device, incrementally learning new tasks in bio-plasticity ways is
urgently demanded for Neuromorphic chips. Due to the inherent characteristics
of its structure, spiking neural networks are naturally well-suited for
BMI-chips. Here we propose Hebbian Weight Consolidation, as well as an on-chip
learning framework. HWC selectively masks synapse modifications for previous
tasks, retaining them to store new knowledge from subsequent tasks while
preserving the old knowledge. Leveraging the bio-plasticity of dendritic
spines, the intrinsic self-organizing nature of Hebbian Weight Consolidation
aligns naturally with the incremental learning paradigm, facilitating robust
learning outcomes. By reading out spikes layer by layer and performing
back-propagation on the external micro-controller unit, MLoC can efficiently
accomplish on-chip learning. Experiments show that our HWC algorithm up to
23.19% outperforms lower bound that without incremental learning algorithm,
particularly in more challenging monkey behavior decoding scenarios. Taking
into account on-chip computing on Synsense Speck 2e chip, our proposed
algorithm exhibits an improvement of 11.06%. This study demonstrates the
feasibility of employing incremental learning for high-performance neural
signal decoding in next-generation brain-machine interfaces.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18341" title="Abstract">arXiv:2311.18341</a> [<a href="/pdf/2311.18341" title="Download PDF">pdf</a>, <a href="/format/2311.18341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Precipitation Forecaster by Temporal Frame Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lu Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu-Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Han-Jia Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-Chuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.02968">arXiv:2212.02968</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Recent advancements in deep learning have propelled the field of weather
prediction models to new heights. Despite their progress, these models often
struggle with real-world application due to their sensitivity to
spatial-temporal shifts, a vulnerability particularly pronounced in weather
prediction tasks where overfitting to local and temporal variations is common.
This paper presents an investigation into the development of a robust
precipitation forecasting model that stands resilient to such shifts. We
introduce Temporal Frame Interpolation (TFI), an innovative technique designed
to fortify forecasting models against spatial-temporal discrepancies. TFI
operates by generating synthetic samples through the interpolation of adjacent
frames from satellite imagery and ground radar data, thereby enriching the
training dataset and bolstering the model's defense against noise on frames.
Additionally, we integrate a novel multi-level dice loss, which exploits the
ordinal nature of rainfall intensities to further refine model performance.
These methodologies have collectively advanced our model's forecasting
precision, achieving \textit{1st place} on the transfer learning leaderboard in
the \textit{Weather4Cast'23 competition}.It not only demonstrates the efficacy
of our approaches but also sets a new benchmark for deep learning applications
in meteorological forecasting. Our code and weights have been public on
\url{https://github.com/Secilia-Cxy/UNetTFI}.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18343" title="Abstract">arXiv:2311.18343</a> [<a href="/pdf/2311.18343" title="Download PDF">pdf</a>, <a href="/ps/2311.18343" title="Download PostScript">ps</a>, <a href="/format/2311.18343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAR-RIS Assisted Cell-Free Massive MIMO System Under  Spatially-Correlated Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papazafeiropoulos%2C+A">Anastasios Papazafeiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Kourtessis%2C+P">Pandelis Kourtessis</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in IEEE TVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper investigates the performance of downlink simultaneous transmitting
and reflecting reconfigurable intelligent surface (STAR-RIS)-assisted cell-free
(CF) massive multiple-input multiple-output (mMIMO) systems, where user
equipments (UEs) are located on both sides of the RIS.
<br />We account for correlated Rayleigh fading and multiple antennas per access
point (AP), while the maximum ratio (MR) beamforming is applied for the design
of the active beamforming in terms of instantaneous channel state information
(CSI). Firstly, we rely on an aggregated channel estimation approach that
reduces the overhead required for channel estimation while providing sufficient
information for data processing. We obtain the normalized mean square error
(NMSE) of the channel estimate per AP, and design the passive beamforming (PB)
of the surface based on the long-time statistical CSI. Next, we derive the
received signal in the asymptotic regime of numbers of APs and surface
elements. Then, we obtain a closed-form expression of the downlink achievable
rate for arbitrary numbers of APs and STAR-RIS elements under statistical CSI.
Finally, based on the derived expressions, the numerical results show the
feasibility and the advantages of deploying a STAR-RIS into conventional CF
mMIMO systems. In particular, we theoretically analyze the properties of
STAR-RIS-assisted CF mMIMO systems and reveal explicit insights in terms of the
impact of channel correlation, the number of surface elements, and the pilot
contamination on the achievable rate.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18344" title="Abstract">arXiv:2311.18344</a> [<a href="/pdf/2311.18344" title="Download PDF">pdf</a>, <a href="/format/2311.18344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSeg: Direct Line Segments Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cyrille%2C+B">Berger Cyrille</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+L">Lacroix Simon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a model-driven approach to detect image line segments.
The approach incrementally detects segments on the gradient image using a
linear Kalman filter that estimates the supporting line parameters and their
associated variances. The algorithm is fast and robust with respect to image
noise and illumination variations, it allows the detection of longer line
segments than data-driven approaches, and does not require any tedious
parameters tuning. An extension of the algorithm that exploits a pyramidal
approach to enhance the quality of results is proposed. Results with varying
scene illumination and comparisons to classic existing approaches are
presented.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18345" title="Abstract">arXiv:2311.18345</a> [<a href="/pdf/2311.18345" title="Download PDF">pdf</a>, <a href="/ps/2311.18345" title="Download PostScript">ps</a>, <a href="/format/2311.18345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Situating the social issues of image generation models in the model life  cycle: a sociotechnical approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katirai%2C+A">Amelia Katirai</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+N">Noa Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Ide%2C+K">Kazuki Ide</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Kishimoto%2C+A">Atsuo Kishimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The race to develop image generation models is intensifying, with a rapid
increase in the number of text-to-image models available. This is coupled with
growing public awareness of these technologies. Though other generative AI
models--notably, large language models--have received recent critical attention
for the social and other non-technical issues they raise, there has been
relatively little comparable examination of image generation models. This paper
reports on a novel, comprehensive categorization of the social issues
associated with image generation models. At the intersection of machine
learning and the social sciences, we report the results of a survey of the
literature, identifying seven issue clusters arising from image generation
models: data issues, intellectual property, bias, privacy, and the impacts on
the informational, cultural, and natural environments. We situate these social
issues in the model life cycle, to aid in considering where potential issues
arise, and mitigation may be needed. We then compare these issue clusters with
what has been reported for large language models. Ultimately, we argue that the
risks posed by image generation models are comparable in severity to the risks
posed by large language models, and that the social impact of image generation
models must be urgently considered.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18350" title="Abstract">arXiv:2311.18350</a> [<a href="/pdf/2311.18350" title="Download PDF">pdf</a>, <a href="/format/2311.18350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Jiaqi Wang is the corresponding author. arXiv admin note: text overlap with <a href="/abs/2311.00144">arXiv:2311.00144</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The foundation models (FMs) have been used to generate synthetic public
datasets for the heterogeneous federated learning (HFL) problem where each
client uses a unique model architecture. However, the vulnerabilities of
integrating FMs, especially against backdoor attacks, are not well-explored in
the HFL contexts. In this paper, we introduce a novel backdoor attack mechanism
for HFL that circumvents the need for client compromise or ongoing
participation in the FL process. This method plants and transfers the backdoor
through a generated synthetic public dataset, which could help evade existing
backdoor defenses in FL by presenting normal client behaviors. Empirical
experiments across different HFL configurations and benchmark datasets
demonstrate the effectiveness of our attack compared to traditional
client-based attacks. Our findings reveal significant security risks in
developing robust FM-assisted HFL systems. This research contributes to
enhancing the safety and integrity of FL systems, highlighting the need for
advanced security measures in the era of FMs.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18353" title="Abstract">arXiv:2311.18353</a> [<a href="/pdf/2311.18353" title="Download PDF">pdf</a>, <a href="/format/2311.18353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Rationale Understanding of Critical Reasoning in Logical  Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawabata%2C+A">Akira Kawabata</a>, 
<a href="/search/cs?searchtype=author&query=Sugawara%2C+S">Saku Sugawara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To precisely evaluate a language model's capability for logical reading
comprehension, we present a dataset for testing the understanding of the
rationale behind critical reasoning. For questions taken from an existing
multiplechoice logical reading comprehension dataset, we crowdsource rationale
texts that explain why we should select or eliminate answer options, resulting
in 3,003 multiple-choice subquestions that are associated with 943 main
questions. Experiments on our dataset show that recent large language models
(e.g., InstructGPT) struggle to answer the subquestions even if they are able
to answer the main questions correctly. We find that the models perform
particularly poorly in answering subquestions written for the incorrect options
of the main questions, implying that the models have a limited capability for
explaining why incorrect alternatives should be eliminated. These results
suggest that our dataset encourages further investigation into the critical
reasoning ability of language models while focusing on the elimination process
of relevant alternatives.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18355" title="Abstract">arXiv:2311.18355</a> [<a href="/pdf/2311.18355" title="Download PDF">pdf</a>, <a href="/format/2311.18355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Demonstrations Using Automated Excuse Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diehl%2C+M">Maximilian Diehl</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborti%2C+T">Tathagata Chakraborti</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez-Amaro%2C+K">Karinne Ramirez-Amaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for potential publication at IEEE ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Teaching task-level directives to robots via demonstration is a popular tool
to expand the robot's capabilities to interact with its environment. While
current learning from demonstration systems primarily focuses on abstracting
the task-level knowledge to the robot, these systems lack the ability to
understand which part of the task can be already solved given the robot's prior
knowledge. Therefore, instead of only requiring demonstrations of the missing
pieces, these systems will require a demonstration of the complete task, which
is cumbersome, repetitive, and can discourage people from helping the robot by
performing the demonstrations. Therefore, we propose to use the notion of
"excuses" to identify the smallest change in the robot state that makes a task,
currently not solvable by the robot, solvable -- as a means to solicit more
targeted demonstrations from a human. These excuses are generated automatically
using combinatorial search over possible changes that can be made to the
robot's state and choosing the minimum changes that make it solvable. These
excuses then serve as guidance for the demonstrator who can use it to decide
what to demonstrate to the robot in order to make this requested change
possible, thereby making the original task solvable for the robot without
having to demonstrate it in its entirety. By working with symbolic state
descriptions, the excuses can be directly communicated and intuitively
understood by a human demonstrator. We show empirically and in a user study
that the use of excuses reduces the demonstration time by 54% and leads to a
74% reduction in demonstration size.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18356" title="Abstract">arXiv:2311.18356</a> [<a href="/pdf/2311.18356" title="Download PDF">pdf</a>, <a href="/ps/2311.18356" title="Download PostScript">ps</a>, <a href="/format/2311.18356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Comparable Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Werner%2C+T">Thorben Werner</a>, 
<a href="/search/cs?searchtype=author&query=Burchert%2C+J">Johannes Burchert</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Active Learning has received significant attention in the field of machine
learning for its potential in selecting the most informative samples for
labeling, thereby reducing data annotation costs. However, we show that the
reported lifts in recent literature generalize poorly to other domains leading
to an inconclusive landscape in Active Learning research. Furthermore, we
highlight overlooked problems for reproducing AL experiments that can lead to
unfair comparisons and increased variance in the results. This paper addresses
these issues by providing an Active Learning framework for a fair comparison of
algorithms across different tasks and domains, as well as a fast and performant
oracle algorithm for evaluation. To the best of our knowledge, we propose the
first AL benchmark that tests algorithms in 3 major domains: Tabular, Image,
and Text. We report empirical results for 6 widely used algorithms on 7
real-world and 2 synthetic datasets and aggregate them into a domain-specific
ranking of AL algorithms.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18358" title="Abstract">arXiv:2311.18358</a> [<a href="/pdf/2311.18358" title="Download PDF">pdf</a>, <a href="/format/2311.18358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIDE: Test Time Few Shot Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hongfeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanlai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Y">Yudi Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Ying Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot object detection (FSOD) aims to extract semantic knowledge from
limited object instances of novel categories within a target domain. Recent
advances in FSOD focus on fine-tuning the base model based on a few objects via
meta-learning or data augmentation. Despite their success, the majority of them
are grounded with parametric readjustment to generalize on novel objects, which
face considerable challenges in Industry 5.0, such as (i) a certain amount of
fine-tuning time is required, and (ii) the parameters of the constructed model
being unavailable due to the privilege protection, making the fine-tuning fail.
Such constraints naturally limit its application in scenarios with real-time
configuration requirements or within black-box settings. To tackle the
challenges mentioned above, we formalize a novel FSOD task, referred to as Test
TIme Few Shot DEtection (TIDE), where the model is un-tuned in the
configuration procedure. To that end, we introduce an asymmetric architecture
for learning a support-instance-guided dynamic category classifier. Further, a
cross-attention module and a multi-scale resizer are provided to enhance the
model performance. Experimental results on multiple few-shot object detection
platforms reveal that the proposed TIDE significantly outperforms existing
contemporary methods. The implementation codes are available at
https://github.com/deku-0621/TIDE
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18361" title="Abstract">arXiv:2311.18361</a> [<a href="/pdf/2311.18361" title="Download PDF">pdf</a>, <a href="/ps/2311.18361" title="Download PostScript">ps</a>, <a href="/format/2311.18361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating lookahead planning using site appearance and space  utilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mengiste%2C+E">Eyob Mengiste</a>, 
<a href="/search/cs?searchtype=author&query=de+Soto%2C+B+G">Borja Garcia de Soto</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+T">Timo Hartmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study proposes a method to automate the development of lookahead
planning. The proposed method uses construction material conditions (i.e.,
appearances) and site space utilization to predict task completion rates. A
Gated Recurrent Unit (GRU) based Recurrent Neural Network (RNN) model was
trained using a segment of a construction project timeline to estimate
completion rates of tasks and propose data-aware lookahead plans. The proposed
method was evaluated in a sample construction project involving finishing works
such as plastering, painting, and installing electrical fixtures. The results
show that the proposed method can assist with developing automated lookahead
plans. In doing so, this study links construction planning with actual events
at the construction site. It extends the traditional scheduling techniques and
integrates a broader spectrum of site spatial constraints into lookahead
planning.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18363" title="Abstract">arXiv:2311.18363</a> [<a href="/pdf/2311.18363" title="Download PDF">pdf</a>, <a href="/format/2311.18363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Each Test Image Deserves A Specific Prompt: Continual Test-Time  Adaptation for 2D Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yiwen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Mengkang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yongsheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Distribution shift widely exists in medical images acquired from different
medical centres and poses a significant obstacle to deploying the pre-trained
semantic segmentation model in real-world applications. Test-time adaptation
has proven its effectiveness in tackling the cross-domain distribution shift
during inference. However, most existing methods achieve adaptation by updating
the pre-trained models, rendering them susceptible to error accumulation and
catastrophic forgetting when encountering a series of distribution shifts
(i.e., under the continual test-time adaptation setup). To overcome these
challenges caused by updating the models, in this paper, we freeze the
pre-trained model and propose the Visual Prompt-based Test-Time Adaptation
(VPTTA) method to train a specific prompt for each test image to align the
statistics in the batch normalization layers. Specifically, we present the
low-frequency prompt, which is lightweight with only a few parameters and can
be effectively trained in a single iteration. To enhance prompt initialization,
we equip VPTTA with a memory bank to benefit the current prompt from previous
ones. Additionally, we design a warm-up mechanism, which mixes source and
target statistics to construct warm-up statistics, thereby facilitating the
training process. Extensive experiments demonstrate the superiority of our
VPTTA over other state-of-the-art methods on two medical image segmentation
benchmark tasks. The code and weights of pre-trained source models are
available at https://github.com/Chen-Ziyang/VPTTA.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18364" title="Abstract">arXiv:2311.18364</a> [<a href="/pdf/2311.18364" title="Download PDF">pdf</a>, <a href="/format/2311.18364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hubness Reduction Improves Sentence-BERT Semantic Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+B+M+G">Beatrix M. G. Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+L+K">Lars Kai Hansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NLDL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Semantic representations of text, i.e. representations of natural language
which capture meaning by geometry, are essential for areas such as information
retrieval and document grouping. High-dimensional trained dense vectors have
received much attention in recent years as such representations. We investigate
the structure of semantic spaces that arise from embeddings made with
Sentence-BERT and find that the representations suffer from a well-known
problem in high dimensions called hubness. Hubness results in asymmetric
neighborhood relations, such that some texts (the hubs) are neighbours of many
other texts while most texts (so-called anti-hubs), are neighbours of few or no
other texts. We quantify the semantic quality of the embeddings using hubness
scores and error rate of a neighbourhood based classifier. We find that when
hubness is high, we can reduce error rate and hubness using hubness reduction
methods. We identify a combination of two methods as resulting in the best
reduction. For example, on one of the tested pretrained models, this combined
method can reduce hubness by about 75% and error rate by about 9%. Thus, we
argue that mitigating hubness in the embedding space provides better semantic
representations of text.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18365" title="Abstract">arXiv:2311.18365</a> [<a href="/pdf/2311.18365" title="Download PDF">pdf</a>, <a href="/ps/2311.18365" title="Download PostScript">ps</a>, <a href="/format/2311.18365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Dynamic Algorithms for Euclidean Steiner Tree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+T+H">T-H. Hubert Chan</a>, 
<a href="/search/cs?searchtype=author&query=Goranci%2C+G">Gramoz Goranci</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S+H+-">Shaofeng H.-C. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Q">Quan Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The Euclidean Steiner tree problem asks to find a min-cost metric graph that
connects a given set of \emph{terminal} points $X$ in $\mathbb{R}^d$, possibly
using points not in $X$ which are called Steiner points. Even though
near-linear time $(1 + \epsilon)$-approximation was obtained in the offline
setting in seminal works of Arora and Mitchell, efficient dynamic algorithms
for Steiner tree is still open. We give the first algorithm that (implicitly)
maintains a $(1 + \epsilon)$-approximate solution which is accessed via a set
of tree traversal queries, subject to point insertion and deletions, with
amortized update and query time $O(\poly\log n)$ with high probability. Our
approach is based on an Arora-style geometric dynamic programming, and our main
technical contribution is to maintain the DP subproblems in the dynamic setting
efficiently. We also need to augment the DP subproblems to support the tree
traversal queries.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18368" title="Abstract">arXiv:2311.18368</a> [<a href="/pdf/2311.18368" title="Download PDF">pdf</a>, <a href="/ps/2311.18368" title="Download PostScript">ps</a>, <a href="/format/2311.18368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing Experience Around Component Compositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourguin%2C+G">Gr&#xe9;gory Bourguin</a> (LISIC), 
<a href="/search/cs?searchtype=author&query=Lewandowski%2C+A">Arnaud Lewandowski</a> (LISIC), 
<a href="/search/cs?searchtype=author&query=Lewkowicz%2C+M">Myriam Lewkowicz</a> (Tech-CICO, LIST3N)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Distributed Systems and Technologies,
  2013, 4 (4), pp.15-28
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Society currently lives in a world of tailorable systems in which end-users
are able to transform their working environment while achieving their tasks,
day to day and over the time. Tailorability is most of the time achieved
through dynamic component integration thanks to a huge number of components
available over the Internet. In this context, the main problem for users is not
anymore the integration of new components, but how to find the most interesting
set of components that will fulfill their needs. Facing this issue, the
authors' assumption is that it would be helpful for users to take benefit of
the experience of other users and our work aims at enhancing current software
ecosystems to support this sharing of experience. The authors have applied this
approach in the context of software development while considering Eclipse as
one of the most advanced and used software ecosystem. The authors then offer
ShareXP, an Eclipse feature that allows members of a group to share their
expertise, this expertise being embodied in the ``compositions'' each of them
has built. ShareXP was already presented in (Bourguin et al., 2012). The
current paper is an extension where the authors deeper show that ShareXP is
only a first step in their global approach trying to enhance not only the
Eclipse ecosystem, but software ecosystems in general.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18373" title="Abstract">arXiv:2311.18373</a> [<a href="/pdf/2311.18373" title="Download PDF">pdf</a>, <a href="/format/2311.18373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Deep Learning for Polyp Segmentation: Techniques, Challenges  and Future Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jiaxin Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, and
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Early detection and assessment of polyps play a crucial role in the
prevention and treatment of colorectal cancer (CRC). Polyp segmentation
provides an effective solution to assist clinicians in accurately locating and
segmenting polyp regions. In the past, people often relied on manually
extracted lower-level features such as color, texture, and shape, which often
had issues capturing global context and lacked robustness to complex scenarios.
With the advent of deep learning, more and more outstanding medical image
segmentation algorithms based on deep learning networks have emerged, making
significant progress in this field. This paper provides a comprehensive review
of polyp segmentation algorithms. We first review some traditional algorithms
based on manually extracted features and deep segmentation algorithms, then
detail benchmark datasets related to the topic. Specifically, we carry out a
comprehensive evaluation of recent deep learning models and results based on
polyp sizes, considering the pain points of research topics and differences in
network structures. Finally, we discuss the challenges of polyp segmentation
and future trends in this field. The models, benchmark datasets, and source
code links we collected are all published at
https://github.com/taozh2017/Awesome-Polyp-Segmentation.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18387" title="Abstract">arXiv:2311.18387</a> [<a href="/pdf/2311.18387" title="Download PDF">pdf</a>, <a href="/format/2311.18387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Exact Inversion of DPM-Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Seongmin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyeonghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S+Y">Suh Yoon Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Hyewon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S+Y">Se Young Chun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion probabilistic models (DPMs) are a key component in modern
generative models. DPM-solvers have achieved reduced latency and enhanced
quality significantly, but have posed challenges to find the exact inverse
(i.e., finding the initial noise from the given image). Here we investigate the
exact inversions for DPM-solvers and propose algorithms to perform them when
samples are generated by the first-order as well as higher-order DPM-solvers.
For each explicit denoising step in DPM-solvers, we formulated the inversions
using implicit methods such as gradient descent or forward step method to
ensure the robustness to large classifier-free guidance unlike the prior
approach using fixed-point iteration. Experimental results demonstrated that
our proposed exact inversion methods significantly reduced the error of both
image and noise reconstructions, greatly enhanced the ability to distinguish
invisible watermarks and well prevented unintended background changes
consistently during image editing. Project page:
\url{https://smhongok.github.io/inv-dpm.html}.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18388" title="Abstract">arXiv:2311.18388</a> [<a href="/pdf/2311.18388" title="Download PDF">pdf</a>, <a href="/format/2311.18388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Lyapunov conditions for k-contraction: analysis and feedback  design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cecilia%2C+A">Andreu Cecilia</a> (UPC), 
<a href="/search/eess?searchtype=author&query=Zoboli%2C+S">Samuele Zoboli</a> (LAAS), 
<a href="/search/eess?searchtype=author&query=Astolfi%2C+D">Daniele Astolfi</a> (LAGEPP), 
<a href="/search/eess?searchtype=author&query=Serres%2C+U">Ulysse Serres</a> (LAGEPP), 
<a href="/search/eess?searchtype=author&query=Andrieu%2C+V">Vincent Andrieu</a> (LAGEPP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">Recently, the concept of k-contraction has been introduced as a promising
generalization of contraction for dynamical systems. However, the study of
k-contraction properties has faced significant challenges due to the reliance
on complex mathematical objects called matrix compounds. As a result, related
control design methodologies have yet to appear in the literature. In this
paper, we overcome existing limitations and propose new sufficient conditions
for k-contraction which do not rely on matrix compounds. Our design-oriented
conditions stem from a strong geometrical interpretation and establish a
connection between kcontraction and p-dominance. Notably, these conditions are
also necessary in the linear time-invariant framework. Leveraging on these
findings, we propose a feedback design methodology for both the linear and the
nonlinear scenarios.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18390" title="Abstract">arXiv:2311.18390</a> [<a href="/pdf/2311.18390" title="Download PDF">pdf</a>, <a href="/ps/2311.18390" title="Download PostScript">ps</a>, <a href="/format/2311.18390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Cross Z-Complementary Set and Its Application in Generalized  Spatial Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen-Ming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+C">Cheng-Yu Pai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao-Yu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Generalized spatial modulation (GSM) is a novel multiple-antenna technique
offering flexibility among spectral efficiency, energy efficiency, and the cost
of RF chains. In this paper, a novel class of sequence sets, called enhanced
cross Zcomplementary set (E-CZCS), is proposed for efficient training sequence
design in broadband GSM systems. Specifically, an E-CZCS consists of multiple
CZCSs possessing front-end and tail-end zero-correlation zones (ZCZs), whereby
any two distinct CZCSs have a tail-end ZCZ when a novel type of cross-channel
aperiodic correlation sums is considered. The theoretical upper bound on the
ZCZ width is first derived, upon which optimal E-CZCSs with flexible parameters
are constructed. For optimal channel estimation over frequency-selective
channels, we introduce and evaluate a novel GSM training framework employing
the proposed E-CZCSs.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18393" title="Abstract">arXiv:2311.18393</a> [<a href="/pdf/2311.18393" title="Download PDF">pdf</a>, <a href="/format/2311.18393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-efficient Deep Reinforcement Learning for Vehicle Trajectory  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frauenknecht%2C+B">Bernd Frauenknecht</a>, 
<a href="/search/cs?searchtype=author&query=Ehlgen%2C+T">Tobias Ehlgen</a>, 
<a href="/search/cs?searchtype=author&query=Trimpe%2C+S">Sebastian Trimpe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Advanced vehicle control is a fundamental building block in the development
of autonomous driving systems. Reinforcement learning (RL) promises to achieve
control performance superior to classical approaches while keeping
computational demands low during deployment. However, standard RL approaches
like soft-actor critic (SAC) require extensive amounts of training data to be
collected and are thus impractical for real-world application. To address this
issue, we apply recently developed data-efficient deep RL methods to vehicle
trajectory control. Our investigation focuses on three methods, so far
unexplored for vehicle control: randomized ensemble double Q-learning (REDQ),
probabilistic ensembles with trajectory sampling and model predictive path
integral optimizer (PETS-MPPI), and model-based policy optimization (MBPO). We
find that in the case of trajectory control, the standard model-based RL
formulation used in approaches like PETS-MPPI and MBPO is not suitable. We,
therefore, propose a new formulation that splits dynamics prediction and
vehicle localization. Our benchmark study on the CARLA simulator reveals that
the three identified data-efficient deep RL approaches learn control strategies
on a par with or better than SAC, yet reduce the required number of environment
interactions by more than one order of magnitude.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18394" title="Abstract">arXiv:2311.18394</a> [<a href="/pdf/2311.18394" title="Download PDF">pdf</a>, <a href="/format/2311.18394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HMAS: enabling seamless collaboration between drones, quadruped robots,  and human operators with efficient spatial awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saint-Jore%2C+A">Amaury Saint-Jore</a> (SIMBIOT), 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Ye-Qiong Song</a> (SIMBIOT), 
<a href="/search/cs?searchtype=author&query=Ciarletta%2C+L">Laurent Ciarletta</a> (SIMBIOT)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE 21th International Conference on Embedded and Ubiquitous
  Computing (EUC), Nov 2023, Exeter, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Heterogeneous robots equipped with multi-modal sensors (e.g., UAV, wheeled
and legged terrestrial robots) provide rich and complementary functions that
may help human operators to accomplish complex tasks in unknown environments.
However, seamlessly integrating heterogeneous agents and making them interact
and collaborate still arise challenging issues. In this paper, we define a ROS
2 based software architecture that allows to build incarnated heterogeneous
multi-agent systems (HMAS) in a generic way. We showcase its effectiveness
through a scenario integrating aerial drones, quadruped robots, and human
operators (see https://youtu.be/iOtCCticGuk). In addition, agent spatial
awareness in unknown outdoor environments is a critical step for realizing
autonomous individual movements, interactions, and collaborations. Through
intensive experimental measurements, RTK-GPS is shown to be a suitable solution
for achieving the required locating accuracy.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18397" title="Abstract">arXiv:2311.18397</a> [<a href="/pdf/2311.18397" title="Download PDF">pdf</a>, <a href="/format/2311.18397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IAG: Induction-Augmented Generation Framework for Answering Reasoning  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhebin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuanhang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Saijiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Meng Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongkang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Ruofei Lai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieval-Augmented Generation (RAG), by incorporating external knowledge
with parametric memory of language models, has become the state-of-the-art
architecture for open-domain QA tasks. However, common knowledge bases are
inherently constrained by limited coverage and noisy information, making
retrieval-based approaches inadequate to answer implicit reasoning questions.
In this paper, we propose an Induction-Augmented Generation (IAG) framework
that utilizes inductive knowledge along with the retrieved documents for
implicit reasoning. We leverage large language models (LLMs) for deriving such
knowledge via a novel prompting method based on inductive reasoning patterns.
On top of this, we implement two versions of IAG named IAG-GPT and IAG-Student,
respectively. IAG-GPT directly utilizes the knowledge generated by GPT-3 for
answer prediction, while IAG-Student gets rid of dependencies on GPT service at
inference time by incorporating a student inductor model. The inductor is
firstly trained via knowledge distillation and further optimized by
back-propagating the generator feedback via differentiable beam scores.
Experimental results show that IAG outperforms RAG baselines as well as ChatGPT
on two Open-Domain QA tasks. Notably, our best models have won the first place
in the official leaderboards of CSQA2.0 (since Nov 1, 2022) and StrategyQA
(since Jan 8, 2023).
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18398" title="Abstract">arXiv:2311.18398</a> [<a href="/pdf/2311.18398" title="Download PDF">pdf</a>, <a href="/format/2311.18398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RainAI -- Precipitation Nowcasting from Satellite Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarabia%2C+R+P">Rafael Pablos Sarabia</a>, 
<a href="/search/cs?searchtype=author&query=Nyborg%2C+J">Joachim Nyborg</a>, 
<a href="/search/cs?searchtype=author&query=Birk%2C+M">Morten Birk</a>, 
<a href="/search/cs?searchtype=author&query=Assent%2C+I">Ira Assent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">This paper presents a solution to the Weather4Cast 2023 competition, where
the goal is to forecast high-resolution precipitation with an 8-hour lead time
using lower-resolution satellite radiance images. We propose a simple, yet
effective method for spatiotemporal feature learning using a 2D U-Net model,
that outperforms the official 3D U-Net baseline in both performance and
efficiency. We place emphasis on refining the dataset, through importance
sampling and dataset preparation, and show that such techniques have a
significant impact on performance. We further study an alternative
cross-entropy loss function that improves performance over the standard mean
squared error loss, while also enabling models to produce probabilistic
outputs. Additional techniques are explored regarding the generation of
predictions at different lead times, specifically through Conditioning Lead
Time. Lastly, to generate high-resolution forecasts, we evaluate standard and
learned upsampling methods. The code and trained parameters are available at
https://github.com/rafapablos/w4c23-rainai.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18402" title="Abstract">arXiv:2311.18402</a> [<a href="/pdf/2311.18402" title="Download PDF">pdf</a>, <a href="/format/2311.18402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MV-CLIP: Multi-View CLIP for Zero-shot 3D Shape Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dan Song</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale pre-trained models have demonstrated impressive performance in
vision and language tasks within open-world scenarios. Due to the lack of
comparable pre-trained models for 3D shapes, recent methods utilize
language-image pre-training to realize zero-shot 3D shape recognition. However,
due to the modality gap, pretrained language-image models are not confident
enough in the generalization to 3D shape recognition. Consequently, this paper
aims to improve the confidence with view selection and hierarchical prompts.
Leveraging the CLIP model as an example, we employ view selection on the vision
side by identifying views with high prediction confidence from multiple
rendered views of a 3D shape. On the textual side, the strategy of hierarchical
prompts is proposed for the first time. The first layer prompts several
classification candidates with traditional class-level descriptions, while the
second layer refines the prediction based on function-level descriptions or
further distinctions between the candidates. Remarkably, without the need for
additional training, our proposed method achieves impressive zero-shot 3D
classification accuracies of 84.44\%, 91.51\%, and 66.17\% on ModelNet40,
ModelNet10, and ShapeNet Core55, respectively. Furthermore, we will make the
code publicly available to facilitate reproducibility and further research in
this area.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18403" title="Abstract">arXiv:2311.18403</a> [<a href="/pdf/2311.18403" title="Download PDF">pdf</a>, <a href="/format/2311.18403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image  Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengshan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhifei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unlearnable datasets lead to a drastic drop in the generalization performance
of models trained on them by introducing elaborate and imperceptible
perturbations into clean training sets. Many existing defenses, e.g., JPEG
compression and adversarial training, effectively counter UDs based on
norm-constrained additive noise. However, a fire-new type of convolution-based
UDs have been proposed and render existing defenses all ineffective, presenting
a greater challenge to defenders. To address this, we express the
convolution-based unlearnable sample as the result of multiplying a matrix by a
clean sample in a simplified scenario, and formalize the intra-class matrix
inconsistency as $\Theta_{imi}$, inter-class matrix consistency as
$\Theta_{imc}$ to investigate the working mechanism of the convolution-based
UDs. We conjecture that increasing both of these metrics will mitigate the
unlearnability effect. Through validation experiments that commendably support
our hypothesis, we further design a random matrix to boost both $\Theta_{imi}$
and $\Theta_{imc}$, achieving a notable degree of defense effect. Hence, by
building upon and extending these facts, we first propose a brand-new image
COrruption that employs randomly multiplicative transformation via
INterpolation operation to successfully defend against convolution-based UDs.
Our approach leverages global pixel random interpolations, effectively
suppressing the impact of multiplicative noise in convolution-based UDs.
Additionally, we have also designed two new forms of convolution-based UDs, and
find that our defense is the most effective against them.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18405" title="Abstract">arXiv:2311.18405</a> [<a href="/pdf/2311.18405" title="Download PDF">pdf</a>, <a href="/format/2311.18405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jianhao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dan Song</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hongshuo Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tongtong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-based virtual try-on enables users to virtually try on different
garments by altering original clothes in their photographs. Generative
Adversarial Networks (GANs) dominate the research field in image-based virtual
try-on, but have not resolved problems such as unnatural deformation of
garments and the blurry generation quality. Recently, diffusion models have
emerged with surprising performance across various image generation tasks.
While the generative quality of diffusion models is impressive, achieving
controllability poses a significant challenge when applying it to virtual
try-on tasks and multiple denoising iterations limit its potential for
real-time applications. In this paper, we propose Controllable Accelerated
virtual Try-on with Diffusion Model called CAT-DM. To enhance the
controllability, a basic diffusion-based virtual try-on network is designed,
which utilizes ControlNet to introduce additional control conditions and
improves the feature extraction of garment images. In terms of acceleration,
CAT-DM initiates a reverse denoising process with an implicit distribution
generated by a pre-trained GAN-based model. Compared with previous try-on
methods based on diffusion models, CAT-DM not only retains the pattern and
texture details of the in-shop garment but also reduces the sampling steps
without compromising generation quality. Extensive experiments demonstrate the
superiority of CAT-DM against both GAN-based and diffusion-based methods in
producing more realistic images and accurately reproducing garment patterns.
Our code and models will be publicly released.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18406" title="Abstract">arXiv:2311.18406</a> [<a href="/pdf/2311.18406" title="Download PDF">pdf</a>, <a href="/format/2311.18406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenMORE: an open-source tool for sampling-based path replanning in ROS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonola%2C+C">Cesare Tonola</a>, 
<a href="/search/cs?searchtype=author&query=Beschi%2C+M">Manuel Beschi</a>, 
<a href="/search/cs?searchtype=author&query=Faroni%2C+M">Marco Faroni</a>, 
<a href="/search/cs?searchtype=author&query=Pedrocchi%2C+N">Nicola Pedrocchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE ETFA 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE 28th International Conference on Emerging Technologies and
  Factory Automation (ETFA), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the spread of robots in unstructured, dynamic environments, the topic of
path replanning has gained importance in the robotics community. Although the
number of replanning strategies has significantly increased, there is a lack of
agreed-upon libraries and tools, making the use, development, and benchmarking
of new algorithms arduous. This paper introduces OpenMORE, a new open-source
ROS-based C++ library for sampling-based path replanning algorithms. The
library builds a framework that allows for continuous replanning and collision
checking of the traversed path during the execution of the robot trajectory.
Users can solve replanning tasks exploiting the already available algorithms
and can easily integrate new ones, leveraging the library to manage the entire
execution.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18418" title="Abstract">arXiv:2311.18418</a> [<a href="/pdf/2311.18418" title="Download PDF">pdf</a>, <a href="/ps/2311.18418" title="Download PostScript">ps</a>, <a href="/format/2311.18418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming Design for Active RIS-Aided Over-the-Air Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Over-the-air computation (AirComp) is emerging as a promising technology for
wireless data aggregation. However, its performance is hampered by users with
poor channel conditions. To mitigate such a performance bottleneck, this paper
introduces an active reconfigurable intelligence surface (RIS) into the AirComp
system. Specifically, we begin by exploring the ideal RIS model and propose a
joint optimization of the transceiver design and RIS configuration to minimize
the mean squared error (MSE) between the target and estimated function values.
To manage the resultant tri-convex optimization problem, we employ the
alternating optimization (AO) technique to decompose it into three convex
subproblems, each solvable optimally. Subsequently, we investigate two specific
cases and analyze their respective asymptotic performance to reveal the
superiority of the active RIS in mitigating the MSE relative to its passive
counterpart. Lastly, we adapt our transceiver and RIS configuration design to
account for the self-interference of the active RIS. To handle the resultant
highly non-convex problem, we further devise a two-layer AO framework.
Simulation results demonstrate the superiority of the active RIS in enhancing
AirComp performance compared to its passive counterpart.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18420" title="Abstract">arXiv:2311.18420</a> [<a href="/pdf/2311.18420" title="Download PDF">pdf</a>, <a href="/format/2311.18420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeG-DG: Textually Guided Domain Generalization for Face Anti-Spoofing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+L">Lianrui Mu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jianhong Bai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiangnan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaoyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jiedong Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haoji Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Enhancing the domain generalization performance of Face Anti-Spoofing (FAS)
techniques has emerged as a research focus. Existing methods are dedicated to
extracting domain-invariant features from various training domains. Despite the
promising performance, the extracted features inevitably contain residual style
feature bias (e.g., illumination, capture device), resulting in inferior
generalization performance. In this paper, we propose an alternative and
effective solution, the Textually Guided Domain Generalization (TeG-DG)
framework, which can effectively leverage text information for cross-domain
alignment. Our core insight is that text, as a more abstract and universal form
of expression, can capture the commonalities and essential characteristics
across various attacks, bridging the gap between different image domains.
Contrary to existing vision-language models, the proposed framework is
elaborately designed to enhance the domain generalization ability of the FAS
task. Concretely, we first design a Hierarchical Attention Fusion (HAF) module
to enable adaptive aggregation of visual features at different levels; Then, a
Textual-Enhanced Visual Discriminator (TEVD) is proposed for not only better
alignment between the two modalities but also to regularize the classifier with
unbiased text features. TeG-DG significantly outperforms previous approaches,
especially in situations with extremely limited source domain data (~14% and
~12% improvements on HTER and AUC respectively), showcasing impressive few-shot
performance.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18424" title="Abstract">arXiv:2311.18424</a> [<a href="/pdf/2311.18424" title="Download PDF">pdf</a>, <a href="/ps/2311.18424" title="Download PostScript">ps</a>, <a href="/format/2311.18424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Disciplinary Data Work Practices in Artificial Intelligence  Research: a Healthcare Case Study in the UK
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henkin%2C+R">Rafael Henkin</a>, 
<a href="/search/cs?searchtype=author&query=Remfry%2C+E">Elizabeth Remfry</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+D+J">Duncan J. Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Clinch%2C+M">Megan Clinch</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+M+R">Michael R. Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Developing artificial intelligence (AI) tools for healthcare is a multiple
disciplinary effort, bringing data scientists, clinicians, patients and other
disciplines together. In this paper, we explore the AI development workflow and
how participants navigate the challenges and tensions of sharing and generating
knowledge across disciplines. Through an inductive thematic analysis of 13
semi-structured interviews with participants in a large research consortia, our
findings suggest that multiple disciplinarity heavily impacts work practices.
Participants faced challenges to learn the languages of other disciplines and
needed to adapt the tools used for sharing and communicating with their
audience, particularly those from a clinical or patient perspective. Large
health datasets also posed certain restrictions on work practices. We
identified meetings as a key platform for facilitating exchanges between
disciplines and allowing for the blending and creation of knowledge. Finally,
we discuss design implications for data science and collaborative tools, and
recommendations for future research.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18425" title="Abstract">arXiv:2311.18425</a> [<a href="/pdf/2311.18425" title="Download PDF">pdf</a>, <a href="/ps/2311.18425" title="Download PostScript">ps</a>, <a href="/format/2311.18425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the (In)approximability of Combinatorial Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ezra%2C+T">Tomer Ezra</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+M">Michal Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Schlesinger%2C+M">Maya Schlesinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study two combinatorial contract design models -- multi-agent and
multi-action -- where a principal delegates the execution of a costly project
to others. In both settings, the principal cannot observe the choices of the
agent(s), only the project's outcome (success or failure), and incentivizes the
agent(s) using a contract, which is a payment scheme that specifies the payment
to the agent(s) upon a project's success.
<br />In the multi-agent setting, the project is delegated to a team of agents, and
every agent chooses whether or not to exert effort. A success probability
function specifies the probability of success for every subset of agents
exerting effort. For the family of submodular success probability functions,
Duetting et al. [2023] established a poly-time constant-factor approximation to
the optimal contract, and left open whether this problem admits a PTAS. We show
that no poly-time algorithm guarantees a better than $0.7$-approximation to the
optimal contract. For XOS functions, Duetting et al. [2023] give a poly-time
constant approximation with value and demand queries. We show that with value
queries only, one cannot get any constant approximation.
<br />In the multi-action setting, the project is delegated to a single agent, who
can take any subset of a given set of actions. Here, a success probability
function specifies the probability of success for any subset of actions.
Duetting et al. [2021a] devised a poly-time algorithm for computing an optimal
contract for gross substitutes success probability functions, and established
NP-hardness with respect to submodular functions. We further strengthen this
hardness result by showing that this problem does not admit any constant
approximation either. For the broader class of XOS functions, we establish the
hardness of obtaining a $n^{-1/2+\varepsilon}$-approximation for any
$\varepsilon &gt; 0$.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18430" title="Abstract">arXiv:2311.18430</a> [<a href="/pdf/2311.18430" title="Download PDF">pdf</a>, <a href="/format/2311.18430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicular Cooperative Maneuvers -- Quo Vaditis?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%A4fner%2C+B">Bernhard H&#xe4;fner</a>, 
<a href="/search/cs?searchtype=author&query=Ott%2C+J">J&#xf6;rg Ott</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+G+A">Georg Albrecht Schmitt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages incl. references and author biographies, 4 figures incl. multiple sub-figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Vehicles will not only get more and more automated, but they will also
cooperate in new ways. Currently, human-driven vehicles begin to communicate
with each other using vehicle-to-everything technology. Future vehicles will
use communication to share sensor data and even negotiate cooperative
maneuvers. This lets them learn more about the environment and improves traffic
flow and passenger comfort as more predictable maneuvers are likely to lead to
a smoother ride. This paper introduces the most important concepts around
cooperative vehicular maneuvers. We also summarize currently open challenges
and questions to answer before a deployment can begin. Afterward, we give some
perspectives on the further evolution of cooperative maneuvers and beyond.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18432" title="Abstract">arXiv:2311.18432</a> [<a href="/pdf/2311.18432" title="Download PDF">pdf</a>, <a href="/ps/2311.18432" title="Download PostScript">ps</a>, <a href="/format/2311.18432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three classes of new optimal cyclic $(r,&#x3b4;)$ locally recoverable  codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaozong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dabin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">An $(r, \delta)$-locally repairable code ($(r, \delta)$-LRC for short) was
introduced by Prakash et al. for tolerating multiple failed nodes in
distributed storage systems, and has garnered significant interest among
researchers. An $(r,\delta)$-LRC is called an optimal code if its parameters
achieve the Singleton-like bound. In this paper, we construct three classes of
$q$-ary optimal cyclic $(r,\delta)$-LRCs with new parameters by investigating
the defining sets of cyclic codes. Our results generalize the related work of
\cite{Chen2022,Qian2020}, and the obtained optimal cyclic $(r, \delta)$-LRCs
have flexible parameters. A lot of numerical examples of optimal cyclic $(r,
\delta)$-LRCs are given to show that our constructions are capable of
generating new optimal cyclic $(r, \delta)$-LRCs.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18433" title="Abstract">arXiv:2311.18433</a> [<a href="/pdf/2311.18433" title="Download PDF">pdf</a>, <a href="/format/2311.18433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2PNet: Event to Point Cloud Registration with Spatio-Temporal  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiuhong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Changjie Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Siqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yu Zang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+X">Xuesheng Bian</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Matthias M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, accepted by Thirty-seventh Conference on Neural Information Processing Systems(NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras have emerged as a promising vision sensor in recent years due
to their unparalleled temporal resolution and dynamic range. While registration
of 2D RGB images to 3D point clouds is a long-standing problem in computer
vision, no prior work studies 2D-3D registration for event cameras. To this
end, we propose E2PNet, the first learning-based method for event-to-point
cloud registration. The core of E2PNet is a novel feature representation
network called Event-Points-to-Tensor (EP2T), which encodes event data into a
2D grid-shaped feature tensor. This grid-shaped feature enables matured
RGB-based frameworks to be easily used for event-to-point cloud registration,
without changing hyper-parameters and the training procedure. EP2T treats the
event input as spatio-temporal point clouds. Unlike standard 3D learning
architectures that treat all dimensions of point clouds equally, the novel
sampling and information aggregation modules in EP2T are designed to handle the
inhomogeneity of the spatial and temporal dimensions. Experiments on the MVSEC
and VECtor datasets demonstrate the superiority of E2PNet over hand-crafted and
other learning-based methods. Compared to RGB-based registration, E2PNet is
more robust to extreme illumination or fast motion due to the use of event
data. Beyond 2D-3D registration, we also show the potential of EP2T for other
vision tasks such as flow estimation, event-to-image reconstruction and object
recognition. The source code can be found at:
https://github.com/Xmu-qcj/E2PNet.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18434" title="Abstract">arXiv:2311.18434</a> [<a href="/pdf/2311.18434" title="Download PDF">pdf</a>, <a href="/format/2311.18434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Temperature-Dependent Phase Transition in Modern Hopfield  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koulischer%2C+F">Felix Koulischer</a>, 
<a href="/search/cs?searchtype=author&query=Goemaere%2C+C">C&#xe9;dric Goemaere</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Meersch%2C+T">Tom van der Meersch</a>, 
<a href="/search/cs?searchtype=author&query=Deleu%2C+J">Johannes Deleu</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as poster for Associative Memory and Hopfield Networks workshop at NeurIPS23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
<p class="mathjax">The recent discovery of a connection between Transformers and Modern Hopfield
Networks (MHNs) has reignited the study of neural networks from a physical
energy-based perspective. This paper focuses on the pivotal effect of the
inverse temperature hyperparameter $\beta$ on the distribution of energy minima
of the MHN. To achieve this, the distribution of energy minima is tracked in a
simplified MHN in which equidistant normalised patterns are stored. This
network demonstrates a phase transition at a critical temperature
$\beta_{\text{c}}$, from a single global attractor towards highly pattern
specific minima as $\beta$ is increased. Importantly, the dynamics are not
solely governed by the hyperparameter $\beta$ but are instead determined by an
effective inverse temperature $\beta_{\text{eff}}$ which also depends on the
distribution and size of the stored patterns. Recognizing the role of
hyperparameters in the MHN could, in the future, aid researchers in the domain
of Transformers to optimise their initial choices, potentially reducing the
necessity for time and energy expensive hyperparameter fine-tuning.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18435" title="Abstract">arXiv:2311.18435</a> [<a href="/pdf/2311.18435" title="Download PDF">pdf</a>, <a href="/format/2311.18435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layered Rendering Diffusion Model for Zero-Shot Guided Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zipeng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guoxi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zebin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lufei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+E">Errui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces innovative solutions to enhance spatial controllability
in diffusion models reliant on text queries. We present two key innovations:
Vision Guidance and the Layered Rendering Diffusion (LRDiff) framework. Vision
Guidance, a spatial layout condition, acts as a clue in the perturbed
distribution, greatly narrowing down the search space, to focus on the image
sampling process adhering to the spatial layout condition. The LRDiff framework
constructs an image-rendering process with multiple layers, each of which
applies the vision guidance to instructively estimate the denoising direction
for a single object. Such a layered rendering strategy effectively prevents
issues like unintended conceptual blending or mismatches, while allowing for
more coherent and contextually accurate image synthesis. The proposed method
provides a more efficient and accurate means of synthesising images that align
with specific spatial and contextual requirements. We demonstrate through our
experiments that our method provides better results than existing techniques
both quantitatively and qualitatively. We apply our method to three practical
applications: bounding box-to-image, semantic mask-to-image and image editing.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18436" title="Abstract">arXiv:2311.18436</a> [<a href="/pdf/2311.18436" title="Download PDF">pdf</a>, <a href="/ps/2311.18436" title="Download PostScript">ps</a>, <a href="/format/2311.18436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Visual Features in Text-Based CAPTCHAs: An fNIRS Study for  Usable Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mulazimoglu%2C+E">Emre Mulazimoglu</a>, 
<a href="/search/cs?searchtype=author&query=Cakir%2C+M+P">Murat P. Cakir</a>, 
<a href="/search/cs?searchtype=author&query=Acarturk%2C+C">Cengiz Acarturk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 32 figures, Computational Intelligence and Neuroscience
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computational Intelligence and Neuroscience, Volume 2021, Article
  ID 8842420
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">To mitigate dictionary attacks or similar undesirable automated attacks to
information systems, developers mostly prefer using CAPTCHA challenges as Human
Interactive Proofs (HIPs) to distinguish between human users and scripts.
Appropriate use of CAPTCHA requires a setup that balances between robustness
and usability during the design of a challenge. The previous research reveals
that most usability studies have used accuracy and response time as measurement
criteria for quantitative analysis. The present study aims at applying optical
neuroimaging techniques for the analysis of CAPTCHA design. The functional
Near-Infrared Spectroscopy technique was used to explore the hemodynamic
responses in the prefrontal cortex elicited by CAPTCHA stimulus of varying
types. )e findings suggest that regions in the left and right dorsolateral and
right dorsomedial prefrontal cortex respond to the degrees of line occlusion,
rotation, and wave distortions present in a CAPTCHA. The systematic addition of
the visual effects introduced nonlinear effects on the behavioral and
prefrontal oxygenation measures, indicative of the emergence of Gestalt effects
that might have influenced the perception of the overall CAPTCHA figure.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18437" title="Abstract">arXiv:2311.18437</a> [<a href="/pdf/2311.18437" title="Download PDF">pdf</a>, <a href="/format/2311.18437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sliding Regret in Stochastic Bandits: Discriminating Index and  Randomized Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boone%2C+V">Victor Boone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper studies the one-shot behavior of no-regret algorithms for
stochastic bandits. Although many algorithms are known to be asymptotically
optimal with respect to the expected regret, over a single run, their
pseudo-regret seems to follow one of two tendencies: it is either smooth or
bumpy. To measure this tendency, we introduce a new notion: the sliding regret,
that measures the worst pseudo-regret over a time-window of fixed length
sliding to infinity. We show that randomized methods (e.g. Thompson Sampling
and MED) have optimal sliding regret, while index policies, although possibly
asymptotically optimal for the expected regret, have the worst possible sliding
regret under regularity conditions on their index (e.g. UCB, UCB-V, KL-UCB,
MOSS, IMED etc.). We further analyze the average bumpiness of the pseudo-regret
of index policies via the regret of exploration, that we show to be suboptimal
as well.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18440" title="Abstract">arXiv:2311.18440</a> [<a href="/pdf/2311.18440" title="Download PDF">pdf</a>, <a href="/format/2311.18440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Agents in Software Development: A Vision Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+Z">Zeeshan Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Waseem%2C+M">Muhammad Waseem</a>, 
<a href="/search/cs?searchtype=author&query=Kemell%2C+K">Kai-Kristian Kemell</a>, 
<a href="/search/cs?searchtype=author&query=Xiaofeng%2C+W">Wang Xiaofeng</a>, 
<a href="/search/cs?searchtype=author&query=Duc%2C+A+N">Anh Nguyen Duc</a>, 
<a href="/search/cs?searchtype=author&query=Syst%C3%A4%2C+K">Kari Syst&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=Abrahamsson%2C+P">Pekka Abrahamsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLM) and Generative Pre-trained Transformers (GPT),
are reshaping the field of Software Engineering (SE). They enable innovative
methods for executing many software engineering tasks, including automated code
generation, debugging, maintenance, etc. However, only a limited number of
existing works have thoroughly explored the potential of GPT agents in SE. This
vision paper inquires about the role of GPT-based agents in SE. Our vision is
to leverage the capabilities of multiple GPT agents to contribute to SE tasks
and to propose an initial road map for future work. We argue that multiple GPT
agents can perform creative and demanding tasks far beyond coding and
debugging. GPT agents can also do project planning, requirements engineering,
and software design. These can be done through high-level descriptions given by
the human developer. We have shown in our initial experimental analysis for
simple software (e.g., Snake Game, Tic-Tac-Toe, Notepad) that multiple GPT
agents can produce high-quality code and document it carefully. We argue that
it shows a promise of unforeseen efficiency and will dramatically reduce
lead-times. To this end, we intend to expand our efforts to understand how we
can scale these autonomous capabilities further.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18444" title="Abstract">arXiv:2311.18444</a> [<a href="/pdf/2311.18444" title="Download PDF">pdf</a>, <a href="/ps/2311.18444" title="Download PostScript">ps</a>, <a href="/format/2311.18444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Medical Education through the cINnAMON Web Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marin%2C+I">Iuliana Marin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 16th annual International Conference of Education, Research and
  Innovation, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The cINnAMON EUREKA Traditional project endeavours to revolutionize indoor
lighting positioning and monitoring through the integration of intelligent
devices and advanced sensor technologies. This article presents the prototypes
developed for various project components and explores their potential
application in medical education, particularly for aspiring healthcare
professionals. The current variant of the intelligent bulb prototype offers a
comparative analysis of the project's bulb against commercially available smart
bulbs, shedding light on its superior efficiency and capabilities. Furthermore,
the initial smart bracelet prototype showcases its ability to collect and
analyse data from an array of built-in sensors, empowering medical students to
evaluate fragility levels based on accelerometer, gyroscope, orientation, and
heart rate data. Leveraging trilateration and optimization algorithms, the
intelligent location module enables precise monitoring of individuals'
positions within a building, enhancing medical students' understanding of
patient localization in healthcare settings. In addition, the recognition of
human activity module harnesses data from the bracelet's sensors to classify
different activities, providing medical students with invaluable insights into
patients' daily routines and mobility patterns. The user's personal profile
module facilitates seamless user registration and access to the comprehensive
services offered by the cINnAMON system, empowering medical students to collect
patient data for analysis and aiding doctors in making informed healthcare
decisions. With the telemonitoring system, medical students can remotely
monitor patients by configuring sensors in their homes, thus enabling a deeper
understanding of remote patient management.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18445" title="Abstract">arXiv:2311.18445</a> [<a href="/pdf/2311.18445" title="Download PDF">pdf</a>, <a href="/format/2311.18445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VTimeLLM: Empower LLM to Grasp Video Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zihan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown remarkable text understanding
capabilities, which have been extended as Video LLMs to handle video data for
comprehending visual details. However, existing Video LLMs can only provide a
coarse description of the entire video, failing to capture the precise start
and end time boundary of specific events. In this paper, we solve this issue
via proposing VTimeLLM, a novel Video LLM designed for fine-grained video
moment understanding and reasoning with respect to time boundary. Specifically,
our VTimeLLM adopts a boundary-aware three-stage training strategy, which
respectively utilizes image-text pairs for feature alignment, multiple-event
videos to increase temporal-boundary awareness, and high-quality
video-instruction tuning to further improve temporal understanding ability as
well as align with human intents. Extensive experiments demonstrate that in
fine-grained time-related comprehension tasks for videos such as Temporal Video
Grounding and Dense Video Captioning, VTimeLLM significantly outperforms
existing Video LLMs. Besides, benefits from the fine-grained temporal
understanding of the videos further enable VTimeLLM to beat existing Video LLMs
in video dialogue benchmark, showing its superior cross-modal understanding and
reasoning abilities.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18448" title="Abstract">arXiv:2311.18448</a> [<a href="/pdf/2311.18448" title="Download PDF">pdf</a>, <a href="/format/2311.18448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and  Objects from Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zicong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Parelli%2C+M">Maria Parelli</a>, 
<a href="/search/cs?searchtype=author&query=Kadoglou%2C+M+E">Maria Eleni Kadoglou</a>, 
<a href="/search/cs?searchtype=author&query=Kocabas%2C+M">Muhammed Kocabas</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Since humans interact with diverse objects every day, the holistic 3D capture
of these interactions is important to understand and model human behaviour.
However, most existing methods for hand-object reconstruction from RGB either
assume pre-scanned object templates or heavily rely on limited 3D hand-object
data, restricting their ability to scale and generalize to more unconstrained
interaction settings. To this end, we introduce HOLD -- the first
category-agnostic method that reconstructs an articulated hand and object
jointly from a monocular interaction video. We develop a compositional
articulated implicit model that can reconstruct disentangled 3D hand and object
from 2D images. We also further incorporate hand-object constraints to improve
hand-object poses and consequently the reconstruction quality. Our method does
not rely on 3D hand-object annotations while outperforming fully-supervised
baselines in both in-the-lab and challenging in-the-wild settings. Moreover, we
qualitatively show its robustness in reconstructing from in-the-wild videos.
Code: https://github.com/zc-alexfan/hold
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18449" title="Abstract">arXiv:2311.18449</a> [<a href="/pdf/2311.18449" title="Download PDF">pdf</a>, <a href="/format/2311.18449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Debt Management Automation: State of the Art and Future  Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biazotto%2C+J+P">Jo&#xe3;o Paulo Biazotto</a>, 
<a href="/search/cs?searchtype=author&query=Feitosa%2C+D">Daniel Feitosa</a>, 
<a href="/search/cs?searchtype=author&query=Avgeriou%2C+P">Paris Avgeriou</a>, 
<a href="/search/cs?searchtype=author&query=Nakagawa%2C+E+Y">Elisa Yumi Nakagawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Technical Debt (TD) refers to non-optimal decisions made in software projects
that may lead to short-term benefits, but potentially harm the system's
maintenance in the long-term. Technical debt management (TDM) refers to a set
of activities that are performed to handle TD, e.g., identification. These
activities can entail tasks such as code and architectural analysis, which can
be time-consuming if done manually. Thus, substantial research work has focused
on automating TDM tasks (e.g., automatic identification of code smells).
However, there is a lack of studies that summarize current approaches in TDM
automation. This can hinder practitioners in selecting optimal automation
strategies to efficiently manage TD. It can also prevent researchers from
understanding the research landscape and addressing the research problems that
matter the most. Thus, the main objective of this study is to provide an
overview of the state of the art in TDM automation, analyzing the available
tools, their use, and the challenges in automating TDM. For this, we conducted
a systematic mapping study (SMS), and from an initial set of 1086 primary
studies, 178 were selected to answer three research questions covering
different facets of TDM automation. We found 121 automation artifacts, which
were classified in 4 different types (i.e., tools, plugins, scripts, and bots);
the inputs/outputs and interfaces were also collected and reported. Finally, a
conceptual model is proposed that synthesizes the results and allows to discuss
the current state of TDM automation and related challenges. The results show
that the research community has investigated to a large extent how to perform
various TDM activities automatically, considering the number of studies and
automation artifacts we identified. More research is needed towards fully
automated TDM, specially concerning the integration of the automation
artifacts.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18450" title="Abstract">arXiv:2311.18450</a> [<a href="/pdf/2311.18450" title="Download PDF">pdf</a>, <a href="/format/2311.18450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lessons from Building CodeBuddy: A Contextualized AI Coding Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinto%2C+g">gustavo Pinto</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+C">Cleidson de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+J+B">Jo&#xe3;o Batista Neto</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+A">Alberto de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Gotto%2C+T">Tarc&#xed;sio Gotto</a>, 
<a href="/search/cs?searchtype=author&query=Monteiro%2C+E">Edward Monteiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With their exceptional natural language processing capabilities, tools based
on Large Language Models (LLMs) like ChatGPT and Co-Pilot have swiftly become
indispensable resources in the software developer's toolkit. While recent
studies suggest the potential productivity gains these tools can unlock, users
still encounter drawbacks, such as generic or incorrect answers. Additionally,
the pursuit of improved responses often leads to extensive prompt engineering
efforts, diverting valuable time from writing code that delivers actual value.
To address these challenges, a new breed of tools, built atop LLMs, is
emerging. These tools aim to mitigate drawbacks by employing techniques like
fine-tuning or enriching user prompts with contextualized information.
<br />In this paper, we delve into the lessons learned by a software development
team venturing into the creation of such a contextualized LLM-based
application, using retrieval-based techniques, called CodeBuddy. Over a
four-month period, the team, despite lacking prior professional experience in
LLM-based applications, built the product from scratch. Following the initial
product release, we engaged with the development team responsible for the code
generative components. Through interviews and analysis of the application's
issue tracker, we uncover various intriguing challenges that teams working on
LLM-based applications might encounter. For instance, we found three main group
of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By
understanding these lessons, software development teams could become better
prepared to build LLM-based applications.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18451" title="Abstract">arXiv:2311.18451</a> [<a href="/pdf/2311.18451" title="Download PDF">pdf</a>, <a href="/format/2311.18451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Much Is Hidden in the NAS Benchmarks? Few-Shot Adaptation of a NAS  Predictor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loya%2C+H">Hrushikesh Loya</a>, 
<a href="/search/cs?searchtype=author&query=Dudziak%2C+%C5%81">&#x141;ukasz Dudziak</a>, 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+A">Abhinav Mehrotra</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Royson Lee</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez-Marques%2C+J">Javier Fernandez-Marques</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+N+D">Nicholas D. Lane</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongkai Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural architecture search has proven to be a powerful approach to designing
and refining neural networks, often boosting their performance and efficiency
over manually-designed variations, but comes with computational overhead. While
there has been a considerable amount of research focused on lowering the cost
of NAS for mainstream tasks, such as image classification, a lot of those
improvements stem from the fact that those tasks are well-studied in the
broader context. Consequently, applicability of NAS to emerging and
under-represented domains is still associated with a relatively high cost
and/or uncertainty about the achievable gains. To address this issue, we turn
our focus towards the recent growth of publicly available NAS benchmarks in an
attempt to extract general NAS knowledge, transferable across different tasks
and search spaces. We borrow from the rich field of meta-learning for few-shot
adaptation and carefully study applicability of those methods to NAS, with a
special focus on the relationship between task-level correlation (domain shift)
and predictor transferability; which we deem critical for improving NAS on
diverse tasks. In our experiments, we use 6 NAS benchmarks in conjunction,
spanning in total 16 NAS settings -- our meta-learning approach not only shows
superior (or matching) performance in the cross-validation experiments but also
successful extrapolation to a new search space and tasks.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18452" title="Abstract">arXiv:2311.18452</a> [<a href="/pdf/2311.18452" title="Download PDF">pdf</a>, <a href="/format/2311.18452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developer Experiences with a Contextualized AI Coding Assistant:  Usability, Expectations, and Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinto%2C+G">Gustavo Pinto</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+C">Cleidson de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Rocha%2C+T">Thayssa Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Steinmacher%2C+I">Igor Steinmacher</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+A">Alberto de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Monteiro%2C+E">Edward Monteiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the rapidly advancing field of artificial intelligence, software
development has emerged as a key area of innovation. Despite the plethora of
general-purpose AI assistants available, their effectiveness diminishes in
complex, domain-specific scenarios. Noting this limitation, both the academic
community and industry players are relying on contextualized coding AI
assistants. These assistants surpass general-purpose AI tools by integrating
proprietary, domain-specific knowledge, offering precise and relevant
solutions. Our study focuses on the initial experiences of 62 participants who
used a contextualized coding AI assistant -- named StackSpot AI -- in a
controlled setting. According to the participants, the assistants' use resulted
in significant time savings, easier access to documentation, and the generation
of accurate codes for internal APIs. However, challenges associated with the
knowledge sources necessary to make the coding assistant access more contextual
information as well as variable responses and limitations in handling complex
codes were observed. The study's findings, detailing both the benefits and
challenges of contextualized AI assistants, underscore their potential to
revolutionize software development practices, while also highlighting areas for
further refinement.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18460" title="Abstract">arXiv:2311.18460</a> [<a href="/pdf/2311.18460" title="Download PDF">pdf</a>, <a href="/format/2311.18460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Fairness under Unobserved Confounding: A Neural Sensitivity  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+M">Maresa Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Frauen%2C+D">Dennis Frauen</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Methodology (stat.ME)

</div>
<p class="mathjax">Fairness for machine learning predictions is widely required in practice for
legal, ethical, and societal reasons. Existing work typically focuses on
settings without unobserved confounding, even though unobserved confounding can
lead to severe violations of causal fairness and, thus, unfair predictions. In
this work, we analyze the sensitivity of causal fairness to unobserved
confounding. Our contributions are three-fold. First, we derive bounds for
causal fairness metrics under different sources of unobserved confounding. This
enables practitioners to examine the sensitivity of their machine learning
models to unobserved confounding in fairness-critical applications. Second, we
propose a novel neural framework for learning fair predictions, which allows us
to offer worst-case guarantees of the extent to which causal fairness can be
violated due to unobserved confounding. Third, we demonstrate the effectiveness
of our framework in a series of experiments, including a real-world case study
about predicting prison sentences. To the best of our knowledge, ours is the
first work to study causal fairness under unobserved confounding. To this end,
our work is of direct practical value as a refutation strategy to ensure the
fairness of predictions in high-stakes applications.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18461" title="Abstract">arXiv:2311.18461</a> [<a href="/pdf/2311.18461" title="Download PDF">pdf</a>, <a href="/format/2311.18461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-time least squares approximation for Schr&#xf6;dinger equation and  efficient solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bressan%2C+A">Andrea Bressan</a>, 
<a href="/search/math?searchtype=author&query=Kushova%2C+A">Alen Kushova</a>, 
<a href="/search/math?searchtype=author&query=Sangalli%2C+G">Giancarlo Sangalli</a>, 
<a href="/search/math?searchtype=author&query=Tani%2C+M">Mattia Tani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1909.07309">arXiv:1909.07309</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we present a space-time least squares isogeometric
discretization of the Schr\"odinger equation and propose a preconditioner for
the arising linear system in the parametric domain. Exploiting the tensor
product structure of the basis functions, the preconditioner is written as the
sum of Kronecker products of matrices. Thanks to an extension to the classical
Fast Diagonalization method, the application of the preconditioner is efficient
and robust w.r.t. the polynomial degree of the spline space. The time required
for the application is almost proportional to the number of degrees-of-freedom,
for a serial execution.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18466" title="Abstract">arXiv:2311.18466</a> [<a href="/pdf/2311.18466" title="Download PDF">pdf</a>, <a href="/format/2311.18466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of explicit replies as coordination mechanisms in online student  debate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira-Saraiva%2C+B+D">Bruno D. Ferreira-Saraiva</a>, 
<a href="/search/cs?searchtype=author&query=Matos-Carvalho%2C+J+P">Joao P. Matos-Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Pita%2C+M">Manuel Pita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">People in conversation entrain their linguistic behaviours through
spontaneous alignment mechanisms [7] - both in face-to-face and
computer-mediated communication (CMC) [8]. In CMC, one of the mechanisms
through which linguistic entrainment happens is through explicit replies.
Indeed, the use of explicit replies influences the structure of conversations,
favouring the formation of reply-trees typically delineated by topic shifts
[5]. The interpersonal coordination mechanisms realized by how actors address
each other have been studied using a probabilistic framework proposed by David
Gibson [2,3]. Other recent approaches use computational methods and information
theory to quantify changes in text. We explore coordination mechanisms
concerned with some of the roles utterances play in dialogues - specifically in
explicit replies. We identify these roles by finding community structure in the
conversation's vocabulary using a non-parametric, hierarchical topic model.
Some conversations may always stay on the ground, remaining at the level of
general introductory chatter. Some others may develop a specific sub-topic in
significant depth and detail. Even others may jump between general chatter,
out-of-topic remarks and people agreeing or disagreeing without further
elaboration.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18473" title="Abstract">arXiv:2311.18473</a> [<a href="/pdf/2311.18473" title="Download PDF">pdf</a>, <a href="/format/2311.18473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGMem: Learning Visual Navigation Policy without Any Labels by Dynamic  Graph Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wenzhe Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Teng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangran Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lele Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changyin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent years, learning-based approaches have demonstrated significant
promise in addressing intricate navigation tasks. Traditional methods for
training deep neural network navigation policies rely on meticulously designed
reward functions or extensive teleoperation datasets as navigation
demonstrations. However, the former is often confined to simulated
environments, and the latter demands substantial human labor, making it a
time-consuming process. Our vision is for robots to autonomously learn
navigation skills and adapt their behaviors to environmental changes without
any human intervention. In this work, we discuss the self-supervised navigation
problem and present Dynamic Graph Memory (DGMem), which facilitates training
only with on-board observations. With the help of DGMem, agents can actively
explore their surroundings, autonomously acquiring a comprehensive navigation
policy in a data-efficient manner without external feedback. Our method is
evaluated in photorealistic 3D indoor scenes, and empirical studies demonstrate
the effectiveness of DGMem.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18474" title="Abstract">arXiv:2311.18474</a> [<a href="/pdf/2311.18474" title="Download PDF">pdf</a>, <a href="/ps/2311.18474" title="Download PostScript">ps</a>, <a href="/format/2311.18474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Hessian-based Trust Region Algorithm for Spherical Conformal  Parameterizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%2C+Z">Zhong-Heng Tan</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+T">Tiexiang Li</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+W">Wen-Wei Lin</a>, 
<a href="/search/math?searchtype=author&query=Yau%2C+S">Shing-Tung Yau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Surface parameterizations are widely applied in computer graphics, medical
imaging and transformation optics. In this paper, we rigorously derive the
gradient vector and Hessian matrix of the discrete conformal energy for
spherical conformal parameterizations of simply connected closed surfaces of
genus-$0$. In addition, we give the sparsity structure of the Hessian matrix,
which leads to a robust Hessian-based trust region algorithm for the
computation of spherical conformal maps. Numerical experiments demonstrate the
local quadratic convergence of the proposed algorithm with low conformal
distortions. We subsequently propose an application of our method to surface
registrations that still maintains local quadratic convergence.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18480" title="Abstract">arXiv:2311.18480</a> [<a href="/pdf/2311.18480" title="Download PDF">pdf</a>, <a href="/format/2311.18480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESPiM: Eye-Strain Probation Model, An Eye-Tracking Analysis Measure for  Digital Displays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parisay%2C+M">Mohsen Parisay</a>, 
<a href="/search/cs?searchtype=author&query=Haghbin%2C+N">Negar Haghbin</a>, 
<a href="/search/cs?searchtype=author&query=Poullis%2C+C">Charalambos Poullis</a>, 
<a href="/search/cs?searchtype=author&query=Kersten-Oertel%2C+M">Marta Kersten-Oertel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Eye-strain is a common issue among computer users due to the prolonged
periods they spend working in front of digital displays. This can lead to
vision problems, such as irritation and tiredness of the eyes and headaches. We
propose the Eye-Strain Probation Model (ESPiM), a computational model based on
eye-tracking data that measures eye-strain on digital displays based on the
spatial properties of the user interface and display area for a required period
of time. As well as measuring eye-strain, ESPiM can be applied to compare (a)
different user interface designs, (b) different display devices, and (c)
different interaction techniques. Two user studies were conducted to evaluate
the effectiveness of ESPiM. The first was conducted in the form of an in-person
study with an infrared eye-tracking sensor with 32 participants. The second was
conducted in the form of an online study with a video-based eye-tracking
technique via webcams on users' computers with 13 participants. Our analysis
showed significantly different eye-strain patterns based on the video gameplay
frequency of participants. Further, we found distinctive patterns among users
on a regular 9-to-5 routine versus those with more flexible work hours in terms
of (a) error rates and (b) reported eye-strain symptoms.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18481" title="Abstract">arXiv:2311.18481</a> [<a href="/pdf/2311.18481" title="Download PDF">pdf</a>, <a href="/format/2311.18481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESG Accountability Made Easy: DocQA at Your Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+L">Lokesh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Berrospi%2C+C">Cesar Berrospi</a>, 
<a href="/search/cs?searchtype=author&query=Dinkla%2C+K">Kasper Dinkla</a>, 
<a href="/search/cs?searchtype=author&query=Antognini%2C+D">Diego Antognini</a>, 
<a href="/search/cs?searchtype=author&query=Fusco%2C+F">Francesco Fusco</a>, 
<a href="/search/cs?searchtype=author&query=Bothur%2C+B">Benedikt Bothur</a>, 
<a href="/search/cs?searchtype=author&query=Lysak%2C+M">Maksym Lysak</a>, 
<a href="/search/cs?searchtype=author&query=Livathinos%2C+N">Nikolaos Livathinos</a>, 
<a href="/search/cs?searchtype=author&query=Nassar%2C+A">Ahmed Nassar</a>, 
<a href="/search/cs?searchtype=author&query=Vagenas%2C+P">Panagiotis Vagenas</a>, 
<a href="/search/cs?searchtype=author&query=Morin%2C+L">Lucas Morin</a>, 
<a href="/search/cs?searchtype=author&query=Auer%2C+C">Christoph Auer</a>, 
<a href="/search/cs?searchtype=author&query=Dolfi%2C+M">Michele Dolfi</a>, 
<a href="/search/cs?searchtype=author&query=Staar%2C+P">Peter Staar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Demonstration Track of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present Deep Search DocQA. This application enables information extraction
from documents via a question-answering conversational assistant. The system
integrates several technologies from different AI disciplines consisting of
document conversion to machine-readable format (via computer vision), finding
relevant data (via natural language processing), and formulating an eloquent
response (via large language models). Users can explore over 10,000
Environmental, Social, and Governance (ESG) disclosure reports from over 2000
corporations. The Deep Search platform can be accessed at:
https://ds4sd.github.io.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18482" title="Abstract">arXiv:2311.18482</a> [<a href="/pdf/2311.18482" title="Download PDF">pdf</a>, <a href="/format/2311.18482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jin-Chuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Hao-Bin Duan</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+S">Shao-Hua Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Open-vocabulary querying in 3D space is challenging but essential for scene
understanding tasks such as object localization and segmentation.
Language-embedded scene representations have made progress by incorporating
language features into 3D spaces. However, their efficacy heavily depends on
neural networks that are resource-intensive in training and rendering. Although
recent 3D Gaussians offer efficient and high-quality novel view synthesis,
directly embedding language features in them leads to prohibitive memory usage
and decreased performance. In this work, we introduce Language Embedded 3D
Gaussians, a novel scene representation for open-vocabulary query tasks.
Instead of embedding high-dimensional raw semantic features on 3D Gaussians, we
propose a dedicated quantization scheme that drastically alleviates the memory
requirement, and a novel embedding procedure that achieves smoother yet high
accuracy query, countering the multi-view feature inconsistencies and the
high-frequency inductive bias in point-based representations. Our comprehensive
experiments show that our representation achieves the best visual quality and
language querying accuracy across current language-embedded representations,
while maintaining real-time rendering frame rates on a single desktop GPU.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18484" title="Abstract">arXiv:2311.18484</a> [<a href="/pdf/2311.18484" title="Download PDF">pdf</a>, <a href="/format/2311.18484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing EEG Dataset Resources for Schizophrenia Diagnosis: Inaugural  West-African (Nigerian) Endeavor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olateju%2C+E+O">E.O. Olateju</a>, 
<a href="/search/cs?searchtype=author&query=Ayodele%2C+K+P">K.P. Ayodele</a>, 
<a href="/search/cs?searchtype=author&query=Mosaku%2C+S+K">S.K. Mosaku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript being updated as more data-acquisition proceeds. Link to dataset will be added on next update
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">This work has been carried out to improve the dearth of high-quality EEG
datasets used for schizophrenia diagnostic tools development and studies from
populations of developing and underdeveloped regions of the world. To this aim,
the presented dataset contains international 10/20 system EEG recordings from
West African subjects of Nigerian origin under rest conditions, in restful
states, mental arithmetic task execution states and while passively reacting to
auditory stimuli. The subjects are divided into cases and healthy controls and
recorded from 36 cases and 21 healthy conTrol subjects identified by the Mini
International Schizophrenia Interview (MINI) and also assessed by the Positive
and Negative Symptoms Scale (PANSS) and the World Health Organization
Disability Assessment Schedule (WHODAS). All cases are admitted schizophrenia
patients of the Mental Health Ward, Medical Outpatient Department of the
Obafemi Awolowo University Teaching Hospital Complex (OAUTHC, Ile-Ife) and its
subsidiary Wesley Guild Hospital Unit (OAUTHC, Ilesa). Controls are drawn from
students who volunteered to participate in the study at the Mental Health Ward
of OAUTHC and the Wesley Guild Hospital Unit. The recordings are available at
Datasets. This dataset can be used by the neuroscience and computational
psychiatry research community studying the diagnosis and prognosis of
schizophrenia using the electroencephalogram signal modality.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18486" title="Abstract">arXiv:2311.18486</a> [<a href="/pdf/2311.18486" title="Download PDF">pdf</a>, <a href="/format/2311.18486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Perspectives on the Evaluation of Link Prediction Algorithms for  Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+R">Rapha&#xeb;l Romero</a>, 
<a href="/search/cs?searchtype=author&query=De+Bie%2C+T">Tijl De Bie</a>, 
<a href="/search/cs?searchtype=author&query=Lijffijt%2C+J">Jefrey Lijffijt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There is a fast-growing body of research on predicting future links in
dynamic networks, with many new algorithms. Some benchmark data exists, and
performance evaluations commonly rely on comparing the scores of observed
network events (positives) with those of randomly generated ones (negatives).
These evaluation measures depend on both the predictive ability of the model
and, crucially, the type of negative samples used. Besides, as generally the
case with temporal data, prediction quality may vary over time. This creates a
complex evaluation space. In this work, we catalog the possibilities for
negative sampling and introduce novel visualization methods that can yield
insight into prediction performance and the dynamics of temporal networks. We
leverage these visualization tools to investigate the effect of negative
sampling on the predictive performance, at the node and edge level. We validate
empirically, on datasets extracted from recent benchmarks that the error is
typically not evenly distributed across different data segments. Finally, we
argue that such visualization tools can serve as powerful guides to evaluate
dynamic link prediction methods at different levels.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18488" title="Abstract">arXiv:2311.18488</a> [<a href="/pdf/2311.18488" title="Download PDF">pdf</a>, <a href="/format/2311.18488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Linear Programming Based Decoding of Quantum LDPC codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javed%2C+S">Sana Javed</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Herrero%2C+F">Francisco Garcia-Herrero</a>, 
<a href="/search/cs?searchtype=author&query=Vasic%2C+B">Bane Vasic</a>, 
<a href="/search/cs?searchtype=author&query=Flanagan%2C+M+F">Mark F. Flanagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper proposes two approaches for reducing the impact of the error floor
phenomenon when decoding quantum low-density parity-check codes with belief
propagation based algorithms. First, a low-complexity syndrome-based linear
programming (SB-LP) decoding algorithm is proposed, and second, the proposed
SB-LP is applied as a post-processing step after syndrome-based min-sum (SB-MS)
decoding. For the latter case, a new early stopping criterion is introduced to
decide when to activate the SB-LP algorithm, avoiding executing a predefined
maximum number of iterations for the SB-MS decoder. Simulation results show,
for a sample hypergraph code, that the proposed decoder can lower the error
floor by two to three orders of magnitude compared to SB-MS for the same total
number of decoding iterations.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18491" title="Abstract">arXiv:2311.18491</a> [<a href="/pdf/2311.18491" title="Download PDF">pdf</a>, <a href="/format/2311.18491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+V+M">Violeta Men&#xe9;ndez Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+A">Andrew Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Phillipson%2C+G">Graeme Phillipson</a>, 
<a href="/search/cs?searchtype=author&query=Jolly%2C+S">Stephen Jolly</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+S">Simon Hadfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VUA BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of media production, video editing techniques play a pivotal
role. Recent approaches have had great success at performing novel view image
synthesis of static scenes. But adding temporal information adds an extra layer
of complexity. Previous models have focused on implicitly representing static
and dynamic scenes using NeRF. These models achieve impressive results but are
costly at training and inference time. They overfit an MLP to describe the
scene implicitly as a function of position. This paper proposes ZeST-NeRF, a
new approach that can produce temporal NeRFs for new scenes without retraining.
We can accurately reconstruct novel views using multi-view synthesis techniques
and scene flow-field estimation, trained only with unrelated scenes. We
demonstrate how existing state-of-the-art approaches from a range of fields
cannot adequately solve this new task and demonstrate the efficacy of our
solution. The resulting network improves quantitatively by 15% and produces
significantly better visual results.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18492" title="Abstract">arXiv:2311.18492</a> [<a href="/pdf/2311.18492" title="Download PDF">pdf</a>, <a href="/format/2311.18492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLS-CAD: Synthesizing CAD Assemblies in Fusion 360
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaumet%2C+C">Constantin Chaumet</a>, 
<a href="/search/cs?searchtype=author&query=Rehof%2C+J">Jakob Rehof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The CAD design process includes a number of repetitive steps when creating
assemblies. This issue is compounded when engineering whole product lines or
design families, as steps like inserting parts common to all variations, such
as fasteners and product-integral base parts, get repeated numerous times. This
makes creating designs time-, and as a result, cost-intensive. While many CAD
software packages have APIs, the effort of creating use-case specific plugins
to automate creation of assemblies usually outweighs the benefit.
<br />We developed a plugin for the CAD software package "Fusion 360" which tackles
this issue. The plugin adds several graphical interfaces to Fusion 360 that
allow parts to be annotated with types, subtype hierarchies to be managed, and
requests to synthesize assembly programs for assemblies to be posed. The plugin
is use-case agnostic and is able to generate arbitrary open kinematic chain
structures. We envision engineers working with CAD software being able to make
designed parts reusable and automate the generation of different design
alternatives as well as whole product lines.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18494" title="Abstract">arXiv:2311.18494</a> [<a href="/pdf/2311.18494" title="Download PDF">pdf</a>, <a href="/format/2311.18494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRS: Sharp Feature Priors for Resolution-Free Surface Remeshing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soboleva%2C+N">Natalia Soboleva</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunova%2C+O">Olga Gorbunova</a>, 
<a href="/search/cs?searchtype=author&query=Ivanova%2C+M">Maria Ivanova</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Zorin%2C+D">Denis Zorin</a>, 
<a href="/search/cs?searchtype=author&query=Artemov%2C+A">Alexey Artemov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Surface reconstruction with preservation of geometric features is a
challenging computer vision task. Despite significant progress in implicit
shape reconstruction, state-of-the-art mesh extraction methods often produce
aliased, perceptually distorted surfaces and lack scalability to
high-resolution 3D shapes. We present a data-driven approach for automatic
feature detection and remeshing that requires only a coarse, aliased mesh as
input and scales to arbitrary resolution reconstructions. We define and learn a
collection of surface-based fields to (1) capture sharp geometric features in
the shape with an implicit vertexwise model and (2) approximate improvements in
normals alignment obtained by applying edge-flips with an edgewise model. To
support scaling to arbitrary complexity shapes, we learn our fields using local
triangulated patches, fusing estimates on complete surface meshes. Our feature
remeshing algorithm integrates the learned fields as sharp feature priors and
optimizes vertex placement and mesh connectivity for maximum expected surface
improvement. On a challenging collection of high-resolution shape
reconstructions in the ABC dataset, our algorithm improves over
state-of-the-art by 26% normals F-score and 42% perceptual
$\text{RMSE}_{\text{v}}$.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18495" title="Abstract">arXiv:2311.18495</a> [<a href="/pdf/2311.18495" title="Download PDF">pdf</a>, <a href="/format/2311.18495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Transferability via Model Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+A">Avery Ma</a>, 
<a href="/search/cs?searchtype=author&query=Farahmand%2C+A">Amir-massoud Farahmand</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yangchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural networks are susceptible to adversarial perturbations that are
transferable across different models. In this paper, we introduce a novel model
alignment technique aimed at improving a given source model's ability in
generating transferable adversarial perturbations. During the alignment
process, the parameters of the source model are fine-tuned to minimize an
alignment loss. This loss measures the divergence in the predictions between
the source model and another, independently trained model, referred to as the
witness model. To understand the effect of model alignment, we conduct a
geometric anlaysis of the resulting changes in the loss landscape. Extensive
experiments on the ImageNet dataset, using a variety of model architectures,
demonstrate that perturbations generated from aligned source models exhibit
significantly higher transferability than those from the original source model.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18496" title="Abstract">arXiv:2311.18496</a> [<a href="/pdf/2311.18496" title="Download PDF">pdf</a>, <a href="/format/2311.18496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Segmentation of Optic Disc And Cup from Multiple Pseudo-labels  by Noise-Aware Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Tengjin Weng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhidong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to CSCWD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Optic disc and cup segmentation play a crucial role in automating the
screening and diagnosis of optic glaucoma. While data-driven convolutional
neural networks (CNNs) show promise in this area, the inherent ambiguity of
segmenting object and background boundaries in the task of optic disc and cup
segmentation leads to noisy annotations that impact model performance. To
address this, we propose an innovative label-denoising method of Multiple
Pseudo-labels Noise-aware Network (MPNN) for accurate optic disc and cup
segmentation. Specifically, the Multiple Pseudo-labels Generation and Guided
Denoising (MPGGD) module generates pseudo-labels by multiple different
initialization networks trained on true labels, and the pixel-level consensus
information extracted from these pseudo-labels guides to differentiate clean
pixels from noisy pixels. The training framework of the MPNN is constructed by
a teacher-student architecture to learn segmentation from clean pixels and
noisy pixels. Particularly, such a framework adeptly leverages (i) reliable and
fundamental insights from clean pixels and (ii) the supplementary knowledge
within noisy pixels via multiple perturbation-based unsupervised consistency.
Compared to other label-denoising methods, comprehensive experimental results
on the RIGA dataset demonstrate our method's excellent performance and
significant denoising ability.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18498" title="Abstract">arXiv:2311.18498</a> [<a href="/pdf/2311.18498" title="Download PDF">pdf</a>, <a href="/format/2311.18498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Agnostic Model Poisoning against Federated Learning: A Graph  Autoencoder Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jingjing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+W">Wei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Akan%2C+O+B">Ozgur B. Akan</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures, submitted to IEEE Transactions on Information Forensics and Security (TIFS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper proposes a novel, data-agnostic, model poisoning attack on
Federated Learning (FL), by designing a new adversarial graph autoencoder
(GAE)-based framework. The attack requires no knowledge of FL training data and
achieves both effectiveness and undetectability. By listening to the benign
local models and the global model, the attacker extracts the graph structural
correlations among the benign local models and the training data features
substantiating the models. The attacker then adversarially regenerates the
graph structural correlations while maximizing the FL training loss, and
subsequently generates malicious local models using the adversarial graph
structure and the training data features of the benign ones. A new algorithm is
designed to iteratively train the malicious local models using GAE and
sub-gradient descent. The convergence of FL under attack is rigorously proved,
with a considerably large optimality gap. Experiments show that the FL accuracy
drops gradually under the proposed attack and existing defense mechanisms fail
to detect it. The attack can give rise to an infection across all benign
devices, making it a serious threat to FL.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18503" title="Abstract">arXiv:2311.18503</a> [<a href="/pdf/2311.18503" title="Download PDF">pdf</a>, <a href="/format/2311.18503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Retrieval with Learned Dense and Sparse Representations Using  Lucene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lassance%2C+C">Carlos Lassance</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The bi-encoder architecture provides a framework for understanding
machine-learned retrieval models based on dense and sparse vector
representations. Although these representations capture parametric realizations
of the same underlying conceptual framework, their respective implementations
of top-$k$ similarity search require the coordination of different software
components (e.g., inverted indexes, HNSW indexes, and toolkits for neural
inference), often knitted together in complex architectures. In this work, we
ask the following question: What's the simplest design, in terms of requiring
the fewest changes to existing infrastructure, that can support end-to-end
retrieval with modern dense and sparse representations? The answer appears to
be that Lucene is sufficient, as we demonstrate in Anserini, a toolkit for
reproducible information retrieval research. That is, effective retrieval with
modern single-vector neural models can be efficiently performed directly in
Java on the CPU. We examine the implications of this design for information
retrieval researchers pushing the state of the art as well as for software
engineers building production search systems.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18505" title="Abstract">arXiv:2311.18505</a> [<a href="/pdf/2311.18505" title="Download PDF">pdf</a>, <a href="/format/2311.18505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> String Sound Synthesizer on GPU-accelerated Finite Difference Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+W">Jin Woo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M+J">Min Jun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyogu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces a nonlinear string sound synthesizer, based on a finite
difference simulation of the dynamic behavior of strings under various
excitations. The presented synthesizer features a versatile string simulation
engine capable of stochastic parameterization, encompassing fundamental
frequency modulation, stiffness, tension, frequency-dependent loss, and
excitation control. This open-source physical model simulator not only benefits
the audio signal processing community but also contributes to the burgeoning
field of neural network-based audio synthesis by serving as a novel dataset
construction tool. Implemented in PyTorch, this synthesizer offers flexibility,
facilitating both CPU and GPU utilization, thereby enhancing its applicability
as a simulator. GPU utilization expedites computation by parallelizing
operations across spatial and batch dimensions, further enhancing its utility
as a data generator.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18512" title="Abstract">arXiv:2311.18512</a> [<a href="/pdf/2311.18512" title="Download PDF">pdf</a>, <a href="/format/2311.18512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Proposal-based Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+A">Aritra Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper revisits the pipeline for detecting objects in images with
proposals. For any object detector, the obtained box proposals or queries need
to be classified and regressed towards ground truth boxes. The common solution
for the final predictions is to directly maximize the overlap between each
proposal and the ground truth box, followed by a winner-takes-all ranking or
non-maximum suppression. In this work, we propose a simple yet effective
alternative. For proposal regression, we solve a simpler problem where we
regress to the area of intersection between proposal and ground truth. In this
way, each proposal only specifies which part contains the object, avoiding a
blind inpainting problem where proposals need to be regressed beyond their
visual scope. In turn, we replace the winner-takes-all strategy and obtain the
final prediction by taking the union over the regressed intersections of a
proposal group surrounding an object. Our revisited approach comes with minimal
changes to the detection pipeline and can be plugged into any existing method.
We show that our approach directly improves canonical object detection and
instance segmentation architectures, highlighting the utility of
intersection-based regression and grouping.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18518" title="Abstract">arXiv:2311.18518</a> [<a href="/pdf/2311.18518" title="Download PDF">pdf</a>, <a href="/format/2311.18518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Color-Emotion Associations in Art: Fuzzy Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shamoi%2C+P">Pakizar Shamoi</a>, 
<a href="/search/cs?searchtype=author&query=Muratbekova%2C+M">Muragul Muratbekova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Art objects can evoke certain emotions. Color is a fundamental element of
visual art and plays a significant role in how art is perceived. This paper
introduces a novel approach to classifying emotions in art using Fuzzy Sets. We
employ a fuzzy approach because it aligns well with human judgments' imprecise
and subjective nature. Extensive fuzzy colors (n=120) and a broad emotional
spectrum (n=10) allow for a more human-consistent and context-aware exploration
of emotions inherent in paintings. First, we introduce the fuzzy color
representation model. Then, at the fuzzification stage, we process the Wiki Art
Dataset of paintings tagged with emotions, extracting fuzzy dominant colors
linked to specific emotions. This results in fuzzy color distributions for ten
emotions. Finally, we convert them back to a crisp domain, obtaining a
knowledge base of color-emotion associations in primary colors. Our findings
reveal strong associations between specific emotions and colors; for instance,
gratitude strongly correlates with green, brown, and orange. Other noteworthy
associations include brown and anger, orange with shame, yellow with happiness,
and gray with fear. Using these associations and Jaccard similarity, we can
find the emotions in the arbitrary untagged image. We conducted a 2AFC
experiment involving human subjects to evaluate the proposed method. The
average hit rate of 0.77 indicates a significant correlation between the
method's predictions and human perception. The proposed method is simple to
adapt to art painting retrieval systems. The study contributes to the
theoretical understanding of color-emotion associations in art, offering
valuable insights for various practical applications besides art, like
marketing, design, and psychology.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18520" title="Abstract">arXiv:2311.18520</a> [<a href="/pdf/2311.18520" title="Download PDF">pdf</a>, <a href="/format/2311.18520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration-free online test-time adaptation for electroencephalography  motor imagery decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wimpff%2C+M">Martin Wimpff</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6bler%2C+M">Mario D&#xf6;bler</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, submitted to: 12th International Winter Conference on Brain-Computer Interface 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Providing a promising pathway to link the human brain with external devices,
Brain-Computer Interfaces (BCIs) have seen notable advancements in decoding
capabilities, primarily driven by increasingly sophisticated techniques,
especially deep learning. However, achieving high accuracy in real-world
scenarios remains a challenge due to the distribution shift between sessions
and subjects. In this paper we will explore the concept of online test-time
adaptation (OTTA) to continuously adapt the model in an unsupervised fashion
during inference time. Our approach guarantees the preservation of privacy by
eliminating the requirement to access the source data during the adaptation
process. Additionally, OTTA achieves calibration-free operation by not
requiring any session- or subject-specific data. We will investigate the task
of electroencephalography (EEG) motor imagery decoding using a lightweight
architecture together with different OTTA techniques like alignment, adaptive
batch normalization, and entropy minimization. We examine two datasets and
three distinct data settings for a comprehensive analysis. Our adaptation
methods produce state-of-the-art results, potentially instigating a shift in
transfer learning for BCI decoding towards online adaptation.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18521" title="Abstract">arXiv:2311.18521</a> [<a href="/pdf/2311.18521" title="Download PDF">pdf</a>, <a href="/format/2311.18521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining deep generative models with extreme value theory for synthetic  hazard simulation: a multivariate and spatially coherent approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peard%2C+A">Alison Peard</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+J">Jim Hall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning (CCAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Climate hazards can cause major disasters when they occur simultaneously as
compound hazards. To understand the distribution of climate risk and inform
adaptation policies, scientists need to simulate a large number of physically
realistic and spatially coherent events. Current methods are limited by
computational constraints and the probabilistic spatial distribution of
compound events is not given sufficient attention. The bottleneck in current
approaches lies in modelling the dependence structure between variables, as
inference on parametric models suffers from the curse of dimensionality.
Generative adversarial networks (GANs) are well-suited to such a problem due to
their ability to implicitly learn the distribution of data in high-dimensional
settings. We employ a GAN to model the dependence structure for daily maximum
wind speed, significant wave height, and total precipitation over the Bay of
Bengal, combining this with traditional extreme value theory for controlled
extrapolation of the tails. Once trained, the model can be used to efficiently
generate thousands of realistic compound hazard events, which can inform
climate risk assessments for climate adaptation and disaster preparedness. The
method developed is flexible and transferable to other multivariate and spatial
climate datasets.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18525" title="Abstract">arXiv:2311.18525</a> [<a href="/pdf/2311.18525" title="Download PDF">pdf</a>, <a href="/format/2311.18525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Anomalous Network Communication Patterns Using Graph  Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaisman%2C+Y">Yizhak Vaisman</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+G">Gilad Katz</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To protect an organizations' endpoints from sophisticated cyberattacks,
advanced detection methods are required. In this research, we present
GCNetOmaly: a graph convolutional network (GCN)-based variational autoencoder
(VAE) anomaly detector trained on data that include connection events among
internal and external machines. As input, the proposed GCN-based VAE model
receives two matrices: (i) the normalized adjacency matrix, which represents
the connections among the machines, and (ii) the feature matrix, which includes
various features (demographic, statistical, process-related, and Node2vec
structural features) that are used to profile the individual nodes/machines.
After training the model on data collected for a predefined time window, the
model is applied on the same data; the reconstruction score obtained by the
model for a given machine then serves as the machine's anomaly score.
GCNetOmaly was evaluated on real, large-scale data logged by Carbon Black EDR
from a large financial organization's automated teller machines (ATMs) as well
as communication with Active Directory (AD) servers in two setups: unsupervised
and supervised. The results of our evaluation demonstrate GCNetOmaly's
effectiveness in detecting anomalous behavior of machines on unsupervised data.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18526" title="Abstract">arXiv:2311.18526</a> [<a href="/pdf/2311.18526" title="Download PDF">pdf</a>, <a href="/format/2311.18526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOT: Higher-Order Dynamic Graph Representation Learning with Efficient  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Besta%2C+M">Maciej Besta</a>, 
<a href="/search/cs?searchtype=author&query=Catarino%2C+A+C">Afonso Claudino Catarino</a>, 
<a href="/search/cs?searchtype=author&query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="/search/cs?searchtype=author&query=Blach%2C+N">Nils Blach</a>, 
<a href="/search/cs?searchtype=author&query=Nyczyk%2C+P">Piotr Nyczyk</a>, 
<a href="/search/cs?searchtype=author&query=Niewiadomski%2C+H">Hubert Niewiadomski</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of Learning on Graphs (LOG), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Many graph representation learning (GRL) problems are dynamic, with millions
of edges added or removed per second. A fundamental workload in this setting is
dynamic link prediction: using a history of graph updates to predict whether a
given pair of vertices will become connected. Recent schemes for link
prediction in such dynamic settings employ Transformers, modeling individual
graph updates as single tokens. In this work, we propose HOT: a model that
enhances this line of works by harnessing higher-order (HO) graph structures;
specifically, k-hop neighbors and more general subgraphs containing a given
pair of vertices. Harnessing such HO structures by encoding them into the
attention matrix of the underlying Transformer results in higher accuracy of
link prediction outcomes, but at the expense of increased memory pressure. To
alleviate this, we resort to a recent class of schemes that impose hierarchy on
the attention matrix, significantly reducing memory footprint. The final design
offers a sweetspot between high accuracy and low memory utilization. HOT
outperforms other dynamic GRL schemes, for example achieving 9%, 7%, and 15%
higher accuracy than - respectively - DyGFormer, TGN, and GraphMixer, for the
MOOC dataset. Our design can be seamlessly extended towards other dynamic GRL
workloads.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18528" title="Abstract">arXiv:2311.18528</a> [<a href="/pdf/2311.18528" title="Download PDF">pdf</a>, <a href="/format/2311.18528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bottom-up computation using trees of sublists (Functional Pearl)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Shin-Cheng Mu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Functional Programming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Some top-down problem specifications, if executed, may compute sub-problems
repeatedly. Instead, we may want a bottom-up algorithm that stores solutions of
sub-problems in a table to be reused. How the table can be represented and
efficiently maintained, however, can be tricky.
<br />We study a special case: computing a function $h$ taking lists as inputs such
that $h~xs$ is defined in terms of all immediate sublists of $xs$. Richard Bird
studied this problem in 2008, and presented a concise but cryptic algorithm
without much explanation. We give this algorithm a proper derivation, and
discovered a key property that allows it to work. The algorithm builds trees
that have certain shapes -- the sizes along the left spine is a diagonal in
Pascal's triangle. The crucial function we derive transforms one diagonal to
the next.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18531" title="Abstract">arXiv:2311.18531</a> [<a href="/pdf/2311.18531" title="Download PDF">pdf</a>, <a href="/format/2311.18531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Distillation via the Wasserstein Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+T">Tiancheng Xing</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dalal%2C+V">Vibhu Dalal</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Dataset distillation (DD) offers a compelling approach in computer vision,
with the goal of condensing extensive datasets into smaller synthetic versions
without sacrificing much of the model performance. In this paper, we continue
to study the methods for DD, by addressing its conceptually core objective: how
to capture the essential representation of extensive datasets in smaller,
synthetic forms.
<br />We propose a novel approach utilizing the Wasserstein distance, a metric
rooted in optimal transport theory, to enhance distribution matching in DD. Our
method leverages the Wasserstein barycenter, offering a geometrically
meaningful way to quantify distribution differences and effectively capture the
centroid of a set of distributions. Our approach retains the computational
benefits of distribution matching-based methods while achieving new
state-of-the-art performance on several benchmarks.
<br />To provide useful prior for learning the images, we embed the synthetic data
into the feature space of pretrained classification models to conduct
distribution matching. Extensive testing on various high-resolution datasets
confirms the effectiveness and adaptability of our method, indicating the
promising yet unexplored capabilities of Wasserstein metrics in dataset
distillation.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18533" title="Abstract">arXiv:2311.18533</a> [<a href="/pdf/2311.18533" title="Download PDF">pdf</a>, <a href="/ps/2311.18533" title="Download PostScript">ps</a>, <a href="/format/2311.18533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A knowledge-driven framework for synthesizing designs from modular  components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaumet%2C+C">Constantin Chaumet</a>, 
<a href="/search/cs?searchtype=author&query=Rehof%2C+J">Jakob Rehof</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+T">Thomas Schuster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Creating a design from modular components necessitates three steps: Acquiring
knowledge about available components, conceiving an abstract design concept,
and implementing that concept in a concrete design. The third step entails many
repetitive and menial tasks, such as inserting parts and creating joints
between them. Especially when comparing and implementing design alternatives,
this issue is compounded. We propose a use-case agnostic knowledge-driven
framework to automate the implementation step. In particular, the framework
catalogues the acquired knowledge and the design concept, as well as utilizes
Combinatory Logic Synthesis to synthesize concrete design alternatives. This
minimizes the effort required to create designs, allowing the design space to
be thoroughly explored. We implemented the framework as a plugin for the CAD
software Autodesk Fusion 360. We conducted a case study in which robotic arms
were synthesized from a set of 28 modular components. Based on the case study,
the applicability of the framework is analyzed and discussed.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18534" title="Abstract">arXiv:2311.18534</a> [<a href="/pdf/2311.18534" title="Download PDF">pdf</a>, <a href="/format/2311.18534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The lowest-order Neural Approximated Virtual Element Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Berrone%2C+S">Stefano Berrone</a>, 
<a href="/search/math?searchtype=author&query=Oberto%2C+D">Davide Oberto</a>, 
<a href="/search/math?searchtype=author&query=Pintore%2C+M">Moreno Pintore</a>, 
<a href="/search/math?searchtype=author&query=Teora%2C+G">Gioana Teora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce the Neural Approximated Virtual Element Method, a novel
polygonal method that relies on neural networks to eliminate the need for
projection and stabilization operators in the Virtual Element Method. In this
paper, we discuss its formulation and detail the strategy for training the
underlying neural network. The efficacy of this new method is tested through
numerical experiments on elliptic problems.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18537" title="Abstract">arXiv:2311.18537</a> [<a href="/pdf/2311.18537" title="Download PDF">pdf</a>, <a href="/format/2311.18537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Ju He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qihang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+I">Inkyu Shin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xueqing Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaohui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang-Chieh Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code at <a href="https://github.com/TACJu/MaXTron">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video panoptic segmentation requires consistently segmenting (for both
`thing' and `stuff' classes) and tracking objects in a video over time. In this
work, we present MaXTron, a general framework that exploits Mask XFormer with
Trajectory Attention to tackle the task. MaXTron enriches an off-the-shelf mask
transformer by leveraging trajectory attention. The deployed mask transformer
takes as input a short clip consisting of only a few frames and predicts the
clip-level segmentation. To enhance the temporal consistency, MaXTron employs
within-clip and cross-clip tracking modules, efficiently utilizing trajectory
attention. Originally designed for video classification, trajectory attention
learns to model the temporal correspondences between neighboring frames and
aggregates information along the estimated motion paths. However, it is
nontrivial to directly extend trajectory attention to the per-pixel dense
prediction tasks due to its quadratic dependency on input size. To alleviate
the issue, we propose to adapt the trajectory attention for both the dense
pixel features and object queries, aiming to improve the short-term and
long-term tracking results, respectively. Particularly, in our within-clip
tracking module, we propose axial-trajectory attention that effectively
computes the trajectory attention for tracking dense pixels sequentially along
the height- and width-axes. The axial decomposition significantly reduces the
computational complexity for dense pixel features. In our cross-clip tracking
module, since the object queries in mask transformer are learned to encode the
object information, we are able to capture the long-term temporal connections
by applying trajectory attention to object queries, which learns to track each
object across different clips. Without bells and whistles, MaXTron demonstrates
state-of-the-art performances on video segmentation benchmarks.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18539" title="Abstract">arXiv:2311.18539</a> [<a href="/pdf/2311.18539" title="Download PDF">pdf</a>, <a href="/format/2311.18539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Both Worlds in Semantics and Time: Domain Knowledge Based  Analysis and Correlation of Industrial Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ike%2C+M">Moses Ike</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+K">Kandy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Badapanda%2C+A">Anwesh Badapanda</a>, 
<a href="/search/cs?searchtype=author&query=Landen%2C+M">Matthew Landen</a>, 
<a href="/search/cs?searchtype=author&query=Sadoski%2C+K">Keaton Sadoski</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wanda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Asfahan Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zonouz%2C+S">Saman Zonouz</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wenke Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Modern industrial control systems (ICS) attacks infect supervisory control
and data acquisition (SCADA) hosts to stealthily alter industrial processes,
causing damage. To detect attacks with low false alarms, recent work detects
attacks in both SCADA and process data. Unfortunately, this led to the same
problem - disjointed (false) alerts, due to the semantic and time gap in SCADA
and process behavior, i.e., SCADA execution does not map to process dynamics
nor evolve at similar time scales. We propose BRIDGE to analyze and correlate
SCADA and industrial process attacks using domain knowledge to bridge their
unique semantic and time evolution. This enables operators to tie malicious
SCADA operations to their adverse process effects, which reduces false alarms
and improves attack understanding. BRIDGE (i) identifies process constraints
violations in SCADA by measuring actuation dependencies in SCADA
process-control, and (ii) detects malicious SCADA effects in processes via a
physics-informed neural network that embeds generic knowledge of inertial
process dynamics. BRIDGE then dynamically aligns both analysis (i and ii) in a
time-window that adjusts their time evolution based on process inertial delays.
We applied BRIDGE to 11 diverse real-world industrial processes, and adaptive
attacks inspired by past events. BRIDGE correlated 98.3% of attacks with 0.8%
false positives (FP), compared to 78.3% detection accuracy and 13.7% FP of
recent work.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18540" title="Abstract">arXiv:2311.18540</a> [<a href="/pdf/2311.18540" title="Download PDF">pdf</a>, <a href="/format/2311.18540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Match me if you can: Semantic Correspondence Learning with Unpaired  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+B">Byeongho Heo</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sangdoo Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongyoon Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent approaches for semantic correspondence have focused on obtaining
high-quality correspondences using a complicated network, refining the
ambiguous or noisy matching points. Despite their performance improvements,
they remain constrained by the limited training pairs due to costly point-level
annotations. This paper proposes a simple yet effective method that performs
training with unlabeled pairs to complement both limited image pairs and sparse
point pairs, requiring neither extra labeled keypoints nor trainable modules.
We fundamentally extend the data quantity and variety by augmenting new
unannotated pairs not primitively provided as training pairs in benchmarks.
Using a simple teacher-student framework, we offer reliable pseudo
correspondences to the student network via machine supervision. Finally, the
performance of our network is steadily improved by the proposed iterative
training, putting back the student as a teacher to generate refined labels and
train a new student repeatedly. Our models outperform the milestone baselines,
including state-of-the-art methods on semantic correspondence benchmarks.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18542" title="Abstract">arXiv:2311.18542</a> [<a href="/pdf/2311.18542" title="Download PDF">pdf</a>, <a href="/format/2311.18542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-Assisted Generalized Receive Quadrature Spatial Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinan%2C+M+H">Mohamad H. Dinan</a>, 
<a href="/search/cs?searchtype=author&query=Flanagan%2C+M+F">Mark F. Flanagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages (2-column), 5 figures, 1 table, Prepared for Globcom 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, reconfigurable intelligent surface (RIS)-assisted generalized
receive quadrature spatial modulation (RIS-GRQSM) is proposed to improve the
spectral efficiency of RIS-aided quadrature spatial modulation (QSM) systems by
utilizing the concept of generalized spatial modulation (GSM). That is,
multiple antennas are activated at the receiver independently for both the real
and imaginary parts. We propose a max-min optimization problem to adjust the
phase shifts of all RIS elements to maximize the relevant signal-to-noise
ratios (SNRs) at all activated receive antennas. Using Lagrange duality, the
non-convex optimization problem involving the phase shifts of all RIS elements
reduces to a convex optimization involving a number of variables equal to the
number of activated receive antennas. A successive greedy detector (GD) can be
used at the receiver to detect the active antennas, which simplifies the
detection process. The numerical results show that the proposed scheme
outperforms the benchmark schemes in terms of error rate performance,
especially in systems with a larger number of receive antennas. In the special
case where each receive antenna corresponds to a user and is activated, the
RIS-GRQSM system becomes a multicast communication system. In this context, in
contrast to existing phase shift optimization algorithms which exhibit an
impractical level of complexity, our proposed solution offers the advantage of
low complexity and practical feasibility of implementation.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18543" title="Abstract">arXiv:2311.18543</a> [<a href="/pdf/2311.18543" title="Download PDF">pdf</a>, <a href="/format/2311.18543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrimeGraphNet: Link Prediction in Criminal Networks with Graph  Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In this paper, we introduce CrimeGraphNet, a novel approach for link
prediction in criminal networks utilizingGraph Convolutional Networks (GCNs).
Criminal networks are intricate and dynamic, with covert links that are
challenging to uncover. Accurate prediction of these links can aid in proactive
crime prevention and investigation. Existing methods often fail to capture the
complex interconnections in such networks. They also struggle in scenarios
where only limited labeled data is available for training. To address these
challenges, we propose CrimeGraphNet, which leverages the power of GCNs for
link prediction in these networks. The GCNmodel effectively captures
topological features and node characteristics, making it well-suited for this
task. We evaluate CrimeGraphNet on several real-world criminal network
datasets. Our results demonstrate that CrimeGraphNet outperforms existing
methods in terms of prediction accuracy, robustness, and computational
efAciency. Furthermore, our approach enables the extraction of meaningful
insights from the predicted links, thereby contributing to a better
understanding of the underlying criminal activities. Overall, CrimeGraphNet
represents a signiAcant step forward in the use of deep learning for criminal
network analysis.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18545" title="Abstract">arXiv:2311.18545</a> [<a href="/pdf/2311.18545" title="Download PDF">pdf</a>, <a href="/format/2311.18545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Deepfake Detection Network using Blockchain Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+D">Dipankar Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deepfake technology is a major threat to the integrity of digital media. This
paper presents a comprehensive framework for a blockchain-based decentralized
system designed to tackle the escalating challenge of digital content
integrity. The proposed system integrates advanced deep learning algorithms
with the immutable and transparent nature of blockchain technology to create a
trustless environment where authenticity can be verified without relying on a
single centralized authority. Furthermore, the system utilizes smart contracts
for dynamic algorithm management and token-based incentives further enhances
the system's effectiveness and adaptability. The decentralized architecture of
the system democratizes the process of verifying digital content and introduces
a novel approach to combat deepfakes. The collaborative and adjustable nature
of this system sets a new benchmark for digital media integrity, offering a
more robust digital media environment.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18547" title="Abstract">arXiv:2311.18547</a> [<a href="/pdf/2311.18547" title="Download PDF">pdf</a>, <a href="/format/2311.18547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Vibration-Based Bearing Fault Diagnosis Under Time-Varying  Speed Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalonen%2C+T">Tuomas Jalonen</a>, 
<a href="/search/cs?searchtype=author&query=Al-Sa%27d%2C+M">Mohammad Al-Sa&#x27;d</a>, 
<a href="/search/cs?searchtype=author&query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Detection of rolling-element bearing faults is crucial for implementing
proactive maintenance strategies and for minimizing the economic and
operational consequences of unexpected failures. However, many existing
techniques are developed and tested under strictly controlled conditions,
limiting their adaptability to the diverse and dynamic settings encountered in
practical applications. This paper presents an efficient real-time
convolutional neural network (CNN) for diagnosing multiple bearing faults under
various noise levels and time-varying rotational speeds. Additionally, we
propose a novel Fisher-based spectral separability analysis (SSA) method to
elucidate the effectiveness of the designed CNN model. We conducted experiments
on both healthy bearings and bearings afflicted with inner race, outer race,
and roller ball faults. The experimental results show the superiority of our
model over the current state-of-the-art approach in three folds: it achieves
substantial accuracy gains of up to 15.8%, it is robust to noise with high
performance across various signal-to-noise ratios, and it runs in real-time
with processing durations five times less than acquisition. Additionally, by
using the proposed SSA technique, we offer insights into the model's
performance and underscore its effectiveness in tackling real-world challenges.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18550" title="Abstract">arXiv:2311.18550</a> [<a href="/pdf/2311.18550" title="Download PDF">pdf</a>, <a href="/ps/2311.18550" title="Download PostScript">ps</a>, <a href="/format/2311.18550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search Still Matters: Information Retrieval in the Era of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hersh%2C+W+R">William R. Hersh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objective: Information retrieval (IR, also known as search) systems are
ubiquitous in modern times. How does the emergence of generative artificial
intelligence (AI), based on large language models (LLMs), fit into the IR
process? Process: This perspective explores the use of generative AI in the
context of the motivations, considerations, and outcomes of the IR process with
a focus on the academic use of such systems. Conclusions: There are many
information needs, from simple to complex, that motivate use of IR. Users of
such systems, particularly academics, have concerns for authoritativeness,
timeliness, and contextualization of search. While LLMs may provide
functionality that aids the IR process, the continued need for search systems,
and research into their improvement, remains essential.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18553" title="Abstract">arXiv:2311.18553</a> [<a href="/pdf/2311.18553" title="Download PDF">pdf</a>, <a href="/format/2311.18553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Graph-based Trajectory Prediction using Local Map Context  and Social Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grimm%2C+D">Daniel Grimm</a>, 
<a href="/search/cs?searchtype=author&query=Zipfl%2C+M">Maximilian Zipfl</a>, 
<a href="/search/cs?searchtype=author&query=Hertlein%2C+F">Felix Hertlein</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+A">Alexander Naumann</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCttin%2C+J">J&#xfc;rgen L&#xfc;ttin</a>, 
<a href="/search/cs?searchtype=author&query=Thoma%2C+S">Steffen Thoma</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Halilaj%2C+L">Lavdim Halilaj</a>, 
<a href="/search/cs?searchtype=author&query=Rettinger%2C+A">Achim Rettinger</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on IEEE ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Precisely predicting the future trajectories of surrounding traffic
participants is a crucial but challenging problem in autonomous driving, due to
complex interactions between traffic agents, map context and traffic rules.
Vector-based approaches have recently shown to achieve among the best
performances on trajectory prediction benchmarks. These methods model simple
interactions between traffic agents but don't distinguish between relation-type
and attributes like their distance along the road. Furthermore, they represent
lanes only by sequences of vectors representing center lines and ignore context
information like lane dividers and other road elements. We present a novel
approach for vector-based trajectory prediction that addresses these
shortcomings by leveraging three crucial sources of information: First, we
model interactions between traffic agents by a semantic scene graph, that
accounts for the nature and important features of their relation. Second, we
extract agent-centric image-based map features to model the local map context.
Finally, we generate anchor paths to enforce the policy in multi-modal
prediction to permitted trajectories only. Each of these three enhancements
shows advantages over the baseline model HoliGraph.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18557" title="Abstract">arXiv:2311.18557</a> [<a href="/pdf/2311.18557" title="Download PDF">pdf</a>, <a href="/format/2311.18557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can semi-supervised learning use all the data effectively? A lower bound  perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A2ifrea%2C+A">Alexandru &#x162;ifrea</a>, 
<a href="/search/cs?searchtype=author&query=Y%C3%BCce%2C+G">Gizem Y&#xfc;ce</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+A">Amartya Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fanny Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Advances in Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Prior works have shown that semi-supervised learning algorithms can leverage
unlabeled data to improve over the labeled sample complexity of supervised
learning (SL) algorithms. However, existing theoretical analyses focus on
regimes where the unlabeled data is sufficient to learn a good decision
boundary using unsupervised learning (UL) alone. This begs the question: Can
SSL algorithms simultaneously improve upon both UL and SL? To this end, we
derive a tight lower bound for 2-Gaussian mixture models that explicitly
depends on the labeled and the unlabeled dataset size as well as the
signal-to-noise ratio of the mixture distribution. Surprisingly, our result
implies that no SSL algorithm can improve upon the minimax-optimal statistical
error rates of SL or UL algorithms for these distributions. Nevertheless, we
show empirically on real-world data that SSL algorithms can still outperform UL
and SL methods. Therefore, our work suggests that, while proving performance
gains for SSL algorithms is possible, it requires careful tracking of
constants.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18558" title="Abstract">arXiv:2311.18558</a> [<a href="/pdf/2311.18558" title="Download PDF">pdf</a>, <a href="/format/2311.18558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Radio Environments by Differentiable Ray Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoydis%2C+J">Jakob Hoydis</a>, 
<a href="/search/cs?searchtype=author&query=Aoudia%2C+F+A">Fay&#xe7;al A&#xef;t Aoudia</a>, 
<a href="/search/cs?searchtype=author&query=Cammerer%2C+S">Sebastian Cammerer</a>, 
<a href="/search/cs?searchtype=author&query=Euchner%2C+F">Florian Euchner</a>, 
<a href="/search/cs?searchtype=author&query=Nimier-David%2C+M">Merlin Nimier-David</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+A">Alexander Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Ray tracing (RT) is instrumental in 6G research in order to generate
spatially-consistent and environment-specific channel impulse responses (CIRs).
While acquiring accurate scene geometries is now relatively straightforward,
determining material characteristics requires precise calibration using channel
measurements. We therefore introduce a novel gradient-based calibration method,
complemented by differentiable parametrizations of material properties,
scattering and antenna patterns. Our method seamlessly integrates with
differentiable ray tracers that enable the computation of derivatives of CIRs
with respect to these parameters. Essentially, we approach field computation as
a large computational graph wherein parameters are trainable akin to weights of
a neural network (NN). We have validated our method using both synthetic data
and real-world indoor channel measurements, employing a distributed
multiple-input multiple-output (MIMO) channel sounder.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18559" title="Abstract">arXiv:2311.18559</a> [<a href="/pdf/2311.18559" title="Download PDF">pdf</a>, <a href="/format/2311.18559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FediOS: Decoupling Orthogonal Subspaces for Personalization in  Feature-skew Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lingzhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Personalized federated learning (pFL) enables collaborative training among
multiple clients to enhance the capability of customized local models. In pFL,
clients may have heterogeneous (also known as non-IID) data, which poses a key
challenge in how to decouple the data knowledge into generic knowledge for
global sharing and personalized knowledge for preserving local personalization.
A typical way of pFL focuses on label distribution skew, and they adopt a
decoupling scheme where the model is split into a common feature extractor and
two prediction heads (generic and personalized). However, such a decoupling
scheme cannot solve the essential problem of feature skew heterogeneity,
because a common feature extractor cannot decouple the generic and personalized
features. Therefore, in this paper, we rethink the architecture decoupling
design for feature-skew pFL and propose an effective pFL method called FediOS.
In FediOS, we reformulate the decoupling into two feature extractors (generic
and personalized) and one shared prediction head. Orthogonal projections are
used for clients to map the generic features into one common subspace and
scatter the personalized features into different subspaces to achieve
decoupling for them. In addition, a shared prediction head is trained to
balance the importance of generic and personalized features during inference.
Extensive experiments on four vision datasets demonstrate our method reaches
state-of-the-art pFL performances under feature skew heterogeneity.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18561" title="Abstract">arXiv:2311.18561</a> [<a href="/pdf/2311.18561" title="Download PDF">pdf</a>, <a href="/format/2311.18561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Periodic Vibration Gaussian: Dynamic Urban Scene Reconstruction and  Real-time Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yurui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chun Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junzhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://fudan-zvg.github.io/PVG/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modeling dynamic, large-scale urban scenes is challenging due to their highly
intricate geometric structures and unconstrained dynamics in both space and
time. Prior methods often employ high-level architectural priors, separating
static and dynamic elements, resulting in suboptimal capture of their
synergistic interactions. To address this challenge, we present a unified
representation model, called Periodic Vibration Gaussian (PVG). PVG builds upon
the efficient 3D Gaussian splatting technique, originally designed for static
scene representation, by introducing periodic vibration-based temporal
dynamics. This innovation enables PVG to elegantly and uniformly represent the
characteristics of various objects and elements in dynamic urban scenes. To
enhance temporally coherent representation learning with sparse training data,
we introduce a novel flow-based temporal smoothing mechanism and a
position-aware adaptive control strategy. Extensive experiments on Waymo Open
Dataset and KITTI benchmarks demonstrate that PVG surpasses state-of-the-art
alternatives in both reconstruction and novel view synthesis for both dynamic
and static scenes. Notably, PVG achieves this without relying on manually
labeled object bounding boxes or expensive optical flow estimation. Moreover,
PVG exhibits 50/6000-fold acceleration in training/rendering over the best
alternative.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18564" title="Abstract">arXiv:2311.18564</a> [<a href="/pdf/2311.18564" title="Download PDF">pdf</a>, <a href="/format/2311.18564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seam-guided local alignment and stitching for large parallax images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+T">Tianli Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Heling Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, in peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Seam-cutting methods have been proven effective in the composition step of
image stitching, especially for images with parallax. However, the
effectiveness of seam-cutting usually depends on that images can be roughly
aligned such that there exists a local region where a plausible seam can be
found. For images with large parallax, current alignment methods often fall
short of expectations. In this paper, we propose a local alignment and
stitching method guided by seam quality evaluation. First, we use existing
image alignment and seam-cutting methods to calculate an initial seam and
evaluate the quality of pixels along the seam. Then, for pixels with low
qualities, we separate their enclosing patches in the aligned images and
locally align them by extracting modified dense correspondences via SIFT flow.
Finally, we composite the aligned patches via seam-cutting and merge them into
the original aligned result to generate the final mosaic. Experiments show that
compared with the state-of-the-art seam-cutting methods, our result is more
plausible and with fewer artifacts. The code will be available at
https://github.com/tlliao/Seam-guided-local-alignment.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18565" title="Abstract">arXiv:2311.18565</a> [<a href="/pdf/2311.18565" title="Download PDF">pdf</a>, <a href="/format/2311.18565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Formulation of Structural Design Optimization Problems for Quantum  Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Key%2C+F">Fabian Key</a>, 
<a href="/search/cs?searchtype=author&query=Freinberger%2C+L">Lukas Freinberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We present a novel formulation of structural design optimization problems
specifically tailored to be solved by quantum annealing (QA). Structural design
optimization aims to find the best, i.e., material-efficient yet
high-performance, configuration of a structure. To this end, computational
optimization strategies can be employed, where a recently evolving strategy
based on quantum mechanical effects is QA. This approach requires the
optimization problem to be present, e.g., as a quadratic unconstrained binary
optimization (QUBO) model. Thus, we develop a novel formulation of the
optimization problem. The latter typically involves an analysis model for the
component. Here, we use energy minimization principles that govern the behavior
of structures under applied loads. This allows us to state the optimization
problem as one overall minimization problem. Next, we map this to a QUBO
problem that can be immediately solved by QA. We validate the proposed approach
using a size optimization problem of a compound rod under self-weight loading.
To this end, we develop strategies to account for the limitations of currently
available hardware and find that the presented formulation is suitable for
solving structural design optimization problems through QA and, for small-scale
problems, already works on today's hardware.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18567" title="Abstract">arXiv:2311.18567</a> [<a href="/pdf/2311.18567" title="Download PDF">pdf</a>, <a href="/format/2311.18567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grammatical Gender&#x27;s Influence on Distributional Semantics: A Causal  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+K">Karolina Sta&#x144;czak</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kevin Du</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Augenstein%2C+I">Isabelle Augenstein</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">How much meaning influences gender assignment across languages is an active
area of research in modern linguistics and cognitive science. We can view
current approaches as aiming to determine where gender assignment falls on a
spectrum, from being fully arbitrarily determined to being largely semantically
determined. For the latter case, there is a formulation of the neo-Whorfian
hypothesis, which claims that even inanimate noun gender influences how people
conceive of and talk about objects (using the choice of adjective used to
modify inanimate nouns as a proxy for meaning). We offer a novel, causal
graphical model that jointly represents the interactions between a noun's
grammatical gender, its meaning, and adjective choice. In accordance with past
results, we find a relationship between the gender of nouns and the adjectives
which modify them. However, when we control for the meaning of the noun, we
find that grammatical gender has a near-zero effect on adjective choice,
thereby calling the neo-Whorfian hypothesis into question.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18572" title="Abstract">arXiv:2311.18572</a> [<a href="/pdf/2311.18572" title="Download PDF">pdf</a>, <a href="/format/2311.18572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Label Noise for Source-free Unsupervised Video Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+A">Avijit Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C. V. Jawahar</a>, 
<a href="/search/cs?searchtype=author&query=Alahari%2C+K">Karteek Alahari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of our ICVGIP paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the progress seen in classification methods, current approaches for
handling videos with distribution shifts in source and target domains remain
source-dependent as they require access to the source data during the
adaptation stage. In this paper, we present a self-training based source-free
video domain adaptation approach to address this challenge by bridging the gap
between the source and the target domains. We use the source pre-trained model
to generate pseudo-labels for the target domain samples, which are inevitably
noisy. Thus, we treat the problem of source-free video domain adaptation as
learning from noisy labels and argue that the samples with correct
pseudo-labels can help us in adaptation. To this end, we leverage the
cross-entropy loss as an indicator of the correctness of the pseudo-labels and
use the resulting small-loss samples from the target domain for fine-tuning the
model. We further enhance the adaptation performance by implementing a
teacher-student framework, in which the teacher, which is updated gradually,
produces reliable pseudo-labels. Meanwhile, the student undergoes fine-tuning
on the target domain videos using these generated pseudo-labels to improve its
performance. Extensive experimental evaluations show that our methods, termed
as CleanAdapt, CleanAdapt + TS, achieve state-of-the-art results, outperforming
the existing approaches on various open datasets. Our source code is publicly
available at https://avijit9.github.io/CleanAdapt.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18575" title="Abstract">arXiv:2311.18575</a> [<a href="/pdf/2311.18575" title="Download PDF">pdf</a>, <a href="/format/2311.18575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Distribution Shifts in Zero-Shot Learning: Learning Robust  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slavutsky%2C+Y">Yuli Slavutsky</a>, 
<a href="/search/cs?searchtype=author&query=Benjamini%2C+Y">Yuval Benjamini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Distribution shifts between training and deployment data often affect the
performance of machine learning models. In this paper, we explore a setting
where a hidden variable induces a shift in the distribution of classes. These
distribution shifts are particularly challenging for zero-shot classifiers, as
they rely on representations learned from training classes, but are deployed on
new, unseen ones. We introduce an algorithm to learn data representations that
are robust to such class distribution shifts in zero-shot verification tasks.
We show that our approach, which combines hierarchical data sampling with
out-of-distribution generalization techniques, improves generalization to
diverse class distributions in both simulations and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18576" title="Abstract">arXiv:2311.18576</a> [<a href="/pdf/2311.18576" title="Download PDF">pdf</a>, <a href="/format/2311.18576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fingerprint Matching with Localized Deep Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yongjie Duan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianjiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Compared to minutia-based fingerprint representations, fixed-length
representations are attractive due to simple and efficient matching. However,
fixed-length fingerprint representations are limited in accuracy when matching
fingerprints with different visible areas, which can occur due to different
finger poses or acquisition methods. To address this issue, we propose a
localized deep representation of fingerprint, named LDRF. By focusing on the
discriminative characteristics within local regions, LDRF provides a more
robust and accurate fixed-length representation for fingerprints with variable
visible areas. LDRF can be adapted to retain information within any valid area,
making it highly flexible. The matching scores produced by LDRF also exhibit
intuitive statistical characteristics, which led us to propose a matching score
normalization technique to mitigate the uncertainty in the cases of very small
overlapping area. With this new technique, we can maintain a high level of
accuracy and reliability in our fingerprint matching, even as the size of the
database grows rapidly. Our experimental results on 21 datasets containing over
140K fingerprints of various finger poses and impression types show that LDRF
outperforms other fixed-length representations and is robust to sensing
technologies and impression types. Besides, the proposed matching score
normalization effectively reduces the false match rate (FMR) in large-scale
identification experiments comprising over 5.11 million fingerprints.
Specifically, this technique results in a reduction of two orders of magnitude
compared to matching without matching score normalization and five orders of
magnitude compared to prior works.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18578" title="Abstract">arXiv:2311.18578</a> [<a href="/pdf/2311.18578" title="Download PDF">pdf</a>, <a href="/format/2311.18578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Heterogeneous Federated Learning with  Generalized Heavy-Ball Momentum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaccone%2C+R">Riccardo Zaccone</a>, 
<a href="/search/cs?searchtype=author&query=Masone%2C+C">Carlo Masone</a>, 
<a href="/search/cs?searchtype=author&query=Ciccone%2C+M">Marco Ciccone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated Learning (FL) is the state-of-the-art approach for learning from
decentralized data in privacy-constrained scenarios. As the current literature
reports, the main problems associated with FL refer to system and statistical
challenges: the former ones demand for efficient learning from edge devices,
including lowering communication bandwidth and frequency, while the latter
require algorithms robust to non-iidness. State-of-art approaches either
guarantee convergence at increased communication cost or are not sufficiently
robust to handle extreme heterogeneous local distributions. In this work we
propose a novel generalization of the heavy-ball momentum, and present FedHBM
to effectively address statistical heterogeneity in FL without introducing any
communication overhead. We conduct extensive experimentation on common FL
vision and NLP datasets, showing that our FedHBM algorithm empirically yields
better model quality and higher convergence speed w.r.t. the state-of-art,
especially in pathological non-iid scenarios. While being designed for
cross-silo settings, we show how FedHBM is applicable in moderate-to-high
cross-device scenarios, and how good model initializations (e.g. pre-training)
can be exploited for prompt acceleration. Extended experimentation on
large-scale real-world federated datasets further corroborates the
effectiveness of our approach for real-world FL applications.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18580" title="Abstract">arXiv:2311.18580</a> [<a href="/pdf/2311.18580" title="Download PDF">pdf</a>, <a href="/format/2311.18580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FFT: Towards Harmlessness Evaluation and Analysis for LLMs with  Factuality, Fairness, Toxicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shiyao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tingwen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The widespread of generative artificial intelligence has heightened concerns
about the potential harms posed by AI-generated texts, primarily stemming from
factoid, unfair, and toxic content. Previous researchers have invested much
effort in assessing the harmlessness of generative language models. However,
existing benchmarks are struggling in the era of large language models (LLMs),
due to the stronger language generation and instruction following capabilities,
as well as wider applications. In this paper, we propose FFT, a new benchmark
with 2116 elaborated-designed instances, for LLM harmlessness evaluation with
factuality, fairness, and toxicity. To investigate the potential harms of LLMs,
we evaluate 9 representative LLMs covering various parameter scales, training
stages, and creators. Experiments show that the harmlessness of LLMs is still
under-satisfactory, and extensive analysis derives some insightful findings
that could inspire future research for harmless LLM research.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18587" title="Abstract">arXiv:2311.18587</a> [<a href="/pdf/2311.18587" title="Download PDF">pdf</a>, <a href="/format/2311.18587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of deep learning, the prevalence of models initially trained
with 32-bit precision is a testament to its robustness and accuracy. However,
the continuous evolution of these models often demands further training, which
can be resource-intensive. This study introduces a novel approach where we
continue the training of these pre-existing 32-bit models using 16-bit
precision. This technique not only caters to the need for efficiency in
computational resources but also significantly improves the speed of additional
training phases. By adopting 16-bit precision for ongoing training, we are able
to substantially decrease memory requirements and computational burden, thereby
accelerating the training process in a resource-limited setting. Our
experiments show that this method maintains the high standards of accuracy set
by the original 32-bit training while providing a much-needed boost in training
speed. This approach is especially pertinent in today's context, where most
models are initially trained in 32-bit and require periodic updates and
refinements. The findings from our research suggest that this strategy of
16-bit continuation training can be a key solution for sustainable and
efficient deep learning, offering a practical way to enhance pre-trained models
rapidly and in a resource-conscious manner.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18592" title="Abstract">arXiv:2311.18592</a> [<a href="/pdf/2311.18592" title="Download PDF">pdf</a>, <a href="/format/2311.18592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Frame-Event Fusion based Pattern Recognition via Large  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiandong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yanlin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaoyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Peer Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pattern recognition through the fusion of RGB frames and Event streams has
emerged as a novel research area in recent years. Current methods typically
employ backbone networks to individually extract the features of RGB frames and
event streams, and subsequently fuse these features for pattern recognition.
However, we posit that these methods may suffer from key issues like sematic
gaps and small-scale backbone networks. In this study, we introduce a novel
pattern recognition framework that consolidates the semantic labels, RGB
frames, and event streams, leveraging pre-trained large-scale vision-language
models. Specifically, given the input RGB frames, event streams, and all the
predefined semantic labels, we employ a pre-trained large-scale vision model
(CLIP vision encoder) to extract the RGB and event features. To handle the
semantic labels, we initially convert them into language descriptions through
prompt engineering, and then obtain the semantic features using the pre-trained
large-scale language model (CLIP text encoder). Subsequently, we integrate the
RGB/Event features and semantic features using multimodal Transformer networks.
The resulting frame and event tokens are further amplified using self-attention
layers. Concurrently, we propose to enhance the interactions between text
tokens and RGB/Event tokens via cross-attention. Finally, we consolidate all
three modalities using self-attention and feed-forward layers for recognition.
Comprehensive experiments on the HARDVS and PokerEvent datasets fully
substantiate the efficacy of our proposed SAFE model. The source code will be
made available at https://github.com/Event-AHU/SAFE_LargeVLM.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18595" title="Abstract">arXiv:2311.18595</a> [<a href="/pdf/2311.18595" title="Download PDF">pdf</a>, <a href="/format/2311.18595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEFT: Distributed, Elastic, and Fault-tolerant State Management of  Network Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahriyar%2C+M+M">Md Mahir Shahriyar</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+G">Gourab Saha</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+B">Bishwajit Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Reaz%2C+R">Rezwana Reaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Network function virtualization is the key to developing elastically scalable
and fault-tolerant network functions (e.g. load balancer, firewall etc.). By
integrating NFV and SDN technologies, it is feasible to dynamically reroute
traffic to new network function (NF) instances in the event of an NF failure or
overload scenario. The fact that the majority of network functions are stateful
makes the task more challenging. State migration and state replication are
common approaches in achieving elasticity and fault tolerance. The majority of
the studies in the literature either emphasize fault tolerance or elastic
scalability while designing a state management system for network functions. In
this paper, we have designed a complete state management system, called DEFT,
that meets both elasticity and fault-tolerance goals. Our system also supports
strong consistency on global state updates. While existing designs rely on a
central controller or remote central storage to achieve strong consistency on
state updates, DEFT utilizes distributed consensus mechanism to achieve the
same. We have done a proof of concept implementation of DEFT and extensively
tested DEFT under several model conditions to evaluate its scalability and
performance. Our experimental results show that DEFT is scalable and maintains
a considerably high throughput throughout. It incurs minimal performance
overhead while achieving strong consistency on state updates.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18598" title="Abstract">arXiv:2311.18598</a> [<a href="/pdf/2311.18598" title="Download PDF">pdf</a>, <a href="/format/2311.18598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalisable Agents for Neural Network Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tessera%2C+K">Kale-ab Tessera</a>, 
<a href="/search/cs?searchtype=author&query=Tilbury%2C+C+R">Callum Rhys Tilbury</a>, 
<a href="/search/cs?searchtype=author&query=Abramowitz%2C+S">Sasha Abramowitz</a>, 
<a href="/search/cs?searchtype=author&query=de+Kock%2C+R">Ruan de Kock</a>, 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+O">Omayma Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=Rosman%2C+B">Benjamin Rosman</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Workshop on Advanced Neural Network Training (WANT) and Optimization for Machine Learning (OPT) at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Optimising deep neural networks is a challenging task due to complex training
dynamics, high computational requirements, and long training times. To address
this difficulty, we propose the framework of Generalisable Agents for Neural
Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL)
approach that learns to improve neural network optimisation by dynamically and
responsively scheduling hyperparameters during training. GANNO utilises an
agent per layer that observes localised network dynamics and accordingly takes
actions to adjust these dynamics at a layerwise level to collectively improve
global performance. In this paper, we use GANNO to control the layerwise
learning rate and show that the framework can yield useful and responsive
schedules that are competitive with handcrafted heuristics. Furthermore, GANNO
is shown to perform robustly across a wide variety of unseen initial
conditions, and can successfully generalise to harder problems than it was
trained on. Our work presents an overview of the opportunities that this
paradigm offers for training neural networks, along with key challenges that
remain to be overcome.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18603" title="Abstract">arXiv:2311.18603</a> [<a href="/pdf/2311.18603" title="Download PDF">pdf</a>, <a href="/ps/2311.18603" title="Download PostScript">ps</a>, <a href="/format/2311.18603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy conservative isogeometric techniques for the wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bressan%2C+A">Andrea Bressan</a>, 
<a href="/search/math?searchtype=author&query=Buffa%2C+A">Annalisa Buffa</a>, 
<a href="/search/math?searchtype=author&query=Kushova%2C+A">Alen Kushova</a>, 
<a href="/search/math?searchtype=author&query=V%C3%A1zquez%2C+R">Rafael V&#xe1;zquez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We analyze the wave equation in mixed form, with periodic and/or Dirichlet
homogeneous boundary conditions, and nonconstant coefficients that depend on
the spatial variable. For the discretization, the weak form of the second
equation is replaced by a strong form, written in terms of a projection
operator. The system of equations is discretized with B-splines forming a De
Rham complex along with suitable commutative projectors for the approximation
of the second equation. The discrete scheme is energy conservative when
discretized in time with a conservative method such as Crank-Nicolson. We
propose a convergence analysis of the method to study the dependence with
respect to the mesh size $h$, with focus on the consistency error. Numerical
results show optimal convergence of the error in energy norm, and a relative
error in energy conservation for long-time simulations of the order of machine
precision.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18604" title="Abstract">arXiv:2311.18604</a> [<a href="/pdf/2311.18604" title="Download PDF">pdf</a>, <a href="/format/2311.18604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barwise Music Structure Analysis with the Correlation Block-Matching  Segmentation Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marmoret%2C+A">Axel Marmoret</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+E">J&#xe9;r&#xe9;my E. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Bimbot%2C+F">Fr&#xe9;d&#xe9;ric Bimbot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures, 11 tables, 1 algorithm, published in Transactions of the International Society for Music Information Retrieval
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions of the International Society for Music Information
  Retrieval, 6(1), 2023, 167--185
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music Structure Analysis (MSA) is a Music Information Retrieval task
consisting of representing a song in a simplified, organized manner by breaking
it down into sections typically corresponding to ``chorus'', ``verse'',
``solo'', etc. In this work, we extend an MSA algorithm called the Correlation
Block-Matching (CBM) algorithm introduced by (Marmoret et al., 2020, 2022b).
The CBM algorithm is a dynamic programming algorithm that segments
self-similarity matrices, which are a standard description used in MSA and in
numerous other applications. In this work, self-similarity matrices are
computed from the feature representation of an audio signal and time is sampled
at the bar-scale. This study examines three different standard similarity
functions for the computation of self-similarity matrices. Results show that,
in optimal conditions, the proposed algorithm achieves a level of performance
which is competitive with supervised state-of-the-art methods while only
requiring knowledge of bar positions. In addition, the algorithm is made
open-source and is highly customizable.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18605" title="Abstract">arXiv:2311.18605</a> [<a href="/pdf/2311.18605" title="Download PDF">pdf</a>, <a href="/format/2311.18605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Triangular Distribution in Visual World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Ping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengtao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dichao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Peng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yanlin Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Convolution neural network is successful in pervasive vision tasks, including
label distribution learning, which usually takes the form of learning an
injection from the non-linear visual features to the well-defined labels.
However, how the discrepancy between features is mapped to the label
discrepancy is ambient, and its correctness is not guaranteed.To address these
problems, we study the mathematical connection between feature and its label,
presenting a general and simple framework for label distribution learning. We
propose a so-called Triangular Distribution Transform (TDT) to build an
injective function between feature and label, guaranteeing that any symmetric
feature discrepancy linearly reflects the difference between labels. The
proposed TDT can be used as a plug-in in mainstream backbone networks to
address different label distribution learning tasks. Experiments on Facial Age
Recognition, Illumination Chromaticity Estimation, and Aesthetics assessment
show that TDT achieves on-par or better results than the prior arts.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18608" title="Abstract">arXiv:2311.18608</a> [<a href="/pdf/2311.18608" title="Download PDF">pdf</a>, <a href="/format/2311.18608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Denoising Score for Text-guided Latent Diffusion Image  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Hyelin Nam</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+G">Gihyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G+Y">Geon Yeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://hyelinnam.github.io/CDS/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the remarkable advent of text-to-image diffusion models, image editing
methods have become more diverse and continue to evolve. A promising recent
approach in this realm is Delta Denoising Score (DDS) - an image editing
technique based on Score Distillation Sampling (SDS) framework that leverages
the rich generative prior of text-to-image diffusion models. However, relying
solely on the difference between scoring functions is insufficient for
preserving specific structural elements from the original image, a crucial
aspect of image editing. Inspired by the similarity and importance differences
between DDS and the contrastive learning for unpaired image-to-image
translation (CUT), here we present an embarrassingly simple yet very powerful
modification of DDS, called Contrastive Denoising Score (CDS), for latent
diffusion models (LDM). Specifically, to enforce structural correspondence
between the input and output while maintaining the controllability of contents,
we introduce a straightforward approach to regulate structural consistency
using CUT loss within the DDS framework. To calculate this loss, instead of
employing auxiliary networks, we utilize the intermediate features of LDM, in
particular, those from the self-attention layers, which possesses rich spatial
information. Our approach enables zero-shot image-to-image translation and
neural radiance field (NeRF) editing, achieving a well-balanced interplay
between maintaining the structural details and transforming content.
Qualitative results and comparisons demonstrates the effectiveness of our
proposed method. Project page with code is available at
https://hyelinnam.github.io/CDS/.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18609" title="Abstract">arXiv:2311.18609</a> [<a href="/pdf/2311.18609" title="Download PDF">pdf</a>, <a href="/format/2311.18609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArthModel: Enhance Arithmetic Skills to Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yingdi Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the great success of ChatGPT, the research of large language models has
become increasingly popular. However, the models have several limitations, such
as toxicity and pool performance of arithmetic solving. Meanwhile, LLM may have
some potential abilities that have yet to be exploited. In this paper, we
choose a different way to enhance the arithmetic ability of LLM. We propose to
train LLM to generate a postfix expression related to the arithmetic problem
and incorporate it with small pretrained models. Moreover, this small model
transfers the token embeddings into real dense numbers and invokes native
functions of a deep learning platform to get the correct answer. To generate
the final result, we propose prompt injection for adding the result outputs by
the small model to LLM. This work provides different ways of thinking, training
and using a language model. The codes and models will be released at
\url{https://github.com/eteced/arithmetic_finetuning_v1}.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18610" title="Abstract">arXiv:2311.18610</a> [<a href="/pdf/2311.18610" title="Download PDF">pdf</a>, <a href="/format/2311.18610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffCAD: Weakly-Supervised Probabilistic CAD Model Retrieval and  Alignment from an RGB Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daoyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Rozenberszki%2C+D">D&#xe1;vid Rozenberszki</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://daoyig.github.io/DiffCAD/">this https URL</a> Video: <a href="https://www.youtube.com/watch?v=PCursyPosMY">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Perceiving 3D structures from RGB images based on CAD model primitives can
enable an effective, efficient 3D object-based representation of scenes.
However, current approaches rely on supervision from expensive annotations of
CAD models associated with real images, and encounter challenges due to the
inherent ambiguities in the task -- both in depth-scale ambiguity in monocular
perception, as well as inexact matches of CAD database models to real
observations. We thus propose DiffCAD, the first weakly-supervised
probabilistic approach to CAD retrieval and alignment from an RGB image. We
formulate this as a conditional generative task, leveraging diffusion to learn
implicit probabilistic models capturing the shape, pose, and scale of CAD
objects in an image. This enables multi-hypothesis generation of different
plausible CAD reconstructions, requiring only a few hypotheses to characterize
ambiguities in depth/scale and inexact shape matches. Our approach is trained
only on synthetic data, leveraging monocular depth and mask estimates to enable
robust zero-shot adaptation to various real target domains. Despite being
trained solely on synthetic data, our multi-hypothesis approach can even
surpass the supervised state-of-the-art on the Scan2CAD dataset by 5.9% with 8
hypotheses.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18614" title="Abstract">arXiv:2311.18614</a> [<a href="/pdf/2311.18614" title="Download PDF">pdf</a>, <a href="/ps/2311.18614" title="Download PostScript">ps</a>, <a href="/format/2311.18614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomy and Physiology of Artificial Intelligence in PET Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradshaw%2C+T+J">Tyler J. Bradshaw</a>, 
<a href="/search/cs?searchtype=author&query=McMillan%2C+A+B">Alan B. McMillan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PET Clin; 16(4):471-482 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The influence of artificial intelligence (AI) within the field of nuclear
medicine has been rapidly growing. Many researchers and clinicians are seeking
to apply AI within PET, and clinicians will soon find themselves engaging with
AI-based applications all along the chain of molecular imaging, from image
reconstruction to enhanced reporting. This expanding presence of AI in PET
imaging will result in greater demand for educational resources for those
unfamiliar with AI. The objective of this article to is provide an illustrated
guide to the core principles of modern AI, with specific focus on aspects that
are most likely to be encountered in PET imaging. We describe convolutional
neural networks, algorithm training, and explain the components of the commonly
used U-Net for segmentation and image synthesis.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18615" title="Abstract">arXiv:2311.18615</a> [<a href="/pdf/2311.18615" title="Download PDF">pdf</a>, <a href="/ps/2311.18615" title="Download PostScript">ps</a>, <a href="/format/2311.18615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-scale exponential integrators with uniform accuracy for  three-dimensional charged-particle dynamics under strong magnetic field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/math?searchtype=author&query=Miao%2C+Z">Zhen Miao</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yaolin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The numerical simulation of three-dimensional charged-particle dynamics (CPD)
under strong magnetic field is challenging. In this paper, we introduce a new
methodology to design two-scale exponential integrators for three-dimensional
CPD whose magnetic field's strength is inversely proportional to a
dimensionless parameter $0&lt;\varepsilon \ll 1$. By dealing with the transformed
form of three-dimensional CPD, we linearize the magnetic field and put the rest
part in a nonlinear function which can be shown to be small. Based on which and
the proposed two-scale exponential integrators, a class of novel integrators is
formulated. The corresponding uniform accuracy over
$\mathcal{O}(1/\varepsilon^{\beta})$ time interval is
$\mathcal{O}(\varepsilon^{r\beta} h^r)$ for the $r$-th order integrator with
the time stepsize $h$, $r=1,2,3,4$ and $0&lt;\beta&lt;1$. A rigorous proof of this
error bound is presented and a numerical test is performed to illustrate the
error behaviour of the proposed integrators.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18618" title="Abstract">arXiv:2311.18618</a> [<a href="/pdf/2311.18618" title="Download PDF">pdf</a>, <a href="/format/2311.18618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JPPF: Multi-task Fusion for Consistent Panoptic-Part Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muralidhara%2C+S">Shishir Muralidhara</a>, 
<a href="/search/cs?searchtype=author&query=Jagadeesh%2C+S+K">Sravan Kumar Jagadeesh</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+R">Ren&#xe9; Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Stricker%2C+D">Didier Stricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Springer Nature Computer Science. arXiv admin note: substantial text overlap with <a href="/abs/2212.07671">arXiv:2212.07671</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Part-aware panoptic segmentation is a problem of computer vision that aims to
provide a semantic understanding of the scene at multiple levels of
granularity. More precisely, semantic areas, object instances, and semantic
parts are predicted simultaneously. In this paper, we present our Joint
Panoptic Part Fusion (JPPF) that combines the three individual segmentations
effectively to obtain a panoptic-part segmentation. Two aspects are of utmost
importance for this: First, a unified model for the three problems is desired
that allows for mutually improved and consistent representation learning.
Second, balancing the combination so that it gives equal importance to all
individual results during fusion. Our proposed JPPF is parameter-free and
dynamically balances its input. The method is evaluated and compared on the
Cityscapes Panoptic Parts (CPP) and Pascal Panoptic Parts (PPP) datasets in
terms of PartPQ and Part-Whole Quality (PWQ). In extensive experiments, we
verify the importance of our fair fusion, highlight its most significant impact
for areas that can be further segmented into parts, and demonstrate the
generalization capabilities of our design without fine-tuning on 5 additional
datasets.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18620" title="Abstract">arXiv:2311.18620</a> [<a href="/pdf/2311.18620" title="Download PDF">pdf</a>, <a href="/format/2311.18620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven prediction of tool wear using Bayesian-regularized  artificial neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T+T">Tam T. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Airao%2C+J">Jay Airao</a>, 
<a href="/search/cs?searchtype=author&query=Karras%2C+P">Panagiotis Karras</a>, 
<a href="/search/cs?searchtype=author&query=Hojati%2C+F">Faramarz Hojati</a>, 
<a href="/search/cs?searchtype=author&query=Azarhoushang%2C+B">Bahman Azarhoushang</a>, 
<a href="/search/cs?searchtype=author&query=Aghababaei%2C+R">Ramin Aghababaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prediction of tool wear helps minimize costs and enhance product quality
in manufacturing. While existing data-driven models using machine learning and
deep learning have contributed to the accurate prediction of tool wear, they
often lack generality and require substantial training data for high accuracy.
In this paper, we propose a new data-driven model that uses Bayesian
Regularized Artificial Neural Networks (BRANNs) to precisely predict milling
tool wear. BRANNs combine the strengths and leverage the benefits of artificial
neural networks (ANNs) and Bayesian regularization, whereby ANNs learn complex
patterns and Bayesian regularization handles uncertainty and prevents
overfitting, resulting in a more generalized model. We treat both process
parameters and monitoring sensor signals as BRANN input parameters. We
conducted an extensive experimental study featuring four different experimental
data sets, including the NASA Ames milling dataset, the 2010 PHM Data Challenge
dataset, the NUAA Ideahouse tool wear dataset, and an in-house performed
end-milling of the Ti6Al4V dataset. We inspect the impact of input features,
training data size, hidden units, training algorithms, and transfer functions
on the performance of the proposed BRANN model and demonstrate that it
outperforms existing state-of-the-art models in terms of accuracy and
reliability.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18628" title="Abstract">arXiv:2311.18628</a> [<a href="/pdf/2311.18628" title="Download PDF">pdf</a>, <a href="/format/2311.18628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Clustering Framework for Unsupervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y+S+J">Yau Shing Jonathan Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lihe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised semantic segmentation aims to label each pixel of an image to a
corresponding class without the use of annotated data. It is a widely
researched area as obtaining labeled datasets are expensive. While previous
works in the field demonstrated a gradual improvement in segmentation
performance, most of them required neural network training. This made
segmentation equally expensive, especially when dealing with large-scale
datasets. We thereby propose a lightweight clustering framework for
unsupervised semantic segmentation. Attention features of the self-supervised
vision transformer exhibit strong foreground-background differentiability. By
clustering these features into a small number of clusters, we could separate
foreground and background image patches into distinct groupings. In our
clustering framework, we first obtain attention features from the
self-supervised vision transformer. Then we extract Dataset-level,
Category-level and Image-level masks by clustering features within the same
dataset, category and image. We further ensure multilevel clustering
consistency across the three levels and this allows us to extract patch-level
binary pseudo-masks. Finally, the pseudo-mask is upsampled, refined and class
assignment is performed according to the CLS token of object regions. Our
framework demonstrates great promise in unsupervised semantic segmentation and
achieves state-of-the-art results on PASCAL VOC and MS COCO datasets.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18630" title="Abstract">arXiv:2311.18630</a> [<a href="/pdf/2311.18630" title="Download PDF">pdf</a>, <a href="/format/2311.18630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SATHUR: Self Augmenting Task Hallucinal Unified Representation for  Generalized Class Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanagarajah%2C+S">Sathursan Kanagarajah</a>, 
<a href="/search/cs?searchtype=author&query=Ambegoda%2C+T">Thanuja Ambegoda</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigo%2C+R">Ranga Rodrigo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, ICCVW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class Incremental Learning (CIL) is inspired by the human ability to learn
new classes without forgetting previous ones. CIL becomes more challenging in
real-world scenarios when the samples in each incremental step are imbalanced.
This creates another branch of problem, called Generalized Class Incremental
Learning (GCIL) where each incremental step is structured more realistically.
Grow When Required (GWR) network, a type of Self-Organizing Map (SOM),
dynamically create and remove nodes and edges for adaptive learning. GWR
performs incremental learning from feature vectors extracted by a Convolutional
Neural Network (CNN), which acts as a feature extractor. The inherent ability
of GWR to form distinct clusters, each corresponding to a class in the feature
vector space, regardless of the order of samples or class imbalances, is well
suited to achieving GCIL. To enhance GWR's classification performance, a
high-quality feature extractor is required. However, when the convolutional
layers are adapted at each incremental step, the GWR nodes corresponding to
prior knowledge are subject to near-invalidation. This work introduces the Self
Augmenting Task Hallucinal Unified Representation (SATHUR), which
re-initializes the GWR network at each incremental step, aligning it with the
current feature extractor. Comprehensive experimental results demonstrate that
our proposed method significantly outperforms other state-of-the-art GCIL
methods on CIFAR-100 and CORe50 datasets.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18635" title="Abstract">arXiv:2311.18635</a> [<a href="/pdf/2311.18635" title="Download PDF">pdf</a>, <a href="/format/2311.18635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirschstein%2C+T">Tobias Kirschstein</a>, 
<a href="/search/cs?searchtype=author&query=Giebenhain%2C+S">Simon Giebenhain</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://tobias-kirschstein.github.io/diffusion-avatars/">this https URL</a> , Video: <a href="https://youtu.be/nSjDiiTnp2E">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">DiffusionAvatars synthesizes a high-fidelity 3D head avatar of a person,
offering intuitive control over both pose and expression. We propose a
diffusion-based neural renderer that leverages generic 2D priors to produce
compelling images of faces. For coarse guidance of the expression and head
pose, we render a neural parametric head model (NPHM) from the target
viewpoint, which acts as a proxy geometry of the person. Additionally, to
enhance the modeling of intricate facial expressions, we condition
DiffusionAvatars directly on the expression codes obtained from NPHM via
cross-attention. Finally, to synthesize consistent surface details across
different viewpoints and expressions, we rig learnable spatial features to the
head's surface via TriPlane lookup in NPHM's canonical space. We train
DiffusionAvatars on RGB videos and corresponding tracked NPHM meshes of a
person and test the obtained avatars in both self-reenactment and animation
scenarios. Our experiments demonstrate that DiffusionAvatars generates
temporally consistent and visually appealing videos for novel poses and
expressions of a person, outperforming existing approaches.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18636" title="Abstract">arXiv:2311.18636</a> [<a href="/pdf/2311.18636" title="Download PDF">pdf</a>, <a href="/format/2311.18636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Autonomous Driving using Deep Learning: A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Apoorv Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, submitted in WACV conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">End-to-end autonomous driving is a fully differentiable machine learning
system that takes raw sensor input data and other metadata as prior information
and directly outputs the ego vehicle's control signals or planned trajectories.
This paper attempts to systematically review all recent Machine Learning-based
techniques to perform this end-to-end task, including, but not limited to,
object detection, semantic scene understanding, object tracking, trajectory
predictions, trajectory planning, vehicle control, social behavior, and
communications. This paper focuses on recent fully differentiable end-to-end
reinforcement learning and deep learning-based techniques. Our paper also
builds taxonomies of the significant approaches by sub-grouping them and
showcasing their research trends. Finally, this survey highlights the open
challenges and points out possible future directions to enlighten further
research on the topic.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18641" title="Abstract">arXiv:2311.18641</a> [<a href="/pdf/2311.18641" title="Download PDF">pdf</a>, <a href="/format/2311.18641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrimeGAT: Leveraging Graph Attention Networks for Enhanced Predictive  Policing in Criminal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In this paper, we present CrimeGAT, a novel application of Graph Attention
Networks (GATs) for predictive policing in criminal networks. Criminal networks
pose unique challenges for predictive analytics due to their complex structure,
multi-relational links, and dynamic behavior. Traditional methods often fail to
capture these complexities, leading to suboptimal predictions. To address these
challenges, we propose the use of GATs, which can effectively leverage both
node features and graph structure to make predictions. Our proposed CrimeGAT
model integrates attention mechanisms to weigh the importance of a node's
neighbors, thereby capturing the local and global structures of criminal
networks. We formulate the problem as learning a function that maps node
features and graph structure to a prediction of future criminal activity. The
experimental results on real-world datasets demonstrate that CrimeGAT
out-performs conventional methods in predicting criminal activities, thereby
providing a powerful tool for law enforcement agencies to proactively deploy
resources. Furthermore, the interpretable nature of the attentionmechanism
inGATs offers insights into the key players and relationships in criminal
networks. This research opens new avenues for applying deep learning techniques
in the Aeld of predictive policing and criminal network analysis.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18643" title="Abstract">arXiv:2311.18643</a> [<a href="/pdf/2311.18643" title="Download PDF">pdf</a>, <a href="/format/2311.18643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoT-based Analysis for Smart Energy Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+G">Guang-Li Huang</a>, 
<a href="/search/eess?searchtype=author&query=Anwar%2C+A">Adnan Anwar</a>, 
<a href="/search/eess?searchtype=author&query=Loke%2C+S+W">Seng W. Loke</a>, 
<a href="/search/eess?searchtype=author&query=Zaslavsky%2C+A">Arkady Zaslavsky</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Jinho Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Smart energy management based on the Internet of Things (IoT) aims to achieve
optimal energy utilization through real-time energy monitoring and analyses of
power consumption patterns in IoT networks (e.g., residential homes and
offices) supported by wireless technologies. This is of great significance for
the sustainable development of energy. Energy disaggregation is an important
technology to realize smart energy management, as it can determine the power
consumption of each appliance from the total load (e.g., aggregated data).
Also, it gives us clear insights into users' daily power-consumption-related
behaviours, which can enhance their awareness of power-saving and lead them to
a more sustainable lifestyle. This paper reviews the state-of-the-art
algorithms for energy disaggregation and public datasets of power consumption.
Also, potential use cases for smart energy management based on IoT networks are
presented along with a discussion of open issues for future study.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18644" title="Abstract">arXiv:2311.18644</a> [<a href="/pdf/2311.18644" title="Download PDF">pdf</a>, <a href="/format/2311.18644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the hierarchical structure of human plans via program  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Correa%2C+C+G">Carlos G. Correa</a>, 
<a href="/search/cs?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+M+K">Mark K. Ho</a>, 
<a href="/search/cs?searchtype=author&query=Callaway%2C+F">Frederick Callaway</a>, 
<a href="/search/cs?searchtype=author&query=Daw%2C+N+D">Nathaniel D. Daw</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Human behavior is inherently hierarchical, resulting from the decomposition
of a task into subtasks or an abstract action into concrete actions. However,
behavior is typically measured as a sequence of actions, which makes it
difficult to infer its hierarchical structure. In this paper, we explore how
people form hierarchically-structured plans, using an experimental paradigm
that makes hierarchical representations observable: participants create
programs that produce sequences of actions in a language with explicit
hierarchical structure. This task lets us test two well-established principles
of human behavior: utility maximization (i.e. using fewer actions) and minimum
description length (MDL; i.e. having a shorter program). We find that humans
are sensitive to both metrics, but that both accounts fail to predict a
qualitative feature of human-created programs, namely that people prefer
programs with reuse over and above the predictions of MDL. We formalize this
preference for reuse by extending the MDL account into a generative model over
programs, modeling hierarchy choice as the induction of a grammar over actions.
Our account can explain the preference for reuse and provides the best
prediction of human behavior, going beyond simple accounts of compressibility
to highlight a principle that guides hierarchical planning.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18645" title="Abstract">arXiv:2311.18645</a> [<a href="/pdf/2311.18645" title="Download PDF">pdf</a>, <a href="/format/2311.18645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Vision Transformers with Wasserstein Distance-Aware Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erick%2C+F+X">Franciskus Xaverius Erick</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+M">Mina Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J+P">Johanna Paula M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-supervised learning is one of the most promising approaches to acquiring
knowledge from limited labeled data. Despite the substantial advancements made
in recent years, self-supervised models have posed a challenge to
practitioners, as they do not readily provide insight into the model's
confidence and uncertainty. Tackling this issue is no simple feat, primarily
due to the complexity involved in implementing techniques that can make use of
the latent representations learned during pre-training without relying on
explicit labels. Motivated by this, we introduce a new stochastic vision
transformer that integrates uncertainty and distance awareness into
self-supervised learning (SSL) pipelines. Instead of the conventional
deterministic vector embedding, our novel stochastic vision transformer encodes
image patches into elliptical Gaussian distributional embeddings. Notably, the
attention matrices of these stochastic representational embeddings are computed
using Wasserstein distance-based attention, effectively capitalizing on the
distributional nature of these embeddings. Additionally, we propose a
regularization term based on Wasserstein distance for both pre-training and
fine-tuning processes, thereby incorporating distance awareness into latent
representations. We perform extensive experiments across different tasks such
as in-distribution generalization, out-of-distribution detection, dataset
corruption, semi-supervised settings, and transfer learning to other datasets
and tasks. Our proposed method achieves superior accuracy and calibration,
surpassing the self-supervised baseline in a wide range of experiments on a
variety of datasets.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18646" title="Abstract">arXiv:2311.18646</a> [<a href="/pdf/2311.18646" title="Download PDF">pdf</a>, <a href="/format/2311.18646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust-to-Noise Algorithms for Distributed Resource Allocation and  Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Doostmohammadian%2C+M">Mohammadreza Doostmohammadian</a>, 
<a href="/search/eess?searchtype=author&query=Aghasi%2C+A">Alireza Aghasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/RSI ICRoM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
<p class="mathjax">Efficient resource allocation and scheduling algorithms are essential for
various distributed applications, ranging from wireless networks and cloud
computing platforms to autonomous multi-agent systems and swarm robotic
networks. However, real-world environments are often plagued by uncertainties
and noise, leading to sub-optimal performance and increased vulnerability of
traditional algorithms. This paper addresses the challenge of robust resource
allocation and scheduling in the presence of noise and disturbances. The
proposed study introduces a novel sign-based dynamics for developing
robust-to-noise algorithms distributed over a multi-agent network that can
adaptively handle external disturbances. Leveraging concepts from convex
optimization theory, control theory, and network science the framework
establishes a principled approach to design algorithms that can maintain key
properties such as resource-demand balance and constraint feasibility.
Meanwhile, notions of uniform-connectivity and versatile networking conditions
are also addressed.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18649" title="Abstract">arXiv:2311.18649</a> [<a href="/pdf/2311.18649" title="Download PDF">pdf</a>, <a href="/format/2311.18649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Semantic-Aided Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shanlin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning from a limited amount of data, namely Few-Shot Learning, stands out
as a challenging computer vision task. Several works exploit semantics and
design complicated semantic fusion mechanisms to compensate for rare
representative features within restricted data. However, relying on naive
semantics such as class names introduces biases due to their brevity, while
acquiring extensive semantics from external knowledge takes a huge time and
effort. This limitation severely constrains the potential of semantics in
few-shot learning. In this paper, we design an automatic way called Semantic
Evolution to generate high-quality semantics. The incorporation of high-quality
semantics alleviates the need for complex network structures and learning
algorithms used in previous works. Hence, we employ a simple two-layer network
termed Semantic Alignment Network to transform semantics and visual features
into robust class prototypes with rich discriminative features for few-shot
classification. The experimental results show our framework outperforms all
previous methods on five benchmarks, demonstrating a simple network with
high-quality semantics can beat intricate multi-modal modules on few-shot
classification tasks.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18651" title="Abstract">arXiv:2311.18651</a> [<a href="/pdf/2311.18651" title="Download PDF">pdf</a>, <a href="/format/2311.18651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding,  Reasoning, and Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sijin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://ll3da.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in Large Multimodal Models (LMM) have made it possible for
various applications in human-machine interactions. However, developing LMMs
that can comprehend, reason, and plan in complex and diverse 3D environments
remains a challenging topic, especially considering the demand for
understanding permutation-invariant point cloud 3D representations of the 3D
scene. Existing works seek help from multi-view images, and project 2D features
to 3D space as 3D scene representations. This, however, leads to huge
computational overhead and performance degradation. In this paper, we present
LL3DA, a Large Language 3D Assistant that takes point cloud as direct input and
respond to both textual-instructions and visual-prompts. This help LMMs better
comprehend human interactions and further help to remove the ambiguities in
cluttered 3D scenes. Experiments show that LL3DA achieves remarkable results,
and surpasses various 3D vision-language models on both 3D Dense Captioning and
3D Question Answering.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18654" title="Abstract">arXiv:2311.18654</a> [<a href="/pdf/2311.18654" title="Download PDF">pdf</a>, <a href="/format/2311.18654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detailed Human-Centric Text Description-Driven Large Scene Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gwanghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D+U">Dong Un Kang</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+H">Hoigi Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hayeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S+Y">Se Young Chun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-driven large scene image synthesis has made significant progress with
diffusion models, but controlling it is challenging. While using additional
spatial controls with corresponding texts has improved the controllability of
large scene synthesis, it is still challenging to faithfully reflect detailed
text descriptions without user-provided controls. Here, we propose
DetText2Scene, a novel text-driven large-scale image synthesis with high
faithfulness, controllability, and naturalness in a global context for the
detailed human-centric text description. Our DetText2Scene consists of 1)
hierarchical keypoint-box layout generation from the detailed description by
leveraging large language model (LLM), 2) view-wise conditioned joint diffusion
process to synthesize a large scene from the given detailed text with
LLM-generated grounded keypoint-box layout and 3) pixel perturbation-based
pyramidal interpolation to progressively refine the large scene for global
coherence. Our DetText2Scene significantly outperforms prior arts in
text-to-large scene synthesis qualitatively and quantitatively, demonstrating
strong faithfulness with detailed descriptions, superior controllability, and
excellent naturalness in a global context.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18655" title="Abstract">arXiv:2311.18655</a> [<a href="/pdf/2311.18655" title="Download PDF">pdf</a>, <a href="/format/2311.18655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OISA: Architecting an Optical In-Sensor Accelerator for Efficient Visual  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morsali%2C+M">Mehrdad Morsali</a>, 
<a href="/search/cs?searchtype=author&query=Tabrizchi%2C+S">Sepehr Tabrizchi</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+D">Deniz Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Imani%2C+M">Mohsen Imani</a>, 
<a href="/search/cs?searchtype=author&query=Nikdast%2C+M">Mahdi Nikdast</a>, 
<a href="/search/cs?searchtype=author&query=Roohi%2C+A">Arman Roohi</a>, 
<a href="/search/cs?searchtype=author&query=Angizi%2C+S">Shaahin Angizi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Targeting vision applications at the edge, in this work, we systematically
explore and propose a high-performance and energy-efficient Optical In-Sensor
Accelerator architecture called OISA for the first time. Taking advantage of
the promising efficiency of photonic devices, the OISA intrinsically implements
a coarse-grained convolution operation on the input frames in an innovative
minimum-conversion fashion in low-bit-width neural networks. Such a design
remarkably reduces the power consumption of data conversion, transmission, and
processing in the conventional cloud-centric architecture as well as
recently-presented edge accelerators. Our device-to-architecture simulation
results on various image data-sets demonstrate acceptable accuracy while OISA
achieves 6.68 TOp/s/W efficiency. OISA reduces power consumption by a factor of
7.9 and 18.4 on average compared with existing electronic in-/near-sensor and
ASIC accelerators.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18656" title="Abstract">arXiv:2311.18656</a> [<a href="/pdf/2311.18656" title="Download PDF">pdf</a>, <a href="/format/2311.18656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Lebesgue constants by Chebyshev polynomial meshes on cube,  simplex and ball
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bialas-Ciez%2C+L">L. Bialas-Ciez</a>, 
<a href="/search/math?searchtype=author&query=Kenne%2C+D+J">D.J. Kenne</a>, 
<a href="/search/math?searchtype=author&query=Sommariva%2C+A">A. Sommariva</a>, 
<a href="/search/math?searchtype=author&query=Vianello%2C+M">M. Vianello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We show that product Chebyshev polynomial meshes can be used, in a fully
discrete way, to evaluate with rigorous error bounds the Lebesgue constant,
i.e. the maximum of the Lebesgue function, for a class of polynomial projectors
on cube, simplex and ball, including interpolation, hyperinterpolation and
weighted least-squares. Several examples are presented and possible
generalizations outlined. A numerical software package implementing the method
is freely available online.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18657" title="Abstract">arXiv:2311.18657</a> [<a href="/pdf/2311.18657" title="Download PDF">pdf</a>, <a href="/ps/2311.18657" title="Download PostScript">ps</a>, <a href="/format/2311.18657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extension and convergence analysis of Iterative Filtering to spherical  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barbarino%2C+G">Giovanni Barbarino</a>, 
<a href="/search/math?searchtype=author&query=Cavassi%2C+R">Roberto Cavassi</a>, 
<a href="/search/math?searchtype=author&query=Cicone%2C+A">Antonio Cicone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Many real-life signals are defined on spherical domains, in particular in
geophysics and physics applications. In this work, we tackle the problem of
extending the iterative filtering algorithm, developed for the decomposition of
non-stationary signals defined in Euclidean spaces, to spherical domains. We
review the properties of the classical Iterative Filtering method, present its
extension, and study its convergence in the discrete setting. In particular, by
leveraging the Generalized Locally Toeplitz sequence theory, we are able to
characterize spectrally the operators associated with the spherical extension
of Iterative Filtering, and we show a counterexample of its convergence.
Finally, we propose a convergent version, called Spherical Iterative Filtering,
and present numerical results of its application to spherical data.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18658" title="Abstract">arXiv:2311.18658</a> [<a href="/pdf/2311.18658" title="Download PDF">pdf</a>, <a href="/format/2311.18658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArcMMLU: A Library and Information Science Benchmark for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shitou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xingshen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In light of the rapidly evolving capabilities of large language models
(LLMs), it becomes imperative to develop rigorous domain-specific evaluation
benchmarks to accurately assess their capabilities. In response to this need,
this paper introduces ArcMMLU, a specialized benchmark tailored for the Library
&amp; Information Science (LIS) domain in Chinese. This benchmark aims to measure
the knowledge and reasoning capability of LLMs within four key sub-domains:
Archival Science, Data Science, Library Science, and Information Science.
Following the format of MMLU/CMMLU, we collected over 6,000 high-quality
questions for the compilation of ArcMMLU. This extensive compilation can
reflect the diverse nature of the LIS domain and offer a robust foundation for
LLM evaluation. Our comprehensive evaluation reveals that while most mainstream
LLMs achieve an average accuracy rate above 50% on ArcMMLU, there remains a
notable performance gap, suggesting substantial headroom for refinement in LLM
capabilities within the LIS domain. Further analysis explores the effectiveness
of few-shot examples on model performance and highlights challenging questions
where models consistently underperform, providing valuable insights for
targeted improvements. ArcMMLU fills a critical gap in LLM evaluations within
the Chinese LIS domain and paves the way for future development of LLMs
tailored to this specialized area.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18659" title="Abstract">arXiv:2311.18659</a> [<a href="/pdf/2311.18659" title="Download PDF">pdf</a>, <a href="/format/2311.18659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Autoscaling Frameworks for Containerised  Machine-Learning-Applications in a Local and Cloud Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schroeder%2C+C">Christian Schroeder</a>, 
<a href="/search/cs?searchtype=author&query=Boehm%2C+R">Rene Boehm</a>, 
<a href="/search/cs?searchtype=author&query=Lampe%2C+A">Alexander Lampe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">When deploying machine learning (ML) applications, the automated allocation
of computing resources-commonly referred to as autoscaling-is crucial for
maintaining a consistent inference time under fluctuating workloads. The
objective is to maximize the Quality of Service metrics, emphasizing
performance and availability, while minimizing resource costs. In this paper,
we compare scalable deployment techniques across three levels of scaling: at
the application level (TorchServe, RayServe) and the container level (K3s) in a
local environment (production server), as well as at the container and machine
levels in a cloud environment (Amazon Web Services Elastic Container Service
and Elastic Kubernetes Service). The comparison is conducted through the study
of mean and standard deviation of inference time in a multi-client scenario,
along with upscaling response times. Based on this analysis, we propose a
deployment strategy for both local and cloud-based environments.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18661" title="Abstract">arXiv:2311.18661</a> [<a href="/pdf/2311.18661" title="Download PDF">pdf</a>, <a href="/format/2311.18661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Part Segmentation from Synthetic Animals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiawei Peng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Ju He</a>, 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+P">Prakhar Kaushik</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zihao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+J">Jiteng Mu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic part segmentation provides an intricate and interpretable
understanding of an object, thereby benefiting numerous downstream tasks.
However, the need for exhaustive annotations impedes its usage across diverse
object types. This paper focuses on learning part segmentation from synthetic
animals, leveraging the Skinned Multi-Animal Linear (SMAL) models to scale up
existing synthetic data generated by computer-aided design (CAD) animal models.
Compared to CAD models, SMAL models generate data with a wider range of poses
observed in real-world scenarios. As a result, our first contribution is to
construct a synthetic animal dataset of tigers and horses with more pose
diversity, termed Synthetic Animal Parts (SAP). We then benchmark Syn-to-Real
animal part segmentation from SAP to PartImageNet, namely SynRealPart, with
existing semantic segmentation domain adaptation methods and further improve
them as our second contribution. Concretely, we examine three Syn-to-Real
adaptation methods but observe relative performance drop due to the innate
difference between the two tasks. To address this, we propose a simple yet
effective method called Class-Balanced Fourier Data Mixing (CB-FDM). Fourier
Data Mixing aligns the spectral amplitudes of synthetic images with real
images, thereby making the mixed images have more similar frequency content to
real images. We further use Class-Balanced Pseudo-Label Re-Weighting to
alleviate the imbalanced class distribution. We demonstrate the efficacy of
CB-FDM on SynRealPart over previous methods with significant performance
improvements. Remarkably, our third contribution is to reveal that the learned
parts from synthetic tiger and horse are transferable across all quadrupeds in
PartImageNet, further underscoring the utility and potential applications of
animal part segmentation.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18662" title="Abstract">arXiv:2311.18662</a> [<a href="/pdf/2311.18662" title="Download PDF">pdf</a>, <a href="/ps/2311.18662" title="Download PostScript">ps</a>, <a href="/format/2311.18662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the Team Orienteering Problem with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuertes%2C+D">Daniel Fuertes</a>, 
<a href="/search/cs?searchtype=author&query=del-Blanco%2C+C+R">Carlos R. del-Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Jaureguizar%2C+F">Fernando Jaureguizar</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+N">Narciso Garc&#xed;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Route planning for a fleet of vehicles is an important task in applications
such as package delivery, surveillance, or transportation. This problem is
usually modeled as a Combinatorial Optimization problem named as Team
Orienteering Problem. The most popular Team Orienteering Problem solvers are
mainly based on either linear programming, which provides accurate solutions by
employing a large computation time that grows with the size of the problem, or
heuristic methods, which usually find suboptimal solutions in a shorter amount
of time. In this paper, a multi-agent route planning system capable of solving
the Team Orienteering Problem in a very fast and accurate manner is presented.
The proposed system is based on a centralized Transformer neural network that
can learn to encode the scenario (modeled as a graph) and the context of the
agents to provide fast and accurate solutions. Several experiments have been
performed to demonstrate that the presented system can outperform most of the
state-of-the-art works in terms of computation speed. In addition, the code is
publicly available at \url{<a href="http://gti.ssr.upm.es/data">this http URL</a>}.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18664" title="Abstract">arXiv:2311.18664</a> [<a href="/pdf/2311.18664" title="Download PDF">pdf</a>, <a href="/format/2311.18664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task learning with cross-task consistency for improved depth  estimation in colonoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solano%2C+P+E+C">Pedro Esteban Chavarrias Solano</a>, 
<a href="/search/cs?searchtype=author&query=Bulpitt%2C+A">Andrew Bulpitt</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+V">Venkataraman Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Sharib Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Colonoscopy screening is the gold standard procedure for assessing
abnormalities in the colon and rectum, such as ulcers and cancerous polyps.
Measuring the abnormal mucosal area and its 3D reconstruction can help quantify
the surveyed area and objectively evaluate disease burden. However, due to the
complex topology of these organs and variable physical conditions, for example,
lighting, large homogeneous texture, and image modality estimating distance
from the camera aka depth) is highly challenging. Moreover, most colonoscopic
video acquisition is monocular, making the depth estimation a non-trivial
problem. While methods in computer vision for depth estimation have been
proposed and advanced on natural scene datasets, the efficacy of these
techniques has not been widely quantified on colonoscopy datasets. As the
colonic mucosa has several low-texture regions that are not well pronounced,
learning representations from an auxiliary task can improve salient feature
extraction, allowing estimation of accurate camera depths. In this work, we
propose to develop a novel multi-task learning (MTL) approach with a shared
encoder and two decoders, namely a surface normal decoder and a depth estimator
decoder. Our depth estimator incorporates attention mechanisms to enhance
global context awareness. We leverage the surface normal prediction to improve
geometric feature extraction. Also, we apply a cross-task consistency loss
among the two geometrically related tasks, surface normal and camera depth. We
demonstrate an improvement of 14.17% on relative error and 10.4% improvement on
$\delta_{1}$ accuracy over the most accurate baseline state-of-the-art BTS
approach. All experiments are conducted on a recently released C3VD dataset;
thus, we provide a first benchmark of state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18665" title="Abstract">arXiv:2311.18665</a> [<a href="/pdf/2311.18665" title="Download PDF">pdf</a>, <a href="/ps/2311.18665" title="Download PostScript">ps</a>, <a href="/format/2311.18665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose Estimation and Tracking for ASIST
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodman%2C+A">Ari Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurpreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shea%2C+R">Ryan O&#x27;Shea</a>, 
<a href="/search/cs?searchtype=author&query=Teague%2C+P">Peter Teague</a>, 
<a href="/search/cs?searchtype=author&query=Hing%2C+J">James Hing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures. Published in the Proceedings of the ASNE 2023 Technology, Systems &amp; Ships Symposium. Reproduced with permission from the American Society of Naval Engineers. Distribution Statement A: Approved for public release; distribution is unlimited, as submitted under NAVAIR Public Release Authorization 2023-018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Aircraft Ship Integrated Secure and Traverse (ASIST) is a system designed to
arrest helicopters safely and efficiently on ships. Originally, a precision
Helicopter Position Sensing Equipment (HPSE) tracked and monitored the position
of the helicopter relative to the Rapid Securing Device (RSD). However, using
the HPSE component was determined to be infeasible in the transition of the
ASIST system due to the hardware installation requirements. As a result,
sailors track the position of the helicopters with their eyes with no sensor or
artificially intelligent decision aid. Manually tracking the helicopter takes
additional time and makes recoveries more difficult, especially at high sea
states. Performing recoveries without the decision aid leads to higher
uncertainty and cognitive load. PETA (Pose Estimation and Tracking for ASIST)
is a research effort to create a helicopter tracking system prototype without
hardware installation requirements for ASIST system operators. Its overall goal
is to improve situational awareness and reduce operator uncertainty with
respect to the aircrafts position relative to the RSD, and consequently
increase the allowable landing area. The authors produced a prototype system
capable of tracking helicopters with respect to the RSD. The software included
a helicopter pose estimation component, camera pose estimation component, and a
user interface component. PETA demonstrated the potential for state-of-the-art
computer vision algorithms Faster R-CNN and HRNet (High-Resolution Network) to
be used to estimate the pose of helicopters in real-time, returning ASIST to
its originally intended capability. PETA also demonstrated that traditional
methods of encoder-decoders could be used to estimate the orientation of the
helicopter and could be used to confirm the output from HRNet.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18666" title="Abstract">arXiv:2311.18666</a> [<a href="/pdf/2311.18666" title="Download PDF">pdf</a>, <a href="/format/2311.18666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Recognition in Video Recordings from Gynecologic Laparoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasirihaghighi%2C+S">Sahar Nasirihaghighi</a>, 
<a href="/search/cs?searchtype=author&query=Ghamsarian%2C+N">Negin Ghamsarian</a>, 
<a href="/search/cs?searchtype=author&query=Stefanics%2C+D">Daniela Stefanics</a>, 
<a href="/search/cs?searchtype=author&query=Schoeffmann%2C+K">Klaus Schoeffmann</a>, 
<a href="/search/cs?searchtype=author&query=Husslein%2C+H">Heinrich Husslein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Action recognition is a prerequisite for many applications in laparoscopic
video analysis including but not limited to surgical training, operation room
planning, follow-up surgery preparation, post-operative surgical assessment,
and surgical outcome estimation. However, automatic action recognition in
laparoscopic surgeries involves numerous challenges such as (I) cross-action
and intra-action duration variation, (II) relevant content distortion due to
smoke, blood accumulation, fast camera motions, organ movements, object
occlusion, and (III) surgical scene variations due to different illuminations
and viewpoints. Besides, action annotations in laparoscopy surgeries are
limited and expensive due to requiring expert knowledge. In this study, we
design and evaluate a CNN-RNN architecture as well as a customized
training-inference framework to deal with the mentioned challenges in
laparoscopic surgery action recognition. Using stacked recurrent layers, our
proposed network takes advantage of inter-frame dependencies to negate the
negative effect of content distortion and variation in action recognition.
Furthermore, our proposed frame sampling strategy effectively manages the
duration variations in surgical actions to enable action recognition with high
temporal resolution. Our extensive experiments confirm the superiority of our
proposed method in action recognition compared to static CNNs.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18670" title="Abstract">arXiv:2311.18670</a> [<a href="/pdf/2311.18670" title="Download PDF">pdf</a>, <a href="/ps/2311.18670" title="Download PostScript">ps</a>, <a href="/format/2311.18670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Geometry Determines Global Landscape in Low-rank Factorization for  Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Shuyang Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC); Computation (stat.CO)

</div>
<p class="mathjax">The orthogonal group synchronization problem, which focuses on recovering
orthogonal group elements from their corrupted pairwise measurements,
encompasses examples such as high-dimensional Kuramoto model on general signed
networks, $\mathbb{Z}_2$-synchronization, community detection under stochastic
block models, and orthogonal Procrustes problem. The semidefinite relaxation
(SDR) has proven its power in solving this problem; however, its expensive
computational costs impede its widespread practical applications. We consider
the Burer-Monteiro factorization approach to the orthogonal group
synchronization, an effective and scalable low-rank factorization to solve
large scale SDPs. Despite the significant empirical successes of this
factorization approach, it is still a challenging task to understand when the
nonconvex optimization landscape is benign, i.e., the optimization landscape
possesses only one local minimizer, which is also global. In this work, we
demonstrate that if the degree of freedom within the factorization exceeds
twice the condition number of the ``Laplacian" (certificate matrix) at the
global minimizer, the optimization landscape is absent of spurious local
minima. Our main theorem is purely algebraic and versatile, and it seamlessly
applies to all the aforementioned examples: the nonconvex landscape remains
benign under almost identical condition that enables the success of the SDR.
Additionally, we illustrate that the Burer-Monteiro factorization is robust to
``monotone adversaries", mirroring the resilience of the SDR. In other words,
introducing ``favorable" adversaries into the data will not result in the
emergence of new spurious local minimizers.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18671" title="Abstract">arXiv:2311.18671</a> [<a href="/pdf/2311.18671" title="Download PDF">pdf</a>, <a href="/ps/2311.18671" title="Download PostScript">ps</a>, <a href="/format/2311.18671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution to an open problem on the closeness of graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayat%2C+F">Fazal Hayat</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shou-Jun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">A network can be analyzed by means of many graph theoretical parameters. In
the context of networks analysis, closeness is a structural metric that
evaluates a node's significance inside a network. A cactus is a connected graph
in which any block is either a cut edge or a cycle. This paper analyzes the
closeness of cacti, we determine the unique graph that minimizes the closeness
over all cacti with fixed numbers of vertices and cycles, which solves an open
problem proposed by Poklukar \&amp; \v{Z}erovnik [Fundam. Inform. 167 (2019)
219--234].
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18674" title="Abstract">arXiv:2311.18674</a> [<a href="/pdf/2311.18674" title="Download PDF">pdf</a>, <a href="/format/2311.18674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Lightweight Post-Quantum Authentication for Internet of  Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+A+A">Attila A. Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Darzi%2C+S">Saleh Darzi</a>, 
<a href="/search/cs?searchtype=author&query=Nouma%2C+S+E">Saif E. Nouma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Internet of Things (IoT) applications are composed of massive quantities of
resource-limited devices that collect sensitive data with long-term operational
and security requirements. With the threat of emerging quantum computers,
Post-Quantum Cryptography (PQC) is a critical requirement for IoTs. In
particular, digital signatures offer scalable authentication with
non-repudiation and are an essential tool for IoTs. However, as seen in NIST
PQC standardization, post-quantum signatures are extremely costly for
resource-limited IoTs. Hence, there is a significant need for quantum-safe
signatures that respect the processing, memory, and bandwidth limitations of
IoTs. In this paper, we created a new lightweight quantum-safe digital
signature referred to as INFinity-HORS (INF-HORS), which is (to the best of our
knowledge) the first signer-optimal hash-based signature with (polynomially)
unbounded signing capability. INF-HORS enables a verifier to non-interactively
construct one-time public keys from a master public key via encrypted function
evaluations. This strategy avoids the performance bottleneck of hash-based
standards (e.g., SPHINCS+) by eliminating hyper-tree structures. It also does
not require a trusted party or non-colliding servers to distribute public keys.
Our performance analysis confirms that INF-HORS is magnitudes of times more
signer computation efficient than selected NIST PQC schemes (e.g., SPHINCS+,
Dilithium, Falcon) with a small memory footprint.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18675" title="Abstract">arXiv:2311.18675</a> [<a href="/pdf/2311.18675" title="Download PDF">pdf</a>, <a href="/format/2311.18675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascaded Interaction with Eroded Deep Supervision for Salient Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hewen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jie Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guangfu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weiren Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep convolutional neural networks have been widely applied in salient object
detection and have achieved remarkable results in this field. However, existing
models suffer from information distortion caused by interpolation during
up-sampling and down-sampling. In response to this drawback, this article
starts from two directions in the network: feature and label. On the one hand,
a novel cascaded interaction network with a guidance module named global-local
aligned attention (GAA) is designed to reduce the negative impact of
interpolation on the feature side. On the other hand, a deep supervision
strategy based on edge erosion is proposed to reduce the negative guidance of
label interpolation on lateral output. Extensive experiments on five popular
datasets demonstrate the superiority of our method.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18676" title="Abstract">arXiv:2311.18676</a> [<a href="/pdf/2311.18676" title="Download PDF">pdf</a>, <a href="/format/2311.18676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DQSSA: A Quantum-Inspired Solution for Maximizing Influence in Online  Social Networks (Student Abstract)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Aryaman Rao</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Parth Singh</a>, 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+D+K">Dinesh Kumar Vishwakarma</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+M">Mukesh Prasad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI Conference on Artificial Intelligence 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Influence Maximization is the task of selecting optimal nodes maximising the
influence spread in social networks. This study proposes a Discretized
Quantum-based Salp Swarm Algorithm (DQSSA) for optimizing influence diffusion
in social networks. By discretizing meta-heuristic algorithms and infusing them
with quantum-inspired enhancements, we address issues like premature
convergence and low efficacy. The proposed method, guided by quantum
principles, offers a promising solution for Influence Maximisation. Experiments
on four real-world datasets reveal DQSSA's superior performance as compared to
established cutting-edge algorithms.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18677" title="Abstract">arXiv:2311.18677</a> [<a href="/pdf/2311.18677" title="Download PDF">pdf</a>, <a href="/format/2311.18677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splitwise: Efficient generative LLM inference using phase splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+P">Pratyush Patel</a>, 
<a href="/search/cs?searchtype=author&query=Choukse%2C+E">Esha Choukse</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Goiri%2C+%C3%8D">&#xcd;&#xf1;igo Goiri</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Aashaka Shah</a>, 
<a href="/search/cs?searchtype=author&query=Maleki%2C+S">Saeed Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Bianchini%2C+R">Ricardo Bianchini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recent innovations in generative large language models (LLMs) have made their
applications and use-cases ubiquitous. This has led to large-scale deployments
of these models, using complex, expensive, and power-hungry AI accelerators,
most commonly GPUs. These developments make LLM inference efficiency an
important challenge. Based on our extensive characterization, we find that
there are two main phases during an LLM inference request: a compute-intensive
prompt computation, and a memory-intensive token generation, each with distinct
latency, throughput, memory, and power characteristics. Despite
state-of-the-art batching and scheduling, the token generation phase
underutilizes compute resources. Specifically, unlike compute-intensive prompt
computation phases, token generation phases do not require the compute
capability of the latest GPUs, and can be run with lower power and cost.
<br />With Splitwise, we propose splitting the two phases of a LLM inference
request on to separate machines. This allows us to use hardware that is
well-suited for each phase, and provision resources independently per phase.
However, splitting an inference request across machines requires state transfer
from the machine running prompt computation over to the machine generating
tokens. We implement and optimize this state transfer using the fast back-plane
interconnects available in today's GPU clusters.
<br />We use the Splitwise technique to design LLM inference clusters using the
same or different types of machines for the prompt computation and token
generation phases. Our clusters are optimized for three key objectives:
throughput, cost, and power. In particular, we show that we can achieve 1.4x
higher throughput at 20% lower cost than current designs. Alternatively, we can
achieve 2.35x more throughput with the same cost and power budgets.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18679" title="Abstract">arXiv:2311.18679</a> [<a href="/pdf/2311.18679" title="Download PDF">pdf</a>, <a href="/format/2311.18679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A proposal for federated chatbots for distributed information access  (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tricas-Garc%C3%ADa%2C+F">Fernando Tricas-Garc&#xed;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preliminary (and longer) version of the original paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the ESM'2023 (The 37th annual European
  Simulation and Modelling Conference) October 2023, Toulouse, France, pp.
  151--154
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Chatbots can be a good way to interact with IoT devices, and other
information systems: they can provide information with a convenient interface
for casual or frequent interaction. Sometimes there can be good reasons to have
more than one chatbot: maybe we have several computers, or diverse
infrastructure, with different access conditions. This work concentrates on
this case, when it can be useful to establish a method for them to work in a
cooperative way. In principle, coordination is a good property: each one of
these chatbots can be devoted to solve different tasks and our users can have
different needs when accessing to every capability of each chatbot.
<br />In this paper we are proposing an architecture for several chatbots that can
interact via a command and control channel, requesting actions for other bots
and collecting the replies in order to pass them to the user. The chatbot
infrastructure is lightweight, and it can use public (but not publicly
viewable) infrastructure providing an easy way to start a project with it.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18681" title="Abstract">arXiv:2311.18681</a> [<a href="/pdf/2311.18681" title="Download PDF">pdf</a>, <a href="/format/2311.18681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaDialog: A Large Vision-Language Model for Radiology Report Generation  and Conversational Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pellegrini%2C+C">Chantal Pellegrini</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zsoy%2C+E">Ege &#xd6;zsoy</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Keicher%2C+M">Matthias Keicher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Conversational AI tools that can generate and discuss clinically correct
radiology reports for a given medical image have the potential to transform
radiology. Such a human-in-the-loop radiology assistant could facilitate a
collaborative diagnostic process, thus saving time and improving the quality of
reports. Towards this goal, we introduce RaDialog, the first thoroughly
evaluated and publicly available large vision-language model for radiology
report generation and interactive dialog. RaDialog effectively integrates
visual image features and structured pathology findings with a large language
model (LLM) while simultaneously adapting it to a specialized domain using
parameter-efficient fine-tuning. To keep the conversational abilities of the
underlying LLM, we propose a comprehensive, semi-automatically labeled,
image-grounded instruct dataset for chest X-ray radiology tasks. By training
with this dataset, our method achieves state-of-the-art clinical correctness in
report generation and shows impressive abilities in interactive tasks such as
correcting reports and answering questions, serving as a foundational step
toward clinical dialog systems. Our code is available on github:
https://github.com/ChantalMP/RaDialog.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18684" title="Abstract">arXiv:2311.18684</a> [<a href="/pdf/2311.18684" title="Download PDF">pdf</a>, <a href="/format/2311.18684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handling Cost and Constraints with Off-Policy Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markowitz%2C+J">Jared Markowitz</a>, 
<a href="/search/cs?searchtype=author&query=Silverberg%2C+J">Jesse Silverberg</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+G">Gary Collins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">By reusing data throughout training, off-policy deep reinforcement learning
algorithms offer improved sample efficiency relative to on-policy approaches.
For continuous action spaces, the most popular methods for off-policy learning
include policy improvement steps where a learned state-action ($Q$) value
function is maximized over selected batches of data. These updates are often
paired with regularization to combat associated overestimation of $Q$ values.
With an eye toward safety, we revisit this strategy in environments with
"mixed-sign" reward functions; that is, with reward functions that include
independent positive (incentive) and negative (cost) terms. This setting is
common in real-world applications, and may be addressed with or without
constraints on the cost terms. We find the combination of function
approximation and a term that maximizes $Q$ in the policy update to be
problematic in such environments, because systematic errors in value estimation
impact the contributions from the competing terms asymmetrically. This results
in overemphasis of either incentives or costs and may severely limit learning.
We explore two remedies to this issue. First, consistent with prior work, we
find that periodic resetting of $Q$ and policy networks can be used to reduce
value estimation error and improve learning in this setting. Second, we
formulate novel off-policy actor-critic methods for both unconstrained and
constrained learning that do not explicitly maximize $Q$ in the policy update.
We find that this second approach, when applied to continuous action spaces
with mixed-sign rewards, consistently and significantly outperforms
state-of-the-art methods augmented by resetting. We further find that our
approach produces agents that are both competitive with popular methods overall
and more reliably competent on frequently-studied control problems that do not
have mixed-sign rewards.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18685" title="Abstract">arXiv:2311.18685</a> [<a href="/pdf/2311.18685" title="Download PDF">pdf</a>, <a href="/format/2311.18685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient, Responsive, and Robust Hopping on Deformable Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lynch%2C+D+J">Daniel J. Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Pusey%2C+J+L">Jason L. Pusey</a>, 
<a href="/search/cs?searchtype=author&query=Gart%2C+S+W">Sean W. Gart</a>, 
<a href="/search/cs?searchtype=author&query=Umbanhowar%2C+P+B">Paul B. Umbanhowar</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+K+M">Kevin M. Lynch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures, submitted to IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robot locomotion is hindered by a mismatch between applications where
legs can outperform wheels or treads, most of which feature deformable
substrates, and existing tools for planning and control, most of which assume
flat, rigid substrates. In this study we focus on the ramifications of plastic
terrain deformation on the hop-to-hop energy dynamics of a spring-legged
monopedal hopping robot animated by a switched-compliance energy injection
controller. From this deliberately simple robot-terrain model, we derive a
hop-to-hop energy return map, and we use physical experiments and simulations
to validate the hop-to-hop energy map for a real robot hopping on a real
deformable substrate. The dynamical properties (fixed points, eigenvalues,
basins of attraction) of this map provide insights into efficient, responsive,
and robust locomotion on deformable terrain. Specifically, we identify
constant-fixed-point surfaces in a controller parameter space that suggest it
is possible to tune control parameters for efficiency or responsiveness while
targeting a desired gait energy level. We also identify conditions under which
fixed points of the energy map are globally stable, and we further characterize
the basins of attraction of fixed points when these conditions are not
satisfied. We conclude by discussing the implications of this hop-to-hop energy
map for planning, control, and estimation for efficient, agile, and robust
legged locomotion on deformable terrain.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18695" title="Abstract">arXiv:2311.18695</a> [<a href="/pdf/2311.18695" title="Download PDF">pdf</a>, <a href="/format/2311.18695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seg2Reg: Differentiable 2D Segmentation to 1D Regression Rendering for  360 Room Layout Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+W">Wei-En Tai</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+Y">Yu-Lin Shih</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kuan-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Syu%2C+Y">Yong-Jing Syu</a>, 
<a href="/search/cs?searchtype=author&query=The%2C+K+S">Kent Selwyn The</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hwann-Tzong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">State-of-the-art single-view 360-degree room layout reconstruction methods
formulate the problem as a high-level 1D (per-column) regression task. On the
other hand, traditional low-level 2D layout segmentation is simpler to learn
and can represent occluded regions, but it requires complex post-processing for
the targeting layout polygon and sacrifices accuracy. We present Seg2Reg to
render 1D layout depth regression from the 2D segmentation map in a
differentiable and occlusion-aware way, marrying the merits of both sides.
Specifically, our model predicts floor-plan density for the input
equirectangular 360-degree image. Formulating the 2D layout representation as a
density field enables us to employ `flattened' volume rendering to form 1D
layout depth regression. In addition, we propose a novel 3D warping
augmentation on layout to improve generalization. Finally, we re-implement
recent room layout reconstruction methods into our codebase for benchmarking
and explore modern backbones and training techniques to serve as the strong
baseline. Our model significantly outperforms previous arts. The code will be
made available upon publication.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18702" title="Abstract">arXiv:2311.18702</a> [<a href="/pdf/2311.18702" title="Download PDF">pdf</a>, <a href="/format/2311.18702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable  Evaluation of Large Language Model Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bosi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhuoer Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xuanyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Aohan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since the natural language processing (NLP) community started to make large
language models (LLMs), such as GPT-4, act as a critic to evaluate the quality
of generated texts, most of them only train a critique generation model of a
specific scale on specific datasets. We argue that a comprehensive
investigation on the key factor of LLM-based evaluation models, such as scaling
properties, is lacking, so that it is still inconclusive whether these models
have potential to replace GPT-4's evaluation in practical scenarios. In this
paper, we propose a new critique generation model called CritiqueLLM, which
includes a dialogue-based prompting method for high-quality referenced /
reference-free evaluation data. Experimental results show that our model can
achieve comparable evaluation performance to GPT-4 especially in system-level
correlations, and even outperform GPT-4 in 3 out of 8 tasks in a challenging
reference-free setting. We conduct detailed analysis to show promising scaling
properties of our model in the quality of generated critiques. We also
demonstrate that our generated critiques can act as scalable feedback to
directly improve the generation quality of LLMs.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18703" title="Abstract">arXiv:2311.18703</a> [<a href="/pdf/2311.18703" title="Download PDF">pdf</a>, <a href="/format/2311.18703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictable Reinforcement Learning Dynamics through Entropy Rate  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ornia%2C+D+J">Daniel Jarne Ornia</a>, 
<a href="/search/cs?searchtype=author&query=Delimpaltadakis%2C+G">Giannis Delimpaltadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">In Reinforcement Learning (RL), agents have no incentive to exhibit
predictable behaviors, and are often pushed (through e.g. policy entropy
regularization) to randomize their actions in favor of exploration. From a
human perspective, this makes RL agents hard to interpret and predict, and from
a safety perspective, even harder to formally verify. We propose a novel method
to induce predictable behavior in RL agents, referred to as
Predictability-Aware RL (PA-RL), which employs the state sequence entropy rate
as a predictability measure. We show how the entropy rate can be formulated as
an average reward objective, and since its entropy reward function is
policy-dependent, we introduce an action-dependent surrogate entropy enabling
the use of PG methods. We prove that deterministic policies minimizing the
average surrogate reward exist and also minimize the actual entropy rate, and
show how, given a learned dynamical model, we are able to approximate the value
function associated to the true entropy rate. Finally, we demonstrate the
effectiveness of the approach in RL tasks inspired by human-robot use-cases,
and show how it produces agents with more predictable behavior while achieving
near-optimal rewards.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18705" title="Abstract">arXiv:2311.18705</a> [<a href="/pdf/2311.18705" title="Download PDF">pdf</a>, <a href="/format/2311.18705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying metadata-structure relationships in networks using  description length
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mangold%2C+L">Lena Mangold</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+C">Camille Roth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Network analysis is often enriched by including an examination of node
metadata. In the context of understanding the mesoscale of networks it is often
assumed that node groups based on metadata and node groups based on
connectivity patterns are intrinsically linked. Recently, this assumption has
been challenged and it has been demonstrated that metadata might be entirely
unrelated to structure or, similarly, multiple sets of metadata might be
relevant to the structure of a network in different ways. We propose the
metablox tool to quantify the relationship between a networks node metadata and
its mesoscale structure, measuring the strength of the relationship and the
type of structural arrangement exhibited by the metadata. Our tool incorporates
a way to distinguish significantly relevant relationships and can be used as
part of systematic meta analyses comparing large numbers of networks, which we
demonstrate on a number of synthetic and empirical networks.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18710" title="Abstract">arXiv:2311.18710</a> [<a href="/pdf/2311.18710" title="Download PDF">pdf</a>, <a href="/format/2311.18710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Prior: Meta learning for Adaptive Inverse Problem Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terris%2C+M">Matthieu Terris</a>, 
<a href="/search/cs?searchtype=author&query=Moreau%2C+T">Thomas Moreau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks have become a foundational tool for addressing imaging
inverse problems. They are typically trained for a specific task, with a
supervised loss to learn a mapping from the observations to the image to
recover. However, real-world imaging challenges often lack ground truth data,
rendering traditional supervised approaches ineffective. Moreover, for each new
imaging task, a new model needs to be trained from scratch, wasting time and
resources. To overcome these limitations, we introduce a novel approach based
on meta-learning. Our method trains a meta-model on a diverse set of imaging
tasks that allows the model to be efficiently fine-tuned for specific tasks
with few fine-tuning steps. We show that the proposed method extends to the
unsupervised setting, where no ground truth data is available. In its bilevel
formulation, the outer level uses a supervised loss, that evaluates how well
the fine-tuned model performs, while the inner loss can be either supervised or
unsupervised, relying only on the measurement operator. This allows the
meta-model to leverage a few ground truth samples for each task while being
able to generalize to new imaging tasks. We show that in simple settings, this
approach recovers the Bayes optimal estimator, illustrating the soundness of
our approach. We also demonstrate our method's effectiveness on various tasks,
including image processing and magnetic resonance imaging.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18711" title="Abstract">arXiv:2311.18711</a> [<a href="/pdf/2311.18711" title="Download PDF">pdf</a>, <a href="/format/2311.18711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine  Translation and Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pikuliak%2C+M">Mat&#xfa;&#x161; Pikuliak</a>, 
<a href="/search/cs?searchtype=author&query=Hrckova%2C+A">Andrea Hrckova</a>, 
<a href="/search/cs?searchtype=author&query=Oresko%2C+S">Stefan Oresko</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0imko%2C+M">Mari&#xe1;n &#x160;imko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present GEST -- a new dataset for measuring gender-stereotypical reasoning
in masked LMs and English-to-X machine translation systems. GEST contains
samples that are compatible with 9 Slavic languages and English for 16 gender
stereotypes about men and women (e.g., Women are beautiful, Men are leaders).
The definition of said stereotypes was informed by gender experts. We used GEST
to evaluate 11 masked LMs and 4 machine translation systems. We discovered
significant and consistent amounts of stereotypical reasoning in almost all the
evaluated models and languages.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18712" title="Abstract">arXiv:2311.18712</a> [<a href="/pdf/2311.18712" title="Download PDF">pdf</a>, <a href="/format/2311.18712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoRec: An Easy Approach for Coordination Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Haojie Jia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wenfei Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 Main Conference (oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we observe and address the challenges of the coordination
recognition task. Most existing methods rely on syntactic parsers to identify
the coordinators in a sentence and detect the coordination boundaries. However,
state-of-the-art syntactic parsers are slow and suffer from errors, especially
for long and complicated sentences. To better solve the problems, we propose a
pipeline model COordination RECognizer (CoRec). It consists of two components:
coordinator identifier and conjunct boundary detector. The experimental results
on datasets from various domains demonstrate the effectiveness and efficiency
of the proposed method. Further experiments show that CoRec positively impacts
downstream tasks, improving the yield of state-of-the-art Open IE models.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18714" title="Abstract">arXiv:2311.18714</a> [<a href="/pdf/2311.18714" title="Download PDF">pdf</a>, <a href="/format/2311.18714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAOS as HPC Storage: Exploring Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+A">Adrian Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Manubens%2C+N">Nicolau Manubens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This work in progress paper outlines research looking at the performance
impact of using different storage interfaces to access the high performance
object store DAOS. We demonstrate that using DAOS through a FUSE based
filesystem interface can provide high performance, but there are impacts when
choosing what I/O library or interface to utilises, with HDF5 exhibiting the
highest impact. However, this varied depending on what type of I/O operations
were undertaken.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18718" title="Abstract">arXiv:2311.18718</a> [<a href="/pdf/2311.18718" title="Download PDF">pdf</a>, <a href="/format/2311.18718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Deep Feature Learning with Backward Aligned Feature Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chizat%2C+L">L&#xe9;na&#xef;c Chizat</a>, 
<a href="/search/cs?searchtype=author&query=Netrapalli%2C+P">Praneeth Netrapalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning succeeds by doing hierarchical feature learning, yet tuning
Hyper-Parameters (HP) such as initialization scales, learning rates etc., only
give indirect control over this behavior. In this paper, we propose the
alignment between the feature updates and the backward pass as a key notion to
predict, measure and control feature learning. On the one hand, we show that
when alignment holds, the magnitude of feature updates after one SGD step is
related to the magnitude of the forward and backward passes by a simple and
general formula. This leads to techniques to automatically adjust HPs
(initialization scales and learning rates) at initialization and throughout
training to attain a desired feature learning behavior. On the other hand, we
show that, at random initialization, this alignment is determined by the
spectrum of a certain kernel, and that well-conditioned layer-to-layer
Jacobians (aka dynamical isometry) implies alignment. Finally, we investigate
ReLU MLPs and ResNets in the large width-then-depth limit. Combining hints from
random matrix theory and numerical experiments, we show that (i) in MLP with
iid initializations, alignment degenerates with depth, making it impossible to
start training, and that (ii) in ResNets, the branch scale
$1/\sqrt{\text{depth}}$ is the only one maintaining non-trivial alignment at
infinite depth.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18724" title="Abstract">arXiv:2311.18724</a> [<a href="/pdf/2311.18724" title="Download PDF">pdf</a>, <a href="/format/2311.18724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routing-Guided Learned Product Quantization for Graph-Based Approximate  Nearest Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Q">Qiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yikun Tao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xuliyuan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Given a vector dataset $\mathcal{X}$, a query vector $\vec{x}_q$, graph-based
Approximate Nearest Neighbor Search (ANNS) aims to build a proximity graph (PG)
as an index of $\mathcal{X}$ and approximately return vectors with minimum
distances to $\vec{x}_q$ by searching over the PG index. It suffers from the
large-scale $\mathcal{X}$ because a PG with full vectors is too large to fit
into the memory, e.g., a billion-scale $\mathcal{X}$ in 128 dimensions would
consume nearly 600 GB memory. To solve this, Product Quantization (PQ)
integrated graph-based ANNS is proposed to reduce the memory usage, using
smaller compact codes of quantized vectors in memory instead of the large
original vectors. Existing PQ methods do not consider the important routing
features of PG, resulting in low-quality quantized vectors that affect the
ANNS's effectiveness. In this paper, we present an end-to-end Routing-guided
learned Product Quantization (RPQ) for graph-based ANNS. It consists of (1) a
\textit{differentiable quantizer} used to make the standard discrete PQ
differentiable to suit for back-propagation of end-to-end learning, (2) a
\textit{sampling-based feature extractor} used to extract neighborhood and
routing features of a PG, and (3) a \textit{multi-feature joint training
module} with two types of feature-aware losses to continuously optimize the
differentiable quantizer. As a result, the inherent features of a PG would be
embedded into the learned PQ, generating high-quality quantized vectors.
Moreover, we integrate our RPQ with the state-of-the-art DiskANN and existing
popular PGs to improve their performance. Comprehensive experiments on
real-world large-scale datasets (from 1M to 1B) demonstrate RPQ's superiority,
e.g., 1.7$\times$-4.2$\times$ improvement on QPS at the same recall@10 of 95\%.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18727" title="Abstract">arXiv:2311.18727</a> [<a href="/pdf/2311.18727" title="Download PDF">pdf</a>, <a href="/format/2311.18727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Functional Differentiation in JAX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We extend JAX with the capability to automatically differentiate higher-order
functions (functionals and operators). By representing functions as a
generalization of arrays, we seamlessly use JAX's existing primitive system to
implement higher-order functions. We present a set of primitive operators that
serve as foundational building blocks for constructing several key types of
functionals. For every introduced primitive operator, we derive and implement
both linearization and transposition rules, aligning with JAX's internal
protocols for forward and reverse mode automatic differentiation. This
enhancement allows for functional differentiation in the same syntax
traditionally use for functions. The resulting functional gradients are
themselves functions ready to be invoked in python. We showcase this tool's
efficacy and simplicity through applications where functional derivatives are
indispensable. The source code of this work is released at
https://github.com/sail-sg/autofd .
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18729" title="Abstract">arXiv:2311.18729</a> [<a href="/pdf/2311.18729" title="Download PDF">pdf</a>, <a href="/format/2311.18729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Duomin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaohang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yudeng.github.io/Portrait4D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing one-shot 4D head synthesis methods usually learn from monocular
videos with the aid of 3DMM reconstruction, yet the latter is evenly
challenging which restricts them from reasonable 4D head synthesis. We present
a method to learn one-shot 4D head synthesis via large-scale synthetic data.
The key is to first learn a part-wise 4D generative model from monocular images
via adversarial learning, to synthesize multi-view images of diverse identities
and full motions as training data; then leverage a transformer-based animatable
triplane reconstructor to learn 4D head reconstruction using the synthetic
data. A novel learning strategy is enforced to enhance the generalizability to
real images by disentangling the learning process of 3D reconstruction and
reenactment. Experiments demonstrate our superiority over the prior art.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18730" title="Abstract">arXiv:2311.18730</a> [<a href="/pdf/2311.18730" title="Download PDF">pdf</a>, <a href="/format/2311.18730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space --  Transformer Ensemble Models Tackling Deception and Persuasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mangalvedhekar%2C+S">Sudeep Mangalvedhekar</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+K">Kshitij Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Patwardhan%2C+Y">Yash Patwardhan</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+V">Vedant Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Murumkar%2C+R">Ravindra Murumkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, accepted at the ArAIEval ArabicNLP workshop, EMNLP conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we highlight our approach for the "Arabic AI Tasks Evaluation
(ArAiEval) Shared Task 2023". We present our approaches for task 1-A and task
2-A of the shared task which focus on persuasion technique detection and
disinformation detection respectively. Detection of persuasion techniques and
disinformation has become imperative to avoid distortion of authentic
information. The tasks use multigenre snippets of tweets and news articles for
the given binary classification problem. We experiment with several
transformer-based models that were pre-trained on the Arabic language. We
fine-tune these state-of-the-art models on the provided dataset. Ensembling is
employed to enhance the performance of the systems. We achieved a micro
F1-score of 0.742 on task 1-A (8th rank on the leaderboard) and 0.901 on task
2-A (7th rank on the leaderboard) respectively.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18735" title="Abstract">arXiv:2311.18735</a> [<a href="/pdf/2311.18735" title="Download PDF">pdf</a>, <a href="/format/2311.18735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension Mixer: A Generalized Method for Structured Sparsity in Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapkota%2C+S">Suman Sapkota</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+B">Binod Bhattarai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The recent success of multiple neural architectures like CNNs, Transformers,
and MLP-Mixers motivated us to look for similarities and differences between
them. We found that these architectures can be interpreted through the lens of
a general concept of dimension mixing. Research on coupling flows and the
butterfly transform shows that partial and hierarchical signal mixing schemes
are sufficient for efficient and expressive function approximation. In this
work, we study group-wise sparse, non-linear, multi-layered and learnable
mixing schemes of inputs and find that they are complementary to many standard
neural architectures. Following our observations and drawing inspiration from
the Fast Fourier Transform, we generalize Butterfly Structure to use non-linear
mixer function allowing for MLP as mixing function called Butterfly MLP. We
were also able to mix along sequence dimension for Transformer-based
architectures called Butterfly Attention. Experiments on CIFAR and LRA datasets
demonstrate that the proposed Non-Linear Butterfly Mixers are efficient and
scale well when the host architectures are used as mixing function.
Additionally, we propose Patch-Only MLP-Mixer for processing spatial 2D signals
demonstrating a different dimension mixing strategy.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18736" title="Abstract">arXiv:2311.18736</a> [<a href="/pdf/2311.18736" title="Download PDF">pdf</a>, <a href="/format/2311.18736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlgym: Large-Scale Safety-Critical Control Environments for  Benchmarking Reinforcement Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiangyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+W">Weichao Mao</a>, 
<a href="/search/eess?searchtype=author&query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
<a href="/search/eess?searchtype=author&query=Benosman%2C+M">Mouhacine Benosman</a>, 
<a href="/search/eess?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We introduce controlgym, a library of thirty-six safety-critical industrial
control settings, and ten infinite-dimensional partial differential equation
(PDE)-based control problems. Integrated within the OpenAI Gym/Gymnasium (Gym)
framework, controlgym allows direct applications of standard reinforcement
learning (RL) algorithms like stable-baselines3. Our control environments
complement those in Gym with continuous, unbounded action and observation
spaces, motivated by real-world control applications. Moreover, the PDE control
environments uniquely allow the users to extend the state dimensionality of the
system to infinity while preserving the intrinsic dynamics. This feature is
crucial for evaluating the scalability of RL algorithms for control. This
project serves the learning for dynamics &amp; control (L4DC) community, aiming to
explore key questions: the convergence of RL algorithms in learning control
policies; the stability and robustness issues of learning-based controllers;
and the scalability of RL algorithms to high- and potentially
infinite-dimensional systems. We open-source the controlgym project at
https://github.com/xiangyuan-zhang/controlgym.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18739" title="Abstract">arXiv:2311.18739</a> [<a href="/pdf/2311.18739" title="Download PDF">pdf</a>, <a href="/format/2311.18739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mavericks at NADI 2023 Shared Task: Unravelling Regional Nuances through  Dialect Identification using Transformer-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+V">Vedant Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Patwardhan%2C+Y">Yash Patwardhan</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+K">Kshitij Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Mangalvedhekar%2C+S">Sudeep Mangalvedhekar</a>, 
<a href="/search/cs?searchtype=author&query=Murumkar%2C+R">Ravindra Murumkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, accepted at the NADI ArabicNLP Workshop, EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we present our approach for the "Nuanced Arabic Dialect
Identification (NADI) Shared Task 2023". We highlight our methodology for
subtask 1 which deals with country-level dialect identification. Recognizing
dialects plays an instrumental role in enhancing the performance of various
downstream NLP tasks such as speech recognition and translation. The task uses
the Twitter dataset (TWT-2023) that encompasses 18 dialects for the multi-class
classification problem. Numerous transformer-based models, pre-trained on
Arabic language, are employed for identifying country-level dialects. We
fine-tune these state-of-the-art models on the provided dataset. The ensembling
method is leveraged to yield improved performance of the system. We achieved an
F1-score of 76.65 (11th rank on the leaderboard) on the test dataset.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18740" title="Abstract">arXiv:2311.18740</a> [<a href="/pdf/2311.18740" title="Download PDF">pdf</a>, <a href="/format/2311.18740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First-Order Model Checking on Monadically Stable Graph Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dreier%2C+J">Jan Dreier</a>, 
<a href="/search/cs?searchtype=author&query=Eleftheriadis%2C+I">Ioannis Eleftheriadis</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4hlmann%2C+N">Nikolas M&#xe4;hlmann</a>, 
<a href="/search/cs?searchtype=author&query=McCarty%2C+R">Rose McCarty</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Micha&#x142; Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Toru%C5%84czyk%2C+S">Szymon Toru&#x144;czyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO); Logic (math.LO)

</div>
<p class="mathjax">A graph class $\mathscr{C}$ is called monadically stable if one cannot
interpret, in first-order logic, arbitrary large linear orders in colored
graphs from $\mathscr{C}$. We prove that the model checking problem for
first-order logic is fixed-parameter tractable on every monadically stable
graph class. This extends the results of [Grohe, Kreutzer, and Siebertz; J. ACM
'17] for nowhere dense classes and of [Dreier, M\"ahlmann, and Siebertz; STOC
'23] for structurally nowhere dense classes to all monadically stable classes.
<br />As a complementary hardness result, we prove that for every hereditary graph
class $\mathscr{C}$ that is edge-stable (excludes some half-graph as a
semi-induced subgraph) but not monadically stable, first-order model checking
is $\mathrm{AW}[*]$-hard on $\mathscr{C}$, and $\mathrm{W}[1]$-hard when
restricted to existential sentences. This confirms, in the special case of
edge-stable classes, an on-going conjecture that the notion of monadic NIP
delimits the tractability of first-order model checking on hereditary classes
of graphs.
<br />For our tractability result, we first prove that monadically stable graph
classes have almost linear neighborhood complexity. Using this, we construct
sparse neighborhood covers for monadically stable classes, which provides the
missing ingredient for the algorithm of [Dreier, M\"ahlmann, and Siebertz; STOC
'23]. The key component of this construction is the usage of orders with low
crossing number [Welzl; SoCG '88], a tool from the area of range queries.
<br />For our hardness result, we prove a new characterization of monadically
stable graph classes in terms of forbidden induced subgraphs. We then use this
characterization to show that in hereditary classes that are edge-stable but
not monadically stable, one can effectively interpret the class of all graphs
using only existential formulas.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18741" title="Abstract">arXiv:2311.18741</a> [<a href="/pdf/2311.18741" title="Download PDF">pdf</a>, <a href="/format/2311.18741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VREM-FL: Mobility-Aware Computation-Scheduling Co-Design for Vehicular  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ballotta%2C+L">Luca Ballotta</a>, 
<a href="/search/eess?searchtype=author&query=Fabbro%2C+N+D">Nicol&#xf2; Dal Fabbro</a>, 
<a href="/search/eess?searchtype=author&query=Perin%2C+G">Giovanni Perin</a>, 
<a href="/search/eess?searchtype=author&query=Schenato%2C+L">Luca Schenato</a>, 
<a href="/search/eess?searchtype=author&query=Rossi%2C+M">Michele Rossi</a>, 
<a href="/search/eess?searchtype=author&query=Piro%2C+G">Giuseppe Piro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Assisted and autonomous driving are rapidly gaining momentum, and will soon
become a reality. Among their key enablers, artificial intelligence and machine
learning are expected to play a prominent role, also thanks to the massive
amount of data that smart vehicles will collect from their onboard sensors. In
this domain, federated learning is one of the most effective and promising
techniques for training global machine learning models, while preserving data
privacy at the vehicles and optimizing communications resource usage. In this
work, we propose VREM-FL, a computation-scheduling co-design for vehicular
federated learning that leverages mobility of vehicles in conjunction with
estimated 5G radio environment maps. VREM-FL jointly optimizes the global model
learned at the server while wisely allocating communication resources. This is
achieved by orchestrating local computations at the vehicles in conjunction
with the transmission of their local model updates in an adaptive and
predictive fashion, by exploiting radio channel maps. The proposed algorithm
can be tuned to trade model training time for radio resource usage.
Experimental results demonstrate the efficacy of utilizing radio maps. VREM-FL
outperforms literature benchmarks for both a linear regression model (learning
time reduced by 28%) and a deep neural network for a semantic image
segmentation task (doubling the number of model updates within the same time
window).
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18743" title="Abstract">arXiv:2311.18743</a> [<a href="/pdf/2311.18743" title="Download PDF">pdf</a>, <a href="/format/2311.18743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlignBench: Benchmarking Chinese Alignment of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xuanyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhuoer Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bosi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tam%2C+W+L">Weng Lam Tam</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Alignment has become a critical step for instruction-tuned Large Language
Models (LLMs) to become helpful assistants. However, effective evaluation of
alignment for emerging Chinese LLMs is still significantly lacking, calling for
real-scenario grounded, open-ended, challenging and automatic evaluations
tailored for alignment. To fill in this gap, we introduce AlignBench, a
comprehensive multi-dimensional benchmark for evaluating LLMs' alignment in
Chinese. Equipped with a human-in-the-loop data curation pipeline, our
benchmark employs a rule-calibrated multi-dimensional LLM-as-Judge with
Chain-of-Thought to generate explanations and final ratings as evaluations,
ensuring high reliability and interpretability. Furthermore, we developed a
dedicated companion evaluator LLM -- CritiqueLLM, which recovers 95\% of
GPT-4's evaluation ability and will be provided via public APIs to researchers
for evaluation of alignment in Chinese LLMs. All evaluation codes, data, and
LLM generations are available at \url{https://github.com/THUDM/AlignBench}.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18746" title="Abstract">arXiv:2311.18746</a> [<a href="/pdf/2311.18746" title="Download PDF">pdf</a>, <a href="/format/2311.18746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A data-science pipeline to enable the Interpretability of Many-Objective  Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Njoku%2C+U+F">Uchechukwu F. Njoku</a>, 
<a href="/search/cs?searchtype=author&query=Abell%C3%B3%2C+A">Alberto Abell&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Bilalli%2C+B">Besim Bilalli</a>, 
<a href="/search/cs?searchtype=author&query=Bontempi%2C+G">Gianluca Bontempi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many-Objective Feature Selection (MOFS) approaches use four or more
objectives to determine the relevance of a subset of features in a supervised
learning task. As a consequence, MOFS typically returns a large set of
non-dominated solutions, which have to be assessed by the data scientist in
order to proceed with the final choice. Given the multi-variate nature of the
assessment, which may include criteria (e.g. fairness) not related to
predictive accuracy, this step is often not straightforward and suffers from
the lack of existing tools. For instance, it is common to make use of a tabular
presentation of the solutions, which provide little information about the
trade-offs and the relations between criteria over the set of solutions.
<br />This paper proposes an original methodology to support data scientists in the
interpretation and comparison of the MOFS outcome by combining post-processing
and visualisation of the set of solutions. The methodology supports the data
scientist in the selection of an optimal feature subset by providing her with
high-level information at three different levels: objectives, solutions, and
individual features.
<br />The methodology is experimentally assessed on two feature selection tasks
adopting a GA-based MOFS with six objectives (number of selected features,
balanced accuracy, F1-Score, variance inflation factor, statistical parity, and
equalised odds). The results show the added value of the methodology in the
selection of the final subset of features.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18749" title="Abstract">arXiv:2311.18749</a> [<a href="/pdf/2311.18749" title="Download PDF">pdf</a>, <a href="/format/2311.18749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransCORALNet: A Two-Stream Transformer CORAL Networks for Supply Chain  Credit Assessment Cold Start
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Siebes%2C+A+P+J+M">Arno P. J. M. Siebes</a>, 
<a href="/search/cs?searchtype=author&query=Mehrkanoon%2C+S">Siamak Mehrkanoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Risk Management (q-fin.RM)

</div>
<p class="mathjax">This paper proposes an interpretable two-stream transformer CORAL networks
(TransCORALNet) for supply chain credit assessment under the segment industry
and cold start problem. The model aims to provide accurate credit assessment
prediction for new supply chain borrowers with limited historical data. Here,
the two-stream domain adaptation architecture with correlation alignment
(CORAL) loss is used as a core model and is equipped with transformer, which
provides insights about the learned features and allow efficient
parallelization during training. Thanks to the domain adaptation capability of
the proposed model, the domain shift between the source and target domain is
minimized. Therefore, the model exhibits good generalization where the source
and target do not follow the same distribution, and a limited amount of target
labeled instances exist. Furthermore, we employ Local Interpretable
Model-agnostic Explanations (LIME) to provide more insight into the model
prediction and identify the key features contributing to supply chain credit
assessment decisions. The proposed model addresses four significant supply
chain credit assessment challenges: domain shift, cold start, imbalanced-class
and interpretability. Experimental results on a real-world data set demonstrate
the superiority of TransCORALNet over a number of state-of-the-art baselines in
terms of accuracy. The code is available on GitHub
https://github.com/JieJieNiu/TransCORALN .
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18751" title="Abstract">arXiv:2311.18751</a> [<a href="/pdf/2311.18751" title="Download PDF">pdf</a>, <a href="/format/2311.18751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Agents Suffer from Compositional Generalization in Web  Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furuta%2C+H">Hiroki Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+Y">Yutaka Matsuo</a>, 
<a href="/search/cs?searchtype=author&query=Faust%2C+A">Aleksandra Faust</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+I">Izzeddin Gur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/google-research/google-research/tree/master/compositional_rl/compwob">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Language model agents (LMA) recently emerged as a promising paradigm on
muti-step decision making tasks, often outperforming humans and other
reinforcement learning agents. Despite the promise, their performance on
real-world applications that often involve combinations of tasks is still
underexplored. In this work, we introduce a new benchmark, called CompWoB -- 50
new compositional web automation tasks reflecting more realistic assumptions.
We show that while existing prompted LMAs (gpt-3.5-turbo or gpt-4) achieve
94.0% average success rate on base tasks, their performance degrades to 24.9%
success rate on compositional tasks. On the other hand, transferred LMAs
(finetuned only on base tasks) show less generalization gap, dropping from
85.4% to 54.8%. By balancing data distribution across tasks, we train a new
model, HTML-T5++, that surpasses human-level performance (95.2%) on MiniWoB,
and achieves the best zero-shot performance on CompWoB (61.5%). While these
highlight the promise of small-scale finetuned and transferred models for
compositional generalization, their performance further degrades under
different instruction compositions changing combinational order. In contrast to
the recent remarkable success of LMA, our benchmark and detailed analysis
emphasize the necessity of building LMAs that are robust and generalizable to
task compositionality for real-world deployment.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18758" title="Abstract">arXiv:2311.18758</a> [<a href="/pdf/2311.18758" title="Download PDF">pdf</a>, <a href="/format/2311.18758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Semantic Segmentation via Boosting Uncertainty on  Unlabeled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daoan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yunhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianguo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We bring a new perspective to semi-supervised semantic segmentation by
providing an analysis on the labeled and unlabeled distributions in training
datasets. We first figure out that the distribution gap between labeled and
unlabeled datasets cannot be ignored, even though the two datasets are sampled
from the same distribution. To address this issue, we theoretically analyze and
experimentally prove that appropriately boosting uncertainty on unlabeled data
can help minimize the distribution gap, which benefits the generalization of
the model. We propose two strategies and design an uncertainty booster
algorithm, specially for semi-supervised semantic segmentation. Extensive
experiments are carried out based on these theories, and the results confirm
the efficacy of the algorithm and strategies. Our plug-and-play uncertainty
booster is tiny, efficient, and robust to hyperparameters but can significantly
promote performance. Our approach achieves state-of-the-art performance in our
experiments compared to the current semi-supervised semantic segmentation
methods on the popular benchmarks: Cityscapes and PASCAL VOC 2012 with
different train settings.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18760" title="Abstract">arXiv:2311.18760</a> [<a href="/pdf/2311.18760" title="Download PDF">pdf</a>, <a href="/format/2311.18760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaskBench: Benchmarking Large Language Models for Task Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yongliang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Siyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weiming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, the incredible progress of large language models (LLMs) has ignited
the spark of task automation, which decomposes the complex tasks described by
user instructions into sub-tasks, and invokes external tools to execute them,
and plays a central role in autonomous agents. However, there lacks a
systematic and standardized benchmark to foster the development of LLMs in task
automation. To this end, we introduce TaskBench to evaluate the capability of
LLMs in task automation. Specifically, task automation can be formulated into
three critical stages: task decomposition, tool invocation, and parameter
prediction to fulfill user intent. This complexity makes data collection and
evaluation more challenging compared to common NLP tasks. To generate
high-quality evaluation datasets, we introduce the concept of Tool Graph to
represent the decomposed tasks in user intent, and adopt a back-instruct method
to simulate user instruction and annotations. Furthermore, we propose TaskEval
to evaluate the capability of LLMs from different aspects, including task
decomposition, tool invocation, and parameter prediction. Experimental results
demonstrate that TaskBench can effectively reflects the capability of LLMs in
task automation. Benefiting from the mixture of automated data construction and
human verification, TaskBench achieves a high consistency compared to the human
evaluation, which can be utilized as a comprehensive and faithful benchmark for
LLM-based autonomous agents.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18761" title="Abstract">arXiv:2311.18761</a> [<a href="/pdf/2311.18761" title="Download PDF">pdf</a>, <a href="/format/2311.18761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can training neural language models on a curriculum with developmentally  plausible data improve alignment with human reading behavior?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chobey%2C+A">Aryaman Chobey</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+O">Oliver Smith</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Anzi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+G">Grusha Prasad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of BabyLM shared task CoNLL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The use of neural language models to model human behavior has met with mixed
success. While some work has found that the surprisal estimates from these
models can be used to predict a wide range of human neural and behavioral
responses, other work studying more complex syntactic phenomena has found that
these surprisal estimates generate incorrect behavioral predictions. This paper
explores the extent to which the misalignment between empirical and
model-predicted behavior can be minimized by training models on more
developmentally plausible data, such as in the BabyLM Challenge. We trained
teacher language models on the BabyLM "strict-small" dataset and used sentence
level surprisal estimates from these teacher models to create a curriculum. We
found tentative evidence that our curriculum made it easier for models to
acquire linguistic knowledge from the training data: on the subset of tasks in
the BabyLM challenge suite evaluating models' grammatical knowledge of English,
models first trained on the BabyLM data curriculum and then on a few randomly
ordered training epochs performed slightly better than models trained on
randomly ordered epochs alone. This improved linguistic knowledge acquisition
did not result in better alignment with human reading behavior, however: models
trained on the BabyLM dataset (with or without a curriculum) generated
predictions that were as misaligned with human behavior as models trained on
larger less curated datasets. This suggests that training on developmentally
plausible datasets alone is likely insufficient to generate language models
capable of accurately predicting human language processing.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18762" title="Abstract">arXiv:2311.18762</a> [<a href="/pdf/2311.18762" title="Download PDF">pdf</a>, <a href="/ps/2311.18762" title="Download PostScript">ps</a>, <a href="/format/2311.18762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Integrated Sensing and Communications Under  Gain-Phase Imperfections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuaishuai Han</a>, 
<a href="/search/cs?searchtype=author&query=Al-Jarrah%2C+M+A">Mohammad Ahmad Al-Jarrah</a>, 
<a href="/search/cs?searchtype=author&query=Alsusa%2C+E">Emad Alsusa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper evaluates the performance of uplink integrated sensing and
communication systems in the presence of gain and phase imperfections.
Specifically, we consider multiple unmanned aerial vehicles (UAVs) transmitting
data to a multiple-input-multiple-output base-station (BS) that is responsible
for estimating the transmitted information in addition to localising the
transmitting UAVs. The signal processing at the BS is divided into two
consecutive stages: localisation and communication. A maximum likelihood (ML)
algorithm is introduced for the localisation stage to jointly estimate the
azimuth-elevation angles and Doppler frequency of the UAVs under gain-phase
defects, which are then compared to the estimation of signal parameters via
rotational invariance techniques (ESPRIT) and multiple signal classification
(MUSIC). Furthermore, the Cramer-Rao lower bound (CRLB) is derived to evaluate
the asymptotic performance and quantify the influence of the gain-phase
imperfections which are modelled using Rician and von Mises distributions,
respectively. Thereafter, in the communication stage, the location parameters
estimated in the first stage are employed to estimate the communication
channels which are fed into a maximum ratio combiner to preprocess the received
communication signal. An accurate closed-form approximation of the achievable
average sum data rate (SDR) for all UAVs is derived. The obtained results show
that gain-phase imperfections have a significant influence on both localisation
and communication, however, the proposed ML is less sensitive when compared to
other algorithms. The derived analysis is concurred with simulations.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18763" title="Abstract">arXiv:2311.18763</a> [<a href="/pdf/2311.18763" title="Download PDF">pdf</a>, <a href="/format/2311.18763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Diffusion with STAMINA: STack-And-Mask INcremental Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+J+S">James Seale Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+Y">Yen-Chang Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yilin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work has demonstrated a remarkable ability to customize text-to-image
diffusion models to multiple, fine-grained concepts in a sequential (i.e.,
continual) manner while only providing a few example images for each concept.
This setting is known as continual diffusion. Here, we ask the question: Can we
scale these methods to longer concept sequences without forgetting? Although
prior work mitigates the forgetting of previously learned concepts, we show
that its capacity to learn new tasks reaches saturation over longer sequences.
We address this challenge by introducing a novel method, STack-And-Mask
INcremental Adapters (STAMINA), which is composed of low-ranked
attention-masked adapters and customized MLP tokens. STAMINA is designed to
enhance the robust fine-tuning properties of LoRA for sequential concept
learning via learnable hard-attention masks parameterized with low rank MLPs,
enabling precise, scalable learning via sparse adaptation. Notably, all
introduced trainable parameters can be folded back into the model after
training, inducing no additional inference parameter costs. We show that
STAMINA outperforms the prior SOTA for the setting of text-to-image continual
customization on a 50-concept benchmark composed of landmarks and human faces,
with no stored replay data. Additionally, we extended our method to the setting
of continual learning for image classification, demonstrating that our gains
also translate to state-of-the-art performance in this standard benchmark.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18765" title="Abstract">arXiv:2311.18765</a> [<a href="/pdf/2311.18765" title="Download PDF">pdf</a>, <a href="/format/2311.18765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLLMs-Augmented Visual-Language Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Visual-language pre-training (VLP) have achieved remarkable success in
multi-modal tasks, largely attributed to the availability of large-scale
image-text datasets. In this work, we demonstrate that multi-modal large
language models (MLLMs) can enhance visual-language representation learning by
improving data quality. Our approach is simple, utilizing MLLMs to extend
multiple captions for each image. To prevent the bias that introduced by MLLMs'
hallucinations and intrinsic caption styles, we propose a "text shearing" to
keep the lengths of extended captions identical to the originals. In image-text
retrieval, our method consistently obtains 5.6 ~ 35.0% and 16.8 ~ 46.1%
improvement on R@1 under the fine-tuning and zero-shot settings, respectively.
Notably, our zero-shot results are comparable to fine-tuning on target
datasets, which encourages more exploration on the versatile use of MLLMs.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18768" title="Abstract">arXiv:2311.18768</a> [<a href="/pdf/2311.18768" title="Download PDF">pdf</a>, <a href="/format/2311.18768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Impact of Flaky Simulators on Testing Autonomous Driving  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amini%2C+M+H">Mohammad Hossein Amini</a>, 
<a href="/search/cs?searchtype=author&query=Naseri%2C+S">Shervin Naseri</a>, 
<a href="/search/cs?searchtype=author&query=Nejati%2C+S">Shiva Nejati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication by Empirical Software Engineering Journal (EMSE) (in November 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Simulators are widely used to test Autonomous Driving Systems (ADS), but
their potential flakiness can lead to inconsistent test results. We investigate
test flakiness in simulation-based testing of ADS by addressing two key
questions: (1) How do flaky ADS simulations impact automated testing that
relies on randomized algorithms? and (2) Can machine learning (ML) effectively
identify flaky ADS tests while decreasing the required number of test reruns?
Our empirical results, obtained from two widely-used open-source ADS simulators
and five diverse ADS test setups, show that test flakiness in ADS is a common
occurrence and can significantly impact the test results obtained by randomized
algorithms. Further, our ML classifiers effectively identify flaky ADS tests
using only a single test run, achieving F1-scores of $85$%, $82$% and $96$% for
three different ADS test setups. Our classifiers significantly outperform our
non-ML baseline, which requires executing tests at least twice, by $31$%,
$21$%, and $13$% in F1-score performance, respectively. We conclude with a
discussion on the scope, implications and limitations of our study. We provide
our complete replication package in a Github repository.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18769" title="Abstract">arXiv:2311.18769</a> [<a href="/pdf/2311.18769" title="Download PDF">pdf</a>, <a href="/format/2311.18769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Change Points Detection for Linear Dynamical Systems with Finite  Sample Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+L">Lei Xin</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+G">George Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+S">Shreyas Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">The problem of online change point detection is to detect abrupt changes in
properties of time series, ideally as soon as possible after those changes
occur. Existing work on online change point detection either assumes i.i.d
data, focuses on asymptotic analysis, does not present theoretical guarantees
on the trade-off between detection accuracy and detection delay, or is only
suitable for detecting single change points. In this work, we study the online
change point detection problem for linear dynamical systems with unknown
dynamics, where the data exhibits temporal correlations and the system could
have multiple change points. We develop a data-dependent threshold that can be
used in our test that allows one to achieve a pre-specified upper bound on the
probability of making a false alarm. We further provide a finite-sample-based
bound for the probability of detecting a change point. Our bound demonstrates
how parameters used in our algorithm affect the detection probability and
delay, and provides guidance on the minimum required time between changes to
guarantee detection.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18773" title="Abstract">arXiv:2311.18773</a> [<a href="/pdf/2311.18773" title="Download PDF">pdf</a>, <a href="/format/2311.18773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spacewalk-18: A Benchmark for Multimodal and Long-form Procedural Video  Understanding in Novel Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+R+M">Rohan Myer Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zitian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiqiu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission. Code and models will be released at <a href="https://brown-palm.github.io/Spacewalk-18/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning from videos is an emerging research area that enables robots to
acquire skills from human demonstrations, such as procedural videos. To do
this, video-language models must be able to obtain structured understandings,
such as the temporal segmentation of a demonstration into sequences of actions
and skills, and to generalize the understandings to novel domains. In pursuit
of this goal, we introduce Spacewalk-18, a benchmark containing two tasks: (1)
step recognition and (2) intra-video retrieval over a dataset of temporally
segmented and labeled tasks in International Space Station spacewalk
recordings. In tandem, the two tasks quantify a model's ability to make use of:
(1) out-of-domain visual information; (2) a high temporal context window; and
(3) multimodal (text + video) domains. This departs from existing benchmarks
for procedural video understanding, which typically deal with short context
lengths and can be solved with a single modality. Spacewalk-18, with its
inherent multimodal and long-form complexity, exposes the high difficulty of
task recognition and segmentation. We find that state-of-the-art methods
perform poorly on our benchmark, demonstrating that the goal of generalizable
procedural video understanding models is far out and underscoring the need to
develop new approaches to these tasks. Data, model, and code will be publicly
released.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18775" title="Abstract">arXiv:2311.18775</a> [<a href="/pdf/2311.18775" title="Download PDF">pdf</a>, <a href="/format/2311.18775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zineng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Khademi%2C+M">Mahmoud Khademi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenguang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://codi-2.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present CoDi-2, a versatile and interactive Multimodal Large Language
Model (MLLM) that can follow complex multimodal interleaved instructions,
conduct in-context learning (ICL), reason, chat, edit, etc., in an any-to-any
input-output modality paradigm. By aligning modalities with language for both
encoding and generation, CoDi-2 empowers Large Language Models (LLMs) to not
only understand complex modality-interleaved instructions and in-context
examples, but also autoregressively generate grounded and coherent multimodal
outputs in the continuous feature space. To train CoDi-2, we build a
large-scale generation dataset encompassing in-context multimodal instructions
across text, vision, and audio. CoDi-2 demonstrates a wide range of zero-shot
capabilities for multimodal generation, such as in-context learning, reasoning,
and compositionality of any-to-any modality generation through multi-round
interactive conversation. CoDi-2 surpasses previous domain-specific models on
tasks such as subject-driven image generation, vision transformation, and audio
editing. CoDi-2 signifies a substantial breakthrough in developing a
comprehensive multimodal foundation model adept at interpreting in-context
language-vision-audio interleaved instructions and producing multimodal
outputs.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18778" title="Abstract">arXiv:2311.18778</a> [<a href="/pdf/2311.18778" title="Download PDF">pdf</a>, <a href="/format/2311.18778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mavericks at BLP-2023 Task 1: Ensemble-based Approach Using Language  Models for Violence Inciting Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Page%2C+S">Saurabh Page</a>, 
<a href="/search/cs?searchtype=author&query=Mangalvedhekar%2C+S">Sudeep Mangalvedhekar</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+K">Kshitij Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Chavan%2C+T">Tanmay Chavan</a>, 
<a href="/search/cs?searchtype=author&query=Sonawane%2C+S">Sheetal Sonawane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, accepted at the BLP Workshop, EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents our work for the Violence Inciting Text Detection shared
task in the First Workshop on Bangla Language Processing. Social media has
accelerated the propagation of hate and violence-inciting speech in society. It
is essential to develop efficient mechanisms to detect and curb the propagation
of such texts. The problem of detecting violence-inciting texts is further
exacerbated in low-resource settings due to sparse research and less data. The
data provided in the shared task consists of texts in the Bangla language,
where each example is classified into one of the three categories defined based
on the types of violence-inciting texts. We try and evaluate several BERT-based
models, and then use an ensemble of the models as our final submission. Our
submission is ranked 10th in the final leaderboard of the shared task with a
macro F1 score of 0.737.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18780" title="Abstract">arXiv:2311.18780</a> [<a href="/pdf/2311.18780" title="Download PDF">pdf</a>, <a href="/format/2311.18780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiResFormer: Transformer with Adaptive Multi-Resolution Modeling for  General Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Linfeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+J">Ji Xin</a>, 
<a href="/search/cs?searchtype=author&query=Labach%2C+A">Alex Labach</a>, 
<a href="/search/cs?searchtype=author&query=Zuberi%2C+S">Saba Zuberi</a>, 
<a href="/search/cs?searchtype=author&query=Volkovs%2C+M">Maksims Volkovs</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+R+G">Rahul G. Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformer-based models have greatly pushed the boundaries of time series
forecasting recently. Existing methods typically encode time series data into
$\textit{patches}$ using one or a fixed set of patch lengths. This, however,
could result in a lack of ability to capture the variety of intricate temporal
dependencies present in real-world multi-periodic time series. In this paper,
we propose MultiResFormer, which dynamically models temporal variations by
adaptively choosing optimal patch lengths. Concretely, at the beginning of each
layer, time series data is encoded into several parallel branches, each using a
detected periodicity, before going through the transformer encoder block. We
conduct extensive evaluations on long- and short-term forecasting datasets
comparing MultiResFormer with state-of-the-art baselines. MultiResFormer
outperforms patch-based Transformer baselines on long-term forecasting tasks
and also consistently outperforms CNN baselines by a large margin, while using
much fewer parameters than these baselines.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18783" title="Abstract">arXiv:2311.18783</a> [<a href="/pdf/2311.18783" title="Download PDF">pdf</a>, <a href="/format/2311.18783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust and adaptive GenEO-type domain decomposition preconditioner for  $\mathbf{H}(\mathbf{curl})$ problems in general non-convex three-dimensional  geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bootland%2C+N">Niall Bootland</a>, 
<a href="/search/math?searchtype=author&query=Dolean%2C+V">Victorita Dolean</a>, 
<a href="/search/math?searchtype=author&query=Nataf%2C+F">Fr&#xe9;d&#xe9;ric Nataf</a>, 
<a href="/search/math?searchtype=author&query=Tournier%2C+P">Pierre-Henri Tournier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">In this paper we develop and analyse domain decomposition methods for linear
systems of equations arising from conforming finite element discretisations of
positive Maxwell-type equations, namely for $\mathbf{H}(\mathbf{curl})$
problems. It is well known that convergence of domain decomposition methods
rely heavily on the efficiency of the coarse space used in the second level. We
design adaptive coarse spaces that complement a near-kernel space made from the
gradient of scalar functions. The new class of preconditioner is inspired by
the idea of subspace decomposition, but based on spectral coarse spaces, and is
specially designed for curl-conforming discretisations of Maxwell's equations
in heterogeneous media on general domains which may have holes. Our approach
has wider applicability and theoretical justification than the well-known
Hiptmair-Xu auxiliary space preconditioner, with results extending to the
variable coefficient case and non-convex domains at the expense of a larger
coarse space.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18787" title="Abstract">arXiv:2311.18787</a> [<a href="/pdf/2311.18787" title="Download PDF">pdf</a>, <a href="/format/2311.18787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Federated Optimization over Semi-Decentralized  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">In large-scale federated and decentralized learning, communication efficiency
is one of the most challenging bottlenecks. While gossip communication -- where
agents can exchange information with their connected neighbors -- is more
cost-effective than communicating with the remote server, it often requires a
greater number of communication rounds, especially for large and sparse
networks. To tackle the trade-off, we examine the communication efficiency
under a semi-decentralized communication protocol, in which agents can perform
both agent-to-agent and agent-to-server communication in a probabilistic
manner. We design a tailored communication-efficient algorithm over
semi-decentralized networks, referred to as PISCO, which inherits the
robustness to data heterogeneity thanks to gradient tracking and allows
multiple local updates for saving communication. We establish the convergence
rate of PISCO for nonconvex problems and show that PISCO enjoys a linear
speedup in terms of the number of agents and local updates. Our numerical
results highlight the superior communication efficiency of PISCO and its
resilience to data heterogeneity and various network topologies.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18789" title="Abstract">arXiv:2311.18789</a> [<a href="/pdf/2311.18789" title="Download PDF">pdf</a>, <a href="/format/2311.18789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised learning architecture based on neural Darwinism and  Hopfield networks recognizes symbols with high accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stepanik%2C+M">Mario Stepanik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">This paper introduces a novel unsupervised learning paradigm inspired by
Gerald Edelman's theory of neuronal group selection ("Neural Darwinism"). The
presented automaton learns to recognize arbitrary symbols (e.g., letters of an
alphabet) when they are presented repeatedly, as they are when children learn
to read. On a second hierarchical level, the model creates abstract categories
representing the learnt symbols. The fundamental computational unit are simple
McCulloch-Pitts neurons arranged into fully-connected groups (Hopfield networks
with randomly initialized weights), which are "selected", in an evolutionary
sense, through symbol presentation. The learning process is fully tractable and
easily interpretable for humans, in contrast to most neural network
architectures. Computational properties of Hopfield networks enabling pattern
recognition are discussed. In simulations, the model achieves high accuracy in
learning the letters of the Latin alphabet, presented as binary patterns on a
grid. This paper is a proof of concept with no claims to state-of-the-art
performance in letter recognition, but hopefully inspires new thinking in
bio-inspired machine learning.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18791" title="Abstract">arXiv:2311.18791</a> [<a href="/pdf/2311.18791" title="Download PDF">pdf</a>, <a href="/format/2311.18791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Weighted Sum Age of Information with Open-Loop Cyclic  Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamgam%2C+E+O">Ege Orkun Gamgam</a>, 
<a href="/search/cs?searchtype=author&query=Akar%2C+N">Nail Akar</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We study the scheduling problem in a status update system composed of an
arbitrary number of information sources with different service time
distributions and weights for the purpose of minimizing the weighted sum age of
information (AoI). In particular, we study open-loop schedulers which rely only
on the statistics (specifically, only on the first two moments) of the source
service times, in contrast to closed-loop schedulers that also make use of the
actual realizations of the service times and the AoI processes in making
scheduling decisions. Open-loop scheduling policies can be constructed off-line
and are simpler to implement compared to their closed-loop counterparts. We
consider the generate-at-will (GAW) model, and develop an analytical method to
calculate the exact AoI for the probabilistic and cyclic open-loop schedulers.
In both cases, the server initiates the sampling of a source and the ensuing
transmission of the update packet from the source to the server in an open-loop
manner; either based on a certain probability (probabilistic scheme) or
according to a deterministic cyclic pattern (cyclic scheme). We derive the
optimum open-loop cyclic scheduling policy in closed form for the specific case
of N=2 sources and propose well-performing heuristic cyclic schedulers for
general number of sources, i.e., N&gt;2. We study the proposed cyclic schedulers
against probabilistic schedulers and several existing methods in the literature
to validate their effectiveness.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18792" title="Abstract">arXiv:2311.18792</a> [<a href="/pdf/2311.18792" title="Download PDF">pdf</a>, <a href="/ps/2311.18792" title="Download PostScript">ps</a>, <a href="/format/2311.18792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Sharing in Energy Communities: A Cooperative Game Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alahmed%2C+A+S">Ahmed S. Alahmed</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+L">Lang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH); Systems and Control (eess.SY)

</div>
<p class="mathjax">We analyze the overall benefits of an energy community cooperative game under
which distributed energy resources (DER) are shared behind a regulated
distribution utility meter under a general net energy metering (NEM) tariff.
Two community DER scheduling algorithms are examined. The first is a community
with centrally controlled DER, whereas the second is decentralized letting its
members schedule their own DER locally. For both communities, we prove that the
cooperative game's value function is superadditive, hence the grand coalition
achieves the highest welfare. We also prove the balancedness of the cooperative
game under the two DER scheduling algorithms, which means that there is a
welfare re-distribution scheme that de-incentivizes players from leaving the
grand coalition to form smaller ones. Lastly, we present five ex-post and an
ex-ante welfare re-distribution mechanisms and evaluate them in simulation, in
addition to investigating the performance of various community sizes under the
two DER scheduling algorithms.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18799" title="Abstract">arXiv:2311.18799</a> [<a href="/pdf/2311.18799" title="Download PDF">pdf</a>, <a href="/format/2311.18799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-InstructBLIP: A Framework for aligning X-Modal instruction-aware  representations to LLMs and Emergent Cross-modal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panagopoulou%2C+A">Artemis Panagopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Le Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongxu Li</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Niebles%2C+J+C">Juan Carlos Niebles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Vision-language pre-training and instruction tuning have demonstrated
general-purpose capabilities in 2D visual reasoning tasks by aligning visual
encoders with state-of-the-art large language models (LLMs). In this paper, we
introduce a simple, yet effective, cross-modality framework built atop frozen
LLMs that allows the integration of various modalities without extensive
modality-specific customization. To facilitate instruction-modality
fine-tuning, we collect high-quality instruction tuning data in an automatic
and scalable manner, composed of 24K QA samples for audio and 250K QA samples
for 3D. Leveraging instruction-aware representations, our model performs
comparably with leading-edge counterparts without the need of extensive
modality-specific pre-training or customization. Furthermore, our approach
demonstrates cross-modal reasoning abilities across two or more input
modalities, despite each modality projection being trained individually. To
study the model's cross-modal abilities, we contribute a novel Discriminative
Cross-modal Reasoning (DisCRn) evaluation task, comprising 9K audio-video QA
samples and 28K image-3D QA samples that require the model to reason
discriminatively across disparate input modalities.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18801" title="Abstract">arXiv:2311.18801</a> [<a href="/pdf/2311.18801" title="Download PDF">pdf</a>, <a href="/format/2311.18801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Global Structure-from-Motion with a Deep Front-End
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baid%2C+A">Ayush Baid</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+J">John Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Driver%2C+T">Travis Driver</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+A">Akshay Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Stepanyan%2C+H">Hayk Stepanyan</a>, 
<a href="/search/cs?searchtype=author&query=Dellaert%2C+F">Frank Dellaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While initial approaches to Structure-from-Motion (SfM) revolved around both
global and incremental methods, most recent applications rely on incremental
systems to estimate camera poses due to their superior robustness. Though there
has been tremendous progress in SfM `front-ends' powered by deep models learned
from data, the state-of-the-art (incremental) SfM pipelines still rely on
classical SIFT features, developed in 2004. In this work, we investigate
whether leveraging the developments in feature extraction and matching helps
global SfM perform on par with the SOTA incremental SfM approach (COLMAP). To
do so, we design a modular SfM framework that allows us to easily combine
developments in different stages of the SfM pipeline. Our experiments show that
while developments in deep-learning based two-view correspondence estimation do
translate to improvements in point density for scenes reconstructed with global
SfM, none of them outperform SIFT when comparing with incremental SfM results
on a range of datasets. Our SfM system is designed from the ground up to
leverage distributed computation, enabling us to parallelize computation on
multiple machines and scale to large scenes.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18803" title="Abstract">arXiv:2311.18803</a> [<a href="/pdf/2311.18803" title="Download PDF">pdf</a>, <a href="/format/2311.18803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIOCLIP: A Vision Foundation Model for the Tree of Life
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaman Wu</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+M+J">Matthew J Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Campolongo%2C+E+G">Elizabeth G Campolongo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C+H">Chan Hee Song</a>, 
<a href="/search/cs?searchtype=author&query=Carlyn%2C+D+E">David Edward Carlyn</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dahdul%2C+W+M">Wasila M Dahdul</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Charles Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Berger-Wolf%2C+T">Tanya Berger-Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Images of the natural world, collected by a variety of cameras, from drones
to individual phones, are increasingly abundant sources of biological
information. There is an explosion of computational methods and tools,
particularly computer vision, for extracting biologically relevant information
from images for science and conservation. Yet most of these are bespoke
approaches designed for a specific task and are not easily adaptable or
extendable to new questions, contexts, and datasets. A vision model for general
organismal biology questions on images is of timely need. To approach this, we
curate and release TreeOfLife-10M, the largest and most diverse ML-ready
dataset of biology images. We then develop BioCLIP, a foundation model for the
tree of life, leveraging the unique properties of biology captured by
TreeOfLife-10M, namely the abundance and variety of images of plants, animals,
and fungi, together with the availability of rich structured biological
knowledge. We rigorously benchmark our approach on diverse fine-grained biology
classification tasks, and find that BioCLIP consistently and substantially
outperforms existing baselines (by 17% to 20% absolute). Intrinsic evaluation
reveals that BioCLIP has learned a hierarchical representation conforming to
the tree of life, shedding light on its strong generalizability. Our code,
models and data will be made available at
https://github.com/Imageomics/bioclip.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18805" title="Abstract">arXiv:2311.18805</a> [<a href="/pdf/2311.18805" title="Download PDF">pdf</a>, <a href="/format/2311.18805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural  Scrambled Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+T">Takeshi Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+Y">Yutaka Matsuo</a>, 
<a href="/search/cs?searchtype=author&query=Iwasawa%2C+Y">Yusuke Iwasawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (with an additional analysis section in appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While Large Language Models (LLMs) have achieved remarkable performance in
many tasks, much about their inner workings remains unclear. In this study, we
present novel experimental insights into the resilience of LLMs, particularly
GPT-4, when subjected to extensive character-level permutations. To investigate
this, we first propose the Scrambled Bench, a suite designed to measure the
capacity of LLMs to handle scrambled input, in terms of both recovering
scrambled sentences and answering questions given scrambled context. The
experimental results indicate that most powerful LLMs demonstrate the
capability akin to typoglycemia, a phenomenon where humans can understand the
meaning of words even when the letters within those words are scrambled, as
long as the first and last letters remain in place. More surprisingly, we found
that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even
under the extreme condition, a task that poses significant challenges for other
LLMs and often even for humans. Specifically, GPT-4 can almost perfectly
reconstruct the original sentences from scrambled ones, decreasing the edit
distance by 95%, even when all letters within each word are entirely scrambled.
It is counter-intuitive that LLMs can exhibit such resilience despite severe
disruption to input tokenization caused by scrambled text.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18806" title="Abstract">arXiv:2311.18806</a> [<a href="/pdf/2311.18806" title="Download PDF">pdf</a>, <a href="/format/2311.18806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Baseline for Quantitative Precipitation Forecasting in  Weather4cast 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Punjabi%2C+A">Akshay Punjabi</a>, 
<a href="/search/cs?searchtype=author&query=Ayala%2C+P+I">Pablo Izquierdo Ayala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, Weather4Cast 2023 challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Accurate precipitation forecasting is indispensable for informed
decision-making across various industries. However, the computational demands
of current models raise environmental concerns. We address the critical need
for accurate precipitation forecasting while considering the environmental
impact of computational resources and propose a minimalist U-Net architecture
to be used as a baseline for future weather forecasting initiatives.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18807" title="Abstract">arXiv:2311.18807</a> [<a href="/pdf/2311.18807" title="Download PDF">pdf</a>, <a href="/format/2311.18807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-registration for Predictive Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hofman%2C+J+M">Jake M. Hofman</a>, 
<a href="/search/cs?searchtype=author&query=Chatzimparmpas%2C+A">Angelos Chatzimparmpas</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Amit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Watts%2C+D+J">Duncan J. Watts</a>, 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Amid rising concerns of reproducibility and generalizability in predictive
modeling, we explore the possibility and potential benefits of introducing
pre-registration to the field. Despite notable advancements in predictive
modeling, spanning core machine learning tasks to various scientific
applications, challenges such as overlooked contextual factors, data-dependent
decision-making, and unintentional re-use of test data have raised questions
about the integrity of results. To address these issues, we propose adapting
pre-registration practices from explanatory modeling to predictive modeling. We
discuss current best practices in predictive modeling and their limitations,
introduce a lightweight pre-registration template, and present a qualitative
study with machine learning researchers to gain insight into the effectiveness
of pre-registration in preventing biased estimates and promoting more reliable
research outcomes. We conclude by exploring the scope of problems that
pre-registration can address in predictive modeling and acknowledging its
limitations within this context.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18809" title="Abstract">arXiv:2311.18809</a> [<a href="/pdf/2311.18809" title="Download PDF">pdf</a>, <a href="/format/2311.18809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoundPose: Unseen Object Pose Estimation with Foundation Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96rnek%2C+E+P">Evin P&#x131;nar &#xd6;rnek</a>, 
<a href="/search/cs?searchtype=author&query=Labb%C3%A9%2C+Y">Yann Labb&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tekin%2C+B">Bugra Tekin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lingni Ma</a>, 
<a href="/search/cs?searchtype=author&query=Keskin%2C+C">Cem Keskin</a>, 
<a href="/search/cs?searchtype=author&query=Forster%2C+C">Christian Forster</a>, 
<a href="/search/cs?searchtype=author&query=Hodan%2C+T">Tomas Hodan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We propose FoundPose, a method for 6D pose estimation of unseen rigid objects
from a single RGB image. The method assumes that 3D models of the objects are
available but does not require any object-specific training. This is achieved
by building upon DINOv2, a recent vision foundation model with impressive
generalization capabilities. An online pose estimation stage is supported by a
minimal object representation that is built during a short onboarding stage
from DINOv2 patch features extracted from rendered object templates. Given a
query image with an object segmentation mask, FoundPose first rapidly retrieves
a handful of similarly looking templates by a DINOv2-based bag-of-words
approach. Pose hypotheses are then generated from 2D-3D correspondences
established by matching DINOv2 patch features between the query image and a
retrieved template, and finally optimized by featuremetric refinement. The
method can handle diverse objects, including challenging ones with symmetries
and without any texture, and noticeably outperforms existing RGB methods for
coarse pose estimation in both accuracy and speed on the standard BOP
benchmark. With the featuremetric and additional MegaPose refinement, which are
demonstrated complementary, the method outperforms all RGB competitors. Source
code is at: evinpinar.github.io/foundpose.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18810" title="Abstract">arXiv:2311.18810</a> [<a href="/pdf/2311.18810" title="Download PDF">pdf</a>, <a href="/format/2311.18810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Nonconvex PnP-ADMM with MMSE Denoisers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chicago Park</a>, 
<a href="/search/cs?searchtype=author&query=Shoushtari%2C+S">Shirin Shoushtari</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Weijie Gan</a>, 
<a href="/search/cs?searchtype=author&query=Kamilov%2C+U+S">Ulugbek S. Kamilov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Plug-and-Play Alternating Direction Method of Multipliers (PnP-ADMM) is a
widely-used algorithm for solving inverse problems by integrating physical
measurement models and convolutional neural network (CNN) priors. PnP-ADMM has
been theoretically proven to converge for convex data-fidelity terms and
nonexpansive CNNs. It has however been observed that PnP-ADMM often empirically
converges even for expansive CNNs. This paper presents a theoretical
explanation for the observed stability of PnP-ADMM based on the interpretation
of the CNN prior as a minimum mean-squared error (MMSE) denoiser. Our
explanation parallels a similar argument recently made for the iterative
shrinkage/thresholding algorithm variant of PnP (PnP-ISTA) and relies on the
connection between MMSE denoisers and proximal operators. We also numerically
evaluate the performance gap between PnP-ADMM using a nonexpansive DnCNN
denoiser and expansive DRUNet denoiser, thus motivating the use of expansive
CNNs.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18812" title="Abstract">arXiv:2311.18812</a> [<a href="/pdf/2311.18812" title="Download PDF">pdf</a>, <a href="/format/2311.18812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Do Llamas Really Think? Revealing Preference Biases in Language  Model Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Raphael Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ture%2C+F">Ferhan Ture</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Do large language models (LLMs) exhibit sociodemographic biases, even when
they decline to respond? To bypass their refusal to "speak," we study this
research question by probing contextualized embeddings and exploring whether
this bias is encoded in its latent representations. We propose a logistic
Bradley-Terry probe which predicts word pair preferences of LLMs from the
words' hidden vectors. We first validate our probe on three pair preference
tasks and thirteen LLMs, where we outperform the word embedding association
test (WEAT), a standard approach in testing for implicit association, by a
relative 27% in error rate. We also find that word pair preferences are best
represented in the middle layers. Next, we transfer probes trained on harmless
tasks (e.g., pick the larger number) to controversial ones (compare
ethnicities) to examine biases in nationality, politics, religion, and gender.
We observe substantial bias for all target classes: for instance, the Mistral
model implicitly prefers Europe to Africa, Christianity to Judaism, and
left-wing to right-wing politics, despite declining to answer. This suggests
that instruction fine-tuning does not necessarily debias contextualized
embeddings. Our codebase is at https://github.com/castorini/biasprobe.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18814" title="Abstract">arXiv:2311.18814</a> [<a href="/pdf/2311.18814" title="Download PDF">pdf</a>, <a href="/format/2311.18814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Underwater Image Enhancement All Object Detectors Need?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jichang Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wanru He</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Huan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huihui Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zenan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater object detection is a crucial and challenging problem in marine
engineering and aquatic robot. The difficulty is partly because of the
degradation of underwater images caused by light selective absorption and
scattering. Intuitively, enhancing underwater images can benefit high-level
applications like underwater object detection. However, it is still unclear
whether all object detectors need underwater image enhancement as
pre-processing. We therefore pose the questions "Does underwater image
enhancement really improve underwater object detection?" and "How does
underwater image enhancement contribute to underwater object detection?". With
these two questions, we conduct extensive studies. Specifically, we use 18
state-of-the-art underwater image enhancement algorithms, covering traditional,
CNN-based, and GAN-based algorithms, to pre-process underwater object detection
data. Then, we retrain 7 popular deep learning-based object detectors using the
corresponding results enhanced by different algorithms, obtaining 126
underwater object detection models. Coupled with 7 object detection models
retrained using raw underwater images, we employ these 133 models to
comprehensively analyze the effect of underwater image enhancement on
underwater object detection. We expect this study can provide sufficient
exploration to answer the aforementioned questions and draw more attention of
the community to the joint problem of underwater image enhancement and
underwater object detection. The pre-trained models and results are publicly
available and will be regularly updated. Project page:
https://github.com/BIGWangYuDong/lqit/tree/main/configs/detection/uw_enhancement_affect_detection.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18815" title="Abstract">arXiv:2311.18815</a> [<a href="/pdf/2311.18815" title="Download PDF">pdf</a>, <a href="/format/2311.18815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMMA: Immunizing text-to-image Models against Malicious Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yijia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+R+A">Raymond A. Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advancements in text-to-image models and fine-tuning methods have led to the
increasing risk of malicious adaptation, i.e., fine-tuning to generate harmful
unauthorized content. Recent works, e.g., Glaze or MIST, have developed
data-poisoning techniques which protect the data against adaptation methods. In
this work, we consider an alternative paradigm for protection. We propose to
``immunize'' the model by learning model parameters that are difficult for the
adaptation methods when fine-tuning malicious content; in short IMMA. Empirical
results show IMMA's effectiveness against malicious adaptations, including
mimicking the artistic style and learning of inappropriate/unauthorized
content, over three adaptation methods: LoRA, Textual-Inversion, and
DreamBooth.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18817" title="Abstract">arXiv:2311.18817</a> [<a href="/pdf/2311.18817" title="Download PDF">pdf</a>, <a href="/format/2311.18817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce  Grokking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+K">Kaifeng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jikai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent work by Power et al. (2022) highlighted a surprising "grokking"
phenomenon in learning arithmetic tasks: a neural net first "memorizes" the
training set, resulting in perfect training accuracy but near-random test
accuracy, and after training for sufficiently longer, it suddenly transitions
to perfect test accuracy. This paper studies the grokking phenomenon in
theoretical setups and shows that it can be induced by a dichotomy of early and
late phase implicit biases. Specifically, when training homogeneous neural nets
with large initialization and small weight decay on both classification and
regression tasks, we prove that the training process gets trapped at a solution
corresponding to a kernel predictor for a long time, and then a very sharp
transition to min-norm/max-margin predictors occurs, leading to a dramatic
change in test accuracy.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18820" title="Abstract">arXiv:2311.18820</a> [<a href="/pdf/2311.18820" title="Download PDF">pdf</a>, <a href="/format/2311.18820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks and Defenses for Wireless Signal Classifiers using  CDI-aware GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Sujata Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Soysal%2C+A">Alkan Soysal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">We introduce a Channel Distribution Information (CDI)-aware Generative
Adversarial Network (GAN), designed to address the unique challenges of
adversarial attacks in wireless communication systems. The generator in this
CDI-aware GAN maps random input noise to the feature space, generating
perturbations intended to deceive a target modulation classifier. Its
discriminators play a dual role: one enforces that the perturbations follow a
Gaussian distribution, making them indistinguishable from Gaussian noise, while
the other ensures these perturbations account for realistic channel effects and
resemble no-channel perturbations.
<br />Our proposed CDI-aware GAN can be used as an attacker and a defender. In
attack scenarios, the CDI-aware GAN demonstrates its prowess by generating
robust adversarial perturbations that effectively deceive the target
classifier, outperforming known methods. Furthermore, CDI-aware GAN as a
defender significantly improves the target classifier's resilience against
adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18822" title="Abstract">arXiv:2311.18822</a> [<a href="/pdf/2311.18822" title="Download PDF">pdf</a>, <a href="/format/2311.18822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ElasticDiffusion: Training-free Arbitrary Size Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haji-Ali%2C+M">Moayed Haji-Ali</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+G">Guha Balakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+V">Vicente Ordonez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have revolutionized image generation in recent years, yet
they are still limited to a few sizes and aspect ratios. We propose
ElasticDiffusion, a novel training-free decoding method that enables pretrained
text-to-image diffusion models to generate images with various sizes.
ElasticDiffusion attempts to decouple the generation trajectory of a pretrained
model into local and global signals. The local signal controls low-level pixel
information and can be estimated on local patches, while the global signal is
used to maintain overall structural consistency and is estimated with a
reference image. We test our method on CelebA-HQ (faces) and LAION-COCO
(objects/indoor/outdoor scenes). Our experiments and qualitative results show
superior image coherence quality across aspect ratios compared to
MultiDiffusion and the standard decoding strategy of Stable Diffusion. Code:
https://github.com/MoayedHajiAli/ElasticDiffusion-official.git
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18823" title="Abstract">arXiv:2311.18823</a> [<a href="/pdf/2311.18823" title="Download PDF">pdf</a>, <a href="/format/2311.18823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initializing Models with Larger Ones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiqiu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vishniakov%2C+K">Kirill Vishniakov</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yida Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Weight initialization plays an important role in neural network training.
Widely used initialization methods are proposed and evaluated for networks that
are trained from scratch. However, the growing number of pretrained models now
offers new opportunities for tackling this classical problem of weight
initialization. In this work, we introduce weight selection, a method for
initializing smaller models by selecting a subset of weights from a pretrained
larger model. This enables the transfer of knowledge from pretrained weights to
smaller models. Our experiments demonstrate that weight selection can
significantly enhance the performance of small models and reduce their training
time. Notably, it can also be used together with knowledge distillation. Weight
selection offers a new approach to leverage the power of pretrained models in
resource-constrained settings, and we hope it can be a useful tool for training
small models in the large-model era. Code is available at
https://github.com/OscarXZQ/weight-selection.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18824" title="Abstract">arXiv:2311.18824</a> [<a href="/pdf/2311.18824" title="Download PDF">pdf</a>, <a href="/format/2311.18824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Framework for Generalizing Network Traffic Prediction  towards Uncertain Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Downey%2C+A">Alexander Downey</a>, 
<a href="/search/cs?searchtype=author&query=Tuna%2C+E">Evren Tuna</a>, 
<a href="/search/cs?searchtype=author&query=Soysal%2C+A">Alkan Soysal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">We have developed a new framework using time-series analysis for dynamically
assigning mobile network traffic prediction models in previously unseen
wireless environments. Our framework selectively employs learned behaviors,
outperforming any single model with over a 50% improvement relative to current
studies. More importantly, it surpasses traditional approaches without needing
prior knowledge of a cell. While this paper focuses on network traffic
prediction using our adaptive forecasting framework, this framework can also be
applied to other machine learning applications in uncertain environments.
<br />The framework begins with unsupervised clustering of time-series data to
identify unique trends and seasonal patterns. Subsequently, we apply supervised
learning for traffic volume prediction within each cluster. This specialization
towards specific traffic behaviors occurs without penalties from spatial and
temporal variations. Finally, the framework adaptively assigns trained models
to new, previously unseen cells. By analyzing real-time measurements of a cell,
our framework intelligently selects the most suitable cluster for that cell at
any given time, with cluster assignment dynamically adjusting to
spatio-temporal fluctuations.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18825" title="Abstract">arXiv:2311.18825</a> [<a href="/pdf/2311.18825" title="Download PDF">pdf</a>, <a href="/format/2311.18825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAST: Cross-Attention in Space and Time for Video Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongseo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinwoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an accepted NeurIPS 2023. Project webpage is available at <a href="https://jong980812.github.io/CAST.github.io/">this https URL</a> Code is available at <a href="https://github.com/KHU-VLL/CAST">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognizing human actions in videos requires spatial and temporal
understanding. Most existing action recognition models lack a balanced
spatio-temporal understanding of videos. In this work, we propose a novel
two-stream architecture, called Cross-Attention in Space and Time (CAST), that
achieves a balanced spatio-temporal understanding of videos using only RGB
input. Our proposed bottleneck cross-attention mechanism enables the spatial
and temporal expert models to exchange information and make synergistic
predictions, leading to improved performance. We validate the proposed method
with extensive experiments on public benchmarks with different characteristics:
EPIC-KITCHENS-100, Something-Something-V2, and Kinetics-400. Our method
consistently shows favorable performance across these datasets, while the
performance of existing methods fluctuates depending on the dataset
characteristics.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18826" title="Abstract">arXiv:2311.18826</a> [<a href="/pdf/2311.18826" title="Download PDF">pdf</a>, <a href="/format/2311.18826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+K">Kaiwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This manuscript enriches the framework of continuous normalizing flows (CNFs)
within causal inference, primarily to augment the geometric properties of
parametric submodels used in targeted maximum likelihood estimation (TMLE). By
introducing an innovative application of CNFs, we construct a refined series of
parametric submodels that enable a directed interpolation between the prior
distribution $p_0$ and the empirical distribution $p_1$. This proposed
methodology serves to optimize the semiparametric efficiency bound in causal
inference by orchestrating CNFs to align with Wasserstein gradient flows. Our
approach not only endeavors to minimize the mean squared error in the
estimation but also imbues the estimators with geometric sophistication,
thereby enhancing robustness against misspecification. This robustness is
crucial, as it alleviates the dependence on the standard $n^{\frac{1}{4}}$ rate
for a doubly-robust perturbation direction in TMLE. By incorporating robust
optimization principles and differential geometry into the estimators, the
developed geometry-aware CNFs represent a significant advancement in the
pursuit of doubly robust causal inference.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18827" title="Abstract">arXiv:2311.18827</a> [<a href="/pdf/2311.18827" title="Download PDF">pdf</a>, <a href="/format/2311.18827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-Conditioned Image Animation for Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wilson Yan</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+A">Andrew Brown</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Girdhar%2C+R">Rohit Girdhar</a>, 
<a href="/search/cs?searchtype=author&query=Azadi%2C+S">Samaneh Azadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://facebookresearch.github.io/MoCA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">We introduce MoCA, a Motion-Conditioned Image Animation approach for video
editing. It leverages a simple decomposition of the video editing problem into
image editing followed by motion-conditioned image animation. Furthermore,
given the lack of robust evaluation datasets for video editing, we introduce a
new benchmark that measures edit capability across a wide variety of tasks,
such as object replacement, background changes, style changes, and motion
edits. We present a comprehensive human evaluation of the latest video editing
methods along with MoCA, on our proposed benchmark. MoCA establishes a new
state-of-the-art, demonstrating greater human preference win-rate, and
outperforming notable recent approaches including Dreamix (63%), MasaCtrl
(75%), and Tune-A-Video (72%), with especially significant improvements for
motion edits.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18828" title="Abstract">arXiv:2311.18828</a> [<a href="/pdf/2311.18828" title="Download PDF">pdf</a>, <a href="/format/2311.18828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-step Diffusion with Distribution Matching Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+T">Tianwei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Micha&#xeb;l Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+F">Fr&#xe9;do Durand</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+W+T">William T. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taesung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tianweiy.github.io/dmd/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models generate high-quality images but require dozens of forward
passes. We introduce Distribution Matching Distillation (DMD), a procedure to
transform a diffusion model into a one-step image generator with minimal impact
on image quality. We enforce the one-step image generator match the diffusion
model at distribution level, by minimizing an approximate KL divergence whose
gradient can be expressed as the difference between 2 score functions, one of
the target distribution and the other of the synthetic distribution being
produced by our one-step generator. The score functions are parameterized as
two diffusion models trained separately on each distribution. Combined with a
simple regression loss matching the large-scale structure of the multi-step
diffusion outputs, our method outperforms all published few-step diffusion
approaches, reaching 2.62 FID on ImageNet 64x64 and 11.49 FID on zero-shot
COCO-30k, comparable to Stable Diffusion but orders of magnitude faster.
Utilizing FP16 inference, our model can generate images at 20 FPS on modern
hardware.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18829" title="Abstract">arXiv:2311.18829</a> [<a href="/pdf/2311.18829" title="Download PDF">pdf</a>, <a href="/format/2311.18829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wenming Weng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dacheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q+D+Z">Qi Dai Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+K">Kai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baining Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://wangyanhui666.github.io/MicroCinema.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present MicroCinema, a straightforward yet effective framework for
high-quality and coherent text-to-video generation. Unlike existing approaches
that align text prompts with video directly, MicroCinema introduces a
Divide-and-Conquer strategy which divides the text-to-video into a two-stage
process: text-to-image generation and image\&amp;text-to-video generation. This
strategy offers two significant advantages. a) It allows us to take full
advantage of the recent advances in text-to-image models, such as Stable
Diffusion, Midjourney, and DALLE, to generate photorealistic and highly
detailed images. b) Leveraging the generated image, the model can allocate less
focus to fine-grained appearance details, prioritizing the efficient learning
of motion dynamics. To implement this strategy effectively, we introduce two
core designs. First, we propose the Appearance Injection Network, enhancing the
preservation of the appearance of the given image. Second, we introduce the
Appearance Noise Prior, a novel mechanism aimed at maintaining the capabilities
of pre-trained 2D diffusion models. These design elements empower MicroCinema
to generate high-quality videos with precise motion, guided by the provided
text prompts. Extensive experiments demonstrate the superiority of the proposed
framework. Concretely, MicroCinema achieves SOTA zero-shot FVD of 342.86 on
UCF-101 and 377.40 on MSR-VTT. See
https://wangyanhui666.github.io/MicroCinema.github.io/ for video samples.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18830" title="Abstract">arXiv:2311.18830</a> [<a href="/pdf/2311.18830" title="Download PDF">pdf</a>, <a href="/format/2311.18830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionEditor: Editing Video Motion via Content-Aware Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+S">Shuyuan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xintong Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 15 figures. Project page at <a href="https://francis-rings.github.io/MotionEditor/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing diffusion-based video editing models have made gorgeous advances for
editing attributes of a source video over time but struggle to manipulate the
motion information while preserving the original protagonist's appearance and
background. To address this, we propose MotionEditor, a diffusion model for
video motion editing. MotionEditor incorporates a novel content-aware motion
adapter into ControlNet to capture temporal motion correspondence. While
ControlNet enables direct generation based on skeleton poses, it encounters
challenges when modifying the source motion in the inverted noise due to
contradictory signals between the noise (source) and the condition (reference).
Our adapter complements ControlNet by involving source content to transfer
adapted control signals seamlessly. Further, we build up a two-branch
architecture (a reconstruction branch and an editing branch) with a
high-fidelity attention injection mechanism facilitating branch interaction.
This mechanism enables the editing branch to query the key and value from the
reconstruction branch in a decoupled manner, making the editing branch retain
the original background and protagonist appearance. We also propose a skeleton
alignment algorithm to address the discrepancies in pose size and position.
Experiments demonstrate the promising motion editing ability of MotionEditor,
both qualitatively and quantitatively.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18832" title="Abstract">arXiv:2311.18832</a> [<a href="/pdf/2311.18832" title="Download PDF">pdf</a>, <a href="/format/2311.18832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Diffusion Prior for Generalizable Pixel-Level Semantic  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+H">Hung-Yu Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://shinying.github.io/dmp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contents generated by recent advanced Text-to-Image (T2I) diffusion models
are sometimes too imaginative for existing off-the-shelf property semantic
predictors to estimate due to the immitigable domain gap. We introduce DMP, a
pipeline utilizing pre-trained T2I models as a prior for pixel-level semantic
prediction tasks. To address the misalignment between deterministic prediction
tasks and stochastic T2I models, we reformulate the diffusion process through a
sequence of interpolations, establishing a deterministic mapping between input
RGB images and output prediction distributions. To preserve generalizability,
we use low-rank adaptation to fine-tune pre-trained models. Extensive
experiments across five tasks, including 3D property estimation, semantic
segmentation, and intrinsic image decomposition, showcase the efficacy of the
proposed method. Despite limited-domain training data, the approach yields
faithful estimations for arbitrary images, surpassing existing state-of-the-art
algorithms.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18834" title="Abstract">arXiv:2311.18834</a> [<a href="/pdf/2311.18834" title="Download PDF">pdf</a>, <a href="/format/2311.18834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ART$\boldsymbol{\cdot}$V: Auto-Regressive Text-to-Video Generation with  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wenming Weng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dacheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+K">Kai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yueyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 21 figures. Project page at <a href="https://warranweng.github.io/art.v">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present ART$\boldsymbol{\cdot}$V, an efficient framework for
auto-regressive video generation with diffusion models. Unlike existing methods
that generate entire videos in one-shot, ART$\boldsymbol{\cdot}$V generates a
single frame at a time, conditioned on the previous ones. The framework offers
three distinct advantages. First, it only learns simple continual motions
between adjacent frames, therefore avoiding modeling complex long-range motions
that require huge training data. Second, it preserves the high-fidelity
generation ability of the pre-trained image diffusion models by making only
minimal network modifications. Third, it can generate arbitrarily long videos
conditioned on a variety of prompts such as text, image or their combinations,
making it highly versatile and flexible. To combat the common drifting issue in
AR models, we propose masked diffusion model which implicitly learns which
information can be drawn from reference images rather than network predictions,
in order to reduce the risk of generating inconsistent appearances that cause
drifting. Moreover, we further enhance generation coherence by conditioning it
on the initial frame, which typically contains minimal noise. This is
particularly useful for long video generation. When trained for only two weeks
on four GPUs, ART$\boldsymbol{\cdot}$V already can generate videos with natural
motions, rich details and a high level of aesthetic quality. Besides, it
enables various appealing applications, e.g., composing a long video from
multiple text prompts.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18835" title="Abstract">arXiv:2311.18835</a> [<a href="/pdf/2311.18835" title="Download PDF">pdf</a>, <a href="/format/2311.18835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructSeq: Unifying Vision Tasks with Instruction-conditioned  Multi-modal Sequence Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Rongyao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shilin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingqiu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Empowering models to dynamically accomplish tasks specified through natural
language instructions represents a promising path toward more capable and
general artificial intelligence. In this work, we introduce InstructSeq, an
instruction-conditioned multi-modal modeling framework that unifies diverse
vision tasks through flexible natural language control and handling of both
visual and textual data. InstructSeq employs a multimodal transformer
architecture encompassing visual, language, and sequential modeling. We utilize
a visual encoder to extract image features and a text encoder to encode
instructions. An autoregressive transformer fuses the representations and
generates sequential task outputs. By training with LLM-generated natural
language instructions, InstructSeq acquires a strong comprehension of free-form
instructions for specifying visual tasks. This provides an intuitive interface
for directing capabilities using flexible natural instructions. Without any
task-specific tuning, InstructSeq achieves compelling performance on semantic
segmentation, referring expression segmentation/comprehension, and image
captioning. The flexible control and multi-task unification empower the model
with more human-like versatility and generalizability for computer vision. The
code will be released soon at https://github.com/rongyaofang/InstructSeq.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18836" title="Abstract">arXiv:2311.18836</a> [<a href="/pdf/2311.18836" title="Download PDF">pdf</a>, <a href="/format/2311.18836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoseGPT: Chatting about 3D Human Pose
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+S+K">Sai Kumar Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+P">Priyanka Patel</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Home page: <a href="https://yfeng95.github.io/posegpt">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce PoseGPT, a framework employing Large Language Models (LLMs) to
understand and reason about 3D human poses from images or textual descriptions.
Our work is motivated by the human ability to intuitively understand postures
from a single image or a brief description, a process that intertwines image
interpretation, world knowledge, and an understanding of body language.
Traditional human pose estimation methods, whether image-based or text-based,
often lack holistic scene comprehension and nuanced reasoning, leading to a
disconnect between visual data and its real-world implications. PoseGPT
addresses these limitations by embedding SMPL poses as a distinct signal token
within a multi-modal LLM, enabling direct generation of 3D body poses from both
textual and visual inputs. This approach not only simplifies pose prediction
but also empowers LLMs to apply their world knowledge in reasoning about human
poses, fostering two advanced tasks: speculative pose generation and reasoning
about pose estimation. These tasks involve reasoning about humans to generate
3D poses from subtle text queries, possibly accompanied by images. We establish
benchmarks for these tasks, moving beyond traditional 3D pose generation and
estimation methods. Our results show that PoseGPT outperforms existing
multimodal LLMs and task-sepcific methods on these newly proposed tasks.
Furthermore, PoseGPT's ability to understand and generate 3D human poses based
on complex reasoning opens new directions in human pose analysis.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18837" title="Abstract">arXiv:2311.18837</a> [<a href="/pdf/2311.18837" title="Download PDF">pdf</a>, <a href="/format/2311.18837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIDiff: Translating Videos via Multi-Modal Instructions with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Diffusion models have achieved significant success in image and video
generation. This motivates a growing interest in video editing tasks, where
videos are edited according to provided text descriptions. However, most
existing approaches only focus on video editing for short clips and rely on
time-consuming tuning or inference. We are the first to propose Video
Instruction Diffusion (VIDiff), a unified foundation model designed for a wide
range of video tasks. These tasks encompass both understanding tasks (such as
language-guided video object segmentation) and generative tasks (video editing
and enhancement). Our model can edit and translate the desired results within
seconds based on user instructions. Moreover, we design an iterative
auto-regressive method to ensure consistency in editing and enhancing long
videos. We provide convincing generative results for diverse input videos and
written instructions, both qualitatively and quantitatively. More examples can
be found at our website https://ChenHsing.github.io/VIDiff.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18838" title="Abstract">arXiv:2311.18838</a> [<a href="/pdf/2311.18838" title="Download PDF">pdf</a>, <a href="/format/2311.18838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Distillation in Large Data Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zeyuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and distilled ImageNet-21K dataset are available at <a href="https://github.com/VILA-Lab/SRe2L/tree/main/CDA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Dataset distillation aims to generate a smaller but representative subset
from a large dataset, which allows a model to be trained efficiently, meanwhile
evaluating on the original testing data distribution to achieve decent
performance. Many prior works have aimed to align with diverse aspects of the
original datasets, such as matching the training weight trajectories, gradient,
feature/BatchNorm distributions, etc. In this work, we show how to distill
various large-scale datasets such as full ImageNet-1K/21K under a conventional
input resolution of 224$\times$224 to achieve the best accuracy over all
previous approaches, including SRe$^2$L, TESLA and MTT. To achieve this, we
introduce a simple yet effective ${\bf C}$urriculum ${\bf D}$ata ${\bf
A}$ugmentation ($\texttt{CDA}$) during data synthesis that obtains the accuracy
on large-scale ImageNet-1K and 21K with 63.2% under IPC (Images Per Class) 50
and 36.1% under IPC 20, respectively. Finally, we show that, by integrating all
our enhancements together, the proposed model beats the current
state-of-the-art by more than 4% Top-1 accuracy on ImageNet-1K/21K and for the
first time, reduces the gap to its full-data training counterpart to less than
absolute 15%. Moreover, this work represents the inaugural success in dataset
distillation on larger-scale ImageNet-21K under the standard 224$\times$224
resolution. Our code and distilled ImageNet-21K dataset of 20 IPC, 2K recovery
budget are available at https://github.com/VILA-Lab/SRe2L/tree/main/CDA.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18839" title="Abstract">arXiv:2311.18839</a> [<a href="/pdf/2311.18839" title="Download PDF">pdf</a>, <a href="/format/2311.18839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrafficMOT: A Challenging Dataset for Multi-Object Tracking in Complex  Traffic Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shujun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaowei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A">Angelica Aviles-Rivero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-object tracking in traffic videos is a crucial research area, offering
immense potential for enhancing traffic monitoring accuracy and promoting road
safety measures through the utilisation of advanced machine learning
algorithms. However, existing datasets for multi-object tracking in traffic
videos often feature limited instances or focus on single classes, which cannot
well simulate the challenges encountered in complex traffic scenarios. To
address this gap, we introduce TrafficMOT, an extensive dataset designed to
encompass diverse traffic situations with complex scenarios. To validate the
complexity and challenges presented by TrafficMOT, we conducted comprehensive
empirical studies using three different settings: fully-supervised,
semi-supervised, and a recent powerful zero-shot foundation model Tracking
Anything Model (TAM). The experimental results highlight the inherent
complexity of this dataset, emphasising its value in driving advancements in
the field of traffic monitoring and multi-object tracking.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18840" title="Abstract">arXiv:2311.18840</a> [<a href="/pdf/2311.18840" title="Download PDF">pdf</a>, <a href="/format/2311.18840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just Add $&#x3c0;$! Pose Induced Video Transformers for Understanding  Activities of Daily Living
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reilly%2C+D">Dominick Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srijan Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models will be released at: <a href="https://github.com/dominickrei/pi-vit">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video transformers have become the de facto standard for human action
recognition, yet their exclusive reliance on the RGB modality still limits
their adoption in certain domains. One such domain is Activities of Daily
Living (ADL), where RGB alone is not sufficient to distinguish between visually
similar actions, or actions observed from multiple viewpoints. To facilitate
the adoption of video transformers for ADL, we hypothesize that the
augmentation of RGB with human pose information, known for its sensitivity to
fine-grained motion and multiple viewpoints, is essential. Consequently, we
introduce the first Pose Induced Video Transformer: PI-ViT (or $\pi$-ViT), a
novel approach that augments the RGB representations learned by video
transformers with 2D and 3D pose information. The key elements of $\pi$-ViT are
two plug-in modules, 2D Skeleton Induction Module and 3D Skeleton Induction
Module, that are responsible for inducing 2D and 3D pose information into the
RGB representations. These modules operate by performing pose-aware auxiliary
tasks, a design choice that allows $\pi$-ViT to discard the modules during
inference. Notably, $\pi$-ViT achieves the state-of-the-art performance on
three prominent ADL datasets, encompassing both real-world and large-scale
RGB-D datasets, without requiring poses or additional computational overhead at
inference.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri,  1 Dec 23</h3>
<dl>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04431" title="Abstract">arXiv:2301.04431</a> (cross-list from math.OC) [<a href="/pdf/2301.04431" title="Download PDF">pdf</a>, <a href="/format/2301.04431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive proximal algorithms for convex optimization under local  Lipschitz continuity of the gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Latafat%2C+P">Puya Latafat</a>, 
<a href="/search/math?searchtype=author&query=Themelis%2C+A">Andreas Themelis</a>, 
<a href="/search/math?searchtype=author&query=Stella%2C+L">Lorenzo Stella</a>, 
<a href="/search/math?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Backtracking linesearch is the de facto approach for minimizing continuously
differentiable functions with locally Lipschitz gradient. In recent years, it
has been shown that in the convex setting it is possible to avoid linesearch
altogether, and to allow the stepsize to adapt based on a local smoothness
estimate without any backtracks or evaluations of the function value. In this
work we propose an adaptive proximal gradient method, adaPG, that uses novel
estimates of the local smoothness modulus which leads to less conservative
stepsize updates and that can additionally cope with nonsmooth terms. This idea
is extended to the primal-dual setting where an adaptive three-term primal-dual
algorithm, adaPD, is proposed which can be viewed as an extension of the PDHG
method. Moreover, in this setting the ``essentially'' fully adaptive variant
adaPD$^+$ is proposed that avoids evaluating the linear operator norm by
invoking a backtracking procedure, that, remarkably, does not require extra
gradient evaluations. Numerical simulations demonstrate the effectiveness of
the proposed algorithms compared to the state of the art.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11286" title="Abstract">arXiv:2311.11286</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.11286" title="Download PDF">pdf</a>, <a href="/format/2311.11286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Radio Galaxies with trainable COSFIRE filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Ndungu%2C+S">Steven Ndungu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Grobler%2C+T">Trienko Grobler</a>, 
<a href="/search/astro-ph?searchtype=author&query=Karastoyanova%2C+S+J+W+D">Stefan J. Wijnholds Dimka Karastoyanova</a>, 
<a href="/search/astro-ph?searchtype=author&query=Azzopardi%2C+G">George Azzopardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, submitted for review at MNRAS journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Radio galaxies exhibit a rich diversity of characteristics and emit radio
emissions through a variety of radiation mechanisms, making their
classification into distinct types based on morphology a complex challenge. To
address this challenge effectively, we introduce an innovative approach for
radio galaxy classification using COSFIRE filters. These filters possess the
ability to adapt to both the shape and orientation of prototype patterns within
images. The COSFIRE approach is explainable, learning-free, rotation-tolerant,
efficient, and does not require a huge training set. To assess the efficacy of
our method, we conducted experiments on a benchmark radio galaxy data set
comprising of 1180 training samples and 404 test samples. Notably, our approach
achieved an average accuracy rate of 93.36\%. This achievement outperforms
contemporary deep learning models, and it is the best result ever achieved on
this data set. Additionally, COSFIRE filters offer better computational
performance, $\sim$20$\times$ fewer operations than the DenseNet-based
competing method (when comparing at the same accuracy). Our findings underscore
the effectiveness of the COSFIRE filter-based approach in addressing the
complexities associated with radio galaxy classification. This research
contributes to advancing the field by offering a robust solution that
transcends the orientation challenges intrinsic to radio galaxy observations.
Our method is versatile in that it is applicable to various image
classification approaches.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17923" title="Abstract">arXiv:2311.17923</a> (cross-list from eess.AS) [<a href="/pdf/2311.17923" title="Download PDF">pdf</a>, <a href="/format/2311.17923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Generative Adversarial Networks for Unseen Word Generation from  EEG Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y">Young-Eun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seo-Hyun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Soowon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jung-Sun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+D">Deok-Seon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Recent advances in brain-computer interface (BCI) technology, particularly
based on generative adversarial networks (GAN), have shown great promise for
improving decoding performance for BCI. Within the realm of Brain-Computer
Interfaces (BCI), GANs find application in addressing many areas. They serve as
a valuable tool for data augmentation, which can solve the challenge of limited
data availability, and synthesis, effectively expanding the dataset and
creating novel data formats, thus enhancing the robustness and adaptability of
BCI systems. Research in speech-related paradigms has significantly expanded,
with a critical impact on the advancement of assistive technologies and
communication support for individuals with speech impairments. In this study,
GANs were investigated, particularly for the BCI field, and applied to generate
text from EEG signals. The GANs could generalize all subjects and decode unseen
words, indicating its ability to capture underlying speech patterns consistent
across different individuals. The method has practical applications in neural
signal-based speech recognition systems and communication aids for individuals
with speech difficulties.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17931" title="Abstract">arXiv:2311.17931</a> (cross-list from math.LO) [<a href="/pdf/2311.17931" title="Download PDF">pdf</a>, <a href="/ps/2311.17931" title="Download PostScript">ps</a>, <a href="/format/2311.17931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Theory of Ultrafinitism II: Deconstructing the Term Model (First  Draft)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mannucci%2C+M+A">Mirco A. Mannucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> second installment of the series Model Theory of Ultrafinitism
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This paper presents a novel possible worlds semantics, designed to elucidate
the underpinnings of ultrafinitism. By constructing a careful modification of
the well-known Kripke models for inuitionistic logic, we seek to extend our
comprehension of the ultra-finite mindset. As it turns out, the passage from
standard constructivist mathematics to the ultrafinite is in a sense an
operation of deconstruction of familiar mathematical entities, most notably
clear when it comes to N.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17932" title="Abstract">arXiv:2311.17932</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.17932" title="Download PDF">pdf</a>, <a href="/format/2311.17932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Molecular Conformer Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="/search/physics?searchtype=author&query=Elhag%2C+A+A">Ahmed A. Elhag</a>, 
<a href="/search/physics?searchtype=author&query=Jaitly%2C+N">Navdeep Jaitly</a>, 
<a href="/search/physics?searchtype=author&query=Susskind%2C+J+M">Joshua M. Susskind</a>, 
<a href="/search/physics?searchtype=author&query=Bautista%2C+M+A">Miguel Angel Bautista</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures. arXiv admin note: text overlap with <a href="/abs/2305.15586">arXiv:2305.15586</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we tackle the problem of generating conformers of a molecule in
3D space given its molecular graph. We parameterize these conformers as
continuous functions that map elements from the molecular graph to points in 3D
space. We then formulate the problem of learning to generate conformers as
learning a distribution over these functions using a diffusion generative
model, called Molecular Conformer Fields (MCF). Our approach is simple and
scalable, and achieves state-of-the-art performance on challenging molecular
conformer generation benchmarks while making no assumptions about the explicit
structure of molecules (e.g. modeling torsional angles). MCF represents an
advance in extending diffusion models to handle complex scientific problems in
a conceptually simple, scalable and effective manner.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17961" title="Abstract">arXiv:2311.17961</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.17961" title="Download PDF">pdf</a>, <a href="/format/2311.17961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skilful Precipitation Nowcasting Using NowcastNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+A">Ajitabh Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Designing early warning system for precipitation requires accurate short-term
forecasting system. Climate change has led to an increase in frequency of
extreme weather events, and hence such systems can prevent disasters and loss
of life. Managing such events remain a challenge for both public and private
institutions. Precipitation nowcasting can help relevant institutions to better
prepare for such events as they impact agriculture, transport, public health
and safety, etc. Physics-based numerical weather prediction (NWP) is unable to
perform well for nowcasting because of large computational turn-around time.
Deep-learning based models on the other hand are able to give predictions
within seconds. We use recently proposed NowcastNet, a physics-conditioned deep
generative network, to forecast precipitation for different regions of Europe
using satellite images. Both spatial and temporal transfer learning is done by
forecasting for the unseen regions and year. Model makes realistic predictions
and is able to outperform baseline for such a prediction task.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17964" title="Abstract">arXiv:2311.17964</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.17964" title="Download PDF">pdf</a>, <a href="/ps/2311.17964" title="Download PostScript">ps</a>, <a href="/format/2311.17964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear normalised hash function for clustering gene sequences and  identifying reference sequences from multiple sequence alignments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Helal%2C+M">Manal Helal</a>, 
<a href="/search/q-bio?searchtype=author&query=Kong%2C+F">Fanrong Kong</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+S+C">Sharon C-A Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+F">Fei Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Dwyer%2C+D+E">Dominic E Dwyer</a>, 
<a href="/search/q-bio?searchtype=author&query=Potter%2C+J">John Potter</a>, 
<a href="/search/q-bio?searchtype=author&query=Sintchenko%2C+V">Vitali Sintchenko</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Microbial Informatics and Experimentation volume 2, Article
  number: 2 (2012)
  https://microbialinformaticsj.biomedcentral.com/counter/pdf/10.1186/2042-5783-2-2.pdf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The aim of this study was to develop a method that would identify the cluster
centroids and the optimal number of clusters for a given sensitivity level and
could work equally well for the different sequence datasets. A novel method
that combines the linear mapping hash function and multiple sequence alignment
(MSA) was developed. This method takes advantage of the already sorted by
similarity sequences from the MSA output, and identifies the optimal number of
clusters, clusters cut-offs, and clusters centroids that can represent
reference gene vouchers for the different species. The linear mapping hash
function can map an already ordered by similarity distance matrix to indices to
reveal gaps in the values around which the optimal cut-offs of the different
clusters can be identified. The method was evaluated using sets of closely
related (16S rRNA gene sequences of Nocardia species) and highly variable (VP1
genomic region of Enterovirus 71) sequences and outperformed existing
unsupervised machine learning clustering methods and dimensionality reduction
methods. This method does not require prior knowledge of the number of clusters
or the distance between clusters, handles clusters of different sizes and
shapes, and scales linearly with the dataset. The combination of MSA with the
linear mapping hash function is a computationally efficient way of gene
sequence clustering and can be a valuable tool for the assessment of
similarity, clustering of different microbial genomes, identifying reference
sequences, and for the study of evolution of bacteria and viruses.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17965" title="Abstract">arXiv:2311.17965</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.17965" title="Download PDF">pdf</a>, <a href="/ps/2311.17965" title="Download PostScript">ps</a>, <a href="/format/2311.17965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining Reference Sequences for Nocardia Species by Similarity and  Clustering Analyses of 16S rRNA Gene Sequence Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Helal%2C+M">Manal Helal</a>, 
<a href="/search/q-bio?searchtype=author&query=Kong%2C+F">Fanrong Kong</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+S+C+A">Sharon C. A. Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Bain%2C+M">Michael Bain</a>, 
<a href="/search/q-bio?searchtype=author&query=Christen%2C+R">Richard Christen</a>, 
<a href="/search/q-bio?searchtype=author&query=Sintchenko%2C+V">Vitali Sintchenko</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PLoS ONE June 2011 | Volume 6 | Issue 6 | e19517
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The intra- and inter-species genetic diversity of bacteria and the absence of
'reference', or the most representative, sequences of individual species
present a significant challenge for sequence-based identification. The aims of
this study were to determine the utility, and compare the performance of
several clustering and classification algorithms to identify the species of 364
sequences of 16S rRNA gene with a defined species in GenBank, and 110 sequences
of 16S rRNA gene with no defined species, all within the genus Nocardia. A
total of 364 16S rRNA gene sequences of Nocardia species were studied. In
addition, 110 16S rRNA gene sequences assigned only to the Nocardia genus level
at the time of submission to GenBank were used for machine learning
classification experiments. Different clustering algorithms were compared with
a novel algorithm or the linear mapping (LM) of the distance matrix. Principal
Components Analysis was used for the dimensionality reduction and
visualization. Results: The LM algorithm achieved the highest performance and
classified the set of 364 16S rRNA sequences into 80 clusters, the majority of
which (83.52%) corresponded with the original species. The most representative
16S rRNA sequences for individual Nocardia species have been identified as
'centroids' in respective clusters from which the distances to all other
sequences were minimized; 110 16S rRNA gene sequences with identifications
recorded only at the genus level were classified using machine learning
methods. Simple kNN machine learning demonstrated the highest performance and
classified Nocardia species sequences with an accuracy of 92.7% and a mean
frequency of 0.578.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17968" title="Abstract">arXiv:2311.17968</a> (cross-list from eess.SP) [<a href="/pdf/2311.17968" title="Download PDF">pdf</a>, <a href="/format/2311.17968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Alignment with Deep Set EEG Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bakas%2C+S">Stylianos Bakas</a>, 
<a href="/search/eess?searchtype=author&query=Ludwig%2C+S">Siegfried Ludwig</a>, 
<a href="/search/eess?searchtype=author&query=Adamos%2C+D+A">Dimitrios A. Adamos</a>, 
<a href="/search/eess?searchtype=author&query=Laskaris%2C+N">Nikolaos Laskaris</a>, 
<a href="/search/eess?searchtype=author&query=Panagakis%2C+Y">Yannis Panagakis</a>, 
<a href="/search/eess?searchtype=author&query=Zafeiriou%2C+S">Stefanos Zafeiriou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The variability in EEG signals between different individuals poses a
significant challenge when implementing brain-computer interfaces (BCI).
Commonly proposed solutions to this problem include deep learning models, due
to their increased capacity and generalization, as well as explicit domain
adaptation techniques. Here, we introduce the Latent Alignment method that won
the Benchmarks for EEG Transfer Learning (BEETL) competition and present its
formulation as a deep set applied on the set of trials from a given subject.
Its performance is compared to recent statistical domain adaptation techniques
under various conditions. The experimental paradigms include motor imagery
(MI), oddball event-related potentials (ERP) and sleep stage classification,
where different well-established deep learning models are applied on each task.
Our experimental results show that performing statistical distribution
alignment at later stages in a deep learning model is beneficial to the
classification accuracy, yielding the highest performance for our proposed
method. We further investigate practical considerations that arise in the
context of using deep learning and statistical alignment for EEG decoding. In
this regard, we study class-discriminative artifacts that can spuriously
improve results for deep learning models, as well as the impact of
class-imbalance on alignment. We delineate a trade-off relationship between
increased classification accuracy when alignment is performed at later modeling
stages, and susceptibility to class-imbalance in the set of trials that the
statistics are computed on.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17969" title="Abstract">arXiv:2311.17969</a> (cross-list from q-bio.MN) [<a href="/pdf/2311.17969" title="Download PDF">pdf</a>, <a href="/format/2311.17969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of a Compendium of Transcription Factor Cascades and  Identification of Potential Therapeutic Targets using Graph Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sivarajkumar%2C+S">Sonish Sivarajkumar</a>, 
<a href="/search/q-bio?searchtype=author&query=Tandale%2C+P">Pratyush Tandale</a>, 
<a href="/search/q-bio?searchtype=author&query=Bhardwaj%2C+A">Ankit Bhardwaj</a>, 
<a href="/search/q-bio?searchtype=author&query=Johnson%2C+K+W">Kipp W. Johnson</a>, 
<a href="/search/q-bio?searchtype=author&query=Titus%2C+A">Anoop Titus</a>, 
<a href="/search/q-bio?searchtype=author&query=Glicksberg%2C+B+S">Benjamin S. Glicksberg</a>, 
<a href="/search/q-bio?searchtype=author&query=Khader%2C+S">Shameer Khader</a>, 
<a href="/search/q-bio?searchtype=author&query=Yadav%2C+K+K">Kamlesh K. Yadav</a>, 
<a href="/search/q-bio?searchtype=author&query=Subramanian%2C+L">Lakshminarayanan Subramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transcription factors (TFs) play a vital role in the regulation of gene
expression thereby making them critical to many cellular processes. In this
study, we used graph machine learning methods to create a compendium of TF
cascades using data extracted from the STRING database. A TF cascade is a
sequence of TFs that regulate each other, forming a directed path in the TF
network. We constructed a knowledge graph of 81,488 unique TF cascades, with
the longest cascade consisting of 62 TFs. Our results highlight the complex and
intricate nature of TF interactions, where multiple TFs work together to
regulate gene expression. We also identified 10 TFs with the highest regulatory
influence based on centrality measurements, providing valuable information for
researchers interested in studying specific TFs. Furthermore, our pathway
enrichment analysis revealed significant enrichment of various pathways and
functional categories, including those involved in cancer and other diseases,
as well as those involved in development, differentiation, and cell signaling.
The enriched pathways identified in this study may have potential as targets
for therapeutic intervention in diseases associated with dysregulation of
transcription factors. We have released the dataset, knowledge graph, and
graphML methods for the TF cascades, and created a website to display the
results, which can be accessed by researchers interested in using this dataset.
Our study provides a valuable resource for understanding the complex network of
interactions between TFs and their regulatory roles in cellular processes.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17970" title="Abstract">arXiv:2311.17970</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.17970" title="Download PDF">pdf</a>, <a href="/format/2311.17970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Description Generation using Variational Auto-Encoders for precursor  microRNA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Petkovi%C4%87%2C+M">Marko Petkovi&#x107;</a>, 
<a href="/search/q-bio?searchtype=author&query=Menkovski%2C+V">Vlado Menkovski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Micro RNAs (miRNA) are a type of non-coding RNA, which are involved in gene
regulation and can be associated with diseases such as cancer, cardiovascular
and neurological diseases. As such, identifying the entire genome of miRNA can
be of great relevance. Since experimental methods for novel precursor miRNA
(pre-miRNA) detection are complex and expensive, computational detection using
ML could be useful. Existing ML methods are often complex black boxes, which do
not create an interpretable structural description of pre-miRNA. In this paper,
we propose a novel framework, which makes use of generative modeling through
Variational Auto-Encoders to uncover the generative factors of pre-miRNA. After
training the VAE, the pre-miRNA description is developed using a decision tree
on the lower dimensional latent space. Applying the framework to miRNA
classification, we obtain a high reconstruction and classification performance,
while also developing an accurate miRNA description.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18002" title="Abstract">arXiv:2311.18002</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.18002" title="Download PDF">pdf</a>, <a href="/format/2311.18002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Echoes in the Noise: Posterior Samples of Faint Galaxy Surface  Brightness Profiles with Score-Based Likelihoods and Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Adam%2C+A">Alexandre Adam</a>, 
<a href="/search/astro-ph?searchtype=author&query=Stone%2C+C">Connor Stone</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bottrell%2C+C">Connor Bottrell</a>, 
<a href="/search/astro-ph?searchtype=author&query=Legin%2C+R">Ronan Legin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hezaveh%2C+Y">Yashar Hezaveh</a>, 
<a href="/search/astro-ph?searchtype=author&query=Perreault-Levasseur%2C+L">Laurence Perreault-Levasseur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+5 pages, 10 figures, Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Examining the detailed structure of galaxy populations provides valuable
insights into their formation and evolution mechanisms. Significant barriers to
such analysis are the non-trivial noise properties of real astronomical images
and the point spread function (PSF) which blurs structure. Here we present a
framework which combines recent advances in score-based likelihood
characterization and diffusion model priors to perform a Bayesian analysis of
image deconvolution. The method, when applied to minimally processed
\emph{Hubble Space Telescope} (\emph{HST}) data, recovers structures which have
otherwise only become visible in next-generation \emph{James Webb Space
Telescope} (\emph{JWST}) imaging.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18007" title="Abstract">arXiv:2311.18007</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.18007" title="Download PDF">pdf</a>, <a href="/format/2311.18007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards out-of-distribution generalization in large-scale astronomical  surveys: robust networks learn similar representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gondhalekar%2C+Y">Yash Gondhalekar</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hassan%2C+S">Sultan Hassan</a>, 
<a href="/search/astro-ph?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>, 
<a href="/search/astro-ph?searchtype=author&query=Andrianomena%2C+S">Sambatra Andrianomena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Astrophysics of Galaxies (astro-ph.GA); Machine Learning (cs.LG)

</div>
<p class="mathjax">The generalization of machine learning (ML) models to out-of-distribution
(OOD) examples remains a key challenge in extracting information from upcoming
astronomical surveys. Interpretability approaches are a natural way to gain
insights into the OOD generalization problem. We use Centered Kernel Alignment
(CKA), a similarity measure metric of neural network representations, to
examine the relationship between representation similarity and performance of
pre-trained Convolutional Neural Networks (CNNs) on the CAMELS Multifield
Dataset. We find that when models are robust to a distribution shift, they
produce substantially different representations across their layers on OOD
data. However, when they fail to generalize, these representations change less
from layer to layer on OOD data. We discuss the potential application of
similarity representation in guiding model design, training strategy, and
mitigating the OOD problem by incorporating CKA as an inductive bias during
training.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18012" title="Abstract">arXiv:2311.18012</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.18012" title="Download PDF">pdf</a>, <a href="/format/2311.18012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Imaging for Radio Interferometry with Score-Based Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Dia%2C+N">Noe Dia</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yantovski-Barth%2C+M+J">M. J. Yantovski-Barth</a>, 
<a href="/search/astro-ph?searchtype=author&query=Adam%2C+A">Alexandre Adam</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bowles%2C+M">Micah Bowles</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="/search/astro-ph?searchtype=author&query=Scaife%2C+A+M+M">Anna M. M. Scaife</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hezaveh%2C+Y">Yashar Hezaveh</a>, 
<a href="/search/astro-ph?searchtype=author&query=Perreault-Levasseur%2C+L">Laurence Perreault-Levasseur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10+4 pages, 6 figures, Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The inverse imaging task in radio interferometry is a key limiting factor to
retrieving Bayesian uncertainties in radio astronomy in a computationally
effective manner. We use a score-based prior derived from optical images of
galaxies to recover images of protoplanetary disks from the DSHARP survey. We
demonstrate that our method produces plausible posterior samples despite the
misspecified galaxy prior. We show that our approach produces results which are
competitive with existing radio interferometry imaging algorithms.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18027" title="Abstract">arXiv:2311.18027</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.18027" title="Download PDF">pdf</a>, <a href="/format/2311.18027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Data-Assimilation in CFD using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Quattromini%2C+M">Michele Quattromini</a>, 
<a href="/search/physics?searchtype=author&query=Bucci%2C+M+A">Michele Alessandro Bucci</a>, 
<a href="/search/physics?searchtype=author&query=Cherubini%2C+S">Stefania Cherubini</a>, 
<a href="/search/physics?searchtype=author&query=Semeraro%2C+O">Onofrio Semeraro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at: Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel machine learning approach for data assimilation applied in
fluid mechanics, based on adjoint-optimization augmented by Graph Neural
Networks (GNNs) models. We consider as baseline the Reynolds-Averaged
Navier-Stokes (RANS) equations, where the unknown is the meanflow and a closure
model based on the Reynolds-stress tensor is required for correctly computing
the solution. An end-to-end process is cast; first, we train a GNN model for
the closure term. Second, the GNN model is introduced in the training process
of data assimilation, where the RANS equations act as a physics constraint for
a consistent prediction. We obtain our results using direct numerical
simulations based on a Finite Element Method (FEM) solver; a two-fold interface
between the GNN model and the solver allows the GNN's predictions to be
incorporated into post-processing steps of the FEM analysis. The proposed
scheme provides an excellent reconstruction of the meanflow without any
features selection; preliminary results show promising generalization
properties over unseen flow configurations.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18084" title="Abstract">arXiv:2311.18084</a> (cross-list from math.AP) [<a href="/pdf/2311.18084" title="Download PDF">pdf</a>, <a href="/ps/2311.18084" title="Download PostScript">ps</a>, <a href="/format/2311.18084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the exponential stability of uniformly damped wave equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Egger%2C+H">Herbert Egger</a>, 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Stefan Kurz</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B6scher%2C+R">Richard L&#xf6;scher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We study damped wave propagation problems phrased as abstract evolution
equations in Hilbert spaces. Under some general assumptions, including a
natural compatibility condition for initial values, we establish exponential
decay estimates for all mild solutions using the language and tools of Hilbert
complexes. This framework turns out strong enough to conduct our analysis but
also general enough to include a number of interesting examples. Some of these
are briefly discussed. By a slight modification of the main arguments, we also
obtain corresponding decay results for numerical approximations obtained by
compatible discretization strategies.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18092" title="Abstract">arXiv:2311.18092</a> (cross-list from math.PR) [<a href="/pdf/2311.18092" title="Download PDF">pdf</a>, <a href="/ps/2311.18092" title="Download PostScript">ps</a>, <a href="/format/2311.18092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully lifted interpolating comparisons of bilinearly indexed random  processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Information Theory (cs.IT); Mathematical Physics (math-ph); Statistics Theory (math.ST)

</div>
<p class="mathjax">A powerful statistical interpolating concept, which we call \emph{fully
lifted} (fl), is introduced and presented while establishing a connection
between bilinearly indexed random processes and their corresponding fully
decoupled (linearly indexed) comparative alternatives. Despite on occasion very
involved technical considerations, the final interpolating forms and their
underlying relations admit rather elegant expressions that provide conceivably
highly desirable and useful tool for further studying various different aspects
of random processes and their applications. We also discuss the generality of
the considered models and show that they encompass many well known random
structures and optimization problems to which then the obtained results
automatically apply.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18094" title="Abstract">arXiv:2311.18094</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.18094" title="Download PDF">pdf</a>, <a href="/format/2311.18094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Driving Telescopes: Autonomous Scheduling of Astronomical  Observation Campaigns with Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Terranova%2C+F">Franco Terranova</a>, 
<a href="/search/astro-ph?searchtype=author&query=Voetberg%2C+M">M. Voetberg</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nord%2C+B">Brian Nord</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pagul%2C+A">Amanda Pagul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Machine Learning and the Physical Sciences Workshop at NeurIPS 2023; 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern astronomical experiments are designed to achieve multiple scientific
goals, from studies of galaxy evolution to cosmic acceleration. These goals
require data of many different classes of night-sky objects, each of which has
a particular set of observational needs. These observational needs are
typically in strong competition with one another. This poses a challenging
multi-objective optimization problem that remains unsolved. The effectiveness
of Reinforcement Learning (RL) as a valuable paradigm for training autonomous
systems has been well-demonstrated, and it may provide the basis for
self-driving telescopes capable of optimizing the scheduling for astronomy
campaigns. Simulated datasets containing examples of interactions between a
telescope and a discrete set of sky locations on the celestial sphere can be
used to train an RL model to sequentially gather data from these several
locations to maximize a cumulative reward as a measure of the quality of the
data gathered. We use simulated data to test and compare multiple
implementations of a Deep Q-Network (DQN) for the task of optimizing the
schedule of observations from the Stone Edge Observatory (SEO). We combine
multiple improvements on the DQN and adjustments to the dataset, showing that
DQNs can achieve an average reward of 87%+-6% of the maximum achievable reward
in each state on the test set. This is the first comparison of offline RL
algorithms for a particular astronomical challenge and the first open-source
framework for performing such a comparison and assessment task.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18097" title="Abstract">arXiv:2311.18097</a> (cross-list from math.PR) [<a href="/pdf/2311.18097" title="Download PDF">pdf</a>, <a href="/ps/2311.18097" title="Download PostScript">ps</a>, <a href="/format/2311.18097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilinearly indexed random processes -- \emph{stationarization} of fully  lifted interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Information Theory (cs.IT); Mathematical Physics (math-ph); Statistics Theory (math.ST)

</div>
<p class="mathjax">Our companion paper \cite{Stojnicnflgscompyx23} introduced a very powerful
\emph{fully lifted} (fl) statistical interpolating/comparison mechanism for
bilinearly indexed random processes. Here, we present a particular realization
of such fl mechanism that relies on a stationarization along the interpolating
path concept. A collection of very fundamental relations among the
interpolating parameters is uncovered, contextualized, and presented. As a nice
bonus, in particular special cases, we show that the introduced machinery
allows various simplifications to forms readily usable in practice. Given how
many well known random structures and optimization problems critically rely on
the results of the type considered here, the range of applications is pretty
much unlimited. We briefly point to some of these opportunities as well.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18103" title="Abstract">arXiv:2311.18103</a> (cross-list from eess.IV) [<a href="/pdf/2311.18103" title="Download PDF">pdf</a>, <a href="/format/2311.18103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corner-to-Center Long-range Context Model for Efficient Learned Image  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sui%2C+Y">Yang Sui</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+D">Ding Ding</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+X">Xiang Pan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xiaozhong Xu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+B">Bo Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhenzhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the framework of learned image compression, the context model plays a
pivotal role in capturing the dependencies among latent representations. To
reduce the decoding time resulting from the serial autoregressive context
model, the parallel context model has been proposed as an alternative that
necessitates only two passes during the decoding phase, thus facilitating
efficient image compression in real-world scenarios. However, performance
degradation occurs due to its incomplete casual context. To tackle this issue,
we conduct an in-depth analysis of the performance degradation observed in
existing parallel context models, focusing on two aspects: the Quantity and
Quality of information utilized for context prediction and decoding. Based on
such analysis, we propose the \textbf{Corner-to-Center transformer-based
Context Model (C$^3$M)} designed to enhance context and latent predictions and
improve rate-distortion performance. Specifically, we leverage the
logarithmic-based prediction order to predict more context features from corner
to center progressively. In addition, to enlarge the receptive field in the
analysis and synthesis transformation, we use the Long-range Crossing Attention
Module (LCAM) in the encoder/decoder to capture the long-range semantic
information by assigning the different window shapes in different channels.
Extensive experimental evaluations show that the proposed method is effective
and outperforms the state-of-the-art parallel methods. Finally, according to
the subjective analysis, we suggest that improving the detailed representation
in transformer-based image compression is a promising direction to be explored.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18106" title="Abstract">arXiv:2311.18106</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2311.18106" title="Download PDF">pdf</a>, <a href="/ps/2311.18106" title="Download PostScript">ps</a>, <a href="/format/2311.18106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic proving of replica symmetry breaking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph); Probability (math.PR)

</div>
<p class="mathjax">We study the replica symmetry breaking (rsb) concepts on a generic level
through the prism of recently introduced interpolating/comparison mechanisms
for bilinearly indexed (bli) random processes. In particular,
\cite{Stojnicnflgscompyx23} introduced a \emph{fully lifted} (fl) interpolating
mechanism and \cite{Stojnicsflgscompyx23} developed its a \emph{stationarized
fully lifted} (sfl) variant. Here, we present a sfl \emph{matching} mechanism
that shows that the results obtained in
\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23} completely correspond to the
ones obtained by a statistical physics replica tool with the replica symmetry
breaking (rsb) form suggested by Parisi in \cite{Par79,Parisi80,Par80}. The
results are very generic as they allow to handle pretty much all bilinear
models at once. Moreover, given that the results of
\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23} are extendable to many other
forms, the concepts presented here automatically extend to any such forms as
well.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18144" title="Abstract">arXiv:2311.18144</a> (cross-list from quant-ph) [<a href="/pdf/2311.18144" title="Download PDF">pdf</a>, <a href="/format/2311.18144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamical phase transition in quantum neural networks with large depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+B">Bingzhi Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+X">Xiao-Chuan Wu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+L">Liang Jiang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhuang%2C+Q">Quntao Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11+35 pages, comments are welcomed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding the training dynamics of quantum neural networks is a
fundamental task in quantum information science with wide impact in physics,
chemistry and machine learning. In this work, we show that the late-time
training dynamics of quantum neural networks can be described by the
generalized Lotka-Volterra equations, which lead to a dynamical phase
transition. When the targeted value of cost function crosses the minimum
achievable value from above to below, the dynamics evolve from a frozen-kernel
phase to a frozen-error phase, showing a duality between the quantum neural
tangent kernel and the total error. In both phases, the convergence towards the
fixed point is exponential, while at the critical point becomes polynomial. Via
mapping the Hessian of the training dynamics to a Hamiltonian in the imaginary
time, we reveal the nature of the phase transition to be second-order with the
exponent $\nu=1$, where scale invariance and closing gap are observed at
critical point. We also provide a non-perturbative analytical theory to explain
the phase transition via a restricted Haar ensemble at late time, when the
output state approaches the steady state. The theory findings are verified
experimentally on IBM quantum devices.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18164" title="Abstract">arXiv:2311.18164</a> (cross-list from q-fin.GN) [<a href="/pdf/2311.18164" title="Download PDF">pdf</a>, <a href="/format/2311.18164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Paradox Of Just-in-Time Liquidity in Decentralized Exchanges: More  Providers Can Sometimes Mean Less Liquidity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Capponi%2C+A">Agostino Capponi</a>, 
<a href="/search/q-fin?searchtype=author&query=Jia%2C+R">Ruizhe Jia</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhu%2C+B">Brian Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">We study just-in-time (JIT) liquidity provision within blockchain-based
decentralized exchanges (DEXs). In contrast to passive liquidity providers
(LPs) who deposit assets into liquidity pools before observing order flows, JIT
LPs take a more active approach. They monitor pending orders from public
blockchain mempools and swiftly supply liquidity, only to withdraw it in the
same block. Our game-theoretical analysis uncovers a paradoxical scenario: the
presence of a JIT LP, rather than enhancing liquidity as expected, can
inadvertently reduce it. A central reason behind the paradox is the adverse
selection problem encountered by passive LPs, stemming from the presence of
informed arbitrageurs. Unlike passive LPs, JIT LPs have the advantage of
analyzing the order flow prior to providing liquidity and block confirmation.
We show that this second-mover advantage mitigates their adverse selection
costs and potentially crowds out passive LPs, particularly when order flows are
not highly elastic to changes in pool liquidity. These equilibrium effects may
lead to an overall reduction of pool liquidity and to an increased execution
risk for liquidity demanders. To alleviate the detrimental effects of JIT
liquidity, we propose a two-tiered fee structure for passive and JIT LPs. We
show that this structure may prevent crowding out and improve welfare.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18171" title="Abstract">arXiv:2311.18171</a> (cross-list from quant-ph) [<a href="/pdf/2311.18171" title="Download PDF">pdf</a>, <a href="/format/2311.18171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconditionally secure quantum commitments with preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Qian%2C+L">Luowen Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We demonstrate how to build computationally secure commitment schemes with
the aid of quantum auxiliary inputs without unproven complexity assumptions.
Furthermore, the quantum auxiliary input can be prepared either (1) efficiently
through a trusted setup similar to the classical common random string model, or
(2) strictly between the two involved parties in uniform exponential time.
Classically this remains impossible without first proving $\mathsf{P} \neq
\mathsf{NP}$.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18173" title="Abstract">arXiv:2311.18173</a> (cross-list from eess.IV) [<a href="/pdf/2311.18173" title="Download PDF">pdf</a>, <a href="/ps/2311.18173" title="Download PostScript">ps</a>, <a href="/format/2311.18173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantification of cardiac capillarization in single-immunostained  myocardial slices using weakly supervised instance segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiwen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Richardson%2C+W">William Richardson</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+B+Z">Bruce Z. Gao</a>, 
<a href="/search/eess?searchtype=author&query=Razi%2C+A">Abolfazl Razi</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+T">Tong Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Decreased myocardial capillary density has been reported as an important
histopathological feature associated with various heart disorders. Quantitative
assessment of cardiac capillarization typically involves double immunostaining
of cardiomyocytes (CMs) and capillaries in myocardial slices. In contrast,
single immunostaining of basement membrane components is a straightforward
approach to simultaneously label CMs and capillaries, presenting fewer
challenges in background staining. However, subsequent image analysis always
requires manual work in identifying and segmenting CMs and capillaries. Here,
we developed an image analysis tool, AutoQC, to automatically identify and
segment CMs and capillaries in immunofluorescence images of collagen type IV, a
predominant basement membrane protein within the myocardium. In addition,
commonly used capillarization-related measurements can be derived from
segmentation masks. AutoQC features a weakly supervised instance segmentation
algorithm by leveraging the power of a pre-trained segmentation model via
prompt engineering. AutoQC outperformed YOLOv8-Seg, a state-of-the-art instance
segmentation model, in both instance segmentation and capillarization
assessment. Furthermore, the training of AutoQC required only a small dataset
with bounding box annotations instead of pixel-wise annotations, leading to a
reduced workload during network training. AutoQC provides an automated solution
for quantifying cardiac capillarization in basement-membrane-immunostained
myocardial slices, eliminating the need for manual image analysis once it is
trained.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18188" title="Abstract">arXiv:2311.18188</a> (cross-list from eess.AS) [<a href="/pdf/2311.18188" title="Download PDF">pdf</a>, <a href="/format/2311.18188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging cache to enable SLU on tiny devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Benazir%2C+A">Afsara Benazir</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhiming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a> (University of Virginia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Mobisys 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper addresses spoken language understanding (SLU) on
microcontroller-like embedded devices, integrating on-device execution with
cloud offloading in a novel fashion. We exploit temporal locality in a device's
speech inputs and accordingly reuse recent SLU inferences. Our idea is simple:
let the device match new inputs against cached results, and only offload
unmatched inputs to the cloud for full inference. Realization of this idea,
however, is non-trivial: the device needs to compare acoustic features in a
robust, low-cost way. To this end, we present XYZ, a speech cache for tiny
devices. It matches speech inputs at two levels of representations: first by
clustered sequences of raw sound units, then as sequences of phonemes. Working
in tandem, the two representations offer complementary cost/accuracy tradeoffs.
To further boost accuracy, our cache is learning: with the mismatched and then
offloaded inputs, it continuously finetunes the device's feature extractors
(with the assistance of the cloud). We implement XYZ on an off-the-shelf STM32
microcontroller. The resultant implementation has a small memory footprint of
2MB. Evaluated on challenging speech benchmarks, our system resolves 45%--90%
of inputs on device, reducing the average latency by up to 80% compared to
offloading to popular cloud speech services. Our benefit is pronounced even in
adversarial settings -- noisy environments, cold cache, or one device shared by
a number of users.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18210" title="Abstract">arXiv:2311.18210</a> (cross-list from math.OC) [<a href="/pdf/2311.18210" title="Download PDF">pdf</a>, <a href="/format/2311.18210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Adaptive Greedy Quasi-Newton Methods with Explicit  Non-asymptotic Convergence Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Du%2C+Y">Yubo Du</a>, 
<a href="/search/math?searchtype=author&query=You%2C+K">Keyou You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Though quasi-Newton methods have been extensively studied in the literature,
they either suffer from local convergence or use a series of line searches for
global convergence which is not acceptable in the distributed setting. In this
work, we first propose a line search free greedy quasi-Newton (GQN) method with
adaptive steps and establish explicit non-asymptotic bounds for both the global
convergence rate and local superlinear rate. Our novel idea lies in the design
of multiple greedy quasi-Newton updates, which involves computing
Hessian-vector products, to control the Hessian approximation error, and a
simple mechanism to adjust stepsizes to ensure the objective function
improvement per iterate. Then, we extend it to the master-worker framework and
propose a distributed adaptive GQN method whose communication cost is
comparable with that of first-order methods, yet it retains the superb
convergence property of its centralized counterpart. Finally, we demonstrate
the advantages of our methods via numerical experiments.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18214" title="Abstract">arXiv:2311.18214</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.18214" title="Download PDF">pdf</a>, <a href="/format/2311.18214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perception of Misalignment States for Sky Survey Telescopes with the  Digital Twin and the Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jia%2C+P">Peng Jia</a>, 
<a href="/search/astro-ph?searchtype=author&query=Li%2C+Z">Zhengyang Li</a>, 
<a href="/search/astro-ph?searchtype=author&query=Xiang%2C+W">Wennan Xiang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lv%2C+J">Jiameng Lv</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sun%2C+R">Rui Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The aforementioned submission has been accepted by Optics Express. We kindly request any feedback or comments to be directed to the corresponding author, Peng Jia (robinmartin20@gmail.com), or the second corresponding author, Zhengyang Li (lizy@niaot.ac.cn). Please note that Zhengyang is currently stationed in the South Antarctica and will not be available until after February 1st, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR); Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)

</div>
<p class="mathjax">Sky survey telescopes play a critical role in modern astronomy, but
misalignment of their optical elements can introduce significant variations in
point spread functions, leading to reduced data quality. To address this, we
need a method to obtain misalignment states, aiding in the reconstruction of
accurate point spread functions for data processing methods or facilitating
adjustments of optical components for improved image quality. Since sky survey
telescopes consist of many optical elements, they result in a vast array of
potential misalignment states, some of which are intricately coupled, posing
detection challenges. However, by continuously adjusting the misalignment
states of optical elements, we can disentangle coupled states. Based on this
principle, we propose a deep neural network to extract misalignment states from
continuously varying point spread functions in different field of views. To
ensure sufficient and diverse training data, we recommend employing a digital
twin to obtain data for neural network training. Additionally, we introduce the
state graph to store misalignment data and explore complex relationships
between misalignment states and corresponding point spread functions, guiding
the generation of training data from experiments. Once trained, the neural
network estimates misalignment states from observation data, regardless of the
impacts caused by atmospheric turbulence, noise, and limited spatial sampling
rates in the detector. The method proposed in this paper could be used to
provide prior information for the active optics system and the optical system
alignment.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18245" title="Abstract">arXiv:2311.18245</a> (cross-list from eess.IV) [<a href="/pdf/2311.18245" title="Download PDF">pdf</a>, <a href="/format/2311.18245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Detection of Alzheimer&#x27;s Disease with Multi-Modal Fusion of  Clinical MRI Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Liben Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+B">Binfeng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wenxin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Razavian%2C+N">Narges Razavian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The aging population of the U.S. drives the prevalence of Alzheimer's
disease. Brookmeyer et al. forecasts approximately 15 million Americans will
have either clinical AD or mild cognitive impairment by 2060. In response to
this urgent call, methods for early detection of Alzheimer's disease have been
developed for prevention and pre-treatment. Notably, literature on the
application of deep learning in the automatic detection of the disease has been
proliferating. This study builds upon previous literature and maintains a focus
on leveraging multi-modal information to enhance automatic detection. We aim to
predict the stage of the disease - Cognitively Normal (CN), Mildly Cognitive
Impairment (MCI), and Alzheimer's Disease (AD), based on two different types of
brain MRI scans. We design an AlexNet-based deep learning model that learns the
synergy of complementary information from both T1 and FLAIR MRI scans.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18260" title="Abstract">arXiv:2311.18260</a> (cross-list from eess.IV) [<a href="/pdf/2311.18260" title="Download PDF">pdf</a>, <a href="/format/2311.18260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus, dissensus and synergy between clinicians and specialist  foundation models in radiology report generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tanno%2C+R">Ryutaro Tanno</a>, 
<a href="/search/eess?searchtype=author&query=Barrett%2C+D+G+T">David G.T. Barrett</a>, 
<a href="/search/eess?searchtype=author&query=Sellergren%2C+A">Andrew Sellergren</a>, 
<a href="/search/eess?searchtype=author&query=Ghaisas%2C+S">Sumedh Ghaisas</a>, 
<a href="/search/eess?searchtype=author&query=Dathathri%2C+S">Sumanth Dathathri</a>, 
<a href="/search/eess?searchtype=author&query=See%2C+A">Abigail See</a>, 
<a href="/search/eess?searchtype=author&query=Welbl%2C+J">Johannes Welbl</a>, 
<a href="/search/eess?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Azizi%2C+S">Shekoofeh Azizi</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+T">Tao Tu</a>, 
<a href="/search/eess?searchtype=author&query=Schaekermann%2C+M">Mike Schaekermann</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+R">Rhys May</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+R">Roy Lee</a>, 
<a href="/search/eess?searchtype=author&query=Man%2C+S">SiWai Man</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+Z">Zahra Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Mahdavi%2C+S">Sara Mahdavi</a>, 
<a href="/search/eess?searchtype=author&query=Belgrave%2C+D">Danielle Belgrave</a>, 
<a href="/search/eess?searchtype=author&query=Natarajan%2C+V">Vivek Natarajan</a>, 
<a href="/search/eess?searchtype=author&query=Shetty%2C+S">Shravya Shetty</a>, 
<a href="/search/eess?searchtype=author&query=Kohli%2C+P">Pushmeet Kohli</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+P">Po-Sen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="/search/eess?searchtype=author&query=Ktena%2C+I">Ira Ktena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Radiology reports are an instrumental part of modern medicine, informing key
clinical decisions such as diagnosis and treatment. The worldwide shortage of
radiologists, however, restricts access to expert care and imposes heavy
workloads, contributing to avoidable errors and delays in report delivery.
While recent progress in automated report generation with vision-language
models offer clear potential in ameliorating the situation, the path to
real-world adoption has been stymied by the challenge of evaluating the
clinical quality of AI-generated reports. In this study, we build a
state-of-the-art report generation system for chest radiographs, Flamingo-CXR,
by fine-tuning a well-known vision-language foundation model on radiology data.
To evaluate the quality of the AI-generated reports, a group of 16 certified
radiologists provide detailed evaluations of AI-generated and human written
reports for chest X-rays from an intensive care setting in the United States
and an inpatient setting in India. At least one radiologist (out of two per
case) preferred the AI report to the ground truth report in over 60$\%$ of
cases for both datasets. Amongst the subset of AI-generated reports that
contain errors, the most frequently cited reasons were related to the location
and finding, whereas for human written reports, most mistakes were related to
severity and finding. This disparity suggested potential complementarity
between our AI system and human experts, prompting us to develop an assistive
scenario in which Flamingo-CXR generates a first-draft report, which is
subsequently revised by a clinician. This is the first demonstration of
clinician-AI collaboration for report writing, and the resultant reports are
assessed to be equivalent or preferred by at least one radiologist to reports
written by experts alone in 80$\%$ of in-patient cases and 66$\%$ of intensive
care cases.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18274" title="Abstract">arXiv:2311.18274</a> (cross-list from stat.ML) [<a href="/pdf/2311.18274" title="Download PDF">pdf</a>, <a href="/format/2311.18274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semiparametric Efficient Inference in Adaptive Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cook%2C+T">Thomas Cook</a>, 
<a href="/search/stat?searchtype=author&query=Mishler%2C+A">Alan Mishler</a>, 
<a href="/search/stat?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We consider the problem of efficient inference of the Average Treatment
Effect in a sequential experiment where the policy governing the assignment of
subjects to treatment or control can change over time. We first provide a
central limit theorem for the Adaptive Augmented Inverse-Probability Weighted
estimator, which is semiparametric efficient, under weaker assumptions than
those previously made in the literature. This central limit theorem enables
efficient inference at fixed sample sizes. We then consider a sequential
inference setting, deriving both asymptotic and nonasymptotic confidence
sequences that are considerably tighter than previous methods. These
anytime-valid methods enable inference under data-dependent stopping times
(sample sizes). Additionally, we use propensity score truncation techniques
from the recent off-policy estimation literature to reduce the finite sample
variance of our estimator without affecting the asymptotic variance. Empirical
results demonstrate that our methods yield narrower confidence sequences than
those previously developed in the literature while maintaining time-uniform
error control.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18281" title="Abstract">arXiv:2311.18281</a> (cross-list from eess.IV) [<a href="/pdf/2311.18281" title="Download PDF">pdf</a>, <a href="/format/2311.18281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Radiomic Feature Analysis For Automated MRI Keypoint  Detection: Enhancing Graph Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nasser%2C+S+A">Sahar Almahfouz Nasser</a>, 
<a href="/search/eess?searchtype=author&query=Pathak%2C+S">Shashwat Pathak</a>, 
<a href="/search/eess?searchtype=author&query=Singhal%2C+K">Keshav Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Meena%2C+M">Mohit Meena</a>, 
<a href="/search/eess?searchtype=author&query=Gupte%2C+N">Nihar Gupte</a>, 
<a href="/search/eess?searchtype=author&query=Chinmaya%2C+A">Ananya Chinmaya</a>, 
<a href="/search/eess?searchtype=author&query=Garg%2C+P">Prateek Garg</a>, 
<a href="/search/eess?searchtype=author&query=Sethi%2C+A">Amit Sethi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Graph neural networks (GNNs) present a promising alternative to CNNs and
transformers in certain image processing applications due to their
parameter-efficiency in modeling spatial relationships. Currently, a major area
of research involves the converting non-graph input data for GNN-based models,
notably in scenarios where the data originates from images. One approach
involves converting images into nodes by identifying significant keypoints
within them. Super-Retina, a semi-supervised technique, has been utilized for
detecting keypoints in retinal images. However, its limitations lie in the
dependency on a small initial set of ground truth keypoints, which is
progressively expanded to detect more keypoints. Having encountered
difficulties in detecting consistent initial keypoints in brain images using
SIFT and LoFTR, we proposed a new approach: radiomic feature-based keypoint
detection. Demonstrating the anatomical significance of the detected keypoints
was achieved by showcasing their efficacy in improving registration processes
guided by these keypoints. Subsequently, these keypoints were employed as the
ground truth for the keypoint detection method (LK-SuperRetina). Furthermore,
the study showcases the application of GNNs in image matching, highlighting
their superior performance in terms of both the number of good matches and
confidence scores. This research sets the stage for expanding GNN applications
into various other applications, including but not limited to image
classification, segmentation, and registration.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18284" title="Abstract">arXiv:2311.18284</a> (cross-list from math.CO) [<a href="/pdf/2311.18284" title="Download PDF">pdf</a>, <a href="/format/2311.18284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complement of the Djokovic-Winkler Relation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hellmuth%2C+M">Marc Hellmuth</a>, 
<a href="/search/math?searchtype=author&query=Schmidt%2C+B+J">Bruno J. Schmidt</a>, 
<a href="/search/math?searchtype=author&query=Scholz%2C+G+E">Guillaume E. Scholz</a>, 
<a href="/search/math?searchtype=author&query=Puthiyaveedu%2C+S+T">Sandhya Thekkumpadan Puthiyaveedu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The Djokovi\'{c}-Winkler relation $\Theta$ is a binary relation defined on
the edge set of a given graph that is based on the distances of certain
vertices and which plays a prominent role in graph theory. In this paper, we
explore the relatively uncharted ``reflexive complement'' $\overline\Theta$ of
$\Theta$, where $(e,f)\in \overline\Theta$ if and only if $e=f$ or $(e,f)\notin
\Theta$ for edges $e$ and $f$. We establish the relationship between
$\overline\Theta$ and the set $\Delta_{ef}$, comprising the distances between
the vertices of $e$ and $f$ and shed some light on the intricacies of its
transitive closure $\overline\Theta^*$. Notably, we demonstrate that
$\overline\Theta^*$ exhibits multiple equivalence classes only within a
restricted subclass of complete multipartite graphs. In addition, we
characterize non-trivial relations $R$ that coincide with $\overline\Theta$ as
those where the graph representation is disconnected, with each connected
component being the (join of) Cartesian product of complete graphs. The latter
results imply, somewhat surprisingly, that knowledge about the distances
between vertices is not required to determine $\overline\Theta^*$. Moreover,
$\overline\Theta^*$ has either exactly one or three equivalence classes.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18287" title="Abstract">arXiv:2311.18287</a> (cross-list from eess.IV) [<a href="/pdf/2311.18287" title="Download PDF">pdf</a>, <a href="/format/2311.18287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dispersed Structured Light for Hyperspectral 3D Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shin%2C+S">Suhyun Shin</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+S">Seokjun Choi</a>, 
<a href="/search/eess?searchtype=author&query=Heide%2C+F">Felix Heide</a>, 
<a href="/search/eess?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
<p class="mathjax">Hyperspectral 3D imaging aims to acquire both depth and spectral information
of a scene. However, existing methods are either prohibitively expensive and
bulky or compromise on spectral and depth accuracy. In this work, we present
Dispersed Structured Light (DSL), a cost-effective and compact method for
accurate hyperspectral 3D imaging. DSL modifies a traditional projector-camera
system by placing a sub-millimeter thick diffraction grating film front of the
projector. The grating disperses structured light based on light wavelength. To
utilize the dispersed structured light, we devise a model for dispersive
projection image formation and a per-pixel hyperspectral 3D reconstruction
method. We validate DSL by instantiating a compact experimental prototype. DSL
achieves spectral accuracy of 18.8nm full-width half-maximum (FWHM) and depth
error of 1mm. We demonstrate that DSL outperforms prior work on practical
hyperspectral 3D imaging. DSL promises accurate and practical hyperspectral 3D
imaging for diverse application domains, including computer vision and
graphics, cultural heritage, geology, and biology.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18306" title="Abstract">arXiv:2311.18306</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.18306" title="Download PDF">pdf</a>, <a href="/ps/2311.18306" title="Download PostScript">ps</a>, <a href="/format/2311.18306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAUNet: Precipitation Attention-based U-Net for rain prediction from  satellite radiance data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Reddy%2C+P+J">P. Jyoteeshkumar Reddy</a>, 
<a href="/search/physics?searchtype=author&query=Baki%2C+H">Harish Baki</a>, 
<a href="/search/physics?searchtype=author&query=Chinta%2C+S">Sandeep Chinta</a>, 
<a href="/search/physics?searchtype=author&query=Matear%2C+R">Richard Matear</a>, 
<a href="/search/physics?searchtype=author&query=Taylor%2C+J">John Taylor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces Precipitation Attention-based U-Net (PAUNet), a deep
learning architecture for predicting precipitation from satellite radiance
data, addressing the challenges of the Weather4cast 2023 competition. PAUNet is
a variant of U-Net and Res-Net, designed to effectively capture the large-scale
contextual information of multi-band satellite images in visible, water vapor,
and infrared bands through encoder convolutional layers with center cropping
and attention mechanisms. We built upon the Focal Precipitation Loss including
an exponential component (e-FPL), which further enhanced the importance across
different precipitation categories, particularly medium and heavy rain. Trained
on a substantial dataset from various European regions, PAUNet demonstrates
notable accuracy with a higher Critical Success Index (CSI) score than the
baseline model in predicting rainfall over multiple time slots. PAUNet's
architecture and training methodology showcase improvements in precipitation
forecasting, crucial for sectors like emergency services and retail and supply
chain management.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18313" title="Abstract">arXiv:2311.18313</a> (cross-list from math.DS) [<a href="/pdf/2311.18313" title="Download PDF">pdf</a>, <a href="/format/2311.18313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Implementation of Neural Networks through Reaction Networks --  Part I: Circuit Design and Convergence Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fan%2C+Y">Yuzhen Fan</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+C">Chuanhou Gao</a>, 
<a href="/search/math?searchtype=author&query=Dochain%2C+D">Denis Dochain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Information processing relying on biochemical interactions in the cellular
environment is essential for biological organisms. The implementation of
molecular computational systems holds significant interest and potential in the
fields of synthetic biology and molecular computation. This two-part article
aims to introduce a programmable biochemical reaction network (BCRN) system
endowed with mass action kinetics that realizes the fully connected neural
network (FCNN) and has the potential to act automatically in vivo. In part I,
the feedforward propagation computation, the backpropagation component, and all
bridging processes of FCNN are ingeniously designed as specific BCRN modules
based on their dynamics. This approach addresses a design gap in the
biochemical assignment module and judgment termination module and provides a
novel precise and robust realization of bi-molecular reactions for the learning
process. Through equilibrium approaching, we demonstrate that the designed BCRN
system achieves FCNN functionality with exponential convergence to target
computational results, thereby enhancing the theoretical support for such work.
Finally, the performance of this construction is further evaluated on two
typical logic classification problems.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18324" title="Abstract">arXiv:2311.18324</a> (cross-list from math.OC) [<a href="/pdf/2311.18324" title="Download PDF">pdf</a>, <a href="/format/2311.18324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank optimization on Tucker tensor varieties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+B">Bin Gao</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+R">Renfeng Peng</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+Y">Ya-xiang Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 14 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In the realm of tensor optimization, low-rank tensor decomposition,
particularly Tucker decomposition, stands as a pivotal technique for reducing
the number of parameters and for saving storage. We embark on an exploration of
Tucker tensor varieties -- the set of tensors with bounded Tucker rank -- in
which the geometry is notably more intricate than the well-explored geometry of
matrix varieties. We give an explicit parametrization of the tangent cone of
Tucker tensor varieties and leverage its geometry to develop provable
gradient-related line-search methods for optimization on Tucker tensor
varieties. The search directions are computed from approximate projections of
antigradient onto the tangent cone, which circumvents the calculation of
intractable metric projections. To the best of our knowledge, this is the first
work concerning geometry and optimization on Tucker tensor varieties. In
practice, low-rank tensor optimization suffers from the difficulty of choosing
a reliable rank parameter. To this end, we incorporate the established geometry
and propose a Tucker rank-adaptive method that is capable of identifying an
appropriate rank during iterations while the convergence is also guaranteed.
Numerical experiments on tensor completion with synthetic and real-world
datasets reveal that the proposed methods are in favor of recovering
performance over other state-of-the-art methods. Moreover, the rank-adaptive
method performs the best across various rank parameter selections and is indeed
able to find an appropriate rank.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18348" title="Abstract">arXiv:2311.18348</a> (cross-list from physics.geo-ph) [<a href="/pdf/2311.18348" title="Download PDF">pdf</a>, <a href="/format/2311.18348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Historical Climate Fields With Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bochow%2C+N">Nils Bochow</a>, 
<a href="/search/physics?searchtype=author&query=Poltronieri%2C+A">Anna Poltronieri</a>, 
<a href="/search/physics?searchtype=author&query=Rypdal%2C+M">Martin Rypdal</a>, 
<a href="/search/physics?searchtype=author&query=Boers%2C+N">Niklas Boers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Historical records of climate fields are often sparse due to missing
measurements, especially before the introduction of large-scale satellite
missions. Several statistical and model-based methods have been introduced to
fill gaps and reconstruct historical records. Here, we employ a recently
introduced deep-learning approach based on Fourier convolutions, trained on
numerical climate model output, to reconstruct historical climate fields. Using
this approach we are able to realistically reconstruct large and irregular
areas of missing data, as well as reconstruct known historical events such as
strong El Ni\~no and La Ni\~na with very little given information. Our method
outperforms the widely used statistical kriging method as well as other recent
machine learning approaches. The model generalizes to higher resolutions than
the ones it was trained on and can be used on a variety of climate fields.
Moreover, it allows inpainting of masks never seen before during the model
training.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18376" title="Abstract">arXiv:2311.18376</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.18376" title="Download PDF">pdf</a>, <a href="/ps/2311.18376" title="Download PostScript">ps</a>, <a href="/format/2311.18376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age Effects on Decision-Making, Drift Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kavian%2C+Z">Zahra Kavian</a>, 
<a href="/search/q-bio?searchtype=author&query=Hajisadeghi%2C+K">Kimia Hajisadeghi</a>, 
<a href="/search/q-bio?searchtype=author&query=Rezazadeh%2C+Y">Yashar Rezazadeh</a>, 
<a href="/search/q-bio?searchtype=author&query=Faraji%2C+M">Mehrbod Faraji</a>, 
<a href="/search/q-bio?searchtype=author&query=Ebrahimpour%2C+R">Reza Ebrahimpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training can improve human decision-making performance. After several
training sessions, a person can quickly and accurately complete a task.
However, decision-making is always a trade-off between accuracy and response
time. Factors such as age and drug abuse can affect the decision-making
process. This study examines how training can improve the performance of
different age groups in completing a random dot motion (RDM) task. The
participants are divided into two groups: old and young. They undergo a
three-phase training and then repeat the same RDM task. The hierarchical
drift-diffusion model analyzes the subjects' responses and determines how the
model's parameters change after training for both age groups. The results show
that after training, the participants were able to accumulate sensory
information faster, and the model drift rate increased. However, their decision
boundary decreased as they became more confident and had a lower
decision-making threshold. Additionally, the old group had a higher boundary
and lower drift rate in both pre and post-training, and there was less
difference between the two group parameters after training.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18377" title="Abstract">arXiv:2311.18377</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.18377" title="Download PDF">pdf</a>, <a href="/ps/2311.18377" title="Download PostScript">ps</a>, <a href="/format/2311.18377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning across Different Chemical Domains: Virtual Screening  of Organic Materials with Deep Learning Models Pretrained on Small Molecule  and Chemical Reaction Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+C">Chengwei Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhai%2C+Y">Yushuang Zhai</a>, 
<a href="/search/physics?searchtype=author&query=Gong%2C+Z">Ziyang Gong</a>, 
<a href="/search/physics?searchtype=author&query=She%2C+Y">Yuan-Bin She</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+Y">Yun-Fang Yang</a>, 
<a href="/search/physics?searchtype=author&query=Su%2C+A">An Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Machine learning prediction of organic materials properties is an efficient
virtual screening method ahead of more expensive screening methods. However,
this approach has suffered from insufficient labeled data on organic materials
to train state-of-the-art machine learning models. In this study, we
demonstrate that drug-like small molecule and chemical reaction databases can
be used to pretrain the BERT model for the virtual screening of organic
materials. Among the BERT models fine-tuned by five virtual screening tasks on
organic materials, the USPTO-SMILES pretrained BERT model had R2 &gt; 0.90 for two
tasks and R2 &gt; 0.82 for one, which was generally superior to the same models
pretrained by the small molecule or organic materials databases, as well as to
the other three traditional machine learning models trained directly on the
virtual screening task data. The superior performance of the USPTO-SMILES
pretrained BERT model is due to the greater variety of organic building blocks
in the USPTO database and the broader coverage of the chemical space. The even
better performance of the BERT model pretrained externally from a chemical
reaction database with additional sources of chemical reactions strengthens our
proof of concept that transfer learning across different chemical domains is
practical for the virtual screening of organic materials.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18399" title="Abstract">arXiv:2311.18399</a> (cross-list from eess.AS) [<a href="/pdf/2311.18399" title="Download PDF">pdf</a>, <a href="/format/2311.18399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Prompt Tuning for Universal Sound Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yuzhuo Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuanyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+R">Rui Xia</a>, 
<a href="/search/eess?searchtype=author&query=Tain%2C+P">Pingchuan Tain</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Universal sound separation (USS) is a task to separate arbitrary sounds from
an audio mixture. Existing USS systems are capable of separating arbitrary
sources, given a few examples of the target sources as queries. However,
separating arbitrary sounds with a single system is challenging, and the
robustness is not always guaranteed. In this work, we propose audio prompt
tuning (APT), a simple yet effective approach to enhance existing USS systems.
Specifically, APT improves the separation performance of specific sources
through training a small number of prompt parameters with limited audio
samples, while maintaining the generalization of the USS model by keeping its
parameters frozen. We evaluate the proposed method on MUSDB18 and ESC-50
datasets. Compared with the baseline model, APT can improve the
signal-to-distortion ratio performance by 0.67 dB and 2.06 dB using the full
training set of two datasets. Moreover, APT with only 5 audio samples even
outperforms the baseline systems utilizing full training data on the ESC-50
dataset, indicating the great potential of few-shot APT.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18426" title="Abstract">arXiv:2311.18426</a> (cross-list from math.OC) [<a href="/pdf/2311.18426" title="Download PDF">pdf</a>, <a href="/format/2311.18426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Fractional Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aggarwal%2C+A">Ashwani Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Fractional derivatives are a well-studied generalization of integer order
derivatives. Naturally, for optimization, it is of interest to understand the
convergence properties of gradient descent using fractional derivatives.
Convergence analysis of fractional gradient descent is currently limited both
in the methods analyzed and the settings analyzed. This paper aims to fill in
these gaps by analyzing variations of fractional gradient descent in smooth and
convex, smooth and strongly convex, and smooth and non-convex settings. First,
novel bounds will be established bridging fractional and integer derivatives.
Then, these bounds will be applied to the aforementioned settings to prove
$O(1/T)$ convergence for smooth and convex functions and linear convergence for
smooth and strongly convex functions. Additionally, we prove $O(1/T)$
convergence for smooth and non-convex functions using an extended notion of
smoothness that is more natural for fractional derivatives. Finally, empirical
results will be presented on the potential speed up of fractional gradient
descent over standard gradient descent as well as the challenges of predicting
which will be faster in general.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18431" title="Abstract">arXiv:2311.18431</a> (cross-list from math.OC) [<a href="/pdf/2311.18431" title="Download PDF">pdf</a>, <a href="/format/2311.18431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence of adaptive first order methods: proximal gradient  and alternating minimization algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Latafat%2C+P">Puya Latafat</a>, 
<a href="/search/math?searchtype=author&query=Themelis%2C+A">Andreas Themelis</a>, 
<a href="/search/math?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Building upon recent works on linesearch-free adaptive proximal gradient
methods, this paper proposes AdaPG$^{\pi,r}$, a framework that unifies and
extends existing results by providing larger stepsize policies and improved
lower bounds. Different choices of the parameters $\pi$ and $r$ are discussed
and the efficacy of the resulting methods is demonstrated through numerical
simulations. In an attempt to better understand the underlying theory, its
convergence is established in a more general setting that allows for
time-varying parameters. Finally, an adaptive alternating minimization
algorithm is presented by exploring the dual setting. This algorithm not only
incorporates additional adaptivity, but also expands its applicability beyond
standard strongly convex settings.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18471" title="Abstract">arXiv:2311.18471</a> (cross-list from quant-ph) [<a href="/pdf/2311.18471" title="Download PDF">pdf</a>, <a href="/format/2311.18471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the security of image transmission in Quantum era: A  Chaos-Assisted QKD Approach using entanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Rahman%2C+R">Raiyan Rahman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Azad%2C+M+S">Md Shawmoon Azad</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hasan%2C+M+R">Mohammed Rakibul Hasan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shubha%2C+S+E+U">Syed Emad Uddin Shubha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mahdy%2C+M+R+C">M.R.C.Mahdy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 10 equations, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The emergence of quantum computing has introduced unprecedented security
challenges to conventional cryptographic systems, particularly in the domain of
optical communications. This research addresses these challenges by
innovatively combining quantum key distribution (QKD), specifically the E91
protocol, with logistic chaotic maps to establish a secure image transmission
scheme. Our approach utilizes the unpredictability of chaotic systems alongside
the robust security mechanisms inherent in quantum entanglement. The scheme is
further fortified with an eavesdropping detection mechanism based on CHSH
inequality, thereby enhancing its resilience against unauthorized access.
Through quantitative simulations, we demonstrate the effectiveness of this
scheme in encrypting images, achieving high entropy and sensitivity to the
original images. The results indicate a significant improvement in encryption
and decryption efficiency, showcasing the potential of the scheme as a viable
solution against the vulnerabilities posed by quantum computing advancements.
Our research offers a novel perspective in secure optical communications,
blending the principles of chaos theory with QKD to create a more robust
cryptographic framework.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18506" title="Abstract">arXiv:2311.18506</a> (cross-list from stat.ML) [<a href="/pdf/2311.18506" title="Download PDF">pdf</a>, <a href="/format/2311.18506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Convergence of Online Identification for Mixed Linear Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+Y">Yujing Liu</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+Z">Zhixin Liu</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+L">Lei Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Statistics Theory (math.ST)

</div>
<p class="mathjax">Mixed linear regression (MLR) is a powerful model for characterizing
nonlinear relationships by utilizing a mixture of linear regression sub-models.
The identification of MLR is a fundamental problem, where most of the existing
results focus on offline algorithms, rely on independent and identically
distributed (i.i.d) data assumptions, and provide local convergence results
only. This paper investigates the online identification and data clustering
problems for two basic classes of MLRs, by introducing two corresponding new
online identification algorithms based on the expectation-maximization (EM)
principle. It is shown that both algorithms will converge globally without
resorting to the traditional i.i.d data assumptions. The main challenge in our
investigation lies in the fact that the gradient of the maximum likelihood
function does not have a unique zero, and a key step in our analysis is to
establish the stability of the corresponding differential equation in order to
apply the celebrated Ljung's ODE method. It is also shown that the
within-cluster error and the probability that the new data is categorized into
the correct cluster are asymptotically the same as those in the case of known
parameters. Finally, numerical simulations are provided to verify the
effectiveness of our online algorithms.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18508" title="Abstract">arXiv:2311.18508</a> (cross-list from eess.IV) [<a href="/pdf/2311.18508" title="Download PDF">pdf</a>, <a href="/format/2311.18508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DifAugGAN: A Practical Diffusion-style Data Augmentation for GAN-based  Single Image Super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Niu%2C+A">Axi Niu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tee%2C+J+T+J">Joshua Tian Jin Tee</a>, 
<a href="/search/eess?searchtype=author&query=Pham%2C+T+X">Trung X. Pham</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Jinqiu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>, 
<a href="/search/eess?searchtype=author&query=Kweon%2C+I+S">In So Kweon</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">It is well known the adversarial optimization of GAN-based image
super-resolution (SR) methods makes the preceding SR model generate unpleasant
and undesirable artifacts, leading to large distortion. We attribute the cause
of such distortions to the poor calibration of the discriminator, which hampers
its ability to provide meaningful feedback to the generator for learning
high-quality images. To address this problem, we propose a simple but
non-travel diffusion-style data augmentation scheme for current GAN-based SR
methods, known as DifAugGAN. It involves adapting the diffusion process in
generative diffusion models for improving the calibration of the discriminator
during training motivated by the successes of data augmentation schemes in the
field to achieve good calibration. Our DifAugGAN can be a Plug-and-Play
strategy for current GAN-based SISR methods to improve the calibration of the
discriminator and thus improve SR performance. Extensive experimental
evaluations demonstrate the superiority of DifAugGAN over state-of-the-art
GAN-based SISR methods across both synthetic and real-world datasets,
showcasing notable advancements in both qualitative and quantitative results.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18524" title="Abstract">arXiv:2311.18524</a> (cross-list from math.CO) [<a href="/pdf/2311.18524" title="Download PDF">pdf</a>, <a href="/ps/2311.18524" title="Download PostScript">ps</a>, <a href="/format/2311.18524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix discrepancy and the log-rank conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sudakov%2C+B">Benny Sudakov</a>, 
<a href="/search/math?searchtype=author&query=Tomon%2C+I">Istv&#xe1;n Tomon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Given an $m\times n$ binary matrix $M$ with $|M|=p\cdot mn$ (where $|M|$
denotes the number of 1 entries), define the discrepancy of $M$ as
$\mbox{disc}(M)=\displaystyle\max_{X\subset [m], Y\subset [n]}\big||M[X\times
Y]|-p|X|\cdot |Y|\big|$. Using semidefinite programming and spectral
techniques, we prove that if $\mbox{rank}(M)\leq r$ and $p\leq 1/2$, then
<br />$$\mbox{disc}(M)\geq \Omega(mn)\cdot
\min\left\{p,\frac{p^{1/2}}{\sqrt{r}}\right\}.$$
<br />We use this result to obtain a modest improvement of Lovett's best known
upper bound on the log-rank conjecture. We prove that any $m\times n$ binary
matrix $M$ of rank at most $r$ contains an $(m\cdot 2^{-O(\sqrt{r})})\times
(n\cdot 2^{-O(\sqrt{r})})$ sized all-1 or all-0 submatrix, which implies that
the deterministic communication complexity of any Boolean function of rank $r$
is at most $O(\sqrt{r})$.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18566" title="Abstract">arXiv:2311.18566</a> (cross-list from quant-ph) [<a href="/pdf/2311.18566" title="Download PDF">pdf</a>, <a href="/ps/2311.18566" title="Download PostScript">ps</a>, <a href="/format/2311.18566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconditionally Secure Commitments with Quantum Auxiliary Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Morimae%2C+T">Tomoyuki Morimae</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nehoran%2C+B">Barak Nehoran</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yamakawa%2C+T">Takashi Yamakawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We show the following unconditional results on quantum commitments in two
related yet different models:
<br />1. We revisit the notion of quantum auxiliary-input commitments introduced by
Chailloux, Kerenidis, and Rosgen (Comput. Complex. 2016) where both the
committer and receiver take the same quantum state, which is determined by the
security parameter, as quantum auxiliary inputs. We show that
computationally-hiding and statistically-binding quantum auxiliary-input
commitments exist unconditionally, i.e., without relying on any unproven
assumption, while Chailloux et al. assumed a complexity-theoretic assumption,
${\bf QIP}\not\subseteq{\bf QMA}$. On the other hand, we observe that achieving
both statistical hiding and statistical binding at the same time is impossible
even in the quantum auxiliary-input setting. To the best of our knowledge, this
is the first example of unconditionally proving computational security of any
form of (classical or quantum) commitments for which statistical security is
impossible. As intermediate steps toward our construction, we introduce and
unconditionally construct post-quantum sparse pseudorandom distributions and
quantum auxiliary-input EFI pairs which may be of independent interest.
<br />2. We introduce a new model which we call the common reference quantum state
(CRQS) model where both the committer and receiver take the same quantum state
that is randomly sampled by an efficient setup algorithm. We unconditionally
prove that there exist statistically hiding and statistically binding
commitments in the CRQS model, circumventing the impossibility in the plain
model.
<br />We also discuss their applications to zero-knowledge proofs, oblivious
transfers, and multi-party computations.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18574" title="Abstract">arXiv:2311.18574</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.18574" title="Download PDF">pdf</a>, <a href="/format/2311.18574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Iterative Refinement towards Robust and Versatile Molecular  Docking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+J">Jiaxian Yan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Z">Zaixi Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Molecular docking is a key computational tool utilized to predict the binding
conformations of small molecules to protein targets, which is fundamental in
the design of novel drugs. Despite recent advancements in geometric deep
learning-based approaches leading to improvements in blind docking efficiency,
these methods have encountered notable challenges, such as limited
generalization performance on unseen proteins, the inability to concurrently
address the settings of blind docking and site-specific docking, and the
frequent occurrence of physical implausibilities such as inter-molecular steric
clash. In this study, we introduce DeltaDock, a robust and versatile framework
designed for efficient molecular docking to overcome these challenges.
DeltaDock operates in a two-step process: rapid initial complex structures
sampling followed by multi-scale iterative refinement of the initial
structures. In the initial stage, to sample accurate structures with high
efficiency, we develop a ligand-dependent binding site prediction model founded
on large protein models and graph neural networks. This model is then paired
with GPU-accelerated sampling algorithms. The sampled structures are updated
using a multi-scale iterative refinement module that captures both
protein-ligand atom-atom interactions and residue-atom interactions in the
following stage. Distinct from previous geometric deep learning methods that
are conditioned on the blind docking setting, DeltaDock demonstrates superior
performance in both blind docking and site-specific docking settings.
Comprehensive experimental results reveal that DeltaDock consistently surpasses
baseline methods in terms of docking accuracy. Furthermore, it displays
remarkable generalization capabilities and proficiency for predicting
physically valid structures, thereby attesting to its robustness and
reliability in various scenarios.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18588" title="Abstract">arXiv:2311.18588</a> (cross-list from quant-ph) [<a href="/pdf/2311.18588" title="Download PDF">pdf</a>, <a href="/format/2311.18588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing ZX-Diagrams with Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=N%C3%A4gele%2C+M">Maximilian N&#xe4;gele</a>, 
<a href="/search/quant-ph?searchtype=author&query=Marquardt%2C+F">Florian Marquardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">ZX-diagrams are a powerful graphical language for the description of quantum
processes with applications in fundamental quantum mechanics, quantum circuit
optimization, tensor network simulation, and many more. The utility of
ZX-diagrams relies on a set of local transformation rules that can be applied
to them without changing the underlying quantum process they describe. These
rules can be exploited to optimize the structure of ZX-diagrams for a range of
applications. However, finding an optimal sequence of transformation rules is
generally an open problem. In this work, we bring together ZX-diagrams with
reinforcement learning, a machine learning technique designed to discover an
optimal sequence of actions in a decision-making problem and show that a
trained reinforcement learning agent can significantly outperform other
optimization techniques like a greedy strategy or simulated annealing. The use
of graph neural networks to encode the policy of the agent enables
generalization to diagrams much bigger than seen during the training phase.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18593" title="Abstract">arXiv:2311.18593</a> (cross-list from eess.SP) [<a href="/pdf/2311.18593" title="Download PDF">pdf</a>, <a href="/format/2311.18593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Old Idea: Beam-Steering Reflectarrays for Efficient Sub-THz  Multiuser MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+K+K">Krishan Kumar Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We present a novel, power- &amp; hardware-efficient, multiuser, multibeam RIS
(Reflective Intelligent Surface) architecture for multiuser MIMO, especially
for very high frequency bands (e.g., high mmWave and sub-THz), where channels
are typically sparse in the beamspace and LOS is the dominant component. The
key module is formed by an active multiantenna feeder (AMAF) with a small
number of active antennas, placed in the near field of a RIS with a much larger
number of passive controllable reflecting elements. We propose a pragmatic
approach to obtain a steerable beam with high gain and very low sidelobes. Then
K independently controlled beams can be achieved by closely stacking K such
AMAF-RIS modules. Our analysis includes the mutual interference between the
modules and the fact that, due to the delay difference of propagation through
the AMAF-RIS structure, the resulting channel matrix is frequency selective
even in for pure LOS propagation. We consider a 3D geometry and show that
``beam focusing'' is in fact possible (and much more effective in terms of
coverage) also in the far-field, by creating spotbeams with limited footprint
both in angle and in range. Our results show that: 1) simple RF beamforming
(BF) without computationally expensive baseband multiuser precoding is
sufficient to practically eliminate multiuser interference when the users are
chosen with sufficient angular/range separation, thanks to the extremely low
sidelobe beams; 2) the impact of beam pointing errors with standard deviation
as large as 2.5 deg and RIS quantized phase-shifters with quantization bits &gt; 2
is essentially negligible; 3) The proposed architecture is more power efficient
&amp; much simpler from a hardware implementation viewpoint than standard active
arrays with the same BF performance. We show also that the array gain of the
proposed AMAF-RIS structure is linear with the RIS aperture.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18599" title="Abstract">arXiv:2311.18599</a> (cross-list from eess.SP) [<a href="/pdf/2311.18599" title="Download PDF">pdf</a>, <a href="/ps/2311.18599" title="Download PostScript">ps</a>, <a href="/format/2311.18599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Detection Algorithm for Multiple Cognitive Users in Spectrum  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lele Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yingxin Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Demeter%2C+D">David Demeter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://aei.ewapublishing.org/article.html?pk=e24c40d220434209ae2fe2e984bcf2c2">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Engineering Innovation, Vol. 4, 16-25 Advances in
  Engineering Innovation, Published 27 November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spectrum sensing technology is a crucial aspect of modern communication
technology, serving as one of the essential techniques for efficiently
utilizing scarce information resources in tight frequency bands. This paper
first introduces three common logical circuit decision criteria in hard
decisions and analyzes their decision rigor. Building upon hard decisions, the
paper further introduces a method for multi-user spectrum sensing based on soft
decisions. Then the paper simulates the false alarm probability and detection
probability curves corresponding to the three criteria. The simulated results
of multi-user collaborative sensing indicate that the simulation process
significantly reduces false alarm probability and enhances detection
probability. This approach effectively detects spectrum resources unoccupied
during idle periods, leveraging the concept of time-division multiplexing and
rationalizing the redistribution of information resources. The entire
computation process relies on the calculation principles of power spectral
density in communication theory, involving threshold decision detection for
noise power and the sum of noise and signal power. It provides a secondary
decision detection, reflecting the perceptual decision performance of logical
detection methods with relative accuracy.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18612" title="Abstract">arXiv:2311.18612</a> (cross-list from eess.IV) [<a href="/pdf/2311.18612" title="Download PDF">pdf</a>, <a href="/format/2311.18612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cancer-Net PCa-Gen: Synthesis of Realistic Prostate Diffusion Weighted  Imaging Data via Anatomic-Conditional Controlled Latent Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sridhar%2C+A">Aditya Sridhar</a>, 
<a href="/search/eess?searchtype=author&query=Tai%2C+C+A">Chi-en Amy Tai</a>, 
<a href="/search/eess?searchtype=author&query=Gunraj%2C+H">Hayden Gunraj</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In Canada, prostate cancer is the most common form of cancer in men and
accounted for 20% of new cancer cases for this demographic in 2022. Due to
recent successes in leveraging machine learning for clinical decision support,
there has been significant interest in the development of deep neural networks
for prostate cancer diagnosis, prognosis, and treatment planning using
diffusion weighted imaging (DWI) data. A major challenge hindering widespread
adoption in clinical use is poor generalization of such networks due to
scarcity of large-scale, diverse, balanced prostate imaging datasets for
training such networks. In this study, we explore the efficacy of latent
diffusion for generating realistic prostate DWI data through the introduction
of an anatomic-conditional controlled latent diffusion strategy. To the best of
the authors' knowledge, this is the first study to leverage conditioning for
synthesis of prostate cancer imaging. Experimental results show that the
proposed strategy, which we call Cancer-Net PCa-Gen, enhances synthesis of
diverse prostate images through controllable tumour locations and better
anatomical and textural fidelity. These crucial features make it well-suited
for augmenting real patient data, enabling neural networks to be trained on a
more diverse and comprehensive data distribution. The Cancer-Net PCa-Gen
framework and sample images have been made publicly available at
https://www.kaggle.com/datasets/deetsadi/cancer-net-pca-gen-dataset as a part
of a global open-source initiative dedicated to accelerating advancement in
machine learning to aid clinicians in the fight against cancer.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18639" title="Abstract">arXiv:2311.18639</a> (cross-list from stat.ML) [<a href="/pdf/2311.18639" title="Download PDF">pdf</a>, <a href="/format/2311.18639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Reduction of Causal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Keki%C4%87%2C+A">Armin Keki&#x107;</a>, 
<a href="/search/stat?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/stat?searchtype=author&query=Besserve%2C+M">Michel Besserve</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Why does a phenomenon occur? Addressing this question is central to most
scientific inquiries based on empirical observations, and often heavily relies
on simulations of scientific models. As models become more intricate,
deciphering the causes behind these phenomena in high-dimensional spaces of
interconnected variables becomes increasingly challenging. Causal machine
learning may assist scientists in the discovery of relevant and interpretable
patterns of causation in simulations. We introduce Targeted Causal Reduction
(TCR), a method for turning complex models into a concise set of causal factors
that explain a specific target phenomenon. We derive an information theoretic
objective to learn TCR from interventional data or simulations and propose
algorithms to optimize this objective efficiently. TCR's ability to generate
interpretable high-level explanations from complex models is demonstrated on
toy and mechanical systems, illustrating its potential to assist scientists in
the study of complex phenomena in a broad range of disciplines.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18663" title="Abstract">arXiv:2311.18663</a> (cross-list from stat.ML) [<a href="/pdf/2311.18663" title="Download PDF">pdf</a>, <a href="/format/2311.18663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choosing the parameter of the Fermat distance: navigating geometry and  noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chazal%2C+F">Fr&#xe9;d&#xe9;ric Chazal</a>, 
<a href="/search/stat?searchtype=author&query=Ferraris%2C+L">Laure Ferraris</a>, 
<a href="/search/stat?searchtype=author&query=Groisman%2C+P">Pablo Groisman</a>, 
<a href="/search/stat?searchtype=author&query=Jonckheere%2C+M">Matthieu Jonckheere</a>, 
<a href="/search/stat?searchtype=author&query=Pascal%2C+F">Fr&#xe9;d&#xe9;ric Pascal</a>, 
<a href="/search/stat?searchtype=author&query=Sapienza%2C+F">Facundo Sapienza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">The Fermat distance has been recently established as a useful tool for
machine learning tasks when a natural distance is not directly available to the
practitioner or to improve the results given by Euclidean distances by
exploding the geometrical and statistical properties of the dataset. This
distance depends on a parameter $\alpha$ that greatly impacts the performance
of subsequent tasks. Ideally, the value of $\alpha$ should be large enough to
navigate the geometric intricacies inherent to the problem. At the same, it
should remain restrained enough to sidestep any deleterious ramifications
stemming from noise during the process of distance estimation. We study both
theoretically and through simulations how to select this parameter.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18672" title="Abstract">arXiv:2311.18672</a> (cross-list from quant-ph) [<a href="/pdf/2311.18672" title="Download PDF">pdf</a>, <a href="/format/2311.18672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison Between Invariant and Equivariant Classical and Quantum  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Forestano%2C+R+T">Roy T. Forestano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cara%2C+M+C">Mar&#xe7;al Comajoan Cara</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dahale%2C+G+R">Gopal Ramesh Dahale</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Z">Zhongtian Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gleyzer%2C+S">Sergei Gleyzer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Justice%2C+D">Daniel Justice</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kong%2C+K">Kyoungchul Kong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magorsch%2C+T">Tom Magorsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matchev%2C+K+T">Konstantin T. Matchev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matcheva%2C+K">Katia Matcheva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Unlu%2C+E+B">Eyup B. Unlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, 3 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine learning algorithms are heavily relied on to understand the vast
amounts of data from high-energy particle collisions at the CERN Large Hadron
Collider (LHC). The data from such collision events can naturally be
represented with graph structures. Therefore, deep geometric methods, such as
graph neural networks (GNNs), have been leveraged for various data analysis
tasks in high-energy physics. One typical task is jet tagging, where jets are
viewed as point clouds with distinct features and edge connections between
their constituent particles. The increasing size and complexity of the LHC
particle datasets, as well as the computational models used for their analysis,
greatly motivate the development of alternative fast and efficient
computational paradigms such as quantum computation. In addition, to enhance
the validity and robustness of deep networks, one can leverage the fundamental
symmetries present in the data through the use of invariant inputs and
equivariant layers. In this paper, we perform a fair and comprehensive
comparison between classical graph neural networks (GNNs) and equivariant graph
neural networks (EGNNs) and their quantum counterparts: quantum graph neural
networks (QGNNs) and equivariant quantum graph neural networks (EQGNN). The
four architectures were benchmarked on a binary classification task to classify
the parton-level particle initiating the jet. Based on their AUC scores, the
quantum networks were shown to outperform the classical networks. However,
seeing the computational advantage of the quantum networks in practice may have
to wait for the further development of quantum technology and its associated
APIs.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18689" title="Abstract">arXiv:2311.18689</a> (cross-list from eess.AS) [<a href="/pdf/2311.18689" title="Download PDF">pdf</a>, <a href="/format/2311.18689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace Hybrid MVDR Beamforming for Augmented Hearing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hafezi%2C+S">Sina Hafezi</a>, 
<a href="/search/eess?searchtype=author&query=Moore%2C+A+H">Alastair H. Moore</a>, 
<a href="/search/eess?searchtype=author&query=Guiraud%2C+P+H">Pierre H. Guiraud</a>, 
<a href="/search/eess?searchtype=author&query=Naylor%2C+P+A">Patrick A. Naylor</a>, 
<a href="/search/eess?searchtype=author&query=Donley%2C+J">Jacob Donley</a>, 
<a href="/search/eess?searchtype=author&query=Tourbabin%2C+V">Vladimir Tourbabin</a>, 
<a href="/search/eess?searchtype=author&query=Lunner%2C+T">Thomas Lunner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, submitted for IEEE/ACM Transactions on Audio, Speech, and Language Processing on 23-Nov-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Signal-dependent beamformers are advantageous over signal-independent
beamformers when the acoustic scenario - be it real-world or simulated - is
straightforward in terms of the number of sound sources, the ambient sound
field and their dynamics. However, in the context of augmented reality audio
using head-worn microphone arrays, the acoustic scenarios encountered are often
far from straightforward. The design of robust, high-performance, adaptive
beamformers for such scenarios is an on-going challenge. This is due to the
violation of the typically required assumptions on the noise field caused by,
for example, rapid variations resulting from complex acoustic environments,
and/or rotations of the listener's head. This work proposes a multi-channel
speech enhancement algorithm which utilises the adaptability of
signal-dependent beamformers while still benefiting from the computational
efficiency and robust performance of signal-independent super-directive
beamformers. The algorithm has two stages. (i) The first stage is a hybrid
beamformer based on a dictionary of weights corresponding to a set of noise
field models. (ii) The second stage is a wide-band subspace post-filter to
remove any artifacts resulting from (i). The algorithm is evaluated using both
real-world recordings and simulations of a cocktail-party scenario. Noise
suppression, intelligibility and speech quality results show a significant
performance improvement by the proposed algorithm compared to the baseline
super-directive beamformer. A data-driven implementation of the noise field
dictionary is shown to provide more noise suppression, and similar speech
intelligibility and quality, compared to a parametric dictionary.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18694" title="Abstract">arXiv:2311.18694</a> (cross-list from stat.ML) [<a href="/pdf/2311.18694" title="Download PDF">pdf</a>, <a href="/format/2311.18694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Summarization and Change Detection in Graph Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fukushima%2C+S">Shintaro Fukushima</a>, 
<a href="/search/stat?searchtype=author&query=Yamanishi%2C+K">Kenji Yamanishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, Accepted to 23rd IEEE International Conference on Data Mining (ICDM2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study addresses the issue of balancing graph summarization and graph
change detection. Graph summarization compresses large-scale graphs into a
smaller scale. However, the question remains: To what extent should the
original graph be compressed? This problem is solved from the perspective of
graph change detection, aiming to detect statistically significant changes
using a stream of summary graphs. If the compression rate is extremely high,
important changes can be ignored, whereas if the compression rate is extremely
low, false alarms may increase with more memory. This implies that there is a
trade-off between compression rate in graph summarization and accuracy in
change detection. We propose a novel quantitative methodology to balance this
trade-off to simultaneously realize reliable graph summarization and change
detection. We introduce a probabilistic structure of hierarchical latent
variable model into a graph, thereby designing a parameterized summary graph on
the basis of the minimum description length principle. The parameter specifying
the summary graph is then optimized so that the accuracy of change detection is
guaranteed to suppress Type I error probability (probability of raising false
alarms) to be less than a given confidence level. First, we provide a
theoretical framework for connecting graph summarization with change detection.
Then, we empirically demonstrate its effectiveness on synthetic and real
datasets.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18715" title="Abstract">arXiv:2311.18715</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.18715" title="Download PDF">pdf</a>, <a href="/format/2311.18715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Flow Simulations using Online Dynamic Mode Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Suh%2C+S+W">Seung Won Suh</a>, 
<a href="/search/physics?searchtype=author&query=Chung%2C+S+W">Seung Whan Chung</a>, 
<a href="/search/physics?searchtype=author&query=Bremer%2C+P">Peer-Timo Bremer</a>, 
<a href="/search/physics?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We develop an on-the-fly reduced-order model (ROM) integrated with a flow
simulation, gradually replacing a corresponding full-order model (FOM) of a
physics solver. Unlike offline methods requiring a separate FOM-only simulation
prior to model reduction, our approach constructs a ROM dynamically during the
simulation, replacing the FOM when deemed credible. Dynamic mode decomposition
(DMD) is employed for online ROM construction, with a single snapshot vector
used for rank-1 updates in each iteration. Demonstrated on a flow over a
cylinder with Re = 100, our hybrid FOM/ROM simulation is verified in terms of
the Strouhal number, resulting in a 4.4 times speedup compared to the FOM
solver.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18717" title="Abstract">arXiv:2311.18717</a> (cross-list from econ.GN) [<a href="/pdf/2311.18717" title="Download PDF">pdf</a>, <a href="/format/2311.18717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crypto Wash Trading: Direct vs. Indirect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Falk%2C+B+H">Brett Hemenway Falk</a>, 
<a href="/search/econ?searchtype=author&query=Tsoukalas%2C+G">Gerry Tsoukalas</a>, 
<a href="/search/econ?searchtype=author&query=Zhang%2C+N">Niuniu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Cryptography and Security (cs.CR); Multiagent Systems (cs.MA); Trading and Market Microstructure (q-fin.TR); Applications (stat.AP)

</div>
<p class="mathjax">Recent studies using indirect statistical methods estimate that around 70% of
traded value on centralized crypto exchanges like Binance, can be characterized
as wash trading. This paper turns to NFT markets, where transaction
transparency, including analysis of roundtrip trades and common wallet
activities, allows for more accurate direct estimation methods to be applied.
We find roughly 30% of NFT volume and between 45-95% of traded value, involve
wash trading. More importantly, our approach enables a critical evaluation of
common indirect estimation methods used in the literature. We find major
differences in their effectiveness; some failing entirely. Roundedness filters,
like those used in Cong et al. (2023), emerge as the most accurate. In fact,
the two approaches can be closely aligned via hyper-parameter optimization if
direct data is available.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18725" title="Abstract">arXiv:2311.18725</a> (cross-list from stat.ME) [<a href="/pdf/2311.18725" title="Download PDF">pdf</a>, <a href="/format/2311.18725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI in Pharma for Personalized Sequential Decision-Making: Methods,  Applications and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Hongtao Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Anderson%2C+K">Keaven Anderson</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+S">Songzi Li</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+R">Ruoqing Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the pharmaceutical industry, the use of artificial intelligence (AI) has
seen consistent growth over the past decade. This rise is attributed to major
advancements in statistical machine learning methodologies, computational
capabilities and the increased availability of large datasets. AI techniques
are applied throughout different stages of drug development, ranging from drug
discovery to post-marketing benefit-risk assessment. Kolluri et al. provided a
review of several case studies that span these stages, featuring key
applications such as protein structure prediction, success probability
estimation, subgroup identification, and AI-assisted clinical trial monitoring.
From a regulatory standpoint, there was a notable uptick in submissions
incorporating AI components in 2021. The most prevalent therapeutic areas
leveraging AI were oncology (27%), psychiatry (15%), gastroenterology (12%),
and neurology (11%). The paradigm of personalized or precision medicine has
gained significant traction in recent research, partly due to advancements in
AI techniques \cite{hamburg2010path}. This shift has had a transformative
impact on the pharmaceutical industry. Departing from the traditional
"one-size-fits-all" model, personalized medicine incorporates various
individual factors, such as environmental conditions, lifestyle choices, and
health histories, to formulate customized treatment plans. By utilizing
sophisticated machine learning algorithms, clinicians and researchers are
better equipped to make informed decisions in areas such as disease prevention,
diagnosis, and treatment selection, thereby optimizing health outcomes for each
individual.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18732" title="Abstract">arXiv:2311.18732</a> (cross-list from eess.SP) [<a href="/pdf/2311.18732" title="Download PDF">pdf</a>, <a href="/format/2311.18732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indoor Millimeter Wave Localization using Multiple Self-Supervised Tiny  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shastri%2C+A">Anish Shastri</a>, 
<a href="/search/eess?searchtype=author&query=Garcia-Saavedra%2C+A">Andres Garcia-Saavedra</a>, 
<a href="/search/eess?searchtype=author&query=Casari%2C+P">Paolo Casari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We consider the localization of a mobile millimeter-wave client in a large
indoor environment using multilayer perceptron neural networks (NNs). Instead
of training and deploying a single deep model, we proceed by choosing among
multiple tiny NNs trained in a self-supervised manner. The main challenge then
becomes to determine and switch to the best NN among the available ones, as an
incorrect NN will fail to localize the client. In order to upkeep the
localization accuracy, we propose two switching schemes: one based on a Kalman
filter, and one based on the statistical distribution of the training data. We
analyze the proposed schemes via simulations, showing that our approach
outperforms both geometric localization schemes and the use of a single NN.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18734" title="Abstract">arXiv:2311.18734</a> (cross-list from math.PR) [<a href="/pdf/2311.18734" title="Download PDF">pdf</a>, <a href="/format/2311.18734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural results for the Tree Builder Random Walk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Engl%C3%A4nder%2C+J">Janos Engl&#xe4;nder</a>, 
<a href="/search/math?searchtype=author&query=Iacobelli%2C+G">Giulio Iacobelli</a>, 
<a href="/search/math?searchtype=author&query=Pete%2C+G">G&#xe1;bor Pete</a>, 
<a href="/search/math?searchtype=author&query=Ribeiro%2C+R">Rodrigo Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Data Structures and Algorithms (cs.DS); Chemical Physics (physics.chem-ph); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We study the Tree Builder Random Walk: a randomly growing tree, built by a
walker as she is walking around the tree. Namely, at each time $n$, she adds a
leaf to her current vertex with probability $p_n=n^{-\gamma}$, $\gamma\in
(2/3,1]$, then moves to a uniform random neighbor on the possibly modified
tree. We show that the tree process at its growth times, after a random finite
number of steps, can be coupled to be identical to the Barab\'asi-Albert
preferential attachment tree model. Thus, our TBRW-model is a local dynamics
giving rise to the BA-model. The coupling also implies that many properties
known for the BA-model, such as diameter and degree distribution, can be
directly transferred to our TBRW-model, extending previous results.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18744" title="Abstract">arXiv:2311.18744</a> (cross-list from quant-ph) [<a href="/pdf/2311.18744" title="Download PDF">pdf</a>, <a href="/format/2311.18744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks:  Benchmarking against Classical Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Z">Zhongtian Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cara%2C+M+C">Mar&#xe7;al Comajoan Cara</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dahale%2C+G+R">Gopal Ramesh Dahale</a>, 
<a href="/search/quant-ph?searchtype=author&query=Forestano%2C+R+T">Roy T. Forestano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gleyzer%2C+S">Sergei Gleyzer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Justice%2C+D">Daniel Justice</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kong%2C+K">Kyoungchul Kong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magorsch%2C+T">Tom Magorsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matchev%2C+K+T">Konstantin T. Matchev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matcheva%2C+K">Katia Matcheva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Unlu%2C+E+B">Eyup B. Unlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents a comprehensive comparative analysis of the performance
of Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks
(QNN), juxtaposed against their classical counterparts: Equivariant Neural
Networks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of
each network with two toy examples for a binary classification task, focusing
on model complexity (measured by the number of parameters) and the size of the
training data set. Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$
EQNN and the QNN provide superior performance for smaller parameter sets and
modest training data samples.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18772" title="Abstract">arXiv:2311.18772</a> (cross-list from math.CO) [<a href="/pdf/2311.18772" title="Download PDF">pdf</a>, <a href="/format/2311.18772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Study of the Game Exact Nim(5, 2)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gurvich%2C+V">Vladimir Gurvich</a>, 
<a href="/search/math?searchtype=author&query=Parfenov%2C+A">Artem Parfenov</a>, 
<a href="/search/math?searchtype=author&query=Vyalyi%2C+M">Michael Vyalyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We compare to different extensions of the ancient game of nim: Moore's
nim$(n, \leq k)$ and exact nim$(n, = k)$. Given integers $n$ and $k$ such that
$0 &lt; k \leq n$, we consider $n$ piles of stones. Two players alternate turns.
By one move it is allowed to choose and reduce any (i) at most $k$ or (ii)
exactly $k$ piles of stones in games nim$(n, \leq k)$ and nim$(n, = k)$,
respectively. The player who has to move but cannot is the loser. Both games
coincide with nim when $k=1$. Game nim$(n, \leq k)$ was introduced by Moore
(1910) who characterized its Sprague-Grundy (SG) values 0 (that is,
P-positions) and 1. The first open case is SG values 2 for nim$(4, \leq 2)$.
Game nim$(n, = k)$, was introduced in 2018. An explicit formula for its SG
function was computed for $2k \geq n$. In contrast, case $2k &lt; n$ seems
difficult: even the P-positions are not known already for nim$(5,=2)$. Yet, it
seems that the P-position of games nim$(n+1,=2)$ and nim$(n+1,\leq 2)$ are
closely related. (Note that P-positions of the latter are known.) Here we
provide some theoretical and computational evidence of such a relation for
$n=5$.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18774" title="Abstract">arXiv:2311.18774</a> (cross-list from eess.AS) [<a href="/pdf/2311.18774" title="Download PDF">pdf</a>, <a href="/format/2311.18774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Aliasing-Free Hybrid Digital-Analog Polyphonic Synthesizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Roth%2C+J">Jonas Roth</a>, 
<a href="/search/eess?searchtype=author&query=Keller%2C+D">Domenic Keller</a>, 
<a href="/search/eess?searchtype=author&query=Casta%C3%B1eda%2C+O">Oscar Casta&#xf1;eda</a>, 
<a href="/search/eess?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at DAFx23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Analog subtractive synthesizers are generally considered to provide superior
sound quality compared to digital emulations. However, analog circuitry
requires calibration and suffers from aging, temperature instability, and
limited flexibility in generating a wide variety of waveforms. Digital
synthesis can mitigate many of these drawbacks, but generating arbitrary
aliasing-free waveforms remains challenging. In this paper, we present the
+-synth, a hybrid digital-analog eight-voice polyphonic synthesizer prototype
that combines the best of both worlds. At the heart of the synthesizer is the
big Fourier oscillator (BFO), a novel digital very-large scale integration
(VLSI) design that utilizes additive synthesis to generate a wide variety of
aliasing-free waveforms. Each BFO produces two voices, using four oscillators
per voice. A single oscillator can generate up to 1024 freely configurable
partials (harmonic or inharmonic), which are calculated using coordinate
rotation digital computers (CORDICs). The BFOs were fabricated as 65nm CMOS
custom application-specific integrated circuits (ASICs), which are integrated
in the +-synth to simultaneously generate up to 32768 partials. Four 24-bit
96kHz stereo DACs then convert the eight voices into the analog domain,
followed by digitally controlled analog low-pass filtering and amplification.
Measurement results of the +-synth prototype demonstrate high fidelity and low
latency.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18788" title="Abstract">arXiv:2311.18788</a> (cross-list from eess.IV) [<a href="/pdf/2311.18788" title="Download PDF">pdf</a>, <a href="/format/2311.18788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated interpretation of congenital heart disease from multi-view  echocardiograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Fangyun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+L">Lin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+F">Fengqiao Gao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hanwen Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+W">Wanqing Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Binbin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Medical Image Analysis
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Analysis (Volume 69, April 2021, 101942)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Congenital heart disease (CHD) is the most common birth defect and the
leading cause of neonate death in China. Clinical diagnosis can be based on the
selected 2D key-frames from five views. Limited by the availability of
multi-view data, most methods have to rely on the insufficient single view
analysis. This study proposes to automatically analyze the multi-view
echocardiograms with a practical end-to-end framework. We collect the five-view
echocardiograms video records of 1308 subjects (including normal controls,
ventricular septal defect (VSD) patients and atrial septal defect (ASD)
patients) with both disease labels and standard-view key-frame labels.
Depthwise separable convolution-based multi-channel networks are adopted to
largely reduce the network parameters. We also approach the imbalanced class
problem by augmenting the positive training samples. Our 2D key-frame model can
diagnose CHD or negative samples with an accuracy of 95.4\%, and in negative,
VSD or ASD classification with an accuracy of 92.3\%. To further alleviate the
work of key-frame selection in real-world implementation, we propose an
adaptive soft attention scheme to directly explore the raw video data. Four
kinds of neural aggregation methods are systematically investigated to fuse the
information of an arbitrary number of frames in a video. Moreover, with a view
detection module, the system can work without the view records. Our video-based
model can diagnose with an accuracy of 93.9\% (binary classification), and
92.1\% (3-class classification) in a collected 2D video testing set, which does
not need key-frame selection and view annotation in testing. The detailed
ablation study and the interpretability analysis are provided.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18797" title="Abstract">arXiv:2311.18797</a> (cross-list from math.CO) [<a href="/pdf/2311.18797" title="Download PDF">pdf</a>, <a href="/ps/2311.18797" title="Download PostScript">ps</a>, <a href="/format/2311.18797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3b5;$-Uniform Mixing in Discrete Quantum Walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhan%2C+H">Hanmeng Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We study whether a discrete quantum walk can get arbitrarily close to a state
whose Schur square is constant on all arcs, given that the walk starts with a
uniform superposition of the outgoing arcs of some vertex. We characterize this
phenomenon on non-bipartite graphs using the adjacency spectrum of the graph;
in particular, if this happens at every vertex, and the states we get
arbitrarily close to are constant on the outgoing arcs of the vertices, then
the adjacency algebra of the graph contains a real (regular) Hadamard matrix.
We then find infinite families of primitive strongly regular graphs that admit
this phenomenon.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri,  1 Dec 23</h3>
<dl>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1808.09401" title="Abstract">arXiv:1808.09401</a> (replaced) [<a href="/pdf/1808.09401" title="Download PDF">pdf</a>, <a href="/format/1808.09401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Information Extraction by Predicting Relative Time-lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leeuwenberg%2C+A">Artuur Leeuwenberg</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Conference on Empirical Methods in Natural Language Processing (EMNLP 2018). Small correction in Eq. 6 on 30 Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.12431" title="Abstract">arXiv:1910.12431</a> (replaced) [<a href="/pdf/1910.12431" title="Download PDF">pdf</a>, <a href="/format/1910.12431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Dimension-Independent Likelihood-Informed MCMC for  Large-Scale Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cui%2C+T">Tiangang Cui</a>, 
<a href="/search/stat?searchtype=author&query=Detommaso%2C+G">Gianluca Detommaso</a>, 
<a href="/search/stat?searchtype=author&query=Scheichl%2C+R">Robert Scheichl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.05794" title="Abstract">arXiv:2009.05794</a> (replaced) [<a href="/pdf/2009.05794" title="Download PDF">pdf</a>, <a href="/format/2009.05794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BARS-CTR: Open Benchmarking for Click-Through Rate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiuqiang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2021. See the benchmark at <a href="https://openbenchmark.github.io/BARS/CTR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.09213" title="Abstract">arXiv:2009.09213</a> (replaced) [<a href="/pdf/2009.09213" title="Download PDF">pdf</a>, <a href="/format/2009.09213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Juefei-Xu%2C+F">Felix Juefei-Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">Geguang Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.01502" title="Abstract">arXiv:2010.01502</a> (replaced) [<a href="/pdf/2010.01502" title="Download PDF">pdf</a>, <a href="/format/2010.01502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-turn Response Selection using Dialogue Dependency Relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Q">Qi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haifeng Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication as a long paper in EMNLP2020
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.15408" title="Abstract">arXiv:2012.15408</a> (replaced) [<a href="/pdf/2012.15408" title="Download PDF">pdf</a>, <a href="/ps/2012.15408" title="Download PostScript">ps</a>, <a href="/format/2012.15408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gated Ensemble of Spatio-temporal Mixture of Experts for Multi-task  Learning in Ride-hailing System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+H">M. H. Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Rifaat%2C+S+M">S. M. Rifaat</a>, 
<a href="/search/cs?searchtype=author&query=Sadeek%2C+S+N">S. N. Sadeek</a>, 
<a href="/search/cs?searchtype=author&query=Abrar%2C+M">M. Abrar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">D. Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2012.08868">arXiv:2012.08868</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.03808" title="Abstract">arXiv:2103.03808</a> (replaced) [<a href="/pdf/2103.03808" title="Download PDF">pdf</a>, <a href="/ps/2103.03808" title="Download PostScript">ps</a>, <a href="/format/2103.03808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-step reinforcement learning for model-free redesign of nonlinear  optimal regulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Minami%2C+M">Mei Minami</a>, 
<a href="/search/eess?searchtype=author&query=Masumoto%2C+Y">Yuka Masumoto</a>, 
<a href="/search/eess?searchtype=author&query=Okawa%2C+Y">Yoshihiro Okawa</a>, 
<a href="/search/eess?searchtype=author&query=Sasaki%2C+T">Tomotake Sasaki</a>, 
<a href="/search/eess?searchtype=author&query=Hori%2C+Y">Yutaka Hori</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SICE Journal of Control, Measurement, and System Integration, vol.
  16, no. 1, pp. 349--362, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.13245" title="Abstract">arXiv:2103.13245</a> (replaced) [<a href="/pdf/2103.13245" title="Download PDF">pdf</a>, <a href="/format/2103.13245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime informed path re-planning and optimization for robots in  changing environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonola%2C+C">Cesare Tonola</a>, 
<a href="/search/cs?searchtype=author&query=Faroni%2C+M">Marco Faroni</a>, 
<a href="/search/cs?searchtype=author&query=Pedrocchi%2C+N">Nicola Pedrocchi</a>, 
<a href="/search/cs?searchtype=author&query=Beschi%2C+M">Manuel Beschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.00599" title="Abstract">arXiv:2106.00599</a> (replaced) [<a href="/pdf/2106.00599" title="Download PDF">pdf</a>, <a href="/format/2106.00599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClustML: A Measure of Cluster Pattern Complexity in Scatterplots Learnt  from Human-labeled Groupings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbas%2C+M+M">Mostafa M. Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+E">Ehsan Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Baggag%2C+A">Abdelkader Baggag</a>, 
<a href="/search/cs?searchtype=author&query=Bensmail%2C+H">Halima Bensmail</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmair%2C+M">Michael Sedlmair</a>, 
<a href="/search/cs?searchtype=author&query=Aupetit%2C+M">Micha&#xeb;l Aupetit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13855" title="Abstract">arXiv:2108.13855</a> (replaced) [<a href="/pdf/2108.13855" title="Download PDF">pdf</a>, <a href="/ps/2108.13855" title="Download PostScript">ps</a>, <a href="/format/2108.13855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successful Recovery Performance Guarantees of SOMP Under the L2-norm of  Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taejoon Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.06296" title="Abstract">arXiv:2109.06296</a> (replaced) [<a href="/pdf/2109.06296" title="Download PDF">pdf</a>, <a href="/format/2109.06296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monocular Camera Localization for Automated Vehicles Using Image  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joa%2C+E">Eunhyek Joa</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yibo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Borrelli%2C+F">Francesco Borrelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.11369" title="Abstract">arXiv:2109.11369</a> (replaced) [<a href="/pdf/2109.11369" title="Download PDF">pdf</a>, <a href="/format/2109.11369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances of Continual Learning in Computer Vision: An Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Haoxuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hossein Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Li Xu</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B">Bryan Williams</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.12613" title="Abstract">arXiv:2109.12613</a> (replaced) [<a href="/pdf/2109.12613" title="Download PDF">pdf</a>, <a href="/format/2109.12613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimpleX: A Simple and Strong Baseline for Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Kelong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Quanyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenhua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiuqiang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2021. Code available at <a href="https://reczoo.github.io/SimpleX">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04996" title="Abstract">arXiv:2110.04996</a> (replaced) [<a href="/pdf/2110.04996" title="Download PDF">pdf</a>, <a href="/ps/2110.04996" title="Download PostScript">ps</a>, <a href="/format/2110.04996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Learning Criteria Going Beyond the Usual Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Holland%2C+M+J">Matthew J. Holland</a>, 
<a href="/search/stat?searchtype=author&query=Tanabe%2C+K">Kazuki Tanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version published in JAIR
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research, 78:781-821, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.15114" title="Abstract">arXiv:2110.15114</a> (replaced) [<a href="/pdf/2110.15114" title="Download PDF">pdf</a>, <a href="/format/2110.15114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraGCN: Ultra Simplification of Graph Convolutional Networks for  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Kelong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Biao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiuqiang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2021. Code available at: <a href="https://reczoo.github.io/UltraGCN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.12727" title="Abstract">arXiv:2111.12727</a> (replaced) [<a href="/pdf/2111.12727" title="Download PDF">pdf</a>, <a href="/format/2111.12727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating More Pertinent Captions by Leveraging Semantics and Style on  Multi-Source Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cornia%2C+M">Marcella Cornia</a>, 
<a href="/search/cs?searchtype=author&query=Baraldi%2C+L">Lorenzo Baraldi</a>, 
<a href="/search/cs?searchtype=author&query=Fiameni%2C+G">Giuseppe Fiameni</a>, 
<a href="/search/cs?searchtype=author&query=Cucchiara%2C+R">Rita Cucchiara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IJCV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.05128" title="Abstract">arXiv:2112.05128</a> (replaced) [<a href="/pdf/2112.05128" title="Download PDF">pdf</a>, <a href="/format/2112.05128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Community Detection and Structure Learning in Heterogeneous  Graphical Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tarzanagh%2C+D+A">Davoud Ataee Tarzanagh</a>, 
<a href="/search/stat?searchtype=author&query=Balzano%2C+L">Laura Balzano</a>, 
<a href="/search/stat?searchtype=author&query=Hero%2C+A+O">Alfred O. Hero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.03215" title="Abstract">arXiv:2201.03215</a> (replaced) [<a href="/pdf/2201.03215" title="Download PDF">pdf</a>, <a href="/ps/2201.03215" title="Download PostScript">ps</a>, <a href="/format/2201.03215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handwriting recognition and automatic scoring for descriptive answers in  Japanese language tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+T">Hung Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+T">Cuong Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Oka%2C+H">Haruki Oka</a>, 
<a href="/search/cs?searchtype=author&query=Ishioka%2C+T">Tsunenori Ishioka</a>, 
<a href="/search/cs?searchtype=author&query=Nakagawa%2C+M">Masaki Nakagawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: handwritten Japanese answers, handwriting recognition, automatic scoring, ensemble recognition, deep neural networks; Reported in IEICE technical report, PRMU2021-32, pp.45-50 (2021.12) Published after peer review and Presented in ICFHR2022, Lecture Notes in Computer Science, vol. 13639, pp. 274-284 (2022.11)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.14034" title="Abstract">arXiv:2202.14034</a> (replaced) [<a href="/pdf/2202.14034" title="Download PDF">pdf</a>, <a href="/format/2202.14034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Descent: Simulating Object-Centric Datasets on the Content  Level and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yue Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Napthade%2C+M">Milind Napthade</a>, 
<a href="/search/cs?searchtype=author&query=Gedeon%2C+T">Tom Gedeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, Accepted to IEEE Trans on PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.03416" title="Abstract">arXiv:2204.03416</a> (replaced) [<a href="/pdf/2204.03416" title="Download PDF">pdf</a>, <a href="/ps/2204.03416" title="Download PostScript">ps</a>, <a href="/format/2204.03416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A CCBM-based generalized GKB iterative regularization algorithm for  inverse Cauchy problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gong%2C+R">Rongfang Gong</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+M">Min Wang</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+Q">Qin Huang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Ye Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational and Applied Mathematics, 432 (2023),
  115282
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08728" title="Abstract">arXiv:2205.08728</a> (replaced) [<a href="/pdf/2205.08728" title="Download PDF">pdf</a>, <a href="/format/2205.08728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RandoMix: A mixed sample data augmentation method with multiple mixed  modes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Furao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+C">Changhai Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06214" title="Abstract">arXiv:2206.06214</a> (replaced) [<a href="/pdf/2206.06214" title="Download PDF">pdf</a>, <a href="/format/2206.06214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-World Light Field Image Super-Resolution via Degradation Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhengyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jungang Yang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+W">Wei An</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yulan Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10234" title="Abstract">arXiv:2206.10234</a> (replaced) [<a href="/pdf/2206.10234" title="Download PDF">pdf</a>, <a href="/format/2206.10234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Many-Worlds Calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chardonnet%2C+K">Kostia Chardonnet</a>, 
<a href="/search/cs?searchtype=author&query=de+Visme%2C+M">Marc de Visme</a>, 
<a href="/search/cs?searchtype=author&query=Valiron%2C+B">Beno&#xee;t Valiron</a>, 
<a href="/search/cs?searchtype=author&query=Vilmart%2C+R">Renaud Vilmart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06799" title="Abstract">arXiv:2207.06799</a> (replaced) [<a href="/pdf/2207.06799" title="Download PDF">pdf</a>, <a href="/format/2207.06799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMOTU: A Multi-Modality Ovarian Tumor Ultrasound Image Dataset for  Unsupervised Cross-Domain Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shuchang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Wenpei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Linghan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Binghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangliang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Meijing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+X">Xiubo Sang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lijiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code: <a href="https://github.com/cv516Buaa/MMOTU_DS2Net">this https URL</a> paper:18 pages, 12 figures, 11 tables, 16 formulas
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04180" title="Abstract">arXiv:2208.04180</a> (replaced) [<a href="/pdf/2208.04180" title="Download PDF">pdf</a>, <a href="/ps/2208.04180" title="Download PostScript">ps</a>, <a href="/format/2208.04180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSO Queries on Trees: Enumerating Answers under Updates Using Forest  Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kleest-Mei%C3%9Fner%2C+S">Sarah Kleest-Mei&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Marasus%2C+J">Jonas Marasus</a>, 
<a href="/search/cs?searchtype=author&query=Niewerth%2C+M">Matthias Niewerth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05507" title="Abstract">arXiv:2208.05507</a> (replaced) [<a href="/pdf/2208.05507" title="Download PDF">pdf</a>, <a href="/format/2208.05507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compositional Approach to Verifying Modular Robotic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luckcuck%2C+M">Matt Luckcuck</a>, 
<a href="/search/cs?searchtype=author&query=Farrell%2C+M">Marie Farrell</a>, 
<a href="/search/cs?searchtype=author&query=Ferrando%2C+A">Angelo Ferrando</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+R+C">Rafael C. Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+L+A">Louise A. Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+M">Michael Fisher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version submitted to RAS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07711" title="Abstract">arXiv:2208.07711</a> (replaced) [<a href="/pdf/2208.07711" title="Download PDF">pdf</a>, <a href="/format/2208.07711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Low-light Image Enhancement via Region-Aware Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shihurong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yizhan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11377" title="Abstract">arXiv:2208.11377</a> (replaced) [<a href="/pdf/2208.11377" title="Download PDF">pdf</a>, <a href="/format/2208.11377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The END: Estimation Network Design for games under partial-decision  information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bianchi%2C+M">Mattia Bianchi</a>, 
<a href="/search/math?searchtype=author&query=Grammatico%2C+S">Sergio Grammatico</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02973" title="Abstract">arXiv:2209.02973</a> (replaced) [<a href="/pdf/2209.02973" title="Download PDF">pdf</a>, <a href="/format/2209.02973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations of probability-raising causality in Markov decision  processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baier%2C+C">Christel Baier</a>, 
<a href="/search/cs?searchtype=author&query=Piribauer%2C+J">Jakob Piribauer</a>, 
<a href="/search/cs?searchtype=author&query=Ziemek%2C+R">Robin Ziemek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission for Logical Methods in Computer Science (special issue FoSSaCS 2022). arXiv admin note: substantial text overlap with <a href="/abs/2201.08768">arXiv:2201.08768</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03077" title="Abstract">arXiv:2209.03077</a> (replaced) [<a href="/pdf/2209.03077" title="Download PDF">pdf</a>, <a href="/ps/2209.03077" title="Download PostScript">ps</a>, <a href="/format/2209.03077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of the ELBO to Entropy Sums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=L%C3%BCcke%2C+J">J&#xf6;rg L&#xfc;cke</a>, 
<a href="/search/stat?searchtype=author&query=Warnken%2C+J">Jan Warnken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09207" title="Abstract">arXiv:2209.09207</a> (replaced) [<a href="/pdf/2209.09207" title="Download PDF">pdf</a>, <a href="/format/2209.09207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Table Detection in the Wild: A Novel Diverse Table Detection Dataset and  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haloi%2C+M">Mrinal Haloi</a>, 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+S">Shashank Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=Fande%2C+N">Nikhil Fande</a>, 
<a href="/search/cs?searchtype=author&query=Dash%2C+S+S">Siddhant Swaroop Dash</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+S">Sanjay G</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Open source Table detection dataset and baseline results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14278" title="Abstract">arXiv:2209.14278</a> (replaced) [<a href="/pdf/2209.14278" title="Download PDF">pdf</a>, <a href="/format/2209.14278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Phase Processing and its Applications in Estimating Phase and  Entropies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Youle Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yu%2C+Z">Zhan Yu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages including appendix, v3 is close to the published version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03628" title="Abstract">arXiv:2210.03628</a> (replaced) [<a href="/pdf/2210.03628" title="Download PDF">pdf</a>, <a href="/format/2210.03628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraspCaps: A Capsule Network Approach for Familiar 6DoF Object Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Velde%2C+T">Tomas van der Velde</a>, 
<a href="/search/cs?searchtype=author&query=Ayoobi%2C+H">Hamed Ayoobi</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+H">Hamidreza Kasaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to CVPR 2023, Supplementary video: <a href="https://youtu.be/d13rEhKgApI?si=EhgbDI84nlXL5V2M">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04020" title="Abstract">arXiv:2210.04020</a> (replaced) [<a href="/pdf/2210.04020" title="Download PDF">pdf</a>, <a href="/format/2210.04020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast-ParC: Capturing Position Aware Global Feature for ConvNets and ViTs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haokui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenze Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, 10 tables. A preliminary version of this paper has been published in ECCV 2022 and it can be find in <a href="/abs/2203.03952">arXiv:2203.03952</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06186" title="Abstract">arXiv:2210.06186</a> (replaced) [<a href="/pdf/2210.06186" title="Download PDF">pdf</a>, <a href="/format/2210.06186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gotcha: Real-Time Video Deepfake Detection via Challenge-Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+G">Govind Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+C">Chinmay Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Memon%2C+N">Nasir Memon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data to be released by the end of 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01858" title="Abstract">arXiv:2211.01858</a> (replaced) [<a href="/pdf/2211.01858" title="Download PDF">pdf</a>, <a href="/format/2211.01858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relating graph auto-encoders to linear models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klepper%2C+S">Solveig Klepper</a>, 
<a href="/search/cs?searchtype=author&query=von+Luxburg%2C+U">Ulrike von Luxburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06841" title="Abstract">arXiv:2211.06841</a> (replaced) [<a href="/pdf/2211.06841" title="Download PDF">pdf</a>, <a href="/format/2211.06841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-DAE: Denoising Autoencoders for Self-supervised Point Cloud  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yabin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruihuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The codes are available at \url{<a href="https://github.com/YBZh/Point-DAE">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09512" title="Abstract">arXiv:2211.09512</a> (replaced) [<a href="/pdf/2211.09512" title="Download PDF">pdf</a>, <a href="/format/2211.09512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Koopman-Based Models for Holistic Controller and Observer  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Junker%2C+A">Annika Junker</a>, 
<a href="/search/math?searchtype=author&query=Pape%2C+K">Keno Pape</a>, 
<a href="/search/math?searchtype=author&query=Timmermann%2C+J">Julia Timmermann</a>, 
<a href="/search/math?searchtype=author&query=Tr%C3%A4chtler%2C+A">Ansgar Tr&#xe4;chtler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for: 3rd Modeling, Estimation and Control Conference (MECC 2023) \c{opyright} 2023 the authors. This work has been accepted to IFAC for publication under a Creative Commons Licence CC-BY-NC-ND
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11293" title="Abstract">arXiv:2211.11293</a> (replaced) [<a href="/pdf/2211.11293" title="Download PDF">pdf</a>, <a href="/format/2211.11293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Field-of-View: Enhancing Scene Visibility and Perception with  Clip-Recurrent Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoting Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Huajian Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code and dataset are made publicly available at <a href="https://github.com/MasterHow/FlowLens">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13316" title="Abstract">arXiv:2211.13316</a> (replaced) [<a href="/pdf/2211.13316" title="Download PDF">pdf</a>, <a href="/format/2211.13316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Sample Generation Strategies for Learning Heuristic  Functions in Classical Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bettker%2C+R+V">R. V. Bettker</a>, 
<a href="/search/cs?searchtype=author&query=Minini%2C+P+P">P. P. Minini</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+A+G">A. G. Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Ritt%2C+M">M. Ritt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10696" title="Abstract">arXiv:2212.10696</a> (replaced) [<a href="/pdf/2212.10696" title="Download PDF">pdf</a>, <a href="/format/2212.10696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Semantic Faithfulness of Language Models via Input  Intervention on Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaturvedi%2C+A">Akshay Chaturvedi</a>, 
<a href="/search/cs?searchtype=author&query=Bhar%2C+S">Swarnadeep Bhar</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Soumadeep Saha</a>, 
<a href="/search/cs?searchtype=author&query=Garain%2C+U">Utpal Garain</a>, 
<a href="/search/cs?searchtype=author&query=Asher%2C+N">Nicholas Asher</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computational Linguistics (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12993" title="Abstract">arXiv:2301.12993</a> (replaced) [<a href="/pdf/2301.12993" title="Download PDF">pdf</a>, <a href="/format/2301.12993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Robustness to Adversarial Image Obfuscations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stimberg%2C+F">Florian Stimberg</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+A">Ayan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chun-Ta Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hazimeh%2C+H">Hussein Hazimeh</a>, 
<a href="/search/cs?searchtype=author&query=Stretcu%2C+O">Otilia Stretcu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+W">Wei Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yintao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kaya%2C+M">Merve Kaya</a>, 
<a href="/search/cs?searchtype=author&query=Rashtchian%2C+C">Cyrus Rashtchian</a>, 
<a href="/search/cs?searchtype=author&query=Fuxman%2C+A">Ariel Fuxman</a>, 
<a href="/search/cs?searchtype=author&query=Tek%2C+M">Mehmet Tek</a>, 
<a href="/search/cs?searchtype=author&query=Gowal%2C+S">Sven Gowal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01235" title="Abstract">arXiv:2302.01235</a> (replaced) [<a href="/pdf/2302.01235" title="Download PDF">pdf</a>, <a href="/ps/2302.01235" title="Download PostScript">ps</a>, <a href="/format/2302.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Printing Protocol: Physical ZKPs for Decomposition Puzzles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruangwises%2C+S">Suthee Ruangwises</a>, 
<a href="/search/cs?searchtype=author&query=Iwamoto%2C+M">Mitsugu Iwamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this paper has appeared at LATINCRYPT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05633" title="Abstract">arXiv:2302.05633</a> (replaced) [<a href="/pdf/2302.05633" title="Download PDF">pdf</a>, <a href="/ps/2302.05633" title="Download PostScript">ps</a>, <a href="/format/2302.05633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Competitive Ratio for Edge-Weighted Online Stochastic Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yilong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">Guoliang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaowei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shengwei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in WINE2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08893" title="Abstract">arXiv:2302.08893</a> (replaced) [<a href="/pdf/2302.08893" title="Download PDF">pdf</a>, <a href="/format/2302.08893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active learning for data streams: a survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cacciarelli%2C+D">Davide Cacciarelli</a>, 
<a href="/search/stat?searchtype=author&query=Kulahci%2C+M">Murat Kulahci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Machine Learning (2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning (2023): 1-55
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09270" title="Abstract">arXiv:2302.09270</a> (replaced) [<a href="/pdf/2302.09270" title="Download PDF">pdf</a>, <a href="/format/2302.09270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safer Generative Language Models: A Survey on Safety Risks,  Evaluations, and Improvements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiawen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhexin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10414" title="Abstract">arXiv:2302.10414</a> (replaced) [<a href="/pdf/2302.10414" title="Download PDF">pdf</a>, <a href="/format/2302.10414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Scene Text Image Super-resolution via Dual Prior Modulation  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zuoyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+P">Pengfei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hui Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10886" title="Abstract">arXiv:2302.10886</a> (replaced) [<a href="/pdf/2302.10886" title="Download PDF">pdf</a>, <a href="/format/2302.10886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Intriguing Aspects about Lipschitz Continuity of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khromov%2C+G">Grigory Khromov</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Sidak Pal Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14336" title="Abstract">arXiv:2302.14336</a> (replaced) [<a href="/pdf/2302.14336" title="Download PDF">pdf</a>, <a href="/format/2302.14336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming and Device Selection Design in Federated Learning with  Over-the-air Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalarde%2C+F+M">Faeze Moradi Kalarde</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Min Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Ben Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Y+A+E">Yahia A. Eldemerdash Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H+T">Ho Ting Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00566" title="Abstract">arXiv:2303.00566</a> (replaced) [<a href="/pdf/2303.00566" title="Download PDF">pdf</a>, <a href="/format/2303.00566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Pruning for Deep Convolutional Neural Networks: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yang He</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lingao Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01681" title="Abstract">arXiv:2303.01681</a> (replaced) [<a href="/pdf/2303.01681" title="Download PDF">pdf</a>, <a href="/format/2303.01681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Pixel-to-Pixel Harmonization via Continuous Image Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yilan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01923" title="Abstract">arXiv:2303.01923</a> (replaced) [<a href="/pdf/2303.01923" title="Download PDF">pdf</a>, <a href="/format/2303.01923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian CART models for insurance claims frequency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Y">Yaojun Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Ji%2C+L">Lanpeng Ji</a>, 
<a href="/search/stat?searchtype=author&query=Aivaliotis%2C+G">Georgios Aivaliotis</a>, 
<a href="/search/stat?searchtype=author&query=Taylor%2C+C">Charles Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistical Finance (q-fin.ST); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04955" title="Abstract">arXiv:2303.04955</a> (replaced) [<a href="/pdf/2303.04955" title="Download PDF">pdf</a>, <a href="/format/2303.04955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Smart Commercial Building Occupants&#x27; Perceptions and  Notification Preferences of Internet of Things Data Collection in the United  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Tu Le</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Alan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yaxing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuanyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Heydarian%2C+A">Arsalan Heydarian</a>, 
<a href="/search/cs?searchtype=author&query=Sadeh%2C+N">Norman Sadeh</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EuroS&amp;P 2023 camera ready
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 8th European Symposium on Security and Privacy (EuroS&amp;P)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08314" title="Abstract">arXiv:2303.08314</a> (replaced) [<a href="/pdf/2303.08314" title="Download PDF">pdf</a>, <a href="/format/2303.08314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Slot Attention for Unsupervised Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minhyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Suhwan Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dogyoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chaewon Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyoun Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12001" title="Abstract">arXiv:2303.12001</a> (replaced) [<a href="/pdf/2303.12001" title="Download PDF">pdf</a>, <a href="/format/2303.12001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViC-MAE: Self-Supervised Representation Learning from Images and Video  with Contrastive Masked Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+J">Jefferson Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Villegas%2C+R">Ruben Villegas</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+V">Vicente Ordonez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More results on Video an Image datasets, ViC-MAE now supports training on videos and images
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00096" title="Abstract">arXiv:2304.00096</a> (replaced) [<a href="/pdf/2304.00096" title="Download PDF">pdf</a>, <a href="/format/2304.00096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Price of Transparency: A Comparison between Overt Persuasion and  Covert Signaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted to CDC23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00902" title="Abstract">arXiv:2304.00902</a> (replaced) [<a href="/pdf/2304.00902" title="Download PDF">pdf</a>, <a href="/format/2304.00902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Kelong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Liangcai Su</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guohao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuru Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenhua Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2023. Code available at <a href="https://reczoo.github.io/FinalMLP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00916" title="Abstract">arXiv:2304.00916</a> (replaced) [<a href="/pdf/2304.00916" title="Download PDF">pdf</a>, <a href="/format/2304.00916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yukang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K">Kwan-Yee K. Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yukangcao.github.io/DreamAvatar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00962" title="Abstract">arXiv:2304.00962</a> (replaced) [<a href="/pdf/2304.00962" title="Download PDF">pdf</a>, <a href="/format/2304.00962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RegionPLC: Regional Point-Language Contrastive Learning for Open-World  3D Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jihan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Runyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weipeng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://jihanyang.github.io/projects/RegionPLC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01041" title="Abstract">arXiv:2304.01041</a> (replaced) [<a href="/pdf/2304.01041" title="Download PDF">pdf</a>, <a href="/format/2304.01041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Behavior Planning and Motion Control for Autonomous Vehicles  with Traffic Rules Compliance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haichao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yulin Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenmin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jianghua Duan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, accepted for publication in The 2023 IEEE International Conference on Robotics and Biomimetics (ROBIO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03492" title="Abstract">arXiv:2304.03492</a> (replaced) [<a href="/pdf/2304.03492" title="Download PDF">pdf</a>, <a href="/format/2304.03492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClothCombo: Modeling Inter-Cloth Interaction for Draping Multi-Layered  Clothes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dohae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">In-Kwon Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09976" title="Abstract">arXiv:2304.09976</a> (replaced) [<a href="/pdf/2304.09976" title="Download PDF">pdf</a>, <a href="/format/2304.09976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Domain Shift Immunity of Deep Homography Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingzhen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Tasdizen%2C+T">Tolga Tasdizen</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sarang Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09991" title="Abstract">arXiv:2304.09991</a> (replaced) [<a href="/pdf/2304.09991" title="Download PDF">pdf</a>, <a href="/format/2304.09991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supporting Human-AI Collaboration in Auditing LLMs with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Charvi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+M+T">Marco Tulio Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+N">Nicholas King</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+H">Harsha Nori</a>, 
<a href="/search/cs?searchtype=author&query=Amershi%2C+S">Saleema Amershi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 2023 AAAI and ACM Conference on AI, Ethics,
  and Society. Association for Computing Machinery, New York, NY, USA, 913-926
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10253" title="Abstract">arXiv:2304.10253</a> (replaced) [<a href="/pdf/2304.10253" title="Download PDF">pdf</a>, <a href="/format/2304.10253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image retrieval outperforms diffusion models on data augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burg%2C+M+F">Max F. Burg</a>, 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+F">Florian Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Zietlow%2C+D">Dominik Zietlow</a>, 
<a href="/search/cs?searchtype=author&query=Horn%2C+M">Max Horn</a>, 
<a href="/search/cs?searchtype=author&query=Makansi%2C+O">Osama Makansi</a>, 
<a href="/search/cs?searchtype=author&query=Locatello%2C+F">Francesco Locatello</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+C">Chris Russell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10864" title="Abstract">arXiv:2304.10864</a> (replaced) [<a href="/pdf/2304.10864" title="Download PDF">pdf</a>, <a href="/format/2304.10864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreMIM: Fourier Transform Meets Masked Image Modeling for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbo Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuanxiu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shanshan Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangyun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10880" title="Abstract">arXiv:2304.10880</a> (replaced) [<a href="/pdf/2304.10880" title="Download PDF">pdf</a>, <a href="/format/2304.10880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Med-Tuning: Parameter-Efficient Transfer Learning with Fine-Grained  Feature Enhancement for Medical Volumetric Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiachen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbo Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shanshan Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangyun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00162" title="Abstract">arXiv:2305.00162</a> (replaced) [<a href="/pdf/2305.00162" title="Download PDF">pdf</a>, <a href="/format/2305.00162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Prediction: On-street Parking Recommendation using Heterogeneous  Graph-based List-wise Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hanyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02381" title="Abstract">arXiv:2305.02381</a> (replaced) [<a href="/pdf/2305.02381" title="Download PDF">pdf</a>, <a href="/format/2305.02381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Communication Pattern Shifts in Large-Scale Labeled Networks  using Encoder Embedding and Vertex Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cencheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+J">Jonathan Larson</a>, 
<a href="/search/cs?searchtype=author&query=Trinh%2C+H">Ha Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xihan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Youngser Park</a>, 
<a href="/search/cs?searchtype=author&query=Priebe%2C+C+E">Carey E. Priebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + 2 pages appendix, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03972" title="Abstract">arXiv:2305.03972</a> (replaced) [<a href="/pdf/2305.03972" title="Download PDF">pdf</a>, <a href="/format/2305.03972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image to Multi-Modal Retrieval for Industrial Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zida Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+C">Chen Ju</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Z">Zhonghua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shuai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaoyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weilin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04082" title="Abstract">arXiv:2305.04082</a> (replaced) [<a href="/pdf/2305.04082" title="Download PDF">pdf</a>, <a href="/format/2305.04082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Minimal Approach for Natural Language Action Space in Text-based Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryu%2C+D+K">Dongwon Kelvin Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>, 
<a href="/search/cs?searchtype=author&query=Shareghi%2C+E">Ehsan Shareghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05411" title="Abstract">arXiv:2305.05411</a> (replaced) [<a href="/pdf/2305.05411" title="Download PDF">pdf</a>, <a href="/ps/2305.05411" title="Download PostScript">ps</a>, <a href="/format/2305.05411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4/3-Approximation of Graphic TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87ivril%2C+A">Ali &#xc7;ivril</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, further corrections and simplification of the analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06988" title="Abstract">arXiv:2305.06988</a> (replaced) [<a href="/pdf/2305.06988" title="Download PDF">pdf</a>, <a href="/format/2305.06988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Chained Image-Language Model for Video Localization and Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shoubin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaemin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Prateek Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; Our code and checkpoints are available at: <a href="https://github.com/Yui010206/SeViLA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08192" title="Abstract">arXiv:2305.08192</a> (replaced) [<a href="/pdf/2305.08192" title="Download PDF">pdf</a>, <a href="/format/2305.08192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Imperceptible and Transferable Adversarial Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yilan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code Page: <a href="https://github.com/WindVChen/DiffAttack.">this https URL</a> In Paper Version v2, we incorporate more discussions and experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09049" title="Abstract">arXiv:2305.09049</a> (replaced) [<a href="/pdf/2305.09049" title="Download PDF">pdf</a>, <a href="/ps/2305.09049" title="Download PostScript">ps</a>, <a href="/format/2305.09049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsifying sums of norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jambulapati%2C+A">Arun Jambulapati</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+R">James R. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11164" title="Abstract">arXiv:2305.11164</a> (replaced) [<a href="/pdf/2305.11164" title="Download PDF">pdf</a>, <a href="/format/2305.11164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Carbon Footprint of Hugging Face&#x27;s ML Models: A Repository  Mining Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casta%C3%B1o%2C+J">Joel Casta&#xf1;o</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Fern%C3%A1ndez%2C+S">Silverio Mart&#xed;nez-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Franch%2C+X">Xavier Franch</a>, 
<a href="/search/cs?searchtype=author&query=Bogner%2C+J">Justus Bogner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 ACM/IEEE International Symposium on Empirical Software
  Engineering and Measurement (ESEM) (2023) 260-271
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13172" title="Abstract">arXiv:2305.13172</a> (replaced) [<a href="/pdf/2305.13172" title="Download PDF">pdf</a>, <a href="/format/2305.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing Large Language Models: Problems, Methods, and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoubo Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023. Updated with new experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13236" title="Abstract">arXiv:2305.13236</a> (replaced) [<a href="/pdf/2305.13236" title="Download PDF">pdf</a>, <a href="/format/2305.13236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADA-GP: Accelerating DNN Training By Adaptive Gradient Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janfaza%2C+V">Vahid Janfaza</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+S">Shantanu Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+F">Farabi Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Muzahid%2C+A">Abdullah Muzahid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 21 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14595" title="Abstract">arXiv:2305.14595</a> (replaced) [<a href="/pdf/2305.14595" title="Download PDF">pdf</a>, <a href="/format/2305.14595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operationalizing Counterfactual Metrics: Incentives, Ranking, and  Information Asymmetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Serena Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bates%2C+S">Stephen Bates</a>, 
<a href="/search/cs?searchtype=author&query=Aronow%2C+P+M">P. M. Aronow</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14993" title="Abstract">arXiv:2305.14993</a> (replaced) [<a href="/pdf/2305.14993" title="Download PDF">pdf</a>, <a href="/format/2305.14993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Pre-trained Language Models for Grade-Specific Text  Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Sweta Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Carpuat%2C+M">Marine Carpuat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15613" title="Abstract">arXiv:2305.15613</a> (replaced) [<a href="/pdf/2305.15613" title="Download PDF">pdf</a>, <a href="/format/2305.15613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Deep O($n$)-Equivariant Hyperspheres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+P">Pavlo Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+A">Andreas Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cuong Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16526" title="Abstract">arXiv:2305.16526</a> (replaced) [<a href="/pdf/2305.16526" title="Download PDF">pdf</a>, <a href="/format/2305.16526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Explainable Boosting Machines to Scientific Image Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schug%2C+D">Daniel Schug</a>, 
<a href="/search/cs?searchtype=author&query=Yerramreddy%2C+S">Sai Yerramreddy</a>, 
<a href="/search/cs?searchtype=author&query=Caruana%2C+R">Rich Caruana</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+C">Craig Greenberg</a>, 
<a href="/search/cs?searchtype=author&query=Zwolak%2C+J+P">Justyna P. Zwolak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Machine Learning and the Physical Sciences
  Workshop at NeurIPS 2023, New Orleans, LA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Quantum Gases (cond-mat.quant-gas); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17644" title="Abstract">arXiv:2305.17644</a> (replaced) [<a href="/pdf/2305.17644" title="Download PDF">pdf</a>, <a href="/format/2305.17644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Caterpillar: A Pure-MLP Architecture with Shifted-Pillars-Concatenation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoshuang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18498" title="Abstract">arXiv:2305.18498</a> (replaced) [<a href="/pdf/2305.18498" title="Download PDF">pdf</a>, <a href="/format/2305.18498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ANPL: Towards Natural Programming with Interactive Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+Z">Ziyuan Nan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Pengwei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuanbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yewen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18647" title="Abstract">arXiv:2305.18647</a> (replaced) [<a href="/pdf/2305.18647" title="Download PDF">pdf</a>, <a href="/ps/2305.18647" title="Download PostScript">ps</a>, <a href="/format/2305.18647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Alternate Proof of Near-Optimal Light Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SOSA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19007" title="Abstract">arXiv:2305.19007</a> (replaced) [<a href="/pdf/2305.19007" title="Download PDF">pdf</a>, <a href="/format/2305.19007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training a HyperDimensional Computing Classifier using a Threshold on  its Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smets%2C+L">Laura Smets</a>, 
<a href="/search/cs?searchtype=author&query=Van+Leekwijck%2C+W">Werner Van Leekwijck</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+J">Ing Jyh Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Latre%2C+S">Steven Latre</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Computation, 35(12), 2006-2023 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19480" title="Abstract">arXiv:2305.19480</a> (replaced) [<a href="/pdf/2305.19480" title="Download PDF">pdf</a>, <a href="/format/2305.19480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning by Aligning 2D Skeleton Sequences in Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q">Quoc-Huy Tran</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Muhammad Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Popattia%2C+M">Murad Popattia</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+H">M. Hassan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Konin%2C+A">Andrey Konin</a>, 
<a href="/search/cs?searchtype=author&query=Zia%2C+M+Z">M. Zeeshan Zia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.20082" title="Abstract">arXiv:2305.20082</a> (replaced) [<a href="/pdf/2305.20082" title="Download PDF">pdf</a>, <a href="/format/2305.20082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control4D: Efficient 4D Portrait Editing with Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Ruizhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zerong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Boyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The link to our project website is <a href="https://control4darxiv.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00210" title="Abstract">arXiv:2306.00210</a> (replaced) [<a href="/pdf/2306.00210" title="Download PDF">pdf</a>, <a href="/format/2306.00210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PERFOGRAPH: A Numerical Aware Program Graph Representation for  Performance Optimization and Program Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=TehraniJamsaz%2C+A">Ali TehraniJamsaz</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+Q+I">Quazi Ishtiaque Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00519" title="Abstract">arXiv:2306.00519</a> (replaced) [<a href="/pdf/2306.00519" title="Download PDF">pdf</a>, <a href="/format/2306.00519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+X">Xiaoliang Ju</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated: new work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00973" title="Abstract">arXiv:2306.00973</a> (replaced) [<a href="/pdf/2306.00973" title="Download PDF">pdf</a>, <a href="/format/2306.00973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yujie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://haoningwu3639.github.io/StoryGen_Webpage/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00974" title="Abstract">arXiv:2306.00974</a> (replaced) [<a href="/pdf/2306.00974" title="Download PDF">pdf</a>, <a href="/format/2306.00974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Failure Modes of Text-guided Diffusion Models via  Adversarial Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yutong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Song Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://sage-diffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01286" title="Abstract">arXiv:2306.01286</a> (replaced) [<a href="/pdf/2306.01286" title="Download PDF">pdf</a>, <a href="/format/2306.01286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KL-Divergence Guided Temperature Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chung-Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=Reitter%2C+D">David Reitter</a>, 
<a href="/search/cs?searchtype=author&query=Aksitov%2C+R">Renat Aksitov</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+Y">Yun-Hsuan Sung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02582" title="Abstract">arXiv:2306.02582</a> (replaced) [<a href="/pdf/2306.02582" title="Download PDF">pdf</a>, <a href="/format/2306.02582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Point Annotations with Superpixel and Confidence Learning  Guided for Improving Semi-Supervised OCT Fluid Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Tengjin Weng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K">Kai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gewen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission to BSPC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04541" title="Abstract">arXiv:2306.04541</a> (replaced) [<a href="/pdf/2306.04541" title="Download PDF">pdf</a>, <a href="/ps/2306.04541" title="Download PostScript">ps</a>, <a href="/format/2306.04541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-Down Knowledge Compilation for Counting Modulo Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derkinderen%2C+V">Vincent Derkinderen</a>, 
<a href="/search/cs?searchtype=author&query=Martires%2C+P+Z+D">Pedro Zuidberg Dos Martires</a>, 
<a href="/search/cs?searchtype=author&query=Kolb%2C+S">Samuel Kolb</a>, 
<a href="/search/cs?searchtype=author&query=Morettin%2C+P">Paolo Morettin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages; submitted to Workshop on Counting and Sampling 2023 at SAT2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05846" title="Abstract">arXiv:2306.05846</a> (replaced) [<a href="/pdf/2306.05846" title="Download PDF">pdf</a>, <a href="/format/2306.05846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-DVAE: Unsupervised learning for fast human motion denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiche%2C+G">Gu&#xe9;nol&#xe9; Fiche</a>, 
<a href="/search/cs?searchtype=author&query=Leglaive%2C+S">Simon Leglaive</a>, 
<a href="/search/cs?searchtype=author&query=Alameda-Pineda%2C+X">Xavier Alameda-Pineda</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A9guier%2C+R">Renaud S&#xe9;guier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07266" title="Abstract">arXiv:2306.07266</a> (replaced) [<a href="/pdf/2306.07266" title="Download PDF">pdf</a>, <a href="/format/2306.07266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operator Learning with Neural Fields: Tackling PDEs on General  Geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serrano%2C+L">Louis Serrano</a>, 
<a href="/search/cs?searchtype=author&query=Boudec%2C+L+L">Lise Le Boudec</a>, 
<a href="/search/cs?searchtype=author&query=Koupa%C3%AF%2C+A+K">Armand Kassa&#xef; Koupa&#xef;</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T+X">Thomas X Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Vittaut%2C+J">Jean-No&#xeb;l Vittaut</a>, 
<a href="/search/cs?searchtype=author&query=Gallinari%2C+P">Patrick Gallinari</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07384" title="Abstract">arXiv:2306.07384</a> (replaced) [<a href="/pdf/2306.07384" title="Download PDF">pdf</a>, <a href="/format/2306.07384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing Quantifier Comprehension in Large Language Models: Another  Example of Inverse Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshat Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BlackboxNLP (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07404" title="Abstract">arXiv:2306.07404</a> (replaced) [<a href="/pdf/2306.07404" title="Download PDF">pdf</a>, <a href="/format/2306.07404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositor: Bottom-up Clustering and Compositing for Robust Part and  Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Ju He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieneng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming-Xian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qihang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08018" title="Abstract">arXiv:2306.08018</a> (replaced) [<a href="/pdf/2306.08018" title="Download PDF">pdf</a>, <a href="/format/2306.08018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liang%2C+X">Xiaozhuan Liang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+K">Kangwei Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+R">Rui Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Fan%2C+X">Xiaohui Fan</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project homepage: <a href="https://github.com/zjunlp/Mol-Instructions">this https URL</a>, add more experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08266" title="Abstract">arXiv:2306.08266</a> (replaced) [<a href="/pdf/2306.08266" title="Download PDF">pdf</a>, <a href="/format/2306.08266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Robustness of Angluin&#x27;s L$^*$ Algorithm in Presence of Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Lina Ye</a>, 
<a href="/search/cs?searchtype=author&query=Khmelnitsky%2C+I">Igor Khmelnitsky</a>, 
<a href="/search/cs?searchtype=author&query=Haddad%2C+S">Serge Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Barbot%2C+B">Beno&#xee;t Barbot</a>, 
<a href="/search/cs?searchtype=author&query=Bollig%2C+B">Benedikt Bollig</a>, 
<a href="/search/cs?searchtype=author&query=Leucker%2C+M">Martin Leucker</a>, 
<a href="/search/cs?searchtype=author&query=Neider%2C+D">Daniel Neider</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R">Rajarshi Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages. arXiv admin note: substantial text overlap with <a href="/abs/2209.10315">arXiv:2209.10315</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08808" title="Abstract">arXiv:2306.08808</a> (replaced) [<a href="/pdf/2306.08808" title="Download PDF">pdf</a>, <a href="/format/2306.08808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLoop2: Building Self-Adaptive Recommendation Models via Responsive  Error Compensation Loop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guohao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenhua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10012" title="Abstract">arXiv:2306.10012</a> (replaced) [<a href="/pdf/2306.10012" title="Download PDF">pdf</a>, <a href="/format/2306.10012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+L">Lingbo Mo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; Website: <a href="https://osu-nlp-group.github.io/MagicBrush/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12230" title="Abstract">arXiv:2306.12230</a> (replaced) [<a href="/pdf/2306.12230" title="Download PDF">pdf</a>, <a href="/format/2306.12230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nowak%2C+A+I">Aleksandra I. Nowak</a>, 
<a href="/search/cs?searchtype=author&query=Grooten%2C+B">Bram Grooten</a>, 
<a href="/search/cs?searchtype=author&query=Mocanu%2C+D+C">Decebal Constantin Mocanu</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13545" title="Abstract">arXiv:2306.13545</a> (replaced) [<a href="/pdf/2306.13545" title="Download PDF">pdf</a>, <a href="/format/2306.13545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of 2D Stokes flows via lightning and AAA rational  approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xue%2C+Y">Yidan Xue</a>, 
<a href="/search/math?searchtype=author&query=Waters%2C+S+L">Sarah L. Waters</a>, 
<a href="/search/math?searchtype=author&query=Trefethen%2C+L+N">Lloyd N. Trefethen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14875" title="Abstract">arXiv:2306.14875</a> (replaced) [<a href="/pdf/2306.14875" title="Download PDF">pdf</a>, <a href="/format/2306.14875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fully Unsupervised Instance Segmentation Technique for White Blood  Cell Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Biswas%2C+S">Shrijeet Biswas</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+A">Amartya Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15220" title="Abstract">arXiv:2306.15220</a> (replaced) [<a href="/pdf/2306.15220" title="Download PDF">pdf</a>, <a href="/format/2306.15220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apolinario%2C+M+P+E">Marco Paul E. Apolinario</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17140" title="Abstract">arXiv:2306.17140</a> (replaced) [<a href="/pdf/2306.17140" title="Download PDF">pdf</a>, <a href="/format/2306.17140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ID-Pose: Sparse-view Camera Pose Estimation by Inverting Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Weihao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github: <a href="https://xt4d.github.io/id-pose-web/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00115" title="Abstract">arXiv:2307.00115</a> (replaced) [<a href="/pdf/2307.00115" title="Download PDF">pdf</a>, <a href="/ps/2307.00115" title="Download PostScript">ps</a>, <a href="/format/2307.00115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simpler and parallelizable $O(\sqrt{\log n})$-approximation algorithm  for Sparsest Cut
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolmogorov%2C+V">Vladimir Kolmogorov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02433" title="Abstract">arXiv:2307.02433</a> (replaced) [<a href="/pdf/2307.02433" title="Download PDF">pdf</a>, <a href="/format/2307.02433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconditionally stable higher order semi-implicit level set method for  advection equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frolkovi%C4%8D%2C+P">Peter Frolkovi&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Gajdo%C5%A1ov%C3%A1%2C+N">Nikola Gajdo&#x161;ov&#xe1;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03170" title="Abstract">arXiv:2307.03170</a> (replaced) [<a href="/pdf/2307.03170" title="Download PDF">pdf</a>, <a href="/format/2307.03170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focused Transformer: Contrastive Training for Context Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tworkowski%2C+S">Szymon Tworkowski</a>, 
<a href="/search/cs?searchtype=author&query=Staniszewski%2C+K">Konrad Staniszewski</a>, 
<a href="/search/cs?searchtype=author&query=Pacek%2C+M">Miko&#x142;aj Pacek</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhuai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Michalewski%2C+H">Henryk Michalewski</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%82o%C5%9B%2C+P">Piotr Mi&#x142;o&#x15b;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023). 28 pages, 10 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03913" title="Abstract">arXiv:2307.03913</a> (replaced) [<a href="/pdf/2307.03913" title="Download PDF">pdf</a>, <a href="/ps/2307.03913" title="Download PostScript">ps</a>, <a href="/format/2307.03913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying HCAI in developing effective human-AI teaming: A perspective  from human-AI joint cognitive systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zaifeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04470" title="Abstract">arXiv:2307.04470</a> (replaced) [<a href="/pdf/2307.04470" title="Download PDF">pdf</a>, <a href="/format/2307.04470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Adaptation for Nighttime Color-Thermal Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yexin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guoyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinjing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Vasilakos%2C+A">Athanasios Vasilakos</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06627" title="Abstract">arXiv:2307.06627</a> (replaced) [<a href="/e-print/2307.06627" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Practical Quantum-Inspired Classical Algorithms for Solving  Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Q">Qian Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Theorem 3 and Theorem 5 are incorrect, and more efforts are needed to fix existing issues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Numerical Analysis (math.NA); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07688" title="Abstract">arXiv:2307.07688</a> (replaced) [<a href="/pdf/2307.07688" title="Download PDF">pdf</a>, <a href="/format/2307.07688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRM-IR: Task-Adaptive Deep Unfolding Network for All-In-One Image  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuanshuo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingwen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yecong Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08149" title="Abstract">arXiv:2307.08149</a> (replaced) [<a href="/pdf/2307.08149" title="Download PDF">pdf</a>, <a href="/format/2307.08149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Problems in NP can Admit Double-Exponential Lower Bounds when  Parameterized by Treewidth and Vertex Cover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/cs?searchtype=author&query=Galby%2C+E">Esther Galby</a>, 
<a href="/search/cs?searchtype=author&query=Khazaliya%2C+L">Liana Khazaliya</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaohua Li</a>, 
<a href="/search/cs?searchtype=author&query=Inerney%2C+F+M">Fionn Mc Inerney</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Roohani Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Tale%2C+P">Prafullkumar Tale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Shortened abstract to meet arxiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10601" title="Abstract">arXiv:2307.10601</a> (replaced) [<a href="/pdf/2307.10601" title="Download PDF">pdf</a>, <a href="/format/2307.10601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCA-PVNet: Self-and-Cross Attention Based Aggregation of Point Cloud and  Multi-View for 3D Object Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dongyun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+A">Aiyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shangbo Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiqun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11702" title="Abstract">arXiv:2307.11702</a> (replaced) [<a href="/pdf/2307.11702" title="Download PDF">pdf</a>, <a href="/format/2307.11702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SACReg: Scene-Agnostic Coordinate Regression for Visual Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Revaud%2C+J">Jerome Revaud</a>, 
<a href="/search/cs?searchtype=author&query=Cabon%2C+Y">Yohann Cabon</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%A9gier%2C+R">Romain Br&#xe9;gier</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">JongMin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Weinzaepfel%2C+P">Philippe Weinzaepfel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12581" title="Abstract">arXiv:2307.12581</a> (replaced) [<a href="/pdf/2307.12581" title="Download PDF">pdf</a>, <a href="/format/2307.12581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimality of Glauber dynamics for general-purpose Ising model sampling  and free energy approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunisky%2C+D">Dmitriy Kunisky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 1 figure, closest to version forthcoming in SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Mathematical Physics (math-ph); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14680" title="Abstract">arXiv:2307.14680</a> (replaced) [<a href="/pdf/2307.14680" title="Download PDF">pdf</a>, <a href="/format/2307.14680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nancy Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kosma%2C+C">Chrysoula Kosma</a>, 
<a href="/search/cs?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16857" title="Abstract">arXiv:2307.16857</a> (replaced) [<a href="/pdf/2307.16857" title="Download PDF">pdf</a>, <a href="/ps/2307.16857" title="Download PostScript">ps</a>, <a href="/format/2307.16857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher rank antipodality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nasz%C3%B3di%2C+M">M&#xe1;rton Nasz&#xf3;di</a>, 
<a href="/search/math?searchtype=author&query=Szil%C3%A1gyi%2C+Z">Zsombor Szil&#xe1;gyi</a>, 
<a href="/search/math?searchtype=author&query=Weiner%2C+M">Mih&#xe1;ly Weiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages. Minor changes to previous version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Information Theory (cs.IT); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00629" title="Abstract">arXiv:2308.00629</a> (replaced) [<a href="/pdf/2308.00629" title="Download PDF">pdf</a>, <a href="/format/2308.00629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hessian-Aware Bayesian Optimization for Decision Making Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajpal%2C+M">Mohit Rajpal</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L+G">Lac Gia Tran</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yehong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision after ICLR feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01286" title="Abstract">arXiv:2308.01286</a> (replaced) [<a href="/e-print/2308.01286" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-delay Enumeration Kernelizations for Cuts of Bounded Degree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanesh%2C+L">Lawqueen Kanesh</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+D">Diptapriyo Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Ramanujan%2C+M+S">M. S. Ramanujan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lawqueen Kanesh, one of the authors has requested to exit and has requested her name to be removed from this paper. For this reason, I want to withdraw it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04051" title="Abstract">arXiv:2308.04051</a> (replaced) [<a href="/pdf/2308.04051" title="Download PDF">pdf</a>, <a href="/format/2308.04051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Models for Anomaly Detection and Design-Space Dimensionality  Reduction in Shape Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=D%27Agostino%2C+D">Danny D&#x27;Agostino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Engineering Applications of Artificial Intelligence, Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Data Analysis, Statistics and Probability (physics.data-an); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05504" title="Abstract">arXiv:2308.05504</a> (replaced) [<a href="/pdf/2308.05504" title="Download PDF">pdf</a>, <a href="/format/2308.05504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Classifying Bio-Inspired Artificial Landmarks Using In-Air  3D Sonar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Backer%2C+M">Maarten de Backer</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+W">Wouter Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Laurijssen%2C+D">Dennis Laurijssen</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+R">Ralph Simon</a>, 
<a href="/search/cs?searchtype=author&query=Daems%2C+W">Walter Daems</a>, 
<a href="/search/cs?searchtype=author&query=Steckel%2C+J">Jan Steckel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 2023 IEEE Sensors Conference, Vienna, Austria
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09835" title="Abstract">arXiv:2308.09835</a> (replaced) [<a href="/pdf/2308.09835" title="Download PDF">pdf</a>, <a href="/format/2308.09835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microscopy Image Segmentation via Point and Shape Regularized Data  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ach%2C+T">Thomas Ach</a>, 
<a href="/search/cs?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 3rd MICCAI Workshop on Data Augmentation, Labeling, and Imperfections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09922" title="Abstract">arXiv:2308.09922</a> (replaced) [<a href="/pdf/2308.09922" title="Download PDF">pdf</a>, <a href="/format/2308.09922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDCS: More Diverse Experts with Consistency Self-distillation for  Long-tailed Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 Accept. 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09952" title="Abstract">arXiv:2308.09952</a> (replaced) [<a href="/pdf/2308.09952" title="Download PDF">pdf</a>, <a href="/format/2308.09952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding emergence in data by maximizing effective information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yang%2C+M">Mingzhe Yang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+K">Kaiwei Liu</a>, 
<a href="/search/physics?searchtype=author&query=Rong%2C+Y">Yingqi Rong</a>, 
<a href="/search/physics?searchtype=author&query=Yuan%2C+B">Bing Yuan</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10997" title="Abstract">arXiv:2308.10997</a> (replaced) [<a href="/pdf/2308.10997" title="Download PDF">pdf</a>, <a href="/format/2308.10997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MarkovGen: Structured Prediction for Efficient Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayasumana%2C+S">Sadeep Jayasumana</a>, 
<a href="/search/cs?searchtype=author&query=Glasner%2C+D">Daniel Glasner</a>, 
<a href="/search/cs?searchtype=author&query=Ramalingam%2C+S">Srikumar Ramalingam</a>, 
<a href="/search/cs?searchtype=author&query=Veit%2C+A">Andreas Veit</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+A">Ayan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12114" title="Abstract">arXiv:2308.12114</a> (replaced) [<a href="/pdf/2308.12114" title="Download PDF">pdf</a>, <a href="/format/2308.12114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More -- Towards parsimonious multi-task models using structured  sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+R">Richa Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Phlypo%2C+R">Ronald Phlypo</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+R">Rajkumar Saini</a>, 
<a href="/search/cs?searchtype=author&query=Liwicki%2C+M">Marcus Liwicki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at First Conference on Parsimony and Learning (CPAL 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13054" title="Abstract">arXiv:2308.13054</a> (replaced) [<a href="/pdf/2308.13054" title="Download PDF">pdf</a>, <a href="/ps/2308.13054" title="Download PostScript">ps</a>, <a href="/format/2308.13054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are there graphs whose shortest path structure requires large edge  weights?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+A">Aaron Bernstein</a>, 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Wein%2C+N">Nicole Wein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01728" title="Abstract">arXiv:2309.01728</a> (replaced) [<a href="/pdf/2309.01728" title="Download PDF">pdf</a>, <a href="/format/2309.01728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative-based Fusion Mechanism for Multi-Modal Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhangyong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xuefeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kittler%2C+J">Josef Kittler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03661" title="Abstract">arXiv:2309.03661</a> (replaced) [<a href="/e-print/2309.03661" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based Context- and Domain-aware Pretraining for Vision and  Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wansen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the paper has some wrong,and we hope withdrawal it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03720" title="Abstract">arXiv:2309.03720</a> (replaced) [<a href="/pdf/2309.03720" title="Download PDF">pdf</a>, <a href="/format/2309.03720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Natural Gas Consumption Forecasting System for Continual Learning  Scenarios based on Hoeffding Trees with Change Point Detection Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+R">Radek Svoboda</a>, 
<a href="/search/cs?searchtype=author&query=Basterrech%2C+S">Sebastian Basterrech</a>, 
<a href="/search/cs?searchtype=author&query=Kozal%2C+J">J&#x119;drzej Kozal</a>, 
<a href="/search/cs?searchtype=author&query=Plato%C5%A1%2C+J">Jan Plato&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Wo%C5%BAniak%2C+M">Micha&#x142; Wo&#x17a;niak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04917" title="Abstract">arXiv:2309.04917</a> (replaced) [<a href="/pdf/2309.04917" title="Download PDF">pdf</a>, <a href="/format/2309.04917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing 3D Scenes via Text Prompts without Retraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shuangkang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuchang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://sk-fun.fun/DN2N">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05950" title="Abstract">arXiv:2309.05950</a> (replaced) [<a href="/pdf/2309.05950" title="Download PDF">pdf</a>, <a href="/format/2309.05950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models as Black-Box Optimizers for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shihong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqiu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Samuel Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Ryan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+T">Tiffany Ling</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project site: llm-can-optimize-vlm.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06859" title="Abstract">arXiv:2309.06859</a> (replaced) [<a href="/pdf/2309.06859" title="Download PDF">pdf</a>, <a href="/format/2309.06859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information design in Bayesian routing games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cianfanelli%2C+L">Leonardo Cianfanelli</a>, 
<a href="/search/cs?searchtype=author&query=Ambrogio%2C+A">Alexia Ambrogio</a>, 
<a href="/search/cs?searchtype=author&query=Como%2C+G">Giacomo Como</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures. Full version of accepted paper for the 2023 62th IEEE Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06978" title="Abstract">arXiv:2309.06978</a> (replaced) [<a href="/pdf/2309.06978" title="Download PDF">pdf</a>, <a href="/format/2309.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable JPEG: The Devil is in the Details
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+C">Christoph Reich</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+B">Biplob Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Deep Patel</a>, 
<a href="/search/cs?searchtype=author&query=Chakradhar%2C+S">Srimat Chakradhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024. Project page: <a href="https://christophreich1996.github.io/differentiable_jpeg/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09737" title="Abstract">arXiv:2309.09737</a> (replaced) [<a href="/pdf/2309.09737" title="Download PDF">pdf</a>, <a href="/format/2309.09737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moving Object Detection and Tracking with 4D Radar Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhijun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+F">Fangqiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hantao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C+X">Chris Xiaoxuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures. Co-first authorship for Zhijun Pan, Fangqiang Ding and Hantao Zhong, listed randomly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09809" title="Abstract">arXiv:2309.09809</a> (replaced) [<a href="/pdf/2309.09809" title="Download PDF">pdf</a>, <a href="/format/2309.09809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Continual Learning Paradigm for Non-differentiable Visual Programming  Frameworks on Visual Reasoning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Wentao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+N">Nan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuojie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11526" title="Abstract">arXiv:2309.11526</a> (replaced) [<a href="/pdf/2309.11526" title="Download PDF">pdf</a>, <a href="/format/2309.11526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-based Sensor Calibration using Affine Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machhamer%2C+R">R&#xfc;diger Machhamer</a>, 
<a href="/search/cs?searchtype=author&query=Fazlic%2C+L+B">Lejla Begic Fazlic</a>, 
<a href="/search/cs?searchtype=author&query=Guven%2C+E">Eray Guven</a>, 
<a href="/search/cs?searchtype=author&query=Junk%2C+D">David Junk</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+G+K">Gunes Karabulut Kurt</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+S">Stefan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Didas%2C+S">Stephan Didas</a>, 
<a href="/search/cs?searchtype=author&query=Gollmer%2C+K">Klaus-Uwe Gollmer</a>, 
<a href="/search/cs?searchtype=author&query=Bergmann%2C+R">Ralph Bergmann</a>, 
<a href="/search/cs?searchtype=author&query=Timm%2C+I+J">Ingo J. Timm</a>, 
<a href="/search/cs?searchtype=author&query=Dartmann%2C+G">Guido Dartmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12673" title="Abstract">arXiv:2309.12673</a> (replaced) [<a href="/pdf/2309.12673" title="Download PDF">pdf</a>, <a href="/format/2309.12673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Sparse Modern Hopfield Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+Y">Jerry Yao-Chieh Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dennis Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, accepted at NeurIPS 2023. [v2] updated to match with camera-ready version. Code is available at <a href="https://github.com/MAGICS-LAB/SparseModernHopfield">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12677" title="Abstract">arXiv:2309.12677</a> (replaced) [<a href="/pdf/2309.12677" title="Download PDF">pdf</a>, <a href="/ps/2309.12677" title="Download PostScript">ps</a>, <a href="/format/2309.12677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer  for Capturing Trajectory Diversity in Vehicle Population
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruyi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yan Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, work in update
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15419" title="Abstract">arXiv:2309.15419</a> (replaced) [<a href="/pdf/2309.15419" title="Download PDF">pdf</a>, <a href="/format/2309.15419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph $p$-Laplacians and Scale Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fazeny%2C+A">Ariane Fazeny</a>, 
<a href="/search/cs?searchtype=author&query=Tenbrinck%2C+D">Daniel Tenbrinck</a>, 
<a href="/search/cs?searchtype=author&query=Lukin%2C+K">Kseniia Lukin</a>, 
<a href="/search/cs?searchtype=author&query=Burger%2C+M">Martin Burger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 5 figures, submitted to Scale Space and Variational Methods, part of it published in International Conference on Scale Space and Variational Methods in Computer Vision proceedings
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Scale Space and Variational Methods in Computer Vision. SSVM
  2023. Lecture Notes in Computer Science, vol 14009. Springer, Cham (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16483" title="Abstract">arXiv:2309.16483</a> (replaced) [<a href="/pdf/2309.16483" title="Download PDF">pdf</a>, <a href="/format/2309.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Domain Generalization: Discriminability and Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+S">Shaocong Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qianyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+C">Chenhao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16573" title="Abstract">arXiv:2309.16573</a> (replaced) [<a href="/pdf/2309.16573" title="Download PDF">pdf</a>, <a href="/format/2309.16573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models as a Service: Overview of a New Paradigm and its  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=La+Malfa%2C+E">Emanuele La Malfa</a>, 
<a href="/search/cs?searchtype=author&query=Petrov%2C+A">Aleksandar Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Frieder%2C+S">Simon Frieder</a>, 
<a href="/search/cs?searchtype=author&query=Weinhuber%2C+C">Christoph Weinhuber</a>, 
<a href="/search/cs?searchtype=author&query=Burnell%2C+R">Ryan Burnell</a>, 
<a href="/search/cs?searchtype=author&query=Nazar%2C+R">Raza Nazar</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+A+G">Anthony G. Cohn</a>, 
<a href="/search/cs?searchtype=author&query=Shadbolt%2C+N">Nigel Shadbolt</a>, 
<a href="/search/cs?searchtype=author&query=Wooldridge%2C+M">Michael Wooldridge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00402" title="Abstract">arXiv:2310.00402</a> (replaced) [<a href="/pdf/2310.00402" title="Download PDF">pdf</a>, <a href="/format/2310.00402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jiongkang Ni</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Can Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiajie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shihai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages including references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00533" title="Abstract">arXiv:2310.00533</a> (replaced) [<a href="/pdf/2310.00533" title="Download PDF">pdf</a>, <a href="/format/2310.00533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SELF: Language-Driven Self-Evolution for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianqiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03121" title="Abstract">arXiv:2310.03121</a> (replaced) [<a href="/pdf/2310.03121" title="Download PDF">pdf</a>, <a href="/ps/2310.03121" title="Download PostScript">ps</a>, <a href="/format/2310.03121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenMM 8: Molecular Dynamics Simulation with Machine Learning Potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Eastman%2C+P">Peter Eastman</a>, 
<a href="/search/physics?searchtype=author&query=Galvelis%2C+R">Raimondas Galvelis</a>, 
<a href="/search/physics?searchtype=author&query=Pel%C3%A1ez%2C+R+P">Ra&#xfa;l P. Pel&#xe1;ez</a>, 
<a href="/search/physics?searchtype=author&query=Abreu%2C+C+R+A">Charlles R. A. Abreu</a>, 
<a href="/search/physics?searchtype=author&query=Farr%2C+S+E">Stephen E. Farr</a>, 
<a href="/search/physics?searchtype=author&query=Gallicchio%2C+E">Emilio Gallicchio</a>, 
<a href="/search/physics?searchtype=author&query=Gorenko%2C+A">Anton Gorenko</a>, 
<a href="/search/physics?searchtype=author&query=Henry%2C+M+M">Michael M. Henry</a>, 
<a href="/search/physics?searchtype=author&query=Hu%2C+F">Frank Hu</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/physics?searchtype=author&query=Kr%C3%A4mer%2C+A">Andreas Kr&#xe4;mer</a>, 
<a href="/search/physics?searchtype=author&query=Michel%2C+J">Julien Michel</a>, 
<a href="/search/physics?searchtype=author&query=Mitchell%2C+J+A">Joshua A. Mitchell</a>, 
<a href="/search/physics?searchtype=author&query=Pande%2C+V+S">Vijay S. Pande</a>, 
<a href="/search/physics?searchtype=author&query=Rodrigues%2C+J+P">Jo&#xe3;o PGLM Rodrigues</a>, 
<a href="/search/physics?searchtype=author&query=Rodriguez-Guerra%2C+J">Jaime Rodriguez-Guerra</a>, 
<a href="/search/physics?searchtype=author&query=Simmonett%2C+A+C">Andrew C. Simmonett</a>, 
<a href="/search/physics?searchtype=author&query=Singh%2C+S">Sukrit Singh</a>, 
<a href="/search/physics?searchtype=author&query=Swails%2C+J">Jason Swails</a>, 
<a href="/search/physics?searchtype=author&query=Turner%2C+P">Philip Turner</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuanqing Wang</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+I">Ivy Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Chodera%2C+J+D">John D. Chodera</a>, 
<a href="/search/physics?searchtype=author&query=De+Fabritiis%2C+G">Gianni De Fabritiis</a>, 
<a href="/search/physics?searchtype=author&query=Markland%2C+T+E">Thomas E. Markland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03262" title="Abstract">arXiv:2310.03262</a> (replaced) [<a href="/pdf/2310.03262" title="Download PDF">pdf</a>, <a href="/format/2310.03262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Emergent Abilities with Infinite Resolution Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengding Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chaoqun He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Z">Zebin Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guoyang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> After revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03704" title="Abstract">arXiv:2310.03704</a> (replaced) [<a href="/pdf/2310.03704" title="Download PDF">pdf</a>, <a href="/format/2310.03704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose-Free Generalizable Rendering Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+P">Panwang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hanwen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03915" title="Abstract">arXiv:2310.03915</a> (replaced) [<a href="/pdf/2310.03915" title="Download PDF">pdf</a>, <a href="/format/2310.03915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust  Closed-Loop Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tumma%2C+N">Neehal Tumma</a>, 
<a href="/search/cs?searchtype=author&query=Lechner%2C+M">Mathias Lechner</a>, 
<a href="/search/cs?searchtype=author&query=Loo%2C+N">Noel Loo</a>, 
<a href="/search/cs?searchtype=author&query=Hasani%2C+R">Ramin Hasani</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04705" title="Abstract">arXiv:2310.04705</a> (replaced) [<a href="/pdf/2310.04705" title="Download PDF">pdf</a>, <a href="/format/2310.04705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale MRI reconstruction via dilated ensemble networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+W">Wendi Ma</a>, 
<a href="/search/eess?searchtype=author&query=Lorenzana%2C+M+B">Marlon Bran Lorenzana</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+W">Wei Dai</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongfu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+S+S">Shekhar S. Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05518" title="Abstract">arXiv:2310.05518</a> (replaced) [<a href="/pdf/2310.05518" title="Download PDF">pdf</a>, <a href="/format/2310.05518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Double Descent in Reinforcement Learning with LSTD and Random  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brellmann%2C+D">David Brellmann</a>, 
<a href="/search/cs?searchtype=author&query=Berthier%2C+E">Elo&#xef;se Berthier</a>, 
<a href="/search/cs?searchtype=author&query=Filliat%2C+D">David Filliat</a>, 
<a href="/search/cs?searchtype=author&query=Frehse%2C+G">Goran Frehse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05566" title="Abstract">arXiv:2310.05566</a> (replaced) [<a href="/pdf/2310.05566" title="Download PDF">pdf</a>, <a href="/ps/2310.05566" title="Download PostScript">ps</a>, <a href="/format/2310.05566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregated f-average Neural Network for Interpretable Ensembling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+M">Mathieu Vu</a>, 
<a href="/search/cs?searchtype=author&query=Chouzenoux%2C+E">Emilie Chouzenoux</a>, 
<a href="/search/cs?searchtype=author&query=Pesquet%2C+J">Jean-Christophe Pesquet</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05808" title="Abstract">arXiv:2310.05808</a> (replaced) [<a href="/pdf/2310.05808" title="Download PDF">pdf</a>, <a href="/format/2310.05808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Open-Loop Baseline for Reinforcement Learning Locomotion Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Albu-Sch%C3%A4ffer%2C+A">Alin Albu-Sch&#xe4;ffer</a>, 
<a href="/search/cs?searchtype=author&query=Silv%C3%A9rio%2C+J">Jo&#xe3;o Silv&#xe9;rio</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+F">Freek Stulp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> video: <a href="https://b2drop.eudat.eu/s/ykDPMM7F9KFyLgi">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07918" title="Abstract">arXiv:2310.07918</a> (replaced) [<a href="/pdf/2310.07918" title="Download PDF">pdf</a>, <a href="/format/2310.07918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualized Policy Recovery: Modeling and Interpreting Medical  Decisions with Adaptive Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deuschel%2C+J">Jannik Deuschel</a>, 
<a href="/search/cs?searchtype=author&query=Ellington%2C+C+N">Caleb N. Ellington</a>, 
<a href="/search/cs?searchtype=author&query=Lengerich%2C+B+J">Benjamin J. Lengerich</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yingtao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Friederich%2C+P">Pascal Friederich</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E+P">Eric P. Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08129" title="Abstract">arXiv:2310.08129</a> (replaced) [<a href="/pdf/2310.08129" title="Download PDF">pdf</a>, <a href="/format/2310.08129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tailored Visions: Enhancing Text-to-Image Generation with Personalized  Prompt Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+F">Fangsheng Weng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Lili Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhenzhong Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08540" title="Abstract">arXiv:2310.08540</a> (replaced) [<a href="/pdf/2310.08540" title="Download PDF">pdf</a>, <a href="/format/2310.08540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do pretrained Transformers Really Learn In-context by Gradient Descent?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aayush Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09485" title="Abstract">arXiv:2310.09485</a> (replaced) [<a href="/pdf/2310.09485" title="Download PDF">pdf</a>, <a href="/format/2310.09485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Bayesian Ridge Regression AI Modeling in Virus Severity  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+J">Jai Pal</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+B">Bryan Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 5 listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09912" title="Abstract">arXiv:2310.09912</a> (replaced) [<a href="/pdf/2310.09912" title="Download PDF">pdf</a>, <a href="/format/2310.09912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Discovery of Interpretable Directions in h-space of  Pre-trained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhijie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10570" title="Abstract">arXiv:2310.10570</a> (replaced) [<a href="/pdf/2310.10570" title="Download PDF">pdf</a>, <a href="/format/2310.10570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Context Utilization in Summarization with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Aixin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10917" title="Abstract">arXiv:2310.10917</a> (replaced) [<a href="/pdf/2310.10917" title="Download PDF">pdf</a>, <a href="/ps/2310.10917" title="Download PostScript">ps</a>, <a href="/format/2310.10917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Analysis of Near-Field ISAC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Boqun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11346" title="Abstract">arXiv:2310.11346</a> (replaced) [<a href="/pdf/2310.11346" title="Download PDF">pdf</a>, <a href="/format/2310.11346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalizable Multi-Camera 3D Object Detection via Perspective  Debiasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Q">Qing Lian</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15065" title="Abstract">arXiv:2310.15065</a> (replaced) [<a href="/pdf/2310.15065" title="Download PDF">pdf</a>, <a href="/format/2310.15065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergizing Human-AI Agency: A Guide of 23 Heuristics for Service  Co-Creation with LLM-Based Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qingxiao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhongwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Choudhry%2C+A">Abhinav Choudhry</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongming Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V1.0 on Oct 25th, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16111" title="Abstract">arXiv:2310.16111</a> (replaced) [<a href="/pdf/2310.16111" title="Download PDF">pdf</a>, <a href="/format/2310.16111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Differentially Private Document Generation Using Zero Shot  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Utpala%2C+S">Saiteja Utpala</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P+Y">Pin Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16121" title="Abstract">arXiv:2310.16121</a> (replaced) [<a href="/pdf/2310.16121" title="Download PDF">pdf</a>, <a href="/format/2310.16121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Bogatskiy%2C+A">Alexander Bogatskiy</a>, 
<a href="/search/hep-ph?searchtype=author&query=Hoffman%2C+T">Timothy Hoffman</a>, 
<a href="/search/hep-ph?searchtype=author&query=Offermann%2C+J+T">Jan T. Offermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to the "Machine Learning and the Physical Sciences" NeurIPS 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17703" title="Abstract">arXiv:2310.17703</a> (replaced) [<a href="/pdf/2310.17703" title="Download PDF">pdf</a>, <a href="/ps/2310.17703" title="Download PostScript">ps</a>, <a href="/format/2310.17703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The impact of responding to patient messages with large language model  assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guevara%2C+M">Marco Guevara</a>, 
<a href="/search/cs?searchtype=author&query=Moningi%2C+S">Shalini Moningi</a>, 
<a href="/search/cs?searchtype=author&query=Hoebers%2C+F">Frank Hoebers</a>, 
<a href="/search/cs?searchtype=author&query=Elhalawani%2C+H">Hesham Elhalawani</a>, 
<a href="/search/cs?searchtype=author&query=Kann%2C+B+H">Benjamin H. Kann</a>, 
<a href="/search/cs?searchtype=author&query=Chipidza%2C+F+E">Fallon E. Chipidza</a>, 
<a href="/search/cs?searchtype=author&query=Leeman%2C+J">Jonathan Leeman</a>, 
<a href="/search/cs?searchtype=author&query=Aerts%2C+H+J+W+L">Hugo J.W.L. Aerts</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+T">Timothy Miller</a>, 
<a href="/search/cs?searchtype=author&query=Savova%2C+G+K">Guergana K. Savova</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+R+H">Raymond H. Mak</a>, 
<a href="/search/cs?searchtype=author&query=Lustberg%2C+M">Maryam Lustberg</a>, 
<a href="/search/cs?searchtype=author&query=Afshar%2C+M">Majid Afshar</a>, 
<a href="/search/cs?searchtype=author&query=Bitterman%2C+D+S">Danielle S. Bitterman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures and tables in main, submitted for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17940" title="Abstract">arXiv:2310.17940</a> (replaced) [<a href="/pdf/2310.17940" title="Download PDF">pdf</a>, <a href="/format/2310.17940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Segment-to-Segment Framework for Simultaneous Sequence  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaolei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19380" title="Abstract">arXiv:2310.19380</a> (replaced) [<a href="/pdf/2310.19380" title="Download PDF">pdf</a>, <a href="/format/2310.19380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic  Token Mixer for Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+M">Meng Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hong-Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sibei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01442" title="Abstract">arXiv:2311.01442</a> (replaced) [<a href="/pdf/2311.01442" title="Download PDF">pdf</a>, <a href="/format/2311.01442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Double Descent for Time Series Forecasting: Avoiding Undertrained  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assandri%2C+V">Valentino Assandri</a>, 
<a href="/search/cs?searchtype=author&query=Heshmati%2C+S">Sam Heshmati</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Iakovlev%2C+A">Anton Iakovlev</a>, 
<a href="/search/cs?searchtype=author&query=Repetur%2C+A+E">Ariel Emiliano Repetur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01714" title="Abstract">arXiv:2311.01714</a> (replaced) [<a href="/pdf/2311.01714" title="Download PDF">pdf</a>, <a href="/format/2311.01714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+K">Ka-Hei Hui</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chi-Wing Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 &amp; TOG Project page: <a href="https://liuzhengzhe.github.io/EXIM.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01723" title="Abstract">arXiv:2311.01723</a> (replaced) [<a href="/pdf/2311.01723" title="Download PDF">pdf</a>, <a href="/format/2311.01723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Calibrated Robust Fine-Tuning of Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Changdae Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mijoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyesu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junhyeok Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+E">Euiseog Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kyungwoo Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Distribution Shifts (DistShift), camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02496" title="Abstract">arXiv:2311.02496</a> (replaced) [<a href="/pdf/2311.02496" title="Download PDF">pdf</a>, <a href="/format/2311.02496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LocoMuJoCo: A Comprehensive Imitation Learning Benchmark for Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Hafez%2C+F">Firas Al-Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guoping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Tateo%2C+D">Davide Tateo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/robfiras/loco-mujoco">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03054" title="Abstract">arXiv:2311.03054</a> (replaced) [<a href="/pdf/2311.03054" title="Download PDF">pdf</a>, <a href="/format/2311.03054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyText: Multilingual Visual Text Generation And Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuo%2C+Y">Yuxiang Tuo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03192" title="Abstract">arXiv:2311.03192</a> (replaced) [<a href="/pdf/2311.03192" title="Download PDF">pdf</a>, <a href="/format/2311.03192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and Optimization Based Control for Demand Response in Active  Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aryandoust%2C+A">Arsam Aryandoust</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03197" title="Abstract">arXiv:2311.03197</a> (replaced) [<a href="/pdf/2311.03197" title="Download PDF">pdf</a>, <a href="/format/2311.03197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Linear Subspace Identification: A Machine Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Di+Natale%2C+L">Loris Di Natale</a>, 
<a href="/search/eess?searchtype=author&query=Zakwan%2C+M">Muhammad Zakwan</a>, 
<a href="/search/eess?searchtype=author&query=Svetozarevic%2C+B">Bratislav Svetozarevic</a>, 
<a href="/search/eess?searchtype=author&query=Heer%2C+P">Philipp Heer</a>, 
<a href="/search/eess?searchtype=author&query=Trecate%2C+G+F">Giancarlo Ferrari Trecate</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04076" title="Abstract">arXiv:2311.04076</a> (replaced) [<a href="/pdf/2311.04076" title="Download PDF">pdf</a>, <a href="/format/2311.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLMs exhibit human-like response biases? A case study in survey  design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tjuatja%2C+L">Lindia Tjuatja</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+V">Valerie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S+T">Sherry Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05009" title="Abstract">arXiv:2311.05009</a> (replaced) [<a href="/pdf/2311.05009" title="Download PDF">pdf</a>, <a href="/format/2311.05009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus-based construction of high-dimensional free energy surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lyu%2C+L">Liyao Lyu</a>, 
<a href="/search/physics?searchtype=author&query=Lei%2C+H">Huan Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05499" title="Abstract">arXiv:2311.05499</a> (replaced) [<a href="/pdf/2311.05499" title="Download PDF">pdf</a>, <a href="/format/2311.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Prevalence of WiFi Bottlenecks in Home Access Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Ranya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+M">Marc Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+G">Guilherme Martins</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05997" title="Abstract">arXiv:2311.05997</a> (replaced) [<a href="/pdf/2311.05997" title="Download PDF">pdf</a>, <a href="/format/2311.05997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaofei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yonggang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinbing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haowei Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zilong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update project page
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06428" title="Abstract">arXiv:2311.06428</a> (replaced) [<a href="/pdf/2311.06428" title="Download PDF">pdf</a>, <a href="/format/2311.06428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trichotomy for Transductive Online Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanneke%2C+S">Steve Hanneke</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Shay Moran</a>, 
<a href="/search/cs?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08537" title="Abstract">arXiv:2311.08537</a> (replaced) [<a href="/pdf/2311.08537" title="Download PDF">pdf</a>, <a href="/format/2311.08537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Curve Shortening Flow for Curves of Finite Total (Absolute)  Curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guidotti%2C+P">Patrick Guidotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08592" title="Abstract">arXiv:2311.08592</a> (replaced) [<a href="/pdf/2311.08592" title="Download PDF">pdf</a>, <a href="/format/2311.08592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AART: AI-Assisted Red-Teaming with Diverse Data Generation for New  LLM-powered Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radharapu%2C+B">Bhaktipriya Radharapu</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+K">Kevin Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Aroyo%2C+L">Lora Aroyo</a>, 
<a href="/search/cs?searchtype=author&query=Lahoti%2C+P">Preethi Lahoti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10275" title="Abstract">arXiv:2311.10275</a> (replaced) [<a href="/pdf/2311.10275" title="Download PDF">pdf</a>, <a href="/format/2311.10275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telescope: Telemetry at Terabyte Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+A">Alan Nair</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sandeep Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+A">Aravinda Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Rudoff%2C+A">Andy Rudoff</a>, 
<a href="/search/cs?searchtype=author&query=Subramoney%2C+S">Sreenivas Subramoney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Hardware Architecture (cs.AR); Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11398" title="Abstract">arXiv:2311.11398</a> (replaced) [<a href="/pdf/2311.11398" title="Download PDF">pdf</a>, <a href="/format/2311.11398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-preserving semi-convex-splitting numerical scheme for a  Cahn-Hilliard cross-diffusion system in lymphangiogenesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=J%C3%BCngel%2C+A">Ansgar J&#xfc;ngel</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Boyi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11810" title="Abstract">arXiv:2311.11810</a> (replaced) [<a href="/pdf/2311.11810" title="Download PDF">pdf</a>, <a href="/format/2311.11810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocPedia: Unleashing the Power of Large Multimodal Model in the  Frequency Domain for Versatile Document Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12067" title="Abstract">arXiv:2311.12067</a> (replaced) [<a href="/pdf/2311.12067" title="Download PDF">pdf</a>, <a href="/format/2311.12067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality and Quantity: Unveiling a Million High-Quality Images for  Text-to-Image Synthesis in Fashion Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fayu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">MiaoMiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+F">Fangsheng Weng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Lili Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhenzhong Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12188" title="Abstract">arXiv:2311.12188</a> (replaced) [<a href="/pdf/2311.12188" title="Download PDF">pdf</a>, <a href="/ps/2311.12188" title="Download PostScript">ps</a>, <a href="/format/2311.12188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT and post-test probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weisenthal%2C+S+J">Samuel J. Weisenthal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 138 pages, 4 tables. Fixed second url
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12281" title="Abstract">arXiv:2311.12281</a> (replaced) [<a href="/pdf/2311.12281" title="Download PDF">pdf</a>, <a href="/format/2311.12281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPUSCAN$^{++}$:Efficient Structural Graph Clustering on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Long Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zeyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuemin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12630" title="Abstract">arXiv:2311.12630</a> (replaced) [<a href="/pdf/2311.12630" title="Download PDF">pdf</a>, <a href="/format/2311.12630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Joint Graph Learning and Multivariate Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juhyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyungeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Seungwon Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+U">Ung Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+W">Wooyul Jung</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Miseon Park</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+K">Kijung Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Temporal Graph Learning Workshop @ NeurIPS 2023, New Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12704" title="Abstract">arXiv:2311.12704</a> (replaced) [<a href="/pdf/2311.12704" title="Download PDF">pdf</a>, <a href="/format/2311.12704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascade Learning Localises Discriminant Features in Visual Scene  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Farrahi%2C+K">Katayoun Farrahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12825" title="Abstract">arXiv:2311.12825</a> (replaced) [<a href="/pdf/2311.12825" title="Download PDF">pdf</a>, <a href="/ps/2311.12825" title="Download PostScript">ps</a>, <a href="/format/2311.12825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A PSO Based Method to Generate Actionable Counterfactuals for High  Dimensional Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+S">Shashank Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+A">Asif Salim</a>, 
<a href="/search/cs?searchtype=author&query=Bansode%2C+A">Adesh Bansode</a>, 
<a href="/search/cs?searchtype=author&query=Jinturkar%2C+V">Vivaswan Jinturkar</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Anirudha Nayak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE CSDE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12831" title="Abstract">arXiv:2311.12831</a> (replaced) [<a href="/pdf/2311.12831" title="Download PDF">pdf</a>, <a href="/format/2311.12831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECNR: Efficient Compressive Neural Representation of Time-Varying  Volumetric Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kaiyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoli Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13679" title="Abstract">arXiv:2311.13679</a> (replaced) [<a href="/pdf/2311.13679" title="Download PDF">pdf</a>, <a href="/ps/2311.13679" title="Download PostScript">ps</a>, <a href="/format/2311.13679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity vs. AC0 with simple quantum preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Slote%2C+J">Joseph Slote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages. To appear in ITCS 2024. This revision: many typos fixed, some statements clarified
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13994" title="Abstract">arXiv:2311.13994</a> (replaced) [<a href="/pdf/2311.13994" title="Download PDF">pdf</a>, <a href="/format/2311.13994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Distributed Nash Equilibrium Seeking with Compressed and  Event-triggered Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaomeng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+W">Wei Huo</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuchi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+S">Subhrakanti Dey</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14049" title="Abstract">arXiv:2311.14049</a> (replaced) [<a href="/pdf/2311.14049" title="Download PDF">pdf</a>, <a href="/format/2311.14049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of Deep Learning Segmentation for Real-Time Free-Breathing  Cardiac Magnetic Resonance Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schilling%2C+M">Martin Schilling</a>, 
<a href="/search/eess?searchtype=author&query=Unterberg-Buchwald%2C+C">Christina Unterberg-Buchwald</a>, 
<a href="/search/eess?searchtype=author&query=Lotz%2C+J">Joachim Lotz</a>, 
<a href="/search/eess?searchtype=author&query=Uecker%2C+M">Martin Uecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Martin Schilling and Christina Unterberg-Buchwald contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14333" title="Abstract">arXiv:2311.14333</a> (replaced) [<a href="/pdf/2311.14333" title="Download PDF">pdf</a>, <a href="/format/2311.14333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cycle Invariant Positional Encoding for Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zuoyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Liangcai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as oral presentation in the Learning on Graphs Conference (LoG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14631" title="Abstract">arXiv:2311.14631</a> (replaced) [<a href="/pdf/2311.14631" title="Download PDF">pdf</a>, <a href="/format/2311.14631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image  Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingrui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shiyin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For the project page, please visit <a href="https://royzhao926.github.io/CatVersion-page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14656" title="Abstract">arXiv:2311.14656</a> (replaced) [<a href="/pdf/2311.14656" title="Download PDF">pdf</a>, <a href="/format/2311.14656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Charting New Territories: Exploring the Geographic and Geospatial  Capabilities of Multimodal LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J">Jonathan Roberts</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCddecke%2C+T">Timo L&#xfc;ddecke</a>, 
<a href="/search/cs?searchtype=author&query=Sheikh%2C+R">Rehan Sheikh</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V2: Minor formatting changes and added missing subfigure captions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14721" title="Abstract">arXiv:2311.14721</a> (replaced) [<a href="/pdf/2311.14721" title="Download PDF">pdf</a>, <a href="/format/2311.14721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnySyn: A Cost-Generic Logic Synthesis Framework with Customizable Cost  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Siang-Yun Lee</a>, 
<a href="/search/cs?searchtype=author&query=De+Micheli%2C+G">Giovanni De Micheli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Originally accepted at Int'l Workshop on Logic &amp; Synthesis 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14743" title="Abstract">arXiv:2311.14743</a> (replaced) [<a href="/pdf/2311.14743" title="Download PDF">pdf</a>, <a href="/format/2311.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Baseline Analysis of Reward Models&#x27; Ability To Accurately Analyze  Foundation Models Under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pikus%2C+B">Ben Pikus</a>, 
<a href="/search/cs?searchtype=author&query=LeVine%2C+W">Will LeVine</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hendryx%2C+S">Sean Hendryx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14837" title="Abstract">arXiv:2311.14837</a> (replaced) [<a href="/pdf/2311.14837" title="Download PDF">pdf</a>, <a href="/format/2311.14837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Robustness of Text-Image Composed Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14897" title="Abstract">arXiv:2311.14897</a> (replaced) [<a href="/pdf/2311.14897" title="Download PDF">pdf</a>, <a href="/format/2311.14897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via  3D Anomaly Synthesis and A Self-Supervised Learning Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bozhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shenghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingna Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14948" title="Abstract">arXiv:2311.14948</a> (replaced) [<a href="/pdf/2311.14948" title="Download PDF">pdf</a>, <a href="/format/2311.14948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Backdoor Mitigation Depends on the Pre-training Objective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Sahil Verma</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Schwarzschild%2C+A">Avi Schwarzschild</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+S">Soumye Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav Mohanty Das</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>, 
<a href="/search/cs?searchtype=author&query=Dickerson%2C+J+P">John P Dickerson</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeff Bilmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at BUGS workshop @ NeurIPS 2023 (<a href="https://neurips2023-bugs.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15010" title="Abstract">arXiv:2311.15010</a> (replaced) [<a href="/pdf/2311.15010" title="Download PDF">pdf</a>, <a href="/format/2311.15010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapter is All You Need for Tuning Visual Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dongshuo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Leiyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youqun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15202" title="Abstract">arXiv:2311.15202</a> (replaced) [<a href="/pdf/2311.15202" title="Download PDF">pdf</a>, <a href="/format/2311.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-stream contrastive predictive network with joint handcrafted  feature view for SAR ship classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xianting Feng</a>, 
<a href="/search/cs?searchtype=author&query=zheng%2C+H">Hao zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhigang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meiguang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15414" title="Abstract">arXiv:2311.15414</a> (replaced) [<a href="/pdf/2311.15414" title="Download PDF">pdf</a>, <a href="/format/2311.15414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KOPPA: Improving Prompt-based Continual Learning with Key-Query  Orthogonal Projection and Prototype-based One-Versus-All
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q">Quyen Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Lam Tran</a>, 
<a href="/search/cs?searchtype=author&query=Than%2C+K">Khoat Than</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Toan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15773" title="Abstract">arXiv:2311.15773</a> (replaced) [<a href="/pdf/2311.15773" title="Download PDF">pdf</a>, <a href="/format/2311.15773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Check, Locate, Rectify: A Training-Free Layout Calibration System for  Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15841" title="Abstract">arXiv:2311.15841</a> (replaced) [<a href="/pdf/2311.15841" title="Download PDF">pdf</a>, <a href="/format/2311.15841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Disentangled Identifiers for Action-Customized Text-to-Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuqian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15936" title="Abstract">arXiv:2311.15936</a> (replaced) [<a href="/pdf/2311.15936" title="Download PDF">pdf</a>, <a href="/format/2311.15936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Responsible Governance of Biological Design Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moulange%2C+R">Richard Moulange</a>, 
<a href="/search/cs?searchtype=author&query=Langenkamp%2C+M">Max Langenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Alexanian%2C+T">Tessa Alexanian</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+S">Samuel Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Livingston%2C+M">Morgan Livingston</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + references, 1 figure, accepted at NeurIPS 2023 Workshop on Regulatable ML as oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16102" title="Abstract">arXiv:2311.16102</a> (replaced) [<a href="/pdf/2311.16102" title="Download PDF">pdf</a>, <a href="/format/2311.16102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-TTA: Test-time Adaptation of Discriminative Models via  Generative Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabhudesai%2C+M">Mihir Prabhudesai</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+T">Tsung-Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A+C">Alexander C. Li</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Webpage with Code: <a href="https://diffusion-tta.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16361" title="Abstract">arXiv:2311.16361</a> (replaced) [<a href="/pdf/2311.16361" title="Download PDF">pdf</a>, <a href="/format/2311.16361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Self-supervised Learning Robust to Spurious Correlation via  Learning-speed Aware Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Weicheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez-Granda%2C+C">Carlos Fernandez-Granda</a>, 
<a href="/search/cs?searchtype=author&query=Razavian%2C+N">Narges Razavian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Workshop Self-Supervised Learning - Theory and Practice, 18 pages, 7 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16482" title="Abstract">arXiv:2311.16482</a> (replaced) [<a href="/pdf/2311.16482" title="Download PDF">pdf</a>, <a href="/format/2311.16482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animatable 3D Gaussian: Fast and High-Quality Reconstruction of Multiple  Human Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Minghan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qinwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16487" title="Abstract">arXiv:2311.16487</a> (replaced) [<a href="/pdf/2311.16487" title="Download PDF">pdf</a>, <a href="/format/2311.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Decision-Focused Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhat%2C+Y">Yehya Farhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 45 figures, submitted to AAAI artificial intelligence for operations research workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16512" title="Abstract">arXiv:2311.16512</a> (replaced) [<a href="/pdf/2311.16512" title="Download PDF">pdf</a>, <a href="/format/2311.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSeR: Bridging Image and Language for Cognitive Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+R">Renjing Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://coser-main.github.io">this https URL</a> ; GitHub repository: <a href="https://github.com/VINHYU/CoSeR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16605" title="Abstract">arXiv:2311.16605</a> (replaced) [<a href="/pdf/2311.16605" title="Download PDF">pdf</a>, <a href="/format/2311.16605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jintang Li</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+J">Jiawang Dan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruofan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Sheng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baokun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Changhua Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuchang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16703" title="Abstract">arXiv:2311.16703</a> (replaced) [<a href="/pdf/2311.16703" title="Download PDF">pdf</a>, <a href="/format/2311.16703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD  Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haocheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bousseau%2C+A">Adrien Bousseau</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N">Niloy Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16733" title="Abstract">arXiv:2311.16733</a> (replaced) [<a href="/pdf/2311.16733" title="Download PDF">pdf</a>, <a href="/ps/2311.16733" title="Download PostScript">ps</a>, <a href="/format/2311.16733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Science: Usage for Code Generation and Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nejjar%2C+M">Mohamed Nejjar</a>, 
<a href="/search/cs?searchtype=author&query=Zacharias%2C+L">Luca Zacharias</a>, 
<a href="/search/cs?searchtype=author&query=Stiehle%2C+F">Fabian Stiehle</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingo Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; In Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16770" title="Abstract">arXiv:2311.16770</a> (replaced) [<a href="/pdf/2311.16770" title="Download PDF">pdf</a>, <a href="/ps/2311.16770" title="Download PostScript">ps</a>, <a href="/format/2311.16770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The inversion paradox, and classification of fairness notions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feige%2C+U">Uriel Feige</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16867" title="Abstract">arXiv:2311.16867</a> (replaced) [<a href="/pdf/2311.16867" title="Download PDF">pdf</a>, <a href="/format/2311.16867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Falcon Series of Open Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almazrouei%2C+E">Ebtesam Almazrouei</a>, 
<a href="/search/cs?searchtype=author&query=Alobeidli%2C+H">Hamza Alobeidli</a>, 
<a href="/search/cs?searchtype=author&query=Alshamsi%2C+A">Abdulaziz Alshamsi</a>, 
<a href="/search/cs?searchtype=author&query=Cappelli%2C+A">Alessandro Cappelli</a>, 
<a href="/search/cs?searchtype=author&query=Cojocaru%2C+R">Ruxandra Cojocaru</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Goffinet%2C+%C3%89">&#xc9;tienne Goffinet</a>, 
<a href="/search/cs?searchtype=author&query=Hesslow%2C+D">Daniel Hesslow</a>, 
<a href="/search/cs?searchtype=author&query=Launay%2C+J">Julien Launay</a>, 
<a href="/search/cs?searchtype=author&query=Malartic%2C+Q">Quentin Malartic</a>, 
<a href="/search/cs?searchtype=author&query=Mazzotta%2C+D">Daniele Mazzotta</a>, 
<a href="/search/cs?searchtype=author&query=Noune%2C+B">Badreddine Noune</a>, 
<a href="/search/cs?searchtype=author&query=Pannier%2C+B">Baptiste Pannier</a>, 
<a href="/search/cs?searchtype=author&query=Penedo%2C+G">Guilherme Penedo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16926" title="Abstract">arXiv:2311.16926</a> (replaced) [<a href="/pdf/2311.16926" title="Download PDF">pdf</a>, <a href="/format/2311.16926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaFS: When Large-Language Models Meet Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lanyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Deyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17002" title="Abstract">arXiv:2311.17002</a> (replaced) [<a href="/pdf/2311.17002" title="Download PDF">pdf</a>, <a href="/format/2311.17002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Di Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17134" title="Abstract">arXiv:2311.17134</a> (replaced) [<a href="/pdf/2311.17134" title="Download PDF">pdf</a>, <a href="/format/2311.17134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlycoNMR: Dataset and benchmarks for NMR chemical shift prediction of  carbohydrates with graph neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zizhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Badman%2C+R+P">Ryan Paul Badman</a>, 
<a href="/search/cs?searchtype=author&query=Foley%2C+L">Lachele Foley</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+R">Robert Woods</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+P">Pengyu Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17361" title="Abstract">arXiv:2311.17361</a> (replaced) [<a href="/pdf/2311.17361" title="Download PDF">pdf</a>, <a href="/ps/2311.17361" title="Download PostScript">ps</a>, <a href="/format/2311.17361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does spatial structure affect psychological restoration? A method  based on Graph Neural Networks and Street View Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoran Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengyu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 7 figures, Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17396" title="Abstract">arXiv:2311.17396</a> (replaced) [<a href="/pdf/2311.17396" title="Download PDF">pdf</a>, <a href="/format/2311.17396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral and Polarization Vision: Spectro-polarimetric Real-world  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yujin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunsue Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+Y">Yunseong Moon</a>, 
<a href="/search/cs?searchtype=author&query=Omer%2C+K">Khalid Omer</a>, 
<a href="/search/cs?searchtype=author&query=Heide%2C+F">Felix Heide</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17400" title="Abstract">arXiv:2311.17400</a> (replaced) [<a href="/pdf/2311.17400" title="Download PDF">pdf</a>, <a href="/format/2311.17400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Robustness of Transformer-based Large Language Models with  Dynamic Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lujia Shen</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yuwen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chunpeng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17409" title="Abstract">arXiv:2311.17409</a> (replaced) [<a href="/pdf/2311.17409" title="Download PDF">pdf</a>, <a href="/format/2311.17409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talking Head(?) Anime from a Single Image 4: Improved Model and Its  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khungurn%2C+P">Pramook Khungurn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17410" title="Abstract">arXiv:2311.17410</a> (replaced) [<a href="/pdf/2311.17410" title="Download PDF">pdf</a>, <a href="/format/2311.17410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNFlow: A Distributed Framework for Continuous Temporal GNN Learning on  Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuchen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+G">Guangming Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tianzuo Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Q">Quan Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17431" title="Abstract">arXiv:2311.17431</a> (replaced) [<a href="/pdf/2311.17431" title="Download PDF">pdf</a>, <a href="/format/2311.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Foundation Models through Federated Transfer Learning: A  General Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17438" title="Abstract">arXiv:2311.17438</a> (replaced) [<a href="/pdf/2311.17438" title="Download PDF">pdf</a>, <a href="/format/2311.17438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLOMO: Counterfactual Logical Modification with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yinya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Ruixin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changshui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17460" title="Abstract">arXiv:2311.17460</a> (replaced) [<a href="/pdf/2311.17460" title="Download PDF">pdf</a>, <a href="/format/2311.17460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> W-HMR: Human Mesh Recovery in World Space with Weak-supervised Camera  Calibration and Orientation Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunlian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://yw0208.github.io/w-hmr/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17483" title="Abstract">arXiv:2311.17483</a> (replaced) [<a href="/pdf/2311.17483" title="Download PDF">pdf</a>, <a href="/format/2311.17483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification, Challenges, and Automated Approaches to Handle  Non-Functional Requirements in ML-Enabled Systems: A Systematic Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Martino%2C+V">Vincenzo De Martino</a>, 
<a href="/search/cs?searchtype=author&query=Palomba%2C+F">Fabio Palomba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17510" title="Abstract">arXiv:2311.17510</a> (replaced) [<a href="/pdf/2311.17510" title="Download PDF">pdf</a>, <a href="/format/2311.17510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StructRe: Rewriting for Structured Shape Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiepeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our project page: <a href="https://jiepengwang.github.io/StructRe/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17527" title="Abstract">arXiv:2311.17527</a> (replaced) [<a href="/pdf/2311.17527" title="Download PDF">pdf</a>, <a href="/ps/2311.17527" title="Download PostScript">ps</a>, <a href="/format/2311.17527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $(n,&#x3c3;)-$equivalence relation between skew constacyclic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou-azzou%2C+H">Hassan Ou-azzou</a>, 
<a href="/search/cs?searchtype=author&query=Najmeddine%2C+M">Mustapha Najmeddine</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+N">Nuh Aydin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17597" title="Abstract">arXiv:2311.17597</a> (replaced) [<a href="/pdf/2311.17597" title="Download PDF">pdf</a>, <a href="/format/2311.17597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Self-supervised Learning: Towards Universal Multi-modal  Medical Data Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yiwen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17618" title="Abstract">arXiv:2311.17618</a> (replaced) [<a href="/pdf/2311.17618" title="Download PDF">pdf</a>, <a href="/format/2311.17618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShapeGPT: 3D Shape Generation with A Unified Multi-modal Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fukun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Biao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17684" title="Abstract">arXiv:2311.17684</a> (replaced) [<a href="/pdf/2311.17684" title="Download PDF">pdf</a>, <a href="/format/2311.17684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who can help me? Reconstructing users&#x27; psychological journeys in  depression-related social media interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morini%2C+V">Virginia Morini</a>, 
<a href="/search/cs?searchtype=author&query=Citraro%2C+S">Salvatore Citraro</a>, 
<a href="/search/cs?searchtype=author&query=Sajno%2C+E">Elena Sajno</a>, 
<a href="/search/cs?searchtype=author&query=Sansoni%2C+M">Maria Sansoni</a>, 
<a href="/search/cs?searchtype=author&query=Riva%2C+G">Giuseppe Riva</a>, 
<a href="/search/cs?searchtype=author&query=Stella%2C+M">Massimo Stella</a>, 
<a href="/search/cs?searchtype=author&query=Rossetti%2C+G">Giulio Rossetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main article + supporting information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17696" title="Abstract">arXiv:2311.17696</a> (replaced) [<a href="/pdf/2311.17696" title="Download PDF">pdf</a>, <a href="/ps/2311.17696" title="Download PostScript">ps</a>, <a href="/format/2311.17696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Build an AI Tutor that Can Adapt to Any Course and Provide  Accurate Answers Using Large Language Model and Retrieval-Augmented  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chenxi Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17812" title="Abstract">arXiv:2311.17812</a> (replaced) [<a href="/pdf/2311.17812" title="Download PDF">pdf</a>, <a href="/format/2311.17812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAP: Domain-aware Prompt Learning for Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wansen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. arXiv admin note: substantial text overlap with <a href="/abs/2309.03661">arXiv:2309.03661</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17834" title="Abstract">arXiv:2311.17834</a> (replaced) [<a href="/pdf/2311.17834" title="Download PDF">pdf</a>, <a href="/format/2311.17834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPiC-E : Structural Priors in 3D Diffusion Models using Cross-Entity  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sella%2C+E">Etai Sella</a>, 
<a href="/search/cs?searchtype=author&query=Fiebelman%2C+G">Gal Fiebelman</a>, 
<a href="/search/cs?searchtype=author&query=Atia%2C+N">Noam Atia</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://tau-vailab.github.io/spic-e">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17836" title="Abstract">arXiv:2311.17836</a> (replaced) [<a href="/pdf/2311.17836" title="Download PDF">pdf</a>, <a href="/ps/2311.17836" title="Download PostScript">ps</a>, <a href="/format/2311.17836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Scaling Robust Feedback Control and State Estimation Problems in  Power Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bahavarnia%2C+M">MirSaleh Bahavarnia</a>, 
<a href="/search/eess?searchtype=author&query=Nadeem%2C+M">Muhammad Nadeem</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A+F">Ahmad F. Taha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Press
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sustainable Energy, Grids and Networks, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17898" title="Abstract">arXiv:2311.17898</a> (replaced) [<a href="/pdf/2311.17898" title="Download PDF">pdf</a>, <a href="/format/2311.17898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Pursuit Prompting for Zero-Shot Multimodal Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jinqi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+H+R">Kwan Ho Ryan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Dimos%2C+D">Dimitris Dimos</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+R">Ren&#xe9; Vidal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17921" title="Abstract">arXiv:2311.17921</a> (replaced) [<a href="/pdf/2311.17921" title="Download PDF">pdf</a>, <a href="/format/2311.17921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do text-free diffusion models learn discriminative visual  representations?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+S">Soumik Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Gwilliam%2C+M">Matthew Gwilliam</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+Y">Yosuke Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+V">Vatsal Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+N">Namitha Padmanabhan</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Archana Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: see <a href="https://mgwillia.github.io/diffssl/">this https URL</a> . Code: see <a href="https://github.com/soumik-kanad/diffssl">this https URL</a> . The first two authors contributed equally. 15 pages, 9 figures, 15 tables. Submission under review. (this article supersedes <a href="/abs/2307.08702">arXiv:2307.08702</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item386">Cross-lists</a></li>
<li><a href="#item454">Replacements</a></li>
</ul>
<small>[ total of 696 entries:  <b>1-696</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
