<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 20 Dec 23  to  Thu 21 Dec 23, announced Fri, 22 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item294">Cross-lists</a></li>
<li><a href="#item342">Replacements</a></li>
</ul>
<small>[ total of 554 entries:  <b>1-554</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 22 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13294" title="Abstract">arXiv:2312.13294</a> [<a href="/pdf/2312.13294" title="Download PDF">pdf</a>, <a href="/ps/2312.13294" title="Download PostScript">ps</a>, <a href="/format/2312.13294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subsumptions of Algebraic Rewrite Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+la+Tour%2C+T+B">Thierry Boy de la Tour</a> (Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 20-38
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL); Category Theory (math.CT)

</div>
<p class="mathjax">What does it mean for an algebraic rewrite rule to subsume another rule (that
may then be called a subrule)? We view subsumptions as rule morphisms such that
the simultaneous application of a rule and a subrule (i.e. the application of a
subsumption morphism) yields the same result as a single application of the
subsuming rule. Simultaneous applications of categories of rules are obtained
by Global Coherent Transformations and illustrated on graphs in the DPO
approach. Other approaches are possible since these transformations are
formulated in an abstract Rewriting Environment, and such environments exist
for various approaches to Algebraic Rewriting, including DPO, SqPO and PBPO.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13295" title="Abstract">arXiv:2312.13295</a> [<a href="/pdf/2312.13295" title="Download PDF">pdf</a>, <a href="/ps/2312.13295" title="Download PostScript">ps</a>, <a href="/format/2312.13295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A functional scripting interface to an object oriented C++ library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kloimwieder%2C+M">Markus Kloimwieder</a>, 
<a href="/search/cs?searchtype=author&query=Gadermaier%2C+C">Christoph Gadermaier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, code highlighted in color
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The object oriented programming paradigm is widely used in science and
engineering. Many open and commercial libraries are written in C++ and
increasingly provide bindings to Python, which is much easier to learn, but
still partly encourages the use of object oriented programming. However,
scientific ideas are much more directly and meaningfully expressed in the
purely functional programming paradigm. Here, we take a best practice example,
CERNs Python binding for its ROOT library, designed to handle the enormous
amounts of data generated by the worlds largest particle accelerator, and
translate a simple segment of its tutorial into Clojure, a functional language
from the Lisp family. The code examples demonstrate how a purely functional
language straightforwardly expresses scientific ideas. Subsequently, we develop
a compiled Lisp-C++ interoperation layer to access the ROOT library exclusively
via functional code. To preserve the expressivity of the Lisp code, the type
hints necessary for C++ code generation are stored in a separate file. The
interop system presented here is a generic framework that, when provided with a
suitable file of type hints, facilitates access to methods of arbitrary C++
libraries and platforms like real-time microcontrollers.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13299" title="Abstract">arXiv:2312.13299</a> [<a href="/pdf/2312.13299" title="Download PDF">pdf</a>, <a href="/format/2312.13299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact 3D Scene Representation via Self-Organizing Gaussian Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morgenstern%2C+W">Wieland Morgenstern</a>, 
<a href="/search/cs?searchtype=author&query=Barthel%2C+F">Florian Barthel</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D Gaussian Splatting has recently emerged as a highly promising technique
for modeling of static 3D scenes. In contrast to Neural Radiance Fields, it
utilizes efficient rasterization allowing for very fast rendering at
high-quality. However, the storage size is significantly higher, which hinders
practical deployment, e.g.~on resource constrained devices. In this paper, we
introduce a compact scene representation organizing the parameters of 3D
Gaussian Splatting (3DGS) into a 2D grid with local homogeneity, ensuring a
drastic reduction in storage requirements without compromising visual quality
during rendering. Central to our idea is the explicit exploitation of
perceptual redundancies present in natural scenes. In essence, the inherent
nature of a scene allows for numerous permutations of Gaussian parameters to
equivalently represent it. To this end, we propose a novel highly parallel
algorithm that regularly arranges the high-dimensional Gaussian parameters into
a 2D grid while preserving their neighborhood structure. During training, we
further enforce local smoothness between the sorted parameters in the grid. The
uncompressed Gaussians use the same structure as 3DGS, ensuring a seamless
integration with established renderers. Our method achieves a reduction factor
of 8x to 26x in size for complex scenes with no increase in training time,
marking a substantial leap forward in the domain of 3D scene distribution and
consumption. Additional information can be found on our project page:
https://fraunhoferhhi.github.io/Self-Organizing-Gaussians/
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13301" title="Abstract">arXiv:2312.13301</a> [<a href="/pdf/2312.13301" title="Download PDF">pdf</a>, <a href="/format/2312.13301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimQ-NAS: Simultaneous Quantization Policy and Neural Architecture  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S+N">Sharath Nittur Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Szankin%2C+M">Maciej Szankin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+S">Sairam Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Sarah%2C+A">Anthony Sarah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent one-shot Neural Architecture Search algorithms rely on training a
hardware-agnostic super-network tailored to a specific task and then extracting
efficient sub-networks for different hardware platforms. Popular approaches
separate the training of super-networks from the search for sub-networks, often
employing predictors to alleviate the computational overhead associated with
search. Additionally, certain methods also incorporate the quantization policy
within the search space. However, while the quantization policy search for
convolutional neural networks is well studied, the extension of these methods
to transformers and especially foundation models remains under-explored. In
this paper, we demonstrate that by using multi-objective search algorithms
paired with lightly trained predictors, we can efficiently search for both the
sub-network architecture and the corresponding quantization policy and
outperform their respective baselines across different performance objectives
such as accuracy, model size, and latency. Specifically, we demonstrate that
our approach performs well across both uni-modal (ViT and BERT) and multi-modal
(BEiT-3) transformer-based architectures as well as convolutional architectures
(ResNet). For certain networks, we demonstrate an improvement of up to $4.80x$
and $3.44x$ for latency and model size respectively, without degradation in
accuracy compared to the fully quantized INT8 baselines.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13303" title="Abstract">arXiv:2312.13303</a> [<a href="/pdf/2312.13303" title="Download PDF">pdf</a>, <a href="/format/2312.13303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealGen: Retrieval Augmented Generation for Controllable Traffic  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenhao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yulong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Simulation plays a crucial role in the development of autonomous vehicles
(AVs) due to the potential risks associated with real-world testing. Although
significant progress has been made in the visual aspects of simulators,
generating complex behavior among agents remains a formidable challenge. It is
not only imperative to ensure realism in the scenarios generated but also
essential to incorporate preferences and conditions to facilitate controllable
generation for AV training and evaluation. Traditional methods, mainly relying
on memorizing the distribution of training datasets, often fall short in
generating unseen scenarios. Inspired by the success of retrieval augmented
generation in large language models, we present RealGen, a novel
retrieval-based in-context learning framework for traffic scenario generation.
RealGen synthesizes new scenarios by combining behaviors from multiple
retrieved examples in a gradient-free way, which may originate from templates
or tagged scenarios. This in-context learning framework endows versatile
generative capabilities, including the ability to edit scenarios, compose
various behaviors, and produce critical scenarios. Evaluations show that
RealGen offers considerable flexibility and controllability, marking a new
direction in the field of controllable traffic scenario generation. Check our
project website for more information: https://realgen.github.io.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13305" title="Abstract">arXiv:2312.13305</a> [<a href="/pdf/2312.13305" title="Download PDF">pdf</a>, <a href="/format/2312.13305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DVIS++: Improved Decoupled Framework for Universal Video Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xingye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yikang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shunping Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuebo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present the \textbf{D}ecoupled \textbf{VI}deo \textbf{S}egmentation (DVIS)
framework, a novel approach for the challenging task of universal video
segmentation, including video instance segmentation (VIS), video semantic
segmentation (VSS), and video panoptic segmentation (VPS). Unlike previous
methods that model video segmentation in an end-to-end manner, our approach
decouples video segmentation into three cascaded sub-tasks: segmentation,
tracking, and refinement. This decoupling design allows for simpler and more
effective modeling of the spatio-temporal representations of objects,
especially in complex scenes and long videos. Accordingly, we introduce two
novel components: the referring tracker and the temporal refiner. These
components track objects frame by frame and model spatio-temporal
representations based on pre-aligned features. To improve the tracking
capability of DVIS, we propose a denoising training strategy and introduce
contrastive learning, resulting in a more robust framework named DVIS++.
Furthermore, we evaluate DVIS++ in various settings, including open vocabulary
and using a frozen pre-trained backbone. By integrating CLIP with DVIS++, we
present OV-DVIS++, the first open-vocabulary universal video segmentation
framework. We conduct extensive experiments on six mainstream benchmarks,
including the VIS, VSS, and VPS datasets. Using a unified architecture, DVIS++
significantly outperforms state-of-the-art specialized methods on these
benchmarks in both close- and open-vocabulary settings.
Code:~\url{https://github.com/zhang-tao-whu/DVIS_Plus}.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13306" title="Abstract">arXiv:2312.13306</a> [<a href="/pdf/2312.13306" title="Download PDF">pdf</a>, <a href="/format/2312.13306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fair Graph Federated Learning via Incentive Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chenglu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiarong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingbiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, accepted by AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph federated learning (FL) has emerged as a pivotal paradigm enabling
multiple agents to collaboratively train a graph model while preserving local
data privacy. Yet, current efforts overlook a key issue: agents are
self-interested and would hesitant to share data without fair and satisfactory
incentives. This paper is the first endeavor to address this issue by studying
the incentive mechanism for graph federated learning. We identify a unique
phenomenon in graph federated learning: the presence of agents posing potential
harm to the federation and agents contributing with delays. This stands in
contrast to previous FL incentive mechanisms that assume all agents contribute
positively and in a timely manner. In view of this, this paper presents a novel
incentive mechanism tailored for fair graph federated learning, integrating
incentives derived from both model gradient and payoff. To achieve this, we
first introduce an agent valuation function aimed at quantifying agent
contributions through the introduction of two criteria: gradient alignment and
graph diversity. Moreover, due to the high heterogeneity in graph federated
learning, striking a balance between accuracy and fairness becomes particularly
crucial. We introduce motif prototypes to enhance accuracy, communicated
between the server and agents, enhancing global model aggregation and aiding
agents in local model optimization. Extensive experiments show that our model
achieves the best trade-off between accuracy and the fairness of model
gradient, as well as superior payoff fairness.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13307" title="Abstract">arXiv:2312.13307</a> [<a href="/pdf/2312.13307" title="Download PDF">pdf</a>, <a href="/format/2312.13307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Steps are Equal: Efficient Generation with Progressive Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiu Su</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shan You</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion models have demonstrated remarkable efficacy in various generative
tasks with the predictive prowess of denoising model. Currently, these models
employ a uniform denoising approach across all timesteps. However, the inherent
variations in noisy latents at each timestep lead to conflicts during training,
constraining the potential of diffusion models. To address this challenge, we
propose a novel two-stage training strategy termed Step-Adaptive Training. In
the initial stage, a base denoising model is trained to encompass all
timesteps. Subsequently, we partition the timesteps into distinct groups,
fine-tuning the model within each group to achieve specialized denoising
capabilities. Recognizing that the difficulties of predicting noise at
different timesteps vary, we introduce a diverse model size requirement. We
dynamically adjust the model size for each timestep by estimating task
difficulty based on its signal-to-noise ratio before fine-tuning. This
adjustment is facilitated by a proxy-based structural importance assessment
mechanism, enabling precise and efficient pruning of the base denoising model.
Our experiments validate the effectiveness of the proposed training strategy,
demonstrating an improvement in the FID score on CIFAR10 by over 0.3 while
utilizing only 80\% of the computational resources. This innovative approach
not only enhances model performance but also significantly reduces
computational costs, opening new avenues for the development and application of
diffusion models.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13308" title="Abstract">arXiv:2312.13308</a> [<a href="/pdf/2312.13308" title="Download PDF">pdf</a>, <a href="/format/2312.13308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SWAGS: Sampling Windows Adaptively for Dynamic 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaw%2C+R">Richard Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jifei Song</a>, 
<a href="/search/cs?searchtype=author&query=Moreau%2C+A">Arthur Moreau</a>, 
<a href="/search/cs?searchtype=author&query=Nazarczuk%2C+M">Michal Nazarczuk</a>, 
<a href="/search/cs?searchtype=author&query=Catley-Chandar%2C+S">Sibi Catley-Chandar</a>, 
<a href="/search/cs?searchtype=author&query=Dhamo%2C+H">Helisa Dhamo</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Pellitero%2C+E">Eduardo Perez-Pellitero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Novel view synthesis has shown rapid progress recently, with methods capable
of producing evermore photo-realistic results. 3D Gaussian Splatting has
emerged as a particularly promising method, producing high-quality renderings
of static scenes and enabling interactive viewing at real-time frame rates.
However, it is currently limited to static scenes only. In this work, we extend
3D Gaussian Splatting to reconstruct dynamic scenes. We model the dynamics of a
scene using a tunable MLP, which learns the deformation field from a canonical
space to a set of 3D Gaussians per frame. To disentangle the static and dynamic
parts of the scene, we learn a tuneable parameter for each Gaussian, which
weighs the respective MLP parameters to focus attention on the dynamic parts.
This improves the model's ability to capture dynamics in scenes with an
imbalance of static to dynamic regions. To handle scenes of arbitrary length
whilst maintaining high rendering quality, we introduce an adaptive window
sampling strategy to partition the sequence into windows based on the amount of
movement in the sequence. We train a separate dynamic Gaussian Splatting model
for each window, allowing the canonical representation to change, thus enabling
the reconstruction of scenes with significant geometric or topological changes.
Temporal consistency is enforced using a fine-tuning step with self-supervising
consistency loss on randomly sampled novel views. As a result, our method
produces high-quality renderings of general dynamic scenes with competitive
quantitative performance, which can be viewed in real-time with our dynamic
interactive viewer.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13309" title="Abstract">arXiv:2312.13309</a> [<a href="/pdf/2312.13309" title="Download PDF">pdf</a>, <a href="/format/2312.13309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generate E-commerce Product Background by Integrating Category  Commonality and Personalized Style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jingjing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Lixing Bo</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The state-of-the-art methods for e-commerce product background generation
suffer from the inefficiency of designing product-wise prompts when scaling up
the production, as well as the ineffectiveness of describing fine-grained
styles when customizing personalized backgrounds for some specific brands. To
address these obstacles, we integrate the category commonality and personalized
style into diffusion models. Concretely, we propose a Category-Wise Generator
to enable large-scale background generation for the first time. A unique
identifier in the prompt is assigned to each category, whose attention is
located on the background by a mask-guided cross attention layer to learn the
category-wise style. Furthermore, for products with specific and fine-grained
requirements in layout, elements, etc, a Personality-Wise Generator is devised
to learn such personalized style directly from a reference image to resolve
textual ambiguities, and is trained in a self-supervised manner for more
efficient training data usage. To advance research in this field, the first
large-scale e-commerce product background generation dataset BG60k is
constructed, which covers more than 60k product images from over 2k categories.
Experiments demonstrate that our method could generate high-quality backgrounds
for different categories, and maintain the personalized background style of
reference images. The link to BG60k and codes will be available soon.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13311" title="Abstract">arXiv:2312.13311</a> [<a href="/pdf/2312.13311" title="Download PDF">pdf</a>, <a href="/format/2312.13311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Deep Learning: A BP-Free Approach for Parallel Block-Wise  Training of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">Anzhe Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Chenzhong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingxi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+H">Heng Ping</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Nazarian%2C+S">Shahin Nazarian</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Backpropagation (BP) has been a successful optimization technique for deep
learning models. However, its limitations, such as backward- and
update-locking, and its biological implausibility, hinder the concurrent
updating of layers and do not mimic the local learning processes observed in
the human brain. To address these issues, recent research has suggested using
local error signals to asynchronously train network blocks. However, this
approach often involves extensive trial-and-error iterations to determine the
best configuration for local training. This includes decisions on how to
decouple network blocks and which auxiliary networks to use for each block. In
our work, we introduce a novel BP-free approach: a block-wise BP-free (BWBPF)
neural network that leverages local error signals to optimize distinct
sub-neural networks separately, where the global loss is only responsible for
updating the output layer. The local error signals used in the BP-free model
can be computed in parallel, enabling a potential speed-up in the weight update
process through parallel implementation. Our experimental results consistently
show that this approach can identify transferable decoupled architectures for
VGG and ResNet variations, outperforming models trained with end-to-end
backpropagation and other state-of-the-art block-wise learning techniques on
datasets such as CIFAR-10 and Tiny-ImageNet. The code is released at
https://github.com/Belis0811/BWBPF.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13312" title="Abstract">arXiv:2312.13312</a> [<a href="/pdf/2312.13312" title="Download PDF">pdf</a>, <a href="/format/2312.13312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label Learning from Privacy-Label
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongnian Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haotian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tongfeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhichen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Multi-abel Learning (MLL) often involves the assignment of multiple relevant
labels to each instance, which can lead to the leakage of sensitive information
(such as smoking, diseases, etc.) about the instances. However, existing MLL
suffer from failures in protection for sensitive information. In this paper, we
propose a novel setting named Multi-Label Learning from Privacy-Label (MLLPL),
which Concealing Labels via Privacy-Label Unit (CLPLU). Specifically, during
the labeling phase, each privacy-label is randomly combined with a non-privacy
label to form a Privacy-Label Unit (PLU). If any label within a PLU is
positive, the unit is labeled as positive; otherwise, it is labeled negative,
as shown in Figure 1. PLU ensures that only non-privacy labels are appear in
the label set, while the privacy-labels remain concealed. Moreover, we further
propose a Privacy-Label Unit Loss (PLUL) to learn the optimal classifier by
minimizing the empirical risk of PLU. Experimental results on multiple
benchmark datasets demonstrate the effectiveness and superiority of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13314" title="Abstract">arXiv:2312.13314</a> [<a href="/pdf/2312.13314" title="Download PDF">pdf</a>, <a href="/format/2312.13314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Pre-trained Image Backbones for Semantic Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrada%2C+T">Tariq Berrada</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+J">Jakob Verbeek</a>, 
<a href="/search/cs?searchtype=author&query=Couprie%2C+C">Camille Couprie</a>, 
<a href="/search/cs?searchtype=author&query=Alahari%2C+K">Karteek Alahari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to CVPR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic image synthesis, i.e., generating images from user-provided semantic
label maps, is an important conditional image generation task as it allows to
control both the content as well as the spatial layout of generated images.
Although diffusion models have pushed the state of the art in generative image
modeling, the iterative nature of their inference process makes them
computationally demanding. Other approaches such as GANs are more efficient as
they only need a single feed-forward pass for generation, but the image quality
tends to suffer on large and diverse datasets. In this work, we propose a new
class of GAN discriminators for semantic image synthesis that generates highly
realistic images by exploiting feature backbone networks pre-trained for tasks
such as image classification. We also introduce a new generator architecture
with better context modeling and using cross-attention to inject noise into
latent variables, leading to more diverse generated images. Our model, which we
dub DP-SIMS, achieves state-of-the-art results in terms of image quality and
consistency with the input label maps on ADE-20K, COCO-Stuff, and Cityscapes,
surpassing recent diffusion models while requiring two orders of magnitude less
compute for inference.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13316" title="Abstract">arXiv:2312.13316</a> [<a href="/pdf/2312.13316" title="Download PDF">pdf</a>, <a href="/format/2312.13316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECAMP: Entity-centered Context-aware Medical Vision Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rongsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Qingsong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Haoran Lai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiyang He</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaodong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zihang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S.Kevin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant advancements in medical vision-language pre-training,
existing methods have largely overlooked the inherent entity-specific context
within radiology reports and the complex cross-modality contextual
relationships between text and images. To close this gap, we propose a novel
Entity-centered Context-aware Medical Vision-language Pre-training (ECAMP)
framework, which is designed to enable a more entity-centered and
context-sensitive interpretation of medical data. Utilizing the recent powerful
large language model, we distill entity-centered context from medical reports,
which enables ECAMP to gain more effective supervision from the text modality.
By further pre-training our model with carefully designed entity-aware,
context-enhanced masked language modeling and context-guided super-resolution
tasks, ECAMP significantly refines the interplay between text and image
modalities, leading to an enhanced ability to extract entity-centered
contextual features. Besides, our proposed multi-scale context fusion design
also improves the semantic integration of both coarse and fine-level image
representations, prompting better performance for multi-scale downstream
applications. Combining these components leads to significant performance leaps
over current state-of-the-art methods and establishes a new standard for
cross-modality learning in medical imaging, whose effectiveness is demonstrated
by our extensive experiments on various tasks including classification,
segmentation, and detection across several public datasets. Code and models are
available at https://github.com/ToniChopp/ECAMP.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13317" title="Abstract">arXiv:2312.13317</a> [<a href="/pdf/2312.13317" title="Download PDF">pdf</a>, <a href="/format/2312.13317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Hybrid Camera Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rim%2C+J">Jaesung Rim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junyong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Heemin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sunghyun Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page : <a href="http://cg.postech.ac.kr/research/HCBlur">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Mobile cameras, despite their significant advancements, still face low-light
challenges due to compact sensors and lenses, leading to longer exposures and
motion blur. Traditional solutions like blind deconvolution and learning-based
methods often fall short in handling ill-posedness of the deblurring problem.
To address this, we propose a novel deblurring framework for multi-camera
smartphones, utilizing a hybrid imaging technique. We simultaneously capture a
long exposure wide-angle image and ultra-wide burst images from a smartphone,
and use the sharp burst to estimate blur kernels for deblurring the wide-angle
image. For learning and evaluation of our network, we introduce the HCBlur
dataset, which includes pairs of blurry wide-angle and sharp ultra-wide burst
images, and their sharp wide-angle counterparts. We extensively evaluate our
method, and the result shows the state-of-the-art quality.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13318" title="Abstract">arXiv:2312.13318</a> [<a href="/pdf/2312.13318" title="Download PDF">pdf</a>, <a href="/format/2312.13318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Shot Initial Orbit Determination in Low-Earth Orbit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ferreira%2C+R">Ricardo Ferreira</a>, 
<a href="/search/eess?searchtype=author&query=Guimar%C3%A3es%2C+M">Marta Guimar&#xe3;es</a>, 
<a href="/search/eess?searchtype=author&query=Valdeira%2C+F">Filipa Valdeira</a>, 
<a href="/search/eess?searchtype=author&query=Soares%2C+C">Cl&#xe1;udia Soares</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Due to the importance of satellites for society and the exponential increase
in the number of objects in orbit, it is important to accurately determine the
state (e.g., position and velocity) of these Resident Space Objects (RSOs) at
any time and in a timely manner. State-of-the-art methodologies for initial
orbit determination consist of Kalman-type filters that process sequential data
over time and return the state and associated uncertainty of the object, as is
the case of the Extended Kalman Filter (EKF). However, these methodologies are
dependent on a good initial guess for the state vector and usually simplify the
physical dynamical model, due to the difficulty of precisely modeling
perturbative forces, such as atmospheric drag and solar radiation pressure.
Other approaches do not require assumptions about the dynamical system, such as
the trilateration method, and require simultaneous measurements, such as three
measurements of range and range-rate for the particular case of trilateration.
We consider the same setting of simultaneous measurements (one-shot), resorting
to time delay and Doppler shift measurements. Based on recent advancements in
the problem of moving target localization for sonar multistatic systems, we are
able to formulate the problem of initial orbit determination as a Weighted
Least Squares. With this approach, we are able to directly obtain the state of
the object (position and velocity) and the associated covariance matrix from
the Fisher's Information Matrix (FIM). We demonstrate that, for small noise,
our estimator is able to attain the Cram\'er-Rao Lower Bound accuracy, i.e.,
the accuracy attained by the unbiased estimator with minimum variance. We also
numerically demonstrate that our estimator is able to attain better accuracy on
the state estimation than the trilateration method and returns a smaller
uncertainty associated with the estimation.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13320" title="Abstract">arXiv:2312.13320</a> [<a href="/pdf/2312.13320" title="Download PDF">pdf</a>, <a href="/ps/2312.13320" title="Download PostScript">ps</a>, <a href="/format/2312.13320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A faster FPRAS for #NFA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sourav Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+U">Umang Mathur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
<p class="mathjax">Given a non-deterministic finite automaton (NFA) A with m states, and a
natural number n (presented in unary), the #NFA problem asks to determine the
size of the set L(A_n) of words of length n accepted by A. While the
corresponding decision problem of checking the emptiness of L(A_n) is solvable
in polynomial time, the #NFA problem is known to be #P-hard. Recently, the
long-standing open question -- whether there is an FPRAS (fully polynomial time
randomized approximation scheme) for #NFA -- was resolved in \cite{ACJR19}. The
FPRAS due to \cite{ACJR19} relies on the interreducibility of counting and
sampling, and computes, for each pair of state q and natural number i &lt;= n, a
set of O(\frac{m^7 n^7}{epsilon^7}) many uniformly chosen samples from the set
of words of length i that have a run ending at q (\epsilon is the error
tolerance parameter of the FPRAS). This informative measure -- the number of
samples maintained per state and length -- also affects the overall time
complexity with a quadratic dependence.
<br />Given the prohibitively high time complexity, in terms of each of the input
parameters, of the FPRAS due to \cite{ACJR19}, and considering the widespread
application of approximate counting (and sampling) in various tasks in Computer
Science, a natural question arises: Is there a faster FPRAS for #NFA that can
pave the way for the practical implementation of approximate #NFA tools? In
this work, we demonstrate that significant improvements in time complexity are
achievable. Specifically, we have reduced the number of samples required for
each state to be independent of m, with significantly less dependence on $n$
and $\epsilon$, maintaining only \widetilde{O}(\frac{n^4}{epsilon^2}) samples
per state.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13322" title="Abstract">arXiv:2312.13322</a> [<a href="/pdf/2312.13322" title="Download PDF">pdf</a>, <a href="/format/2312.13322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Specific Code Language Models: Unraveling the Potential for HPC  Codes and Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadosh%2C+T">Tal Kadosh</a>, 
<a href="/search/cs?searchtype=author&query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+V+A">Vy A. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nadav Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Krien%2C+N">Neva Krien</a>, 
<a href="/search/cs?searchtype=author&query=Capota%2C+M">Mihai Capota</a>, 
<a href="/search/cs?searchtype=author&query=Wasay%2C+A">Abdul Wasay</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N">Nesreen Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Willke%2C+T">Ted Willke</a>, 
<a href="/search/cs?searchtype=author&query=Tamir%2C+G">Guy Tamir</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+T">Timothy Mattson</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">With easier access to powerful compute resources, there is a growing trend in
AI for software development to develop larger language models (LLMs) to address
a variety of programming tasks. Even LLMs applied to tasks from the
high-performance computing (HPC) domain are huge in size and demand expensive
compute resources for training. This is partly because these LLMs for HPC tasks
are obtained by finetuning existing LLMs that support several natural and/or
programming languages. We found this design choice confusing - why do we need
large LMs trained on natural languages and programming languages unrelated to
HPC for HPC-specific tasks?
<br />In this line of work, we aim to question choices made by existing LLMs by
developing smaller LMs for specific domains - we call them domain-specific LMs.
Specifically, we start off with HPC as a domain and build an HPC-specific LM,
named MonoCoder, that is orders of magnitude smaller than existing LMs but
delivers similar, if not better performance, on non-HPC and HPC tasks.
Specifically, we pre-trained MonoCoder on an HPC-specific dataset (named
HPCorpus) of C and C++ programs mined from GitHub. We evaluated the performance
of MonoCoder against conventional multi-lingual LLMs. Results demonstrate that
MonoCoder, although much smaller than existing LMs, achieves similar results on
normalized-perplexity tests and much better ones in CodeBLEU competence for
high-performance and parallel code generations. Furthermore, fine-tuning the
base model for the specific task of parallel code generation (OpenMP parallel
for pragmas) demonstrates outstanding results compared to GPT, especially when
local misleading semantics are removed by our novel pre-processor Tokompiler,
showcasing the ability of domain-specific models to assist in HPC-relevant
tasks.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13324" title="Abstract">arXiv:2312.13324</a> [<a href="/pdf/2312.13324" title="Download PDF">pdf</a>, <a href="/format/2312.13324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShowRoom3D: Text to High-Quality 3D Room Generation Using 3D Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weijia Mao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhongcong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce ShowRoom3D, a three-stage approach for generating high-quality
3D room-scale scenes from texts. Previous methods using 2D diffusion priors to
optimize neural radiance fields for generating room-scale scenes have shown
unsatisfactory quality. This is primarily attributed to the limitations of 2D
priors lacking 3D awareness and constraints in the training methodology. In
this paper, we utilize a 3D diffusion prior, MVDiffusion, to optimize the 3D
room-scale scene. Our contributions are in two aspects. Firstly, we propose a
progressive view selection process to optimize NeRF. This involves dividing the
training process into three stages, gradually expanding the camera sampling
scope. Secondly, we propose the pose transformation method in the second stage.
It will ensure MVDiffusion provide the accurate view guidance. As a result,
ShowRoom3D enables the generation of rooms with improved structural integrity,
enhanced clarity from any view, reduced content repetition, and higher
consistency across different perspectives. Extensive experiments demonstrate
that our method, significantly outperforms state-of-the-art approaches by a
large margin in terms of user study.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13327" title="Abstract">arXiv:2312.13327</a> [<a href="/pdf/2312.13327" title="Download PDF">pdf</a>, <a href="/format/2312.13327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Reinforcement Learning for Variable Action Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinii%2C+V">Viacheslav Sinii</a>, 
<a href="/search/cs?searchtype=author&query=Nikulin%2C+A">Alexander Nikulin</a>, 
<a href="/search/cs?searchtype=author&query=Kurenkov%2C+V">Vladislav Kurenkov</a>, 
<a href="/search/cs?searchtype=author&query=Zisman%2C+I">Ilya Zisman</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent work has shown that supervised pre-training on learning histories of
RL algorithms results in a model that captures the learning process and is able
to improve in-context on novel tasks through interactions with an environment.
Despite the progress in this area, there is still a gap in the existing
literature, particularly in the in-context generalization to new action spaces.
While existing methods show high performance on new tasks created by different
reward distributions, their architectural design and training process are not
suited for the introduction of new actions during evaluation. We aim to bridge
this gap by developing an architecture and training methodology specifically
for the task of generalizing to new action spaces. Inspired by Headless LLM, we
remove the dependence on the number of actions by directly predicting the
action embeddings. Furthermore, we use random embeddings to force the semantic
inference of actions from context and to prepare for the new unseen embeddings
during test time. Using multi-armed bandit environments with a variable number
of arms, we show that our model achieves the performance of the data generation
algorithm without requiring retraining for each new environment.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13328" title="Abstract">arXiv:2312.13328</a> [<a href="/pdf/2312.13328" title="Download PDF">pdf</a>, <a href="/format/2312.13328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeLF-Pro: Neural Light Field Probes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Z">Zinuo You</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anpei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For more information, see project webpage <a href="https://sinoyou.github.io/nelf-pro/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present NeLF-Pro, a novel representation for modeling and reconstructing
light fields in diverse natural scenes that vary in extend and spatial
granularity. In contrast to previous fast reconstruction methods that represent
the 3D scene globally, we model the light field of a scene as a set of local
light field feature probes, parameterized with position and multi-channel 2D
feature maps. Our central idea is to bake the scene's light field into
spatially varying learnable representations and to query point features by
weighted blending of probes close to the camera - allowing for mipmap
representation and rendering. We introduce a novel vector-matrix-matrix (VMM)
factorization technique that effectively represents the light field feature
probes as products of core factors (i.e., VM) shared among local feature
probes, and a basis factor (i.e., M) - efficiently encoding internal
relationships and patterns within the scene.Experimentally, we demonstrate that
NeLF-Pro significantly boosts the performance of feature grid-based
representations, and achieves fast reconstruction with better rendering quality
while maintaining compact modeling.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13330" title="Abstract">arXiv:2312.13330</a> [<a href="/pdf/2312.13330" title="Download PDF">pdf</a>, <a href="/format/2312.13330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subject-Oriented Video Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chang Teng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuankai Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guorong Li</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+L">Laiyu Qing</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Describing video content according to users' needs is a long-held goal.
Although existing video captioning methods have made significant progress, the
generated captions may not focus on the entity that users are particularly
interested in. To address this problem, we propose a new video captioning task,
subject-oriented video captioning, which allows users to specify the describing
target via a bounding box. To support this task, we construct two
subject-oriented video captioning datasets based on two widely used video
captioning datasets: MSVD and MSRVTT, by annotating subjects in each video for
each caption. These datasets pave the way for future technique development. As
the first attempt, we evaluate four state-of-the-art general video captioning
models, and have observed a large performance drop. We then explore several
strategies to enable them to describe the desired target. Experimental results
show obvious improvement, but there is still a large room for further
exploration in this field.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13332" title="Abstract">arXiv:2312.13332</a> [<a href="/pdf/2312.13332" title="Download PDF">pdf</a>, <a href="/format/2312.13332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ternary-type Opacity and Hybrid Odometry for RGB-only NeRF-SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nachkov%2C+A">Asen Nachkov</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Songyou Peng</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The opacity of rigid 3D scenes with opaque surfaces is considered to be of a
binary type. However, we observed that this property is not followed by the
existing RGB-only NeRF-SLAM. Therefore, we are motivated to introduce this
prior into the RGB-only NeRF-SLAM pipeline. Unfortunately, the optimization
through the volumetric rendering function does not facilitate easy integration
of the desired prior. Instead, we observed that the opacity of ternary-type
(TT) is well supported. In this work, we study why ternary-type opacity is
well-suited and desired for the task at hand. In particular, we provide
theoretical insights into the process of jointly optimizing radiance and
opacity through the volumetric rendering process. Through exhaustive
experiments on benchmark datasets, we validate our claim and provide insights
into the optimization process, which we believe will unleash the potential of
RGB-only NeRF-SLAM. To foster this line of research, we also propose a simple
yet novel visual odometry scheme that uses a hybrid combination of volumetric
and warping-based image renderings. More specifically, the proposed hybrid
odometry (HO) additionally uses image warping-based coarse odometry, leading up
to an order of magnitude final speed-up. Furthermore, we show that the proposed
TT and HO well complement each other, offering state-of-the-art results on
benchmark datasets in terms of both speed and accuracy.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13334" title="Abstract">arXiv:2312.13334</a> [<a href="/pdf/2312.13334" title="Download PDF">pdf</a>, <a href="/format/2312.13334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparency and Privacy: The Role of Explainable AI and Federated  Learning in Financial Fraud Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Awosika%2C+T">Tomisin Awosika</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+R+M">Raj Mani Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Pranggono%2C+B">Bernardi Pranggono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submitted to a journal for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Fraudulent transactions and how to detect them remain a significant problem
for financial institutions around the world. The need for advanced fraud
detection systems to safeguard assets and maintain customer trust is paramount
for financial institutions, but some factors make the development of effective
and efficient fraud detection systems a challenge. One of such factors is the
fact that fraudulent transactions are rare and that many transaction datasets
are imbalanced; that is, there are fewer significant samples of fraudulent
transactions than legitimate ones. This data imbalance can affect the
performance or reliability of the fraud detection model. Moreover, due to the
data privacy laws that all financial institutions are subject to follow,
sharing customer data to facilitate a higher-performing centralized model is
impossible. Furthermore, the fraud detection technique should be transparent so
that it does not affect the user experience. Hence, this research introduces a
novel approach using Federated Learning (FL) and Explainable AI (XAI) to
address these challenges. FL enables financial institutions to collaboratively
train a model to detect fraudulent transactions without directly sharing
customer data, thereby preserving data privacy and confidentiality. Meanwhile,
the integration of XAI ensures that the predictions made by the model can be
understood and interpreted by human experts, adding a layer of transparency and
trust to the system. Experimental results, based on realistic transaction
datasets, reveal that the FL-based fraud detection system consistently
demonstrates high performance metrics. This study grounds FL's potential as an
effective and privacy-preserving tool in the fight against fraud.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13377" title="Abstract">arXiv:2312.13377</a> [<a href="/pdf/2312.13377" title="Download PDF">pdf</a>, <a href="/format/2312.13377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SADA: Semantic adversarial unsupervised domain adaptation for Temporal  Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pujol-Perich%2C+D">David Pujol-Perich</a>, 
<a href="/search/cs?searchtype=author&query=Clap%C3%A9s%2C+A">Albert Clap&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Temporal Action Localization (TAL) is a complex task that poses relevant
challenges, particularly when attempting to generalize on new -- unseen --
domains in real-world applications. These scenarios, despite realistic, are
often neglected in the literature, exposing these solutions to important
performance degradation. In this work, we tackle this issue by introducing, for
the first time, an approach for Unsupervised Domain Adaptation (UDA) in sparse
TAL, which we refer to as Semantic Adversarial unsupervised Domain Adaptation
(SADA). Our contribution is threefold: (1) we pioneer the development of a
domain adaptation model that operates on realistic sparse action detection
benchmarks; (2) we tackle the limitations of global-distribution alignment
techniques by introducing a novel adversarial loss that is sensitive to local
class distributions, ensuring finer-grained adaptation; and (3) we present a
novel experimental setup, based on EpicKitchens100, that evaluates multiple
types of domain shifts in a comprehensive manner. Our experimental results
indicate that SADA improves the adaptation across domains when compared to
fully supervised state-of-the-art and alternative UDA methods, attaining a
relative performance boost of up to 14%.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13379" title="Abstract">arXiv:2312.13379</a> [<a href="/pdf/2312.13379" title="Download PDF">pdf</a>, <a href="/ps/2312.13379" title="Download PostScript">ps</a>, <a href="/format/2312.13379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling Complexity of Deep Approximation Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdeljawad%2C+A">Ahmed Abdeljawad</a>, 
<a href="/search/cs?searchtype=author&query=Grohs%2C+P">Philipp Grohs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Functional Analysis (math.FA); Machine Learning (stat.ML)

</div>
<p class="mathjax">While it is well-known that neural networks enjoy excellent approximation
capabilities, it remains a big challenge to compute such approximations from
point samples. Based on tools from Information-based complexity, recent work by
Grohs and Voigtlaender [Journal of the FoCM (2023)] developed a rigorous
framework for assessing this so-called "theory-to-practice gap". More
precisely, in that work it is shown that there exist functions that can be
approximated by neural networks with ReLU activation function at an arbitrary
rate while requiring an exponentially growing (in the input dimension) number
of samples for their numerical computation. The present study extends these
findings by showing analogous results for the ReQU activation function.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13380" title="Abstract">arXiv:2312.13380</a> [<a href="/pdf/2312.13380" title="Download PDF">pdf</a>, <a href="/format/2312.13380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-QSSL: A Framework for Personalized Federated Learning under Bitwidth  and Data Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vikalo%2C+H">Haris Vikalo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chianing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted at the 38th AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Motivated by high resource costs of centralized machine learning schemes as
well as data privacy concerns, federated learning (FL) emerged as an efficient
alternative that relies on aggregating locally trained models rather than
collecting clients' potentially private data. In practice, available resources
and data distributions vary from one client to another, creating an inherent
system heterogeneity that leads to deterioration of the performance of
conventional FL algorithms. In this work, we present a federated
quantization-based self-supervised learning scheme (Fed-QSSL) designed to
address heterogeneity in FL systems. At clients' side, to tackle data
heterogeneity we leverage distributed self-supervised learning while utilizing
low-bit quantization to satisfy constraints imposed by local infrastructure and
limited communication resources. At server's side, Fed-QSSL deploys
de-quantization, weighted aggregation and re-quantization, ultimately creating
models personalized to both data distribution as well as specific
infrastructure of each client's device. We validated the proposed algorithm on
real world datasets, demonstrating its efficacy, and theoretically analyzed
impact of low-bit training on the convergence and robustness of the learned
models.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13382" title="Abstract">arXiv:2312.13382</a> [<a href="/pdf/2312.13382" title="Download PDF">pdf</a>, <a href="/ps/2312.13382" title="Download PostScript">ps</a>, <a href="/format/2312.13382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSPy Assertions: Computational Constraints for Self-Refining Language  Model Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhvi%2C+A">Arnav Singhvi</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+M">Manish Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shangyin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+C">Christopher Potts</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+K">Koushik Sen</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Khattab%2C+O">Omar Khattab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Arnav*, Manish*, Shangyin* contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
<p class="mathjax">Chaining language model (LM) calls as composable modules is fueling a new
powerful way of programming. However, ensuring that LMs adhere to important
constraints remains a key challenge, one often addressed with heuristic "prompt
engineering". We introduce LM Assertions, a new programming construct for
expressing computational constraints that LMs should satisfy. We integrate our
constructs into the recent DSPy programming model for LMs, and present new
strategies that allow DSPy to compile programs with arbitrary LM Assertions
into systems that are more reliable and more accurate. In DSPy, LM Assertions
can be integrated at compile time, via automatic prompt optimization, and/or at
inference time, via automatic selfrefinement and backtracking. We report on two
early case studies for complex question answering (QA), in which the LM program
must iteratively retrieve information in multiple hops and synthesize a
long-form answer with citations. We find that LM Assertions improve not only
compliance with imposed rules and guidelines but also enhance downstream task
performance, delivering intrinsic and extrinsic gains up to 35.7% and 13.3%,
respectively. Our reference implementation of LM Assertions is integrated into
DSPy at https://github.com/stanfordnlp/dspy
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13385" title="Abstract">arXiv:2312.13385</a> [<a href="/pdf/2312.13385" title="Download PDF">pdf</a>, <a href="/format/2312.13385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ORBSLAM3-Enhanced Autonomous Toy Drones: Pioneering Indoor Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tukan%2C+M">Murad Tukan</a>, 
<a href="/search/cs?searchtype=author&query=Fares%2C+F">Fares Fares</a>, 
<a href="/search/cs?searchtype=author&query=Grufinkle%2C+Y">Yotam Grufinkle</a>, 
<a href="/search/cs?searchtype=author&query=Talmor%2C+I">Ido Talmor</a>, 
<a href="/search/cs?searchtype=author&query=Mualem%2C+L">Loay Mualem</a>, 
<a href="/search/cs?searchtype=author&query=Braverman%2C+V">Vladimir Braverman</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+D">Dan Feldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Navigating toy drones through uncharted GPS-denied indoor spaces poses
significant difficulties due to their reliance on GPS for location
determination. In such circumstances, the necessity for achieving proper
navigation is a primary concern. In response to this formidable challenge, we
introduce a real-time autonomous indoor exploration system tailored for drones
equipped with a monocular \emph{RGB} camera.
<br />Our system utilizes \emph{ORB-SLAM3}, a state-of-the-art vision feature-based
SLAM, to handle both the localization of toy drones and the mapping of unmapped
indoor terrains. Aside from the practicability of \emph{ORB-SLAM3}, the
generated maps are represented as sparse point clouds, making them prone to the
presence of outlier data. To address this challenge, we propose an outlier
removal algorithm with provable guarantees. Furthermore, our system
incorporates a novel exit detection algorithm, ensuring continuous exploration
by the toy drone throughout the unfamiliar indoor environment. We also
transform the sparse point to ensure proper path planning using existing path
planners.
<br />To validate the efficacy and efficiency of our proposed system, we conducted
offline and real-time experiments on the autonomous exploration of indoor
spaces. The results from these endeavors demonstrate the effectiveness of our
methods.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13394" title="Abstract">arXiv:2312.13394</a> [<a href="/pdf/2312.13394" title="Download PDF">pdf</a>, <a href="/ps/2312.13394" title="Download PostScript">ps</a>, <a href="/format/2312.13394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Forms via Informed Motion, a Flight Inspired Method Based on  Wind and Topography Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>, 
<a href="/search/cs?searchtype=author&query=Sumer%2C+O">Osman Sumer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures. 4th International Symposium - Formal Methods in Architecture, April 3-5, 2017 Porto, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Generative systems are becoming a crucial part of current design practice.
There exist gaps however, between the digital processes, field data and
designer's input. To solve this problem, multiple processes were developed in
order to generate emergent and self-organizing design solutions that combine
the designer's input with surface models acquired via photogrammetry and
generative design tools. Different generative design methods were utilized for
trials, including surface scattering based on UV coordinates, animation
snapshots (similar to long exposure photography) and a particle swarm algorithm
on arbitrary data, interpolated within GIS software. A large volume of adaptive
forms that are complex, yet responsive to changes in parameters, user input,
topography and/or various spatial data were acquired. Resulting outputs were
rendered and projection mapped onto the original physical model and evaluated
for further iterations.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13395" title="Abstract">arXiv:2312.13395</a> [<a href="/pdf/2312.13395" title="Download PDF">pdf</a>, <a href="/format/2312.13395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Optimization Through Innovation: The Multi-Strategy Improved  Black Widow Optimization Algorithm (MSBWOA)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper introduces a Multi-Strategy Improved Black Widow Optimization
Algorithm (MSBWOA), designed to enhance the performance of the standard Black
Widow Algorithm (BW) in solving complex optimization problems. The proposed
algorithm integrates four key strategies: initializing the population using
Tent chaotic mapping to enhance diversity and initial exploratory capability;
implementing mutation optimization on the least fit individuals to maintain
dynamic population and prevent premature convergence; incorporating a
non-linear inertia weight to balance global exploration and local exploitation;
and adding a random perturbation strategy to enhance the algorithm's ability to
escape local optima. Evaluated through a series of standard test functions, the
MSBWOA demonstrates significant performance improvements in various dimensions,
particularly in convergence speed and solution quality. Experimental results
show that compared to the traditional BW algorithm and other existing
optimization methods, the MSBWOA exhibits better stability and efficiency in
handling a variety of optimization problems. These findings validate the
effectiveness of the proposed strategies and offer a new solution approach for
complex optimization challenges.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13396" title="Abstract">arXiv:2312.13396</a> [<a href="/pdf/2312.13396" title="Download PDF">pdf</a>, <a href="/format/2312.13396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPNet: An Efficient Pyramid Network for Enhanced Single-Image  Super-Resolution with Reduced Computational Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinman Park</a>, 
<a href="/search/cs?searchtype=author&query=Fieguth%2C+P">Paul Fieguth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-image super-resolution (SISR) has seen significant advancements
through the integration of deep learning. However, the substantial
computational and memory requirements of existing methods often limit their
practical application. This paper introduces a new Efficient Pyramid Network
(EPNet) that harmoniously merges an Edge Split Pyramid Module (ESPM) with a
Panoramic Feature Extraction Module (PFEM) to overcome the limitations of
existing methods, particularly in terms of computational efficiency. The ESPM
applies a pyramid-based channel separation strategy, boosting feature
extraction while maintaining computational efficiency. The PFEM, a novel fusion
of CNN and Transformer structures, enables the concurrent extraction of local
and global features, thereby providing a panoramic view of the image landscape.
Our architecture integrates the PFEM in a manner that facilitates the
streamlined exchange of feature information and allows for the further
refinement of image texture details. Experimental results indicate that our
model outperforms existing state-of-the-art methods in image resolution
quality, while considerably decreasing computational and memory costs. This
research contributes to the ongoing evolution of efficient and practical SISR
methodologies, bearing broader implications for the field of computer vision.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13398" title="Abstract">arXiv:2312.13398</a> [<a href="/pdf/2312.13398" title="Download PDF">pdf</a>, <a href="/ps/2312.13398" title="Download PostScript">ps</a>, <a href="/format/2312.13398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Systems for Closing Gaps with Rheotomic Surfaces and Allometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, in Turkish language. 9 figures. XII. Computational Design Research in Architecture Symposium, June 21-22, 2018 Isparta, Turkey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">This study aims to present a material based, second order design method that
makes the rapid creation of bridging structures in order to connect two or more
horizontal planes which are currently separated and three design instances
created via such method. The first element of the presented method is a
generative system that creates circulation surfaces through the interpolation
of the curves defined on the current surfaces, and also creates the structural
volumes via rheotomic (minimal) surfaces. The second constituent is the
instantiation of the exposed variable, connected to a displacement algorithm
inspired by allometry based on user input, contextual data, or simulation
results. The method was created with applicability through additive
manufacturing in consideration. The design process - similar to manufacturing -
proceeds in a vertical manner, in order to reduce the generation of support
geometry as much as possible. The system includes a raster data input viable
for simulation results, feeding the accumulation variable in order to modify
material amount or quality with the aim of improving structural performance
where stress is greater. Through the application of the method, three physical
models which connect different horizontal planes were obtained. The models can
be evaluated with digital of physical simulations, and results can be utilized
in an iterative manner, improving the results by each recursion.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13401" title="Abstract">arXiv:2312.13401</a> [<a href="/pdf/2312.13401" title="Download PDF">pdf</a>, <a href="/format/2312.13401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time is Encoded in the Weights of Finetuned Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nylund%2C+K">Kai Nylund</a>, 
<a href="/search/cs?searchtype=author&query=Gururangan%2C+S">Suchin Gururangan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present time vectors, a simple tool to customize language models to new
time periods. Time vectors are created by finetuning a language model on data
from a single time (e.g., a year or month), and then subtracting the weights of
the original pretrained model. This vector specifies a direction in weight
space that, as our experiments show, improves performance on text from that
time period. Time vectors specialized to adjacent time periods appear to be
positioned closer together in a manifold. Using this structure, we interpolate
between time vectors to induce new models that perform better on intervening
and future time periods, without any additional training. We demonstrate the
consistency of our findings across different tasks, domains, model sizes, and
time scales. Our results suggest that time is encoded in the weight space of
finetuned models.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13403" title="Abstract">arXiv:2312.13403</a> [<a href="/pdf/2312.13403" title="Download PDF">pdf</a>, <a href="/format/2312.13403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Packed-Ensemble Surrogate Models for Fluid Flow Estimation Arround  Airfoil Geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalaydjian%2C+A">Anthony Kalaydjian</a>, 
<a href="/search/cs?searchtype=author&query=Balykov%2C+A">Anton Balykov</a>, 
<a href="/search/cs?searchtype=author&query=Semiz%2C+A">Alexi Semiz</a>, 
<a href="/search/cs?searchtype=author&query=Chan-Hon-Tong%2C+A">Adrien Chan-Hon-Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Physical based simulations can be very time and computationally demanding
tasks. One way of accelerating these processes is by making use of data-driven
surrogate models that learn from existing simulations. Ensembling methods are
particularly relevant in this domain as their smoothness properties coincide
with the smoothness of physical phenomena. The drawback is that they can remain
costly. This research project focused on studying Packed-Ensembles that
generalize Deep Ensembles but remain faster to train. Several models have been
trained and compared in terms of multiple important metrics. PE(8,4,1) has been
identified as the clear winner in this particular task, beating down its Deep
Ensemble conterpart while accelerating the training time by 25%.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13410" title="Abstract">arXiv:2312.13410</a> [<a href="/pdf/2312.13410" title="Download PDF">pdf</a>, <a href="/format/2312.13410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shared Affordance-awareness via Augmented Reality for Proactive  Assistance in Human-robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moore%2C+D">Drake Moore</a>, 
<a href="/search/cs?searchtype=author&query=Zolotas%2C+M">Mark Zolotas</a>, 
<a href="/search/cs?searchtype=author&query=Padir%2C+T">Taskin Padir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Enabling humans and robots to collaborate effectively requires purposeful
communication and an understanding of each other's affordances. Prior work in
human-robot collaboration has incorporated knowledge of human affordances,
i.e., their action possibilities in the current context, into autonomous robot
decision-making. This "affordance awareness" is especially promising for
service robots that need to know when and how to assist a person that cannot
independently complete a task. However, robots still fall short in performing
many common tasks autonomously. In this work-in-progress paper, we propose an
augmented reality (AR) framework that bridges the gap in an assistive robot's
capabilities by actively engaging with a human through a shared
affordance-awareness representation. Leveraging the different perspectives from
a human wearing an AR headset and a robot's equipped sensors, we can build a
perceptual representation of the shared environment and model regions of
respective agent affordances. The AR interface can also allow both agents to
communicate affordances with one another, as well as prompt for assistance when
attempting to perform an action outside their affordance region. This paper
presents the main components of the proposed framework and discusses its
potential through a domestic cleaning task experiment.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13412" title="Abstract">arXiv:2312.13412</a> [<a href="/pdf/2312.13412" title="Download PDF">pdf</a>, <a href="/ps/2312.13412" title="Download PostScript">ps</a>, <a href="/format/2312.13412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Efficacy of Online Assessments in Higher Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pogaku%2C+S">Santhosh Pogaku</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This experiment research study examines how traditional assessment methods
such as written tests and presentations compared to the new online tests in
higher education We want to know how the use of the Internet for assessment
affects how well students do and what they learn Custom tests are
individualised just like your regular tests On the other hand online testing
allows students to take the test from anywhere using the internet Were trying
to determine if these student assessment changes make a difference There are
some good things about online testing Students are given greater flexibility
because they can take the exam from home or anywhere they like This can help a
variety of students But there are also challenges such as technology problems
and the need for students to be proficient in the use of technology We will
compare how students do on traditional tests versus online tests We will
examine the statistics and hear what students say about their experiences We
will consider where students come from how comfortable they are with technology
and what they want for learning By conducting this research we hope to help
teachers and schools understand how to assess students in this technological
age and determine what works best for everyone
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13415" title="Abstract">arXiv:2312.13415</a> [<a href="/pdf/2312.13415" title="Download PDF">pdf</a>, <a href="/format/2312.13415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Staircase Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shehadeh%2C+M">Mohannad Shehadeh</a>, 
<a href="/search/cs?searchtype=author&query=Kschischang%2C+F+R">Frank R. Kschischang</a>, 
<a href="/search/cs?searchtype=author&query=Sukmadji%2C+A+Y">Alvin Y. Sukmadji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We generalize staircase codes and tiled diagonal zipper codes, preserving
their key properties while allowing each coded symbol to be protected by
arbitrarily many component codewords rather than only two. This generalization
arises from the marriage of two distinct combinatorial objects: difference
triangle sets and finite-geometric nets, which have typically been applied
separately to code design. We demonstrate one realization of the proposed
codes, obtaining powerful, high-rate, low-error-floor, and low-complexity
coding schemes based on simple iterative syndrome-domain decoding of coupled
Hamming component codes. We anticipate that the proposed codes improve
performance--complexity--latency tradeoffs in high-throughput communications
applications, most notably fiber-optic, in which classical staircase codes and
zipper codes have been applied.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13423" title="Abstract">arXiv:2312.13423</a> [<a href="/pdf/2312.13423" title="Download PDF">pdf</a>, <a href="/format/2312.13423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VADIS -- a VAriable Detection, Interlinking and Summarization system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kartal%2C+Y+S">Yavuz Selim Kartal</a>, 
<a href="/search/cs?searchtype=author&query=Shahid%2C+M+A">Muhammad Ahsan Shahid</a>, 
<a href="/search/cs?searchtype=author&query=Takeshita%2C+S">Sotaro Takeshita</a>, 
<a href="/search/cs?searchtype=author&query=Tsereteli%2C+T">Tornike Tsereteli</a>, 
<a href="/search/cs?searchtype=author&query=Zielinski%2C+A">Andrea Zielinski</a>, 
<a href="/search/cs?searchtype=author&query=Zapilko%2C+B">Benjamin Zapilko</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+P">Philipp Mayr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> It is 4 pages and 2 figures. This paper has recently been accepted by ECIR 2024 Demo Track and this version is the camera-ready version of the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The VADIS system addresses the demand of providing enhanced information
access in the domain of the social sciences. This is achieved by allowing users
to search and use survey variables in context of their underlying research data
and scholarly publications which have been interlinked with each other.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13424" title="Abstract">arXiv:2312.13424</a> [<a href="/pdf/2312.13424" title="Download PDF">pdf</a>, <a href="/ps/2312.13424" title="Download PostScript">ps</a>, <a href="/format/2312.13424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Model Wireless Federated Learning with Downlink Beamforming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Min Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Ben Liang</a>, 
<a href="/search/cs?searchtype=author&query=Afana%2C+A">Ali Afana</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Y">Yahia Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies the design of wireless federated learning (FL) for
simultaneously training multiple machine learning models. We consider round
robin device-model assignment and downlink beamforming for concurrent multiple
model updates. After formulating the joint downlink-uplink transmission
process, we derive the per-model global update expression over communication
rounds, capturing the effect of beamforming and noisy reception. To maximize
the multi-model training convergence rate, we derive an upper bound on the
optimality gap of the global model update and use it to formulate a multi-group
multicast beamforming problem. We show that this problem can be converted to
minimizing the sum of inverse signal-to-interference-plus-noise ratios (SINRs),
which can be solved efficiently by projected gradient descent. Simulation shows
that our proposed multi-model FL solution outperforms other alternatives,
including conventional single-model sequential training and multi-model
zero-forcing beamforming.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13425" title="Abstract">arXiv:2312.13425</a> [<a href="/pdf/2312.13425" title="Download PDF">pdf</a>, <a href="/format/2312.13425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadratic and cubic Lagrange finite elements for mixed Laplace  eigenvalue problems on criss-cross meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+K">Kaibo Hu</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+J">Jiguang Sun</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In [6], it was shown that the linear Lagrange element space on criss-cross
meshes and its divergence exhibit spurious eigenvalues when applied in the
mixed formulation of the Laplace eigenvalue problem, despite satisfying both
the inf-sup condition and ellipticity on the discrete kernel. The lack of a
Fortin interpolation is responsible for the spurious eigenvalues produced by
the linear Lagrange space. In contrast, results in [8] confirm that quartic and
higher-order Lagrange elements do not yield spurious eigenvalues on general
meshes without nearly singular vertices, including criss-cross meshes as a
special case. In this paper, we investigate quadratic and cubic Lagrange
elements on criss-cross meshes. We prove the convergence of discrete
eigenvalues by fitting the Lagrange elements on criss-cross meshes into a
complex and constructing a Fortin interpolation. As a by-product, we construct
bounded commuting projections for the finite element Stokes complex, which
induces isomorphisms between cohomologies of the continuous and discrete
complexes. We provide numerical examples to validate the theoretical results.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13427" title="Abstract">arXiv:2312.13427</a> [<a href="/pdf/2312.13427" title="Download PDF">pdf</a>, <a href="/format/2312.13427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R2D2: Reducing Redundancy and Duplication in Data Lakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Raunak Shah</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+K">Koyel Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+A">Atharv Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Karnam%2C+S+K">Sai Keerthana Karnam</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+D">Dhruv Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Bhosale%2C+S">Shivam Bhosale</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Subrata Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally. 25 pages, accepted to the International Conference on Management of Data (SIGMOD) 2024. \copyright Raunak Shah | ACM 2023. This is the author's version of the work. Not for redistribution. The definitive Version of Record was published in Proceedings of the ACM on Management of Data (PACMMOD), <a href="http://dx.doi.org/10.1145/3626762">this http URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Manag. Data 1, 4, Article 268 (December 2023), 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Enterprise data lakes often suffer from substantial amounts of duplicate and
redundant data, with data volumes ranging from terabytes to petabytes. This
leads to both increased storage costs and unnecessarily high maintenance costs
for these datasets. In this work, we focus on identifying and reducing
redundancy in enterprise data lakes by addressing the problem of 'dataset
containment'. To the best of our knowledge, this is one of the first works that
addresses table-level containment at a large scale.
<br />We propose R2D2: a three-step hierarchical pipeline that efficiently
identifies almost all instances of containment by progressively reducing the
search space in the data lake. It first builds (i) a schema containment graph,
followed by (ii) statistical min-max pruning, and finally, (iii) content level
pruning. We further propose minimizing the total storage and access costs by
optimally identifying redundant datasets that can be deleted (and reconstructed
on demand) while respecting latency constraints.
<br />We implement our system on Azure Databricks clusters using Apache Spark for
enterprise data stored in ADLS Gen2, and on AWS clusters for open-source data.
In contrast to existing modified baselines that are inaccurate or take several
days to run, our pipeline can process an enterprise customer data lake at the
TB scale in approximately 5 hours with high accuracy. We present theoretical
results as well as extensive empirical validation on both enterprise (scale of
TBs) and open-source datasets (scale of MBs - GBs), which showcase the
effectiveness of our pipeline.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13428" title="Abstract">arXiv:2312.13428</a> [<a href="/pdf/2312.13428" title="Download PDF">pdf</a>, <a href="/format/2312.13428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BRYT: Data Rich Analytics Based Computer Architecture for A New Paradigm  of Chip Design to Supplant Moore&#x27;s Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDougall%2C+I">Ian McDougall</a>, 
<a href="/search/cs?searchtype=author&query=Wadle%2C+S">Shayne Wadle</a>, 
<a href="/search/cs?searchtype=author&query=Batchu%2C+H">Harish Batchu</a>, 
<a href="/search/cs?searchtype=author&query=Davies%2C+M">Michael Davies</a>, 
<a href="/search/cs?searchtype=author&query=Sankaralingam%2C+K">Karthikeyan Sankaralingam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">This paper introduces a new paradigm of chip design for the semi-conductor
industry called Data-Rich Analytics Based Computer Architecture (BRYT). The
goal is to enable monitoring chip hardware behavior in the field, at real-time
speeds with no slowdowns, with minimal power overheads and obtain insights on
chip behavior and workloads. The paradigm is motivated by the end of Moore's
Law and Dennard Scaling which necessitates architectural efficiency as the
means for improved capability for the next decade or two. This paper implements
the first version of the paradigm with a system architecture and the concept of
an analYtics Processing Unit (YPU). We perform 4 case studies, and implement an
RTL level prototype. Across the case studies we show a YPU with area overhead
&lt;3% at 7nm, and overall power consumption of &lt;25 mW is able to create
previously inconceivable data PICS stacks of arbitrary programs, evaluating
instruction prefetchers in the wild before deployment, fine-grained
cycle-by-cycle utilization of hardware modules, and histograms of tensor-value
distributions of DL models.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13433" title="Abstract">arXiv:2312.13433</a> [<a href="/pdf/2312.13433" title="Download PDF">pdf</a>, <a href="/format/2312.13433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Distributed Semi-speculative Adaptive Anisotropic Parallel Mesh  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garner%2C+K">Kevin Garner</a>, 
<a href="/search/cs?searchtype=author&query=Tsolakis%2C+C">Christos Tsolakis</a>, 
<a href="/search/cs?searchtype=author&query=Thomadakis%2C+P">Polykarpos Thomadakis</a>, 
<a href="/search/cs?searchtype=author&query=Chrisochoides%2C+N">Nikos Chrisochoides</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, submitted to AIAA Aviation Forum 2024 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This paper presents the foundational elements of a distributed memory method
for mesh generation that is designed to leverage concurrency offered by
large-scale computing. To achieve this goal, meshing functionality is separated
from performance aspects by utilizing a separate entity for each - a shared
memory mesh generation code called CDT3D and PREMA for parallel runtime
support. Although CDT3D is designed for scalability, lessons are presented
regarding additional measures that were taken to enable the code's integration
into the distributed memory method as a black box. In the presented method, an
initial mesh is data decomposed and subdomains are distributed amongst the
nodes of a high-performance computing (HPC) cluster. Meshing operations within
CDT3D utilize a speculative execution model, enabling the strict adaptation of
subdomains' interior elements. Interface elements undergo several iterations of
shifting so that they are adapted when their data dependencies are resolved.
PREMA aids in this endeavor by providing asynchronous message passing between
encapsulations of data, work load balancing, and migration capabilities all
within a globally addressable namespace. PREMA also assists in establishing
data dependencies between subdomains, thus enabling "neighborhoods" of
subdomains to work independently of each other in performing interface shifts
and adaptation. Preliminary results show that the presented method is able to
produce meshes of comparable quality to those generated by the original shared
memory CDT3D code. Given the costly overhead of collective communication seen
by existing state-of-the-art software, relative communication performance of
the presented distributed memory method also shows that its emphasis on
avoiding global synchronization presents a potentially viable solution in
achieving scalability when targeting large configurations of cores.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13434" title="Abstract">arXiv:2312.13434</a> [<a href="/pdf/2312.13434" title="Download PDF">pdf</a>, <a href="/format/2312.13434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-1-to-3: Domain-level Zero-shot Cognitive Diagnosis via One Batch of  Early-bird Students towards Three Diagnostic Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weibo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Linan Yue</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+H">Haoyang Bi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fangzhou Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z+Z+X">Zheng Zhangm Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuanjing He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Cognitive diagnosis seeks to estimate the cognitive states of students by
exploring their logged practice quiz data. It plays a pivotal role in
personalized learning guidance within intelligent education systems. In this
paper, we focus on an important, practical, yet often underexplored task:
domain-level zero-shot cognitive diagnosis (DZCD), which arises due to the
absence of student practice logs in newly launched domains. Recent cross-domain
diagnostic models have been demonstrated to be a promising strategy for DZCD.
These methods primarily focus on how to transfer student states across domains.
However, they might inadvertently incorporate non-transferable information into
student representations, thereby limiting the efficacy of knowledge transfer.
To tackle this, we propose Zero-1-to-3, a domain-level zero-shot cognitive
diagnosis framework via one batch of early-bird students towards three
diagnostic objectives. Our approach initiates with pre-training a diagnosis
model with dual regularizers, which decouples student states into domain-shared
and domain-specific parts. The shared cognitive signals can be transferred to
the target domain, enriching the cognitive priors for the new domain, which
ensures the cognitive state propagation objective. Subsequently, we devise a
strategy to generate simulated practice logs for cold-start students through
analyzing the behavioral patterns from early-bird students, fulfilling the
domain-adaption goal. Consequently, we refine the cognitive states of
cold-start students as diagnostic outcomes via virtual data, aligning with the
diagnosis-oriented goal. Finally, extensive experiments on six real-world
datasets highlight the efficacy of our model for DZCD and its practical
application in question recommendation.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13435" title="Abstract">arXiv:2312.13435</a> [<a href="/pdf/2312.13435" title="Download PDF">pdf</a>, <a href="/format/2312.13435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Markov Games: On Adaptive Decision-Based Attacks and  Defenses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsingenopoulos%2C+I">Ilias Tsingenopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Rimmer%2C+V">Vera Rimmer</a>, 
<a href="/search/cs?searchtype=author&query=Preuveneers%2C+D">Davy Preuveneers</a>, 
<a href="/search/cs?searchtype=author&query=Pierazzi%2C+F">Fabio Pierazzi</a>, 
<a href="/search/cs?searchtype=author&query=Cavallaro%2C+L">Lorenzo Cavallaro</a>, 
<a href="/search/cs?searchtype=author&query=Joosen%2C+W">Wouter Joosen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Despite considerable efforts on making them robust, real-world ML-based
systems remain vulnerable to decision based attacks, as definitive proofs of
their operational robustness have so far proven intractable. The canonical
approach in robustness evaluation calls for adaptive attacks, that is with
complete knowledge of the defense and tailored to bypass it. In this study, we
introduce a more expansive notion of being adaptive and show how attacks but
also defenses can benefit by it and by learning from each other through
interaction. We propose and evaluate a framework for adaptively optimizing
black-box attacks and defenses against each other through the competitive game
they form. To reliably measure robustness, it is important to evaluate against
realistic and worst-case attacks. We thus augment both attacks and the evasive
arsenal at their disposal through adaptive control, and observe that the same
can be done for defenses, before we evaluate them first apart and then jointly
under a multi-agent perspective. We demonstrate that active defenses, which
control how the system responds, are a necessary complement to model hardening
when facing decision-based attacks; then how these defenses can be circumvented
by adaptive attacks, only to finally elicit active and adaptive defenses. We
validate our observations through a wide theoretical and empirical
investigation to confirm that AI-enabled adversaries pose a considerable threat
to black-box ML-based systems, rekindling the proverbial arms race where
defenses have to be AI-enabled too. Succinctly, we address the challenges posed
by adaptive adversaries and develop adaptive defenses, thereby laying out
effective strategies in ensuring the robustness of ML-based systems deployed in
the real-world.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13437" title="Abstract">arXiv:2312.13437</a> [<a href="/pdf/2312.13437" title="Download PDF">pdf</a>, <a href="/format/2312.13437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Model for Aggregating Annotations Across Simple, Complex, and  Multi-Object Annotation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braylan%2C+A">Alexander Braylan</a>, 
<a href="/search/cs?searchtype=author&query=Marabella%2C+M">Madalyn Marabella</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+O">Omar Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Lease%2C+M">Matthew Lease</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research 2023, 78, 901-973
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Human annotations are vital to supervised learning, yet annotators often
disagree on the correct label, especially as annotation tasks increase in
complexity. A strategy to improve label quality is to ask multiple annotators
to label the same item and aggregate their labels. Many aggregation models have
been proposed for categorical or numerical annotation tasks, but far less work
has considered more complex annotation tasks involving open-ended,
multivariate, or structured responses. While a variety of bespoke models have
been proposed for specific tasks, our work is the first to introduce
aggregation methods that generalize across many diverse complex tasks,
including sequence labeling, translation, syntactic parsing, ranking, bounding
boxes, and keypoints. This generality is achieved by devising a task-agnostic
method to model distances between labels rather than the labels themselves.
<br />This article extends our prior work with investigation of three new research
questions. First, how do complex annotation properties impact aggregation
accuracy? Second, how should a task owner navigate the many modeling choices to
maximize aggregation accuracy? Finally, what diagnoses can verify that
aggregation models are specified correctly for the given data? To understand
how various factors impact accuracy and to inform model selection, we conduct
simulation studies and experiments on real, complex datasets. Regarding
testing, we introduce unit tests for aggregation models and present a suite of
such tests to ensure that a given model is not mis-specified and exhibits
expected behavior.
<br />Beyond investigating these research questions above, we discuss the
foundational concept of annotation complexity, present a new aggregation model
as a bridge between traditional models and our own, and contribute a new
semi-supervised learning method for complex label aggregation that outperforms
prior work.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13440" title="Abstract">arXiv:2312.13440</a> [<a href="/pdf/2312.13440" title="Download PDF">pdf</a>, <a href="/format/2312.13440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGAug: Multimodal Geometric Augmentation in Latent Spaces of Image  Deformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+T">Tonmoy Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaomiao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Geometric transformations have been widely used to augment the size of
training images. Existing methods often assume a unimodal distribution of the
underlying transformations between images, which limits their power when data
with multimodal distributions occur. In this paper, we propose a novel model,
Multimodal Geometric Augmentation (MGAug), that for the first time generates
augmenting transformations in a multimodal latent space of geometric
deformations. To achieve this, we first develop a deep network that embeds the
learning of latent geometric spaces of diffeomorphic transformations (a.k.a.
diffeomorphisms) in a variational autoencoder (VAE). A mixture of multivariate
Gaussians is formulated in the tangent space of diffeomorphisms and serves as a
prior to approximate the hidden distribution of image transformations. We then
augment the original training dataset by deforming images using randomly
sampled transformations from the learned multimodal latent space of VAE. To
validate the efficiency of our model, we jointly learn the augmentation
strategy with two distinct domain-specific tasks: multi-class classification on
2D synthetic datasets and segmentation on real 3D brain magnetic resonance
images (MRIs). We also compare MGAug with state-of-the-art transformation-based
image augmentation algorithms. Experimental results show that our proposed
approach outperforms all baselines by significantly improved prediction
accuracy. Our code is publicly available at
https://github.com/tonmoy-hossain/MGAug.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13449" title="Abstract">arXiv:2312.13449</a> [<a href="/pdf/2312.13449" title="Download PDF">pdf</a>, <a href="/format/2312.13449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Lane-Level Maps from Aerial Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaochao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024. Project page: <a href="https://github.com/Jiawei-Yao0812/AerialLaneNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting lane lines from sensors is becoming an increasingly significant
part of autonomous driving systems. However, less development has been made on
high-definition lane-level mapping based on aerial images, which could
automatically build and update offline maps for auto-driving systems. To this
end, our work focuses on extracting fine-level detailed lane lines together
with their topological structures. This task is challenging since it requires
large amounts of data covering different lane types, terrain and regions. In
this paper, we introduce for the first time a large-scale aerial image dataset
built for lane detection, with high-quality polyline lane annotations on
high-resolution images of around 80 kilometers of road. Moreover, we developed
a baseline deep learning lane detection method from aerial images, called
AerialLaneNet, consisting of two stages. The first stage is to produce
coarse-grained results at point level, and the second stage exploits the
coarse-grained results and feature to perform the vertex-matching task,
producing fine-grained lanes with topology. The experiments show our approach
achieves significant improvement compared with the state-of-the-art methods on
our new dataset. Our code and new dataset are available at
https://github.com/Jiawei-Yao0812/AerialLaneNet.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13451" title="Abstract">arXiv:2312.13451</a> [<a href="/pdf/2312.13451" title="Download PDF">pdf</a>, <a href="/format/2312.13451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Factors Controlling Mineralization for Geologic Carbon  Sequestration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pachalieva%2C+A">Aleksandra Pachalieva</a>, 
<a href="/search/cs?searchtype=author&query=Hyman%2C+J+D">Jeffrey D. Hyman</a>, 
<a href="/search/cs?searchtype=author&query=O%27Malley%2C+D">Daniel O&#x27;Malley</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+H">Hari Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+G">Gowri Srinivasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">We perform a set of flow and reactive transport simulations within
three-dimensional fracture networks to learn the factors controlling mineral
reactions. CO$_2$ mineralization requires CO$_2$-laden water, dissolution of a
mineral that then leads to precipitation of a CO$_2$-bearing mineral. Our
discrete fracture networks (DFN) are partially filled with quartz that
gradually dissolves until it reaches a quasi-steady state. At the end of the
simulation, we measure the quartz remaining in each fracture within the domain.
We observe that a small backbone of fracture exists, where the quartz is fully
dissolved which leads to increased flow and transport. However, depending on
the DFN topology and the rate of dissolution, we observe a large variability of
these changes, which indicates an interplay between the fracture network
structure and the impact of geochemical dissolution. In this work, we developed
a machine learning framework to extract the important features that support
mineralization in the form of dissolution. In addition, we use structural and
topological features of the fracture network to predict the remaining quartz
volume in quasi-steady state conditions. As a first step to characterizing
carbon mineralization, we study dissolution with this framework. We studied a
variety of reaction and fracture parameters and their impact on the dissolution
of quartz in fracture networks. We found that the dissolution reaction rate
constant of quartz and the distance to the flowing backbone in the fracture
network are the two most important features that control the amount of quartz
left in the system. For the first time, we use a combination of a finite-volume
reservoir model and graph-based approach to study reactive transport in a
complex fracture network to determine the key features that control
dissolution.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13453" title="Abstract">arXiv:2312.13453</a> [<a href="/pdf/2312.13453" title="Download PDF">pdf</a>, <a href="/ps/2312.13453" title="Download PostScript">ps</a>, <a href="/format/2312.13453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing repeated games with sublinear randomness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arthaud%2C+F">Farid Arthaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the amount of entropy players asymptotically need to play a repeated
normal-form game in a Nash equilibrium. Hub\'a\v{c}ek, Naor, and Ullman
(SAGT'15, TCSys'16) gave sufficient conditions on a game for the minimal amount
of randomness required to be $O(1)$ or $\Omega(n)$ for all players, where $n$
is the number of repetitions. We provide a complete characterization of games
in which there exists Nash equilibria of the repeated game using $O(1)$
randomness, closing an open question posed by Budinich and Fortnow (EC'11) and
Hub\'a\v{c}ek, Naor, and Ullman. Moreover, we show a 0--1 law for randomness in
repeated games, showing that any repeated game either has $O(1)$-randomness
Nash equilibria, or all of its Nash equilibria require $\Omega(n)$ randomness.
Our techniques are general and naturally characterize the payoff space of
sublinear-entropy equilibria, and could be of independent interest to the study
of players with other bounded capabilities in repeated games.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13454" title="Abstract">arXiv:2312.13454</a> [<a href="/pdf/2312.13454" title="Download PDF">pdf</a>, <a href="/format/2312.13454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixEHR-SurG: a joint proportional hazard and guided topic model for  inferring mortality-associated topics from electronic health records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Marelli%2C+A">Ariane Marelli</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+Y">Archer Y. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Objective: To improve survival analysis using EHR data, we aim to develop a
supervised topic model called MixEHR-SurG to simultaneously integrate
heterogeneous EHR data and model survival hazard.
<br />Materials and Methods: Our technical contributions are three-folds: (1)
integrating EHR topic inference with Cox proportional hazards likelihood; (2)
inferring patient-specific topic hyperparameters using the PheCode concepts
such that each topic can be identified with exactly one PheCode-associated
phenotype; (3) multi-modal survival topic inference. This leads to a highly
interpretable survival and guided topic model that can infer PheCode-specific
phenotype topics associated with patient mortality. We evaluated MixEHR-G using
a simulated dataset and two real-world EHR datasets: the Quebec Congenital
Heart Disease (CHD) data consisting of 8,211 subjects with 75,187 outpatient
claim data of 1,767 unique ICD codes; the MIMIC-III consisting of 1,458
subjects with multi-modal EHR records.
<br />Results: Compared to the baselines, MixEHR-G achieved a superior dynamic
AUROC for mortality prediction, with a mean AUROC score of 0.89 in the
simulation dataset and a mean AUROC of 0.645 on the CHD dataset. Qualitatively,
MixEHR-G associates severe cardiac conditions with high mortality risk among
the CHD patients after the first heart failure hospitalization and critical
brain injuries with increased mortality among the MIMIC-III patients after
their ICU discharge.
<br />Conclusion: The integration of the Cox proportional hazards model and EHR
topic inference in MixEHR-SurG led to not only competitive mortality prediction
but also meaningful phenotype topics for systematic survival analysis. The
software is available at GitHub: https://github.com/li-lab-mcgill/MixEHR-SurG.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13455" title="Abstract">arXiv:2312.13455</a> [<a href="/pdf/2312.13455" title="Download PDF">pdf</a>, <a href="/format/2312.13455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Deep Generalized Canonical Correlation Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karakasis%2C+P+A">Paris A. Karakasis</a>, 
<a href="/search/cs?searchtype=author&query=Sidiropoulos%2C+N+D">Nicholas D. Sidiropoulos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Signal Processing, vol. 71, pp. 4392-4406,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Canonical correlation analysis (CCA) is a classic statistical method for
discovering latent co-variation that underpins two or more observed random
vectors. Several extensions and variations of CCA have been proposed that have
strengthened our capabilities in terms of revealing common random factors from
multiview datasets. In this work, we first revisit the most recent
deterministic extensions of deep CCA and highlight the strengths and
limitations of these state-of-the-art methods. Some methods allow trivial
solutions, while others can miss weak common factors. Others overload the
problem by also seeking to reveal what is not common among the views -- i.e.,
the private components that are needed to fully reconstruct each view. The
latter tends to overload the problem and its computational and sample
complexities. Aiming to improve upon these limitations, we design a novel and
efficient formulation that alleviates some of the current restrictions. The
main idea is to model the private components as conditionally independent given
the common ones, which enables the proposed compact formulation. In addition,
we also provide a sufficient condition for identifying the common random
factors. Judicious experiments with synthetic and real datasets showcase the
validity of our claims and the effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13461" title="Abstract">arXiv:2312.13461</a> [<a href="/pdf/2312.13461" title="Download PDF">pdf</a>, <a href="/format/2312.13461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Communication in Federated Learning Using Floating-Point Lossy  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkins%2C+G">Grant Wilkins</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Sheng Di</a>, 
<a href="/search/cs?searchtype=author&query=Calhoun%2C+J+C">Jon C. Calhoun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Underwood%2C+R">Robert Underwood</a>, 
<a href="/search/cs?searchtype=author&query=Cappello%2C+F">Franck Cappello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference submission to ICDCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the expanding realm of machine learning (ML) within edge computing, the
efficient exchange of information in federated learning (FL) environments is
paramount. FL's decentralized nature often leads to significant communication
bottlenecks, particularly in settings where resources are limited. Traditional
data compression techniques, such as quantization and pruning, provide partial
solutions but can compromise model performance or necessitate costly
retraining. Our paper addresses this issue through \textit{FedSZ}, a novel
lossy compression-based FL framework. \textit{FedSZ} is designed to minimize
the size of local model updates without impacting model performance. Our
framework features a compression pipeline integrating data partitioning, lossy
and lossless model parameters, metadata compression, and efficient
serialization. We conduct a thorough evaluation of \textit{FedSZ} utilizing a
variety of lossy compressors, among which SZ2 emerged as the most effective,
consistently performing well across diverse neural network architectures,
including AlexNet, MobileNetV2, and ResNet50, and datasets such as CIFAR-10,
Caltech101, and FMNIST. A relative error bound of 1E-2 balances compression and
data integrity, achieving compression ratios ranging from
$5.55\mbox{--}12.61\times$. Furthermore, we observed that the runtime overhead
introduced by \textit{FedSZ} is minimal, at less than $4.7\%$, compared to a
significant reduction in network transfer times, which we noted to exceed
$13.3\times$ reduction or saving of over $100$s in edge networks operating at
10Mbps. Our findings firmly establish the efficacy of \textit{FedSZ}, offering
valuable insights for achieving an optimal balance between communication
efficiency and model performance in FL settings, particularly in edge computing
environments.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13462" title="Abstract">arXiv:2312.13462</a> [<a href="/pdf/2312.13462" title="Download PDF">pdf</a>, <a href="/format/2312.13462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Do You Mean by Memory? When Engineers Are Lost in the Maze of  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudrjavets%2C+G">Gunnar Kudrjavets</a> (University of Groningen), 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aditya Kumar</a> (Google), 
<a href="/search/cs?searchtype=author&query=Thomas%2C+J">Jeff Thomas</a> (Meta Platforms, Inc.), 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+A">Ayushi Rastogi</a> (University of Groningen)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages. To be published in the 46th International Conference on Software Engineering (ICSE 2024), April 14 - April 20 2024, Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">An accepted practice to decrease applications' memory usage is to reduce the
amount and frequency of memory allocations. Factors such as (a) the prevalence
of out-of-memory (OOM) killers, (b) memory allocations in modern programming
languages done implicitly, (c) overcommitting being a default strategy in the
Linux kernel, and (d) the rise in complexity and terminology related to memory
management makes the existing guidance inefficient. The industry needs detailed
guidelines for optimizing memory usage targeting specific operating systems
(OS) and programming language types.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13463" title="Abstract">arXiv:2312.13463</a> [<a href="/pdf/2312.13463" title="Download PDF">pdf</a>, <a href="/format/2312.13463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Devil Is in the Command Line: Associating the Compiler Flags With  the Binary and Build Metadata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudrjavets%2C+G">Gunnar Kudrjavets</a> (University of Groningen), 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aditya Kumar</a> (Google), 
<a href="/search/cs?searchtype=author&query=Thomas%2C+J">Jeff Thomas</a> (Meta Platforms, Inc.), 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+A">Ayushi Rastogi</a> (University of Groningen)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages. To be published in the 46th International Conference on Software Engineering (ICSE 2024), April 14 - April 20 2024, Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Engineers build large software systems for multiple architectures, operating
systems, and configurations. A set of inconsistent or missing compiler flags
generates code that catastrophically impacts the system's behavior. In the
authors' industry experience, defects caused by an undesired combination of
compiler flags are common in nontrivial software projects. We are unaware of
any build and CI/CD systems that track how the compiler produces a specific
binary in a structured manner. We postulate that a queryable database of how
the compiler compiled and linked the software system will help to detect
defects earlier and reduce the debugging time.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13469" title="Abstract">arXiv:2312.13469</a> [<a href="/pdf/2312.13469" title="Download PDF">pdf</a>, <a href="/format/2312.13469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural feels with neural fields: Visuo-tactile perception for in-hand  manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suresh%2C+S">Sudharshan Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Haozhi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tingfan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Taosha Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pineda%2C+L">Luis Pineda</a>, 
<a href="/search/cs?searchtype=author&query=Lambeta%2C+M">Mike Lambeta</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Kalakrishnan%2C+M">Mrinal Kalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Calandra%2C+R">Roberto Calandra</a>, 
<a href="/search/cs?searchtype=author&query=Kaess%2C+M">Michael Kaess</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+J">Joseph Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Mukadam%2C+M">Mustafa Mukadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 20 figures, 1 table; <a href="https://suddhu.github.io/neural-feels/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">To achieve human-level dexterity, robots must infer spatial awareness from
multimodal sensing to reason over contact interactions. During in-hand
manipulation of novel objects, such spatial awareness involves estimating the
object's pose and shape. The status quo for in-hand perception primarily
employs vision, and restricts to tracking a priori known objects. Moreover,
visual occlusion of objects in-hand is imminent during manipulation, preventing
current systems to push beyond tasks without occlusion. We combine vision and
touch sensing on a multi-fingered hand to estimate an object's pose and shape
during in-hand manipulation. Our method, NeuralFeels, encodes object geometry
by learning a neural field online and jointly tracks it by optimizing a pose
graph problem. We study multimodal in-hand perception in simulation and the
real-world, interacting with different objects via a proprioception-driven
policy. Our experiments show final reconstruction F-scores of $81$% and average
pose drifts of $4.7\,\text{mm}$, further reduced to $2.3\,\text{mm}$ with known
CAD models. Additionally, we observe that under heavy visual occlusion we can
achieve up to $94$% improvements in tracking compared to vision-only methods.
Our results demonstrate that touch, at the very least, refines and, at the very
best, disambiguates visual estimates during in-hand manipulation. We release
our evaluation dataset of 70 experiments, FeelSight, as a step towards
benchmarking in this domain. Our neural representation driven by multimodal
sensing can serve as a perception backbone towards advancing robot dexterity.
Videos can be found on our project website
https://suddhu.github.io/neural-feels/
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13470" title="Abstract">arXiv:2312.13470</a> [<a href="/pdf/2312.13470" title="Download PDF">pdf</a>, <a href="/ps/2312.13470" title="Download PostScript">ps</a>, <a href="/format/2312.13470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coffee: Cost-Effective Edge Caching for 360 Degree Live Video Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tingwei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+T">Tongyu Zong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Houwei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">While live 360 degree video streaming delivers immersive viewing experience,
it poses significant bandwidth and latency challenges for content delivery
networks. Edge servers are expected to play an important role in facilitating
live streaming of 360 degree videos. In this paper, we propose a novel
predictive edge caching algorithm (Coffee) for live 360 degree video that
employ collaborative FoV prediction and predictive tile prefetching to reduce
bandwidth consumption, streaming cost and improve the streaming quality and
robustness. Our light-weight caching algorithms exploit the unique tile
consumption patterns of live 360 degree video streaming to achieve high tile
caching gains. Through extensive experiments driven by real 360 degree video
streaming traces, we demonstrate that edge caching algorithms specifically
designed for live 360 degree video streaming can achieve high streaming cost
savings with small edge cache space consumption. Coffee, guided by viewer FoV
predictions, significantly reduces back-haul traffic up to 76% compared to
state-of-the-art edge caching algorithms. Furthermore, we develop a
transcoding-aware variant (TransCoffee) and evaluate it using comprehensive
experiments, which demonstrate that TransCoffee can achieve 63\% lower cost
compared to state-of-the-art transcoding-aware approaches.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13471" title="Abstract">arXiv:2312.13471</a> [<a href="/pdf/2312.13471" title="Download PDF">pdf</a>, <a href="/format/2312.13471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-VO: Real-Time Sparse Visual Odometry with Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naumann%2C+J">Jens Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Binbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+X">Xingxing Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel monocular visual odometry (VO) system, NeRF-VO, that
integrates learning-based sparse visual odometry for low-latency camera
tracking and a neural radiance scene representation for sophisticated dense
reconstruction and novel view synthesis. Our system initializes camera poses
using sparse visual odometry and obtains view-dependent dense geometry priors
from a monocular depth prediction network. We harmonize the scale of poses and
dense geometry, treating them as supervisory cues to train a neural implicit
scene representation. NeRF-VO demonstrates exceptional performance in both
photometric and geometric fidelity of the scene representation by jointly
optimizing a sliding window of keyframed poses and the underlying dense
geometry, which is accomplished through training the radiance field with volume
rendering. We surpass state-of-the-art methods in pose estimation accuracy,
novel view synthesis fidelity, and dense reconstruction quality across a
variety of synthetic and real-world datasets, while achieving a higher camera
tracking frequency and consuming less GPU memory.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13476" title="Abstract">arXiv:2312.13476</a> [<a href="/pdf/2312.13476" title="Download PDF">pdf</a>, <a href="/format/2312.13476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fortify Your Defenses: Strategic Budget Allocation to Enhance Power Grid  Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyur%2C+R">Rounak Meyur</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+S">Sumit Purohit</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+B+K">Braden K. Webb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, AICS workshop paper at the AAAI 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">The abundance of cyber-physical components in modern day power grid with
their diverse hardware and software vulnerabilities has made it difficult to
protect them from advanced persistent threats (APTs). An attack graph depicting
the propagation of potential cyber-attack sequences from the initial access
point to the end objective is vital to identify critical weaknesses of any
cyber-physical system. A cyber security personnel can accordingly plan
preventive mitigation measures for the identified weaknesses addressing the
cyber-attack sequences. However, limitations on available cybersecurity budget
restrict the choice of mitigation measures. We address this aspect through our
framework, which solves the following problem: given potential cyber-attack
sequences for a cyber-physical component in the power grid, find the optimal
manner to allocate an available budget to implement necessary preventive
mitigation measures. We formulate the problem as a mixed integer linear program
(MILP) to identify the optimal budget partition and set of mitigation measures
which minimize the vulnerability of cyber-physical components to potential
attack sequences. We assume that the allocation of budget affects the efficacy
of the mitigation measures. We show how altering the budget allocation for
tasks such as asset management, cybersecurity infrastructure improvement,
incident response planning and employee training affects the choice of the
optimal set of preventive mitigation measures and modifies the associated
cybersecurity risk. The proposed framework can be used by cyber policymakers
and system owners to allocate optimal budgets for various tasks required to
improve the overall security of a cyber-physical system.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13480" title="Abstract">arXiv:2312.13480</a> [<a href="/pdf/2312.13480" title="Download PDF">pdf</a>, <a href="/format/2312.13480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InvertibleNetworks.jl: A Julia package for scalable normalizing flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orozco%2C+R">Rafael Orozco</a>, 
<a href="/search/cs?searchtype=author&query=Witte%2C+P">Philipp Witte</a>, 
<a href="/search/cs?searchtype=author&query=Louboutin%2C+M">Mathias Louboutin</a>, 
<a href="/search/cs?searchtype=author&query=Siahkoohi%2C+A">Ali Siahkoohi</a>, 
<a href="/search/cs?searchtype=author&query=Rizzuti%2C+G">Gabrio Rizzuti</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+B">Bas Peters</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+F+J">Felix J. Herrmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Open Source Software (JOSS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">InvertibleNetworks.jl is a Julia package designed for the scalable
implementation of normalizing flows, a method for density estimation and
sampling in high-dimensional distributions. This package excels in memory
efficiency by leveraging the inherent invertibility of normalizing flows, which
significantly reduces memory requirements during backpropagation compared to
existing normalizing flow packages that rely on automatic differentiation
frameworks. InvertibleNetworks.jl has been adapted for diverse applications,
including seismic imaging, medical imaging, and CO2 monitoring, demonstrating
its effectiveness in learning high-dimensional distributions.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13485" title="Abstract">arXiv:2312.13485</a> [<a href="/pdf/2312.13485" title="Download PDF">pdf</a>, <a href="/format/2312.13485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Duration Generalization for Exact Multi-Agent Collective  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rame%C5%A1%2C+M">Martin Rame&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Surynek%2C+P">Pavel Surynek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, ICAART 2024 extension
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This paper addresses exact approaches to multi-agent collective construction
problem which tasks a group of cooperative agents to build a given structure in
a blocksworld under the gravity constraint. We propose a generalization of the
existing exact model based on mixed integer linear programming by accommodating
varying agent action durations. We refer to the model as a fraction-time model.
The generalization by introducing action duration enables one to create a more
realistic model for various domains. It provides a significant reduction of
plan execution duration at the cost of increased computational time, which
rises steeply the closer the model gets to the exact real-world action
duration. We also propose a makespan estimation function for the fraction-time
model. This can be used to estimate the construction time reduction size for
the purpose of cost-benefit analysis. The fraction-time model and the makespan
estimation function have been evaluated in a series of experiments using a set
of benchmark structures. The results show a significant reduction of plan
execution duration for non-constant duration actions due to decreasing
synchronization overhead at the end of each action. According to the results,
the makespan estimation function provides a reasonably accurate estimate of the
makespan.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13486" title="Abstract">arXiv:2312.13486</a> [<a href="/pdf/2312.13486" title="Download PDF">pdf</a>, <a href="/format/2312.13486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learning with Versatile Loss Geometries for Fast Adaptation Using  Mirror Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yilang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Giannakis%2C+G+B">Georgios B. Giannakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Utilizing task-invariant prior knowledge extracted from related tasks,
meta-learning is a principled framework that empowers learning a new task
especially when data records are limited. A fundamental challenge in
meta-learning is how to quickly "adapt" the extracted prior in order to train a
task-specific model within a few optimization steps. Existing approaches deal
with this challenge using a preconditioner that enhances convergence of the
per-task training process. Though effective in representing locally a quadratic
training loss, these simple linear preconditioners can hardly capture complex
loss geometries. The present contribution addresses this limitation by learning
a nonlinear mirror map, which induces a versatile distance metric to enable
capturing and optimizing a wide range of loss geometries, hence facilitating
the per-task training. Numerical tests on few-shot learning datasets
demonstrate the superior expressiveness and convergence of the advocated
approach.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13487" title="Abstract">arXiv:2312.13487</a> [<a href="/pdf/2312.13487" title="Download PDF">pdf</a>, <a href="/format/2312.13487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Estimating Domain Complexity Across Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doctor%2C+K">Katarina Doctor</a>, 
<a href="/search/cs?searchtype=author&query=Kejriwal%2C+M">Mayank Kejriwal</a>, 
<a href="/search/cs?searchtype=author&query=Holder%2C+L">Lawrence Holder</a>, 
<a href="/search/cs?searchtype=author&query=Kildebeck%2C+E">Eric Kildebeck</a>, 
<a href="/search/cs?searchtype=author&query=Resmini%2C+E">Emma Resmini</a>, 
<a href="/search/cs?searchtype=author&query=Pereyda%2C+C">Christopher Pereyda</a>, 
<a href="/search/cs?searchtype=author&query=Steininger%2C+R+J">Robert J. Steininger</a>, 
<a href="/search/cs?searchtype=author&query=Oliven%C3%A7a%2C+D+V">Daniel V. Oliven&#xe7;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 13 figures, 7 tables. arXiv admin note: substantial text overlap with <a href="/abs/2303.04141">arXiv:2303.04141</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial Intelligence (AI) systems, trained in controlled environments,
often struggle in real-world complexities. We propose a general framework for
estimating domain complexity across diverse environments, like open-world
learning and real-world applications. This framework distinguishes between
intrinsic complexity (inherent to the domain) and extrinsic complexity
(dependent on the AI agent). By analyzing dimensionality, sparsity, and
diversity within these categories, we offer a comprehensive view of domain
challenges. This approach enables quantitative predictions of AI difficulty
during environment transitions, avoids bias in novel situations, and helps
navigate the vast search spaces of open-world domains.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13489" title="Abstract">arXiv:2312.13489</a> [<a href="/pdf/2312.13489" title="Download PDF">pdf</a>, <a href="/ps/2312.13489" title="Download PostScript">ps</a>, <a href="/format/2312.13489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded Shape Matching in Photogrammetry Data for Modeling Making  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zkar%2C+M">Mine &#xd6;zkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, in Turkish language. 6 figures. In: MSTAS 2019 - (XIII. Computational Design in Architecture National Symposium) pp. 313-326., Kocaeli, Turkey (2019)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In three-dimensional models obtained by photogrammetry of existing
structures, all of the shapes that the eye can select cannot always find their
equivalents in the geometric components of the model. However, the matching of
meaningful parts and assemblages with the records acquired with rapid and
detailed documentation methods will provide an advantage for the creation of
information models of existing structures. While aiming to produce answers to
this problem and in order to overcome the difficulties of pattern recognition
in three-dimensional models, we used two-dimensional samples obtained by
projection. Processing techniques such as ambient occlusion, curvature and
normal maps are commonly used in modern computer graphics applications that
enable the representation of three-dimensional surface properties in
two-dimensional data sets. The method we propose is based on the recognition of
patterns through these mappings instead of the usual light-based visualization.
The first stage of the application is photogrammetric capture of a few examples
of Zeugma mosaics and three-dimensional digital modeling of a set of Seljuk era
brick walls based on knowledge obtained through architectural history
literature. The second stage covers the creation of digital models byprocessing
the surface representation obtained from this data using Alice Vision,
OpenCV-Python, and Autodesk Maya to include information on aspects of the
making of the walls. What is envisioned for the next stages is that the mapping
data contributes and supports the knowledge for rule-based design and making
processesof cultural heritage.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13490" title="Abstract">arXiv:2312.13490</a> [<a href="/pdf/2312.13490" title="Download PDF">pdf</a>, <a href="/ps/2312.13490" title="Download PostScript">ps</a>, <a href="/format/2312.13490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension-Accuracy Tradeoffs in Contrastive Embeddings for Triplets,  Terminals &amp; Top-k Nearest Neighbors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatziafratis%2C+V">Vaggos Chatziafratis</a>, 
<a href="/search/cs?searchtype=author&query=Indyk%2C+P">Piotr Indyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened for arxiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Metric embeddings traditionally study how to map $n$ items to a target metric
space such that distance lengths are not heavily distorted; but what if we only
care to preserve the relative order of the distances (and not their length)? In
this paper, we are motivated by the following basic question: given triplet
comparisons of the form ``item $i$ is closer to item $j$ than to item $k$,''
can we find low-dimensional Euclidean representations for the $n$ items that
respect those distance comparisons? Such order-preserving embeddings naturally
arise in important applications and have been studied since the 1950s, under
the name of ordinal or non-metric embeddings. Our main results are:
<br />1. Nearly-Tight Bounds on Triplet Dimension: We introduce the natural concept
of triplet dimension of a dataset, and surprisingly, we show that in order for
an ordinal embedding to be triplet-preserving, its dimension needs to grow as
$\frac n2$ in the worst case. This is optimal (up to constant) as $n-1$
dimensions always suffice.
<br />2. Tradeoffs for Dimension vs (Ordinal) Relaxation: We then relax the
requirement that every triplet should be exactly preserved and present almost
tight lower bounds for the maximum ratio between distances whose relative order
was inverted by the embedding; this ratio is known as (ordinal) relaxation in
the literature and serves as a counterpart to (metric) distortion.
<br />3. New Bounds on Terminal and Top-$k$-NNs Embeddings: Going beyond triplets,
we then study two well-motivated scenarios where we care about preserving
specific sets of distances (not necessarily triplets). The first scenario is
Terminal Ordinal Embeddings and the second scenario is top-$k$-NNs Ordinal
Embeddings.
<br />To the best of our knowledge, these are some of the first tradeoffs on
triplet-preserving ordinal embeddings and the first study of Terminal and
Top-$k$-NNs Ordinal Embeddings.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13492" title="Abstract">arXiv:2312.13492</a> [<a href="/pdf/2312.13492" title="Download PDF">pdf</a>, <a href="/ps/2312.13492" title="Download PostScript">ps</a>, <a href="/format/2312.13492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Support Vector Machine For Transient Stability Assessment: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shahzad%2C+U">Umair Shahzad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Accurate transient stability assessment is a crucial prerequisite for proper
power system operation and planning with various operational constraints.
Transient stability assessment of modern power systems is becoming very
challenging due to rising uncertainty and continuous integration of renewable
energy generation. The stringent requirements of very high accuracy and fast
computation speed has further necessitated accurate transient stability
assessment for power system planning and operation. The traditional approaches
are unable to fulfil these requirements due to their shortcomings. In this
regard, the popularity of prospective approaches based on big data and machine
learning, such as support vector machine, is constantly on the rise as they
have all the features required to fulfil important criteria for real-time TSA.
Therefore, this paper aims to review the application of support vector machine
for transient stability assessment of power systems. It is believed that this
work will provide a solid foundation for researchers in the domain of machine
learning and computational intelligence-based applications to power system
stability and operation.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13494" title="Abstract">arXiv:2312.13494</a> [<a href="/pdf/2312.13494" title="Download PDF">pdf</a>, <a href="/format/2312.13494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Tomography: Physically Faithful Volumetric Models of Partially  Translucent Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakath%2C+D">David Nakath</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+X">Xiangyu Weng</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+M">Mengkun She</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6ser%2C+K">Kevin K&#xf6;ser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at 3DV '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When created faithfully from real-world data, Digital 3D representations of
objects can be useful for human or computer-assisted analysis. Such models can
also serve for generating training data for machine learning approaches in
settings where data is difficult to obtain or where too few training data
exists, e.g. by providing novel views or images in varying conditions. While
the vast amount of visual 3D reconstruction approaches focus on non-physical
models, textured object surfaces or shapes, in this contribution we propose a
volumetric reconstruction approach that obtains a physical model including the
interior of partially translucent objects such as plankton or insects. Our
technique photographs the object under different poses in front of a bright
white light source and computes absorption and scattering per voxel. It can be
interpreted as visual tomography that we solve by inverse raytracing. We
additionally suggest a method to convert non-physical NeRF media into a
physically-based volumetric grid for initialization and illustrate the
usefulness of the approach using two real-world plankton validation sets, the
lab-scanned models being finally also relighted and virtually submerged in a
scenario with augmented medium and illumination conditions. Please visit the
project homepage at www.marine.informatik.uni-kiel.de/go/vito
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13495" title="Abstract">arXiv:2312.13495</a> [<a href="/pdf/2312.13495" title="Download PDF">pdf</a>, <a href="/format/2312.13495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Representation and Knowledge for Few-Shot Intent  Classification and Slot Filling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jie Han</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yixiong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruixuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Few-shot intent classification and slot filling are important but challenging
tasks due to the scarcity of finely labeled data. Therefore, current works
first train a model on source domains with sufficiently labeled data, and then
transfer the model to target domains where only rarely labeled data is
available. However, experience transferring as a whole usually suffers from
gaps that exist among source domains and target domains. For instance,
transferring domain-specific-knowledge-related experience is difficult. To
tackle this problem, we propose a new method that explicitly decouples the
transferring of general-semantic-representation-related experience and the
domain-specific-knowledge-related experience. Specifically, for
domain-specific-knowledge-related experience, we design two modules to capture
intent-slot relation and slot-slot relation respectively. Extensive experiments
on Snips and FewJoint datasets show that our method achieves state-of-the-art
performance. The method improves the joint accuracy metric from 27.72% to
42.20% in the 1-shot setting, and from 46.54% to 60.79% in the 5-shot setting.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13500" title="Abstract">arXiv:2312.13500</a> [<a href="/pdf/2312.13500" title="Download PDF">pdf</a>, <a href="/format/2312.13500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Continual Novel Class Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junfeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiahua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In a privacy-focused era, Federated Learning (FL) has emerged as a promising
machine learning technique. However, most existing FL studies assume that the
data distribution remains nearly fixed over time, while real-world scenarios
often involve dynamic and continual changes. To equip FL systems with continual
model evolution capabilities, we focus on an important problem called Federated
Continual Novel Class Learning (FedCN) in this work. The biggest challenge in
FedCN is to merge and align novel classes that are discovered and learned by
different clients without compromising privacy. To address this, we propose a
Global Alignment Learning (GAL) framework that can accurately estimate the
global novel class number and provide effective guidance for local training
from a global perspective, all while maintaining privacy protection.
Specifically, GAL first locates high-density regions in the representation
space through a bi-level clustering mechanism to estimate the novel class
number, with which the global prototypes corresponding to novel classes can be
constructed. Then, GAL uses a novel semantic weighted loss to capture all
possible correlations between these prototypes and the training data for
mitigating the impact of pseudo-label noise and data heterogeneity. Extensive
experiments on various datasets demonstrate GAL's superior performance over
state-of-the-art novel class discovery methods. In particular, GAL achieves
significant improvements in novel-class performance, increasing the accuracy by
5.1% to 10.6% in the case of one novel class learning stage and by 7.8% to
17.9% in the case of two novel class learning stages, without sacrificing
known-class performance. Moreover, GAL is shown to be effective in equipping a
variety of different mainstream FL algorithms with novel class discovery and
learning capability, highlighting its potential for many real-world
applications.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13501" title="Abstract">arXiv:2312.13501</a> [<a href="/pdf/2312.13501" title="Download PDF">pdf</a>, <a href="/ps/2312.13501" title="Download PostScript">ps</a>, <a href="/format/2312.13501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Decision-Objective Loss for Forecast-then-Optimize in Power  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Haipeng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ran Li</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Fei%2C+T">Teng Fei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Forecast-then-optimize is a widely-used framework for decision-making
problems in power systems. Traditionally, statistical losses have been employed
to train forecasting models, but recent research demonstrated that improved
decision utility in downstream optimization tasks can be achieved by using
decision loss as an alternative. However, the implementation of decision loss
in power systems faces challenges in 1) accommodating multi-stage
decision-making problems where upstream optimality cannot guarantee final
optimality; 2) adapting to dynamic environments such as changing parameters and
nature of the problem like continuous or discrete optimization tasks. To this
end, this paper proposes a novel adaptive decision-objective loss (ADOL) to
address the above challenges. Specifically, ADOL first redefines the decision
loss as objective utilities rather than objective loss to eliminate the need to
manually set the optimal decision, thus ensuring the globally optimal decision.
ADOL enables one-off training in a dynamic environment by introducing
additional variables. The differentiability and convexity of ADOL provide
useful gradients for forecasting model training in conjunction with continuous
and discrete optimization tasks. Experiments are conducted for both linear
programming-based and mixed integer linear programming-based power system
two-stage dispatching cases with changing costs, and the results show that the
proposed ADOL is capable of achieving globally optimal decision-making and
adaptability to dynamic environments. The method can be extended to other
multi-stage tasks in complex systems.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13503" title="Abstract">arXiv:2312.13503</a> [<a href="/pdf/2312.13503" title="Download PDF">pdf</a>, <a href="/format/2312.13503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfoVisDial: An Informative Visual Dialogue Dataset by Bridging Large  Multimodal and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bingbing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>, 
<a href="/search/cs?searchtype=author&query=Howe%2C+B">Bill Howe</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we build a visual dialogue dataset, named InfoVisDial, which
provides rich informative answers in each round even with external knowledge
related to the visual content. Different from existing datasets where the
answer is compact and short, InfoVisDial contains long free-form answers with
rich information in each round of dialogue. For effective data collection, the
key idea is to bridge the large-scale multimodal model (e.g., GIT) and the
language models (e.g., GPT-3). GIT can describe the image content even with
scene text, while GPT-3 can generate informative dialogue based on the image
description and appropriate prompting techniques. With such automatic pipeline,
we can readily generate informative visual dialogue data at scale. Then, we ask
human annotators to rate the generated dialogues to filter the low-quality
conversations.Human analyses show that InfoVisDial covers informative and
diverse dialogue topics: $54.4\%$ of the dialogue rounds are related to image
scene texts, and $36.7\%$ require external knowledge. Each round's answer is
also long and open-ended: $87.3\%$ of answers are unique with an average length
of $8.9$, compared with $27.37\%$ and $2.9$ in VisDial. Last, we propose a
strong baseline by adapting the GIT model for the visual dialogue task and
fine-tune the model on InfoVisDial. Hopefully, our work can motivate more
effort on this direction.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13506" title="Abstract">arXiv:2312.13506</a> [<a href="/pdf/2312.13506" title="Download PDF">pdf</a>, <a href="/format/2312.13506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPDGAN: A Generative Adversarial Network based on SPD Manifold Learning  for Automatic Image Colorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mourchid%2C+Y">Youssef Mourchid</a>, 
<a href="/search/cs?searchtype=author&query=Donias%2C+M">Marc Donias</a>, 
<a href="/search/cs?searchtype=author&query=Berthoumieu%2C+Y">Yannick Berthoumieu</a>, 
<a href="/search/cs?searchtype=author&query=Najim%2C+M">Mohamed Najim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper addresses the automatic colorization problem, which converts a
gray-scale image to a colorized one. Recent deep-learning approaches can
colorize automatically grayscale images. However, when it comes to different
scenes which contain distinct color styles, it is difficult to accurately
capture the color characteristics. In this work, we propose a fully automatic
colorization approach based on Symmetric Positive Definite (SPD) Manifold
Learning with a generative adversarial network (SPDGAN) that improves the
quality of the colorization results. Our SPDGAN model establishes an
adversarial game between two discriminators and a generator. The latter is
based on ResNet architecture with few alterations. Its goal is to generate fake
colorized images without losing color information across layers through
residual connections. Then, we employ two discriminators from different
domains. The first one is devoted to the image pixel domain, while the second
one is to the Riemann manifold domain which helps to avoid color misalignment.
Extensive experiments are conducted on the Places365 and COCO-stuff databases
to test the effect of each component of our SPDGAN. In addition, quantitative
and qualitative comparisons with state-of-the-art methods demonstrate the
effectiveness of our model by achieving more realistic colorized images with
less artifacts visually, and good results of PSNR, SSIM, and FID values.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13508" title="Abstract">arXiv:2312.13508</a> [<a href="/pdf/2312.13508" title="Download PDF">pdf</a>, <a href="/format/2312.13508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Federated Learning with Missing Modality via Prototype Mask  and Contrast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+G">Guangyin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Duoqian Miao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zixuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In real-world scenarios, multimodal federated learning often faces the
practical challenge of intricate modality missing, which poses constraints on
building federated frameworks and significantly degrades model inference
accuracy. Existing solutions for addressing missing modalities generally
involve developing modality-specific encoders on clients and training modality
fusion modules on servers. However, these methods are primarily constrained to
specific scenarios with either unimodal clients or complete multimodal clients,
struggling to generalize effectively in the intricate modality missing
scenarios. In this paper, we introduce a prototype library into the
FedAvg-based Federated Learning framework, thereby empowering the framework
with the capability to alleviate the global model performance degradation
resulting from modality missing during both training and testing. The proposed
method utilizes prototypes as masks representing missing modalities to
formulate a task-calibrated training loss and a model-agnostic uni-modality
inference strategy. In addition, a proximal term based on prototypes is
constructed to enhance local training. Experimental results demonstrate the
state-of-the-art performance of our approach. Compared to the baselines, our
method improved inference accuracy by 3.7\% with 50\% modality missing during
training and by 23.8\% during uni-modality inference. Code is available at
https://github.com/BaoGuangYin/PmcmFL.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13509" title="Abstract">arXiv:2312.13509</a> [<a href="/pdf/2312.13509" title="Download PDF">pdf</a>, <a href="/format/2312.13509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MR-STGN: Multi-Residual Spatio Temporal Graph Network Using Attention  Fusion for Patient Action Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mourchid%2C+Y">Youssef Mourchid</a>, 
<a href="/search/cs?searchtype=author&query=Slama%2C+R">Rim Slama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate assessment of patient actions plays a crucial role in healthcare as
it contributes significantly to disease progression monitoring and treatment
effectiveness. However, traditional approaches to assess patient actions often
rely on manual observation and scoring, which are subjective and
time-consuming. In this paper, we propose an automated approach for patient
action assessment using a Multi-Residual Spatio Temporal Graph Network
(MR-STGN) that incorporates both angular and positional 3D skeletons. The
MR-STGN is specifically designed to capture the spatio-temporal dynamics of
patient actions. It achieves this by integrating information from multiple
residual layers, with each layer extracting features at distinct levels of
abstraction. Furthermore, we integrate an attention fusion mechanism into the
network, which facilitates the adaptive weighting of various features. This
empowers the model to concentrate on the most pertinent aspects of the
patient's movements, offering precise instructions regarding specific body
parts or movements that require attention. Ablation studies are conducted to
analyze the impact of individual components within the proposed model. We
evaluate our model on the UI-PRMD dataset demonstrating its performance in
accurately predicting real-time patient action scores, surpassing
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13510" title="Abstract">arXiv:2312.13510</a> [<a href="/pdf/2312.13510" title="Download PDF">pdf</a>, <a href="/format/2312.13510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moving a Derivation Along a Derivation Preserves the Spine in Adhesive  High-level Replacement Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kreowski%2C+H">Hans-J&#xf6;rg Kreowski</a>, 
<a href="/search/cs?searchtype=author&query=Lye%2C+A">Aaron Lye</a>, 
<a href="/search/cs?searchtype=author&query=Windhorst%2C+A">Aljoscha Windhorst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper published in the proceedings of the 16th International Conference on Graph Transformation; 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">In this paper, we investigate the relationship between two elementary
operations on derivations in adhesive high-level replacement systems that are
well-known in the context of graph transformation: moving a derivation along a
derivation based on parallel and sequential independence on one hand and
restriction of a derivation with respect to a monomorphism into the start
object on the other hand. Intuitively, a restriction clips off parts of the
start object that are never matched by a rule application throughout the
derivation on the other hand. As main result, it is shown that moving a
derivation preserves its spine being the minimal restriction.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13511" title="Abstract">arXiv:2312.13511</a> [<a href="/pdf/2312.13511" title="Download PDF">pdf</a>, <a href="/format/2312.13511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry-enforcing neural networks with applications to constitutive  modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garanger%2C+K">K&#xe9;vin Garanger</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+J">Julie Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Rimoli%2C+J+J">Julian J. Rimoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">The use of machine learning techniques to homogenize the effective behavior
of arbitrary microstructures has been shown to be not only efficient but also
accurate. In a recent work, we demonstrated how to combine state-of-the-art
micromechanical modeling and advanced machine learning techniques to homogenize
complex microstructures exhibiting non-linear and history dependent behaviors.
The resulting homogenized model, termed smart constitutive law (SCL), enables
the adoption of microstructurally informed constitutive laws into finite
element solvers at a fraction of the computational cost required by traditional
concurrent multiscale approaches. In this work, the capabilities of SCLs are
expanded via the introduction of a novel methodology that enforces material
symmetries at the neuron level, applicable across various neural network
architectures. This approach utilizes tensor-based features in neural networks,
facilitating the concise and accurate representation of symmetry-preserving
operations, and is general enough to be extend to problems beyond constitutive
modeling. Details on the construction of these tensor-based neural networks and
their application in learning constitutive laws are presented for both elastic
and inelastic materials. The superiority of this approach over traditional
neural networks is demonstrated in scenarios with limited data and strong
symmetries, through comprehensive testing on various materials, including
isotropic neo-Hookean materials and tensegrity lattice metamaterials. This work
is concluded by a discussion on the potential of this methodology to discover
symmetry bases in materials and by an outline of future research directions.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13513" title="Abstract">arXiv:2312.13513</a> [<a href="/pdf/2312.13513" title="Download PDF">pdf</a>, <a href="/format/2312.13513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An integrated framework for accelerating reactive flow simulation using  GPU and machine learning models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+R">Runze Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiayang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xinyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z+X">Zhi X. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Recent progress in artificial intelligence (AI) and high-performance
computing (HPC) have brought potentially game-changing opportunities in
accelerating reactive flow simulations. In this study, we introduce an
open-source computational fluid dynamics (CFD) framework that integrates the
strengths of machine learning (ML) and graphics processing unit (GPU) to
demonstrate their combined capability. Within this framework, all computational
operations are solely executed on GPU, including ML-accelerated chemistry
integration, fully-implicit solving of PDEs, and computation of thermal and
transport properties, thereby eliminating the CPU-GPU memory copy overhead.
Optimisations both within the kernel functions and during the kernel launch
process are conducted to enhance computational performance. Strategies such as
static data reorganisation and dynamic data allocation are adopted to reduce
the GPU memory footprint. The computational performance is evaluated in two
turbulent flame benchmarks using quasi-DNS and LES modelling, respectively.
Remarkably, while maintaining a similar level of accuracy to the conventional
CPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall
speedup of over two orders of magnitude for both cases. This result highlights
that high-fidelity turbulent combustion simulation with finite-rate chemistry
that requires normally hundreds of CPUs can now be performed on portable
devices such as laptops with a medium-end GPU.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13514" title="Abstract">arXiv:2312.13514</a> [<a href="/pdf/2312.13514" title="Download PDF">pdf</a>, <a href="/format/2312.13514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking of Feature Interaction for Multi-task Learning on Dense  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hancheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baopu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yancheng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing works generally adopt the encoder-decoder structure for Multi-task
Dense Prediction, where the encoder extracts the task-generic features, and
multiple decoders generate task-specific features for predictions. We observe
that low-level representations with rich details and high-level representations
with abundant task information are not both involved in the multi-task
interaction process. Additionally, low-quality and low-efficiency issues also
exist in current multi-task learning architectures. In this work, we propose to
learn a comprehensive intermediate feature globally from both task-generic and
task-specific features, we reveal an important fact that this intermediate
feature, namely the bridge feature, is a good solution to the above issues.
Based on this, we propose a novel Bridge-Feature-Centirc Interaction (BRFI)
method. A Bridge Feature Extractor (BFE) is designed for the generation of
strong bridge features and Task Pattern Propagation (TPP) is applied to ensure
high-quality task interaction participants. Then a Task-Feature Refiner (TFR)
is developed to refine final task predictions with the well-learned knowledge
from the bridge features. Extensive experiments are conducted on NYUD-v2 and
PASCAL Context benchmarks, and the superior performance shows the proposed
architecture is effective and powerful in promoting different dense prediction
tasks simultaneously.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13519" title="Abstract">arXiv:2312.13519</a> [<a href="/pdf/2312.13519" title="Download PDF">pdf</a>, <a href="/format/2312.13519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Information Embedding in Images with Hybrid Firefly Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nokhwal%2C+S">Sahil Nokhwal</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekharan%2C+M">Manoj Chandrasekharan</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+A">Ankit Chaudhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Various methods have been proposed to secure access to sensitive information
over time, such as the many cryptographic methods in use to facilitate secure
communications on the internet. But other methods like steganography have been
overlooked which may be more suitable in cases where the act of transmission of
sensitive information itself should remain a secret. Multiple techniques that
are commonly discussed for such scenarios suffer from low capacity and high
distortion in the output signal. This research introduces a novel
steganographic approach for concealing a confidential portable document format
(PDF) document within a host image by employing the Hybrid Firefly algorithm
(HFA) proposed to select the pixel arrangement. This algorithm combines two
widely used optimization algorithms to improve their performance. The suggested
methodology utilizes the HFA algorithm to conduct a search for optimal pixel
placements in the spatial domain. The purpose of this search is to accomplish
two main goals: increasing the host image's capacity and reducing distortion.
Moreover, the proposed approach intends to reduce the time required for the
embedding procedure. The findings indicate a decrease in image distortion and
an accelerated rate of convergence in the search process. The resultant
embeddings exhibit robustness against steganalytic assaults, hence rendering
the identification of the embedded data a formidable undertaking.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13526" title="Abstract">arXiv:2312.13526</a> [<a href="/pdf/2312.13526" title="Download PDF">pdf</a>, <a href="/format/2312.13526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Tools for Peak Memory Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Ce Jin</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+M">Manish Purohit</a>, 
<a href="/search/cs?searchtype=author&query=Svitkina%2C+Z">Zoya Svitkina</a>, 
<a href="/search/cs?searchtype=author&query=Vee%2C+E">Erik Vee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+R">Joshua R. Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study scheduling of computation graphs to minimize peak memory
consumption, an increasingly critical task due to the surge in popularity of
large deep-learning models. This problem corresponds to the weighted version of
the classical one-shot black pebbling game. We propose the notion of a dominant
schedule to capture the idea of finding the ``best'' schedule for a subgraph
and introduce new tools to compute and utilize dominant schedules.
Surprisingly, we show that despite the strong requirements, a dominant schedule
exists for any computation graph; and, moreover, that it is possible to compute
the dominant schedule efficiently whenever we can find optimal schedules
efficiently for a particular class of graphs (under mild technical conditions).
<br />We apply these new tools to analyze trees and series-parallel graphs. We show
that the weighted one-shot black pebbling game is strongly NP-complete even
when the graph is an out-tree -- or simpler still, a pumpkin, one of the
simplest series-parallel graphs. On the positive side, we design a
fixed-parameter tractable algorithm to find a dominant schedule (hence also a
peak memory minimizing schedule) for series-parallel graphs when parameterized
by the out-degree. This algorithm runs in time $2^{O(d \log d)} \cdot poly(n)$
for series-parallel graphs with $n$ nodes and maximum out-degree $d$; for
pumpkins, we can improve the dependence on $d$ to $O(2^d \cdot poly(n))$.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13527" title="Abstract">arXiv:2312.13527</a> [<a href="/pdf/2312.13527" title="Download PDF">pdf</a>, <a href="/format/2312.13527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindOpt Adapter for CPLEX Benchmarking Performance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wotao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This report provides a comprehensive analysis of the performance of MindOpt
Adapter for CPLEX 12.9 in benchmark testing. CPLEX, recognized as a robust
Mixed Integer Programming (MIP) solver, has faced some scrutiny regarding its
performance on MIPLIB 2017 when configured to default settings. MindOpt Adapter
aims to enhance CPLEX's performance by automatically applying improved
configurations for solving optimization problems. Our testing demonstrates that
MindOpt Adapter for CPLEX yields successfully solved 230 of the 240 problems in
the MIPLIB 2017 benchmark set. This performance surpasses all the other solvers
in terms of the number of problems solved and the geometric mean of running
times. The report provides a comparison of the benchmark results against the
outcomes achieved by CPLEX under its default configuration.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13528" title="Abstract">arXiv:2312.13528</a> [<a href="/pdf/2312.13528" title="Download PDF">pdf</a>, <a href="/format/2312.13528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyBluRF: Dynamic Deblurring Neural Radiance Fields for Blurry Monocular  Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+M+V">Minh-Quan Viet Bui</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongmin Park</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jihyong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Munchurl Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first three authors contributed equally to this work. Please visit our project page at <a href="https://kaist-viclab.github.io/dyblurf-site/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video view synthesis, allowing for the creation of visually appealing frames
from arbitrary viewpoints and times, offers immersive viewing experiences.
Neural radiance fields, particularly NeRF, initially developed for static
scenes, have spurred the creation of various methods for video view synthesis.
However, the challenge for video view synthesis arises from motion blur, a
consequence of object or camera movement during exposure, which hinders the
precise synthesis of sharp spatio-temporal views. In response, we propose a
novel dynamic deblurring NeRF framework for blurry monocular video, called
DyBluRF, consisting of an Interleave Ray Refinement (IRR) stage and a Motion
Decomposition-based Deblurring (MDD) stage. Our DyBluRF is the first that
addresses and handles the novel view synthesis for blurry monocular video. The
IRR stage jointly reconstructs dynamic 3D scenes and refines the inaccurate
camera pose information to combat imprecise pose information extracted from the
given blurry frames. The MDD stage is a novel incremental latent sharp-rays
prediction (ILSP) approach for the blurry monocular video frames by decomposing
the latent sharp rays into global camera motion and local object motion
components. Extensive experimental results demonstrate that our DyBluRF
outperforms qualitatively and quantitatively the very recent state-of-the-art
methods. Our project page including source codes and pretrained model are
publicly available at https://kaist-viclab.github.io/dyblurf-site/.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13530" title="Abstract">arXiv:2312.13530</a> [<a href="/pdf/2312.13530" title="Download PDF">pdf</a>, <a href="/format/2312.13530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HW-V2W-Map: Hardware Vulnerability to Weakness Mapping Framework for  Root Cause Analysis with GPT-assisted Mitigation Suggestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Mamun%2C+M">Muntasir Mamun</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+A">Muhtasim Alam Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shuyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Latibari%2C+B+S">Banafsheh Saber Latibari</a>, 
<a href="/search/cs?searchtype=author&query=Gubbi%2C+K+I">Kevin Immanuel Gubbi</a>, 
<a href="/search/cs?searchtype=author&query=Bavarsad%2C+N+N">Najmeh Nazari Bavarsad</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+A">Arjun Caputo</a>, 
<a href="/search/cs?searchtype=author&query=Sasan%2C+A">Avesta Sasan</a>, 
<a href="/search/cs?searchtype=author&query=Homayoun%2C+H">Houman Homayoun</a>, 
<a href="/search/cs?searchtype=author&query=Rafatirad%2C+S">Setareh Rafatirad</a>, 
<a href="/search/cs?searchtype=author&query=Satam%2C+P">Pratik Satam</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+S">Soheil Salehi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 pages appendix, 10 figures, Submitted to ACM TODAES
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The escalating complexity of modern computing frameworks has resulted in a
surge in the cybersecurity vulnerabilities reported to the National
Vulnerability Database (NVD) by practitioners. Despite the fact that the
stature of NVD is one of the most significant databases for the latest insights
into vulnerabilities, extracting meaningful trends from such a large amount of
unstructured data is still challenging without the application of suitable
technological methodologies. Previous efforts have mostly concentrated on
software vulnerabilities; however, a holistic strategy incorporates approaches
for mitigating vulnerabilities, score prediction, and a knowledge-generating
system that may extract relevant insights from the Common Weakness Enumeration
(CWE) and Common Vulnerability Exchange (CVE) databases is notably absent. As
the number of hardware attacks on Internet of Things (IoT) devices continues to
rapidly increase, we present the Hardware Vulnerability to Weakness Mapping
(HW-V2W-Map) Framework, which is a Machine Learning (ML) framework focusing on
hardware vulnerabilities and IoT security. The architecture that we have
proposed incorporates an Ontology-driven Storytelling framework, which
automates the process of updating the ontology in order to recognize patterns
and evolution of vulnerabilities over time and provides approaches for
mitigating the vulnerabilities. The repercussions of vulnerabilities can be
mitigated as a result of this, and conversely, future exposures can be
predicted and prevented. Furthermore, our proposed framework utilized
Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) to
provide mitigation suggestions.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13533" title="Abstract">arXiv:2312.13533</a> [<a href="/pdf/2312.13533" title="Download PDF">pdf</a>, <a href="/format/2312.13533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Clinical Coding for Outpatient Departments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+V">Viktor Schlegel</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+A+R">Abhinav Ramesh Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh-Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tsung-Han Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V+P">Vijay Prakash Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei-Hsian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Winkle%2C+S">Stefan Winkle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, preprint under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Computerised clinical coding approaches aim to automate the process of
assigning a set of codes to medical records. While there is active research
pushing the state of the art on clinical coding for hospitalized patients, the
outpatient setting -- where doctors tend to non-hospitalised patients -- is
overlooked. Although both settings can be formalised as a multi-label
classification task, they present unique and distinct challenges, which raises
the question of whether the success of inpatient clinical coding approaches
translates to the outpatient setting. This paper is the first to investigate
how well state-of-the-art deep learning-based clinical coding approaches work
in the outpatient setting at hospital scale. To this end, we collect a large
outpatient dataset comprising over 7 million notes documenting over half a
million patients. We adapt four state-of-the-art clinical coding approaches to
this setting and evaluate their potential to assist coders. We find evidence
that clinical coding in outpatient settings can benefit from more innovations
in popular inpatient coding benchmarks. A deeper analysis of the factors
contributing to the success -- amount and form of data and choice of document
representation -- reveals the presence of easy-to-solve examples, the coding of
which can be completely automated with a low error rate.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13536" title="Abstract">arXiv:2312.13536</a> [<a href="/pdf/2312.13536" title="Download PDF">pdf</a>, <a href="/format/2312.13536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptive Graph Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Siyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Ziyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaoxuan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the remarkable accomplishments of graph neural networks (GNNs), they
typically rely on task-specific labels, posing potential challenges in terms of
their acquisition. Existing work have been made to address this issue through
the lens of unsupervised domain adaptation, wherein labeled source graphs are
utilized to enhance the learning process for target data. However, the
simultaneous exploration of graph topology and reduction of domain disparities
remains a substantial hurdle. In this paper, we introduce the Dual Adversarial
Graph Representation Learning (DAGRL), which explore the graph topology from
dual branches and mitigate domain discrepancies via dual adversarial learning.
Our method encompasses a dual-pronged structure, consisting of a graph
convolutional network branch and a graph kernel branch, which enables us to
capture graph semantics from both implicit and explicit perspectives. Moreover,
our approach incorporates adaptive perturbations into the dual branches, which
align the source and target distribution to address domain discrepancies.
Extensive experiments on a wild range graph classification datasets demonstrate
the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13537" title="Abstract">arXiv:2312.13537</a> [<a href="/pdf/2312.13537" title="Download PDF">pdf</a>, <a href="/format/2312.13537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperEditor: Achieving Both Authenticity and Cross-Domain Capability in  Image Editing via Hypernetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chunwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guitao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hailing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Wenming Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Editing real images authentically while also achieving cross-domain editing
remains a challenge. Recent studies have focused on converting real images into
latent codes and accomplishing image editing by manipulating these codes.
However, merely manipulating the latent codes would constrain the edited images
to the generator's image domain, hindering the attainment of diverse editing
goals. In response, we propose an innovative image editing method called
HyperEditor, which utilizes weight factors generated by hypernetworks to
reassign the weights of the pre-trained StyleGAN2's generator. Guided by CLIP's
cross-modal image-text semantic alignment, this innovative approach enables us
to simultaneously accomplish authentic attribute editing and cross-domain style
transfer, a capability not realized in previous methods. Additionally, we
ascertain that modifying only the weights of specific layers in the generator
can yield an equivalent editing result. Therefore, we introduce an adaptive
layer selector, enabling our hypernetworks to autonomously identify the layers
requiring output weight factors, which can further improve our hypernetworks'
efficiency. Extensive experiments on abundant challenging datasets demonstrate
the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13538" title="Abstract">arXiv:2312.13538</a> [<a href="/pdf/2312.13538" title="Download PDF">pdf</a>, <a href="/ps/2312.13538" title="Download PostScript">ps</a>, <a href="/format/2312.13538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Multiuser Scheduling and Power Allocation for Cell-Free  Multiple-Antenna Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mashdour%2C+S">S. Mashdour</a>, 
<a href="/search/cs?searchtype=author&query=Schmeink%2C+A">A. Schmeink</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>, 
<a href="/search/cs?searchtype=author&query=Sales%2C+J+P">J. P. Sales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Resource allocation is a fundamental task in cell-free (CF) massive
multi-input multi-output (MIMO) systems, which can effectively improve the
network performance. In this paper, we study the downlink of CF MIMO networks
with network clustering and linear precoding, and develop a sequential
multiuser scheduling and power allocation scheme. In particular, we present a
multiuser scheduling algorithm based on greedy techniques and a gradient ascent
{(GA)} power allocation algorithm for sum-rate maximization when imperfect
channel state information (CSI) is considered. Numerical results show the
superiority of the proposed sequential scheduling and power allocation scheme
and algorithms to existing approaches while reducing the computational
complexity and the signaling load.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13541" title="Abstract">arXiv:2312.13541</a> [<a href="/pdf/2312.13541" title="Download PDF">pdf</a>, <a href="/format/2312.13541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fuse XORier Lookup Table: Exploration, Implementation, and Revision  of Probabilistic Sets and Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breyer%2C+E">Eric Breyer</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Alan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">This paper presents an exploration, implementations, and revisions of
probabilistic sets and maps, specifically focusing on Bloomier filters and
related data structures. The paper introduces the Fuse XORier Lookup Table
(FXLT), an enhanced version of the Bloomier Filter incorporating spatial
coupling, linear construction, and optimizations. The authors provide
implementations in C and Python, comparing the FXLT's performance with other
data structures like bloom filters, XOR filters, binary fuse filters, hash
tables, and red-black trees. The FXLT demonstrates improvements in both space
and time efficiency over traditional Bloomier Filters and appears competitive
with hash tables for large datasets.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13545" title="Abstract">arXiv:2312.13545</a> [<a href="/pdf/2312.13545" title="Download PDF">pdf</a>, <a href="/ps/2312.13545" title="Download PostScript">ps</a>, <a href="/format/2312.13545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing Interactive Tourism Planning: A Dialogue Robot System Powered  by a Large Language Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+K">Katsumasa Yoshikawa</a>, 
<a href="/search/cs?searchtype=author&query=Yamazaki%2C+T">Takato Yamazaki</a>, 
<a href="/search/cs?searchtype=author&query=Ohagi%2C+M">Masaya Ohagi</a>, 
<a href="/search/cs?searchtype=author&query=Mizumoto%2C+T">Tomoya Mizumoto</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+K">Keiya Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, large language models (LLMs) have rapidly proliferated and
have been utilized in various tasks, including research in dialogue systems. We
aimed to construct a system that not only leverages the flexible conversational
abilities of LLMs but also their advanced planning capabilities to reduce the
speaking load on human interlocutors and efficiently plan trips. Furthermore,
we propose a method that divides the complex task of a travel agency into
multiple subtasks, managing each as a separate phase to effectively accomplish
the task. Our proposed system confirmed a certain level of success by achieving
fourth place in the Dialogue Robot Competition 2023 preliminaries rounds. We
report on the challenges identified through the competition.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13547" title="Abstract">arXiv:2312.13547</a> [<a href="/pdf/2312.13547" title="Download PDF">pdf</a>, <a href="/format/2312.13547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Prune Your Language Model: Recovering Accuracy on the &quot;Sparsity  May Cry&#x27;&#x27; Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurtic%2C+E">Eldar Kurtic</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as oral to CPAL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pruning large language models (LLMs) from the BERT family has emerged as a
standard compression benchmark, and several pruning methods have been proposed
for this task. The recent ``Sparsity May Cry'' (SMC) benchmark put into
question the validity of all existing methods, exhibiting a more complex setup
where many known pruning methods appear to fail. We revisit the question of
accurate BERT-pruning during fine-tuning on downstream datasets, and propose a
set of general guidelines for successful pruning, even on the challenging SMC
benchmark. First, we perform a cost-vs-benefits analysis of pruning model
components, such as the embeddings and the classification head; second, we
provide a simple-yet-general way of scaling training, sparsification and
learning rate schedules relative to the desired target sparsity; finally, we
investigate the importance of proper parametrization for Knowledge Distillation
in the context of LLMs. Our simple insights lead to state-of-the-art results,
both on classic BERT-pruning benchmarks, as well as on the SMC benchmark,
showing that even classic gradual magnitude pruning (GMP) can yield competitive
results, with the right approach.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13554" title="Abstract">arXiv:2312.13554</a> [<a href="/pdf/2312.13554" title="Download PDF">pdf</a>, <a href="/ps/2312.13554" title="Download PostScript">ps</a>, <a href="/format/2312.13554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Lower Bounds for the Metropolis Process and Simulated Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mikulincer%2C+D">Dan Mikulincer</a>, 
<a href="/search/cs?searchtype=author&query=Reichman%2C+D">Daniel Reichman</a>, 
<a href="/search/cs?searchtype=author&query=Wein%2C+A+S">Alexander S. Wein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">The Metropolis process (MP) and Simulated Annealing (SA) are stochastic local
search heuristics that are often used in solving combinatorial optimization
problems. Despite significant interest, there are very few theoretical results
regarding the quality of approximation obtained by MP and SA (with polynomially
many iterations) for NP-hard optimization problems.
<br />We provide rigorous lower bounds for MP and SA with respect to the classical
maximum independent set problem when the algorithms are initialized from the
empty set. We establish the existence of a family of graphs for which both MP
and SA fail to find approximate solutions in polynomial time. More
specifically, we show that for any $\varepsilon \in (0,1)$ there are $n$-vertex
graphs for which the probability SA (when limited to polynomially many
iterations) will approximate the optimal solution within ratio
$\Omega\left(\frac{1}{n^{1-\varepsilon}}\right)$ is exponentially small. Our
lower bounds extend to graphs of constant average degree $d$, illustrating the
failure of MP to achieve an approximation ratio of $\Omega\left(\frac{\log
(d)}{d}\right)$ in polynomial time. In some cases, our impossibility results
also go beyond Simulated Annealing and apply even when the temperature is
chosen adaptively. Finally, we prove time lower bounds when the inputs to these
algorithms are bipartite graphs, and even trees, which are known to admit
polynomial-time algorithms for the independent set problem.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13555" title="Abstract">arXiv:2312.13555</a> [<a href="/pdf/2312.13555" title="Download PDF">pdf</a>, <a href="/format/2312.13555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CR-SAM: Curvature Regularized Sharpness-Aware Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wunsch%2C+D+C">Donald C. Wunsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, main track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The capacity to generalize to future unseen data stands as one of the utmost
crucial attributes of deep neural networks. Sharpness-Aware Minimization (SAM)
aims to enhance the generalizability by minimizing worst-case loss using
one-step gradient ascent as an approximation. However, as training progresses,
the non-linearity of the loss landscape increases, rendering one-step gradient
ascent less effective. On the other hand, multi-step gradient ascent will incur
higher training cost. In this paper, we introduce a normalized Hessian trace to
accurately measure the curvature of loss landscape on {\em both} training and
test sets. In particular, to counter excessive non-linearity of loss landscape,
we propose Curvature Regularized SAM (CR-SAM), integrating the normalized
Hessian trace as a SAM regularizer. Additionally, we present an efficient way
to compute the trace via finite differences with parallelism. Our theoretical
analysis based on PAC-Bayes bounds establishes the regularizer's efficacy in
reducing generalization error. Empirical evaluation on CIFAR and ImageNet
datasets shows that CR-SAM consistently enhances classification performance for
ResNet and Vision Transformer (ViT) models across various datasets. Our code is
available at https://github.com/TrustAIoT/CR-SAM.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13556" title="Abstract">arXiv:2312.13556</a> [<a href="/pdf/2312.13556" title="Download PDF">pdf</a>, <a href="/format/2312.13556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Level Knowledge Distillation for Speech Emotion Recognition in  Noisy Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoqin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Geng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xugang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech emotion recognition (SER) performance deteriorates significantly in
the presence of noise, making it challenging to achieve competitive performance
in noisy conditions. To this end, we propose a multi-level knowledge
distillation (MLKD) method, which aims to transfer the knowledge from a teacher
model trained on clean speech to a simpler student model trained on noisy
speech. Specifically, we use clean speech features extracted by the wav2vec-2.0
as the learning goal and train the distil wav2vec-2.0 to approximate the
feature extraction ability of the original wav2vec-2.0 under noisy conditions.
Furthermore, we leverage the multi-level knowledge of the original wav2vec-2.0
to supervise the single-level output of the distil wav2vec-2.0. We evaluate the
effectiveness of our proposed method by conducting extensive experiments using
five types of noise-contaminated speech on the IEMOCAP dataset, which show
promising results compared to state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13557" title="Abstract">arXiv:2312.13557</a> [<a href="/pdf/2312.13557" title="Download PDF">pdf</a>, <a href="/format/2312.13557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Few-Shot Recommender Systems with Large Language Models --  Enhanced Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhoumeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recommender systems utilizing explicit feedback have witnessed significant
advancements and widespread applications over the past years. However,
generating recommendations in few-shot scenarios remains a persistent
challenge. Recently, large language models (LLMs) have emerged as a promising
solution for addressing natural language processing (NLP) tasks, thereby
offering novel insights into tackling the few-shot scenarios encountered by
explicit feedback-based recommender systems. To bridge recommender systems and
LLMs, we devise a prompting template that generates user and item
representations based on explicit feedback. Subsequently, we integrate these
LLM-processed representations into various recommendation models to evaluate
their significance across diverse recommendation tasks. Our ablation
experiments and case study analysis collectively demonstrate the effectiveness
of LLMs in processing explicit feedback, highlighting that LLMs equipped with
generative and logical reasoning capabilities can effectively serve as a
component of recommender systems to enhance their performance in few-shot
scenarios. Furthermore, the broad adaptability of LLMs augments the
generalization potential of recommender models, despite certain inherent
constraints. We anticipate that our study can inspire researchers to delve
deeper into the multifaceted dimensions of LLMs's involvement in recommender
systems and contribute to the advancement of the explicit feedback-based
recommender systems field.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13558" title="Abstract">arXiv:2312.13558</a> [<a href="/pdf/2312.13558" title="Download PDF">pdf</a>, <a href="/format/2312.13558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Truth is in There: Improving Reasoning in Language Models with  Layer-Selective Rank Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Pratyusha Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Ash%2C+J+T">Jordan T. Ash</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Dipendra Misra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Transformer-based Large Language Models (LLMs) have become a fixture in
modern machine learning. Correspondingly, significant resources are allocated
towards research that aims to further advance this technology, typically
resulting in models of increasing size that are trained on increasing amounts
of data. This work, however, demonstrates the surprising result that it is
often possible to significantly improve the performance of LLMs by selectively
removing higher-order components of their weight matrices. This simple
intervention, which we call LAyer-SElective Rank reduction (LASER), can be done
on a model after training has completed, and requires no additional parameters
or data. We show extensive experiments demonstrating the generality of this
finding across language models and datasets, and provide in-depth analyses
offering insights into both when LASER is effective and the mechanism by which
it operates.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13560" title="Abstract">arXiv:2312.13560</a> [<a href="/pdf/2312.13560" title="Download PDF">pdf</a>, <a href="/format/2312.13560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> kNN-CTC: Enhancing ASR via Retrieval of CTC Pseudo Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiaming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiwan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yong Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The success of retrieval-augmented language models in various natural
language processing (NLP) tasks has been constrained in automatic speech
recognition (ASR) applications due to challenges in constructing fine-grained
audio-text datastores. This paper presents kNN-CTC, a novel approach that
overcomes these challenges by leveraging Connectionist Temporal Classification
(CTC) pseudo labels to establish frame-level audio-text key-value pairs,
circumventing the need for precise ground truth alignments. We further
introduce a skip-blank strategy, which strategically ignores CTC blank frames,
to reduce datastore size. kNN-CTC incorporates a k-nearest neighbors retrieval
mechanism into pre-trained CTC ASR systems, achieving significant improvements
in performance. By incorporating a k-nearest neighbors retrieval mechanism into
pre-trained CTC ASR systems and leveraging a fine-grained, pruned datastore,
kNN-CTC consistently achieves substantial improvements in performance under
various experimental settings. Our code is available at
https://github.com/NKU-HLT/KNN-CTC.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13563" title="Abstract">arXiv:2312.13563</a> [<a href="/pdf/2312.13563" title="Download PDF">pdf</a>, <a href="/format/2312.13563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Efficiency Maximization for Intelligent Surfaces Aided Massive  MIMO with Zero
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Souza+Junior%2C+W">Wilson de Souza Junior</a>, 
<a href="/search/cs?searchtype=author&query=Abrao%2C+T">Taufik Abrao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 9 figures, 3 tables, 37 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we address the energy efficiency (EE) maximization problem in a
downlink communication system utilizing reconfigurable intelligent surface
(RIS) in a multi-user massive multiple-input multiple-output (mMIMO) setup with
zero-forcing (ZF) precoding. The channel between the base station (BS) and RIS
operates under a Rician fading with Rician factor K1. Since systematically
optimizing the RIS phase shifts in each channel coherence time interval is
challenging and burdensome, we employ the statistical channel state information
(CSI)-based optimization strategy to alleviate this overhead. By treating the
RIS phase shifts matrix as a constant over multiple channel coherence time
intervals, we can reduce the computational complexity while maintaining an
interesting performance. Based on an ergodic rate (ER) lower bound closed-form,
the EE optimization problem is formulated. Such a problem is non-convex and
challenging to tackle due to the coupled variables. To circumvent such an
obstacle, we explore the sequential optimization approach where the power
allocation vector p, the number of antennas M, and the RIS phase shifts v are
separated and sequentially solved iteratively until convergence. With the help
of the Lagrangian dual method, fractional programming (FP) techniques, and
Lemma 1, insightful compact closed-form expressions for each of the three
optimization variables are derived. Simulation results validate the
effectiveness of the proposed method across different generalized channel
scenarios, including non-line-of-sight (NLoS) and partially line-of-sight (LoS)
conditions. This underscores its potential to significantly reduce power
consumption, decrease the number of active antennas at the base station, and
effectively incorporate RIS structure in mMIMO communication setup with just
statistical CSI knowledge.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13565" title="Abstract">arXiv:2312.13565</a> [<a href="/pdf/2312.13565" title="Download PDF">pdf</a>, <a href="/format/2312.13565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Curriculum Learning with Gradient Reward Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campbell%2C+R">Ryan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Junsang Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper investigates the impact of using gradient norm reward signals in
the context of Automatic Curriculum Learning (ACL) for deep reinforcement
learning (DRL). We introduce a framework where the teacher model, utilizing the
gradient norm information of a student model, dynamically adapts the learning
curriculum. This approach is based on the hypothesis that gradient norms can
provide a nuanced and effective measure of learning progress. Our experimental
setup involves several reinforcement learning environments (PointMaze, AntMaze,
and AdroitHandRelocate), to assess the efficacy of our method. We analyze how
gradient norm rewards influence the teacher's ability to craft challenging yet
achievable learning sequences, ultimately enhancing the student's performance.
Our results show that this approach not only accelerates the learning process
but also leads to improved generalization and adaptability in complex tasks.
The findings underscore the potential of gradient norm signals in creating more
efficient and robust ACL systems, opening new avenues for research in
curriculum learning and reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13567" title="Abstract">arXiv:2312.13567</a> [<a href="/pdf/2312.13567" title="Download PDF">pdf</a>, <a href="/format/2312.13567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Disentangled Representation Learning for Multimodal Emotion  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoqin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiwan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuechen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yong Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multimodal emotion recognition (MMER) is an active research field that aims
to accurately recognize human emotions by fusing multiple perceptual
modalities. However, inherent heterogeneity across modalities introduces
distribution gaps and information redundancy, posing significant challenges for
MMER. In this paper, we propose a novel fine-grained disentangled
representation learning (FDRL) framework to address these challenges.
Specifically, we design modality-shared and modality-private encoders to
project each modality into modality-shared and modality-private subspaces,
respectively. In the shared subspace, we introduce a fine-grained alignment
component to learn modality-shared representations, thus capturing modal
consistency. Subsequently, we tailor a fine-grained disparity component to
constrain the private subspaces, thereby learning modality-private
representations and enhancing their diversity. Lastly, we introduce a
fine-grained predictor component to ensure that the labels of the output
representations from the encoders remain unchanged. Experimental results on the
IEMOCAP dataset show that FDRL outperforms the state-of-the-art methods,
achieving 78.34% and 79.44% on WAR and UAR, respectively.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13575" title="Abstract">arXiv:2312.13575</a> [<a href="/pdf/2312.13575" title="Download PDF">pdf</a>, <a href="/format/2312.13575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARBiBench: Benchmarking Adversarial Robustness of Binarized Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiehua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bowen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">YingMei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Network binarization exhibits great potential for deployment on
resource-constrained devices due to its low computational cost. Despite the
critical importance, the security of binarized neural networks (BNNs) is rarely
investigated. In this paper, we present ARBiBench, a comprehensive benchmark to
evaluate the robustness of BNNs against adversarial perturbations on CIFAR-10
and ImageNet. We first evaluate the robustness of seven influential BNNs on
various white-box and black-box attacks. The results reveal that 1) The
adversarial robustness of BNNs exhibits a completely opposite performance on
the two datasets under white-box attacks. 2) BNNs consistently exhibit better
adversarial robustness under black-box attacks. 3) Different BNNs exhibit
certain similarities in their robustness performance. Then, we conduct
experiments to analyze the adversarial robustness of BNNs based on these
insights. Our research contributes to inspiring future research on enhancing
the robustness of BNNs and advancing their application in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13578" title="Abstract">arXiv:2312.13578</a> [<a href="/pdf/2312.13578" title="Download PDF">pdf</a>, <a href="/format/2312.13578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DREAM-Talk: Diffusion-based Realistic Emotional Audio-driven Method for  Single Image Talking Face Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guoxian Song</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">You Xie</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaohu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page at <a href="https://magic-research.github.io/dream-talk/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The generation of emotional talking faces from a single portrait image
remains a significant challenge. The simultaneous achievement of expressive
emotional talking and accurate lip-sync is particularly difficult, as
expressiveness is often compromised for the accuracy of lip-sync. As widely
adopted by many prior works, the LSTM network often fails to capture the
subtleties and variations of emotional expressions. To address these
challenges, we introduce DREAM-Talk, a two-stage diffusion-based audio-driven
framework, tailored for generating diverse expressions and accurate lip-sync
concurrently. In the first stage, we propose EmoDiff, a novel diffusion module
that generates diverse highly dynamic emotional expressions and head poses in
accordance with the audio and the referenced emotion style. Given the strong
correlation between lip motion and audio, we then refine the dynamics with
enhanced lip-sync accuracy using audio features and emotion style. To this end,
we deploy a video-to-video rendering module to transfer the expressions and lip
motions from our proxy 3D avatar to an arbitrary portrait. Both quantitatively
and qualitatively, DREAM-Talk outperforms state-of-the-art methods in terms of
expressiveness, lip-sync accuracy and perceptual quality.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13581" title="Abstract">arXiv:2312.13581</a> [<a href="/pdf/2312.13581" title="Download PDF">pdf</a>, <a href="/format/2312.13581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Role of Large Language Models in Personalizing and  Scaffolding Strategies to Combat Academic Procrastination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Ananya Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yuchen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S+Y">Sarah Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kulzhabayeva%2C+D">Dana Kulzhabayeva</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kornfield%2C+R">Rachel Kornfield</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+I">Syed Ishtiaque Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Mariakakis%2C+A">Alex Mariakakis</a>, 
<a href="/search/cs?searchtype=author&query=Czerwinski%2C+M+P">Mary P Czerwinski</a>, 
<a href="/search/cs?searchtype=author&query=Kuzminykh%2C+A">Anastasia Kuzminykh</a>, 
<a href="/search/cs?searchtype=author&query=Liut%2C+M">Michael Liut</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+J+J">Joseph Jay Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Traditional interventions for academic procrastination often fail to capture
the nuanced, individual-specific factors that underlie them. Large language
models (LLMs) hold immense potential for addressing this gap by permitting
open-ended inputs, including the ability to customize interventions to
individuals' unique needs. However, user expectations and potential limitations
of LLMs in this context remain underexplored. To address this, we conducted
interviews and focus group discussions with 15 university students and 6
experts, during which a technology probe for generating personalized advice for
managing procrastination was presented. Our results highlight the necessity for
LLMs to provide structured, deadline-oriented steps and enhanced user support
mechanisms. Additionally, our results surface the need for an adaptive approach
to questioning based on factors like busyness. These findings offer crucial
design implications for the development of LLM-based tools for managing
procrastination while cautioning the use of LLMs for therapeutic guidance.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13583" title="Abstract">arXiv:2312.13583</a> [<a href="/pdf/2312.13583" title="Download PDF">pdf</a>, <a href="/format/2312.13583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning Graph Neural Networks by Preserving Graph Generative  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tianyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiajun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recently, the paradigm of pre-training and fine-tuning graph neural networks
has been intensively studied and applied in a wide range of graph mining tasks.
Its success is generally attributed to the structural consistency between
pre-training and downstream datasets, which, however, does not hold in many
real-world scenarios. Existing works have shown that the structural divergence
between pre-training and downstream graphs significantly limits the
transferability when using the vanilla fine-tuning strategy. This divergence
leads to model overfitting on pre-training graphs and causes difficulties in
capturing the structural properties of the downstream graphs. In this paper, we
identify the fundamental cause of structural divergence as the discrepancy of
generative patterns between the pre-training and downstream graphs.
Furthermore, we propose G-Tuning to preserve the generative patterns of
downstream graphs. Given a downstream graph G, the core idea is to tune the
pre-trained GNN so that it can reconstruct the generative patterns of G, the
graphon W. However, the exact reconstruction of a graphon is known to be
computationally expensive. To overcome this challenge, we provide a theoretical
analysis that establishes the existence of a set of alternative graphons called
graphon bases for any given graphon. By utilizing a linear combination of these
graphon bases, we can efficiently approximate W. This theoretical finding forms
the basis of our proposed model, as it enables effective learning of the
graphon bases and their associated coefficients. Compared with existing
algorithms, G-Tuning demonstrates an average improvement of 0.5% and 2.6% on
in-domain and out-of-domain transfer learning experiments, respectively.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13584" title="Abstract">arXiv:2312.13584</a> [<a href="/pdf/2312.13584" title="Download PDF">pdf</a>, <a href="/format/2312.13584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wave Physics-informed Matrix Factorizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tetali%2C+H+V">Harsha Vardhan Tetali</a>, 
<a href="/search/cs?searchtype=author&query=Harley%2C+J+B">Joel B. Harley</a>, 
<a href="/search/cs?searchtype=author&query=Haeffele%2C+B+D">Benjamin D. Haeffele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2107.09144">arXiv:2107.09144</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">With the recent success of representation learning methods, which includes
deep learning as a special case, there has been considerable interest in
developing techniques that incorporate known physical constraints into the
learned representation. As one example, in many applications that involve a
signal propagating through physical media (e.g., optics, acoustics, fluid
dynamics, etc), it is known that the dynamics of the signal must satisfy
constraints imposed by the wave equation. Here we propose a matrix
factorization technique that decomposes such signals into a sum of components,
where each component is regularized to ensure that it {nearly} satisfies wave
equation constraints. Although our proposed formulation is non-convex, we prove
that our model can be efficiently solved to global optimality. Through this
line of work we establish theoretical connections between wave-informed
learning and filtering theory in signal processing. We further demonstrate the
application of this work on modal analysis problems commonly arising in
structural diagnostics and prognostics.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13585" title="Abstract">arXiv:2312.13585</a> [<a href="/pdf/2312.13585" title="Download PDF">pdf</a>, <a href="/format/2312.13585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech Translation with Large Language Models: An Industrial Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhichao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+T">Tom Ko</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qianqian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shanbo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. 13 pages. Demo: <a href="https://speechtranslation.github.io/llm-st/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Given the great success of large language models (LLMs) across various tasks,
in this paper, we introduce LLM-ST, a novel and effective speech translation
model constructed upon a pre-trained LLM. By integrating the large language
model (LLM) with a speech encoder and employing multi-task instruction tuning,
LLM-ST can produce accurate timestamped transcriptions and translations, even
from long audio inputs. Furthermore, our findings indicate that the
implementation of Chain-of-Thought (CoT) prompting can yield advantages in the
context of LLM-ST. Through rigorous experimentation on English and Chinese
datasets, we showcase the exceptional performance of LLM-ST, establishing a new
benchmark in the field of speech translation. Demo:
https://speechtranslation.github.io/llm-st/.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13592" title="Abstract">arXiv:2312.13592</a> [<a href="/pdf/2312.13592" title="Download PDF">pdf</a>, <a href="/ps/2312.13592" title="Download PostScript">ps</a>, <a href="/format/2312.13592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Optimization of Metaheuristic Algorithms and Federated  Learning for Enhanced Capacity Management and Load Balancing in HetNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S+C">Saimin Chen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This research introduces a revolutionary paradigm for HetNet management,
presenting an innovative algorithmic framework that transcends traditional
notions of network capacity enhancement. Our exploration delves into the
intricate interplay among distinct components, weaving together metaheuristic
algorithms, Neural Networks optimization, and Federated Learning approaches.
The primary focus is on optimizing capacity in IoT-based heterogeneous networks
while ensuring impeccable coverage and data reliability. Employing multi-layer
optimization methods, we propose a dynamic model for optimal transmission
strategy, strategically allocating replicas within cloud computing environments
to curtail data access costs. Our algorithm not only discerns optimal data
replication locations but also navigates the delicate balance between spectral
efficiency and ergodic capacity in cellular IoT networks with small cells using
on/off control. The orchestrated interplay between metaheuristic algorithms,
Neural Networks optimization, and Federated Learning orchestrates resource
reallocation, attaining an optimal balance between spectral efficiency, power
utility, and ergodic capacity based on Quality of Service (QoS) requirements.
Simulation results corroborate the efficacy of our approach, showcasing
enhanced tradeoffs between spectral efficiency and total ergodic capacity with
diminished outage probability compared to prevailing algorithms across diverse
scenarios.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13594" title="Abstract">arXiv:2312.13594</a> [<a href="/pdf/2312.13594" title="Download PDF">pdf</a>, <a href="/format/2312.13594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards More Faithful Natural Language Explanation Using Multi-Level  Contrastive Learning in VQA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Chengen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shengli Song</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shiqi Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Sitong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guangneng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Natural language explanation in visual question answer (VQA-NLE) aims to
explain the decision-making process of models by generating natural language
sentences to increase users' trust in the black-box systems. Existing post-hoc
methods have achieved significant progress in obtaining a plausible
explanation. However, such post-hoc explanations are not always aligned with
human logical inference, suffering from the issues on: 1) Deductive
unsatisfiability, the generated explanations do not logically lead to the
answer; 2) Factual inconsistency, the model falsifies its counterfactual
explanation for answers without considering the facts in images; and 3)
Semantic perturbation insensitivity, the model can not recognize the semantic
changes caused by small perturbations. These problems reduce the faithfulness
of explanations generated by models. To address the above issues, we propose a
novel self-supervised \textbf{M}ulti-level \textbf{C}ontrastive
\textbf{L}earning based natural language \textbf{E}xplanation model (MCLE) for
VQA with semantic-level, image-level, and instance-level factual and
counterfactual samples. MCLE extracts discriminative features and aligns the
feature spaces from explanations with visual question and answer to generate
more consistent explanations. We conduct extensive experiments, ablation
analysis, and case study to demonstrate the effectiveness of our method on two
VQA-NLE benchmarks.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13596" title="Abstract">arXiv:2312.13596</a> [<a href="/pdf/2312.13596" title="Download PDF">pdf</a>, <a href="/ps/2312.13596" title="Download PostScript">ps</a>, <a href="/format/2312.13596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anchoring Path for Inductive Relation Prediction in Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhixiang Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Lizhen Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aiming to accurately predict missing edges representing relations between
entities, which are pervasive in real-world Knowledge Graphs (KGs), relation
prediction plays a critical role in enhancing the comprehensiveness and utility
of KGs. Recent research focuses on path-based methods due to their inductive
and explainable properties. However, these methods face a great challenge when
lots of reasoning paths do not form Closed Paths (CPs) in the KG. To address
this challenge, we propose Anchoring Path Sentence Transformer (APST) by
introducing Anchoring Paths (APs) to alleviate the reliance of CPs.
Specifically, we develop a search-based description retrieval method to enrich
entity descriptions and an assessment mechanism to evaluate the rationality of
APs. APST takes both APs and CPs as the inputs of a unified Sentence
Transformer architecture, enabling comprehensive predictions and high-quality
explanations. We evaluate APST on three public datasets and achieve
state-of-the-art (SOTA) performance in 30 of 36 transductive, inductive, and
few-shot experimental settings.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13597" title="Abstract">arXiv:2312.13597</a> [<a href="/pdf/2312.13597" title="Download PDF">pdf</a>, <a href="/ps/2312.13597" title="Download PostScript">ps</a>, <a href="/format/2312.13597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trochoid Search Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Layeb%2C+A">Abdesslem Layeb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper introduces the Trochoid Search Optimization Algorithm (TSO), a
novel metaheuristic leveraging the mathematical properties of trochoid curves.
The TSO algorithm employs a unique combination of simultaneous translational
and rotational motions inherent in trochoids, fostering a refined equilibrium
between explorative and exploitative search capabilities. Notably, TSO consists
of two pivotal phases global and local search that collectively contribute to
its efficiency and efficacy. Experimental validation demonstrates the TSO
algorithm's remarkable performance across various benchmark functions,
showcasing its competitive edge in balancing exploration and exploitation
within the search space. A distinguishing feature of TSO lies in its
simplicity, marked by a minimal requirement for user-defined parameters, making
it an accessible yet powerful optimization tool.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13602" title="Abstract">arXiv:2312.13602</a> [<a href="/pdf/2312.13602" title="Download PDF">pdf</a>, <a href="/format/2312.13602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peer-to-Peer Learning + Consensus with Non-IID Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pranav%2C+S">Srinivasa Pranav</a>, 
<a href="/search/cs?searchtype=author&query=Moura%2C+J+M+F">Jos&#xe9; M. F. Moura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Asilomar Conference on Signals, Systems, and Computers 2023 Camera-Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Peer-to-peer deep learning algorithms are enabling distributed edge devices
to collaboratively train deep neural networks without exchanging raw training
data or relying on a central server. Peer-to-Peer Learning (P2PL) and other
algorithms based on Distributed Local-Update Stochastic/mini-batch Gradient
Descent (local DSGD) rely on interleaving epochs of training with distributed
consensus steps. This process leads to model parameter drift/divergence amongst
participating devices in both IID and non-IID settings. We observe that model
drift results in significant oscillations in test performance evaluated after
local training and consensus phases. We then identify factors that amplify
performance oscillations and demonstrate that our novel approach, P2PL with
Affinity, dampens test performance oscillations in non-IID settings without
incurring any additional communication cost.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13604" title="Abstract">arXiv:2312.13604</a> [<a href="/pdf/2312.13604" title="Download PDF">pdf</a>, <a href="/format/2312.13604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ponymation: Learning 3D Animal Motions from Unlabeled Online Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Keqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Litvak%2C+D">Dor Litvak</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangzhe Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://keqiangsun.github.io/projects/ponymation.">this https URL</a> The first two authors contributed equally to this work. The last two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Ponymation, a new method for learning a generative model of
articulated 3D animal motions from raw, unlabeled online videos. Unlike
existing approaches for motion synthesis, our model does not require any pose
annotations or parametric shape models for training, and is learned purely from
a collection of raw video clips obtained from the Internet. We build upon a
recent work, MagicPony, which learns articulated 3D animal shapes purely from
single image collections, and extend it on two fronts. First, instead of
training on static images, we augment the framework with a video training
pipeline that incorporates temporal regularizations, achieving more accurate
and temporally consistent reconstructions. Second, we learn a generative model
of the underlying articulated 3D motion sequences via a spatio-temporal
transformer VAE, simply using 2D reconstruction losses without relying on any
explicit pose annotations. At inference time, given a single 2D image of a new
animal instance, our model reconstructs an articulated, textured 3D mesh, and
generates plausible 3D animations by sampling from the learned motion latent
space.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13608" title="Abstract">arXiv:2312.13608</a> [<a href="/pdf/2312.13608" title="Download PDF">pdf</a>, <a href="/format/2312.13608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Argue with Me Tersely: Towards Sentence-Level Counter-Argument  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiayu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Meng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Ruofei Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023, main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Counter-argument generation -- a captivating area in computational
linguistics -- seeks to craft statements that offer opposing views. While most
research has ventured into paragraph-level generation, sentence-level
counter-argument generation beckons with its unique constraints and
brevity-focused challenges. Furthermore, the diverse nature of
counter-arguments poses challenges for evaluating model performance solely
based on n-gram-based metrics. In this paper, we present the ArgTersely
benchmark for sentence-level counter-argument generation, drawing from a
manually annotated dataset from the ChangeMyView debate forum. We also propose
Arg-LlaMA for generating high-quality counter-argument. For better evaluation,
we trained a BERT-based evaluator Arg-Judge with human preference data. We
conducted comparative experiments involving various baselines such as LlaMA,
Alpaca, GPT-3, and others. The results show the competitiveness of our proposed
framework and evaluator in counter-argument generation tasks. Code and data are
available at https://github.com/amazingljy1206/ArgTersely.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13611" title="Abstract">arXiv:2312.13611</a> [<a href="/pdf/2312.13611" title="Download PDF">pdf</a>, <a href="/format/2312.13611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology Learning for Heterogeneous Decentralized Federated Learning  over Unreliable D2D Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheshun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junfan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">With the proliferation of intelligent mobile devices in wireless
device-to-device (D2D) networks, decentralized federated learning (DFL) has
attracted significant interest. Compared to centralized federated learning
(CFL), DFL mitigates the risk of central server failures due to communication
bottlenecks. However, DFL faces several challenges, such as the severe
heterogeneity of data distributions in diverse environments, and the
transmission outages and package errors caused by the adoption of the User
Datagram Protocol (UDP) in D2D networks. These challenges often degrade the
convergence of training DFL models. To address these challenges, we conduct a
thorough theoretical convergence analysis for DFL and derive a convergence
bound. By defining a novel quantity named unreliable links-aware neighborhood
discrepancy in this convergence bound, we formulate a tractable optimization
objective, and develop a novel Topology Learning method considering the
Representation Discrepancy and Unreliable Links in DFL, named ToLRDUL.
Intensive experiments under both feature skew and label skew settings have
validated the effectiveness of our proposed method, demonstrating improved
convergence speed and test accuracy, consistent with our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13614" title="Abstract">arXiv:2312.13614</a> [<a href="/pdf/2312.13614" title="Download PDF">pdf</a>, <a href="/format/2312.13614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Aware Path Inference for Neural Finite State Transducers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weiting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chu-cheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of ICBINB Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Neural finite-state transducers (NFSTs) form an expressive family of
neurosymbolic sequence transduction models. An NFST models each string pair as
having been generated by a latent path in a finite-state transducer. As they
are deep generative models, both training and inference of NFSTs require
inference networks that approximate posterior distributions over such latent
variables. In this paper, we focus on the resulting challenge of imputing the
latent alignment path that explains a given pair of input and output strings
(e.g., during training). We train three autoregressive approximate models for
amortized inference of the path, which can then be used as proposal
distributions for importance sampling. All three models perform lookahead. Our
most sophisticated (and novel) model leverages the FST structure to consider
the graph of future paths; unfortunately, we find that it loses out to the
simpler approaches -- except on an artificial task that we concocted to confuse
the simpler approaches.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13616" title="Abstract">arXiv:2312.13616</a> [<a href="/pdf/2312.13616" title="Download PDF">pdf</a>, <a href="/format/2312.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Structured What-If Spaces: Counterfactual Generation via  Structured Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madaan%2C+N">Nishtha Madaan</a>, 
<a href="/search/cs?searchtype=author&query=Bedathur%2C+S">Srikanta Bedathur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating counterfactual explanations is one of the most effective
approaches for uncovering the inner workings of black-box neural network models
and building user trust. While remarkable strides have been made in generative
modeling using diffusion models in domains like vision, their utility in
generating counterfactual explanations in structured modalities remains
unexplored. In this paper, we introduce Structured Counterfactual Diffuser or
SCD, the first plug-and-play framework leveraging diffusion for generating
counterfactual explanations in structured data. SCD learns the underlying data
distribution via a diffusion model which is then guided at test time to
generate counterfactuals for any arbitrary black-box model, input, and desired
prediction. Our experiments show that our counterfactuals not only exhibit high
plausibility compared to the existing state-of-the-art but also show
significantly better proximity and diversity.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13620" title="Abstract">arXiv:2312.13620</a> [<a href="/pdf/2312.13620" title="Download PDF">pdf</a>, <a href="/format/2312.13620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive End-to-End Computer Vision Framework for Restoration and  Recognition of Low-Quality Engineering Drawings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lvyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiankang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaiqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Longfei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dongyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 13 figures, submitted to Engineering Applications of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The digitization of engineering drawings is crucial for efficient reuse,
distribution, and archiving. Existing computer vision approaches for digitizing
engineering drawings typically assume the input drawings have high quality.
However, in reality, engineering drawings are often blurred and distorted due
to improper scanning, storage, and transmission, which may jeopardize the
effectiveness of existing approaches. This paper focuses on restoring and
recognizing low-quality engineering drawings, where an end-to-end framework is
proposed to improve the quality of the drawings and identify the graphical
symbols on them. The framework uses K-means clustering to classify different
engineering drawing patches into simple and complex texture patches based on
their gray level co-occurrence matrix statistics. Computer vision operations
and a modified Enhanced Super-Resolution Generative Adversarial Network
(ESRGAN) model are then used to improve the quality of the two types of
patches, respectively. A modified Faster Region-based Convolutional Neural
Network (Faster R-CNN) model is used to recognize the quality-enhanced
graphical symbols. Additionally, a multi-stage task-driven collaborative
learning strategy is proposed to train the modified ESRGAN and Faster R-CNN
models to improve the resolution of engineering drawings in the direction that
facilitates graphical symbol recognition, rather than human visual perception.
A synthetic data generation method is also proposed to construct
quality-degraded samples for training the framework. Experiments on real-world
electrical diagrams show that the proposed framework achieves an accuracy of
98.98% and a recall of 99.33%, demonstrating its superiority over previous
approaches. Moreover, the framework is integrated into a widely-used power
system software application to showcase its practicality.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13623" title="Abstract">arXiv:2312.13623</a> [<a href="/pdf/2312.13623" title="Download PDF">pdf</a>, <a href="/format/2312.13623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Rhythmic Trajectories with Geometric Constraints for  Laser-Based Skincare Procedures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+A">Anqing Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liuchen%2C+W">Wanli Liuchen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinsong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Camoriano%2C+R">Raffaello Camoriano</a>, 
<a href="/search/cs?searchtype=author&query=Rosasco%2C+L">Lorenzo Rosasco</a>, 
<a href="/search/cs?searchtype=author&query=Navarro-Alarcon%2C+D">David Navarro-Alarcon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The increasing deployment of robots has significantly enhanced the automation
levels across a wide and diverse range of industries. This paper investigates
the automation challenges of laser-based dermatology procedures in the beauty
industry; This group of related manipulation tasks involves delivering energy
from a cosmetic laser onto the skin with repetitive patterns. To automate this
procedure, we propose to use a robotic manipulator and endow it with the
dexterity of a skilled dermatology practitioner through a
learning-from-demonstration framework. To ensure that the cosmetic laser can
properly deliver the energy onto the skin surface of an individual, we develop
a novel structured prediction-based imitation learning algorithm with the merit
of handling geometric constraints. Notably, our proposed algorithm effectively
tackles the imitation challenges associated with quasi-periodic motions, a
common feature of many laser-based cosmetic tasks. The conducted real-world
experiments illustrate the performance of our robotic beautician in mimicking
realistic dermatological procedures; Our new method is shown to not only
replicate the rhythmic movements from the provided demonstrations but also to
adapt the acquired skills to previously unseen scenarios and subjects.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13625" title="Abstract">arXiv:2312.13625</a> [<a href="/pdf/2312.13625" title="Download PDF">pdf</a>, <a href="/format/2312.13625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Convergence Analysis of GMRES with Weighted Norms, Preconditioning  and Deflation, Leading to a New Deflation Space *
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Spillane%2C+N">Nicole Spillane</a> (CMAP, CNRS), 
<a href="/search/math?searchtype=author&query=Szyld%2C+D+B">Daniel B Szyld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">New convergence bounds are presented for weighted, preconditioned, and
deflated GMRES for the solution of large, sparse, nonsymmetric linear systems,
where it is assumed that the symmetric part of the coefficient matrix is
positive definite. The new bounds are sufficiently explicit to indicate how to
choose the preconditioner and the deflation space to accelerate the
convergence. One such choice of deflating space is presented, and numerical
experiments illustrate the effectiveness of such space.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13628" title="Abstract">arXiv:2312.13628</a> [<a href="/pdf/2312.13628" title="Download PDF">pdf</a>, <a href="/format/2312.13628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where and How to Attack? A Causality-Inspired Recipe for Generating  Counterfactual Adversarial Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruichu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuxuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+J">Jie Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zefeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Furui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have been demonstrated to be vulnerable to
well-crafted \emph{adversarial examples}, which are generated through either
well-conceived $\mathcal{L}_p$-norm restricted or unrestricted attacks.
Nevertheless, the majority of those approaches assume that adversaries can
modify any features as they wish, and neglect the causal generating process of
the data, which is unreasonable and unpractical. For instance, a modification
in income would inevitably impact features like the debt-to-income ratio within
a banking system. By considering the underappreciated causal generating
process, first, we pinpoint the source of the vulnerability of DNNs via the
lens of causality, then give theoretical results to answer \emph{where to
attack}. Second, considering the consequences of the attack interventions on
the current state of the examples to generate more realistic adversarial
examples, we propose CADE, a framework that can generate
\textbf{C}ounterfactual \textbf{AD}versarial \textbf{E}xamples to answer
\emph{how to attack}. The empirical results demonstrate CADE's effectiveness,
as evidenced by its competitive performance across diverse attack scenarios,
including white-box, transfer-based, and random intervention attacks.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13630" title="Abstract">arXiv:2312.13630</a> [<a href="/pdf/2312.13630" title="Download PDF">pdf</a>, <a href="/format/2312.13630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFABA: A More Faithful and Accelerated Boundary-based Attribution Method  for Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhibo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dongxiao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+K+R">Kim-Kwang Raymond Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To better understand the output of deep neural networks (DNN), attribution
based methods have been an important approach for model interpretability, which
assign a score for each input dimension to indicate its importance towards the
model outcome. Notably, the attribution methods use the axioms of sensitivity
and implementation invariance to ensure the validity and reliability of
attribution results. Yet, the existing attribution methods present challenges
for effective interpretation and efficient computation. In this work, we
introduce MFABA, an attribution algorithm that adheres to axioms, as a novel
method for interpreting DNN. Additionally, we provide the theoretical proof and
in-depth analysis for MFABA algorithm, and conduct a large scale experiment.
The results demonstrate its superiority by achieving over 101.5142 times faster
speed than the state-of-the-art attribution algorithms. The effectiveness of
MFABA is thoroughly evaluated through the statistical analysis in comparison to
other methods, and the full implementation package is open-source at:
https://github.com/LMBTough/MFABA
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13631" title="Abstract">arXiv:2312.13631</a> [<a href="/pdf/2312.13631" title="Download PDF">pdf</a>, <a href="/format/2312.13631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-Oracle: Diffusion Model for Oracle Character Generation with  Controllable Styles and Contents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiu-Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deciphering the oracle bone script plays a significant role in Chinese
archaeology and philology. However, it is significantly challenging due to the
scarcity of oracle character images. To overcome this issue, we propose
Diff-Oracle, based on diffusion models (DMs), to generate sufficient
controllable oracle characters. In contrast to most DMs that rely on text
prompts, we incorporate a style encoder to control style information during the
generation process. This encoder extracts style prompts from existing oracle
character images, where style details are converted from a CLIP model into a
text embedding format. Inspired by ControlNet, we introduce a content encoder
to capture desired content information from content images, ensuring the
fidelity of character glyphs. To train Diff-Oracle effectively, we propose to
obtain pixel-level paired oracle character images (i.e., style and content
images) by a pre-trained image-to-image translation model. Extensive
qualitative and quantitative experiments conducted on two benchmark datasets,
Oracle-241 and OBC306, demonstrate that our Diff-Oracle outperforms existing
generative methods in terms of image generation, further enhancing recognition
accuracy. Source codes will be available.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13632" title="Abstract">arXiv:2312.13632</a> [<a href="/pdf/2312.13632" title="Download PDF">pdf</a>, <a href="/format/2312.13632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProvFL: Client-Driven Interpretability of Global Model Predictions in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gill%2C+W">Waris Gill</a> (1), 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A">Ali Anwar</a> (2), 
<a href="/search/cs?searchtype=author&query=Gulzar%2C+M+A">Muhammad Ali Gulzar</a> (1) ((1) Virginia Tech, (2) University of Minnesota Twin Cities)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. For access to the source code used in this study, please contact the authors directly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Software Engineering (cs.SE)

</div>
<p class="mathjax">Federated Learning (FL) trains a collaborative machine learning model by
aggregating multiple privately trained clients' models over several training
rounds. Such a long, continuous action of model aggregations poses significant
challenges in reasoning about the origin and composition of such a global
model. Regardless of the quality of the global model or if it has a fault,
understanding the model's origin is equally important for debugging,
interpretability, and explainability in federated learning. FL application
developers often question: (1) what clients contributed towards a global model
and (2) if a global model predicts a label, which clients are responsible for
it?
<br />We introduce, neuron provenance, a fine-grained lineage capturing mechanism
that tracks the flow of information between the individual participating
clients in FL and the final global model. We operationalize this concept in
ProvFL that functions on two key principles. First, recognizing that monitoring
every neuron of every client's model statically is ineffective and noisy due to
the uninterpretable nature of individual neurons, ProvFL dynamically isolates
influential and sensitive neurons in the global model, significantly reducing
the search space. Second, as multiple clients' models are fused in each round
to form a global model, tracking each client's contribution becomes
challenging. ProvFL leverages the invertible nature of fusion algorithms to
precisely isolate each client's contribution derived from selected neurons.
When asked to localize the clients responsible for the given behavior (i.e.,
prediction) of the global model, ProvFL successfully localizes them with an
average provenance accuracy of 97%. Additionally, ProvFL outperforms the
state-of-the-art FL fault localization approach by an average margin of 50%.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13633" title="Abstract">arXiv:2312.13633</a> [<a href="/pdf/2312.13633" title="Download PDF">pdf</a>, <a href="/format/2312.13633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Domain Adaptation Across Video Scenes for Temporal Video  Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Temporal Video Grounding (TVG) aims to localize the temporal boundary of a
specific segment in an untrimmed video based on a given language query. Since
datasets in this domain are often gathered from limited video scenes, models
tend to overfit to scene-specific factors, which leads to suboptimal
performance when encountering new scenes in real-world applications. In a new
scene, the fine-grained annotations are often insufficient due to the expensive
labor cost, while the coarse-grained video-query pairs are easier to obtain.
Thus, to address this issue and enhance model performance on new scenes, we
explore the TVG task in an unsupervised domain adaptation (UDA) setting across
scenes for the first time, where the video-query pairs in the source scene
(domain) are labeled with temporal boundaries, while those in the target scene
are not. Under the UDA setting, we introduce a novel Adversarial Multi-modal
Domain Adaptation (AMDA) method to adaptively adjust the model's scene-related
knowledge by incorporating insights from the target data. Specifically, we
tackle the domain gap by utilizing domain discriminators, which help identify
valuable scene-related features effective across both domains. Concurrently, we
mitigate the semantic gap between different modalities by aligning video-query
pairs with related semantics. Furthermore, we employ a mask-reconstruction
approach to enhance the understanding of temporal semantics within a scene.
Extensive experiments on Charades-STA, ActivityNet Captions, and YouCook2
demonstrate the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13634" title="Abstract">arXiv:2312.13634</a> [<a href="/pdf/2312.13634" title="Download PDF">pdf</a>, <a href="/ps/2312.13634" title="Download PostScript">ps</a>, <a href="/format/2312.13634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peano Arithmetic and $&#x3bc;$MALL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manighetti%2C+M">Matteo Manighetti</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+D">Dale Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Formal theories of arithmetic have traditionally been based on either
classical or intuitionistic logic, leading to the development of Peano and
Heyting arithmetic, respectively. We propose a use $\mu$MALL as a formal theory
of arithmetic based on linear logic. This formal system is presented as a
sequent calculus proof system that extends the standard proof system for
multiplicative-additive linear logic (MALL) with the addition of the logical
connectives universal and existential quantifiers (first-order quantifiers),
term equality and non-equality, and the least and greatest fixed point
operators. We first demonstrate how functions defined using $\mu$MALL
relational specifications can be computed using a simple proof search
algorithm. By incorporating weakening and contraction into $\mu$MALL, we obtain
$\mu$LK+, a natural candidate for a classical sequent calculus for arithmetic.
While important proof theory results are still lacking for $\mu$LK+ (including
cut-elimination and the completeness of focusing), we prove that $\mu$LK+ is
consistent and that it contains Peano arithmetic. We also prove two
conservativity results regarding $\mu$LK+ over $\mu$MALL.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13641" title="Abstract">arXiv:2312.13641</a> [<a href="/pdf/2312.13641" title="Download PDF">pdf</a>, <a href="/format/2312.13641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPGroup3D: Superpoint Grouping Network for Indoor 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+L">Le Hui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yaqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jin Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current 3D object detection methods for indoor scenes mainly follow the
voting-and-grouping strategy to generate proposals. However, most methods
utilize instance-agnostic groupings, such as ball query, leading to
inconsistent semantic information and inaccurate regression of the proposals.
To this end, we propose a novel superpoint grouping network for indoor
anchor-free one-stage 3D object detection. Specifically, we first adopt an
unsupervised manner to partition raw point clouds into superpoints, areas with
semantic consistency and spatial similarity. Then, we design a geometry-aware
voting module that adapts to the centerness in anchor-free detection by
constraining the spatial relationship between superpoints and object centers.
Next, we present a superpoint-based grouping module to explore the consistent
representation within proposals. This module includes a superpoint attention
layer to learn feature interaction between neighboring superpoints, and a
superpoint-voxel fusion layer to propagate the superpoint-level information to
the voxel level. Finally, we employ effective multiple matching to capitalize
on the dynamic receptive fields of proposals based on superpoints during the
training. Experimental results demonstrate our method achieves state-of-the-art
performance on ScanNet V2, SUN RGB-D, and S3DIS datasets in the indoor
one-stage 3D object detection. Source code is available at
https://github.com/zyrant/SPGroup3D.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13644" title="Abstract">arXiv:2312.13644</a> [<a href="/pdf/2312.13644" title="Download PDF">pdf</a>, <a href="/format/2312.13644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical analysis of git bisect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorbec%2C+P">Paul Dorbec</a> (GREYC), 
<a href="/search/cs?searchtype=author&query=Courtiel%2C+J">Julien Courtiel</a> (GREYC), 
<a href="/search/cs?searchtype=author&query=Lecoq%2C+R">Romain Lecoq</a> (GREYC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In this paper, we consider the problem of finding a regression in a version
control system (VCS), such as \texttt{git}. The set of versions is modelled by
a Directed Acyclic Graph (DAG) where vertices represent versions of the
software, and arcs are the changes between different versions. We assume that
somewhere in the DAG, a bug was introduced, which persists in all of its
subsequent versions. It is possible to query a vertex to check whether the
corresponding version carries the bug. Given a DAG and a bugged vertex, the
Regression Search Problem consists in finding the first vertex containing the
bug in a minimum number of queries in the worst-case scenario. This problem is
known to be NP-complete. We study the algorithm used in \texttt{git} to address
this problem, known as \texttt{git bisect}. We prove that in a general setting,
\texttt{git bisect} can use an exponentially larger number of queries than an
optimal algorithm. We also consider the restriction where all vertices have
indegree at most 2 (i.e. where merges are made between at most two branches at
a time in the VCS), and prove that in this case, \texttt{git bisect} is a
$\frac{1}{\log_2(3/2)}$-approximation algorithm, and that this bound is tight.
We also provide a better approximation algorithm for this case. Finally, we
give an alternative proof of the NP-completeness of the Regression Search
Problem, via a variation with bounded indegree.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13646" title="Abstract">arXiv:2312.13646</a> [<a href="/pdf/2312.13646" title="Download PDF">pdf</a>, <a href="/format/2312.13646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Semantic Segmentation for Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongseob Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+J">Junsuk Choe</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunjung Shim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">State-of-the-art techniques in weakly-supervised semantic segmentation (WSSS)
using image-level labels exhibit severe performance degradation on driving
scene datasets such as Cityscapes. To address this challenge, we develop a new
WSSS framework tailored to driving scene datasets. Based on extensive analysis
of dataset characteristics, we employ Contrastive Language-Image Pre-training
(CLIP) as our baseline to obtain pseudo-masks. However, CLIP introduces two key
challenges: (1) pseudo-masks from CLIP lack in representing small object
classes, and (2) these masks contain notable noise. We propose solutions for
each issue as follows. (1) We devise Global-Local View Training that seamlessly
incorporates small-scale patches during model training, thereby enhancing the
model's capability to handle small-sized yet critical objects in driving scenes
(e.g., traffic light). (2) We introduce Consistency-Aware Region Balancing
(CARB), a novel technique that discerns reliable and noisy regions through
evaluating the consistency between CLIP masks and segmentation predictions. It
prioritizes reliable pixels over noisy pixels via adaptive loss weighting.
Notably, the proposed method achieves 51.8\% mIoU on the Cityscapes test
dataset, showcasing its potential as a strong WSSS baseline on driving scene
datasets. Experimental results on CamVid and WildDash2 demonstrate the
effectiveness of our method across diverse datasets, even with small-scale
datasets or visually challenging conditions. The code is available at
https://github.com/k0u-id/CARB.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13649" title="Abstract">arXiv:2312.13649</a> [<a href="/pdf/2312.13649" title="Download PDF">pdf</a>, <a href="/format/2312.13649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Smart Highway to Babel: the coexistence of different generations of  Intelligent Transport Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+I">Ignacio Soto</a>, 
<a href="/search/cs?searchtype=author&query=Calderon%2C+M">Maria Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Urue%C3%B1a%2C+M">Manuel Urue&#xf1;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The gap between technology readiness level in Cooperative Intelligent
Transport Systems (C-ITS) and its adoption and deployment has caused a
phenomenon where at least two types of network access technologies have to
coexist. Furthermore, for the case of ETSI Intelligent Transport Systems
protocols, work is being completed in Release 2 of the specification while
Release 1 deployments are still underway. This, coupled with industry and
consumer trends in the vehicle industry, is bound to cause a scenario where
fully C-ITS-enabled vehicles have to coexist with non-C-ITS road users and, at
the very least, with different versions of C-ITS. In this paper, we analyze the
performance in terms of efficiency and safety of two releases of the ETSI
GeoNetworking protocol, as well as a discussion on possible paths to tackle the
upcoming compatibility and coexistence problems.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13654" title="Abstract">arXiv:2312.13654</a> [<a href="/pdf/2312.13654" title="Download PDF">pdf</a>, <a href="/format/2312.13654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Space Optical Integrated Sensing and Communication Based on  DCO-OFDM: Performance Metrics and Resource Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yunfeng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jian Song</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
<p class="mathjax">As one of the six usage scenarios of the sixth generation (6G) mobile
communication system, integrated sensing and communication (ISAC) has garnered
considerable attention, and numerous studies have been conducted on
radio-frequency (RF)-ISAC. Benefitting from the communication and sensing
capabilities of an optical system, free space optical (FSO)-ISAC becomes a
potential complement to RF-ISAC. In this paper, a direct-current-biased optical
orthogonal frequency division multiplexing (DCO-OFDM) scheme is proposed for
FSO-ISAC. To derive the spectral efficiency for communication and the Fisher
information for sensing as performance metrics, we model the clipping noise of
DCO-OFDM as additive colored Gaussian noise to obtain the expression of the
signal-to-noise ratio. Based on the derived performance metrics, joint power
allocation problems are formulated for both communication-centric and
sensing-centric scenarios. In addition, the non-convex joint optimization
problems are decomposed into sub-problems for DC bias and subcarriers, which
can be solved by block coordinate descent algorithms. Furthermore, numerical
simulations demonstrate the proposed algorithms and reveal the trade-off
between communication and sensing functionalities of the OFDM-based FSO-ISAC
system.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13655" title="Abstract">arXiv:2312.13655</a> [<a href="/pdf/2312.13655" title="Download PDF">pdf</a>, <a href="/format/2312.13655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Zero-Shot Learning for Attribute-Based Object Reference in  Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a> (1), 
<a href="/search/cs?searchtype=author&query=Jaafar%2C+A">Ahmed Jaafar</a> (1), 
<a href="/search/cs?searchtype=author&query=Reily%2C+B">Brian Reily</a> (2), 
<a href="/search/cs?searchtype=author&query=Reardon%2C+C">Christopher Reardon</a> (3), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a> (1) ((1) University of Massachusetts Amherst, (2) DEVCOM Army Research Laboratory, (3) University of Denver)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Equal contribution from the first two authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Language-enabled robots have been widely studied over the past years to
enable natural human-robot interaction and teaming in various real-world
applications. Language-enabled robots must be able to comprehend referring
expressions to identify a particular object from visual perception using a set
of referring attributes extracted from natural language. However, visual
observations of an object may not be available when it is referred to, and the
number of objects and attributes may also be unbounded in open worlds. To
address the challenges, we implement an attribute-based compositional zero-shot
learning method that uses a list of attributes to perform referring expression
comprehension in open worlds. We evaluate the approach on two datasets
including the MIT-States and the Clothing 16K. The preliminary experimental
results show that our implemented approach allows a robot to correctly identify
the objects referred to by human commands.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13657" title="Abstract">arXiv:2312.13657</a> [<a href="/pdf/2312.13657" title="Download PDF">pdf</a>, <a href="/ps/2312.13657" title="Download PostScript">ps</a>, <a href="/format/2312.13657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Hardness of Analyzing Quantum Programs Quantitatively
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avanzini%2C+M">Martin Avanzini</a> (OLAS), 
<a href="/search/cs?searchtype=author&query=Moser%2C+G">Georg Moser</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9choux%2C+R">Romain P&#xe9;choux</a> (LORIA, UL, CNRS, MOCQUA), 
<a href="/search/cs?searchtype=author&query=Perdrix%2C+S">Simon Perdrix</a> (MOCQUA, LORIA, CNRS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this paper, we study quantitative properties of quantum programs.
Properties of interest include (positive) almost-sure termination, expected
runtime or expected cost, that is, for example, the expected number of
applications of a given quantum gate, etc. After studying the completeness of
these problems in the arithmetical hierarchy over the Clifford+T fragment of
quantum mechanics, we express these problems using a variation of a quantum
pre-expectation transformer, a weakest precondition based technique that allows
to symbolically compute these quantitative properties. Under a smooth
restriction-a restriction to polynomials of bounded degree over a real closed
field-we show that the quantitative problem, which consists in finding an
upper-bound to the pre-expectation, can be decided in time double-exponential
in the size of a program, thus providing, despite its great complexity, one of
the first decidable results on the analysis and verification of quantum
programs. Finally, we sketch how the latter can be transformed into an
efficient synthesis method.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13658" title="Abstract">arXiv:2312.13658</a> [<a href="/pdf/2312.13658" title="Download PDF">pdf</a>, <a href="/ps/2312.13658" title="Download PostScript">ps</a>, <a href="/format/2312.13658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-based nonlinear detectability for discrete-time systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Krauss%2C+I">Isabelle Krauss</a>, 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces two sample-based formulations of incremental
input/output-to-state stability (i-IOSS), a suitable detectability notion for
general nonlinear systems. In this work we consider the case of limited output
information, i.e., measurements are only infrequently and/or irregularly
available. The output-dependent term of the sample-based i-IOSS bound is
properly modified to yield a characterization for detectability in presence of
incomplete output sequences. We provide both a non-timediscounted and a
time-discounted formulation of samplebased i-IOSS. Furthermore, conditions for
an i-IOSS system to be also sample-based i-IOSS are given and the relation
between the two formulations of sample-based i-IOSS is shown.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13662" title="Abstract">arXiv:2312.13662</a> [<a href="/pdf/2312.13662" title="Download PDF">pdf</a>, <a href="/format/2312.13662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DENIS-SDN: Software-Defined Network Slicing Solution for Dense and  Ultra-Dense IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+T">Tryfon Theodorou</a>, 
<a href="/search/cs?searchtype=author&query=Mamatas%2C+L">Lefteris Mamatas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Traditional Wireless Sensor Networks protocols used in Internet of Things
Networks (IoTNs) today face challenges in high- and ultra-density network
topology conditions. New networking paradigms like Software-Defined Networks
(SDN) have emerged as an up-and-coming approach to address IoT application
requirements through implementing global protocol strategies and network
programmability. This paper proposes a divide-and-conquer solution that aims to
improve the PDR in ultra-dense IoT (UDIoT) network environments using network
slicing. As such, we develop and evaluate DENIS-SDN, an open-source SDN
solution for UDIoT Network environments consisting of a modular SDN controller
and an OpenFlow-like data-plane protocol. DENIS-SDN utilizes our Network
Density Control mechanism based on operational specification requirements,
which address the challenges UDIoT network deployments pose, including
interference, congestion, resource management, control, and quality of service
(QoS) performance issues. To achieve this, it divides dense IoT networks into
either logically sliced sub-networks separating nodes using routing rules or
physically sliced sub-networks separating nodes into different radio channels.
We provide evaluation results over realistic scenarios demonstrating improved
PDR performance up to 4.8% for logically and up to 11.6% for physically sliced
network scenarios.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13663" title="Abstract">arXiv:2312.13663</a> [<a href="/pdf/2312.13663" title="Download PDF">pdf</a>, <a href="/format/2312.13663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free-Editor: Zero-shot Text-driven 3D Scene Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karim%2C+N">Nazmul Karim</a>, 
<a href="/search/cs?searchtype=author&query=Khalid%2C+U">Umar Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+H">Hasan Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+J">Jing Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-Image (T2I) diffusion models have gained popularity recently due to
their multipurpose and easy-to-use nature, e.g. image and video generation as
well as editing. However, training a diffusion model specifically for 3D scene
editing is not straightforward due to the lack of large-scale datasets. To
date, editing 3D scenes requires either re-training the model to adapt to
various 3D edited scenes or design-specific methods for each special editing
type. Furthermore, state-of-the-art (SOTA) methods require multiple
synchronized edited images from the same scene to facilitate the scene editing.
Due to the current limitations of T2I models, it is very challenging to apply
consistent editing effects to multiple images, i.e. multi-view inconsistency in
editing. This in turn compromises the desired 3D scene editing performance if
these images are used. In our work, we propose a novel training-free 3D scene
editing technique, Free-Editor, which allows users to edit 3D scenes without
further re-training the model during test time. Our proposed method
successfully avoids the multi-view style inconsistency issue in SOTA methods
with the help of a "single-view editing" scheme. Specifically, we show that
editing a particular 3D scene can be performed by only modifying a single view.
To this end, we introduce an Edit Transformer that enforces intra-view
consistency and inter-view style transfer by utilizing self- and
cross-attention, respectively. Since it is no longer required to re-train the
model and edit every view in a scene, the editing time, as well as memory
resources, are reduced significantly, e.g., the runtime being $\sim \textbf{20}
\times$ faster than SOTA. We have conducted extensive experiments on a wide
range of benchmark datasets and achieve diverse editing capabilities with our
proposed technique.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13671" title="Abstract">arXiv:2312.13671</a> [<a href="/pdf/2312.13671" title="Download PDF">pdf</a>, <a href="/format/2312.13671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Analysis: A Benchmark of Table Question Answering with Advanced  Data Analysis and Unclear Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinyi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinrun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Rui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ran Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zejian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Tabular data analysis is crucial in various fields, and large language models
show promise in this area. However, current research mostly focuses on
rudimentary tasks like Text2SQL and TableQA, neglecting advanced analysis like
forecasting and chart generation. To address this gap, we developed the
Text2Analysis benchmark, incorporating advanced analysis tasks that go beyond
the SQL-compatible operations and require more in-depth analysis. We also
develop five innovative and effective annotation methods, harnessing the
capabilities of large language models to enhance data quality and quantity.
Additionally, we include unclear queries that resemble real-world user
questions to test how well models can understand and tackle such challenges.
Finally, we collect 2249 query-result pairs with 347 tables. We evaluate five
state-of-the-art models using three different metrics and the results show that
our benchmark presents introduces considerable challenge in the field of
tabular data analysis, paving the way for more advanced research opportunities.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13677" title="Abstract">arXiv:2312.13677</a> [<a href="/pdf/2312.13677" title="Download PDF">pdf</a>, <a href="/format/2312.13677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Trust-Region Approaches in Neural Network Training: Beyond  Traditional Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Trotti%2C+K">Ken Trotti</a>, 
<a href="/search/math?searchtype=author&query=Alegr%C3%ADa%2C+S+A+C">Samuel A. Cruz Alegr&#xed;a</a>, 
<a href="/search/math?searchtype=author&query=Kopani%C4%8D%C3%A1kov%C3%A1%2C+A">Alena Kopani&#x10d;&#xe1;kov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+R">Rolf Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose to train neural networks (NNs) using a novel variant of the
``Additively Preconditioned Trust-region Strategy'' (APTS). The proposed method
is based on a parallelizable additive domain decomposition approach applied to
the neural network's parameters. Built upon the TR framework, the APTS method
ensures global convergence towards a minimizer. Moreover, it eliminates the
need for computationally expensive hyper-parameter tuning, as the TR algorithm
automatically determines the step size in each iteration. We demonstrate the
capabilities, strengths, and limitations of the proposed APTS training method
by performing a series of numerical experiments. The presented numerical study
includes a comparison with widely used training methods such as SGD, Adam,
LBFGS, and the standard TR method.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13680" title="Abstract">arXiv:2312.13680</a> [<a href="/pdf/2312.13680" title="Download PDF">pdf</a>, <a href="/format/2312.13680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGE: Embedding Temporal Knowledge Graphs in a Product Space of  Heterogeneous Geometric Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiaxin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Nayyeri%2C+M">Mojtaba Nayyeri</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinan Li</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Temporal knowledge graphs represent temporal facts $(s,p,o,\tau)$ relating a
subject $s$ and an object $o$ via a relation label $p$ at time $\tau$, where
$\tau$ could be a time point or time interval. Temporal knowledge graphs may
exhibit static temporal patterns at distinct points in time and dynamic
temporal patterns between different timestamps. In order to learn a rich set of
static and dynamic temporal patterns and apply them for inference, several
embedding approaches have been suggested in the literature. However, as most of
them resort to single underlying embedding spaces, their capability to model
all kinds of temporal patterns was severely limited by having to adhere to the
geometric property of their one embedding space. We lift this limitation by an
embedding approach that maps temporal facts into a product space of several
heterogeneous geometric subspaces with distinct geometric properties, i.e.\
Complex, Dual, and Split-complex spaces. In addition, we propose a
temporal-geometric attention mechanism to integrate information from different
geometric subspaces conveniently according to the captured relational and
temporal information. Experimental results on standard temporal benchmark
datasets favorably evaluate our approach against state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13682" title="Abstract">arXiv:2312.13682</a> [<a href="/pdf/2312.13682" title="Download PDF">pdf</a>, <a href="/format/2312.13682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Constraint Programming Model for Scheduling the Unloading of Trains in  Ports: Extended
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez%2C+G">Guillaume Perez</a>, 
<a href="/search/cs?searchtype=author&query=Glorian%2C+G">Gael Glorian</a>, 
<a href="/search/cs?searchtype=author&query=Suijlen%2C+W">Wijnand Suijlen</a>, 
<a href="/search/cs?searchtype=author&query=Lallouet%2C+A">Arnaud Lallouet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, we propose a model to schedule the next 24 hours of operations
in a bulk cargo port to unload bulk cargo trains onto stockpiles. It is a
problem that includes multiple parts such as splitting long trains into shorter
ones and the routing of bulk material through a configurable network of
conveyors to the stockpiles. Managing such trains (up to three kilometers long)
also requires specialized equipment. The real world nature of the problem
specification implies the necessity to manage heterogeneous data. Indeed, when
new equipment is added (e.g. dumpers) or a new type of wagon comes in use,
older or different equipment will still be in use as well. All these details
need to be accounted for. In fact, avoiding a full deadlock of the facility
after a new but ineffective schedule is produced. In this paper, we provide a
detailed presentation of this real world problem and its associated data. This
allows us to propose an effective constraint programming model to solve this
problem. We also discuss the model design and the different implementations of
the propagators that we used in practice. Finally, we show how this model,
coupled with a large neighborhood search, was able to find 24 hour schedules
efficiently.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13691" title="Abstract">arXiv:2312.13691</a> [<a href="/pdf/2312.13691" title="Download PDF">pdf</a>, <a href="/format/2312.13691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamTuner: Single Image is Enough for Subject-Driven Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Miao Hua</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+F">Fei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qian He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion-based models have demonstrated impressive capabilities for
text-to-image generation and are expected for personalized applications of
subject-driven generation, which require the generation of customized concepts
with one or a few reference images. However, existing methods based on
fine-tuning fail to balance the trade-off between subject learning and the
maintenance of the generation capabilities of pretrained models. Moreover,
other methods that utilize additional image encoders tend to lose important
details of the subject due to encoding compression. To address these
challenges, we propose DreamTurner, a novel method that injects reference
information from coarse to fine to achieve subject-driven image generation more
effectively. DreamTurner introduces a subject-encoder for coarse subject
identity preservation, where the compressed general subject features are
introduced through an attention layer before visual-text cross-attention. We
then modify the self-attention layers within pretrained text-to-image models to
self-subject-attention layers to refine the details of the target subject. The
generated image queries detailed features from both the reference image and
itself in self-subject-attention. It is worth emphasizing that
self-subject-attention is an effective, elegant, and training-free method for
maintaining the detailed features of customized subjects and can serve as a
plug-and-play solution during inference. Finally, with additional
subject-driven fine-tuning, DreamTurner achieves remarkable performance in
subject-driven image generation, which can be controlled by a text or other
conditions such as pose. For further details, please visit the project page at
https://dreamtuner-diffusion.github.io/.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13694" title="Abstract">arXiv:2312.13694</a> [<a href="/pdf/2312.13694" title="Download PDF">pdf</a>, <a href="/format/2312.13694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Transformation to Construct a Dataset for Generating  Entity-Relationship Model from Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian-Guang Lou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In order to reduce the manual cost of designing ER models, recent approaches
have been proposed to address the task of NL2ERM, i.e., automatically
generating entity-relationship (ER) models from natural language (NL)
utterances such as software requirements. These approaches are typically
rule-based ones, which rely on rigid heuristic rules; these approaches cannot
generalize well to various linguistic ways of describing the same requirement.
Despite having better generalization capability than rule-based approaches,
deep-learning-based models are lacking for NL2ERM due to lacking a large-scale
dataset. To address this issue, in this paper, we report our insight that there
exists a high similarity between the task of NL2ERM and the increasingly
popular task of text-to-SQL, and propose a data transformation algorithm that
transforms the existing data of text-to-SQL into the data of NL2ERM. We apply
our data transformation algorithm on Spider, one of the most popular
text-to-SQL datasets, and we also collect some data entries with different NL
types, to obtain a large-scale NL2ERM dataset. Because NL2ERM can be seen as a
special information extraction (IE) task, we train two state-of-the-art IE
models on our dataset. The experimental results show that both the two models
achieve high performance and outperform existing baselines.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13695" title="Abstract">arXiv:2312.13695</a> [<a href="/pdf/2312.13695" title="Download PDF">pdf</a>, <a href="/format/2312.13695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unexplored Frontiers: A Review of Empirical Studies of Exploratory  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medlar%2C+A">Alan Medlar</a>, 
<a href="/search/cs?searchtype=author&query=Kotkov%2C+D">Denis Kotkov</a>, 
<a href="/search/cs?searchtype=author&query=Glowacka%2C+D">Dorota Glowacka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This article reviews how empirical research of exploratory search is
conducted. We investigated aspects of interdisciplinarity, study settings and
evaluation methodologies from a systematically selected sample of 231
publications from 2010-2021, including a total of 172 articles with empirical
studies. Our results show that exploratory search is highly interdisciplinary,
with the most frequently occurring publication venues including high impact
venues in information science, information systems and human-computer
interaction. However, taken in aggregate, the breadth of study settings
investigated was limited. We found that a majority of studies (77%) focused on
evaluating novel retrieval systems as opposed to investigating users' search
processes. Furthermore, a disproportionate number of studies were based on
scientific literature search (20.7%), a majority of which only considered
searching for Computer Science articles. Study participants were generally from
convenience samples, with 75% of studies composed exclusively of students and
other academics. The methodologies used for evaluation were mostly
quantitative, but lacked consistency between studies and validated
questionnaires were rarely used. In discussion, we offer a critical analysis of
our findings and suggest potential improvements for future exploratory search
studies.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13697" title="Abstract">arXiv:2312.13697</a> [<a href="/pdf/2312.13697" title="Download PDF">pdf</a>, <a href="/format/2312.13697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation of Multi-stage Attack and Defense Simulation for Data  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+%C3%96">&#xd6;mer Sen</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+B">Bozhidar Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Henze%2C+M">Martin Henze</a>, 
<a href="/search/cs?searchtype=author&query=Ulbig%2C+A">Andreas Ulbig</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 International Conference on Smart Energy
  Systems and Technologies (SEST)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The power grid is a critical infrastructure that plays a vital role in modern
society. Its availability is of utmost importance, as a loss can endanger human
lives. However, with the increasing digitalization of the power grid, it also
becomes vulnerable to new cyberattacks that can compromise its availability. To
counter these threats, intrusion detection systems are developed and deployed
to detect cyberattacks targeting the power grid. Among intrusion detection
systems, anomaly detection models based on machine learning have shown
potential in detecting unknown attack vectors. However, the scarcity of data
for training these models remains a challenge due to confidentiality concerns.
To overcome this challenge, this study proposes a model for generating
synthetic data of multi-stage cyber attacks in the power grid, using attack
trees to model the attacker's sequence of steps and a game-theoretic approach
to incorporate the defender's actions. This model aims to create diverse attack
data on which machine learning algorithms can be trained.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13699" title="Abstract">arXiv:2312.13699</a> [<a href="/pdf/2312.13699" title="Download PDF">pdf</a>, <a href="/format/2312.13699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt &amp; Align: Continual Learning with Generative Models Latent Space  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deja%2C+K">Kamil Deja</a>, 
<a href="/search/cs?searchtype=author&query=Cywi%C5%84ski%2C+B">Bartosz Cywi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Rybarczyk%2C+J">Jan Rybarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this work, we introduce Adapt &amp; Align, a method for continual learning of
neural networks by aligning latent representations in generative models. Neural
Networks suffer from abrupt loss in performance when retrained with additional
training data from different distributions. At the same time, training with
additional data without access to the previous examples rarely improves the
model's performance. In this work, we propose a new method that mitigates those
problems by employing generative models and splitting the process of their
update into two parts. In the first one, we train a local generative model
using only data from a new task. In the second phase, we consolidate latent
representations from the local model with a global one that encodes knowledge
of all past experiences. We introduce our approach with Variational
Auteoncoders and Generative Adversarial Networks. Moreover, we show how we can
use those generative models as a general method for continual knowledge
consolidation that can be used in downstream tasks such as classification.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13700" title="Abstract">arXiv:2312.13700</a> [<a href="/pdf/2312.13700" title="Download PDF">pdf</a>, <a href="/ps/2312.13700" title="Download PostScript">ps</a>, <a href="/format/2312.13700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer boycotts in convex games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fokkink%2C+R">Robbert Fokkink</a>, 
<a href="/search/cs?searchtype=author&query=de+Munnik%2C+H">Hans de Munnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We extend the notion of boycotts in cooperative games from one-on-one
boycotts between single players to boycotts between coalitions. We prove that
convex game offer a proper setting for studying the impact of boycotts.
Boycotts have a heterogenous effect. Individual players that are targeted by
many-on-one boycotts suffer most, while non-participating players may actually
benefit from a boycott.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13701" title="Abstract">arXiv:2312.13701</a> [<a href="/pdf/2312.13701" title="Download PDF">pdf</a>, <a href="/ps/2312.13701" title="Download PostScript">ps</a>, <a href="/format/2312.13701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite families $2$-designs from binary projective three-weight codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Canze Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qunying Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haibo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Combinatorial designs are closely related to linear codes. In recent year,
there are a lot of $t$-designs constructed from certain linear codes. In this
paper, we aim to construct $2$-designs from binary three-weight codes. For any
binary three-weight code $\mathcal{C}$ with length $n$, let
$A_{n}(\mathcal{C})$ be the number of codewords in $\mathcal{C}$ with Hamming
weight $n$, then we show that $\mathcal{C}$ holds $2$-designs when
$\mathcal{C}$ is projective and $A_{n}(\mathcal{C})=1$. Furthermore, by
extending some certain binary projective two-weight codes and basing on the
defining set method, we construct two classes of binary projective three-weight
codes which are suitable for holding $2$-designs.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13702" title="Abstract">arXiv:2312.13702</a> [<a href="/pdf/2312.13702" title="Download PDF">pdf</a>, <a href="/format/2312.13702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local certification of local properties: tight bounds, trade-offs and  new parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeitoun%2C+N+B+L+F+S">Nicolas Bousquet Laurent Feuilloley S&#xe9;bastien Zeitoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Local certification is a distributed mechanism enabling the nodes of a
network to check the correctness of the current configuration, thanks to small
pieces of information called certificates. For many classic global properties,
like checking the acyclicity of the network, the optimal size of the
certificates depends on the size of the network, $n$. In this paper, we focus
on properties for which the size of the certificates does not depend on $n$ but
on other parameters. We focus on three such important properties and prove
tight bounds for all of them. Namely, we prove that the optimal certification
size is: $\Theta(\log k)$ for $k$-colorability (and even exactly $\lceil \log k
\rceil$ bits in the anonymous model while previous works had only proved a
$2$-bit lower bound); $(1/2)\log t+o(\log t)$ for dominating sets at distance
$t$ (an unexpected and tighter-than-usual bound) ; and $\Theta(\log \Delta)$
for perfect matching in graphs of maximum degree $\Delta$ (the first
non-trivial bound parameterized by $\Delta$). We also prove some surprising
upper bounds, for example, certifying the existence of a perfect matching in a
planar graph can be done with only two bits. In addition, we explore various
specific cases for these properties, in particular improving our understanding
of the trade-off between locality of the verification and certificate size.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13704" title="Abstract">arXiv:2312.13704</a> [<a href="/pdf/2312.13704" title="Download PDF">pdf</a>, <a href="/ps/2312.13704" title="Download PostScript">ps</a>, <a href="/format/2312.13704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Forecasting-Based DLP Approach for Data Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kishu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kush%2C+A">Ashwani Kush</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sensitive data leakage is the major growing problem being faced by
enterprises in this technical era. Data leakage causes severe threats for
organization of data safety which badly affects the reputation of
organizations. Data leakage is the flow of sensitive data/information from any
data holder to an unauthorized destination. Data leak prevention (DLP) is set
of techniques that try to alleviate the threats which may hinder data security.
DLP unveils guilty user responsible for data leakage and ensures that user
without appropriate permission cannot access sensitive data and also provides
protection to sensitive data if sensitive data is shared accidentally. In this
paper, data leakage prevention (DLP) model is used to restrict/grant data
access permission to user, based on the forecast of their access to data. This
study provides a DLP solution using data statistical analysis to forecast the
data access possibilities of any user in future based on the access to data in
the past. The proposed approach makes use of renowned simple piecewise linear
function for learning/training to model. The results show that the proposed DLP
approach with high level of precision can correctly classify between users even
in cases of extreme data access.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13705" title="Abstract">arXiv:2312.13705</a> [<a href="/pdf/2312.13705" title="Download PDF">pdf</a>, <a href="/format/2312.13705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmark Evaluation of Anomaly-Based Intrusion Detection Systems in the  Context of Smart Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+%C3%96">&#xd6;mer Sen</a>, 
<a href="/search/cs?searchtype=author&query=Glomb%2C+S">Simon Glomb</a>, 
<a href="/search/cs?searchtype=author&query=Henze%2C+M">Martin Henze</a>, 
<a href="/search/cs?searchtype=author&query=Ulbig%2C+A">Andreas Ulbig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of 2023 IEEE PES Innovative Smart Grid Technologies Europe (ISGT EUROPE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The increasing digitization of smart grids has made addressing cybersecurity
issues crucial in order to secure the power supply. Anomaly detection has
emerged as a key technology for cybersecurity in smart grids, enabling the
detection of unknown threats. Many research efforts have proposed various
machine-learning-based approaches for anomaly detection in grid operations.
However, there is a need for a reproducible and comprehensive evaluation
environment to investigate and compare different approaches to anomaly
detection. The assessment process is highly dependent on the specific
application and requires an evaluation that considers representative datasets
from the use case as well as the specific characteristics of the use case. In
this work, we present an evaluation environment for anomaly detection methods
in smart grids that facilitates reproducible and comprehensive evaluation of
different anomaly detection methods.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13710" title="Abstract">arXiv:2312.13710</a> [<a href="/pdf/2312.13710" title="Download PDF">pdf</a>, <a href="/ps/2312.13710" title="Download PostScript">ps</a>, <a href="/format/2312.13710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on polynomial-free unisolvence of polyharmonic splines at random  points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bos%2C+L">Len Bos</a>, 
<a href="/search/math?searchtype=author&query=Sommariva%2C+A">Alvise Sommariva</a>, 
<a href="/search/math?searchtype=author&query=Vianello%2C+M">Marco Vianello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this note we prove almost sure unisolvence of RBF interpolation on
randomly distributed sequences by a wide class of polyharmonic splines
(including Thin-Plate Splines), without polynomial addition.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13711" title="Abstract">arXiv:2312.13711</a> [<a href="/pdf/2312.13711" title="Download PDF">pdf</a>, <a href="/ps/2312.13711" title="Download PostScript">ps</a>, <a href="/format/2312.13711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Learning oriented DLP System based on Classification Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kishu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kush%2C+A">Ashwani Kush</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Data is the key asset for organizations and data sharing is lifeline for
organization growth; which may lead to data loss. Data leakage is the most
critical issue being faced by organizations. In order to mitigate the data
leakage issues data leakage prevention systems (DLPSs) are deployed at various
levels by the organizations. DLPSs are capable to protect all kind of data i.e.
DAR, DIM/DIT, DIU. Statistical analysis, regular expression, data
fingerprinting are common approaches exercised in DLP system. Out of these
techniques; statistical analysis approach is most appropriate for proposed DLP
model of data security. This paper defines a statistical DLP model for document
classification. Model uses various statistical approaches like TF-IDF (Term
Frequency- Inverse Document Frequency) a renowned term count/weighing function,
Vectorization, Gradient boosting document classification etc. to classify the
documents before allowing any access to it. Machine learning is used to test
and train the model. Proposed model also introduces an extremely efficient and
more accurate approach; IGBCA (Improvised Gradient Boosting Classification
Algorithm); for document classification, to prevent them from possible data
leakage. Results depicts that proposed model can classify documents with high
accuracy and on basis of which data can be prevented from being loss.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13712" title="Abstract">arXiv:2312.13712</a> [<a href="/pdf/2312.13712" title="Download PDF">pdf</a>, <a href="/format/2312.13712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conciliating Privacy and Utility in Data Releases via Individual  Differential Privacy and Microaggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soria-Comas%2C+J">Jordi Soria-Comas</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+D">David S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Domingo-Ferrer%2C+J">Josep Domingo-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+S">Sergio Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Del+Vasto-Terrientes%2C+L">Luis Del Vasto-Terrientes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">$\epsilon$-Differential privacy (DP) is a well-known privacy model that
offers strong privacy guarantees. However, when applied to data releases, DP
significantly deteriorates the analytical utility of the protected outcomes. To
keep data utility at reasonable levels, practical applications of DP to data
releases have used weak privacy parameters (large $\epsilon$), which dilute the
privacy guarantees of DP. In this work, we tackle this issue by using an
alternative formulation of the DP privacy guarantees, named
$\epsilon$-individual differential privacy (iDP), which causes less data
distortion while providing the same protection as DP to subjects. We enforce
iDP in data releases by relying on attribute masking plus a pre-processing step
based on data microaggregation. The goal of this step is to reduce the
sensitivity to record changes, which determines the amount of noise required to
enforce iDP (and DP). Specifically, we propose data microaggregation strategies
designed for iDP whose sensitivities are significantly lower than those used in
DP. As a result, we obtain iDP-protected data with significantly better utility
than with DP. We report on experiments that show how our approach can provide
strong privacy (small $\epsilon$) while yielding protected data that do not
significantly degrade the accuracy of secondary data analysis.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13714" title="Abstract">arXiv:2312.13714</a> [<a href="/pdf/2312.13714" title="Download PDF">pdf</a>, <a href="/format/2312.13714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrap Masked Visual Modeling via Hard Patches Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Junsong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiyou Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.05919">arXiv:2304.05919</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Masked visual modeling has attracted much attention due to its promising
potential in learning generalizable representations. Typical approaches urge
models to predict specific contents of masked tokens, which can be intuitively
considered as teaching a student (the model) to solve given problems
(predicting masked contents). Under such settings, the performance is highly
correlated with mask strategies (the difficulty of provided problems). We argue
that it is equally important for the model to stand in the shoes of a teacher
to produce challenging problems by itself. Intuitively, patches with high
values of reconstruction loss can be regarded as hard samples, and masking
those hard patches naturally becomes a demanding reconstruction task. To
empower the model as a teacher, we propose Hard Patches Mining (HPM),
predicting patch-wise losses and subsequently determining where to mask.
Technically, we introduce an auxiliary loss predictor, which is trained with a
relative objective to prevent overfitting to exact loss values. Also, to
gradually guide the training procedure, we propose an easy-to-hard mask
strategy. Empirically, HPM brings significant improvements under both image and
video benchmarks. Interestingly, solely incorporating the extra loss prediction
objective leads to better representations, verifying the efficacy of
determining where is hard to reconstruct. The code is available at
https://github.com/Haochen-Wang409/HPM.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13715" title="Abstract">arXiv:2312.13715</a> [<a href="/pdf/2312.13715" title="Download PDF">pdf</a>, <a href="/format/2312.13715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-control of Dialogue Systems Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukuri%2C+K">Kotaro Shukuri</a>, 
<a href="/search/cs?searchtype=author&query=Ishigaki%2C+R">Ryoma Ishigaki</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+J">Jundai Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Naganuma%2C+T">Tsubasa Naganuma</a>, 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+T">Takuma Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kawakubo%2C+D">Daisuke Kawakubo</a>, 
<a href="/search/cs?searchtype=author&query=Shuzo%2C+M">Masaki Shuzo</a>, 
<a href="/search/cs?searchtype=author&query=Maeda%2C+E">Eisaku Maeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Utilizing Large Language Models (LLMs) facilitates the creation of flexible
and natural dialogues, a task that has been challenging with traditional
rule-based dialogue systems. However, LLMs also have the potential to produce
unexpected responses, which may not align with the intentions of dialogue
system designers. To address this issue, this paper introduces a meta-control
method that employs LLMs to develop more stable and adaptable dialogue systems.
The method includes dialogue flow control to ensure that utterances conform to
predefined scenarios and turn-taking control to foster natural dialogues.
Furthermore, we have implemented a dialogue system that utilizes this
meta-control strategy and verified that the dialogue system utilizing
meta-control operates as intended.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13716" title="Abstract">arXiv:2312.13716</a> [<a href="/pdf/2312.13716" title="Download PDF">pdf</a>, <a href="/format/2312.13716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critic-Guided Decision Transformer for Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanfu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in offline reinforcement learning (RL) have underscored
the capabilities of Return-Conditioned Supervised Learning (RCSL), a paradigm
that learns the action distribution based on target returns for each state in a
supervised manner. However, prevailing RCSL methods largely focus on
deterministic trajectory modeling, disregarding stochastic state transitions
and the diversity of future trajectory distributions. A fundamental challenge
arises from the inconsistency between the sampled returns within individual
trajectories and the expected returns across multiple trajectories.
Fortunately, value-based methods offer a solution by leveraging a value
function to approximate the expected returns, thereby addressing the
inconsistency effectively. Building upon these insights, we propose a novel
approach, termed the Critic-Guided Decision Transformer (CGDT), which combines
the predictability of long-term returns from value-based methods with the
trajectory modeling capability of the Decision Transformer. By incorporating a
learned value function, known as the critic, CGDT ensures a direct alignment
between the specified target returns and the expected returns of actions. This
integration bridges the gap between the deterministic nature of RCSL and the
probabilistic characteristics of value-based methods. Empirical evaluations on
stochastic environments and D4RL benchmark datasets demonstrate the superiority
of CGDT over traditional RCSL methods. These results highlight the potential of
CGDT to advance the state of the art in offline RL and extend the applicability
of RCSL to a wide range of RL tasks.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13721" title="Abstract">arXiv:2312.13721</a> [<a href="/pdf/2312.13721" title="Download PDF">pdf</a>, <a href="/ps/2312.13721" title="Download PostScript">ps</a>, <a href="/format/2312.13721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bundle-based similarity measurement for positive semidefinite matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+K">Ke Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Positive semidefinite (PSD) matrices are indispensable in many fields of
science. A similarity measurement for such matrices is usually an essential
ingredient in the mathematical modelling of a scientific problem. This paper
proposes a unified framework to construct similarity measurements for PSD
matrices. The framework is obtained by exploring the fiber bundle structure of
the cone of PSD matrices and generalizing the idea of the point-set distance
previously developed for linear subsapces and positive definite (PD) matrices.
The framework demonstrates both theoretical advantages and computational
convenience: (1) We prove that the similarity measurement constructed by the
framework can be recognized either as the cost of a parallel transport or as
the length of a quasi-geodesic curve. (2) We extend commonly used divergences
for equidimensional PD matrices to the non-equidimensional case. Examples
include Kullback-Leibler divergence, Bhattacharyya divergence and R\'enyi
divergence. We prove that these extensions enjoy the same consistency property
as their counterpart for geodesic distance. (3) We apply our geometric
framework to further extend those in (2) to similarity measurements for
arbitrary PSD matrices. We also provide simple formulae to compute these
similarity measurements in most situations.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13722" title="Abstract">arXiv:2312.13722</a> [<a href="/pdf/2312.13722" title="Download PDF">pdf</a>, <a href="/format/2312.13722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAE-Net: A Low complexity and high fidelity Bandwidth-Adaptive neural  network for speech super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guochen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiguang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Runqiang Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chengshi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bing Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech bandwidth extension (BWE) has demonstrated promising performance in
enhancing the perceptual speech quality in real communication systems. Most
existing BWE researches primarily focus on fixed upsampling ratios,
disregarding the fact that the effective bandwidth of captured audio may
fluctuate frequently due to various capturing devices and transmission
conditions. In this paper, we propose a novel streaming adaptive bandwidth
extension solution dubbed BAE-Net, which is suitable to handle the
low-resolution speech with unknown and varying effective bandwidth. To address
the challenges of recovering both the high-frequency magnitude and phase speech
content blindly, we devise a dual-stream architecture that incorporates the
magnitude inpainting and phase refinement. For potential applications on edge
devices, this paper also introduces BAE-NET-lite, which is a lightweight,
streaming and efficient framework. Quantitative results demonstrate the
superiority of BAE-Net in terms of both performance and computational
efficiency when compared with existing state-of-the-art BWE methods.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13729" title="Abstract">arXiv:2312.13729</a> [<a href="/pdf/2312.13729" title="Download PDF">pdf</a>, <a href="/format/2312.13729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Splitting Algorithm with Color and Opacity Depended on Viewing  Direction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malarz%2C+D">Dawid Malarz</a>, 
<a href="/search/cs?searchtype=author&query=Smolak%2C+W">Weronika Smolak</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=Tadeja%2C+S">S&#x142;awomir Tadeja</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have demonstrated the remarkable potential of
neural networks to capture the intricacies of 3D objects. By encoding the shape
and color information within neural network weights, NeRFs excel at producing
strikingly sharp novel views of 3D objects. Recently, numerous generalizations
of NeRFs utilizing generative models have emerged, expanding its versatility.
In contrast, Gaussian Splatting (GS) offers a similar renders quality with
faster training and inference as it does not need neural networks to work. We
encode information about the 3D objects in the set of Gaussian distributions
that can be rendered in 3D similarly to classical meshes. Unfortunately, GS are
difficult to condition since they usually require circa hundred thousand
Gaussian components. To mitigate the caveats of both models, we propose a
hybrid model that uses GS representation of the 3D object's shape and
NeRF-based encoding of color and opacity. Our model uses Gaussian distributions
with trainable positions (i.e. means of Gaussian), shape (i.e. covariance of
Gaussian), color and opacity, and neural network, which takes parameters of
Gaussian and viewing direction to produce changes in color and opacity.
Consequently, our model better describes shadows, light reflections, and
transparency of 3D objects.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13734" title="Abstract">arXiv:2312.13734</a> [<a href="/pdf/2312.13734" title="Download PDF">pdf</a>, <a href="/format/2312.13734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dialogue System of Team NTT-EASE for DRC2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kubo%2C+Y">Yuki Kubo</a>, 
<a href="/search/cs?searchtype=author&query=Yamashita%2C+T">Tomoya Yamashita</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+M">Masanori Yamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We developed a dialogue system as a team NTT-EASE in the Dialogue Robot
Competition 2023 (DRC2023). We introduce a dialogue system (EASE-DRCBot)
constructed for DRC2023. EASE-DRCBot incorporates a manually defined dialogue
flow. The conditions for system utterances are based on keyword extraction,
example-based method, and sentiment analysis. For answering a user's question,
EASE-DRCBot utilizes GPT-3.5 to generate responses. We analyze the results of
the preliminary round and explain future works.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13735" title="Abstract">arXiv:2312.13735</a> [<a href="/pdf/2312.13735" title="Download PDF">pdf</a>, <a href="/format/2312.13735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DECO: Query-Based End-to-End Object Detection with ConvNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detection Transformer (DETR) and its variants have shown great potential for
accurate object detection in recent years. The mechanism of object query
enables DETR family to directly obtain a fixed number of object predictions and
streamlines the detection pipeline. Meanwhile, recent studies also reveal that
with proper architecture design, convolution networks (ConvNets) also achieve
competitive performance with transformers, \eg, ConvNeXt. To this end, in this
paper we explore whether we could build a query-based end-to-end object
detection framework with ConvNets instead of sophisticated transformer
architecture. The proposed framework, \ie, Detection ConvNet (DECO), is
composed of a backbone and convolutional encoder-decoder architecture. We
carefully design the DECO encoder and propose a novel mechanism for our DECO
decoder to perform interaction between object queries and image features via
convolutional layers. We compare the proposed DECO against prior detectors on
the challenging COCO benchmark. Despite its simplicity, our DECO achieves
competitive performance in terms of detection accuracy and running speed.
Specifically, with the ResNet-50 and ConvNeXt-Tiny backbone, DECO obtains
$38.6\%$ and $40.8\%$ AP on COCO \textit{val} set with $35$ and $28$ FPS
respectively and outperforms the DETR model. Incorporated with advanced
multi-scale feature module, our DECO+ achieves $47.8\%$ AP with $34$ FPS. We
hope the proposed DECO brings another perspective for designing object
detection framework.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13737" title="Abstract">arXiv:2312.13737</a> [<a href="/pdf/2312.13737" title="Download PDF">pdf</a>, <a href="/format/2312.13737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Approach to Abstract Multi-stage Cyberattack Data Generation for  ML-Based IDS in Smart Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+%C3%96">&#xd6;mer Sen</a>, 
<a href="/search/cs?searchtype=author&query=Malskorn%2C+P">Philipp Malskorn</a>, 
<a href="/search/cs?searchtype=author&query=Glomb%2C+S">Simon Glomb</a>, 
<a href="/search/cs?searchtype=author&query=Hacker%2C+I">Immanuel Hacker</a>, 
<a href="/search/cs?searchtype=author&query=Henze%2C+M">Martin Henze</a>, 
<a href="/search/cs?searchtype=author&query=Ulbig%2C+A">Andreas Ulbig</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 2023 IEEE Belgrade PowerTech
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Power grids are becoming more digitized, resulting in new opportunities for
the grid operation but also new challenges, such as new threats from the
cyber-domain. To address these challenges, cybersecurity solutions are being
considered in the form of preventive, detective, and reactive measures. Machine
learning-based intrusion detection systems are used as part of detection
efforts to detect and defend against cyberattacks. However, training and
testing data for these systems are often not available or suitable for use in
machine learning models for detecting multi-stage cyberattacks in smart grids.
In this paper, we propose a method to generate synthetic data using a
graph-based approach for training machine learning models in smart grids. We
use an abstract form of multi-stage cyberattacks defined via graph formulations
and simulate the propagation behavior of attacks in the network. Within the
selected scenarios, we observed promising results, but a larger number of
scenarios need to be studied to draw a more informed conclusion about the
suitability of synthesized data.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13744" title="Abstract">arXiv:2312.13744</a> [<a href="/pdf/2312.13744" title="Download PDF">pdf</a>, <a href="/ps/2312.13744" title="Download PostScript">ps</a>, <a href="/format/2312.13744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling of Networked Measuring Systems -- From White-Box Models to  Data Based Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sommer%2C+K">Klaus-Dieter Sommer</a> (1), 
<a href="/search/eess?searchtype=author&query=Harris%2C+P">Peter Harris</a> (2), 
<a href="/search/eess?searchtype=author&query=Eichst%C3%A4dt%2C+S">Sascha Eichst&#xe4;dt</a> (3), 
<a href="/search/eess?searchtype=author&query=F%C3%BCssl%2C+R">Roland F&#xfc;ssl</a> (1), 
<a href="/search/eess?searchtype=author&query=Dorst%2C+T">Tanja Dorst</a> (4), 
<a href="/search/eess?searchtype=author&query=Sch%C3%BCtze%2C+A">Andreas Sch&#xfc;tze</a> (4), 
<a href="/search/eess?searchtype=author&query=Heizmann%2C+M">Michael Heizmann</a> (5), 
<a href="/search/eess?searchtype=author&query=Schiering%2C+N">Nadine Schiering</a> (6), 
<a href="/search/eess?searchtype=author&query=Maier%2C+A">Andreas Maier</a> (7), 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yuhui Luo</a> (2), 
<a href="/search/eess?searchtype=author&query=Tachtatzis%2C+C">Christos Tachtatzis</a> (8), 
<a href="/search/eess?searchtype=author&query=Andonovic%2C+I">Ivan Andonovic</a> (8), 
<a href="/search/eess?searchtype=author&query=Gourlay%2C+G">Gordon Gourlay</a> (9) ((1) Technische Universitaet Ilmenau, Germany, (2) National Physical Laboratory, Teddington, United Kingdom, (3) Physikalisch-Technische Bundesanstalt, Braunschweig and Berlin, Germany, (4) ZeMA - Zentrum f&#xfc;r Mechatronik und Automatisierungstechnik gGmbH, Saarbr&#xfc;cken, Germany, (5) Karlsruhe Institute of Technology, Germany, (6) Centre for Measurement and Calibration, Wolfen, Germany, (7) Friedrich-Alexander-University of Erlangen-Nuremberg, Germany, (8) Department of Electronic and Electrical Engineering, University of Strathclyde, UK, (9) Advanced Forming Research Centre, University of Strathclyde, UK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Mathematical modelling is at the core of metrology as it transforms raw
measured data into useful measurement results. A model captures the
relationship between the measurand and all relevant quantities on which the
measurand depends, and is used to design measuring systems, analyse measured
data, make inferences and predictions, and is the basis for evaluating
measurement uncertainties. Traditional modelling approaches are typically
analytical, for example, based on principles of physics. But with the
increasing use of digital technologies, large sensor networks and powerful
computing hardware, these traditional approaches are being replaced more and
more by data-driven methods. This paradigm shift holds true in particular for
the digital future of measurement in all spheres of our lives and the
environment, where data provided by large and complex interconnected systems of
sensors are to be analysed. Additionally, there is a requirement for existing
guidelines and standards in metrology to take the paradigm shift into account.
In this paper we lay the foundation for the development from traditional to
data-driven modelling approaches. We identify key aspects from traditional
modelling approaches and discuss their transformation to data-driven modelling.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13746" title="Abstract">arXiv:2312.13746</a> [<a href="/pdf/2312.13746" title="Download PDF">pdf</a>, <a href="/format/2312.13746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Recognition in Portrait Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingfei Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaojie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See mingfei.info/PMV for data and code information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The creation of new datasets often presents new challenges for video
recognition and can inspire novel ideas while addressing these challenges.
While existing datasets mainly comprise landscape mode videos, our paper seeks
to introduce portrait mode videos to the research community and highlight the
unique challenges associated with this video format. With the growing
popularity of smartphones and social media applications, recognizing portrait
mode videos is becoming increasingly important. To this end, we have developed
the first dataset dedicated to portrait mode video recognition, namely
PortraitMode-400. The taxonomy of PortraitMode-400 was constructed in a
data-driven manner, comprising 400 fine-grained categories, and rigorous
quality assurance was implemented to ensure the accuracy of human annotations.
In addition to the new dataset, we conducted a comprehensive analysis of the
impact of video format (portrait mode versus landscape mode) on recognition
accuracy and spatial bias due to the different formats. Furthermore, we
designed extensive experiments to explore key aspects of portrait mode video
recognition, including the choice of data augmentation, evaluation procedure,
the importance of temporal information, and the role of audio modality.
Building on the insights from our experimental results and the introduction of
PortraitMode-400, our paper aims to inspire further research efforts in this
emerging research area.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13749" title="Abstract">arXiv:2312.13749</a> [<a href="/pdf/2312.13749" title="Download PDF">pdf</a>, <a href="/format/2312.13749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Market Maker on the XRP Ledger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dahi%2C+F">Firas Dahi</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+W">Walter Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yebo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiahua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Malhotra%2C+A">Aanchal Malhotra</a>, 
<a href="/search/cs?searchtype=author&query=Tasca%2C+P">Paolo Tasca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This research paper focuses on the testing and evaluation of the proposed XRP
Ledger (XRPL)-Automated Market Maker (AMM), designed to address the limitations
observed in traditional Ethereum-based Automated Market Makers (AMMs), such as
high transaction fees, significant slippage, high impermanent losses,
synchronization issues, and low transaction throughput. XRPL-AMM leverages the
swift, cost-efficient transaction capabilities of XRPL and its unique design,
featuring a Continuous Auction Mechanism (CAM) that encourages arbitrage
transactions for more efficient price synchronization with external markets.
Our testing and evaluation of the proposed XRPL-AMM compares its performance
against established players like Uniswap. Our evaluation results reveal that
the XRPL-AMM, leveraging market volatility, outperforms Uniswap in various
areas, including slippage and impermanent loss reduction, the pace of price
synchronization, and overall operational efficiency. Our research contributes
to the growing field of Decentralized Finance (DeFi) by providing comprehensive
testing results that underline XRPL-AMM's potential as a more efficient
alternative to current AMMs while encouraging further exploration in XRPL-based
DeFi ecosystems.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13754" title="Abstract">arXiv:2312.13754</a> [<a href="/pdf/2312.13754" title="Download PDF">pdf</a>, <a href="/format/2312.13754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Layer Optimization for Fault-Tolerant Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haitong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, it has been presented at CCF-DAC 2023 while CCF-DAC does not own the copyright
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fault-tolerant deep learning accelerator is the basis for highly reliable
deep learning processing and critical to deploy deep learning in
safety-critical applications such as avionics and robotics. Since deep learning
is known to be computing- and memory-intensive, traditional fault-tolerant
approaches based on redundant computing will incur substantial overhead
including power consumption and chip area. To this end, we propose to
characterize deep learning vulnerability difference across both neurons and
bits of each neuron, and leverage the vulnerability difference to enable
selective protection of the deep learning processing components from the
perspective of architecture layer and circuit layer respectively. At the same
time, we observe the correlation between model quantization and bit protection
overhead of the underlying processing elements of deep learning accelerators,
and propose to reduce the bit protection overhead by adding additional
quantization constrain without compromising the model accuracy. Finally, we
employ Bayesian optimization strategy to co-optimize the correlated cross-layer
design parameters at algorithm layer, architecture layer, and circuit layer to
minimize the hardware resource consumption while fulfilling multiple user
constraints including reliability, accuracy, and performance of the deep
learning processing at the same time.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13763" title="Abstract">arXiv:2312.13763</a> [<a href="/pdf/2312.13763" title="Download PDF">pdf</a>, <a href="/format/2312.13763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Huan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+W">Seung Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+K">Karsten Kreis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-guided diffusion models have revolutionized image and video generation
and have also been successfully used for optimization-based 3D object
synthesis. Here, we instead focus on the underexplored text-to-4D setting and
synthesize dynamic, animated 3D objects using score distillation methods with
an additional temporal dimension. Compared to previous work, we pursue a novel
compositional generation-based approach, and combine text-to-image,
text-to-video, and 3D-aware multiview diffusion models to provide feedback
during 4D object optimization, thereby simultaneously enforcing temporal
consistency, high-quality visual appearance and realistic geometry. Our method,
called Align Your Gaussians (AYG), leverages dynamic 3D Gaussian Splatting with
deformation fields as 4D representation. Crucial to AYG is a novel method to
regularize the distribution of the moving 3D Gaussians and thereby stabilize
the optimization and induce motion. We also propose a motion amplification
mechanism as well as a new autoregressive synthesis scheme to generate and
combine multiple 4D sequences for longer generation. These techniques allow us
to synthesize vivid dynamic scenes, outperform previous work qualitatively and
quantitatively and achieve state-of-the-art text-to-4D performance. Due to the
Gaussian 4D representation, different 4D animations can be seamlessly combined,
as we demonstrate. AYG opens up promising avenues for animation, simulation and
digital content creation as well as synthetic data generation.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13764" title="Abstract">arXiv:2312.13764</a> [<a href="/pdf/2312.13764" title="Download PDF">pdf</a>, <a href="/format/2312.13764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semantic Space is Worth 256 Language Descriptions: Make Stronger  Segmentation Models with Descriptive Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junfei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Shiyi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiding Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Code is available at <a href="https://github.com/lambert-x/ProLab">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces ProLab, a novel approach using property-level label
space for creating strong interpretable segmentation models. Instead of relying
solely on category-specific annotations, ProLab uses descriptive properties
grounded in common sense knowledge for supervising segmentation models. It is
based on two core designs. First, we employ Large Language Models (LLMs) and
carefully crafted prompts to generate descriptions of all involved categories
that carry meaningful common sense knowledge and follow a structured format.
Second, we introduce a description embedding model preserving semantic
correlation across descriptions and then cluster them into a set of descriptive
properties (e.g., 256) using K-Means. These properties are based on
interpretable common sense knowledge consistent with theories of human
recognition. We empirically show that our approach makes segmentation models
perform stronger on five classic benchmarks (e.g., ADE20K, COCO-Stuff, Pascal
Context, Cityscapes, and BDD). Our method also shows better scalability with
extended training steps than category-level supervision. Our interpretable
segmentation framework also emerges with the generalization ability to segment
out-of-domain or unknown categories using only in-domain descriptive
properties. Code is available at https://github.com/lambert-x/ProLab.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13765" title="Abstract">arXiv:2312.13765</a> [<a href="/pdf/2312.13765" title="Download PDF">pdf</a>, <a href="/ps/2312.13765" title="Download PostScript">ps</a>, <a href="/format/2312.13765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Team Irisapu Project Description for DRC2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohashi%2C+R">Reon Ohashi</a>, 
<a href="/search/cs?searchtype=author&query=Agatsuma%2C+S">Shinjitsu Agatsuma</a>, 
<a href="/search/cs?searchtype=author&query=Tsubokura%2C+K">Kazuya Tsubokura</a>, 
<a href="/search/cs?searchtype=author&query=Iribe%2C+Y">Yurie Iribe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper describes the dialog robot system designed by Team Irisapu for the
preliminary round of the Dialogue Robot Competition 2023 (DRC2023). In order to
generate dialogue responses flexibly while adhering to predetermined scenarios,
we attempted to generate dialogue response sentences using OpenAI's GPT-3. We
aimed to create a system that can appropriately respond to users by dividing
the dialogue scenario into five sub-scenarios, and creating prompts for each
sub-scenario. Also, we incorporated a recovery strategy that can handle
dialogue breakdowns flexibly. Our research group has been working on research
related to dialogue breakdown detection, and we incorporated our findings to
date in this competition. As a result of the preliminary round, a bug in our
system affected the outcome and we were not able to achieve a satisfactory
result. However, in the evaluation category of "reliability of provided
information", we ranked third among all teams.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13766" title="Abstract">arXiv:2312.13766</a> [<a href="/pdf/2312.13766" title="Download PDF">pdf</a>, <a href="/format/2312.13766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Contextual Target Attributes for Target Sentiment  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+B">Bowen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+W">Ivor W. Tsang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Journal of Artificial Intelligence Research (JAIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing PTLM-based models for TSC can be categorized into two groups: 1)
fine-tuning-based models that adopt PTLM as the context encoder; 2)
prompting-based models that transfer the classification task to the text/word
generation task. In this paper, we present a new perspective of leveraging PTLM
for TSC: simultaneously leveraging the merits of both language modeling and
explicit target-context interactions via contextual target attributes.
Specifically, we design the domain- and target-constrained cloze test, which
can leverage the PTLMs' strong language modeling ability to generate the given
target's attributes pertaining to the review context. The attributes contain
the background and property information of the target, which can help to enrich
the semantics of the review context and the target. To exploit the attributes
for tackling TSC, we first construct a heterogeneous information graph by
treating the attributes as nodes and combining them with (1) the syntax graph
automatically produced by the off-the-shelf dependency parser and (2) the
semantics graph of the review context, which is derived from the self-attention
mechanism. Then we propose a heterogeneous information gated graph
convolutional network to model the interactions among the attribute
information, the syntactic information, and the contextual information. The
experimental results on three benchmark datasets demonstrate the superiority of
our model, which achieves new state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13768" title="Abstract">arXiv:2312.13768</a> [<a href="/pdf/2312.13768" title="Download PDF">pdf</a>, <a href="/format/2312.13768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Interference from Millimeter Wave and Terahertz Bans  Cross-links in Low Earth Orbit Satellite Networks for 6G and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliaga%2C+S">Sergi Aliaga</a>, 
<a href="/search/cs?searchtype=author&query=Petrov%2C+V">Vitaly Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Jornet%2C+J+M">Josep M. Jornet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 Figures, 2 Tables. The work has been accepted for publication in IEEE Journal on Selected Areas in Communications (JSAC), 2024. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">High-rate satellite communications among hundreds and even thousands of
satellites deployed at low-Earth orbits (LEO) will be an important element of
the forthcoming sixth-generation (6G) of wireless systems beyond 2030. With
millimeter wave communications (mmWave, ~30GHz-100GHz) completely integrated
into 5G terrestrial networks, exploration of its potential, along with
sub-terahertz (sub-THz, 100GHz-300GHz), and even THz (300GHz-3THz) frequencies,
is underway for space-based networks. However, the interference problem between
LEO mmWave/THz satellite cross-links in the same or different constellations is
undeservedly forgotten. This article presents a comprehensive mathematical
framework for modeling directional interference in all key possible scenario
geometries. The framework description is followed by an in-depth numerical
study on the impact of cross-link interference on various performance
indicators, where the delivered analytical results are cross-verified via
computer simulations. The study reveals that, while highly directional mmWave
and, especially, THz beams minimize interference in many cases, there are
numerous practical configurations where the impact of cross-link interference
cannot be neglected and must be accounted for.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13769" title="Abstract">arXiv:2312.13769</a> [<a href="/pdf/2312.13769" title="Download PDF">pdf</a>, <a href="/format/2312.13769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Problems in Trees, with Applications to Fixed Points of  Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turau%2C+V">Volker Turau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures. Extended version of paper to appear at LATIN 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Cellular automata are synchronous discrete dynamical systems used to describe
complex dynamic behaviors. The dynamic is based on local interactions between
the components, these are defined by a finite graph with an initial node
coloring with two colors. In each step, all nodes change their current color
synchronously to the least/most frequent color in their neighborhood and in
case of a tie, keep their current color. After a finite number of rounds these
systems either reach a fixed point or enter a 2-cycle. The problem of counting
the number of fixed points for cellular automata is #P-complete. In this paper
we consider cellular automata defined by a tree. We propose an algorithm with
run-time $O(n\Delta)$ to count the number of fixed points, here $\Delta$ is the
maximal degree of the tree. We also prove upper and lower bounds for the number
of fixed points. Furthermore, we obtain corresponding results for pure cycles,
i.e., instances where each node changes its color in every round. We provide
examples demonstrating that the bounds are sharp. The results are proved for
the minority and the majority model.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13770" title="Abstract">arXiv:2312.13770</a> [<a href="/pdf/2312.13770" title="Download PDF">pdf</a>, <a href="/format/2312.13770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Points Splatting for Real-Time Dynamic Hand Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zheheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+H">Hossein Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+S">Sue Black</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B+M">Bryan M. Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present 3D Points Splatting Hand Reconstruction (3D-PSHR), a real-time and
photo-realistic hand reconstruction approach. We propose a self-adaptive
canonical points upsampling strategy to achieve high-resolution hand geometry
representation. This is followed by a self-adaptive deformation that deforms
the hand from the canonical space to the target pose, adapting to the dynamic
changing of canonical points which, in contrast to the common practice of
subdividing the MANO model, offers greater flexibility and results in improved
geometry fitting. To model texture, we disentangle the appearance color into
the intrinsic albedo and pose-aware shading, which are learned through a
Context-Attention module. Moreover, our approach allows the geometric and the
appearance models to be trained simultaneously in an end-to-end manner. We
demonstrate that our method is capable of producing animatable, photorealistic
and relightable hand reconstructions using multiple datasets, including
monocular videos captured with handheld smartphones and large-scale multi-view
videos featuring various hand poses. We also demonstrate that our approach
achieves real-time rendering speeds while simultaneously maintaining superior
performance compared to existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13771" title="Abstract">arXiv:2312.13771</a> [<a href="/pdf/2312.13771" title="Download PDF">pdf</a>, <a href="/format/2312.13771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AppAgent: Multimodal Agents as Smartphone Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yucheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zebiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have led to the creation
of intelligent agents capable of performing complex tasks. This paper
introduces a novel LLM-based multimodal agent framework designed to operate
smartphone applications. Our framework enables the agent to operate smartphone
applications through a simplified action space, mimicking human-like
interactions such as tapping and swiping. This novel approach bypasses the need
for system back-end access, thereby broadening its applicability across diverse
apps. Central to our agent's functionality is its innovative learning method.
The agent learns to navigate and use new apps either through autonomous
exploration or by observing human demonstrations. This process generates a
knowledge base that the agent refers to for executing complex tasks across
different applications. To demonstrate the practicality of our agent, we
conducted extensive testing over 50 tasks in 10 different applications,
including social media, email, maps, shopping, and sophisticated image editing
tools. The results affirm our agent's proficiency in handling a diverse array
of high-level tasks.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13772" title="Abstract">arXiv:2312.13772</a> [<a href="/pdf/2312.13772" title="Download PDF">pdf</a>, <a href="/format/2312.13772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Task Performance and Model Calibration with Supervised and  Self-Ensembled In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengzu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Glava%C5%A1%2C+G">Goran Glava&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 5 tables (20 pages, 5 figures, 13 tables including references and appendices)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Following the standard supervised fine-tuning (SFT) paradigm, in-context
learning (ICL) has become an efficient approach propelled by the recent
advancements in large language models (LLMs), yielding promising performance
across various tasks in few-shot data setups. However, both paradigms are prone
to suffer from the critical problem of overconfidence (i.e., miscalibration),
especially in such limited data setups. In this work, we deliver an in-depth
analysis of the behavior across different choices of learning methods from the
perspective of both performance and calibration, as well as their interplay.
Through extensive controlled experiments, we find that simultaneous gains for
both task performance and calibration are difficult to achieve, and the problem
of miscalibration exists across all learning methods in low-resource
scenarios.To address this challenging trade-off between performance and
calibration, we then investigate the potential of self-ensembling techniques
applied at different modeling stages (e.g., variations of in-context examples
or variations in prompts or different ensembling strategies). We justify the
feasibility of self-ensembling on SFT in addition to ICL, to make the
predictions more calibrated and have comparable or even better performance. Our
work sheds light on which learning paradigm to choose and how to enhance both
task performance and calibration of LLMs.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13774" title="Abstract">arXiv:2312.13774</a> [<a href="/pdf/2312.13774" title="Download PDF">pdf</a>, <a href="/ps/2312.13774" title="Download PostScript">ps</a>, <a href="/format/2312.13774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Assumptions and Proposals for Blockchain Integration in  the Circular Economy. A Delphi Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caldarelli%2C+G">Giulio Caldarelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The name of experts involved are not mentioned in this version, but will be public in the journal one as to avoid unwanted representation of their thoughts and ideas
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">Given the rising interest in the circular economy and blockchain hype,
numerous integrations were proposed. However, studies on the practical
feasibility were scarce, and the assumptions of blockchain potential in the
circular economy were rarely questioned. With the help of eleven of the most
prominent blockchain experts, the present study critically analyzed technology
integration in many areas of the circular economy to forecast their possible
outcomes. Delphi's technique is leveraged to reach a consensus among experts'
visions and opinions. Results support the view that some circular economy
integrations are unlikely to succeed, while others if specific conditions are
met, may prove to be successful in the long run.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13776" title="Abstract">arXiv:2312.13776</a> [<a href="/pdf/2312.13776" title="Download PDF">pdf</a>, <a href="/format/2312.13776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose-based Tremor Type and Level Analysis for Parkinson&#x27;s Disease from  Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haozheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+E+S+L">Edmond S. L. Ho</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiatian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Del+Din%2C+S">Silvia Del Din</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+H+P+H">Hubert P. H. Shum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Purpose:Current methods for diagnosis of PD rely on clinical examination. The
accuracy of diagnosis ranges between 73% and 84%, and is influenced by the
experience of the clinical assessor. Hence, an automatic, effective and
interpretable supporting system for PD symptom identification would support
clinicians in making more robust PD diagnostic decisions. Methods: We propose
to analyze Parkinson's tremor (PT) to support the analysis of PD, since PT is
one of the most typical symptoms of PD with broad generalizability. To realize
the idea, we present SPA-PTA, a deep learning-based PT classification and
severity estimation system that takes consumer-grade videos of front-facing
humans as input. The core of the system is a novel attention module with a
lightweight pyramidal channel-squeezing-fusion architecture that effectively
extracts relevant PT information and filters noise. It enhances modeling
performance while improving system interpretability. Results:We validate our
system via individual-based leave-one-out cross-validation on two tasks: the PT
classification task and the tremor severity rating estimation task. Our system
presents a 91.3% accuracy and 80.0% F1-score in classifying PT with non-PT
class, while providing a 76.4% accuracy and 76.7% F1-score in more complex
multiclass tremor rating classification task. Conclusion: Our system offers a
cost-effective PT classification and tremor severity estimation results as
warning signs of PD for undiagnosed patients with PT symptoms. In addition, it
provides a potential solution for supporting PD diagnosis in regions with
limited clinical resources.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13777" title="Abstract">arXiv:2312.13777</a> [<a href="/pdf/2312.13777" title="Download PDF">pdf</a>, <a href="/format/2312.13777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arma: Byzantine Fault Tolerant consensus with Linear Scalability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manevich%2C+Y">Yacov Manevich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Arma is a Byzantine Fault Tolerant (BFT) consensus system designed to achieve
linear scalability across all hardware resources: network bandwidth, CPU, and
disk I/O. As opposed to preceding BFT protocols, Arma separates the
dissemination and validation of client transactions from the consensus process,
restricting the latter to totally ordering only metadata of batches of
transactions. This separation enables each party to distribute compute and
storage resources for transaction validation, dissemination and disk I/O among
multiple machines, resulting in linear scalability. Additionally, Arma ensures
censorship resistance by imposing a maximum time limit for the inclusion of
client transactions. We build a prototype implementation of Arma and evaluate
its performance experimentally. Our results show that Arma totally orders over
100,000 transactions per second when deployed in a WAN setting and integrated
into Hyperledger Fabric.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13778" title="Abstract">arXiv:2312.13778</a> [<a href="/pdf/2312.13778" title="Download PDF">pdf</a>, <a href="/format/2312.13778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Evolution from Single-Point to Polygon for Scene Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Linger Deng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xudong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advancement of text shape representations towards compactness has
enhanced text detection and spotting performance, but at a high annotation
cost. Current models use single-point annotations to reduce costs, yet they
lack sufficient localization information for downstream applications. To
overcome this limitation, we introduce Point2Polygon, which can efficiently
transform single-points into compact polygons. Our method uses a coarse-to-fine
process, starting with creating and selecting anchor points based on
recognition confidence, then vertically and horizontally refining the polygon
using recognition information to optimize its shape. We demonstrate the
accuracy of the generated polygons through extensive experiments: 1) By
creating polygons from ground truth points, we achieved an accuracy of 82.0% on
ICDAR 2015; 2) In training detectors with polygons generated by our method, we
attained 86% of the accuracy relative to training with ground truth (GT); 3)
Additionally, the proposed Point2Polygon can be seamlessly integrated to
empower single-point spotters to generate polygons. This integration led to an
impressive 82.5% accuracy for the generated polygons. It is worth mentioning
that our method relies solely on synthetic recognition information, eliminating
the need for any manual annotation beyond single points.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13783" title="Abstract">arXiv:2312.13783</a> [<a href="/pdf/2312.13783" title="Download PDF">pdf</a>, <a href="/format/2312.13783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few Shot Part Segmentation Reveals Compositional Logic for Industrial  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Soopil Kim</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Sion An</a>, 
<a href="/search/cs?searchtype=author&query=Chikontwe%2C+P">Philip Chikontwe</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Myeongkyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Adeli%2C+E">Ehsan Adeli</a>, 
<a href="/search/cs?searchtype=author&query=Pohl%2C+K+M">Kilian M. Pohl</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sanghyun Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Logical anomalies (LA) refer to data violating underlying logical constraints
e.g., the quantity, arrangement, or composition of components within an image.
Detecting accurately such anomalies requires models to reason about various
component types through segmentation. However, curation of pixel-level
annotations for semantic segmentation is both time-consuming and expensive.
Although there are some prior few-shot or unsupervised co-part segmentation
algorithms, they often fail on images with industrial object. These images have
components with similar textures and shapes, and a precise differentiation
proves challenging. In this study, we introduce a novel component segmentation
model for LA detection that leverages a few labeled samples and unlabeled
images sharing logical constraints. To ensure consistent segmentation across
unlabeled images, we employ a histogram matching loss in conjunction with an
entropy loss. As segmentation predictions play a crucial role, we propose to
enhance both local and global sample validity detection by capturing key
aspects from visual semantics via three memory banks: class histograms,
component composition embeddings and patch-level representations. For effective
LA detection, we propose an adaptive scaling strategy to standardize anomaly
scores from different memory banks in inference. Extensive experiments on the
public benchmark MVTec LOCO AD reveal our method achieves 98.1% AUROC in LA
detection vs. 89.6% from competing methods.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13784" title="Abstract">arXiv:2312.13784</a> [<a href="/pdf/2312.13784" title="Download PDF">pdf</a>, <a href="/format/2312.13784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Evolutionary Community Detection Algorithms in Dynamic  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paoletti%2C+G">Giordano Paoletti</a>, 
<a href="/search/cs?searchtype=author&query=Gioacchini%2C+L">Luca Gioacchini</a>, 
<a href="/search/cs?searchtype=author&query=Mellia%2C+M">Marco Mellia</a>, 
<a href="/search/cs?searchtype=author&query=Vassio%2C+L">Luca Vassio</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+J+M">Jussara M. Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 4th Workshop on Graphs and more Complex structures for Learning and Reasoning (GCLR) at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In dynamic complex networks, entities interact and form network communities
that evolve over time. Among the many static Community Detection (CD)
solutions, the modularity-based Louvain, or Greedy Modularity Algorithm (GMA),
is widely employed in real-world applications due to its intuitiveness and
scalability. Nevertheless, addressing CD in dynamic graphs remains an open
problem, since the evolution of the network connections may poison the
identification of communities, which may be evolving at a slower pace. Hence,
naively applying GMA to successive network snapshots may lead to temporal
inconsistencies in the communities. Two evolutionary adaptations of GMA, sGMA
and $\alpha$GMA, have been proposed to tackle this problem. Yet, evaluating the
performance of these methods and understanding to which scenarios each one is
better suited is challenging because of the lack of a comprehensive set of
metrics and a consistent ground truth. To address these challenges, we propose
(i) a benchmarking framework for evolutionary CD algorithms in dynamic networks
and (ii) a generalised modularity-based approach (NeGMA). Our framework allows
us to generate synthetic community-structured graphs and design evolving
scenarios with nine basic graph transformations occurring at different rates.
We evaluate performance through three metrics we define, i.e. Correctness,
Delay, and Stability. Our findings reveal that $\alpha$GMA is well-suited for
detecting intermittent transformations, but struggles with abrupt changes; sGMA
achieves superior stability, but fails to detect emerging communities; and
NeGMA appears a well-balanced solution, excelling in responsiveness and
instantaneous transformations detection.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13787" title="Abstract">arXiv:2312.13787</a> [<a href="/pdf/2312.13787" title="Download PDF">pdf</a>, <a href="/format/2312.13787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-adaptive Tourist Information Dialogue System with Yes/No Classifier  and Sentiment Estimator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yanagimoto%2C+R">Ryo Yanagimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kubo%2C+Y">Yunosuke Kubo</a>, 
<a href="/search/cs?searchtype=author&query=Oshio%2C+M">Miki Oshio</a>, 
<a href="/search/cs?searchtype=author&query=Nakano%2C+M">Mikio Nakano</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+K">Kenta Yamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Komatani%2C+K">Kazunori Komatani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We introduce our system developed for Dialogue Robot Competition 2023
(DRC2023). First, rule-based utterance selection and utterance generation using
a large language model (LLM) are combined. We ensure the quality of system
utterances while also being able to respond to unexpected user utterances.
Second, dialogue flow is controlled by considering the results of the
BERT-based yes/no classifier and sentiment estimator. These allow the system to
adapt state transitions and sightseeing plans to the user.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13788" title="Abstract">arXiv:2312.13788</a> [<a href="/pdf/2312.13788" title="Download PDF">pdf</a>, <a href="/format/2312.13788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Source Reinforcement Learning Environments Implemented in MuJoCo  with Franka Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zichun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaohang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+L">Lei Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingdong Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents three open-source reinforcement learning environments
developed on the MuJoCo physics engine with the Franka Emika Panda arm in
MuJoCo Menagerie. Three representative tasks, push, slide, and pick-and-place,
are implemented through the Gymnasium Robotics API, which inherits from the
core of Gymnasium. Both the sparse binary and dense rewards are supported, and
the observation space contains the keys of desired and achieved goals to follow
the Multi-Goal Reinforcement Learning framework. Three different off-policy
algorithms are used to validate the simulation attributes to ensure the
fidelity of all tasks, and benchmark results are also given. Each environment
and task are defined in a clean way, and the main parameters for modifying the
environment are preserved to reflect the main difference. The repository,
including all environments, is available at
https://github.com/zichunxx/panda_mujoco_gym.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13789" title="Abstract">arXiv:2312.13789</a> [<a href="/pdf/2312.13789" title="Download PDF">pdf</a>, <a href="/format/2312.13789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinySAM: Pushing the Envelope for Efficient Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+H">Han Shu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenshuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yehui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinghao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently segment anything model (SAM) has shown powerful segmentation
capability and has drawn great attention in computer vision fields. Massive
following works have developed various applications based on the pretrained SAM
and achieved impressive performance on downstream vision tasks. However, SAM
consists of heavy architectures and requires massive computational capacity,
which hinders the further application of SAM on computation constrained edge
devices. To this end, in this paper we propose a framework to obtain a tiny
segment anything model (TinySAM) while maintaining the strong zero-shot
performance. We first propose a full-stage knowledge distillation method with
online hard prompt sampling strategy to distill a lightweight student model. We
also adapt the post-training quantization to the promptable segmentation task
and further reduce the computational cost. Moreover, a hierarchical segmenting
everything strategy is proposed to accelerate the everything inference by
$2\times$ with almost no performance degradation. With all these proposed
methods, our TinySAM leads to orders of magnitude computational reduction and
pushes the envelope for efficient segment anything task. Extensive experiments
on various zero-shot transfer tasks demonstrate the significantly advantageous
performance of our TinySAM against counterpart methods. Pre-trained models and
codes will be available at https://github.com/xinghaochen/TinySAM and
https://gitee.com/mindspore/models/tree/master/research/cv/TinySAM.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13791" title="Abstract">arXiv:2312.13791</a> [<a href="/pdf/2312.13791" title="Download PDF">pdf</a>, <a href="/format/2312.13791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Guarantees for Almost Envy-Free Allocations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barman%2C+S">Siddharth Barman</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+D">Debajyoti Kar</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+S">Shraddha Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study fair allocation of indivisible goods among agents with additive
valuations. We obtain novel approximation guarantees for three of the strongest
fairness notions in discrete fair division, namely envy-free up to the removal
of any positively-valued good (EFx), pairwise maximin shares (PMMS), and
envy-free up to the transfer of any positively-valued good (tEFx). Our
approximation guarantees are in terms of an instance-dependent parameter
$\gamma \in (0,1]$ that upper bounds, for each indivisible good in the given
instance, the multiplicative range of nonzero values for the good across the
agents.
<br />First, we consider allocations wherein, between any pair of agents and up to
the removal of any positively-valued good, the envy is multiplicatively
bounded. Specifically, the current work develops a polynomial-time algorithm
that computes a $\left(
\frac{2\gamma}{\sqrt{5+4\gamma}-1}\right)$-approximately EFx allocation for any
given fair division instance with range parameter $\gamma \in (0,1]$. For
instances with $\gamma \geq 0.511$, the obtained approximation guarantee for
EFx surpasses the previously best-known approximation bound of $(\phi-1)
\approx 0.618$, here $\phi$ denotes the golden ratio.
<br />Furthermore, for $\gamma \in (0,1]$, we develop a polynomial-time algorithm
for finding allocations wherein the PMMS requirement is satisfied, between
every pair of agents, within a multiplicative factor of $\frac{5}{6} \gamma$.
En route to this result, we obtain novel existential and computational
guarantees for $\frac{5}{6}$-approximately PMMS allocations under restricted
additive valuations.
<br />Finally, we develop an algorithm that efficiently computes a
$2\gamma$-approximately tEFx allocation. Specifically, we obtain existence and
efficient computation of exact tEFx allocations for all instances with $\gamma
\in [0.5, 1]$.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13792" title="Abstract">arXiv:2312.13792</a> [<a href="/pdf/2312.13792" title="Download PDF">pdf</a>, <a href="/format/2312.13792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Approach to Colour Morphological Supremum Formation using the  LogSumExp Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kahra%2C+M">Marvin Kahra</a>, 
<a href="/search/cs?searchtype=author&query=Breu%C3%9F%2C+M">Michael Breu&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Kleefeld%2C+A">Andreas Kleefeld</a>, 
<a href="/search/cs?searchtype=author&query=Welk%2C+M">Martin Welk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 28 figures, submitted to IAPR Third International Conference on Discrete Geometry and Mathematical Morphology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Mathematical morphology is a part of image processing that has proven to be
fruitful for numerous applications. Two main operations in mathematical
morphology are dilation and erosion. These are based on the construction of a
supremum or infimum with respect to an order over the tonal range in a certain
section of the image. The tonal ordering can easily be realised in grey-scale
morphology, and some morphological methods have been proposed for colour
morphology. However, all of these have certain limitations. In this paper we
present a novel approach to colour morphology extending upon previous work in
the field based on the Loewner order. We propose to consider an approximation
of the supremum by means of a log-sum exponentiation introduced by Maslov. We
apply this to the embedding of an RGB image in a field of symmetric $2\times2$
matrices. In this way we obtain nearly isotropic matrices representing colours
and the structural advantage of transitivity. In numerical experiments we
highlight some remarkable properties of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13794" title="Abstract">arXiv:2312.13794</a> [<a href="/pdf/2312.13794" title="Download PDF">pdf</a>, <a href="/format/2312.13794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE Wireless Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Instead of treating the noise as a detrimental effect, can we use it as an
information carrier? In this letter, we provide the conceptual and mathematical
foundations of wireless communication utilizing noise and random signals in
general. Mainly, the concept of noise modulation (NoiseMod) is introduced to
cover information transmission by both thermal noise and externally generated
noise signals. The performance of underlying NoiseMod schemes is evaluated
under both additive white Gaussian and fading channels and alternative NoiseMod
designs exploiting non-coherent detection and time diversity are proposed.
Extensive numerical and computer simulation results are presented to validate
our designs and theoretical derivations.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13795" title="Abstract">arXiv:2312.13795</a> [<a href="/pdf/2312.13795" title="Download PDF">pdf</a>, <a href="/format/2312.13795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Training for Federated Learning with Regularized Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greidi%2C+R">Ran Greidi</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+K">Kobi Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has attracted much interest due to the significant
advantages it brings to training deep neural network (DNN) models. However,
since communications and computation resources are limited, training DNN models
in FL systems face challenges such as elevated computational and communication
costs in complex tasks. Sparse training schemes gain increasing attention in
order to scale down the dimensionality of each client (i.e., node)
transmission. Specifically, sparsification with error correction methods is a
promising technique, where only important updates are sent to the parameter
server (PS) and the rest are accumulated locally. While error correction
methods have shown to achieve a significant sparsification level of the
client-to-PS message without harming convergence, pushing sparsity further
remains unresolved due to the staleness effect. In this paper, we propose a
novel algorithm, dubbed Federated Learning with Accumulated Regularized
Embeddings (FLARE), to overcome this challenge. FLARE presents a novel sparse
training approach via accumulated pulling of the updated models with
regularization on the embeddings in the FL process, providing a powerful
solution to the staleness effect, and pushing sparsity to an exceptional level.
The performance of FLARE is validated through extensive experiments on diverse
and complex models, achieving a remarkable sparsity level (10 times and more
beyond the current state-of-the-art) along with significantly improved
accuracy. Additionally, an open-source software package has been developed for
the benefit of researchers and developers in related fields.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13797" title="Abstract">arXiv:2312.13797</a> [<a href="/pdf/2312.13797" title="Download PDF">pdf</a>, <a href="/format/2312.13797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Beamforming for Secure Integrated Sensing and Communication  Exploiting Target Location Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+K">Kaiyue Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuowen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for possible journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we study a secure integrated sensing and communication (ISAC)
system where one multi-antenna base station (BS) simultaneously communicates
with one single-antenna user and senses the location parameter of a target
which serves as a potential eavesdropper via its reflected echo signals. In
particular, we consider a challenging scenario where the target's location is
unknown and random, while its distribution information is known a priori.
First, we derive the posterior Cram\'er-Rao bound (PCRB) of the mean-squared
error (MSE) in target location sensing, which has a complicated expression. To
draw more insights, we derive a tight approximation of it in closed form, which
indicates that the transmit beamforming should achieve a "probability-dependent
power focusing" effect over possible target locations, with more power focused
on highly-probable locations. Next, considering an artificial noise based
beamforming structure, we formulate the transmit beamforming optimization
problem to maximize the worst-case secrecy rate among all possible target
(eavesdropper) locations, subject to a threshold on the sensing PCRB. The
formulated problem is non-convex and difficult to solve. We show that the
problem can be solved via a two-stage method, by first obtaining the optimal
beamforming corresponding to any given threshold on the
signal-to-interference-plus-noise ratio (SINR) at the eavesdropper, and then
obtaining the optimal threshold via one-dimensional search. By applying the
semi-definite relaxation (SDR) technique, we relax the first problem into a
convex form and further prove that the relaxation is tight, based on which the
optimal solution of the original beamforming optimization problem can be
obtained with polynomial-time complexity. Then, we further propose two
suboptimal solutions with lower complexity. Numerical results validate the
effectiveness of our designs.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13802" title="Abstract">arXiv:2312.13802</a> [<a href="/pdf/2312.13802" title="Download PDF">pdf</a>, <a href="/format/2312.13802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dense Subframe-based SLAM Framework with Side-scan Sonar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiping Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+L">Li Ling</a>, 
<a href="/search/cs?searchtype=author&query=Folkesson%2C+J">John Folkesson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures. arXiv admin note: substantial text overlap with <a href="/abs/2304.01854">arXiv:2304.01854</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Side-scan sonar (SSS) is a lightweight acoustic sensor that is commonly
deployed on autonomous underwater vehicles (AUVs) to provide high-resolution
seafloor images. However, leveraging side-scan images for simultaneous
localization and mapping (SLAM) presents a notable challenge, primarily due to
the difficulty of establishing sufficient amount of accurate correspondences
between these images. To address this, we introduce a novel subframe-based
dense SLAM framework utilizing side-scan sonar data, enabling effective dense
matching in overlapping regions of paired side-scan images. With each image
being evenly divided into subframes, we propose a robust estimation pipeline to
estimate the relative pose between each paired subframes, by using a good
inlier set identified from dense correspondences. These relative poses are then
integrated as edge constraints in a factor graph to optimize the AUV pose
trajectory.
<br />The proposed framework is evaluated on three real datasets collected by a
Hugin AUV. Among one of them includes manually-annotated keypoint
correspondences as ground truth and is used for evaluation of pose trajectory.
We also present a feasible way of evaluating mapping quality against multi-beam
echosounder (MBES) data without the influence of pose. Experimental results
demonstrate that our approach effectively mitigates drift from the
dead-reckoning (DR) system and enables quasi-dense bathymetry reconstruction.
An open-source implementation of this work is available.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13804" title="Abstract">arXiv:2312.13804</a> [<a href="/pdf/2312.13804" title="Download PDF">pdf</a>, <a href="/ps/2312.13804" title="Download PostScript">ps</a>, <a href="/format/2312.13804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the ensemble Kalman inversion under inequality constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hanu%2C+M">Matei Hanu</a>, 
<a href="/search/math?searchtype=author&query=Weissmann%2C+S">Simon Weissmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The ensemble Kalman inversion (EKI), a recently introduced optimisation
method for solving inverse problems, is widely employed for the efficient and
derivative-free estimation of unknown parameters. Specifically in cases
involving ill-posed inverse problems and high-dimensional parameter spaces, the
scheme has shown promising success. However, in its general form, the EKI does
not take constraints into account, which are essential and often stem from
physical limitations or specific requirements. Based on a log-barrier approach,
we suggest adapting the continuous-time formulation of EKI to incorporate
convex inequality constraints. We underpin this adaptation with a theoretical
analysis that provides lower and upper bounds on the ensemble collapse, as well
as convergence to the constraint optimum for general nonlinear forward models.
Finally, we showcase our results through two examples involving partial
differential equations (PDEs).
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13809" title="Abstract">arXiv:2312.13809</a> [<a href="/pdf/2312.13809" title="Download PDF">pdf</a>, <a href="/format/2312.13809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unitary rational best approximations to the exponential function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jawecki%2C+T">Tobias Jawecki</a>, 
<a href="/search/math?searchtype=author&query=Singh%2C+P">Pranav Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 86 Pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Rational best approximations (in a Chebyshev sense) to real functions are
characterized by an equioscillating approximation error. Similar results do not
hold true for rational best approximations to complex functions in general. In
the present work, we consider unitary rational approximations to the
exponential function on the imaginary axis, which map the imaginary axis to the
unit circle. In the class of unitary rational functions, best approximations
are shown to exist, to be uniquely characterized by equioscillation of a phase
error, and to possess a super-linear convergence rate. Furthermore, the best
approximations have full degree (i.e., non-degenerate), achieve their maximum
approximation error at points of equioscillation, and interpolate at
intermediate points. Asymptotic properties of poles, interpolation nodes, and
equioscillation points of these approximants are studied. Three algorithms,
which are found very effective to compute unitary rational approximations
including candidates for best approximations, are sketched briefly. Some
consequences to numerical time-integration are discussed. In particular, time
propagators based on unitary best approximants are unitary, symmetric and
A-stable.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13813" title="Abstract">arXiv:2312.13813</a> [<a href="/pdf/2312.13813" title="Download PDF">pdf</a>, <a href="/format/2312.13813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Does Connecting Online Activities to Advertising Inferences Impact  Privacy Perceptions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farke%2C+F+M">Florian M. Farke</a>, 
<a href="/search/cs?searchtype=author&query=Balash%2C+D+G">David G. Balash</a>, 
<a href="/search/cs?searchtype=author&query=Golla%2C+M">Maximilian Golla</a>, 
<a href="/search/cs?searchtype=author&query=Aviv%2C+A+J">Adam J. Aviv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures, to be published in Proceedings on Privacy Enhancing Technologies (PoPETs) 2024 Issue 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Data dashboards are designed to help users manage data collected about them.
However, prior work showed that exposure to some dashboards, notably Google's
My Activity dashboard, results in significant decreases in perceived concern
and increases in perceived benefit from data collection, contrary to
expectations. We theorize that this result is due to the fact that data
dashboards currently do not sufficiently "connect the dots" of the data food
chain, that is, by connecting data collection with the use of that data. To
evaluate this, we designed a study where participants assigned advertising
interest labels to their own real activities, effectively acting as a
behavioral advertising engine to "connect the dots." When comparing pre- and
post-labeling task responses, we find no significant difference in concern with
Google's data collection practices, which indicates that participants' priors
are maintained after more exposure to the data food chain (differing from prior
work), suggesting that data dashboards that offer deeper perspectives of how
data collection is used have potential. However, these gains are offset when
participants are exposed to their true interest labels inferred by Google.
Concern for data collection dropped significantly as participants viewed
Google's labeling as generic compared to their own more specific labeling. This
presents a possible new paradox that must be overcome when designing data
dashboards, the generic paradox, which occurs when users misalign individual,
generic inferences from collected data as benign compared to the totality and
specificity of many generic inferences made about them.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13816" title="Abstract">arXiv:2312.13816</a> [<a href="/pdf/2312.13816" title="Download PDF">pdf</a>, <a href="/format/2312.13816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Team Flow at DRC2023: Building Common Ground and Text-based Turn-taking  in a Travel Agent Spoken Dialogue System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirai%2C+R">Ryu Hirai</a>, 
<a href="/search/cs?searchtype=author&query=Iizuka%2C+S">Shinya Iizuka</a>, 
<a href="/search/cs?searchtype=author&query=Iseno%2C+H">Haruhisa Iseno</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+A">Ao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jingjing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ohashi%2C+A">Atsumoto Ohashi</a>, 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">At the Dialogue Robot Competition 2023 (DRC2023), which was held to improve
the capability of dialogue robots, our team developed a system that could build
common ground and take more natural turns based on user utterance texts. Our
system generated queries for sightseeing spot searches using the common ground
and engaged in dialogue while waiting for user comprehension.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13822" title="Abstract">arXiv:2312.13822</a> [<a href="/pdf/2312.13822" title="Download PDF">pdf</a>, <a href="/format/2312.13822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Noise Annotation: Unveiling the Impact of Noisy annotation on  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+K">Kwangrok Ryoo</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yeonsik Jo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mira Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+A">Ahra Jo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Soonyoung Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> appendix and code : <a href="https://github.com/Ryoo72/UNA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For object detection task with noisy labels, it is important to consider not
only categorization noise, as in image classification, but also localization
noise, missing annotations, and bogus bounding boxes. However, previous studies
have only addressed certain types of noise (e.g., localization or
categorization). In this paper, we propose Universal-Noise Annotation (UNA), a
more practical setting that encompasses all types of noise that can occur in
object detection, and analyze how UNA affects the performance of the detector.
We analyzed the development direction of previous works of detection algorithms
and examined the factors that impact the robustness of detection model learning
method. We open-source the code for injecting UNA into the dataset and all the
training log and weight are also shared.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13828" title="Abstract">arXiv:2312.13828</a> [<a href="/pdf/2312.13828" title="Download PDF">pdf</a>, <a href="/ps/2312.13828" title="Download PostScript">ps</a>, <a href="/format/2312.13828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intel PMDK Transactions: Specification, Validation and Concurrency  (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raad%2C+A">Azalea Raad</a>, 
<a href="/search/cs?searchtype=author&query=Lahav%2C+O">Ori Lahav</a>, 
<a href="/search/cs?searchtype=author&query=Wickerson%2C+J">John Wickerson</a>, 
<a href="/search/cs?searchtype=author&query=Balcer%2C+P">Piotr Balcer</a>, 
<a href="/search/cs?searchtype=author&query=Dongol%2C+B">Brijesh Dongol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of paper to appear in ESOP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Software Transactional Memory (STM) is an extensively studied paradigm that
provides an easy-to-use mechanism for thread safety and concurrency control.
With the recent advent of byte-addressable persistent memory, a natural
question to ask is whether STM systems can be adapted to support failure
atomicity. In this article, we answer this question by showing how STM can be
easily integrated with Intel's Persistent Memory Development Kit (PMDK)
transactional library (which we refer to as txPMDK) to obtain STM systems that
are both concurrent and persistent. We demonstrate this approach using known
STM systems, TML and NOrec, which when combined with txPMDK result in
persistent STM systems, referred to as PMDK-TML and PMDK-NORec, respectively.
However, it turns out that existing correctness criteria are insufficient for
specifying the behaviour of txPMDK and our concurrent extensions. We therefore
develop a new correctness criterion, dynamic durable opacity, that extends the
previously defined notion of durable opacity with dynamic memory allocation. We
provide a model of txPMDK, then show that this model satisfies dynamic durable
opacity. Moreover, dynamic durable opacity supports concurrent transactions,
thus we also use it to show correctness of both PMDK-TML and PMDK-NORec.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13832" title="Abstract">arXiv:2312.13832</a> [<a href="/pdf/2312.13832" title="Download PDF">pdf</a>, <a href="/format/2312.13832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SyncDreamer for 3D Reconstruction of Endangered Animal Species with NeRF  and NeuS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ornek%2C+A+H">Ahmet Haydar Ornek</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+D">Deniz Sen</a>, 
<a href="/search/cs?searchtype=author&query=Civil%2C+E">Esmanur Civil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The main aim of this study is to demonstrate how innovative view synthesis
and 3D reconstruction techniques can be used to create models of endangered
species using monocular RGB images. To achieve this, we employed SyncDreamer to
produce unique perspectives and NeuS and NeRF to reconstruct 3D
representations. We chose four different animals, including the oriental stork,
frog, dragonfly, and tiger, as our subjects for this study. Our results show
that the combination of SyncDreamer, NeRF, and NeuS techniques can successfully
create 3D models of endangered animals. However, we also observed that NeuS
produced blurry images, while NeRF generated sharper but noisier images. This
study highlights the potential of modeling endangered animals and offers a new
direction for future research in this field. By showcasing the effectiveness of
these advanced techniques, we hope to encourage further exploration and
development of techniques for preserving and studying endangered species.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13834" title="Abstract">arXiv:2312.13834</a> [<a href="/pdf/2312.13834" title="Download PDF">pdf</a>, <a href="/format/2312.13834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+C">Ching-Yao Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yichen Jia</a>, 
<a href="/search/cs?searchtype=author&query=Krishnakumar%2C+K">Kapil Krishnakumar</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+F">Feng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Licheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://fairy-video2video.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce Fairy, a minimalist yet robust adaptation of
image-editing diffusion models, enhancing them for video editing applications.
Our approach centers on the concept of anchor-based cross-frame attention, a
mechanism that implicitly propagates diffusion features across frames, ensuring
superior temporal coherence and high-fidelity synthesis. Fairy not only
addresses limitations of previous models, including memory and processing
speed. It also improves temporal consistency through a unique data augmentation
strategy. This strategy renders the model equivariant to affine transformations
in both source and target images. Remarkably efficient, Fairy generates
120-frame 512x384 videos (4-second duration at 30 FPS) in just 14 seconds,
outpacing prior works by at least 44x. A comprehensive user study, involving
1000 generated samples, confirms that our approach delivers superior quality,
decisively outperforming established methods.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13839" title="Abstract">arXiv:2312.13839</a> [<a href="/pdf/2312.13839" title="Download PDF">pdf</a>, <a href="/format/2312.13839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-SENN: Quantized Self-Explaining Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norrenbrock%2C+T">Thomas Norrenbrock</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Marco Rudolph</a>, 
<a href="/search/cs?searchtype=author&query=Rosenhahn%2C+B">Bodo Rosenhahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024, SRRAI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Explanations in Computer Vision are often desired, but most Deep Neural
Networks can only provide saliency maps with questionable faithfulness.
Self-Explaining Neural Networks (SENN) extract interpretable concepts with
fidelity, diversity, and grounding to combine them linearly for
decision-making. While they can explain what was recognized, initial
realizations lack accuracy and general applicability. We propose the
Quantized-Self-Explaining Neural Network Q-SENN. Q-SENN satisfies or exceeds
the desiderata of SENN while being applicable to more complex datasets and
maintaining most or all of the accuracy of an uninterpretable baseline model,
out-performing previous work in all considered metrics. Q-SENN describes the
relationship between every class and feature as either positive, negative or
neutral instead of an arbitrary number of possible relations, enforcing more
binary human-friendly features. Since every class is assigned just 5
interpretable features on average, Q-SENN shows convincing local and global
interpretability. Additionally, we propose a feature alignment method, capable
of aligning learned features with human language-based concepts without
additional supervision. Thus, what is learned can be more easily verbalized.
The code is published: https://github.com/ThomasNorr/Q-SENN
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13841" title="Abstract">arXiv:2312.13841</a> [<a href="/pdf/2312.13841" title="Download PDF">pdf</a>, <a href="/format/2312.13841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Time Stepping for Numerical Shape Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%B6hler%2C+A">Alexander K&#xf6;hler</a>, 
<a href="/search/math?searchtype=author&query=Breu%C3%9F%2C+M">Michael Breu&#xdf;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SSVM2021 (2021) 165-176
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The computation of correspondences between shapes is a principal task in
shape analysis. To this end, methods based on partial differential equations
(PDEs) have been established, encompassing e.g. the classic heat kernel
signature as well as numerical solution schemes for geometric PDEs. In this
work we focus on the latter approach.
<br />We consider here several time stepping schemes. The goal of this
investigation is to assess, if one may identify a useful property of methods
for time integration for the shape analysis context. Thereby we investigate the
dependence on time step size, since the class of implicit schemes that are
useful candidates in this context should ideally yield an invariant behaviour
with respect to this parameter.
<br />To this end we study integration of heat and wave equation on a manifold. In
order to facilitate this study, we propose an efficient, unified model order
reduction framework for these models. We show that specific $l_0$ stable
schemes are favourable for numerical shape analysis. We give an experimental
evaluation of the methods at hand of classical TOSCA data sets.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13842" title="Abstract">arXiv:2312.13842</a> [<a href="/pdf/2312.13842" title="Download PDF">pdf</a>, <a href="/ps/2312.13842" title="Download PostScript">ps</a>, <a href="/format/2312.13842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical learning theory and Occam&#x27;s razor: The argument from  empirical risk minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sterkenburg%2C+T+F">Tom F. Sterkenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">This paper considers the epistemic justification for a simplicity preference
in inductive inference that may be obtained from the machine learning framework
of statistical learning theory. Uniting elements from both earlier arguments
suggesting and rejecting such a justification, the paper spells out a qualified
means-ends and model-relative justificatory argument, built on statistical
learning theory's central mathematical learning guarantee for the method of
empirical risk minimization.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13845" title="Abstract">arXiv:2312.13845</a> [<a href="/pdf/2312.13845" title="Download PDF">pdf</a>, <a href="/format/2312.13845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Clustering using Restricted Boltzman Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In various verification systems, Restricted Boltzmann Machines (RBMs) have
demonstrated their efficacy in both front-end and back-end processes. In this
work, we propose the use of RBMs to the image clustering tasks. RBMs are
trained to convert images into image embeddings. We employ the conventional
bottom-up Agglomerative Hierarchical Clustering (AHC) technique. To address the
challenge of limited test face image data, we introduce Agglomerative
Hierarchical Clustering based Method for Image Clustering using Restricted
Boltzmann Machine (AHC-RBM) with two major steps. Initially, a universal RBM
model is trained using all available training dataset. Subsequently, we train
an adapted RBM model using the data from each test image. Finally, RBM vectors
which is the embedding vector is generated by concatenating the
visible-to-hidden weight matrices of these adapted models, and the bias
vectors. These vectors effectively preserve class-specific information and are
utilized in image clustering tasks. Our experimental results, conducted on two
benchmark image datasets (MS-Celeb-1M and DeepFashion), demonstrate that our
proposed approach surpasses well-known clustering algorithms such as k-means,
spectral clustering, and approximate Rank-order.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13848" title="Abstract">arXiv:2312.13848</a> [<a href="/pdf/2312.13848" title="Download PDF">pdf</a>, <a href="/ps/2312.13848" title="Download PostScript">ps</a>, <a href="/format/2312.13848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Hallucinations: Enhancing VQA for Flood Disaster Damage  Assessment with Visual Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yimin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> already be accepted by 2024 3rd International Conference on Computer, Artificial Intelligence and Control Engineering (CAICE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The zero-shot performance of visual question answering (VQA) models relies
heavily on prompts. For example, a zero-shot VQA for disaster scenarios could
leverage well-designed Chain of Thought (CoT) prompts to stimulate the model's
potential. However, using CoT prompts has some problems, such as causing an
incorrect answer in the end due to the hallucination in the thought process. In
this paper, we propose a zero-shot VQA named Flood Disaster VQA with Two-Stage
Prompt (VQA-TSP). The model generates the thought process in the first stage
and then uses the thought process to generate the final answer in the second
stage. In particular, visual context is added in the second stage to relieve
the hallucination problem that exists in the thought process. Experimental
results show that our method exceeds the performance of state-of-the-art
zero-shot VQA models for flood disaster scenarios in total. Our study provides
a research basis for improving the performance of CoT-based zero-shot VQA.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13859" title="Abstract">arXiv:2312.13859</a> [<a href="/pdf/2312.13859" title="Download PDF">pdf</a>, <a href="/format/2312.13859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Functional Estimation: Functional Detectability and Full  Information Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muntwiler%2C+S">Simon Muntwiler</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider the design of functional estimators, i.e., approaches to compute
an estimate of a nonlinear function of the state of a general nonlinear
dynamical system subject to process noise based on noisy output measurements.
To this end, we introduce a novel functional detectability notion in the form
of incremental input/output-to-output stability ($\delta$-IOOS). We show that
$\delta$-IOOS is a necessary condition for the existence of a functional
estimator satisfying an input-to-output type stability property. Additionally,
we prove that a system is functional detectable if and only if it admits a
corresponding $\delta$-IOOS Lyapunov function. Furthermore, $\delta$-IOOS is
shown to be a sufficient condition for the design of a stable functional
estimator by introducing the design of a full information estimation (FIE)
approach for functional estimation. Together, we present a unified framework to
study functional estimation with a detectability condition, which is necessary
and sufficient for the existence of a stable functional estimator, and a
corresponding functional estimator design. The practical need for and
applicability of the proposed functional estimator design is illustrated with a
numerical example of a power system.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13863" title="Abstract">arXiv:2312.13863</a> [<a href="/pdf/2312.13863" title="Download PDF">pdf</a>, <a href="/format/2312.13863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulating Trajectory Prediction with Backdoors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Massoud%2C+K">Kaouther Massoud</a>, 
<a href="/search/cs?searchtype=author&query=Grosse%2C+K">Kathrin Grosse</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mickael Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Alahi%2C+A">Alexandre Alahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous vehicles ought to predict the surrounding agents' trajectories to
allow safe maneuvers in uncertain and complex traffic situations. As companies
increasingly apply trajectory prediction in the real world, security becomes a
relevant concern. In this paper, we focus on backdoors - a security threat
acknowledged in other fields but so far overlooked for trajectory prediction.
To this end, we describe and investigate four triggers that could affect
trajectory prediction. We then show that these triggers (for example, a braking
vehicle), when correlated with a desired output (for example, a curve) during
training, cause the desired output of a state-of-the-art trajectory prediction
model. In other words, the model has good benign performance but is vulnerable
to backdoors. This is the case even if the trigger maneuver is performed by a
non-casual agent behind the target vehicle. As a side-effect, our analysis
reveals interesting limitations within trajectory prediction models. Finally,
we evaluate a range of defenses against backdoors. While some, like simple
offroad checks, do not enable detection for all triggers, clustering is a
promising candidate to support manual inspection to find backdoors.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13866" title="Abstract">arXiv:2312.13866</a> [<a href="/pdf/2312.13866" title="Download PDF">pdf</a>, <a href="/format/2312.13866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Inter-Session Intentions via Complex Logical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaxin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Qingyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Understanding user intentions is crucial for enhancing product
recommendations, navigation suggestions, and query reformulations. However,
user intentions can be complex, involving multiple sessions and attribute
requirements connected by logical operators such as And, Or, and Not. For
example, a user may search for Nike or Adidas running shoes across various
sessions, with a preference for the color purple. In another case, a user may
have purchased a mattress in a previous session and is now seeking a
corresponding bed frame without intending to buy another mattress. Prior
research on session understanding has not sufficiently addressed how to make
product or attribute recommendations for such complex intentions. In this
paper, we introduce the task of logical session complex query answering, where
sessions are treated as hyperedges of items, and we formulate the problem of
complex intention understanding as a task of logical session complex queries
answering (LS-CQA) on an aggregated hypergraph of sessions, items, and
attributes. The proposed task is a special type of complex query answering task
with sessions as ordered hyperedges. We also propose a new model, the Logical
Session Graph Transformer (LSGT), which captures interactions among items
across different sessions and their logical connections using a transformer
structure. We analyze the expressiveness of LSGT and prove the permutation
invariance of the inputs for the logical operators. We evaluate LSGT on three
datasets and demonstrate that it achieves state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13871" title="Abstract">arXiv:2312.13871</a> [<a href="/pdf/2312.13871" title="Download PDF">pdf</a>, <a href="/format/2312.13871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Task-oriented Dialogue Systems: A Systematic Review of  Measures, Constructs and their Operationalisations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braggaar%2C+A">Anouck Braggaar</a>, 
<a href="/search/cs?searchtype=author&query=Liebrecht%2C+C">Christine Liebrecht</a>, 
<a href="/search/cs?searchtype=author&query=van+Miltenburg%2C+E">Emiel van Miltenburg</a>, 
<a href="/search/cs?searchtype=author&query=Krahmer%2C+E">Emiel Krahmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This review gives an extensive overview of evaluation methods for
task-oriented dialogue systems, paying special attention to practical
applications of dialogue systems, for example for customer service. The review
(1) provides an overview of the used constructs and metrics in previous work,
(2) discusses challenges in the context of dialogue system evaluation and (3)
develops a research agenda for the future of dialogue system evaluation. We
conducted a systematic review of four databases (ACL, ACM, IEEE and Web of
Science), which after screening resulted in 122 studies. Those studies were
carefully analysed for the constructs and methods they proposed for evaluation.
We found a wide variety in both constructs and methods. Especially the
operationalisation is not always clearly reported. We hope that future work
will take a more critical approach to the operationalisation and specification
of the used constructs. To work towards this aim, this review ends with
recommendations for evaluation and suggestions for outstanding questions.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13873" title="Abstract">arXiv:2312.13873</a> [<a href="/pdf/2312.13873" title="Download PDF">pdf</a>, <a href="/format/2312.13873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Adaptive AV Fusion Module for Pre-Trained ASR Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simic%2C+C">Christopher Simic</a>, 
<a href="/search/cs?searchtype=author&query=Bocklet%2C+T">Tobias Bocklet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic speech recognition (ASR) has reached a level of accuracy in recent
years, that even outperforms humans in transcribing speech to text.
Nevertheless, all current ASR approaches show a certain weakness against
ambient noise. To reduce this weakness, audio-visual speech recognition (AVSR)
approaches additionally consider visual information from lip movements for
transcription. This additional modality increases the computational cost for
training models from scratch. We propose an approach, that builds on a
pre-trained ASR model and extends it with an adaptive upstream module, that
fuses audio and visual information. Since we do not need to train the
transformer structure from scratch, our approach requires a fraction of the
computational resources compared to traditional AVSR models. Compared to
current SOTA systems like AV-HuBERT, our approach achieves an average
improvement of 8.3% in word error rate across different model sizes, noise
categories and broad SNR range. The approach allows up to 21% smaller models
and requires only a fraction of the computational resources for training and
inference compared to common AVSR approaches.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13876" title="Abstract">arXiv:2312.13876</a> [<a href="/pdf/2312.13876" title="Download PDF">pdf</a>, <a href="/format/2312.13876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capture the Flag: Uncovering Data Insights with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laradji%2C+I">Issam Laradji</a>, 
<a href="/search/cs?searchtype=author&query=Taslakian%2C+P">Perouz Taslakian</a>, 
<a href="/search/cs?searchtype=author&query=Rajeswar%2C+S">Sai Rajeswar</a>, 
<a href="/search/cs?searchtype=author&query=Zantedeschi%2C+V">Valentina Zantedeschi</a>, 
<a href="/search/cs?searchtype=author&query=Lacoste%2C+A">Alexandre Lacoste</a>, 
<a href="/search/cs?searchtype=author&query=Chapados%2C+N">Nicolas Chapados</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+D">David Vazquez</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+C">Christopher Pal</a>, 
<a href="/search/cs?searchtype=author&query=Drouin%2C+A">Alexandre Drouin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 figure, Foundation Models for Decision Making Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">The extraction of a small number of relevant insights from vast amounts of
data is a crucial component of data-driven decision-making. However,
accomplishing this task requires considerable technical skills, domain
expertise, and human labor. This study explores the potential of using Large
Language Models (LLMs) to automate the discovery of insights in data,
leveraging recent advances in reasoning and code generation techniques. We
propose a new evaluation methodology based on a "capture the flag" principle,
measuring the ability of such models to recognize meaningful and pertinent
information (flags) in a dataset. We further propose two proof-of-concept
agents, with different inner workings, and compare their ability to capture
such flags in a real-world sales dataset. While the work reported here is
preliminary, our results are sufficiently interesting to mandate future
exploration by the community.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13878" title="Abstract">arXiv:2312.13878</a> [<a href="/pdf/2312.13878" title="Download PDF">pdf</a>, <a href="/format/2312.13878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Koopmon trajectories in nonadiabatic quantum-classical dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bauer%2C+W">Werner Bauer</a>, 
<a href="/search/math?searchtype=author&query=Bergold%2C+P">Paul Bergold</a>, 
<a href="/search/math?searchtype=author&query=Gay-Balmaz%2C+F">Fran&#xe7;ois Gay-Balmaz</a>, 
<a href="/search/math?searchtype=author&query=Tronci%2C+C">Cesare Tronci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First version. 35 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Quantum Physics (quant-ph)

</div>
<p class="mathjax">In order to alleviate the computational costs of fully quantum nonadiabatic
dynamics, we present a mixed quantum-classical (MQC) particle method based on
the theory of Koopman wavefunctions. Although conventional MQC models often
suffer from consistency issues such as the violation of Heisenberg's principle,
we overcame these difficulties by blending Koopman's classical mechanics on
Hilbert spaces with methods in symplectic geometry. The resulting continuum
model enjoys both a variational and a Hamiltonian structure, while its
nonlinear character calls for suitable closures. Benefiting from the underlying
action principle, here we apply a regularization technique previously developed
within our team. This step allows for a singular solution ansatz which
introduces the trajectories of computational particles - the koopmons -
sampling the Lagrangian classical paths in phase space. In the case of Tully's
nonadiabatic problems, the method reproduces the results of fully quantum
simulations with levels of accuracy that are not achieved by standard MQC
Ehrenfest simulations. In addition, the koopmon method is computationally
advantageous over similar fully quantum approaches, which are also considered
in our study. As a further step, we probe the limits of the method by
considering the Rabi problem in both the ultrastrong and the deep strong
coupling regimes, where MQC treatments appear hardly applicable. In this case,
the method succeeds in reproducing parts of the fully quantum results.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13881" title="Abstract">arXiv:2312.13881</a> [<a href="/pdf/2312.13881" title="Download PDF">pdf</a>, <a href="/format/2312.13881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversifying Knowledge Enhancement of Biomedical Language Models using  Adapter Modules and Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vladika%2C+J">Juraj Vladika</a>, 
<a href="/search/cs?searchtype=author&query=Fichtl%2C+A">Alexander Fichtl</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Full Paper to ICAART 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in natural language processing (NLP) owe their success to
pre-training language models on large amounts of unstructured data. Still,
there is an increasing effort to combine the unstructured nature of LMs with
structured knowledge and reasoning. Particularly in the rapidly evolving field
of biomedical NLP, knowledge-enhanced language models (KELMs) have emerged as
promising tools to bridge the gap between large language models and
domain-specific knowledge, considering the available biomedical knowledge
graphs (KGs) curated by experts over the decades. In this paper, we develop an
approach that uses lightweight adapter modules to inject structured biomedical
knowledge into pre-trained language models (PLMs). We use two large KGs, the
biomedical knowledge system UMLS and the novel biochemical ontology OntoChem,
with two prominent biomedical PLMs, PubMedBERT and BioLinkBERT. The approach
includes partitioning knowledge graphs into smaller subgraphs, fine-tuning
adapter modules for each subgraph, and combining the knowledge in a fusion
layer. We test the performance on three downstream tasks: document
classification,question answering, and natural language inference. We show that
our methodology leads to performance improvements in several instances while
keeping requirements in computing power low. Finally, we provide a detailed
interpretation of the results and report valuable insights for future work.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13888" title="Abstract">arXiv:2312.13888</a> [<a href="/pdf/2312.13888" title="Download PDF">pdf</a>, <a href="/format/2312.13888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Study of the Docker Smells Impact on the Image Size
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durieux%2C+T">Thomas Durieux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE'24. arXiv admin note: text overlap with <a href="/abs/2302.01707">arXiv:2302.01707</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Docker, a widely adopted tool for packaging and deploying applications
leverages Dockerfiles to build images. However, creating an optimal Dockerfile
can be challenging, often leading to "Docker smells" or deviations from best
practices. This paper presents a study of the impact of 14 Docker smells on the
size of Docker images. To assess the size impact of Docker smells, we
identified and repaired 16 145 Docker smells from 11 313 open-source
Dockerfiles. We observe that the smells result in an average increase of 48.06
MB (4.6%) per smelly image. Depending on the smell type, the size increase can
be up to 10 %, and for some specific cases, the smells can represent 89% of the
image size. Interestingly, the most impactful smells are related to package
managers which are commonly encountered and are relatively easy to fix. To
collect the perspective of the developers regarding the size impact of the
Docker smells, we submitted 34 pull requests that repair the smells and we
reported their impact on the Docker image to the developers. 26/34 (76.5%) of
the pull requests have been merged and they contribute to a saving of 3.46GB
(16.4%). The developer's comments demonstrate a positive interest in addressing
those Docker smells even when the pull requests have been rejected.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13891" title="Abstract">arXiv:2312.13891</a> [<a href="/pdf/2312.13891" title="Download PDF">pdf</a>, <a href="/format/2312.13891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Summarized History-based Dialogue System for Amnesia-Free Prompt  Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hyejin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kawano%2C+H">Hibiki Kawano</a>, 
<a href="/search/cs?searchtype=author&query=Maekawa%2C+T">Takuto Maekawa</a>, 
<a href="/search/cs?searchtype=author&query=Yoshimaru%2C+N">Naoki Yoshimaru</a>, 
<a href="/search/cs?searchtype=author&query=Iio%2C+T">Takamasa Iio</a>, 
<a href="/search/cs?searchtype=author&query=Hatano%2C+K">Kenji Hatano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In today's society, information overload presents challenges in providing
optimal recommendations. Consequently, the importance of dialogue systems that
can discern and provide the necessary information through dialogue is
increasingly recognized. However, some concerns existing dialogue systems rely
on pre-trained models and need help to cope with real-time or insufficient
information. To address these concerns, models that allow the addition of
missing information to dialogue robots are being proposed. Yet, maintaining the
integrity of previous conversation history while integrating new data remains a
formidable challenge. This paper presents a novel system for dialogue robots
designed to remember user-specific characteristics by retaining past
conversation history even as new information is added.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13896" title="Abstract">arXiv:2312.13896</a> [<a href="/pdf/2312.13896" title="Download PDF">pdf</a>, <a href="/format/2312.13896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Evaluation of Anomaly Detection Methods for Fraud Detection  in Online Credit Card Payments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thimonier%2C+H">Hugo Thimonier</a>, 
<a href="/search/cs?searchtype=author&query=Popineau%2C+F">Fabrice Popineau</a>, 
<a href="/search/cs?searchtype=author&query=Rimmel%2C+A">Arpad Rimmel</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+B">Bich-Li&#xea;n Doan</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+F">Fabrice Daniel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICICT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">This study explores the application of anomaly detection (AD) methods in
imbalanced learning tasks, focusing on fraud detection using real online credit
card payment data. We assess the performance of several recent AD methods and
compare their effectiveness against standard supervised learning methods.
Offering evidence of distribution shift within our dataset, we analyze its
impact on the tested models' performances. Our findings reveal that LightGBM
exhibits significantly superior performance across all evaluated metrics but
suffers more from distribution shifts than AD methods. Furthermore, our
investigation reveals that LightGBM also captures the majority of frauds
detected by AD methods. This observation challenges the potential benefits of
ensemble methods to combine supervised, and AD approaches to enhance
performance. In summary, this research provides practical insights into the
utility of these techniques in real-world scenarios, showing LightGBM's
superiority in fraud detection while highlighting challenges related to
distribution shifts.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13897" title="Abstract">arXiv:2312.13897</a> [<a href="/pdf/2312.13897" title="Download PDF">pdf</a>, <a href="/format/2312.13897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnergiBridge: Empowering Software Sustainability through Cross-Platform  Energy Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sallou%2C+J">June Sallou</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+L">Lu&#xed;s Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Durieux%2C+T">Thomas Durieux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the continually evolving realm of software engineering, the need to
address software energy consumption has gained increasing prominence. However,
the absence of a platform-independent tool that facilitates straightforward
energy measurements remains a notable gap. This paper presents EnergiBridge, a
cross-platform measurement utility that provides support for Linux, Windows,
and MacOS, as well as Intel, AMD, and Apple ARM CPU architectures. In essence,
EnergiBridge serves as a bridge between energy-conscious software engineering
and the diverse software environments in which it operates. It encourages a
broader community to make informed decisions, minimize energy consumption, and
reduce the environmental impact of software systems.
<br />By simplifying software energy measurements, EnergiBridge offers a valuable
resource to make green software development more lightweight, education more
inclusive, and research more reproducible. Through the evaluation, we highlight
EnergiBridge's ability to gather energy data across diverse platforms and
hardware configurations.
<br />EnergiBridge is publicly available on GitHub:
https://github.com/tdurieux/EnergiBridge, and a demonstration video can be
viewed at: https://youtu.be/-gPJurKFraE.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13905" title="Abstract">arXiv:2312.13905</a> [<a href="/pdf/2312.13905" title="Download PDF">pdf</a>, <a href="/ps/2312.13905" title="Download PostScript">ps</a>, <a href="/format/2312.13905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Specific Fine-Tuning of Large Language Models for Interactive  Robot Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alt%2C+B">Benjamin Alt</a>, 
<a href="/search/cs?searchtype=author&query=Ke%C3%9Fner%2C+U">Urs Ke&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Taranovic%2C+A">Aleksandar Taranovic</a>, 
<a href="/search/cs?searchtype=author&query=Katic%2C+D">Darko Katic</a>, 
<a href="/search/cs?searchtype=author&query=Hermann%2C+A">Andreas Hermann</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4kel%2C+R">Rainer J&#xe4;kel</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+G">Gerhard Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, accepted to the 2024 European Robotics Forum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Industrial robots are applied in a widening range of industries, but robot
programming mostly remains a task limited to programming experts. We propose a
natural language-based assistant for programming of advanced, industrial
robotic applications and investigate strategies for domain-specific fine-tuning
of foundation models with limited data and compute.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13906" title="Abstract">arXiv:2312.13906</a> [<a href="/pdf/2312.13906" title="Download PDF">pdf</a>, <a href="/ps/2312.13906" title="Download PostScript">ps</a>, <a href="/format/2312.13906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EfficientPPS: Part-aware Panoptic Segmentation of Transparent Objects  for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alt%2C+B">Benjamin Alt</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+D">Minh Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hermann%2C+A">Andreas Hermann</a>, 
<a href="/search/cs?searchtype=author&query=Katic%2C+D">Darko Katic</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4kel%2C+R">Rainer J&#xe4;kel</a>, 
<a href="/search/cs?searchtype=author&query=Dillmann%2C+R">R&#xfc;diger Dillmann</a>, 
<a href="/search/cs?searchtype=author&query=Sax%2C+E">Eric Sax</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, presented at the 56th International Symposium on Robotics (ISR Europe)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ISR Europe 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The use of autonomous robots for assistance tasks in hospitals has the
potential to free up qualified staff and im-prove patient care. However, the
ubiquity of deformable and transparent objects in hospital settings poses
signif-icant challenges to vision-based perception systems. We present
EfficientPPS, a neural architecture for part-aware panoptic segmentation that
provides robots with semantically rich visual information for grasping and
ma-nipulation tasks. We also present an unsupervised data collection and
labelling method to reduce the need for human involvement in the training
process. EfficientPPS is evaluated on a dataset containing real-world hospital
objects and demonstrated to be robust and efficient in grasping transparent
transfusion bags with a collaborative robot arm.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13910" title="Abstract">arXiv:2312.13910</a> [<a href="/pdf/2312.13910" title="Download PDF">pdf</a>, <a href="/format/2312.13910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Probabilistic Ensembles with Trajectory Sampling for  Connected Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Ruoqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiahao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guoru Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Autonomous Vehicles (AVs) have attracted significant attention in recent
years and Reinforcement Learning (RL) has shown remarkable performance in
improving the autonomy of vehicles. In that regard, the widely adopted
Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs
(CAVs), contingent on the readiness of a significant amount of data samples for
training. Nevertheless, it might be infeasible in practice and possibly lead to
learning instability. In contrast, Model-Based RL (MBRL) manifests itself in
sample-efficient learning, but the asymptotic performance of MBRL might lag
behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs
are limited to the decision-making of a single AV only, thus underscoring the
performance due to the absence of communications. In this study, we try to
address the decision-making problem of multiple CAVs with limited
communications and propose a decentralized Multi-Agent Probabilistic Ensembles
with Trajectory Sampling algorithm MA-PETS. In particular, in order to better
capture the uncertainty of the unknown environment, MA-PETS leverages
Probabilistic Ensemble (PE) neural networks to learn from communicated samples
among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory
Sampling (TS)-based model-predictive control for decision-making. On this
basis, we derive the multi-agent group regret bound affected by the number of
agents within the communication range and mathematically validate that
incorporating effective information exchange among agents into the multi-agent
learning scheme contributes to reducing the group regret bound in the worst
case. Finally, we empirically demonstrate the superiority of MA-PETS in terms
of the sample efficiency comparable to MFBL.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13912" title="Abstract">arXiv:2312.13912</a> [<a href="/pdf/2312.13912" title="Download PDF">pdf</a>, <a href="/format/2312.13912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Long-run Average Reward Robust MDPs via Stochastic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+K">Krishnendu Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Goharshady%2C+E+K">Ehsan Kafshdar Goharshady</a>, 
<a href="/search/cs?searchtype=author&query=Karrabi%2C+M">Mehrdad Karrabi</a>, 
<a href="/search/cs?searchtype=author&query=Novotn%C3%BD%2C+P">Petr Novotn&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDikeli%C4%87%2C+%C4%90">&#x110;or&#x111;e &#x17d;ikeli&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Markov decision processes (MDPs) provide a standard framework for sequential
decision making under uncertainty. However, transition probabilities in MDPs
are often estimated from data and MDPs do not take data uncertainty into
account. Robust Markov decision processes (RMDPs) address this shortcoming of
MDPs by assigning to each transition an uncertainty set rather than a single
probability value. The goal of solving RMDPs is then to find a policy which
maximizes the worst-case performance over the uncertainty sets. In this work,
we consider polytopic RMDPs in which all uncertainty sets are polytopes and
study the problem of solving long-run average reward polytopic RMDPs. Our focus
is on computational complexity aspects and efficient algorithms. We present a
novel perspective on this problem and show that it can be reduced to solving
long-run average reward turn-based stochastic games with finite state and
action spaces. This reduction allows us to derive several important
consequences that were hitherto not known to hold for polytopic RMDPs. First,
we derive new computational complexity bounds for solving long-run average
reward polytopic RMDPs, showing for the first time that the threshold decision
problem for them is in NP coNP and that they admit a randomized algorithm with
sub-exponential expected runtime. Second, we present Robust Polytopic Policy
Iteration (RPPI), a novel policy iteration algorithm for solving long-run
average reward polytopic RMDPs. Our experimental evaluation shows that RPPI is
much more efficient in solving long-run average reward polytopic RMDPs compared
to state-of-the-art methods based on value iteration.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13913" title="Abstract">arXiv:2312.13913</a> [<a href="/pdf/2312.13913" title="Download PDF">pdf</a>, <a href="/format/2312.13913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianfang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://github.com/OpenTexture/Paint3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents Paint3D, a novel coarse-to-fine generative framework that
is capable of producing high-resolution, lighting-less, and diverse 2K UV
texture maps for untextured 3D meshes conditioned on text or image inputs. The
key challenge addressed is generating high-quality textures without embedded
illumination information, which allows the textures to be re-lighted or
re-edited within modern graphics pipelines. To achieve this, our method first
leverages a pre-trained depth-aware 2D diffusion model to generate
view-conditional images and perform multi-view texture fusion, producing an
initial coarse texture map. However, as 2D models cannot fully represent 3D
shapes and disable lighting effects, the coarse texture map exhibits incomplete
areas and illumination artifacts. To resolve this, we train separate UV
Inpainting and UVHD diffusion models specialized for the shape-aware refinement
of incomplete areas and the removal of illumination artifacts. Through this
coarse-to-fine process, Paint3D can produce high-quality 2K UV textures that
maintain semantic consistency while being lighting-less, significantly
advancing the state-of-the-art in texturing 3D objects.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13919" title="Abstract">arXiv:2312.13919</a> [<a href="/pdf/2312.13919" title="Download PDF">pdf</a>, <a href="/format/2312.13919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age of Actuation and Timeliness: Semantics in a Wireless Power Transfer  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikkhah%2C+A">Ali Nikkhah</a>, 
<a href="/search/cs?searchtype=author&query=Ephremides%2C+A">Anthony Ephremides</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for possible Journal publication. arXiv admin note: text overlap with <a href="/abs/2303.00507">arXiv:2303.00507</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate a model relevant to semantics-aware
goal-oriented communications, and we propose a new metric that incorporates the
utilization of information in addition to its timelines. Specifically, we
consider the transmission of observations from an external process to a
battery-powered receiver through status updates. These updates inform the
receiver about the process status and enable actuation if sufficient energy is
available to achieve a goal. We focus on a wireless power transfer (WPT) model,
where the receiver receives energy from a dedicated power transmitter and
occasionally from the data transmitter when they share a common channel. We
analyze the Age of Information (AoI) and propose a new metric, the \textit{Age
of Actuation (AoA), which is relevant when the receiver utilizes the status
updates to perform actions in a timely manner}. We provide analytical
characterizations of the average AoA and the violation probability of the AoA,
demonstrating that AoA generalizes AoI. Moreover, we introduce and analytically
characterize the \textit{Probability of Missing Actuation (PoMA)}; this metric
becomes relevant also \textit{to quantify the incurred cost of a missed
action}. We formulate unconstrained and constrained optimization problems for
all the metrics and present numerical evaluations of our analytical results.
This proposed set of metrics goes beyond the traditional timeliness metrics
since the synergy of different flows is now considered.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13921" title="Abstract">arXiv:2312.13921</a> [<a href="/pdf/2312.13921" title="Download PDF">pdf</a>, <a href="/ps/2312.13921" title="Download PostScript">ps</a>, <a href="/format/2312.13921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hulls of projective Reed-Muller codes over the projective plane
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>, 
<a href="/search/cs?searchtype=author&query=San-Jos%C3%A9%2C+R">Rodrigo San-Jos&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">By solving a problem regarding polynomials in a quotient ring, we obtain the
relative hull and the Hermitian hull of projective Reed-Muller codes over the
projective plane. The dimension of the hull determines the minimum number of
maximally entangled pairs required for the corresponding entanglement-assisted
quantum error-correcting code. Hence, by computing the dimension of the hull we
now have all the parameters of the symmetric and asymmetric
entanglement-assisted quantum error-correcting codes constructed with
projective Reed-Muller codes over the projective plane. As a byproduct, we also
compute the dimension of the Hermitian hull for affine Reed-Muller codes in 2
variables.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13923" title="Abstract">arXiv:2312.13923</a> [<a href="/pdf/2312.13923" title="Download PDF">pdf</a>, <a href="/format/2312.13923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-CO$_{2}$: Cooperation of Online and Offline Models for Severe Data  Heterogeneity in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has emerged as a promising distributed learning
paradigm that enables multiple clients to learn a global model collaboratively
without sharing their private data. However, the effectiveness of FL is highly
dependent on the quality of the data that is being used for training. In
particular, data heterogeneity issues, such as label distribution skew and
feature skew, can significantly impact the performance of FL. Previous studies
in FL have primarily focused on addressing label distribution skew data
heterogeneity, while only a few recent works have made initial progress in
tackling feature skew issues. Notably, these two forms of data heterogeneity
have been studied separately and have not been well explored within a unified
FL framework. To address this gap, we propose Fed-CO$_{2}$, a universal FL
framework that handles both label distribution skew and feature skew within a
\textbf{C}ooperation mechanism between the \textbf{O}nline and \textbf{O}ffline
models. Specifically, the online model learns general knowledge that is shared
among all clients, while the offline model is trained locally to learn the
specialized knowledge of each individual client. To further enhance model
cooperation in the presence of feature shifts, we design an intra-client
knowledge transfer mechanism that reinforces mutual learning between the online
and offline models, and an inter-client knowledge transfer mechanism to
increase the models' domain generalization ability. Extensive experiments show
that our Fed-CO$_{2}$ outperforms a wide range of existing personalized
federated learning algorithms in terms of handling label distribution skew and
feature skew, both individually and collectively. The empirical results are
supported by our convergence analyses in a simplified setting.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13925" title="Abstract">arXiv:2312.13925</a> [<a href="/pdf/2312.13925" title="Download PDF">pdf</a>, <a href="/format/2312.13925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AsyncMLD: Asynchronous Multi-LLM Framework for Dialogue Recommendation  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshimaru%2C+N">Naoki Yoshimaru</a>, 
<a href="/search/cs?searchtype=author&query=Okuma%2C+M">Motoharu Okuma</a>, 
<a href="/search/cs?searchtype=author&query=Iio%2C+T">Takamasa Iio</a>, 
<a href="/search/cs?searchtype=author&query=Hatano%2C+K">Kenji Hatano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We have reached a practical and realistic phase in human-support dialogue
agents by developing a large language model (LLM). However, when requiring
expert knowledge or anticipating the utterance content using the massive size
of the dialogue database, we still need help with the utterance content's
effectiveness and the efficiency of its output speed, even if using LLM.
Therefore, we propose a framework that uses LLM asynchronously in the part of
the system that returns an appropriate response and in the part that
understands the user's intention and searches the database. In particular,
noting that it takes time for the robot to speak, threading related to database
searches is performed while the robot is speaking.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13927" title="Abstract">arXiv:2312.13927</a> [<a href="/pdf/2312.13927" title="Download PDF">pdf</a>, <a href="/format/2312.13927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence of loss and uncertainty-based active learning  algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haimovich%2C+D">Daniel Haimovich</a>, 
<a href="/search/cs?searchtype=author&query=Karamshuk%2C+D">Dima Karamshuk</a>, 
<a href="/search/cs?searchtype=author&query=Linder%2C+F">Fridolin Linder</a>, 
<a href="/search/cs?searchtype=author&query=Tax%2C+N">Niek Tax</a>, 
<a href="/search/cs?searchtype=author&query=Vojnovic%2C+M">Milan Vojnovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study convergence rates of loss and uncertainty-based active learning
algorithms under various assumptions. First, we provide a set of conditions
under which a convergence rate guarantee holds, and use this for linear
classifiers and linearly separable datasets to show convergence rate guarantees
for loss-based sampling and different loss functions. Second, we provide a
framework that allows us to derive convergence rate bounds for loss-based
sampling by deploying known convergence rate bounds for stochastic gradient
descent algorithms. Third, and last, we propose an active learning algorithm
that combines sampling of points and stochastic Polyak's step size. We show a
condition on the sampling that ensures a convergence rate guarantee for this
algorithm for smooth convex loss functions. Our numerical results demonstrate
efficiency of our proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13931" title="Abstract">arXiv:2312.13931</a> [<a href="/pdf/2312.13931" title="Download PDF">pdf</a>, <a href="/format/2312.13931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Sensing and Task-Oriented Communications with Image and Wireless  Data Modalities for Dynamic Spectrum Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagduyu%2C+Y+E">Yalin E. Sagduyu</a>, 
<a href="/search/cs?searchtype=author&query=Erpek%2C+T">Tugba Erpek</a>, 
<a href="/search/cs?searchtype=author&query=Yener%2C+A">Aylin Yener</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces a deep learning approach to dynamic spectrum access,
leveraging the synergy of multi-modal image and spectrum data for the
identification of potential transmitters. We consider an edge device equipped
with a camera that is taking images of potential objects such as vehicles that
may harbor transmitters. Recognizing the computational constraints and trust
issues associated with on-device computation, we propose a collaborative system
wherein the edge device communicates selectively processed information to a
trusted receiver acting as a fusion center, where a decision is made to
identify whether a potential transmitter is present, or not. To achieve this,
we employ task-oriented communications, utilizing an encoder at the transmitter
for joint source coding, channel coding, and modulation. This architecture
efficiently transmits essential information of reduced dimension for object
classification. Simultaneously, the transmitted signals may reflect off objects
and return to the transmitter, allowing for the collection of target sensing
data. Then the collected sensing data undergoes a second round of encoding at
the transmitter, with the reduced-dimensional information communicated back to
the fusion center through task-oriented communications. On the receiver side, a
decoder performs the task of identifying a transmitter by fusing data received
through joint sensing and task-oriented communications. The two encoders at the
transmitter and the decoder at the receiver are jointly trained, enabling a
seamless integration of image classification and wireless signal detection.
Using AWGN and Rayleigh channel models, we demonstrate the effectiveness of the
proposed approach, showcasing high accuracy in transmitter identification
across diverse channel conditions while sustaining low latency in decision
making.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13933" title="Abstract">arXiv:2312.13933</a> [<a href="/pdf/2312.13933" title="Download PDF">pdf</a>, <a href="/format/2312.13933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Probabilistic Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dou Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lingwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a new supervised representation learning framework,
namely Structured Probabilistic Coding (SPC), to learn compact and informative
representations from input related to the target task. SPC is an encoder-only
probabilistic coding technology with a structured regularization from the
target label space. By extracting compact and informative representations from
input related to the target task, SPC can enhance the generalization ability of
pre-trained language models for better language understanding. Specifically,
the hidden representation is encoded into a Gaussian distribution space, while
maximizing the prior entropy of latent representations concerning label space.
This technique can simultaneously perform information encoding and task
prediction in one module to more fully utilize the effective information from
input data, and use variational inference in the output space to reduce
randomness and uncertainty. To better control the probability distribution in
the latent space, a structured regularization is proposed to promote
class-level uniformity in the latent space. With the regularization term, SPC
can preserve the Gaussian distribution structure of latent code as well as
better cover the hidden space with class uniformly. We conduct evaluations on
12 natural language understanding tasks. The results show that our SPC can
effectively improve the performance of pre-trained language models for various
classification and regression tasks. Experiments demonstrate that SPC can
enhance the generalization capability, robustness to label noise, and
clustering quality of output representations.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13936" title="Abstract">arXiv:2312.13936</a> [<a href="/pdf/2312.13936" title="Download PDF">pdf</a>, <a href="/format/2312.13936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVE-Leiden: Fast Leiden Algorithm for Community Detection in Shared  Memory Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 1 table. arXiv admin note: substantial text overlap with <a href="/abs/2312.04876">arXiv:2312.04876</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Community detection is the problem of identifying natural divisions in
networks. Efficient parallel algorithms for identifying such divisions is
critical in a number of applications, where the size of datasets have reached
significant scales. This technical report presents an optimized parallel
implementation of Leiden, a high quality community detection method, for shared
memory multicore systems. On a server equipped with dual 16-core Intel Xeon
Gold 6226R processors, our Leiden, which we term as GVE-Leiden, outperforms the
original Leiden, igraph Leiden, and NetworKit Leiden by 373x, 86x, and 7.2x
respectively - achieving a processing rate of 352M edges/s on a 3.8B edge
graph. Compared to GVE-Louvain, our optimized parallel Louvain implementation,
GVE-Leiden achieves an 11x reduction in disconnected communities, with only a
36% increase in runtime. In addition, GVE-Leiden improves performance at an
average rate of 1.6x for every doubling of threads.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13938" title="Abstract">arXiv:2312.13938</a> [<a href="/pdf/2312.13938" title="Download PDF">pdf</a>, <a href="/format/2312.13938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Does Stake Distribution Influence Consensus? Analyzing Blockchain  Decentralization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motepalli%2C+S">Shashank Motepalli</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In the PoS blockchain landscape, the challenge of achieving full
decentralization is often hindered by a disproportionate concentration of
staked tokens among a few validators. This study analyses this challenge by
first formalizing decentralization metrics for weighted consensus mechanisms.
An empirical analysis across ten permissionless blockchains uncovers
significant weight concentration among validators, underscoring the need for an
equitable approach. To counter this, we introduce the Square Root Stake Weight
(SRSW) model, which effectively recalibrates staking weight distribution. Our
examination of the SRSW model demonstrates notable improvements in the
decentralization metrics: the Gini index improves by 37.16% on average, while
Nakamoto coefficients for liveness and safety see mean enhancements of 101.04%
and 80.09%, respectively. This research is a pivotal step toward a more fair
and equitable distribution of staking weight, advancing the decentralization in
blockchain consensus mechanisms.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13940" title="Abstract">arXiv:2312.13940</a> [<a href="/pdf/2312.13940" title="Download PDF">pdf</a>, <a href="/ps/2312.13940" title="Download PostScript">ps</a>, <a href="/format/2312.13940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stairway to heaven: designing for an embodied experience with satellite  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hansen%2C+T+O">Thea Overby Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+M+L">Maria Leis Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Tonnesen%2C+L+S">Line Schack Tonnesen</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B8vlie%2C+A+S">Anders Sundnes L&#xf8;vlie</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Hansen, T.O., Jensen, M.L., Tonnesen, L.S.,and L{\o}vlie, A.S.
  (2023) Stairway to Heaven: Designing for an Embodied Experience with
  Satellite Data, in IASDR 2023: Life-Changing Design, 9-13 October, Milan,
  Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper explores the design of an interactive installation in a science
center which facilitates an embodied experience with satellite data. This
addresses a central concern for experience design in museums, which is the
question of how to integrate technologies well in the visitor experience,
sometimes referred to as "experience blend". We present the design and
evaluation of a visualization triggered by movement in a physical staircase to
let visitors explore data about satellites at different orbits. The evaluation
demonstrates strong experience blend, and points towards similar design
opportunities for other institutions interested in finding new uses for mundane
pathways through their buildings.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13941" title="Abstract">arXiv:2312.13941</a> [<a href="/pdf/2312.13941" title="Download PDF">pdf</a>, <a href="/format/2312.13941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable 3D Face Generation with Conditional Style Code Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaolong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating photorealistic 3D faces from given conditions is a challenging
task. Existing methods often rely on time-consuming one-by-one optimization
approaches, which are not efficient for modeling the same distribution content,
e.g., faces. Additionally, an ideal controllable 3D face generation model
should consider both facial attributes and expressions. Thus we propose a novel
approach called TEx-Face(TExt &amp; Expression-to-Face) that addresses these
challenges by dividing the task into three components, i.e., 3D GAN Inversion,
Conditional Style Code Diffusion, and 3D Face Decoding. For 3D GAN inversion,
we introduce two methods which aim to enhance the representation of style codes
and alleviate 3D inconsistencies. Furthermore, we design a style code denoiser
to incorporate multiple conditions into the style code and propose a data
augmentation strategy to address the issue of insufficient paired
visual-language data. Extensive experiments conducted on FFHQ, CelebA-HQ, and
CelebA-Dialog demonstrate the promising performance of our TEx-Face in
achieving the efficient and controllable generation of photorealistic 3D faces.
The code will be available at https://github.com/sxl142/TEx-Face.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13949" title="Abstract">arXiv:2312.13949</a> [<a href="/pdf/2312.13949" title="Download PDF">pdf</a>, <a href="/format/2312.13949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Termination in Term Rewriting and Logic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Payet%2C+E">Etienne Payet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Journal of Automated Reasoning, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this paper, we define two particular forms of non-termination, namely
loops and binary chains, in an abstract framework that encompasses term
rewriting and logic programming. The definition of loops relies on the notion
of compatibility of binary relations. We also present a syntactic criterion for
the detection of a special case of binary chains. Moreover, we describe our
implementation NTI and compare its results at the Termination Competition 2023
with those of leading analyzers.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13951" title="Abstract">arXiv:2312.13951</a> [<a href="/pdf/2312.13951" title="Download PDF">pdf</a>, <a href="/format/2312.13951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typhoon: Thai Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pipatanakul%2C+K">Kunat Pipatanakul</a>, 
<a href="/search/cs?searchtype=author&query=Jirabovonvisut%2C+P">Phatrasek Jirabovonvisut</a>, 
<a href="/search/cs?searchtype=author&query=Manakul%2C+P">Potsawee Manakul</a>, 
<a href="/search/cs?searchtype=author&query=Sripaisarnmongkol%2C+S">Sittipong Sripaisarnmongkol</a>, 
<a href="/search/cs?searchtype=author&query=Patomwong%2C+R">Ruangsak Patomwong</a>, 
<a href="/search/cs?searchtype=author&query=Chokchainant%2C+P">Pathomporn Chokchainant</a>, 
<a href="/search/cs?searchtype=author&query=Tharnpipitchai%2C+K">Kasima Tharnpipitchai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Typhoon is a series of Thai large language models (LLMs) developed
specifically for the Thai language. This technical report presents challenges
and insights in developing Thai LLMs, including data preparation, pretraining,
instruction-tuning, and evaluation. As one of the challenges of low-resource
languages is the amount of pretraining data, we apply continual training to
transfer existing world knowledge from a strong LLM. To evaluate the Thai
knowledge encapsulated in each model from the pretraining stage, we develop
ThaiExam, a benchmark based on examinations for high-school students and
investment professionals in Thailand. In addition, we fine-tune Typhoon to
follow Thai instructions, and we evaluate instruction-tuned models on Thai
instruction datasets as well as translation, summarization, and
question-answering tasks. Experimental results on a suite of Thai benchmarks
show that Typhoon outperforms all open-source Thai language models, and its
performance is on par with GPT-3.5 in Thai while having only 7 billion
parameters and being 2.62 times more efficient in tokenizing Thai text.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13953" title="Abstract">arXiv:2312.13953</a> [<a href="/pdf/2312.13953" title="Download PDF">pdf</a>, <a href="/ps/2312.13953" title="Download PostScript">ps</a>, <a href="/format/2312.13953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subtle Sound Design: Designing for experience blend in a historic house  museum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yates%2C+M+F">Mia F. Yates</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B8vlie%2C+A+S">Anders Sundnes L&#xf8;vlie</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mia F. Yates and Anders S. L{\o}vlie. 2023. Subtle Sound Design:
  Designing for Experience Blend in a Historic House Museum. J. Comput. Cult.
  Herit. (November 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this article, we present and discuss a user-study prototype, developed for
Bakkehuset historic house museum in Copenhagen. We examine how the prototype -
a digital sound installation - can expand visitors' experiences of the house
and offer encounters with immaterial cultural heritage. Historic house museums
often hold back on utilizing digital communication tools inside the houses,
since a central purpose of this type of museum is to preserve an original
environment. Digital communication tools however hold great potential for
facilitating rich encounters with cultural heritage and in particular with the
immaterial aspects of museum collections and their histories. In this article
we present our design steps and choices, aiming at subtly and seamlessly adding
a digital dimension to a historic house. Based on qualitative interviews, we
evaluate how the sound installation at Bakkehuset is sensed, interpreted, and
used by visitors as part of their museum experience. In turn, we shed light on
the historic house museum as a distinct design context for designing hybrid
visitor experiences and point to the potentials of digital communication tools
in this context.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13961" title="Abstract">arXiv:2312.13961</a> [<a href="/pdf/2312.13961" title="Download PDF">pdf</a>, <a href="/format/2312.13961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT as a commenter to the news: can LLMs generate human-like  opinions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseng%2C+R">Rayden Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Verberne%2C+S">Suzan Verberne</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Putten%2C+P">Peter van der Putten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as Tseng, R., Verberne, S., van der Putten, P. (2023). ChatGPT as a Commenter to the News: Can LLMs Generate Human-Like Opinions?. In: Ceolin, D., Caselli, T., Tulin, M. (eds) Disinformation in Open Online Media. MISDOOM 2023. Lecture Notes in Computer Science, vol 14397. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">ChatGPT, GPT-3.5, and other large language models (LLMs) have drawn
significant attention since their release, and the abilities of these models
have been investigated for a wide variety of tasks. In this research we
investigate to what extent GPT-3.5 can generate human-like comments on Dutch
news articles. We define human likeness as `not distinguishable from human
comments', approximated by the difficulty of automatic classification between
human and GPT comments. We analyze human likeness across multiple prompting
techniques. In particular, we utilize zero-shot, few-shot and context prompts,
for two generated personas. We found that our fine-tuned BERT models can easily
distinguish human-written comments from GPT-3.5 generated comments, with none
of the used prompting methods performing noticeably better. We further analyzed
that human comments consistently showed higher lexical diversity than
GPT-generated comments. This indicates that although generative LLMs can
generate fluent text, their capability to create human-like opinionated
comments is still limited.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13964" title="Abstract">arXiv:2312.13964</a> [<a href="/pdf/2312.13964" title="Download PDF">pdf</a>, <a href="/format/2312.13964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIA: Your Personalized Image Animator via Plug-and-Play Modules in  Text-to-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhening Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yanhong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Youqing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://pi-animator.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in personalized text-to-image (T2I) models have
revolutionized content creation, empowering non-experts to generate stunning
images with unique styles. While promising, adding realistic motions into these
personalized images by text poses significant challenges in preserving distinct
styles, high-fidelity details, and achieving motion controllability by text. In
this paper, we present PIA, a Personalized Image Animator that excels in
aligning with condition images, achieving motion controllability by text, and
the compatibility with various personalized T2I models without specific tuning.
To achieve these goals, PIA builds upon a base T2I model with well-trained
temporal alignment layers, allowing for the seamless transformation of any
personalized T2I model into an image animation model. A key component of PIA is
the introduction of the condition module, which utilizes the condition frame
and inter-frame affinity as input to transfer appearance information guided by
the affinity hint for individual frame synthesis in the latent space. This
design mitigates the challenges of appearance-related image alignment within
and allows for a stronger focus on aligning with motion-related guidance.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13967" title="Abstract">arXiv:2312.13967</a> [<a href="/pdf/2312.13967" title="Download PDF">pdf</a>, <a href="/format/2312.13967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mouallem%2C+M">Marwa Mouallem</a>, 
<a href="/search/cs?searchtype=author&query=Eyal%2C+I">Ittay Eyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">A myriad of authentication mechanisms embody a continuous evolution from
verbal passwords in ancient times to contemporary multi-factor authentication.
Nevertheless, digital asset heists and numerous identity theft cases illustrate
the urgent need to revisit the fundamentals of user authentication. We abstract
away credential details and formalize the general, common case of asynchronous
authentication, with unbounded message propagation time. Our model, which might
be of independent interest, allows for eventual message delivery, while
bounding execution time to maintain cryptographic guarantees. Given
credentials' fault probabilities (e.g., loss or leak), we seek mechanisms with
the highest success probability. We show that every mechanism is dominated by
some Boolean mechanism -- defined by a monotonic Boolean function on presented
credentials. We present an algorithm for finding approximately optimal
mechanisms. Previous work analyzed Boolean mechanisms specifically, but used
brute force, which quickly becomes prohibitively complex. We leverage the
problem structure to reduce complexity by orders of magnitude. The algorithm is
readily applicable to practical settings. For example, we revisit the common
approach in cryptocurrency wallets that use a handful of high-quality
credentials. We show that adding low-quality credentials improves security by
orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13969" title="Abstract">arXiv:2312.13969</a> [<a href="/pdf/2312.13969" title="Download PDF">pdf</a>, <a href="/format/2312.13969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An event-driven link-level simulator for validation of AFDX and Ethernet  avionics networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vera-Soto%2C+P">Pablo Vera-Soto</a>, 
<a href="/search/cs?searchtype=author&query=Villegas%2C+J">Javier Villegas</a>, 
<a href="/search/cs?searchtype=author&query=Fortes%2C+S">Sergio Fortes</a>, 
<a href="/search/cs?searchtype=author&query=Pulido%2C+J">Jos&#xe9; Pulido</a>, 
<a href="/search/cs?searchtype=author&query=Esca%C3%B1o%2C+V">Vicente Esca&#xf1;o</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+R">Rafael Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Barco%2C+R">Raquel Barco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Aircraft are composed of many electronic systems: sensors, displays,
navigation equipment and communication elements. These elements require a
reliable interconnection, which is a major challenge for communication networks
as high reliability and predictability requirements must be verified for safe
operation. In addition, their verification via hardware deployments is limited
because these are costly and make difficult to try different architectures and
configurations, thus delaying the design and development in this area.
Therefore, verification at early stages in the design process is of great
importance and must be supported by simulation. In this context, this work
presents an event-driven link level framework and simulator for the validation
of avionics networks. The presented tool supports communication protocols such
as Avionics Full-Duplex Switched Ethernet (AFDX), which is a common protocol in
avionics, as well as Ethernet, used with static routing. Alsa, accurate results
are facilitated by the simulator through the utilization of realistic models
for the different devices. The proposed platform is evaluated in Clean Sky's
Disruptive Cockpit for Large Passenger Aircraft architecture scenario showing
capabilities of the simulator. The speed of the verification is a key factor in
its application, so the computational cost is analysed, proving that the
execution time is linearly dependent on the number of messages sent.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13970" title="Abstract">arXiv:2312.13970</a> [<a href="/pdf/2312.13970" title="Download PDF">pdf</a>, <a href="/format/2312.13970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Partial Optimal Transport: Revising the Infeasibility of Sinkhorn and  Efficient Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+D">Anh Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+D">Tuan Dung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+M">Quang Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Hoang H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Toh%2C+K">Kim-Chuan Toh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper studies the Partial Optimal Transport (POT) problem between two
unbalanced measures with at most $n$ supports and its applications in various
AI tasks such as color transfer or domain adaptation. There is hence the need
for fast approximations of POT with increasingly large problem sizes in arising
applications. We first theoretically and experimentally investigate the
infeasibility of the state-of-the-art Sinkhorn algorithm for POT due to its
incompatible rounding procedure, which consequently degrades its qualitative
performance in real world applications like point-cloud registration. To this
end, we propose a novel rounding algorithm for POT, and then provide a feasible
Sinkhorn procedure with a revised computation complexity of
$\mathcal{\widetilde O}(n^2/\varepsilon^4)$. Our rounding algorithm also
permits the development of two first-order methods to approximate the POT
problem. The first algorithm, Adaptive Primal-Dual Accelerated Gradient Descent
(APDAGD), finds an $\varepsilon$-approximate solution to the POT problem in
$\mathcal{\widetilde O}(n^{2.5}/\varepsilon)$, which is better in $\varepsilon$
than revised Sinkhorn. The second method, Dual Extrapolation, achieves the
computation complexity of $\mathcal{\widetilde O}(n^2/\varepsilon)$, thereby
being the best in the literature. We further demonstrate the flexibility of POT
compared to standard OT as well as the practicality of our algorithms on real
applications where two marginal distributions are unbalanced.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13975" title="Abstract">arXiv:2312.13975</a> [<a href="/pdf/2312.13975" title="Download PDF">pdf</a>, <a href="/format/2312.13975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Communication and Computation Design for Semantic Wireless  Communication with Probability Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhouxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+X">Xu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.00015">arXiv:2310.00015</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we delve into the challenge of optimizing joint communication
and computation for semantic communication over wireless networks using a
probability graph framework. In the considered model, the base station (BS)
extracts the small-sized compressed semantic information through removing
redundant messages based on the stored knowledge base. Specifically, the
knowledge base is encapsulated in a probability graph that encapsulates
statistical relations. At the user side, the compressed information is
accurately deduced using the same probability graph employed by the BS. While
this approach introduces an additional computational overhead for semantic
information extraction, it significantly curtails communication resource
consumption by transmitting concise data. We derive both communication and
computation cost models based on the inference process of the probability
graph. Building upon these models, we introduce a joint communication and
computation resource allocation problem aimed at minimizing the overall energy
consumption of the network, while accounting for latency, power, and semantic
constraints. To address this problem, we obtain a closed-form solution for
transmission power under a fixed semantic compression ratio. Subsequently, we
propose an efficient linear search-based algorithm to attain the optimal
solution for the considered problem with low computational complexity.
Simulation results underscore the effectiveness of our proposed system,
showcasing notable improvements compared to conventional non-semantic schemes.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13977" title="Abstract">arXiv:2312.13977</a> [<a href="/pdf/2312.13977" title="Download PDF">pdf</a>, <a href="/format/2312.13977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse  Input Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junsheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+M">Ming Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yushen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Project page: <a href="https://alvin528.github.io/NeuSurf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, neural implicit functions have demonstrated remarkable results in
the field of multi-view reconstruction. However, most existing methods are
tailored for dense views and exhibit unsatisfactory performance when dealing
with sparse views. Several latest methods have been proposed for generalizing
implicit reconstruction to address the sparse view reconstruction task, but
they still suffer from high training costs and are merely valid under carefully
selected perspectives. In this paper, we propose a novel sparse view
reconstruction framework that leverages on-surface priors to achieve highly
faithful surface reconstruction. Specifically, we design several constraints on
global geometry alignment and local geometry refinement for jointly optimizing
coarse shapes and fine details. To achieve this, we train a neural network to
learn a global implicit field from the on-surface points obtained from SfM and
then leverage it as a coarse geometric constraint. To exploit local geometric
consistency, we project on-surface points onto seen and unseen views, treating
the consistent loss of projected features as a fine geometric constraint. The
experimental results with DTU and BlendedMVS datasets in two prevalent sparse
settings demonstrate significant improvements over the state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13978" title="Abstract">arXiv:2312.13978</a> [<a href="/pdf/2312.13978" title="Download PDF">pdf</a>, <a href="/format/2312.13978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metalearning with Very Few Samples Per Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliakbarpour%2C+M">Maryam Aliakbarpour</a>, 
<a href="/search/cs?searchtype=author&query=Bairaktari%2C+K">Konstantina Bairaktari</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+G">Gavin Brown</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+A">Adam Smith</a>, 
<a href="/search/cs?searchtype=author&query=Ullman%2C+J">Jonathan Ullman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Metalearning and multitask learning are two frameworks for solving a group of
related learning tasks more efficiently than we could hope to solve each of the
individual tasks on their own. In multitask learning, we are given a fixed set
of related learning tasks and need to output one accurate model per task,
whereas in metalearning we are given tasks that are drawn i.i.d. from a
metadistribution and need to output some common information that can be easily
specialized to new, previously unseen tasks from the metadistribution.
<br />In this work, we consider a binary classification setting where tasks are
related by a shared representation, that is, every task $P$ of interest can be
solved by a classifier of the form $f_{P} \circ h$ where $h \in H$ is a map
from features to some representation space that is shared across tasks, and
$f_{P} \in F$ is a task-specific classifier from the representation space to
labels. The main question we ask in this work is how much data do we need to
metalearn a good representation? Here, the amount of data is measured in terms
of both the number of tasks $t$ that we need to see and the number of samples
$n$ per task. We focus on the regime where the number of samples per task is
extremely small. Our main result shows that, in a distribution-free setting
where the feature vectors are in $\mathbb{R}^d$, the representation is a linear
map from $\mathbb{R}^d \to \mathbb{R}^k$, and the task-specific classifiers are
halfspaces in $\mathbb{R}^k$, we can metalearn a representation with error
$\varepsilon$ using just $n = k+2$ samples per task, and $d \cdot
(1/\varepsilon)^{O(k)}$ tasks. Learning with so few samples per task is
remarkable because metalearning would be impossible with $k+1$ samples per
task, and because we cannot even hope to learn an accurate task-specific
classifier with just $k+2$ samples per task.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13980" title="Abstract">arXiv:2312.13980</a> [<a href="/pdf/2312.13980" title="Download PDF">pdf</a>, <a href="/format/2312.13980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Carve3D: Improving Multi-view Reconstruction Consistency for Diffusion  Models with RL Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+D">Desai Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Z">Zhixin Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>, 
<a href="/search/cs?searchtype=author&query=Pirk%2C+S">S&#xf6;ren Pirk</a>, 
<a href="/search/cs?searchtype=author&query=Kaufman%2C+A+E">Arie E. Kaufman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://desaixie.github.io/carve-3d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in the text-to-3D task leverage finetuned text-to-image
diffusion models to generate multi-view images, followed by NeRF
reconstruction. Yet, existing supervised finetuned (SFT) diffusion models still
suffer from multi-view inconsistency and the resulting NeRF artifacts. Although
training longer with SFT improves consistency, it also causes distribution
shift, which reduces diversity and realistic details. We argue that the SFT of
multi-view diffusion models resembles the instruction finetuning stage of the
LLM alignment pipeline and can benefit from RL finetuning (RLFT) methods.
Essentially, RLFT methods optimize models beyond their SFT data distribution by
using their own outputs, effectively mitigating distribution shift. To this
end, we introduce Carve3D, a RLFT method coupled with the Multi-view
Reconstruction Consistency (MRC) metric, to improve the consistency of
multi-view diffusion models. To compute MRC on a set of multi-view images, we
compare them with their corresponding renderings of the reconstructed NeRF at
the same viewpoints. We validate the robustness of MRC with extensive
experiments conducted under controlled inconsistency levels. We enhance the
base RLFT algorithm to stabilize the training process, reduce distribution
shift, and identify scaling laws. Through qualitative and quantitative
experiments, along with a user study, we demonstrate Carve3D's improved
multi-view consistency, the resulting superior NeRF reconstruction quality, and
minimal distribution shift compared to longer SFT. Project webpage:
https://desaixie.github.io/carve-3d.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13981" title="Abstract">arXiv:2312.13981</a> [<a href="/pdf/2312.13981" title="Download PDF">pdf</a>, <a href="/format/2312.13981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Long Range-Frequency Hopping Spread Spectrum (LR-FHSS)  with Real-World Packet Traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bukhari%2C+J">Jumana Bukhari</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenghao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Long Range-Frequency Hopping Spread Spectrum (LR-FHSS) is a new physical
layer option that has been recently added to the LoRa family with the promise
of achieving much higher network capacity than the previous versions of LoRa.
In this paper, we present our evaluation of LR-FHSS based on real-world packet
traces collected with an LR-FHSS device and a receiver we designed and
implemented in software. We overcame challenges due to the lack of
documentations of LR-FHSS and our study is the first of its kind that processes
signals transmitted by an actual LR-FHSS device with practical issues such as
frequency error. Our results show that LR-FHSS meets its expectations in
communication range and network capacity. We also propose customized methods
for LR-FHSS that improve its performance significantly, allowing our receiver
to achieve higher network capacity than those reported earlier.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13985" title="Abstract">arXiv:2312.13985</a> [<a href="/pdf/2312.13985" title="Download PDF">pdf</a>, <a href="/ps/2312.13985" title="Download PostScript">ps</a>, <a href="/format/2312.13985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R&#xe9;nyi Pufferfish Privacy: General Additive Noise Mechanisms and  Privacy Amplification by Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pierquin%2C+C">Cl&#xe9;ment Pierquin</a>, 
<a href="/search/cs?searchtype=author&query=Bellet%2C+A">Aur&#xe9;lien Bellet</a>, 
<a href="/search/cs?searchtype=author&query=Tommasi%2C+M">Marc Tommasi</a>, 
<a href="/search/cs?searchtype=author&query=Boussard%2C+M">Matthieu Boussard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Pufferfish privacy is a flexible generalization of differential privacy that
allows to model arbitrary secrets and adversary's prior knowledge about the
data. Unfortunately, designing general and tractable Pufferfish mechanisms that
do not compromise utility is challenging. Furthermore, this framework does not
provide the composition guarantees needed for a direct use in iterative machine
learning algorithms. To mitigate these issues, we introduce a R\'enyi
divergence-based variant of Pufferfish and show that it allows us to extend the
applicability of the Pufferfish framework. We first generalize the Wasserstein
mechanism to cover a wide range of noise distributions and introduce several
ways to improve its utility. We also derive stronger guarantees against
out-of-distribution adversaries. Finally, as an alternative to composition, we
prove privacy amplification results for contractive noisy iterations and
showcase the first use of Pufferfish in private convex optimization. A common
ingredient underlying our results is the use and extension of shift reduction
lemmas.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13987" title="Abstract">arXiv:2312.13987</a> [<a href="/pdf/2312.13987" title="Download PDF">pdf</a>, <a href="/format/2312.13987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Neural Network Policies for Learning In-Flight Object Catching  with a Robot Hand-Arm System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Acero%2C+F">Fernando Acero</a>, 
<a href="/search/cs?searchtype=author&query=Triantafyllidis%2C+E">Eleftherios Triantafyllidis</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaocheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages. Accepted and presented at IEEE IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a modular framework designed to enable a robot hand-arm system to
learn how to catch flying objects, a task that requires fast, reactive, and
accurately-timed robot motions. Our framework consists of five core modules:
(i) an object state estimator that learns object trajectory prediction, (ii) a
catching pose quality network that learns to score and rank object poses for
catching, (iii) a reaching control policy trained to move the robot hand to
pre-catch poses, (iv) a grasping control policy trained to perform soft
catching motions for safe and robust grasping, and (v) a gating network trained
to synthesize the actions given by the reaching and grasping policy. The former
two modules are trained via supervised learning and the latter three use deep
reinforcement learning in a simulated environment. We conduct extensive
evaluations of our framework in simulation for each module and the integrated
system, to demonstrate high success rates of in-flight catching and robustness
to perturbations and sensory noise. Whilst only simple cylindrical and
spherical objects are used for training, the integrated system shows successful
generalization to a variety of household objects that are not used in training.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13993" title="Abstract">arXiv:2312.13993</a> [<a href="/pdf/2312.13993" title="Download PDF">pdf</a>, <a href="/format/2312.13993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Set: ID Card Presentation Attack Detection using Neural Transfer  Style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markham%2C+R">Reuben Markham</a>, 
<a href="/search/cs?searchtype=author&query=Espin%2C+J+M">Juan M. Espin</a>, 
<a href="/search/cs?searchtype=author&query=Nieto-Hidalgo%2C+M">Mario Nieto-Hidalgo</a>, 
<a href="/search/cs?searchtype=author&query=Tapia%2C+J+E">Juan E. Tapia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The accurate detection of ID card Presentation Attacks (PA) is becoming
increasingly important due to the rising number of online/remote services that
require the presentation of digital photographs of ID cards for digital
onboarding or authentication. Furthermore, cybercriminals are continuously
searching for innovative ways to fool authentication systems to gain
unauthorized access to these services. Although advances in neural network
design and training have pushed image classification to the state of the art,
one of the main challenges faced by the development of fraud detection systems
is the curation of representative datasets for training and evaluation. The
handcrafted creation of representative presentation attack samples often
requires expertise and is very time-consuming, thus an automatic process of
obtaining high-quality data is highly desirable. This work explores ID card
Presentation Attack Instruments (PAI) in order to improve the generation of
samples with four Generative Adversarial Networks (GANs) based image
translation models and analyses the effectiveness of the generated data for
training fraud detection systems. Using open-source data, we show that
synthetic attack presentations are an adequate complement for additional real
attack presentations, where we obtain an EER performance increase of 0.63%
points for print attacks and a loss of 0.29% for screen capture attacks.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14000" title="Abstract">arXiv:2312.14000</a> [<a href="/pdf/2312.14000" title="Download PDF">pdf</a>, <a href="/ps/2312.14000" title="Download PostScript">ps</a>, <a href="/format/2312.14000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Sensitive Stochastic Optimal Control as Rao-Blackwellized Markovian  Score Climbing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulsamad%2C+H">Hany Abdulsamad</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S">Sahel Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Corenflos%2C+A">Adrien Corenflos</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A4rkk%C3%A4%2C+S">Simo S&#xe4;rkk&#xe4;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Stochastic optimal control of dynamical systems is a crucial challenge in
sequential decision-making. Recently, control-as-inference approaches have had
considerable success, providing a viable risk-sensitive framework to address
the exploration-exploitation dilemma. Nonetheless, a majority of these
techniques only invoke the inference-control duality to derive a modified risk
objective that is then addressed within a reinforcement learning framework.
This paper introduces a novel perspective by framing risk-sensitive stochastic
control as Markovian score climbing under samples drawn from a conditional
particle filter. Our approach, while purely inference-centric, provides
asymptotically unbiased estimates for gradient-based policy optimization with
optimal importance weighting and no explicit value function learning. To
validate our methodology, we apply it to the task of learning neural
non-Gaussian feedback policies, showcasing its efficacy on numerical benchmarks
of stochastic dynamical systems.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14001" title="Abstract">arXiv:2312.14001</a> [<a href="/pdf/2312.14001" title="Download PDF">pdf</a>, <a href="/format/2312.14001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Based Face Recognition Method using Siamese Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="/search/cs?searchtype=author&query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Achieving state-of-the-art results in face verification systems typically
hinges on the availability of labeled face training data, a resource that often
proves challenging to acquire in substantial quantities. In this research
endeavor, we proposed employing Siamese networks for face recognition,
eliminating the need for labeled face images. We achieve this by strategically
leveraging negative samples alongside nearest neighbor counterparts, thereby
establishing positive and negative pairs through an unsupervised methodology.
The architectural framework adopts a VGG encoder, trained as a double branch
siamese network. Our primary aim is to circumvent the necessity for labeled
face image data, thus proposing the generation of training pairs in an entirely
unsupervised manner. Positive training data are selected within a dataset based
on their highest cosine similarity scores with a designated anchor, while
negative training data are culled in a parallel fashion, though drawn from an
alternate dataset. During training, the proposed siamese network conducts
binary classification via cross-entropy loss. Subsequently, during the testing
phase, we directly extract face verification scores from the network's output
layer. Experimental results reveal that the proposed unsupervised system
delivers a performance on par with a similar but fully supervised baseline.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14005" title="Abstract">arXiv:2312.14005</a> [<a href="/pdf/2312.14005" title="Download PDF">pdf</a>, <a href="/ps/2312.14005" title="Download PostScript">ps</a>, <a href="/format/2312.14005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the choice of the optimal temporal support for audio classification  with Pre-trained embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quelennec%2C+A">Aurian Quelennec</a>, 
<a href="/search/cs?searchtype=author&query=Olvera%2C+M">Michel Olvera</a>, 
<a href="/search/cs?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a>, 
<a href="/search/cs?searchtype=author&query=Essid%2C+S">Slim Essid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Current state-of-the-art audio analysis systems rely on pre-trained embedding
models, often used off-the-shelf as (frozen) feature extractors. Choosing the
best one for a set of tasks is the subject of many recent publications.
However, one aspect often overlooked in these works is the influence of the
duration of audio input considered to extract an embedding, which we refer to
as Temporal Support (TS). In this work, we study the influence of the TS for
well-established or emerging pre-trained embeddings, chosen to represent
different types of architectures and learning paradigms. We conduct this
evaluation using both musical instrument and environmental sound datasets,
namely OpenMIC, TAU Urban Acoustic Scenes 2020 Mobile, and ESC-50. We
especially highlight that Audio Spectrogram Transformer-based systems (PaSST
and BEATs) remain effective with smaller TS, which therefore allows for a
drastic reduction in memory and computational cost. Moreover, we show that by
choosing the optimal TS we reach competitive results across all tasks. In
particular, we improve the state-of-the-art results on OpenMIC, using BEATs and
PaSST without any fine-tuning.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14020" title="Abstract">arXiv:2312.14020</a> [<a href="/pdf/2312.14020" title="Download PDF">pdf</a>, <a href="/ps/2312.14020" title="Download PostScript">ps</a>, <a href="/format/2312.14020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BANSpEmo: A Bangla Emotional Speech Recognition Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+M+G">Md Gulzar Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mahmuda Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sultana%2C+B">Babe Sultana</a>, 
<a href="/search/cs?searchtype=author&query=Shiren%2C+Y">Ye Shiren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the field of audio and speech analysis, the ability to identify emotions
from acoustic signals is essential. Human-computer interaction (HCI) and
behavioural analysis are only a few of the many areas where the capacity to
distinguish emotions from speech signals has an extensive range of
applications. Here, we are introducing BanSpEmo, a corpus of emotional speech
that only consists of audio recordings and has been created specifically for
the Bangla language. This corpus contains 792 audio recordings over a duration
of more than 1 hour and 23 minutes. 22 native speakers took part in the
recording of two sets of sentences that represent the six desired emotions. The
data set consists of 12 Bangla sentences which are uttered in 6 emotions as
Disgust, Happy, Sad, Surprised, Anger, and Fear. This corpus is not also gender
balanced. Ten individuals who either have experience in related field or have
acting experience took part in the assessment of this corpus. It has a balanced
number of audio recordings in each emotion class. BanSpEmo can be considered as
a useful resource to promote emotion and speech recognition research and
related applications in the Bangla language. The dataset can be found here:
https://data.mendeley.com/datasets/rdwn4bs5ky and might be employed for
academic research.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14023" title="Abstract">arXiv:2312.14023</a> [<a href="/pdf/2312.14023" title="Download PDF">pdf</a>, <a href="/ps/2312.14023" title="Download PostScript">ps</a>, <a href="/format/2312.14023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leakage-Resilient Hardness Equivalence to Logspace Derandomization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shalunov%2C+Y">Yakov Shalunov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Efficient derandomization has long been a goal in complexity theory, and a
major recent result by Yanyi Liu and Rafael Pass identifies a new class of
hardness assumption under which it is possible to perform time-bounded
derandomization efficiently: that of ''leakage-resilient hardness.'' They
identify a specific form of this assumption which is $\textit{equivalent}$ to
$\mathsf{prP} = \mathsf{prBPP}$. In this paper, we pursue a an equivalence to
derandomization of $\mathsf{prBP{\cdot}L}$ (logspace promise problems with
two-way randomness) through techniques analogous to Liu and Pass. We are able
to obtain an equivalence between a similar ''leakage-resilient hardness''
assumption and a slightly stronger statement than derandomization of
$\mathsf{prBP{\cdot}L}$, that of finding ''non-no'' instances of ''promise
search problems.''
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14024" title="Abstract">arXiv:2312.14024</a> [<a href="/pdf/2312.14024" title="Download PDF">pdf</a>, <a href="/format/2312.14024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Awareness in Neural Fields for 3D Human Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marin%2C+R">Riccardo Marin</a>, 
<a href="/search/cs?searchtype=author&query=Corona%2C+E">Enric Corona</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Aligning a template to 3D human point clouds is a long-standing problem
crucial for tasks like animation, reconstruction, and enabling supervised
learning pipelines. Recent data-driven methods leverage predicted surface
correspondences; however, they are not robust to varied poses or distributions.
In contrast, industrial solutions often rely on expensive manual annotations or
multi-view capturing systems. Recently, neural fields have shown promising
results, but their purely data-driven nature lacks geometric awareness, often
resulting in a trivial misalignment of the template registration. In this work,
we propose two solutions: LoVD, a novel neural field model that predicts the
direction towards the localized SMPL vertices on the target surface; and INT,
the first self-supervised task dedicated to neural fields that, at test time,
refines the backbone, exploiting the target geometry. We combine them into
INLoVD, a robust 3D Human body registration pipeline trained on a large MoCap
dataset. INLoVD is efficient (takes less than a minute), solidly achieves the
state of the art over public benchmarks, and provides unprecedented
generalization on out-of-distribution data. We will release code and
checkpoints in \url{url}.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14028" title="Abstract">arXiv:2312.14028</a> [<a href="/pdf/2312.14028" title="Download PDF">pdf</a>, <a href="/ps/2312.14028" title="Download PostScript">ps</a>, <a href="/format/2312.14028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient quantum algorithms for some instances of the semidirect  discrete logarithm problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imran%2C+M">Muhammad Imran</a>, 
<a href="/search/cs?searchtype=author&query=Ivanyos%2C+G">G&#xe1;bor Ivanyos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC); Quantum Physics (quant-ph)

</div>
<p class="mathjax">The semidirect discrete logarithm problem (SDLP) is the following analogue of
the standard discrete logarithm problem in the semidirect product semigroup
$G\rtimes \mathrm{End}(G)$ for a finite semigroup $G$. Given $g\in G, \sigma\in
\mathrm{End}(G)$, and $h=\prod_{i=0}^{t-1}\sigma^i(g)$ for some integer $t$,
the SDLP$(G,\sigma)$, for $g$ and $h$, asks to determine $t$. As Shor's
algorithm crucially depends on commutativity, it is believed not to be
applicable to the SDLP. Previously, the best known algorithm for the SDLP was
based on Kuperberg's subexponential time quantum algorithm. Still, the problem
plays a central role in the security of certain proposed cryptosystems in the
family of \textit{semidirect product key exchange}. This includes a recently
proposed signature protocol called SPDH-Sign. In this paper, we show that the
SDLP is even easier in some important special cases. Specifically, for a finite
group $G$, we describe quantum algorithms for the SDLP in $G\rtimes
\mathrm{Aut}(G)$ for the following two classes of instances: the first one is
when $G$ is solvable and the second is when $G$ is a matrix group and a power
of $\sigma$ with a polynomially small exponent is an inner automorphism of $G$.
We further extend the results to groups composed of factors from these classes.
A consequence is that SPDH-Sign and similar cryptosystems whose security
assumption is based on the presumed hardness of the SDLP in the cases described
above are insecure against quantum attacks. The quantum ingredients we rely on
are not new: these are Shor's factoring and discrete logarithm algorithms and
well-known generalizations.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14029" title="Abstract">arXiv:2312.14029</a> [<a href="/pdf/2312.14029" title="Download PDF">pdf</a>, <a href="/format/2312.14029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phylogenetic tree distance computation over succinct representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Branco%2C+A+P">Ant&#xf3;nio Pedro Branco</a>, 
<a href="/search/cs?searchtype=author&query=Vaz%2C+C">C&#xe1;tia Vaz</a>, 
<a href="/search/cs?searchtype=author&query=Francisco%2C+A+P">Alexandre P. Francisco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">There are several tools available to infer phylogenetic trees, which depict
the evolutionary relationships among biological entities such as viral and
bacterial strains in infectious outbreaks, or cancerous cells in tumor
progression trees. These tools rely on several inference methods available to
produce phylogenetic trees, with resulting trees not being unique. Thus,
methods for comparing phylogenies that are capable of revealing where two
phylogenetic trees agree or differ are required. An approach is then to compute
a similarity or dissimilarity measure between trees, with the Robinson- Foulds
distance being one of the most used, and which can be computed in linear time
and space. Nevertheless, given the large and increasing volume of phylogenetic
data, phylogenetic trees are becoming very large with hundreds of thousands of
leafs. In this context, space requirements become an issue both while computing
tree distances and while storing trees. We propose then an efficient
implementation of the Robinson-Foulds distance over trees succinct
representations. Our implementation generalizes also the Robinson-Foulds
distances to labelled phylogenetic trees, i.e., trees containing labels on all
nodes, instead of only on leaves. Experimental results show that we are able to
still achieve linear time while requiring less space. Our implementation is
available as an open-source tool at
https://github.com/pedroparedesbranco/TreeDiff.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14030" title="Abstract">arXiv:2312.14030</a> [<a href="/pdf/2312.14030" title="Download PDF">pdf</a>, <a href="/format/2312.14030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Diagnosability Analysis of Multi-Mode Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemniya%2C+F">Fatemeh Hashemniya</a>, 
<a href="/search/cs?searchtype=author&query=Caillaud%2C+B">Beno&#xef;t Caillaud</a>, 
<a href="/search/cs?searchtype=author&query=Frisk%2C+E">Erik Frisk</a>, 
<a href="/search/cs?searchtype=author&query=Krysander%2C+M">Mattias Krysander</a>, 
<a href="/search/cs?searchtype=author&query=Malandain%2C+M">Mathias Malandain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Multi-mode systems can operate in different modes, leading to large numbers
of different dynamics. Consequently, applying traditional structural
diagnostics to such systems is often untractable. To address this challenge, we
present a multi-mode diagnostics algorithm that relies on a multi-mode
extension of the Dulmage-Mendelsohn decomposition. We introduce two
methodologies for modeling faults, either as signals or as Boolean variables,
and apply them to a modular switched battery system in order to demonstrate
their effectiveness and discuss their respective advantages.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14033" title="Abstract">arXiv:2312.14033</a> [<a href="/pdf/2312.14033" title="Download PDF">pdf</a>, <a href="/format/2312.14033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-Eval: Evaluating the Tool Utilization Capability Step by Step
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weihua Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiangning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Miao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+J">Jingming Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/open-compass/T-Eval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLM) have achieved remarkable performance on various
NLP tasks and are augmented by tools for broader applications. Yet, how to
evaluate and analyze the tool-utilization capability of LLMs is still
under-explored. In contrast to previous works that evaluate models
holistically, we comprehensively decompose the tool utilization into multiple
sub-processes, including instruction following, planning, reasoning, retrieval,
understanding, and review. Based on that, we further introduce \shortname~to
evaluate the tool utilization capability step by step. \shortname~disentangles
the tool utilization evaluation into several sub-domains along model
capabilities, facilitating the inner understanding of both holistic and
isolated competency of LLMs. We conduct extensive experiments on \shortname~and
in-depth analysis of various LLMs. \shortname~ not only exhibits consistency
with the outcome-oriented evaluation but also provides a more fine-grained
analysis of the capabilities of LLMs, providing a new perspective in LLM
evaluation on tool-utilization ability. The benchmark will be available at
\href{https://github.com/open-compass/T-Eval}{https://github.com/open-compass/T-Eval}.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14035" title="Abstract">arXiv:2312.14035</a> [<a href="/pdf/2312.14035" title="Download PDF">pdf</a>, <a href="/format/2312.14035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRIL-Calib: Targetless Ground Robot IMU-LiDAR Extrinsic Calibration  Method using Ground Plane Motion Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">TaeYoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Pak%2C+G">Gyuhyeon Pak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Euntai Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Targetless IMU-LiDAR extrinsic calibration methods are gaining significant
attention as the importance of the IMU-LiDAR fusion system increases. Notably,
existing calibration methods derive calibration parameters under the assumption
that the methods require full motion in all axes. When IMU and LiDAR are
mounted on a ground robot the motion of which is restricted to planar motion,
existing calibration methods are likely to exhibit degraded performance. To
address this issue, we present GRIL-Calib: a novel targetless Ground Robot
IMU-LiDAR Calibration method. Our proposed method leverages ground information
to compensate for the lack of unrestricted full motion. First, we propose LiDAR
Odometry (LO) using ground plane residuals to enhance calibration accuracy.
Second, we propose the Ground Plane Motion (GPM) constraint and incorporate it
into the optimization for calibration, enabling the determination of full 6-DoF
extrinsic parameters, including theoretically unobservable direction. Finally,
unlike baseline methods, we formulate the calibration not as sequential two
optimizations but as a single optimization (SO) problem, solving all
calibration parameters simultaneously and improving accuracy. We validate our
\textit{GRIL-Calib} by applying it to three public real-world datasets and
comparing its performance with that of existing state-of-the-art methods in
terms of accuracy and robustness. Our code is available at
https://github.com/Taeyoung96/GRIL-Calib.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14036" title="Abstract">arXiv:2312.14036</a> [<a href="/pdf/2312.14036" title="Download PDF">pdf</a>, <a href="/format/2312.14036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Total variation in popular rap vocals from 2009-2023: extension of the  analysis by Georgieva, Ripolles &amp; McFee
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walls%2C+K+L">Kelvin L Walls</a>, 
<a href="/search/cs?searchtype=author&query=Roman%2C+I+R">Iran R Roman</a>, 
<a href="/search/cs?searchtype=author&query=Steers%2C+B">Bea Steers</a>, 
<a href="/search/cs?searchtype=author&query=Georgieva%2C+E">Elena Georgieva</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Ismir 2023 Hybrid Conference 2023 Nov 5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Pitch variability in rap vocals is overlooked in favor of the genre's
uniquely dynamic rhythmic properties. We present an analysis of fundamental
frequency (F0) variation in rap vocals over the past 14 years, focusing on song
examples that represent the state of modern rap music. Our analysis aims at
identifying meaningful trends over time, and is in turn a continuation of the
2023 analysis by Georgieva, Ripolles &amp; McFee. They found rap to be an outlier
with larger F0 variation compared to other genres, but with a declining trend
since the genre's inception. However, they only analyzed data through 2010. Our
analysis looks beyond 2010. We once again observe rap's large F0 variation, but
with a decelerated decline in recent years.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14037" title="Abstract">arXiv:2312.14037</a> [<a href="/pdf/2312.14037" title="Download PDF">pdf</a>, <a href="/ps/2312.14037" title="Download PostScript">ps</a>, <a href="/format/2312.14037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Contextual Bandits for Personalized Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ban%2C+Y">Yikun Ban</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yunzhe Qi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW'24 Tutorial
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the dynamic landscape of online businesses, recommender systems are
pivotal in enhancing user experiences. While traditional approaches have relied
on static supervised learning, the quest for adaptive, user-centric
recommendations has led to the emergence of the formulation of contextual
bandits. This tutorial investigates the contextual bandits as a powerful
framework for personalized recommendations. We delve into the challenges,
advanced algorithms and theories, collaborative strategies, and open challenges
and future prospects within this field. Different from existing related
tutorials, (1) we focus on the exploration perspective of contextual bandits to
alleviate the ``Matthew Effect'' in the recommender systems, i.e., the rich get
richer and the poor get poorer, concerning the popularity of items; (2) in
addition to the conventional linear contextual bandits, we will also dedicated
to neural contextual bandits which have emerged as an important branch in
recent years, to investigate how neural networks benefit contextual bandits for
personalized recommendation both empirically and theoretically; (3) we will
cover the latest topic, collaborative neural contextual bandits, to incorporate
both user heterogeneity and user correlations customized for recommender
system; (4) we will provide and discuss the new emerging challenges and open
questions for neural contextual bandits with applications in the personalized
recommendation, especially for large neural models.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14038" title="Abstract">arXiv:2312.14038</a> [<a href="/pdf/2312.14038" title="Download PDF">pdf</a>, <a href="/ps/2312.14038" title="Download PostScript">ps</a>, <a href="/format/2312.14038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Mining Interval to Improve Blockchain Throughput
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+H">Hou-Wan Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiongfei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+Y">Yain-Whar Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Decentralized Finance (DeFi), propelled by Blockchain technology, has
revolutionized traditional financial systems, improving transparency, reducing
costs, and fostering financial inclusion. However, transaction activities in
these systems fluctuate significantly and the throughput can be effected. To
address this issue, we propose a Dynamic Mining Interval (DMI) mechanism that
adjusts mining intervals in response to block size and trading volume to
enhance the transaction throughput of Blockchain platforms. Besides, in the
context of public Blockchains such as Bitcoin, Ethereum, and Litecoin, a shift
towards transaction fees dominance over coin-based rewards is projected in near
future. As a result, the ecosystem continues to face threats from deviant
mining activities such as Undercutting Attacks, Selfish Mining, and Pool
Hopping, among others. In recent years, Dynamic Transaction Storage (DTS)
strategies were proposed to allocate transactions dynamically based on fees
thereby stabilizing block incentives. However, DTS' utilization of Merkle tree
leaf nodes can reduce system throughput. To alleviate this problem, in this
paper, we propose an approach for combining DMI and DTS. Besides, we also
discuss the DMI selection mechanism for adjusting mining intervals based on
various factors.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14040" title="Abstract">arXiv:2312.14040</a> [<a href="/pdf/2312.14040" title="Download PDF">pdf</a>, <a href="/format/2312.14040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Specialization and Adaptation in a Transforming Scientific  Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautheron%2C+L">Lucas Gautheron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph); Applications (stat.AP)

</div>
<p class="mathjax">How scientists navigate between the need to capitalize on their prior
knowledge by specializing, and the urge to adapt to evolving research
opportunities? Drawing from diverse perspectives on adaptation, in particular
from institutional change and cultural evolution, this paper proposes a
Bayesian model of the evolution of scientists' research portfolios in response
to transformations in their field. The model relies on scientific abstracts and
authorship data to evaluate the influence of intellectual, social, and
institutional resources on scientists' trajectories within a cohort of $2\,195$
high-energy physicists between 2000 and 2019. The reallocation of research
efforts in response to the incentives to adapt is shown to be mainly structured
by learning costs, thus maximizing the utility of the scientific capital
disseminated among scientists. Two dimensions of social capital, namely
``diversity'' and ``power'', have opposite effects on the magnitude of change
in scientists' research interests: while ``diversity'' disrupts and expands
research interests, ``power'' stabilizes physicists' research agendas -- as
does institutional stability. Social capital plays a more crucial role in
shifts between cognitively distant research areas.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14049" title="Abstract">arXiv:2312.14049</a> [<a href="/pdf/2312.14049" title="Download PDF">pdf</a>, <a href="/format/2312.14049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MHE under parametric uncertainty -- Robust state estimation without  informative data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muntwiler%2C+S">Simon Muntwiler</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we study state estimation for general nonlinear systems with
unknown parameters and persistent process and measurement noise. In particular,
we are interested in stability properties of the state estimate in the absence
of persistency of excitation (PE). With a simple academic example, we show that
existing moving horizon estimation (MHE) approaches as well as classical
adaptive observers can result in diverging state estimates in the absence of
PE, even if the noise is small. We propose a novel MHE formulation involving a
regularization based on a constant prior estimate of the unknown system
parameters. Only assuming the existence of a stable estimator, we prove that
the proposed MHE results in practically robustly stable state estimates even in
the absence of PE. We discuss the relation of the proposed MHE formulation to
state-of-the-art results from MHE, adaptive estimation, and functional
estimation. The properties of the proposed MHE approach are illustrated with a
numerical example of a car with unknown tire friction parameters.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14050" title="Abstract">arXiv:2312.14050</a> [<a href="/pdf/2312.14050" title="Download PDF">pdf</a>, <a href="/format/2312.14050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning and domain decomposition methods -- a survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klawonn%2C+A">Axel Klawonn</a>, 
<a href="/search/math?searchtype=author&query=Lanser%2C+M">Martin Lanser</a>, 
<a href="/search/math?searchtype=author&query=Weber%2C+J">Janine Weber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hybrid algorithms, which combine black-box machine learning methods with
experience from traditional numerical methods and domain expertise from diverse
application areas, are progressively gaining importance in scientific machine
learning and various industrial domains, especially in computational science
and engineering. In the present survey, several promising avenues of research
will be examined which focus on the combination of machine learning (ML) and
domain decomposition methods (DDMs). The aim of this survey is to provide an
overview of existing work within this field and to structure it into domain
decomposition for machine learning and machine learning-enhanced domain
decomposition, including: domain decomposition for classical machine learning,
domain decomposition to accelerate the training of physics-aware neural
networks, machine learning to enhance the convergence properties or
computational efficiency of DDMs, and machine learning as a discretization
method in a DDM for the solution of PDEs. In each of these fields, we summarize
existing work and key advances within a common framework and, finally, disuss
ongoing challenges and opportunities for future research.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14053" title="Abstract">arXiv:2312.14053</a> [<a href="/pdf/2312.14053" title="Download PDF">pdf</a>, <a href="/format/2312.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Attention U-Net with Feature Infusion: Pushing the Boundaries of  Multiclass Defect Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshawi%2C+R">Rasha Alshawi</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+M+T">Md Tamjidul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Ferdaus%2C+M+M">Md Meftahul Ferdaus</a>, 
<a href="/search/cs?searchtype=author&query=Abdelguerfi%2C+M">Mahdi Abdelguerfi</a>, 
<a href="/search/cs?searchtype=author&query=Niles%2C+K">Kendall Niles</a>, 
<a href="/search/cs?searchtype=author&query=Prathak%2C+K">Ken Prathak</a>, 
<a href="/search/cs?searchtype=author&query=Tom%2C+J">Joe Tom</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jordan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Mousa%2C+M">Murtada Mousa</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+J+J">Johny Javier Lopez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review in IEEE Transactions on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The proposed architecture, Dual Attentive U-Net with Feature Infusion (DAU-FI
Net), addresses challenges in semantic segmentation, particularly on multiclass
imbalanced datasets with limited samples. DAU-FI Net integrates multiscale
spatial-channel attention mechanisms and feature injection to enhance precision
in object localization. The core employs a multiscale depth-separable
convolution block, capturing localized patterns across scales. This block is
complemented by a spatial-channel squeeze and excitation (scSE) attention unit,
modeling inter-dependencies between channels and spatial regions in feature
maps. Additionally, additive attention gates refine segmentation by connecting
encoder-decoder pathways.
<br />To augment the model, engineered features using Gabor filters for textural
analysis, Sobel and Canny filters for edge detection are injected guided by
semantic masks to expand the feature space strategically. Comprehensive
experiments on a challenging sewer pipe and culvert defect dataset and a
benchmark dataset validate DAU-FI Net's capabilities. Ablation studies
highlight incremental benefits from attention blocks and feature injection.
DAU-FI Net achieves state-of-the-art mean Intersection over Union (IoU) of
95.6% and 98.8% on the defect test set and benchmark respectively, surpassing
prior methods by 8.9% and 12.6%, respectively. Ablation studies highlight
incremental benefits from attention blocks and feature injection. The proposed
architecture provides a robust solution, advancing semantic segmentation for
multiclass problems with limited training data. Our sewer-culvert defects
dataset, featuring pixel-level annotations, opens avenues for further research
in this crucial domain. Overall, this work delivers key innovations in
architecture, attention, and feature engineering to elevate semantic
segmentation efficacy.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14055" title="Abstract">arXiv:2312.14055</a> [<a href="/pdf/2312.14055" title="Download PDF">pdf</a>, <a href="/format/2312.14055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strong Baseline for Temporal Video-Text Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tengda Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we consider the problem of temporally aligning the video and
texts from instructional videos, specifically, given a long-term video, and
associated text sentences, our goal is to determine their corresponding
timestamps in the video. To this end, we establish a simple, yet strong model
that adopts a Transformer-based architecture with all texts as queries,
iteratively attending to the visual features, to infer the optimal timestamp.
We conduct thorough experiments to investigate: (i) the effect of upgrading ASR
systems to reduce errors from speech recognition, (ii) the effect of various
visual-textual backbones, ranging from CLIP to S3D, to the more recent
InternVideo, (iii) the effect of transforming noisy ASR transcripts into
descriptive steps by prompting a large language model (LLM), to summarize the
core activities within the ASR transcript as a new training dataset. As a
result, our proposed simple model demonstrates superior performance on both
narration alignment and procedural step grounding tasks, surpassing existing
state-of-the-art methods by a significant margin on three public benchmarks,
namely, 9.3% on HT-Step, 3.4% on HTM-Align and 4.7% on CrossTask. We believe
the proposed model and dataset with descriptive steps can be treated as a
strong baseline for future research in temporal video-text alignment. All
codes, models, and the resulting dataset will be publicly released to the
research community.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14057" title="Abstract">arXiv:2312.14057</a> [<a href="/pdf/2312.14057" title="Download PDF">pdf</a>, <a href="/format/2312.14057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted least-squares approximation with determinantal point processes  and generalized volume sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nouy%2C+A">Anthony Nouy</a>, 
<a href="/search/math?searchtype=author&query=Michel%2C+B">Bertrand Michel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We consider the problem of approximating a function from $L^2$ by an element
of a given $m$-dimensional space $V_m$, associated with some feature map
$\varphi$, using evaluations of the function at random points $x_1,\dots,x_n$.
After recalling some results on optimal weighted least-squares using
independent and identically distributed points, we consider weighted
least-squares using projection determinantal point processes (DPP) or volume
sampling. These distributions introduce dependence between the points that
promotes diversity in the selected features $\varphi(x_i)$. We first provide a
generalized version of volume-rescaled sampling yielding quasi-optimality
results in expectation with a number of samples $n = O(m\log(m))$, that means
that the expected $L^2$ error is bounded by a constant times the best
approximation error in $L^2$. Also, further assuming that the function is in
some normed vector space $H$ continuously embedded in $L^2$, we further prove
that the approximation is almost surely bounded by the best approximation error
measured in the $H$-norm. This includes the cases of functions from $L^\infty$
or reproducing kernel Hilbert spaces. Finally, we present an alternative
strategy consisting in using independent repetitions of projection DPP (or
volume sampling), yielding similar error bounds as with i.i.d. or volume
sampling, but in practice with a much lower number of samples. Numerical
experiments illustrate the performance of the different strategies.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14059" title="Abstract">arXiv:2312.14059</a> [<a href="/pdf/2312.14059" title="Download PDF">pdf</a>, <a href="/format/2312.14059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protection of Vulnerable Road Users using Hybrid Vehicular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Ronel%C3%B6v%2C+E">Erik Ronel&#xf6;v</a>, 
<a href="/search/cs?searchtype=author&query=Boustedt%2C+K">Katarina Boustedt</a>, 
<a href="/search/cs?searchtype=author&query=Blidkvist%2C+J">Jesper Blidkvist</a>, 
<a href="/search/cs?searchtype=author&query=Vinel%2C+A">Alexey Vinel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Vehicular Electronics and
  Safety (ICVES)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The use of reactive detection technologies such as passive and active sensors
for avoiding car accidents involving pedestrians and other Vulnerable Road
Users (VRU) is one of the cornerstones of Cooperative, Connected, and Automated
Mobility (CCAM). However, CCAM systems are not yet present in all roads at all
times. The use of currently available technologies that are embedded in
smartphones, such as location services and Internet access, are enablers for
the early detection of VRUs. This paper presents the proof-of-concept of a
system that provides vehicles with enough information about the presence of
VRUs by using public cellular networks, an MQTT broker, and IEEE
802.11p-enabled hardware (a roadside unit and an on-board unit). The system was
tested in an urban environment and in a test track, where its feasibility was
evaluated. Results were satisfactory, proving the system is reliable enough to
alert of the sudden appearance of a VRU in time for the driver to react.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14062" title="Abstract">arXiv:2312.14062</a> [<a href="/pdf/2312.14062" title="Download PDF">pdf</a>, <a href="/ps/2312.14062" title="Download PostScript">ps</a>, <a href="/format/2312.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimate and long-time energy conservation of a symmetric  low-regularity integrator for nonlinear Klein-Gordon equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/math?searchtype=author&query=Miao%2C+Z">Zhen Miao</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yaolin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we formulate and analyse a symmetric low-regularity integrator
for solving the nonlinear Klein-Gordon equation in the $d$-dimensional space
with $d=1,2,3$. The integrator is constructed based on the two-step
trigonometric method and the proposed integrator has a simple form. Error
estimates are rigorously presented to show that the integrator can achieve
second-order time accuracy in the energy space under the regularity requirement
in $H^{1+\frac{d}{4}}\times H^{\frac{d}{4}}$. Moreover, the time symmetry of
the scheme ensures the good long-time energy conservation which is rigorously
proved by the technique of modulated Fourier expansions. A numerical test is
presented and the numerical results demonstrate the superiorities of the new
integrator over some existing methods.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14063" title="Abstract">arXiv:2312.14063</a> [<a href="/pdf/2312.14063" title="Download PDF">pdf</a>, <a href="/format/2312.14063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Time Convergence of the Iterative Evaluation of Datalogo  Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sungjin Im</a>, 
<a href="/search/cs?searchtype=author&query=Moseley%2C+B">Benjamin Moseley</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H">Hung Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Pruhs%2C+K">Kirk Pruhs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Datalogo is an extension of Datalog that allows for aggregation and recursion
over an arbitrary commutative semiring. Like Datalog, Datalogo programs can be
evaluated via the natural iterative algorithm until a fixed point is reached.
However unlike Datalog, the natural iterative evaluation of some Datalogo
programs over some semirings may not converge. It is known that the commutative
semirings for which the iterative evaluation of Datalogo programs is guaranteed
to converge are exactly those semirings that are stable~\cite{Khamis0PSW22}.
Previously, the best known upper bound on the number of iterations until
convergence over $p$-stable semirings is $\sum_{i=1}^n (p+2)^i = \Theta(p^n)$
steps, where $n$ is (essentially) the output size. We establish that, in fact,
the natural iterative evaluation of a Datalogoprogram over a $p$-stable
semiring converges within a polynomial number of iterations. In particular our
upper bound is $O( \sigma p n^2( n^2 \lg \lambda + \lg \sigma))$ where $\sigma$
is the number of elements in the semiring present in either the input databases
or the Datalogo program, and $\lambda$ is the maximum number of terms in any
product in the Datalogo program.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14066" title="Abstract">arXiv:2312.14066</a> [<a href="/pdf/2312.14066" title="Download PDF">pdf</a>, <a href="/format/2312.14066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upper Bounding Barlow Twins: A Novel Filter for Multi-Relational  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xiaowei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-relational clustering is a challenging task due to the fact that
diverse semantic information conveyed in multi-layer graphs is difficult to
extract and fuse. Recent methods integrate topology structure and node
attribute information through graph filtering. However, they often use a
low-pass filter without fully considering the correlation among multiple
graphs. To overcome this drawback, we propose to learn a graph filter motivated
by the theoretical analysis of Barlow Twins. We find that input with a negative
semi-definite inner product provides a lower bound for Barlow Twins loss, which
prevents it from reaching a better solution. We thus learn a filter that yields
an upper bound for Barlow Twins. Afterward, we design a simple clustering
architecture and demonstrate its state-of-the-art performance on four benchmark
datasets.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14069" title="Abstract">arXiv:2312.14069</a> [<a href="/pdf/2312.14069" title="Download PDF">pdf</a>, <a href="/format/2312.14069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in  Speech-to-Speech Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Seyssel%2C+M">Maureen de Seyssel</a>, 
<a href="/search/cs?searchtype=author&query=D%27Avirro%2C+A">Antony D&#x27;Avirro</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Dupoux%2C+E">Emmanuel Dupoux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce EmphAssess, a prosodic benchmark designed to evaluate the
capability of speech-to-speech models to encode and reproduce prosodic
emphasis. We apply this to two tasks: speech resynthesis and speech-to-speech
translation. In both cases, the benchmark evaluates the ability of the model to
encode emphasis in the speech input and accurately reproduce it in the output,
potentially across a change of speaker and language. As part of the evaluation
pipeline, we introduce EmphaClass, a new model that classifies emphasis at the
frame or word level.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14072" title="Abstract">arXiv:2312.14072</a> [<a href="/pdf/2312.14072" title="Download PDF">pdf</a>, <a href="/format/2312.14072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Cooperative VRUs: Optimal Positioning Sampling for Pedestrian  Awareness Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-P%C3%A9rez%2C+J">Jorge Mart&#xed;n-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Rydeberg%2C+M">Markus Rydeberg</a>, 
<a href="/search/cs?searchtype=author&query=Olsson%2C+L">Linn&#xe9;a Olsson</a>, 
<a href="/search/cs?searchtype=author&query=Vinel%2C+A">Alexey Vinel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Road safety is the main motivation for Cooperative Intelligent Transport
Systems (C-ITS) in general, and vehicular communications (V2X) technology in
particular. The V2X-based Vulnerable Road User (VRU) protection is an approach
that relies on the persistent broadcasting of "beacon" awareness messages by a
VRU mobile device. To this end the European Telecommunications Standards
Institute (ETSI) has specified the Vulnerable Road User Awareness Message (VAM)
as well as the overall ITS-G5 protocol stack enabling a variety of the V2X
applications. This article studies how often pedestrians (a type of VRU) should
check their position to issue a VAM. To that end, we characterize the rate at
which pedestrians generate VAMs leveraging a recognized mobility model, and
formulate an optimization problem to minimize the time elapsed between VAMs. We
propose an algorithm to solve the problem in 802.11p and assess its accuracy
through numerical and simulation campaigns. Results evidence the accuracy of
our VAM rate characterization, and evidence that we decrease ETSI positioning
sampling rate by more than 30%. On top, our solution decreases the time between
VAMs, and increases the packet delivery ratio. In other words, our approach
increases the pedestrians safety while reducing the battery consumption of
mobile devices.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14074" title="Abstract">arXiv:2312.14074</a> [<a href="/pdf/2312.14074" title="Download PDF">pdf</a>, <a href="/format/2312.14074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Senqiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Mingjie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zoey Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yandong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, Large Language Models (LLMs) and Multimodal Large Language Models
(MLLMs) have shown promise in instruction following and 2D image understanding.
While these models are powerful, they have not yet been developed to comprehend
the more challenging 3D physical scenes, especially when it comes to the sparse
outdoor LiDAR data. In this paper, we introduce LiDAR-LLM, which takes raw
LiDAR data as input and harnesses the remarkable reasoning capabilities of LLMs
to gain a comprehensive understanding of outdoor 3D scenes. The central insight
of our LiDAR-LLM is the reformulation of 3D outdoor scene cognition as a
language modeling problem, encompassing tasks such as 3D captioning, 3D
grounding, 3D question answering, etc. Specifically, due to the scarcity of 3D
LiDAR-text pairing data, we introduce a three-stage training strategy and
generate relevant datasets, progressively aligning the 3D modality with the
language embedding space of LLM. Furthermore, we design a View-Aware
Transformer (VAT) to connect the 3D encoder with the LLM, which effectively
bridges the modality gap and enhances the LLM's spatial orientation
comprehension of visual features. Our experiments show that LiDAR-LLM possesses
favorable capabilities to comprehend various instructions regarding 3D scenes
and engage in complex spatial reasoning. LiDAR-LLM attains a 40.9 BLEU-1 on the
3D captioning task and achieves a 63.1\% classification accuracy and a 14.3\%
BEV mIoU on the 3D grounding task. Web page:
https://sites.google.com/view/lidar-llm
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14075" title="Abstract">arXiv:2312.14075</a> [<a href="/pdf/2312.14075" title="Download PDF">pdf</a>, <a href="/ps/2312.14075" title="Download PostScript">ps</a>, <a href="/format/2312.14075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Quantum Complexity Helps Classical Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaezi%2C+A">Arash Vaezi</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+S+M+H">Seyed Mohammad Hussein Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Noghrehy%2C+N+B">Negin Bagheri Noghrehy</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+S+M">Seyed Mohsen Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+M">Mohammad Ghodsi</a>, 
<a href="/search/cs?searchtype=author&query=Movaghar%2C+A">Ali Movaghar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Scientists have demonstrated that quantum computing has presented novel
approaches to address computational challenges, each varying in complexity.
Adapting problem-solving strategies is crucial to harness the full potential of
quantum computing. Nonetheless, there are defined boundaries to the
capabilities of quantum computing. This paper concentrates on aggregating prior
research efforts dedicated to solving intricate classical computational
problems through quantum computing. The objective is to systematically compile
an exhaustive inventory of these solutions and categorize a collection of
demanding problems that await further exploration.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14090" title="Abstract">arXiv:2312.14090</a> [<a href="/pdf/2312.14090" title="Download PDF">pdf</a>, <a href="/format/2312.14090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Artificial Intelligence Equipped Social Decentralized  Autonomous Organizations for Tackling Sextortion Cases Version 0.7
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alex%2C+N">Norta Alex</a>, 
<a href="/search/cs?searchtype=author&query=Sotiris%2C+M">Makrygiannis Sotiris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">With the rapid diffusion of social networks in combination with mobile
phones, a new social threat of sextortion has emerged, in which vulnerable
young women are essentially blackmailed with their explicit shared multimedia
content. The phenomenon of sextortion is now widely studied by psychologists,
sociologists, criminologists, etc. The findings have been translated into
scattered help from NGOs, specialized law enforcement units, and therapists,
who usually do not coordinate their efforts among each other. This paper
addresses the gap of lacking coordination systems to effectively and
efficiently use modern information technologies that align the efforts of
scattered and non-aligned sextortion help organizations. Consequently, this
paper not only investigates the goals, incentives, and disincentives for a
system design and development that not only governs effectively and efficiently
diverse cases of sextortion victims, but also leverages artificial intelligence
in a targeted manner. It explores how AI and, in particular, autonomous
cognitive entities can improve victim profiles analysis, streamline support
mechanisms, and provide intelligent insight into sextortion cases. Furthermore,
the paper conceptually studies the extent to which such efforts can be
monetized in a sustainable way. Following a novel design methodology for the
design of trusted blockchain decentralized applications, the paper presents a
set of conceptual requirements and system models based on which it is possible
to deduce a best-practice technology stack for rapid implementation deployment.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14091" title="Abstract">arXiv:2312.14091</a> [<a href="/pdf/2312.14091" title="Download PDF">pdf</a>, <a href="/format/2312.14091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HD-Painter: High-Resolution and Prompt-Faithful Text-Guided Image  Inpainting with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manukyan%2C+H">Hayk Manukyan</a>, 
<a href="/search/cs?searchtype=author&query=Sargsyan%2C+A">Andranik Sargsyan</a>, 
<a href="/search/cs?searchtype=author&query=Atanyan%2C+B">Barsegh Atanyan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Navasardyan%2C+S">Shant Navasardyan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent progress in text-guided image inpainting, based on the unprecedented
success of text-to-image diffusion models, has led to exceptionally realistic
and visually plausible results. However, there is still significant potential
for improvement in current text-to-image inpainting models, particularly in
better aligning the inpainted area with user prompts and performing
high-resolution inpainting. Therefore, in this paper we introduce HD-Painter, a
completely training-free approach that accurately follows to prompts and
coherently scales to high-resolution image inpainting. To this end, we design
the Prompt-Aware Introverted Attention (PAIntA) layer enhancing self-attention
scores by prompt information and resulting in better text alignment
generations. To further improve the prompt coherence we introduce the
Reweighting Attention Score Guidance (RASG) mechanism seamlessly integrating a
post-hoc sampling strategy into general form of DDIM to prevent
out-of-distribution latent shifts. Moreover, HD-Painter allows extension to
larger scales by introducing a specialized super-resolution technique
customized for inpainting, enabling the completion of missing regions in images
of up to 2K resolution. Our experiments demonstrate that HD-Painter surpasses
existing state-of-the-art approaches qualitatively and quantitatively,
achieving an impressive generation accuracy improvement of 61.4% vs 51.9%. We
will make the codes publicly available at:
https://github.com/Picsart-AI-Research/HD-Painter
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14102" title="Abstract">arXiv:2312.14102</a> [<a href="/pdf/2312.14102" title="Download PDF">pdf</a>, <a href="/format/2312.14102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Higher-Order Multiscale Method for the Wave Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krumbiegel%2C+F">Felix Krumbiegel</a>, 
<a href="/search/math?searchtype=author&query=Maier%2C+R">Roland Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we propose a multiscale method for the acoustic wave equation
in highly oscillatory media. We use a higher-order extension of the localized
orthogonal decomposition method combined with a higher-order time stepping
scheme and present rigorous a-priori error estimates in the energy-induced
norm. We find that in the very general setting without additional assumptions
on the coefficient beyond boundedness, arbitrary orders of convergence cannot
be expected but that increasing the polynomial degree may still considerably
reduce the size of the error. Under additional regularity assumptions, higher
orders can be obtained as well. Numerical examples are presented that confirm
the theoretical results.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14106" title="Abstract">arXiv:2312.14106</a> [<a href="/pdf/2312.14106" title="Download PDF">pdf</a>, <a href="/format/2312.14106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Human-like Representations to Enable Learning Human Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wynn%2C+A">Andrea Wynn</a>, 
<a href="/search/cs?searchtype=author&query=Sucholutsky%2C+I">Ilia Sucholutsky</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024 (<a href="https://hcrl-workshop.github.io/2024/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">How can we build AI systems that are aligned with human values and objectives
in order to avoid causing harm or violating societal standards for acceptable
behavior? Making AI systems learn human-like representations of the world has
many known benefits, including improving generalization, robustness to domain
shifts, and few-shot learning performance, among others. We propose that this
kind of representational alignment between machine learning (ML) models and
humans is also a necessary condition for value alignment, where ML systems
conform to human values and societal norms. We focus on ethics as one aspect of
value alignment and train multiple ML agents (support vector regression and
kernel regression) in a multi-armed bandit setting, where rewards are sampled
from a distribution that reflects the morality of the chosen action. We then
study the relationship between each agent's degree of representational
alignment with humans and their performance when learning to take the most
ethical actions.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14115" title="Abstract">arXiv:2312.14115</a> [<a href="/pdf/2312.14115" title="Download PDF">pdf</a>, <a href="/format/2312.14115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LingoQA: Video Question Answering for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcu%2C+A">Ana-Maria Marcu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCnermann%2C+J">Jan H&#xfc;nermann</a>, 
<a href="/search/cs?searchtype=author&query=Karnsund%2C+A">Alice Karnsund</a>, 
<a href="/search/cs?searchtype=author&query=Hanotte%2C+B">Benoit Hanotte</a>, 
<a href="/search/cs?searchtype=author&query=Chidananda%2C+P">Prajwal Chidananda</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+S">Saurabh Nair</a>, 
<a href="/search/cs?searchtype=author&query=Badrinarayanan%2C+V">Vijay Badrinarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Kendall%2C+A">Alex Kendall</a>, 
<a href="/search/cs?searchtype=author&query=Shotton%2C+J">Jamie Shotton</a>, 
<a href="/search/cs?searchtype=author&query=Sinavski%2C+O">Oleg Sinavski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Benchmark and dataset are available at <a href="https://github.com/wayveai/LingoQA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Autonomous driving has long faced a challenge with public acceptance due to
the lack of explainability in the decision-making process. Video
question-answering (QA) in natural language provides the opportunity for
bridging this gap. Nonetheless, evaluating the performance of Video QA models
has proved particularly tough due to the absence of comprehensive benchmarks.
To fill this gap, we introduce LingoQA, a benchmark specifically for autonomous
driving Video QA. The LingoQA trainable metric demonstrates a 0.95 Spearman
correlation coefficient with human evaluations. We introduce a Video QA dataset
of central London consisting of 419k samples that we release with the paper. We
establish a baseline vision-language model and run extensive ablation studies
to understand its performance.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14121" title="Abstract">arXiv:2312.14121</a> [<a href="/pdf/2312.14121" title="Download PDF">pdf</a>, <a href="/ps/2312.14121" title="Download PostScript">ps</a>, <a href="/format/2312.14121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Knowledge-Free Deep Learning for General Game Playing (Student  Abstract)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maras%2C+M">Micha&#x142; Maras</a>, 
<a href="/search/cs?searchtype=author&query=K%C4%99pa%2C+M">Micha&#x142; K&#x119;pa</a>, 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+J">Jakub Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Szyku%C5%82a%2C+M">Marek Szyku&#x142;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24 Student Abstracts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We develop a method of adapting the AlphaZero model to General Game Playing
(GGP) that focuses on faster model generation and requires less knowledge to be
extracted from the game rules. The dataset generation uses MCTS playing instead
of self-play; only the value network is used, and attention layers replace the
convolutional ones. This allows us to abandon any assumptions about the action
space and board topology. We implement the method within the Regular Boardgames
GGP system and show that we can build models outperforming the UCT baseline for
most games efficiently.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14124" title="Abstract">arXiv:2312.14124</a> [<a href="/pdf/2312.14124" title="Download PDF">pdf</a>, <a href="/format/2312.14124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Point Cloud Diffusion for Disentangled 3D Shape and Appearance  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6ppel%2C+P">Philipp Schr&#xf6;ppel</a>, 
<a href="/search/cs?searchtype=author&query=Wewer%2C+C">Christopher Wewer</a>, 
<a href="/search/cs?searchtype=author&query=Lenssen%2C+J+E">Jan Eric Lenssen</a>, 
<a href="/search/cs?searchtype=author&query=Ilg%2C+E">Eddy Ilg</a>, 
<a href="/search/cs?searchtype=author&query=Brox%2C+T">Thomas Brox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Controllable generation of 3D assets is important for many practical
applications like content creation in movies, games and engineering, as well as
in AR/VR. Recently, diffusion models have shown remarkable results in
generation quality of 3D objects. However, none of the existing models enable
disentangled generation to control the shape and appearance separately. For the
first time, we present a suitable representation for 3D diffusion models to
enable such disentanglement by introducing a hybrid point cloud and neural
radiance field approach. We model a diffusion process over point positions
jointly with a high-dimensional feature space for a local density and radiance
decoder. While the point positions represent the coarse shape of the object,
the point features allow modeling the geometry and appearance details. This
disentanglement enables us to sample both independently and therefore to
control both separately. Our approach sets a new state of the art in generation
compared to previous disentanglement-capable methods by reduced FID scores of
30-90% and is on-par with other non disentanglement-capable state-of-the art
methods.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14125" title="Abstract">arXiv:2312.14125</a> [<a href="/pdf/2312.14125" title="Download PDF">pdf</a>, <a href="/format/2312.14125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoPoet: A Large Language Model for Zero-Shot Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kondratyuk%2C+D">Dan Kondratyuk</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lijun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiuye Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lezama%2C+J">Jos&#xe9; Lezama</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jonathan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hornung%2C+R">Rachel Hornung</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+H">Hartwig Adam</a>, 
<a href="/search/cs?searchtype=author&query=Akbari%2C+H">Hassan Akbari</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+Y">Yair Alon</a>, 
<a href="/search/cs?searchtype=author&query=Birodkar%2C+V">Vighnesh Birodkar</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+M">Ming-Chang Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Dillon%2C+J">Josh Dillon</a>, 
<a href="/search/cs?searchtype=author&query=Essa%2C+I">Irfan Essa</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Agrim Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+M">Meera Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Hauth%2C+A">Anja Hauth</a>, 
<a href="/search/cs?searchtype=author&query=Hendon%2C+D">David Hendon</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+A">Alonso Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Minnen%2C+D">David Minnen</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+D">David Ross</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+G">Grant Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Sirotenko%2C+M">Mikhail Sirotenko</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+K">Kihyuk Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Somandepalli%2C+K">Krishna Somandepalli</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jimmy Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Seybold%2C+B">Bryan Seybold</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="http://sites.research.google/videopoet/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present VideoPoet, a language model capable of synthesizing high-quality
video, with matching audio, from a large variety of conditioning signals.
VideoPoet employs a decoder-only transformer architecture that processes
multimodal inputs -- including images, videos, text, and audio. The training
protocol follows that of Large Language Models (LLMs), consisting of two
stages: pretraining and task-specific adaptation. During pretraining, VideoPoet
incorporates a mixture of multimodal generative objectives within an
autoregressive Transformer framework. The pretrained LLM serves as a foundation
that can be adapted for a range of video generation tasks. We present empirical
results demonstrating the model's state-of-the-art capabilities in zero-shot
video generation, specifically highlighting VideoPoet's ability to generate
high-fidelity motions. Project page: <a href="http://sites.research.google/videopoet/">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14126" title="Abstract">arXiv:2312.14126</a> [<a href="/pdf/2312.14126" title="Download PDF">pdf</a>, <a href="/format/2312.14126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropic Open-set Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safaei%2C+B">Bardia Safaei</a>, 
<a href="/search/cs?searchtype=author&query=VS%2C+V">Vibashan VS</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+C+M">Celso M. de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+V+M">Vishal M. Patel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Active Learning (AL) aims to enhance the performance of deep models by
selecting the most informative samples for annotation from a pool of unlabeled
data. Despite impressive performance in closed-set settings, most AL methods
fail in real-world scenarios where the unlabeled data contains unknown
categories. Recently, a few studies have attempted to tackle the AL problem for
the open-set setting. However, these methods focus more on selecting known
samples and do not efficiently utilize unknown samples obtained during AL
rounds. In this work, we propose an Entropic Open-set AL (EOAL) framework which
leverages both known and unknown distributions effectively to select
informative samples during AL rounds. Specifically, our approach employs two
different entropy scores. One measures the uncertainty of a sample with respect
to the known-class distributions. The other measures the uncertainty of the
sample with respect to the unknown-class distributions. By utilizing these two
entropy scores we effectively separate the known and unknown samples from the
unlabeled data resulting in better sampling. Through extensive experiments, we
show that the proposed method outperforms existing state-of-the-art methods on
CIFAR-10, CIFAR-100, and TinyImageNet datasets. Code is available at
\url{https://github.com/bardisafa/EOAL}.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14129" title="Abstract">arXiv:2312.14129</a> [<a href="/pdf/2312.14129" title="Download PDF">pdf</a>, <a href="/format/2312.14129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WellFactor: Patient Profiling using Integrative Embedding of Healthcare  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dongjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+A">Andy Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ozturk%2C+O">Ozgur Ozturk</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+D">Deep Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Drake%2C+B">Barry Drake</a>, 
<a href="/search/cs?searchtype=author&query=Haidarian%2C+H">Hamid Haidarian</a>, 
<a href="/search/cs?searchtype=author&query=Javed%2C+F">Faizan Javed</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Haesun Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Big Data (IEEE BigData 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the rapidly evolving healthcare industry, platforms now have access to not
only traditional medical records, but also diverse data sets encompassing
various patient interactions, such as those from healthcare web portals. To
address this rich diversity of data, we introduce WellFactor: a method that
derives patient profiles by integrating information from these sources. Central
to our approach is the utilization of constrained low-rank approximation.
WellFactor is optimized to handle the sparsity that is often inherent in
healthcare data. Moreover, by incorporating task-specific label information,
our method refines the embedding results, offering a more informed perspective
on patients. One important feature of WellFactor is its ability to compute
embeddings for new, previously unobserved patient data instantaneously,
eliminating the need to revisit the entire data set or recomputing the
embedding. Comprehensive evaluations on real-world healthcare data demonstrate
WellFactor's effectiveness. It produces better results compared to other
existing methods in classification performance, yields meaningful clustering of
patients, and delivers consistent results in patient similarity searches and
predictions.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14132" title="Abstract">arXiv:2312.14132</a> [<a href="/pdf/2312.14132" title="Download PDF">pdf</a>, <a href="/format/2312.14132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUSt3R: Geometric 3D Vision Made Easy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuzhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Leroy%2C+V">Vincent Leroy</a>, 
<a href="/search/cs?searchtype=author&query=Cabon%2C+Y">Yohann Cabon</a>, 
<a href="/search/cs?searchtype=author&query=Chidlovskii%2C+B">Boris Chidlovskii</a>, 
<a href="/search/cs?searchtype=author&query=Revaud%2C+J">Jerome Revaud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-view stereo reconstruction (MVS) in the wild requires to first estimate
the camera parameters e.g. intrinsic and extrinsic parameters. These are
usually tedious and cumbersome to obtain, yet they are mandatory to triangulate
corresponding pixels in 3D space, which is the core of all best performing MVS
algorithms. In this work, we take an opposite stance and introduce DUSt3R, a
radically novel paradigm for Dense and Unconstrained Stereo 3D Reconstruction
of arbitrary image collections, i.e. operating without prior information about
camera calibration nor viewpoint poses. We cast the pairwise reconstruction
problem as a regression of pointmaps, relaxing the hard constraints of usual
projective camera models. We show that this formulation smoothly unifies the
monocular and binocular reconstruction cases. In the case where more than two
images are provided, we further propose a simple yet effective global alignment
strategy that expresses all pairwise pointmaps in a common reference frame. We
base our network architecture on standard Transformer encoders and decoders,
allowing us to leverage powerful pretrained models. Our formulation directly
provides a 3D model of the scene as well as depth information, but
interestingly, we can seamlessly recover from it, pixel matches, relative and
absolute camera. Exhaustive experiments on all these tasks showcase that the
proposed DUSt3R can unify various 3D vision tasks and set new SoTAs on
monocular/multi-view depth estimation as well as relative pose estimation. In
summary, DUSt3R makes many geometric 3D vision tasks easy.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14134" title="Abstract">arXiv:2312.14134</a> [<a href="/pdf/2312.14134" title="Download PDF">pdf</a>, <a href="/format/2312.14134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Reward: Learning Rewards via Conditional Video Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page and code: <a href="https://diffusion-reward.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Learning rewards from expert videos offers an affordable and effective
solution to specify the intended behaviors for reinforcement learning tasks. In
this work, we propose Diffusion Reward, a novel framework that learns rewards
from expert videos via conditional video diffusion models for solving complex
visual RL problems. Our key insight is that lower generative diversity is
observed when conditioned on expert trajectories. Diffusion Reward is
accordingly formalized by the negative of conditional entropy that encourages
productive exploration of expert-like behaviors. We show the efficacy of our
method over 10 robotic manipulation tasks from MetaWorld and Adroit with visual
input and sparse reward. Moreover, Diffusion Reward could even solve unseen
tasks successfully and effectively, largely surpassing baseline methods.
Project page and code: https://diffusion-reward.github.io/.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14135" title="Abstract">arXiv:2312.14135</a> [<a href="/pdf/2312.14135" title="Download PDF">pdf</a>, <a href="/format/2312.14135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\textit{V}^*$: Guided Visual Search as a Core Mechanism in Multimodal  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Penghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Saining Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vstar-seal.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When we look around and perform complex tasks, how we see and selectively
process what we see is crucial. However, the lack of this visual search
mechanism in current multimodal LLMs (MLLMs) hinders their ability to focus on
important visual details, especially when handling high-resolution and visually
crowded images. To address this, we introduce $\textit{V}^*$, an LLM-guided
visual search mechanism that employs the world knowledge in LLMs for efficient
visual querying. When combined with an MLLM, this mechanism enhances
collaborative reasoning, contextual understanding, and precise targeting of
specific visual elements. This integration results in a new MLLM
meta-architecture, named $\textbf{S}$how, s$\textbf{EA}$rch, and
Tel$\textbf{L}$ (SEAL). We further create $\textit{V}^*$Bench, a benchmark
specifically designed to evaluate MLLMs in their ability to process
high-resolution images and focus on visual details. Our study highlights the
necessity of incorporating visual search capabilities into multimodal systems.
The code is available https://github.com/penghao-wu/vstar.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14138" title="Abstract">arXiv:2312.14138</a> [<a href="/pdf/2312.14138" title="Download PDF">pdf</a>, <a href="/format/2312.14138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Foreground and Background Separation in Weakly-supervised  Temporal Action Localization: A Clustering-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+S">Shenghai Rong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weakly-supervised temporal action localization aims to localize action
instances in videos with only video-level action labels. Existing methods
mainly embrace a localization-by-classification pipeline that optimizes the
snippet-level prediction with a video classification loss. However, this
formulation suffers from the discrepancy between classification and detection,
resulting in inaccurate separation of foreground and background (F\&amp;B)
snippets. To alleviate this problem, we propose to explore the underlying
structure among the snippets by resorting to unsupervised snippet clustering,
rather than heavily relying on the video classification loss. Specifically, we
propose a novel clustering-based F\&amp;B separation algorithm. It comprises two
core components: a snippet clustering component that groups the snippets into
multiple latent clusters and a cluster classification component that further
classifies the cluster as foreground or background. As there are no
ground-truth labels to train these two components, we introduce a unified
self-labeling mechanism based on optimal transport to produce high-quality
pseudo-labels that match several plausible prior distributions. This ensures
that the cluster assignments of the snippets can be accurately associated with
their F\&amp;B labels, thereby boosting the F\&amp;B separation. We evaluate our method
on three benchmarks: THUMOS14, ActivityNet v1.2 and v1.3. Our method achieves
promising performance on all three benchmarks while being significantly more
lightweight than previous methods. Code is available at
https://github.com/Qinying-Liu/CASE
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14140" title="Abstract">arXiv:2312.14140</a> [<a href="/pdf/2312.14140" title="Download PDF">pdf</a>, <a href="/format/2312.14140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeadCraft: Modeling High-Detail Shape Variations for Animated 3DMMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sevastopolsky%2C+A">Artem Sevastopolsky</a>, 
<a href="/search/cs?searchtype=author&query=Grassal%2C+P">Philip-William Grassal</a>, 
<a href="/search/cs?searchtype=author&query=Giebenhain%2C+S">Simon Giebenhain</a>, 
<a href="/search/cs?searchtype=author&query=Athar%2C+S">ShahRukh Athar</a>, 
<a href="/search/cs?searchtype=author&query=Verdoliva%2C+L">Luisa Verdoliva</a>, 
<a href="/search/cs?searchtype=author&query=Niessner%2C+M">Matthias Niessner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://seva100.github.io/headcraft.">this https URL</a> Video: <a href="https://youtu.be/uBeBT2f1CL0.">this https URL</a> 23 pages, 19 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current advances in human head modeling allow to generate plausible-looking
3D head models via neural representations. Nevertheless, constructing complete
high-fidelity head models with explicitly controlled animation remains an
issue. Furthermore, completing the head geometry based on a partial
observation, e.g. coming from a depth sensor, while preserving details is often
problematic for the existing methods. We introduce a generative model for
detailed 3D head meshes on top of an articulated 3DMM which allows explicit
animation and high-detail preservation at the same time. Our method is trained
in two stages. First, we register a parametric head model with vertex
displacements to each mesh of the recently introduced NPHM dataset of accurate
3D head scans. The estimated displacements are baked into a hand-crafted UV
layout. Second, we train a StyleGAN model in order to generalize over the UV
maps of displacements. The decomposition of the parametric model and
high-quality vertex displacements allows us to animate the model and modify it
semantically. We demonstrate the results of unconditional generation and
fitting to the full or partial observation. The project page is available at
https://seva100.github.io/headcraft.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14149" title="Abstract">arXiv:2312.14149</a> [<a href="/pdf/2312.14149" title="Download PDF">pdf</a>, <a href="/format/2312.14149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TagAlign: Improving Vision-Language Alignment with Multi-Tag  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Z">Zhan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The crux of learning vision-language models is to extract semantically
aligned information from visual and linguistic data. Existing attempts usually
face the problem of coarse alignment, \textit{e.g.}, the vision encoder
struggles in localizing an attribute-specified object. In this work, we propose
an embarrassingly simple approach to better align image and text features with
no need of additional data formats other than image-text pairs. Concretely,
given an image and its paired text, we manage to parse objects (\textit{e.g.},
cat) and attributes (\textit{e.g.}, black) from the description, which are
highly likely to exist in the image. It is noteworthy that the parsing pipeline
is fully automatic and thus enjoys good scalability. With these parsed
semantics as supervision signals, we can complement the commonly used
image-text contrastive loss with the multi-tag classification loss. Extensive
experimental results on a broad suite of semantic segmentation datasets
substantiate the average 3.65\% improvement of our framework over existing
alternatives. Furthermore, the visualization results indicate that attribute
supervision makes vision-language models accurately localize
attribute-specified objects. Project page can be found at
https://qinying-liu.github.io/Tag-Align/
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14150" title="Abstract">arXiv:2312.14150</a> [<a href="/pdf/2312.14150" title="Download PDF">pdf</a>, <a href="/format/2312.14150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DriveLM: Driving with Graph Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sima%2C+C">Chonghao Sima</a>, 
<a href="/search/cs?searchtype=author&query=Renz%2C+K">Katrin Renz</a>, 
<a href="/search/cs?searchtype=author&query=Chitta%2C+K">Kashyap Chitta</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chengen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study how vision-language models (VLMs) trained on web-scale data can be
integrated into end-to-end driving systems to boost generalization and enable
interactivity with human users. While recent approaches adapt VLMs to driving
via single-round visual question answering (VQA), human drivers reason about
decisions in multiple steps. Starting from the localization of key objects,
humans estimate object interactions before taking actions. The key insight is
that with our proposed task, Graph VQA, where we model graph-structured
reasoning through perception, prediction and planning question-answer pairs, we
obtain a suitable proxy task to mimic the human reasoning process. We
instantiate datasets (DriveLM-Data) built upon nuScenes and CARLA, and propose
a VLM-based baseline approach (DriveLM-Agent) for jointly performing Graph VQA
and end-to-end driving. The experiments demonstrate that Graph VQA provides a
simple, principled framework for reasoning about a driving scene, and
DriveLM-Data provides a challenging benchmark for this task. Our DriveLM-Agent
baseline performs end-to-end autonomous driving competitively in comparison to
state-of-the-art driving-specific architectures. Notably, its benefits are
pronounced when it is evaluated zero-shot on unseen objects or sensor
configurations. We hope this work can be the starting point to shed new light
on how to apply VLMs for autonomous driving. To facilitate future research, all
code, data, and models are available to the public.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14154" title="Abstract">arXiv:2312.14154</a> [<a href="/pdf/2312.14154" title="Download PDF">pdf</a>, <a href="/format/2312.14154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Pets: Animatable Animal Generation in 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yen-Chi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C+H">Chieh Hubert Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kant%2C+Y">Yash Kant</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Schwing%2C+A">Alexander Schwing</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+L">Liangyan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Project page: <a href="https://yccyenchicheng.github.io/VirtualPets/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Toward unlocking the potential of generative models in immersive 4D
experiences, we introduce Virtual Pet, a novel pipeline to model realistic and
diverse motions for target animal species within a 3D environment. To
circumvent the limited availability of 3D motion data aligned with
environmental geometry, we leverage monocular internet videos and extract
deformable NeRF representations for the foreground and static NeRF
representations for the background. For this, we develop a reconstruction
strategy, encompassing species-level shared template learning and per-video
fine-tuning. Utilizing the reconstructed data, we then train a conditional 3D
motion model to learn the trajectory and articulation of foreground animals in
the context of 3D backgrounds. We showcase the efficacy of our pipeline with
comprehensive qualitative and quantitative evaluations using cat videos. We
also demonstrate versatility across unseen cats and indoor environments,
producing temporally coherent 4D outputs for enriched virtual experiences.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14157" title="Abstract">arXiv:2312.14157</a> [<a href="/pdf/2312.14157" title="Download PDF">pdf</a>, <a href="/format/2312.14157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Pose Estimation of Two Interacting Hands from a Monocular Event  Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Millerdurai%2C+C">Christen Millerdurai</a>, 
<a href="/search/cs?searchtype=author&query=Luvizon%2C+D">Diogo Luvizon</a>, 
<a href="/search/cs?searchtype=author&query=Rudnev%2C+V">Viktor Rudnev</a>, 
<a href="/search/cs?searchtype=author&query=Jonas%2C+A">Andr&#xe9; Jonas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures, 7 tables; project page: <a href="https://4dqv.mpi-inf.mpg.de/Ev2Hands/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on 3D Vision (3DV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D hand tracking from a monocular video is a very challenging problem due to
hand interactions, occlusions, left-right hand ambiguity, and fast motion. Most
existing methods rely on RGB inputs, which have severe limitations under
low-light conditions and suffer from motion blur. In contrast, event cameras
capture local brightness changes instead of full image frames and do not suffer
from the described effects. Unfortunately, existing image-based techniques
cannot be directly applied to events due to significant differences in the data
modalities. In response to these challenges, this paper introduces the first
framework for 3D tracking of two fast-moving and interacting hands from a
single monocular event camera. Our approach tackles the left-right hand
ambiguity with a novel semi-supervised feature-wise attention mechanism and
integrates an intersection loss to fix hand collisions. To facilitate advances
in this research domain, we release a new synthetic large-scale dataset of two
interacting hands, Ev2Hands-S, and a new real benchmark with real event streams
and ground-truth 3D annotations, Ev2Hands-R. Our approach outperforms existing
methods in terms of the 3D reconstruction accuracy and generalises to real data
under severe light conditions.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 22 Dec 23</h3>
<dl>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11010" title="Abstract">arXiv:2310.11010</a> (cross-list from eess.AS) [<a href="/pdf/2310.11010" title="Download PDF">pdf</a>, <a href="/ps/2310.11010" title="Download PostScript">ps</a>, <a href="/format/2310.11010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Shallow Fusion of Backward Language Model for End-to-End  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ogawa%2C+A">Atsunori Ogawa</a>, 
<a href="/search/eess?searchtype=author&query=Moriya%2C+T">Takafumi Moriya</a>, 
<a href="/search/eess?searchtype=author&query=Kamo%2C+N">Naoyuki Kamo</a>, 
<a href="/search/eess?searchtype=author&query=Tawara%2C+N">Naohiro Tawara</a>, 
<a href="/search/eess?searchtype=author&query=Delcroix%2C+M">Marc Delcroix</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose a new shallow fusion (SF) method to exploit an external backward
language model (BLM) for end-to-end automatic speech recognition (ASR). The BLM
has complementary characteristics with a forward language model (FLM), and the
effectiveness of their combination has been confirmed by rescoring ASR
hypotheses as post-processing. In the proposed SF, we iteratively apply the BLM
to partial ASR hypotheses in the backward direction (i.e., from the possible
next token to the start symbol) during decoding, substituting the newly
calculated BLM scores for the scores calculated at the last iteration. To
enhance the effectiveness of this iterative SF (ISF), we train a partial
sentence-aware BLM (PBLM) using reversed text data including partial sentences,
considering the framework of ISF. In experiments using an attention-based
encoder-decoder ASR system, we confirmed that ISF using the PBLM shows
comparable performance with SF using the FLM. By performing ISF, early pruning
of prospective hypotheses can be prevented during decoding, and we can obtain a
performance improvement compared to applying the PBLM as post-processing.
Finally, we confirmed that, by combining SF and ISF, further performance
improvement can be obtained thanks to the complementarity of the FLM and PBLM.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13289" title="Abstract">arXiv:2312.13289</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.13289" title="Download PDF">pdf</a>, <a href="/format/2312.13289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stoichiometry Representation Learning with Polymorphic Crystal  Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+N">Namkyeong Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Noh%2C+H">Heewoong Noh</a>, 
<a href="/search/cond-mat?searchtype=author&query=Na%2C+G+S">Gyoung S. Na</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fu%2C+T">Tianfan Fu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 AI4Science Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the recent success of machine learning (ML) in materials science, its
success heavily relies on the structural description of crystal, which is
itself computationally demanding and occasionally unattainable. Stoichiometry
descriptors can be an alternative approach, which reveals the ratio between
elements involved to form a certain compound without any structural
information. However, it is not trivial to learn the representations of
stoichiometry due to the nature of materials science called polymorphism, i.e.,
a single stoichiometry can exist in multiple structural forms due to the
flexibility of atomic arrangements, inducing uncertainties in representation.
To this end, we propose PolySRL, which learns the probabilistic representation
of stoichiometry by utilizing the readily available structural information,
whose uncertainty reveals the polymorphic structures of stoichiometry.
Extensive experiments on sixteen datasets demonstrate the superiority of
PolySRL, and analysis of uncertainties shed light on the applicability of
PolySRL in real-world material discovery. The source code for PolySRL is
available at https://github.com/Namkyeong/PolySRL_AI4Science.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13302" title="Abstract">arXiv:2312.13302</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.13302" title="Download PDF">pdf</a>, <a href="/format/2312.13302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Longitudinal prediction of DNA methylation to forecast epigenetic  outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Leroy%2C+A">Arthur Leroy</a>, 
<a href="/search/q-bio?searchtype=author&query=Teh%2C+A+L">Ai Ling Teh</a>, 
<a href="/search/q-bio?searchtype=author&query=Dondelinger%2C+F">Frank Dondelinger</a>, 
<a href="/search/q-bio?searchtype=author&query=Alvarez%2C+M+A">Mauricio A. Alvarez</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+D">Dennis Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Interrogating the evolution of biological changes at early stages of life
requires longitudinal profiling of molecules, such as DNA methylation, which
can be challenging with children. We introduce a probabilistic and longitudinal
machine learning framework based on multi-mean Gaussian processes (GPs),
accounting for individual and gene correlations across time. This method
provides future predictions of DNA methylation status at different individual
ages while accounting for uncertainty. Our model is trained on a birth cohort
of children with methylation profiled at ages 0-4, and we demonstrated that the
status of methylation sites for each child can be accurately predicted at ages
5-7. We show that methylation profiles predicted by multi-mean GPs can be used
to estimate other phenotypes, such as epigenetic age, and enable comparison to
other health measures of interest. This approach encourages epigenetic studies
to move towards longitudinal design for investigating epigenetic changes during
development, ageing and disease progression.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13304" title="Abstract">arXiv:2312.13304</a> (cross-list from eess.IV) [<a href="/pdf/2312.13304" title="Download PDF">pdf</a>, <a href="/format/2312.13304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Rain Streak Removal with RAW Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Du%2C+G">GuoDong Du</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+H">HaoJian Deng</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+J">JiaHao Su</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures,4 tables, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work we address the problem of rain streak removal with RAW images.
The general approach is firstly processing RAW data into RGB images and
removing rain streak with RGB images. Actually the original information of rain
in RAW images is affected by image signal processing (ISP) pipelines including
none-linear algorithms, unexpected noise, artifacts and so on. It gains more
benefit to directly remove rain in RAW data before being processed into RGB
format. To solve this problem, we propose a joint solution for rain removal and
RAW processing to obtain clean color images from rainy RAW image. To be
specific, we generate rainy RAW data by converting color rain streak into RAW
space and design simple but efficient RAW processing algorithms to synthesize
both rainy and clean color images. The rainy color images are used as reference
to help color corrections. Different backbones show that our method conduct a
better result compared with several other state-of-the-art deraining methods
focused on color image. In addition, the proposed network generalizes well to
other cameras beyond our selected RAW dataset. Finally, we give the result
tested on images processed by different ISP pipelines to show the
generalization performance of our model is better compared with methods on
color images.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13310" title="Abstract">arXiv:2312.13310</a> (cross-list from eess.IV) [<a href="/pdf/2312.13310" title="Download PDF">pdf</a>, <a href="/format/2312.13310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Spectral Imaging with Unified Encoding Model: A  Comparative Study and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xinyuan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lingen Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xue Hu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+F">Fenglong Song</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Computational spectral imaging is drawing increasing attention owing to the
snapshot advantage, and amplitude, phase, and wavelength encoding systems are
three types of representative implementations. Fairly comparing and
understanding the performance of these systems is essential, but challenging
due to the heterogeneity in encoding design. To overcome this limitation, we
propose the unified encoding model (UEM) that covers all physical systems using
the three encoding types. Specifically, the UEM comprises physical amplitude,
physical phase, and physical wavelength encoding models that can be combined
with a digital decoding model in a joint encoder-decoder optimization framework
to compare the three systems under a unified experimental setup fairly.
Furthermore, we extend the UEMs to ideal versions, namely, ideal amplitude,
ideal phase, and ideal wavelength encoding models, which are free from physical
constraints, to explore the full potential of the three types of computational
spectral imaging systems. Finally, we conduct a holistic comparison of the
three types of computational spectral imaging systems and provide valuable
insights for designing and exploiting these systems in the future.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13313" title="Abstract">arXiv:2312.13313</a> (cross-list from eess.IV) [<a href="/pdf/2312.13313" title="Download PDF">pdf</a>, <a href="/format/2312.13313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParamISP: Learned Forward and Inverse ISPs using Camera Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+W">Woohyeok Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+G">Geonu Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Junyong Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seungyong Lee</a>, 
<a href="/search/eess?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+S">Sunghyun Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">RAW images are rarely shared mainly due to its excessive data size compared
to their sRGB counterparts obtained by camera ISPs. Learning the forward and
inverse processes of camera ISPs has been recently demonstrated, enabling
physically-meaningful RAW-level image processing on input sRGB images. However,
existing learning-based ISP methods fail to handle the large variations in the
ISP processes with respect to camera parameters such as ISO and exposure time,
and have limitations when used for various applications. In this paper, we
propose ParamISP, a learning-based method for forward and inverse conversion
between sRGB and RAW images, that adopts a novel neural-network module to
utilize camera parameters, which is dubbed as ParamNet. Given the camera
parameters provided in the EXIF data, ParamNet converts them into a feature
vector to control the ISP networks. Extensive experiments demonstrate that
ParamISP achieve superior RAW and sRGB reconstruction results compared to
previous methods and it can be effectively used for a variety of applications
such as deblurring dataset synthesis, raw deblurring, HDR reconstruction, and
camera-to-camera transfer.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13319" title="Abstract">arXiv:2312.13319</a> (cross-list from eess.IV) [<a href="/pdf/2312.13319" title="Download PDF">pdf</a>, <a href="/format/2312.13319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In2SET: Intra-Inter Similarity Exploiting Transformer for Dual-Camera  Compressive Hyperspectral Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+X">Xiangtian Ma</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Maoqing Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Lin Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Hua Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Dual-Camera Compressed Hyperspectral Imaging (DCCHI) offers the capability to
reconstruct 3D Hyperspectral Image (HSI) by fusing compressive and Panchromatic
(PAN) image, which has shown great potential for snapshot hyperspectral imaging
in practice. In this paper, we introduce a novel DCCHI reconstruction network,
the Intra-Inter Similarity Exploiting Transformer (In2SET). Our key insight is
to make full use of the PAN image to assist the reconstruction. To this end, we
propose using the intra-similarity within the PAN image as a proxy for
approximating the intra-similarity in the original HSI, thereby offering an
enhanced content prior for more accurate HSI reconstruction. Furthermore, we
aim to align the features from the underlying HSI with those of the PAN image,
maintaining semantic consistency and introducing new contextual information for
the reconstruction process. By integrating In2SET into a PAN-guided unrolling
framework, our method substantially enhances the spatial-spectral fidelity and
detail of the reconstructed images, providing a more comprehensive and accurate
depiction of the scene. Extensive experiments conducted on both real and
simulated datasets demonstrate that our approach consistently outperforms
existing state-of-the-art methods in terms of reconstruction quality and
computational complexity. Code will be released.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13333" title="Abstract">arXiv:2312.13333</a> (cross-list from eess.IV) [<a href="/pdf/2312.13333" title="Download PDF">pdf</a>, <a href="/ps/2312.13333" title="Download PostScript">ps</a>, <a href="/format/2312.13333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsible Deep Learning for Software as a Medical Device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shah%2C+P">Pratik Shah</a>, 
<a href="/search/eess?searchtype=author&query=Lester%2C+J">Jenna Lester</a>, 
<a href="/search/eess?searchtype=author&query=Deflino%2C+J+G">Jana G Deflino</a>, 
<a href="/search/eess?searchtype=author&query=Pai%2C+V">Vinay Pai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Tools, models and statistical methods for signal processing and medical image
analysis and training deep learning models to create research prototypes for
eventual clinical applications are of special interest to the biomedical
imaging community. But material and optical properties of biological tissues
are complex and not easily captured by imaging devices. Added complexity can be
introduced by datasets with underrepresentation of medical images from races
and ethnicities for deep learning, and limited knowledge about the regulatory
framework needed for commercialization and safety of emerging Artificial
Intelligence (AI) and Machine Learning (ML) technologies for medical image
analysis. This extended version of the workshop paper presented at the special
session of the 2022 IEEE 19th International Symposium on Biomedical Imaging,
describes strategy and opportunities by University of California professors
engaged in machine learning (section I) and clinical research (section II), the
Office of Science and Engineering Laboratories (OSEL) section III, and
officials at the US FDA in Center for Devices &amp; Radiological Health (CDRH)
section IV. Performance evaluations of AI/ML models of skin (RGB), tissue
biopsy (digital pathology), and lungs and kidneys (Magnetic Resonance, X-ray,
Computed Tomography) medical images for regulatory evaluations and real-world
deployment are discussed.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13389" title="Abstract">arXiv:2312.13389</a> (cross-list from stat.ML) [<a href="/pdf/2312.13389" title="Download PDF">pdf</a>, <a href="/format/2312.13389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Trade-offs in Privacy, Utility, and Computational Efficiency  through MUltistage Sampling Technique (MUST)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhao%2C+X">Xingyuan Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+F">Fang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Applying a randomized algorithm to a subset of a dataset rather than the
entire dataset is a common approach to amplify its privacy guarantees in the
released information. We propose a class of subsampling methods named
MUltistage Sampling Technique (MUST) for privacy amplification (PA) in the
context of differential privacy (DP). We conduct comprehensive analyses of the
PA effects and utility for several 2-stage MUST procedures, namely, MUST.WO,
MUST.OW, and MUST.WW that respectively represent sampling with (W), without
(O), with (W) replacement from the original dataset in stage I and then
sampling without (O), with (W), with (W) replacement in stage II from the
subset drawn in stage I. We also provide the privacy composition analysis over
repeated applications of MUST via the Fourier accountant algorithm. Our
theoretical and empirical results suggest that MUST.OW and MUST.WW have
stronger PA in $\epsilon$ than the common one-stage sampling procedures
including Poisson sampling, sampling without replacement, and sampling with
replacement, while the results on $\delta$ vary case by case. We also prove
that MUST.WO is equivalent to sampling with replacement in PA. Furthermore, the
final subset generated by a MUST procedure is a multiset that may contain
multiple copies of the same data points due to sampling with replacement
involved, which enhances the computational efficiency of algorithms that
require complex function calculations on distinct data points (e.g., gradient
descent). Our utility experiments show that MUST delivers similar or improved
utility and stability in the privacy-preserving outputs compared to one-stage
subsampling methods at similar privacy loss. MUST can be seamlessly integrated
into stochastic optimization algorithms or procedures that involve parallel or
simultaneous subsampling (e.g., bagging and subsampling bootstrap) when DP
guarantees are necessary.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13397" title="Abstract">arXiv:2312.13397</a> (cross-list from physics.atom-ph) [<a href="/pdf/2312.13397" title="Download PDF">pdf</a>, <a href="/ps/2312.13397" title="Download PostScript">ps</a>, <a href="/format/2312.13397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review and experimental benchmarking of machine learning algorithms for  efficient optimization of cold atom experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Anton%2C+O">Oliver Anton</a>, 
<a href="/search/physics?searchtype=author&query=Henderson%2C+V+A">Victoria A. Henderson</a>, 
<a href="/search/physics?searchtype=author&query=Da+Ros%2C+E">Elisa Da Ros</a>, 
<a href="/search/physics?searchtype=author&query=Sekulic%2C+I">Ivan Sekulic</a>, 
<a href="/search/physics?searchtype=author&query=Burger%2C+S">Sven Burger</a>, 
<a href="/search/physics?searchtype=author&query=Schneider%2C+P">Philipp-Immanuel Schneider</a>, 
<a href="/search/physics?searchtype=author&query=Krutzik%2C+M">Markus Krutzik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atomic Physics (physics.atom-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The generation of cold atom clouds is a complex process which involves the
optimization of noisy data in high dimensional parameter spaces. Optimization
can be challenging both in and especially outside of the lab due to lack of
time, expertise, or access for lengthy manual optimization. In recent years, it
was demonstrated that machine learning offers a solution since it can optimize
high dimensional problems quickly, without knowledge of the experiment itself.
In this paper we present results showing the benchmarking of nine different
optimization techniques and implementations, alongside their ability to
optimize a Rubidium (Rb) cold atom experiment. The investigations are performed
on a 3D $^{87}$Rb molasses with 10 and 18 adjustable parameters, respectively,
where the atom number obtained by absorption imaging was chosen as the test
problem. We further compare the best performing optimizers under different
effective noise conditions by reducing the Signal-to-Noise ratio of the images
via adapting the atomic vapor pressure in the 2D+ MOT and the detection laser
frequency stability.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13422" title="Abstract">arXiv:2312.13422</a> (cross-list from eess.IV) [<a href="/pdf/2312.13422" title="Download PDF">pdf</a>, <a href="/format/2312.13422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Texture Matching GAN for CT Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nagare%2C+M">Madhuri Nagare</a>, 
<a href="/search/eess?searchtype=author&query=Buzzard%2C+G+T">Gregery T. Buzzard</a>, 
<a href="/search/eess?searchtype=author&query=Bouman%2C+C+A">Charles A. Bouman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNN) are commonly used to denoise and sharpen X-ray
computed tomography (CT) images with the goal of reducing patient X-ray dosage
while maintaining reconstruction quality. However, naive application of
DNN-based methods can result in image texture that is undesirable in clinical
applications. Alternatively, generative adversarial network (GAN) based methods
can produce appropriate texture, but naive application of GANs can introduce
inaccurate or even unreal image detail. In this paper, we propose a texture
matching generative adversarial network (TMGAN) that enhances CT images while
generating an image texture that can be matched to a target texture. We use
parallel generators to separate anatomical features from the generated texture,
which allows the GAN to be trained to match the desired texture without
directly affecting the underlying CT image. We demonstrate that TMGAN generates
enhanced image quality while also producing image texture that is desirable for
clinical application.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13426" title="Abstract">arXiv:2312.13426</a> (cross-list from stat.ML) [<a href="/pdf/2312.13426" title="Download PDF">pdf</a>, <a href="/format/2312.13426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent Long-Term Forecasting of Ergodic Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Inzerilli%2C+P">Prune Inzerilli</a>, 
<a href="/search/stat?searchtype=author&query=Kostic%2C+V">Vladimir Kostic</a>, 
<a href="/search/stat?searchtype=author&query=Lounici%2C+K">Karim Lounici</a>, 
<a href="/search/stat?searchtype=author&query=Novelli%2C+P">Pietro Novelli</a>, 
<a href="/search/stat?searchtype=author&query=Pontil%2C+M">Massimiliano Pontil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We study the evolution of distributions under the action of an ergodic
dynamical system, which may be stochastic in nature. By employing tools from
Koopman and transfer operator theory one can evolve any initial distribution of
the state forward in time, and we investigate how estimators of these operators
perform on long-term forecasting. Motivated by the observation that standard
estimators may fail at this task, we introduce a learning paradigm that neatly
combines classical techniques of eigenvalue deflation from operator theory and
feature centering from statistics. This paradigm applies to any operator
estimator based on empirical risk minimization, making them satisfy learning
bounds which hold uniformly on the entire trajectory of future distributions,
and abide to the conservation of mass for each of the forecasted distributions.
Numerical experiments illustrates the advantages of our approach in practice.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13438" title="Abstract">arXiv:2312.13438</a> (cross-list from stat.ML) [<a href="/pdf/2312.13438" title="Download PDF">pdf</a>, <a href="/ps/2312.13438" title="Download PostScript">ps</a>, <a href="/format/2312.13438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Independent Mechanism Analysis and the Manifold Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ghosh%2C+S">Shubhangi Ghosh</a>, 
<a href="/search/stat?searchtype=author&query=Gresele%2C+L">Luigi Gresele</a>, 
<a href="/search/stat?searchtype=author&query=von+K%C3%BCgelgen%2C+J">Julius von K&#xfc;gelgen</a>, 
<a href="/search/stat?searchtype=author&query=Besserve%2C+M">Michel Besserve</a>, 
<a href="/search/stat?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, Accepted at Neurips Causal Representation Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Independent Mechanism Analysis (IMA) seeks to address non-identifiability in
nonlinear Independent Component Analysis (ICA) by assuming that the Jacobian of
the mixing function has orthogonal columns. As typical in ICA, previous work
focused on the case with an equal number of latent components and observed
mixtures. Here, we extend IMA to settings with a larger number of mixtures that
reside on a manifold embedded in a higher-dimensional than the latent space --
in line with the manifold hypothesis in representation learning. For this
setting, we show that IMA still circumvents several non-identifiability issues,
suggesting that it can also be a beneficial principle for higher-dimensional
observations when the manifold hypothesis holds. Further, we prove that the IMA
principle is approximately satisfied with high probability (increasing with the
number of observed mixtures) when the directions along which the latent
components influence the observations are chosen independently at random. This
provides a new and rigorous statistical interpretation of IMA.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13472" title="Abstract">arXiv:2312.13472</a> (cross-list from math.OC) [<a href="/pdf/2312.13472" title="Download PDF">pdf</a>, <a href="/format/2312.13472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Planning for Multiple Item Insertion using ADMM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zheng%2C+G">Gavin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.13158">arXiv:2208.13158</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Mixed-integer nonlinear programmings (MINLPs) are powerful formulation tools
for task planning. However, it suffers from long solving time especially for
large scale problems. In this work, we first formulate the task planning
problem for item stowing into a mixed-integer nonlinear programming problem,
then solve it using Alternative Direction Method of Multipliers (ADMM). ADMM
separates the complete formulation into a nonlinear programming problem and
mixed-integer programming problem, then iterate between them to solve the
original problem. We show that our ADMM converges better than non-warm-started
nonlinear complementary formulation. Our proposed methods are demonstrated on
hardware as a high level planner to insert books into the bookshelf.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13473" title="Abstract">arXiv:2312.13473</a> (cross-list from quant-ph) [<a href="/pdf/2312.13473" title="Download PDF">pdf</a>, <a href="/format/2312.13473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accuracy vs Memory Advantage in the Quantum Simulation of Stochastic  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Banchi%2C+L">Leonardo Banchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Mathematical Physics (math-ph)

</div>
<p class="mathjax">Many inference scenarios rely on extracting relevant information from known
data in order to make future predictions. When the underlying stochastic
process satisfies certain assumptions, there is a direct mapping between its
exact classical and quantum simulators, with the latter asymptotically using
less memory. Here we focus on studying whether such quantum advantage persists
when those assumptions are not satisfied, and the model is doomed to have
imperfect accuracy. By studying the trade-off between accuracy and memory
requirements, we show that quantum models can reach the same accuracy with less
memory, or alternatively, better accuracy with the same memory. Finally, we
discuss the implications of this result for learning tasks.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13477" title="Abstract">arXiv:2312.13477</a> (cross-list from q-bio.PE) [<a href="/pdf/2312.13477" title="Download PDF">pdf</a>, <a href="/format/2312.13477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating reproduction numbers: a general numerical approach for  age-structured models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=De+Reggi%2C+S">Simone De Reggi</a>, 
<a href="/search/q-bio?searchtype=author&query=Scarabel%2C+F">Francesca Scarabel</a>, 
<a href="/search/q-bio?searchtype=author&query=Vermiglio%2C+R">Rossana Vermiglio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Reproduction numbers play a fundamental role in population dynamics. For
age-structured models, these quantities are typically defined as spectral
radius of operators acting on infinite dimensional spaces. As a result, their
analytical computation is hardly achievable without additional assumptions on
the model coefficients (e.g., separability of age-specific transmission rates)
and numerical approximations are needed. In this paper we introduce a general
numerical approach, based on pseudospectral collocation of the relevant
operators, for approximating the reproduction numbers of a class of
age-structured models with finite life span. To our knowledge, this is the
first numerical method that allows complete flexibility in the choice of the
``birth'' and ``transition'' processes, which is made possible by working with
an equivalent problem for the integrated state. We discuss applications to
epidemic models with continuous rates, as well as models with piecewise
continuous rates estimated from real data, illustrating how the method can
compute different reproduction numbers-including the basic and the type
reproduction number as special cases-by considering different interpretations
of the age variable (e.g., chronological age, infection age, disease age) and
the transmission terms (e.g., horizontal and vertical transmission).
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13484" title="Abstract">arXiv:2312.13484</a> (cross-list from stat.ML) [<a href="/pdf/2312.13484" title="Download PDF">pdf</a>, <a href="/format/2312.13484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Suder%2C+P+M">Piotr M. Suder</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+J">Jason Xu</a>, 
<a href="/search/stat?searchtype=author&query=Dunson%2C+D+B">David B. Dunson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning is a burgeoning concept in statistical machine learning
that seeks to improve inference and/or predictive accuracy on a domain of
interest by leveraging data from related domains. While the term "transfer
learning" has garnered much recent interest, its foundational principles have
existed for years under various guises. Prior literature reviews in computer
science and electrical engineering have sought to bring these ideas into focus,
primarily surveying general methodologies and works from these disciplines.
This article highlights Bayesian approaches to transfer learning, which have
received relatively limited attention despite their innate compatibility with
the notion of drawing upon prior knowledge to guide new learning tasks. Our
survey encompasses a wide range of Bayesian transfer learning frameworks
applicable to a variety of practical settings. We discuss how these methods
address the problem of finding the optimal information to transfer between
domains, which is a central question in transfer learning. We illustrate the
utility of Bayesian transfer learning methods via a simulation study where we
compare performance against frequentist competitors.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13521" title="Abstract">arXiv:2312.13521</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.13521" title="Download PDF">pdf</a>, <a href="/ps/2312.13521" title="Download PostScript">ps</a>, <a href="/format/2312.13521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using GPT-4 Prompts to Determine Whether Articles Contain Functional  Evidence Supporting or Refuting Variant Pathogenicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Aronson%2C+S+J">Samuel J. Aronson</a> (1,2), 
<a href="/search/q-bio?searchtype=author&query=Machini%2C+K">Kalotina Machini</a> (1,3), 
<a href="/search/q-bio?searchtype=author&query=Sriraman%2C+P">Pranav Sriraman</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Shin%2C+J">Jiyeon Shin</a> (2), 
<a href="/search/q-bio?searchtype=author&query=Henricks%2C+E+R">Emma R. Henricks</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Mailly%2C+C">Charlotte Mailly</a> (1,2), 
<a href="/search/q-bio?searchtype=author&query=Nottage%2C+A+J">Angie J. Nottage</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Oates%2C+M">Michael Oates</a> (1,2), 
<a href="/search/q-bio?searchtype=author&query=Lebo%2C+M+S">Matthew S. Lebo</a> (1,3) ((1) Mass Gneral Brigham Personalized Medicine, (2) Accelerator for Clinical Transformation, Mass General Brigham, (3) Department of Pathology, Brigham and Women&#x27;s Hospital)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 tables, 2 figures, 2 supplementary tables These authors contributed equally: Samuel J. Aronson and Kalotina Machini Corresponding author: Samuel J. Aronson
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Purpose: To assess Generative Pre-trained Transformer version 4's (GPT-4)
ability to classify articles containing functional evidence relevant to
assessments of variant pathogenicity.
<br />Results: GPT-4 settings and prompts were trained on a set of 45 articles and
genetic variants. A final test set of 72 manually classified articles and
genetic variants were then processed using two prompts. The prompts asked GPT-4
to supply all functional evidence present in an article for a variant or
indicate that no functional evidence is present. For articles with having
functional evidence, a second prompt asked GPT-4 to classify the evidence into
pathogenic, benign, intermediate, and inconclusive categories. The first prompt
identified articles with variant-level functional evidence with 87% sensitivity
and 89% positive predictive value (PPV). Five of 26 articles with no functional
data were indicated as having functional evidence by GPT-4. For variants with
functional assays present as determined by both manual review and GPT-4, the
sensitivity and PPV of GPT-4 prompt concordance was: Pathogenic (92% sensitive
and 73% PPV), Intermediate or Inconclusive (67% sensitive and 93% PPV), Benign
(100% sensitive and 73% PPV).
<br />Conclusion: The GPT-4 prompts detected the presence or absence of a
functional assay with high sensitivity and PPV, and articles with unambiguous
evidence supporting a benign or pathogenic classification with high sensitivity
and reasonable PPV. Our prompts detected papers with intermediate or
inconclusive evidence with lower sensitivity but high PPV. Our results support
that GPT-4 may be useful in variant classification workflows by enabling
prioritization of articles for review that are likely to have functional
evidence supporting or refuting pathogenicity, but not that GPT-4 is capable of
fully automating the genetics literature review component of variant
classification.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13534" title="Abstract">arXiv:2312.13534</a> (cross-list from eess.IV) [<a href="/pdf/2312.13534" title="Download PDF">pdf</a>, <a href="/format/2312.13534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE(3)-Equivariant and Noise-Invariant 3D Motion Tracking in Medical  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Billot%2C+B">Benjamin Billot</a>, 
<a href="/search/eess?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+N">Neel Dey</a>, 
<a href="/search/eess?searchtype=author&query=Hoffmann%2C+M">Malte Hoffmann</a>, 
<a href="/search/eess?searchtype=author&query=Turk%2C+E+A">Esra Abaci Turk</a>, 
<a href="/search/eess?searchtype=author&query=Gagoski%2C+B">Borjan Gagoski</a>, 
<a href="/search/eess?searchtype=author&query=Grant%2C+E">Ellen Grant</a>, 
<a href="/search/eess?searchtype=author&query=Golland%2C+P">Polina Golland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Rigid motion tracking is paramount in many medical imaging applications where
movements need to be detected, corrected, or accounted for. Modern strategies
rely on convolutional neural networks (CNN) and pose this problem as rigid
registration. Yet, CNNs do not exploit natural symmetries in this task, as they
are equivariant to translations (their outputs shift with their inputs) but not
to rotations. Here we propose EquiTrack, the first method that uses recent
steerable SE(3)-equivariant CNNs (E-CNN) for motion tracking. While steerable
E-CNNs can extract corresponding features across different poses, testing them
on noisy medical images reveals that they do not have enough learning capacity
to learn noise invariance. Thus, we introduce a hybrid architecture that pairs
a denoiser with an E-CNN to decouple the processing of anatomically irrelevant
intensity features from the extraction of equivariant spatial features. Rigid
transforms are then estimated in closed-form. EquiTrack outperforms
state-of-the-art learning and optimisation methods for motion tracking in adult
brain MRI and fetal MRI time series. Our code is available at
github.com/BBillot/equitrack.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13561" title="Abstract">arXiv:2312.13561</a> (cross-list from quant-ph) [<a href="/pdf/2312.13561" title="Download PDF">pdf</a>, <a href="/ps/2312.13561" title="Download PostScript">ps</a>, <a href="/format/2312.13561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revocable Quantum Digital Signatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Morimae%2C+T">Tomoyuki Morimae</a>, 
<a href="/search/quant-ph?searchtype=author&query=Poremba%2C+A">Alexander Poremba</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yamakawa%2C+T">Takashi Yamakawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We study digital signatures with revocation capabilities and show two
results. First, we define and construct digital signatures with revocable
signing keys from the LWE assumption. In this primitive, the signing key is a
quantum state which enables a user to sign many messages and yet, the quantum
key is also revocable, i.e., it can be collapsed into a classical certificate
which can later be verified. Once the key is successfully revoked, we require
that the initial recipient of the key loses the ability to sign. We construct
digital signatures with revocable signing keys from a newly introduced
primitive which we call two-tier one-shot signatures, which may be of
independent interest. This is a variant of one-shot signatures, where the
verification of a signature for the message ``0'' is done publicly, whereas the
verification for the message ``1'' is done in private. We give a construction
of two-tier one-shot signatures from the LWE assumption. As a complementary
result, we also construct digital signatures with quantum revocation from group
actions, where the quantum signing key is simply ``returned'' and then verified
as part of revocation.
<br />Second, we define and construct digital signatures with revocable signatures
from OWFs. In this primitive, the signer can produce quantum signatures which
can later be revoked. Here, the security property requires that, once
revocation is successful, the initial recipient of the signature loses the
ability to find accepting inputs to the signature verification algorithm. We
construct this primitive using a newly introduced two-tier variant of tokenized
signatures. For the construction, we show a new lemma which we call the
adaptive hardcore bit property for OWFs, which may enable further applications.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13600" title="Abstract">arXiv:2312.13600</a> (cross-list from eess.AS) [<a href="/pdf/2312.13600" title="Download PDF">pdf</a>, <a href="/format/2312.13600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainTalker: Low-Resource Brain-to-Speech Synthesis with Transfer  Learning using Wav2Vec 2.0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Miseul Kim</a>, 
<a href="/search/eess?searchtype=author&query=Piao%2C+Z">Zhenyu Piao</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jihyun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+H">Hong-Goo Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages. Accepted to BHI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Decoding spoken speech from neural activity in the brain is a fast-emerging
research topic, as it could enable communication for people who have
difficulties with producing audible speech. For this task, electrocorticography
(ECoG) is a common method for recording brain activity with high temporal
resolution and high spatial precision. However, due to the risky surgical
procedure required for obtaining ECoG recordings, relatively little of this
data has been collected, and the amount is insufficient to train a neural
network-based Brain-to-Speech (BTS) system. To address this problem, we propose
BrainTalker-a novel BTS framework that generates intelligible spoken speech
from ECoG signals under extremely low-resource scenarios. We apply a transfer
learning approach utilizing a pre-trained self supervised model, Wav2Vec 2.0.
Specifically, we train an encoder module to map ECoG signals to latent
embeddings that match Wav2Vec 2.0 representations of the corresponding spoken
speech. These embeddings are then transformed into mel-spectrograms using
stacked convolutional and transformer-based layers, which are fed into a neural
vocoder to synthesize speech waveform. Experimental results demonstrate our
proposed framework achieves outstanding performance in terms of subjective and
objective metrics, including a Pearson correlation coefficient of 0.9 between
generated and ground truth mel spectrograms. We share publicly available Demos
and Code.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13603" title="Abstract">arXiv:2312.13603</a> (cross-list from eess.AS) [<a href="/pdf/2312.13603" title="Download PDF">pdf</a>, <a href="/format/2312.13603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Modeling for Multi-Speaker Articulation-to-Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Miseul Kim</a>, 
<a href="/search/eess?searchtype=author&query=Piao%2C+Z">Zhenyu Piao</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jihyun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+H">Hong-Goo Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, Accepted to ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we propose a neural articulation-to-speech (ATS) framework
that synthesizes high-quality speech from articulatory signal in a
multi-speaker situation. Most conventional ATS approaches only focus on
modeling contextual information of speech from a single speaker's articulatory
features. To explicitly represent each speaker's speaking style as well as the
contextual information, our proposed model estimates style embeddings, guided
from the essential speech style attributes such as pitch and energy. We adopt
convolutional layers and transformer-based attention layers for our model to
fully utilize both local and global information of articulatory signals,
measured by electromagnetic articulography (EMA). Our model significantly
improves the quality of synthesized speech compared to the baseline in terms of
objective and subjective measurements in the Haskins dataset.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13615" title="Abstract">arXiv:2312.13615</a> (cross-list from eess.AS) [<a href="/pdf/2312.13615" title="Download PDF">pdf</a>, <a href="/format/2312.13615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Complex Network for Machine Sound Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Miseul Kim</a>, 
<a href="/search/eess?searchtype=author&query=Ho%2C+M+T">Minh Tri Ho</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+H">Hong-Goo Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in EUSIPCO 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose an anomaly detection algorithm for machine sounds
with a deep complex network trained by self-supervision. Using the fact that
phase continuity information is crucial for detecting abnormalities in
time-series signals, our proposed algorithm utilizes the complex spectrum as an
input and performs complex number arithmetic throughout the entire process.
Since the usefulness of phase information can vary depending on the type of
machine sound, we also apply an attention mechanism to control the weights of
the complex and magnitude spectrum bottleneck features depending on the machine
type. We train our network to perform a self-supervised task that classifies
the machine identifier (id) of normal input sounds among multiple classes. At
test time, an input signal is detected as anomalous if the trained model is
unable to correctly classify the id. In other words, we determine the presence
of an anomality when the output cross-entropy score of the multiclass
identification task is lower than a pre-defined threshold. Experiments with the
MIMII dataset show that the proposed algorithm has a much higher area under the
curve (AUC) score than conventional magnitude spectrum-based algorithms.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13622" title="Abstract">arXiv:2312.13622</a> (cross-list from eess.SP) [<a href="/pdf/2312.13622" title="Download PDF">pdf</a>, <a href="/format/2312.13622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Optimal RIS Placement and Power Allocation for Underlay D2D  Communications: An Outage Probability Minimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghose%2C+S">Sarbani Ghose</a>, 
<a href="/search/eess?searchtype=author&query=Mishra%2C+D">Deepak Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Maity%2C+S+P">Santi P. Maity</a>, 
<a href="/search/eess?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we study underlay device-to-device (D2D) communication systems
empowered by a reconfigurable intelligent surface (RIS) for cognitive cellular
networks. Considering Rayleigh fading channels and the general case where there
exist both the direct and RIS-enabled D2D channels, the outage probability (OP)
of the D2D communication link is presented in closed-form. Next, for the
considered RIS-empowered underlaid D2D system, we frame an OP minimization
problem. We target the joint optimization of the transmit power at the D2D
source and the RIS placement, under constraints on the transmit power at the
D2D source and on the limited interference imposed on the cellular user for two
RIS deployment topologies. Due to the coupled optimization variables, the
formulated optimization problem is extremely intractable. We propose an
equivalent transformation which we are able to solve analytically. In the
transformed problem, an expression for the average value of the
signal-to-interference-noise ratio (SINR) at the D2D receiver is derived in
closed-form. Our theoretical derivations are corroborated through simulation
results, and various system design insights are deduced. It is indicatively
showcased that the proposed RIS-empowered underlaid D2D system design
outperforms the benchmark semi-adaptive optimal power and optimal distance
schemes, offering $44\%$ and $20\%$ performance improvement, respectively.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13636" title="Abstract">arXiv:2312.13636</a> (cross-list from quant-ph) [<a href="/pdf/2312.13636" title="Download PDF">pdf</a>, <a href="/ps/2312.13636" title="Download PostScript">ps</a>, <a href="/format/2312.13636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Optimization Algorithms in Operations Research: Methods,  Applications, and Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klug%2C+F">Florian Klug</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">Quantum optimization algorithms (QOAs) have the potential to fundamentally
transform the application of optimization methods in decision making. For
certain classes of optimization problems, it is widely believed that QOA
enables significant run-time performance benefits over current state-of-the art
solutions. With the latest progress on building quantum computers entering the
industrialization stage, quantum-based optimization algorithms have become more
relevant. The recent extreme increase in the number of publications in the
field of QOA demonstrates the growing importance of the topic in both the
academia and the industry. The objectives of this paper are as follows: (1)
First, we provide insight into the main techniques of quantum-based
optimization algorithms for decision making. (2) We describe and compare the
two basic classes of adiabatic and gate-based optimization algorithms and argue
their potentials and limitations. (3) Herein, we also investigate the key
operations research application areas that are expected to be considerably
impacted by the use of QOA in decision making in the future. (4) Finally,
current implications arising from the future use of QOA from an operations
research perspective are discussed.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13640" title="Abstract">arXiv:2312.13640</a> (cross-list from eess.SP) [<a href="/pdf/2312.13640" title="Download PDF">pdf</a>, <a href="/format/2312.13640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optical Integrated Sensing and Communication: Architectures, Potentials  and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+Y">Yunfeng Wen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+F">Fang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+J">Jian Song</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+Z">Zhu Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Integrated sensing and communication (ISAC) is viewed as a crucial component
of future mobile networks and has gained much interest in both academia and
industry. Similar to the emergence of radio-frequency (RF) ISAC, the
integration of free space optical communication and optical sensing yields
optical ISAC (O-ISAC), which is regarded as a powerful complement to its RF
counterpart. In this article, we first introduce the generalized system
structure of O-ISAC, and then elaborate on three advantages of O-ISAC, i.e.,
increasing communication rate, enhancing sensing precision, and reducing
interference. Next, waveform design and resource allocation of O-ISAC are
discussed based on pulse waveform, constant-modulus waveform, and multi-carrier
waveform. Furthermore, we put forward future trends and challenges of O-ISAC,
which are expected to provide some valuable directions for future research.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13650" title="Abstract">arXiv:2312.13650</a> (cross-list from quant-ph) [<a href="/pdf/2312.13650" title="Download PDF">pdf</a>, <a href="/format/2312.13650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Quantum Neural Networks via Partitioned Features Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kawase%2C+Y">Yoshiaki Kawase</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum neural networks are expected to be a promising application in
near-term quantum computation, but face challenges such as vanishing gradients
during optimization and limited expressibility by a limited number of qubits
and shallow circuits. To mitigate these challenges, distributed quantum neural
networks have been proposed to make a prediction by approximating a large
circuit with multiple small circuits. However, the approximation of a large
circuit requires an exponential number of small circuit evaluations. Here, we
instead propose to distribute partitioned features over multiple small quantum
neural networks and use the ensemble of their expectation values to generate
predictions. To verify our distributed approach, we demonstrate multi-class
classifications of handwritten digit datasets. Especially for the MNIST
dataset, we succeeded in ten class classifications of the dataset with
exceeding 96% accuracy. Our proposed method not only achieved highly accurate
predictions for a large dataset but also reduced the hardware requirements for
each quantum neural network compared to a single quantum neural network. Our
results highlight distributed quantum neural networks as a promising direction
for practical quantum machine learning algorithms compatible with near-term
quantum devices. We hope that our approach is useful for exploring quantum
machine learning applications.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13683" title="Abstract">arXiv:2312.13683</a> (cross-list from eess.SP) [<a href="/pdf/2312.13683" title="Download PDF">pdf</a>, <a href="/format/2312.13683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Channel Estimation and Cooperative Localization for Near-Field  Ultra-Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+R">Ruoxiao Cao</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+H">Hengtao He</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xianghao Yu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+S">Shenghui Song</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Kaibin Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Gong%2C+Y">Yi Gong</a>, 
<a href="/search/eess?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submit to JSAC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The next-generation (6G) wireless networks are expected to provide not only
seamless and high data-rate communications, but also ubiquitous sensing
services. By providing vast spatial degrees of freedom (DoFs), ultra-massive
multiple-input multiple-output (UM-MIMO) technology is a key enabler for both
sensing and communications in 6G. However, the adoption of UM-MIMO leads to a
shift from the far field to the near field in terms of the electromagnetic
propagation, which poses novel challenges in system design. Specifically,
near-field effects introduce highly non-linear spherical wave models that
render existing designs based on plane wave assumptions ineffective. In this
paper, we focus on two crucial tasks in sensing and communications,
respectively, i.e., localization and channel estimation, and investigate their
joint design by exploring the near-field propagation characteristics, achieving
mutual benefits between two tasks. In addition, multiple base stations (BSs)
are leveraged to collaboratively facilitate a cooperative localization
framework. To address the joint channel estimation and cooperative localization
problem for near-field UM-MIMO systems, we propose a variational Newtonized
near-field channel estimation (VNNCE) algorithm and a Gaussian fusion
cooperative localization (GFCL) algorithm. The VNNCE algorithm exploits the
spatial DoFs provided by the near-field channel to obtain position-related soft
information, while the GFCL algorithm fuses this soft information to achieve
more accurate localization. Additionally, we introduce a joint architecture
that seamlessly integrates channel estimation and cooperative localization.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13707" title="Abstract">arXiv:2312.13707</a> (cross-list from eess.AS) [<a href="/pdf/2312.13707" title="Download PDF">pdf</a>, <a href="/format/2312.13707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Localization of Room Reflections with Application to Spatial Audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hadadi%2C+Y">Yogev Hadadi</a>, 
<a href="/search/eess?searchtype=author&query=Tourbabin%2C+V">Vladimir Tourbabin</a>, 
<a href="/search/eess?searchtype=author&query=Calamia%2C+P">Paul Calamia</a>, 
<a href="/search/eess?searchtype=author&query=Rafaely%2C+B">Boaz Rafaely</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in 2023 Immersive and 3D Audio: from Architecture to Automotive
  (I3DA 2023), Bologna, Italy, September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Blind estimation of early room reflections, without knowledge of the room
impulse response, holds substantial value. The FF-PHALCOR (Frequency Focusing
PHase ALigned CORrelation), method was recently developed for this objective,
extending the original PHALCOR method from spherical to arbitrary arrays.
However, previous studies only compared the two methods under limited
conditions without presenting a comprehensive performance analysis. This study
presents an advance by evaluating the performance of the algorithm in a wider
range of conditions. Additionally, performance in terms of perception is
investigated through a listening test. This test involves synthesizing room
impulse responses from known room acoustics parameters and replacing the early
reflections with the estimated ones. The importance of the estimated
reflections for spatial perception is demonstrated through this test.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13752" title="Abstract">arXiv:2312.13752</a> (cross-list from eess.IV) [<a href="/pdf/2312.13752" title="Download PDF">pdf</a>, <a href="/ps/2312.13752" title="Download PostScript">ps</a>, <a href="/format/2312.13752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hunting imaging biomarkers in pulmonary fibrosis: Benchmarks of the  AIIB23 challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nan%2C+Y">Yang Nan</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shiyi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Z">Zeyu Tang</a>, 
<a href="/search/eess?searchtype=author&query=Felder%2C+F+N">Federico N Felder</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ledda%2C+R+E">Roberta Eufrasia Ledda</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+X">Xiaoliu Ding</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+R">Ruiqi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Weiping Liu</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+F">Feng Shi</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+T">Tianyang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Z">Zehong Cao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Minghui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+Y">Yun Gu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hanxiao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jian Gao</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+W">Wen Tang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+P">Pengxin Yu</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+H">Han Kang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Junqiang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+X">Xing Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+B">Boyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Mamalakis%2C+M">Michail Mamalakis</a>, 
<a href="/search/eess?searchtype=author&query=Prinzi%2C+F">Francesco Prinzi</a>, 
<a href="/search/eess?searchtype=author&query=Carlini%2C+G">Gianluca Carlini</a>, 
<a href="/search/eess?searchtype=author&query=Cuneo%2C+L">Lisa Cuneo</a>, 
<a href="/search/eess?searchtype=author&query=Banerjee%2C+A">Abhirup Banerjee</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+Z">Zhaohu Xing</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Mesbah%2C+Z">Zacharia Mesbah</a>, 
<a href="/search/eess?searchtype=author&query=Jain%2C+D">Dhruv Jain</a>, 
<a href="/search/eess?searchtype=author&query=Mayet%2C+T">Tsiry Mayet</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+H">Hongyu Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+Q">Qing Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Wells%2C+A">Athol Wells</a>, 
<a href="/search/eess?searchtype=author&query=Walsh%2C+S+L">Simon LF Walsh</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Airway-related quantitative imaging biomarkers are crucial for examination,
diagnosis, and prognosis in pulmonary diseases. However, the manual delineation
of airway trees remains prohibitively time-consuming. While significant efforts
have been made towards enhancing airway modelling, current public-available
datasets concentrate on lung diseases with moderate morphological variations.
The intricate honeycombing patterns present in the lung tissues of fibrotic
lung disease patients exacerbate the challenges, often leading to various
prediction errors. To address this issue, the 'Airway-Informed Quantitative CT
Imaging Biomarker for Fibrotic Lung Disease 2023' (AIIB23) competition was
organized in conjunction with the official 2023 International Conference on
Medical Image Computing and Computer Assisted Intervention (MICCAI). The airway
structures were meticulously annotated by three experienced radiologists.
Competitors were encouraged to develop automatic airway segmentation models
with high robustness and generalization abilities, followed by exploring the
most correlated QIB of mortality prediction. A training set of 120
high-resolution computerised tomography (HRCT) scans were publicly released
with expert annotations and mortality status. The online validation set
incorporated 52 HRCT scans from patients with fibrotic lung disease and the
offline test set included 140 cases from fibrosis and COVID-19 patients. The
results have shown that the capacity of extracting airway trees from patients
with fibrotic lung disease could be enhanced by introducing voxel-wise weighted
general union loss and continuity loss. In addition to the competitive image
biomarkers for prognosis, a strong airway-derived biomarker (Hazard ratio&gt;1.5,
p&lt;0.0001) was revealed for survival prognostication compared with existing
clinical measurements, clinician assessment and AI-based biomarkers.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13807" title="Abstract">arXiv:2312.13807</a> (cross-list from math.OC) [<a href="/pdf/2312.13807" title="Download PDF">pdf</a>, <a href="/format/2312.13807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized classification with neural ODEs via separability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C3%81lvarez-L%C3%B3pez%2C+A">Antonio &#xc1;lvarez-L&#xf3;pez</a>, 
<a href="/search/math?searchtype=author&query=Orive-Illera%2C+R">Rafael Orive-Illera</a>, 
<a href="/search/math?searchtype=author&query=Zuazua%2C+E">Enrique Zuazua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Classification of $N$ points becomes a simultaneous control problem when
viewed through the lens of neural ordinary differential equations (neural
ODEs), which represent the time-continuous limit of residual networks. For the
narrow model, with one neuron per hidden layer, it has been shown that the task
can be achieved using $O(N)$ neurons. In this study, we focus on estimating the
number of neurons required for efficient cluster-based classification,
particularly in the worst-case scenario where points are independently and
uniformly distributed in $[0,1]^d$. Our analysis provides a novel method for
quantifying the probability of requiring fewer than $O(N)$ neurons, emphasizing
the asymptotic behavior as both $d$ and $N$ increase. Additionally, under the
sole assumption that the data are in general position, we propose a new
constructive algorithm that simultaneously classifies clusters of $d$ points
from any initial configuration, effectively reducing the maximal complexity to
$O(N/d)$ neurons.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13820" title="Abstract">arXiv:2312.13820</a> (cross-list from physics.optics) [<a href="/pdf/2312.13820" title="Download PDF">pdf</a>, <a href="/format/2312.13820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-resolution of THz time-domain images based on low-rank  representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ljubenovic%2C+M">Marina Ljubenovic</a>, 
<a href="/search/physics?searchtype=author&query=Artesani%2C+A">Alessia Artesani</a>, 
<a href="/search/physics?searchtype=author&query=Bonetti%2C+S">Stefano Bonetti</a>, 
<a href="/search/physics?searchtype=author&query=Traviglia%2C+A">Arianna Traviglia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was presented at the Sixth International Workshop on Mobile Terahertz Systems (IWMTS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 Sixth International Workshop on Mobile Terahertz Systems
  (IWMTS), Bonn, Germany, 2023, pp. 1-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Terahertz time-domain spectroscopy (THz-TDS) employs sub-picosecond pulses to
probe dielectric properties of materials giving as a result a 3-dimensional
hyperspectral data cube. The spatial resolution of THz images is primarily
limited by two sources: a non-zero THz beam waist and the acquisition step
size. Acquisition with a small step size allows for the visualisation of
smaller details in images at the expense of acquisition time, but the
frequency-dependent point-spread function remains the biggest bottleneck for
THz imaging. This work presents a super-resolution approach to restore THz
time-domain images acquired with medium-to-big step sizes. The results show the
optimized and robust performance for different frequency bands (from 0.5 to 3.5
THz) obtaining higher resolution and additionally removing effects of blur at
lower frequencies and noise at higher frequencies.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13835" title="Abstract">arXiv:2312.13835</a> (cross-list from quant-ph) [<a href="/pdf/2312.13835" title="Download PDF">pdf</a>, <a href="/format/2312.13835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Reconciliation for Experimental Continuous-Variable Quantum Key  Distribution Over a Turbulent Free-Space Optical Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=G%C3%BCm%C3%BC%C5%9F%2C+K">Kadir G&#xfc;m&#xfc;&#x15f;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fraz%C3%A3o%2C+J+d+R">Jo&#xe3;o dos Reis Fraz&#xe3;o</a>, 
<a href="/search/quant-ph?searchtype=author&query=van+Vliet%2C+V">Vincent van Vliet</a>, 
<a href="/search/quant-ph?searchtype=author&query=van+der+Heide%2C+S">Sjoerd van der Heide</a>, 
<a href="/search/quant-ph?searchtype=author&query=van+den+Hout%2C+M">Menno van den Hout</a>, 
<a href="/search/quant-ph?searchtype=author&query=Albores-Mejia%2C+A">Aaron Albores-Mejia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bradley%2C+T">Thomas Bradley</a>, 
<a href="/search/quant-ph?searchtype=author&query=Okonkwo%2C+C">Chigo Okonkwo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted for OFC 2024, this is a pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Signal Processing (eess.SP)

</div>
<p class="mathjax">We experimentally demonstrate adaptive reconciliation for continuous-variable
quantum key distribution over a turbulent free-space optical channel.
Additionally, we propose a method for optimising the reconciliation efficiency,
increasing secret key rates by up to 8.1%.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13853" title="Abstract">arXiv:2312.13853</a> (cross-list from quant-ph) [<a href="/pdf/2312.13853" title="Download PDF">pdf</a>, <a href="/format/2312.13853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Wave Function Collapse for Procedural Content Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Heese%2C+R">Raoul Heese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Quantum computers exhibit an inherent randomness, so it seems natural to
consider them for procedural content generation. In this work, a quantum
version of the famous (classical) wave function collapse algorithm is proposed.
This quantum wave function collapse algorithm is based on the idea that a
quantum circuit can be prepared in such a way that it acts as a special-purpose
random generator for content of a desired form. The proposed method is
presented theoretically and investigated experimentally on simulators and
actual IBM Quantum devices.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13868" title="Abstract">arXiv:2312.13868</a> (cross-list from physics.chem-ph) [<a href="/pdf/2312.13868" title="Download PDF">pdf</a>, <a href="/format/2312.13868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven path collective variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=France-Lanord%2C+A">Arthur France-Lanord</a>, 
<a href="/search/physics?searchtype=author&query=Vroylandt%2C+H">Hadrien Vroylandt</a>, 
<a href="/search/physics?searchtype=author&query=Salanne%2C+M">Mathieu Salanne</a>, 
<a href="/search/physics?searchtype=author&query=Rotenberg%2C+B">Benjamin Rotenberg</a>, 
<a href="/search/physics?searchtype=author&query=Saitta%2C+A+M">A. Marco Saitta</a>, 
<a href="/search/physics?searchtype=author&query=Pietrucci%2C+F">Fabio Pietrucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Identifying optimal collective variables to model transformations, using
atomic-scale simulations, is a long-standing challenge. We propose a new method
for the generation, optimization, and comparison of collective variables, which
can be thought of as a data-driven generalization of the path collective
variable concept. It consists in a kernel ridge regression of the committor
probability, which encodes a transformation's progress. The resulting
collective variable is one-dimensional, interpretable, and differentiable,
making it appropriate for enhanced sampling simulations requiring biasing. We
demonstrate the validity of the method on two different applications: a
precipitation model, and the association of Li$^+$ and F$^-$ in water. For the
former, we show that global descriptors such as the permutation invariant
vector allow to reach an accuracy far from the one achieved \textit{via}
simpler, more intuitive variables. For the latter, we show that information
correlated with the transformation mechanism is contained in the first
solvation shell only, and that inertial effects prevent the derivation of
optimal collective variables from the atomic positions only.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13875" title="Abstract">arXiv:2312.13875</a> (cross-list from stat.ML) [<a href="/pdf/2312.13875" title="Download PDF">pdf</a>, <a href="/format/2312.13875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best Arm Identification in Batched Multi-armed Bandit Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cao%2C+S">Shengyu Cao</a>, 
<a href="/search/stat?searchtype=author&query=He%2C+S">Simai He</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+R">Ruoqing Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+J">Jin Xu</a>, 
<a href="/search/stat?searchtype=author&query=Yuan%2C+H">Hongsong Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Recently multi-armed bandit problem arises in many real-life scenarios where
arms must be sampled in batches, due to limited time the agent can wait for the
feedback. Such applications include biological experimentation and online
marketing. The problem is further complicated when the number of arms is large
and the number of batches is small. We consider pure exploration in a batched
multi-armed bandit problem. We introduce a general linear programming framework
that can incorporate objectives of different theoretical settings in best arm
identification. The linear program leads to a two-stage algorithm that can
achieve good theoretical properties. We demonstrate by numerical studies that
the algorithm also has good performance compared to certain UCB-type or
Thompson sampling methods.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13884" title="Abstract">arXiv:2312.13884</a> (cross-list from q-fin.RM) [<a href="/pdf/2312.13884" title="Download PDF">pdf</a>, <a href="/format/2312.13884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measures of Resilience to Cyber Contagion -- An Axiomatic Approach for  Complex Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Svindland%2C+G">Gregor Svindland</a>, 
<a href="/search/q-fin?searchtype=author&query=Vo%C3%9F%2C+A">Alexander Vo&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Cryptography and Security (cs.CR); Discrete Mathematics (cs.DM); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">We introduce a novel class of risk measures for the management of systemic
risk in networks. In contrast to most existing approaches, our measures target
the topological structure of the network in order to control the risk of a
pandemic spread of some contagious peril throughout the network. While the main
discussion of the paper is tailored to the management of systemic cyber risk in
digital networks, we also draw parallels to similar risk management frameworks
for other types of complex systems.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13889" title="Abstract">arXiv:2312.13889</a> (cross-list from stat.CO) [<a href="/pdf/2312.13889" title="Download PDF">pdf</a>, <a href="/ps/2312.13889" title="Download PostScript">ps</a>, <a href="/format/2312.13889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metropolis-adjusted interacting particle sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sprungk%2C+B">Bj&#xf6;rn Sprungk</a>, 
<a href="/search/stat?searchtype=author&query=Weissmann%2C+S">Simon Weissmann</a>, 
<a href="/search/stat?searchtype=author&query=Zech%2C+J">Jakob Zech</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In recent years, various interacting particle samplers have been developed to
sample from complex target distributions, such as those found in Bayesian
inverse problems. These samplers are motivated by the mean-field limit
perspective and implemented as ensembles of particles that move in the product
state space according to coupled stochastic differential equations. The
ensemble approximation and numerical time stepping used to simulate these
systems can introduce bias and affect the invariance of the particle system
with respect to the target distribution. To correct for this, we investigate
the use of a Metropolization step, similar to the Metropolis-adjusted Langevin
algorithm. We examine Metropolization of either the whole ensemble or smaller
subsets of the ensemble, and prove basic convergence of the resulting ensemble
Markov chain to the target distribution. Our numerical results demonstrate the
benefits of this correction in numerical examples for popular interacting
particle samplers such as ALDI, CBS, and stochastic SVGD.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13944" title="Abstract">arXiv:2312.13944</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.13944" title="Download PDF">pdf</a>, <a href="/format/2312.13944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Docking-based generative approaches in the search for new drug  candidates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Danel%2C+T">Tomasz Danel</a>, 
<a href="/search/q-bio?searchtype=author&query=%C5%81%C4%99ski%2C+J">Jan &#x141;&#x119;ski</a>, 
<a href="/search/q-bio?searchtype=author&query=Podlewska%2C+S">Sabina Podlewska</a>, 
<a href="/search/q-bio?searchtype=author&query=Podolak%2C+I+T">Igor T. Podolak</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Drug Discovery Today 28.2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the great popularity of virtual screening of existing compound
libraries, the search for new potential drug candidates also takes advantage of
generative protocols, where new compound suggestions are enumerated using
various algorithms. To increase the activity potency of generative approaches,
they have recently been coupled with molecular docking, a leading methodology
of structure-based drug design. In this review, we summarize progress since
docking-based generative models emerged. We propose a new taxonomy for these
methods and discuss their importance for the field of computer-aided drug
design. In addition, we discuss the most promising directions for further
development of generative protocols coupled with docking.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13947" title="Abstract">arXiv:2312.13947</a> (cross-list from eess.IV) [<a href="/pdf/2312.13947" title="Download PDF">pdf</a>, <a href="/format/2312.13947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysRFANet: Physics-Guided Neural Network for Real-Time Prediction of  Thermal Effect During Radiofrequency Ablation Treatment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shin%2C+M">Minwoo Shin</a>, 
<a href="/search/eess?searchtype=author&query=Seo%2C+M">Minjee Seo</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+S">Seonaeng Cho</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Juil Park</a>, 
<a href="/search/eess?searchtype=author&query=Kwon%2C+J+H">Joon Ho Kwon</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Deukhee Lee</a>, 
<a href="/search/eess?searchtype=author&query=Yoon%2C+K">Kyungho Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Radiofrequency ablation (RFA) is a widely used minimally invasive technique
for ablating solid tumors. Achieving precise personalized treatment
necessitates feedback information on in situ thermal effects induced by the RFA
procedure. While computer simulation facilitates the prediction of electrical
and thermal phenomena associated with RFA, its practical implementation in
clinical settings is hindered by high computational demands. In this paper, we
propose a physics-guided neural network model, named PhysRFANet, to enable
real-time prediction of thermal effect during RFA treatment. The networks,
designed for predicting temperature distribution and the corresponding ablation
lesion, were trained using biophysical computational models that integrated
electrostatics, bio-heat transfer, and cell necrosis, alongside magnetic
resonance (MR) images of breast cancer patients. Validation of the
computational model was performed through experiments on ex vivo bovine liver
tissue. Our model demonstrated a 96% Dice score in predicting the lesion volume
and an RMSE of 0.4854 for temperature distribution when tested with foreseen
tumor images. Notably, even with unforeseen images, it achieved a 93% Dice
score for the ablation lesion and an RMSE of 0.6783 for temperature
distribution. All networks were capable of inferring results within 10 ms. The
presented technique, applied to optimize the placement of the electrode for a
specific target region, holds significant promise in enhancing the safety and
efficacy of RFA treatments.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13976" title="Abstract">arXiv:2312.13976</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.13976" title="Download PDF">pdf</a>, <a href="/ps/2312.13976" title="Download PostScript">ps</a>, <a href="/format/2312.13976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomical basis of sex differences in human post-myocardial infarction  ECG phenotypes identified by novel automated torso-cardiac 3D reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Smith%2C+H+J">Hannah J. Smith</a>, 
<a href="/search/physics?searchtype=author&query=Rodriguez%2C+B">Blanca Rodriguez</a>, 
<a href="/search/physics?searchtype=author&query=Sang%2C+Y">Yuling Sang</a>, 
<a href="/search/physics?searchtype=author&query=Beetz%2C+M">Marcel Beetz</a>, 
<a href="/search/physics?searchtype=author&query=Choudhury%2C+R">Robin Choudhury</a>, 
<a href="/search/physics?searchtype=author&query=Grau%2C+V">Vicente Grau</a>, 
<a href="/search/physics?searchtype=author&query=Banerjee%2C+A">Abhirup Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper under revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The electrocardiogram (ECG) is routinely used in cardiology, though its
interpretation is confounded by anatomical variability. A novel, automated
computational pipeline enables quantification of torso-ventricular anatomy
metrics from magnetic resonance imaging, and comparison to ECG characteristics.
Sex and myocardial infarction differences are investigated based on 1051
healthy and 425 post-MI subjects from UK Biobank. Smaller ventricles in females
explain ~50% of shorter QRS durations than in males, and contribute to lower
STJ amplitudes in females (also due to more superior and posterior position).
In females, torso-ventricular anatomy, particularly from larger BMI, is a
stronger modulator of T wave amplitude reductions and left-deviated R axis
angles in post-MI than in males. Thus, female MI phenotype is less reflective
of pathology, and baseline STJ amplitudes and QRS durations are further from
clinical thresholds. Therefore, quantification of anatomical sex-differences
and impact on ECG in health and disease is critical to avoid clinical sex-bias.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14021" title="Abstract">arXiv:2312.14021</a> (cross-list from eess.AS) [<a href="/pdf/2312.14021" title="Download PDF">pdf</a>, <a href="/format/2312.14021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Visual Supervision for Array-based Active Speaker Detection  and Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Berghi%2C+D">Davide Berghi</a>, 
<a href="/search/eess?searchtype=author&query=Jackson%2C+P+J+B">Philip J. B. Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Conventional audio-visual approaches for active speaker detection (ASD)
typically rely on visually pre-extracted face tracks and the corresponding
single-channel audio to find the speaker in a video. Therefore, they tend to
fail every time the face of the speaker is not visible. We demonstrate that a
simple audio convolutional recurrent neural network (CRNN) trained with spatial
input features extracted from multichannel audio can perform simultaneous
horizontal active speaker detection and localization (ASDL), independently of
the visual modality. To address the time and cost of generating ground truth
labels to train such a system, we propose a new self-supervised training
pipeline that embraces a ``student-teacher'' learning approach. A conventional
pre-trained active speaker detector is adopted as a ``teacher'' network to
provide the position of the speakers as pseudo-labels. The multichannel audio
``student'' network is trained to generate the same results. At inference, the
student network can generalize and locate also the occluded speakers that the
teacher network is not able to detect visually, yielding considerable
improvements in recall rate. Experiments on the TragicTalkers dataset show that
an audio network trained with the proposed self-supervised learning approach
can exceed the performance of the typical audio-visual methods and produce
results competitive with the costly conventional supervised training. We
demonstrate that improvements can be achieved when minimal manual supervision
is introduced in the learning pipeline. Further gains may be sought with larger
training sets and integrating vision with the multichannel audio system.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14027" title="Abstract">arXiv:2312.14027</a> (cross-list from stat.ML) [<a href="/pdf/2312.14027" title="Download PDF">pdf</a>, <a href="/ps/2312.14027" title="Download PostScript">ps</a>, <a href="/format/2312.14027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdamMCMC: Combining Metropolis Adjusted Langevin with Momentum-based  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bieringer%2C+S">Sebastian Bieringer</a>, 
<a href="/search/stat?searchtype=author&query=Kasieczka%2C+G">Gregor Kasieczka</a>, 
<a href="/search/stat?searchtype=author&query=Steffen%2C+M+F">Maximilian F. Steffen</a>, 
<a href="/search/stat?searchtype=author&query=Trabs%2C+M">Mathias Trabs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
<p class="mathjax">Uncertainty estimation is a key issue when considering the application of
deep neural network methods in science and engineering. In this work, we
introduce a novel algorithm that quantifies epistemic uncertainty via Monte
Carlo sampling from a tempered posterior distribution. It combines the well
established Metropolis Adjusted Langevin Algorithm (MALA) with momentum-based
optimization using Adam and leverages a prolate proposal distribution, to
efficiently draw from the posterior. We prove that the constructed chain admits
the Gibbs posterior as an invariant distribution and converges to this Gibbs
posterior in total variation distance. Numerical evaluations are postponed to a
first revision.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14078" title="Abstract">arXiv:2312.14078</a> (cross-list from stat.ML) [<a href="/pdf/2312.14078" title="Download PDF">pdf</a>, <a href="/ps/2312.14078" title="Download PostScript">ps</a>, <a href="/format/2312.14078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned reconstruction methods for inverse problems: sample error  estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ratti%2C+L">Luca Ratti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Learning-based and data-driven techniques have recently become a subject of
primary interest in the field of reconstruction and regularization of inverse
problems. Besides the development of novel methods, yielding excellent results
in several applications, their theoretical investigation has attracted growing
interest, e.g., on the topics of reliability, stability, and interpretability.
In this work, a general framework is described, allowing us to interpret many
of these techniques in the context of statistical learning. This is not
intended to provide a complete survey of existing methods, but rather to put
them in a working perspective, which naturally allows their theoretical
treatment. The main goal of this dissertation is thereby to address the
generalization properties of learned reconstruction methods, and specifically
to perform their sample error analysis. This task, well-developed in
statistical learning, consists in estimating the dependence of the learned
operators with respect to the data employed for their training. A rather
general strategy is proposed, whose assumptions are met for a large class of
inverse problems and learned methods, as depicted via a selection of examples.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14095" title="Abstract">arXiv:2312.14095</a> (cross-list from stat.AP) [<a href="/pdf/2312.14095" title="Download PDF">pdf</a>, <a href="/format/2312.14095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetailSynth: Synthetic Data Generation for Retail AI Systems Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xia%2C+Y">Yu Xia</a>, 
<a href="/search/stat?searchtype=author&query=Arian%2C+A">Ali Arian</a>, 
<a href="/search/stat?searchtype=author&query=Narayanamoorthy%2C+S">Sriram Narayanamoorthy</a>, 
<a href="/search/stat?searchtype=author&query=Mabry%2C+J">Joshua Mabry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
<p class="mathjax">Significant research effort has been devoted in recent years to developing
personalized pricing, promotions, and product recommendation algorithms that
can leverage rich customer data to learn and earn. Systematic benchmarking and
evaluation of these causal learning systems remains a critical challenge, due
to the lack of suitable datasets and simulation environments. In this work, we
propose a multi-stage model for simulating customer shopping behavior that
captures important sources of heterogeneity, including price sensitivity and
past experiences. We embedded this model into a working simulation environment
-- RetailSynth. RetailSynth was carefully calibrated on publicly available
grocery data to create realistic synthetic shopping transactions. Multiple
pricing policies were implemented within the simulator and analyzed for impact
on revenue, category penetration, and customer retention. Applied researchers
can use RetailSynth to validate causal demand models for multi-category retail
and to incorporate realistic price sensitivity into emerging benchmarking
suites for personalized pricing, promotions, and product recommendations.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14116" title="Abstract">arXiv:2312.14116</a> (cross-list from math.AC) [<a href="/pdf/2312.14116" title="Download PDF">pdf</a>, <a href="/ps/2312.14116" title="Download PostScript">ps</a>, <a href="/format/2312.14116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $p$-adic algorithm for bivariate Gr&#xf6;bner bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schost%2C+E">Eric Schost</a>, 
<a href="/search/math?searchtype=author&query=St-Pierre%2C+C">Catherine St-Pierre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (ACM) Proceeding in International Symposium on Symbolic and Algebraic Computation 2023 (ISSAC 2023), July 24--27, 2023, Troms{\o}, Norway
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ISSAC '23: Proceedings of the 2023 International Symposium on
  Symbolic and Algebraic ComputationJuly 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">We present a $p$-adic algorithm to recover the lexicographic Gr\"obner basis
$\mathcal G$ of an ideal in $\mathbb Q[x,y]$ with a generating set in $\mathbb
Z[x,y]$, with a complexity that is less than cubic in terms of the dimension of
$\mathbb Q[x,y]/\langle \mathcal G \rangle$ and softly linear in the height of
its coefficients. We observe that previous results of Lazard's that use Hermite
normal forms to compute Gr\"obner bases for ideals with two generators can be
generalized to a set of $t\in \mathbb N^+$ generators. We use this result to
obtain a bound on the height of the coefficients of $\mathcal G$, and to
control the probability of choosing a \textit{good} prime $p$ to build the
$p$-adic expansion of $\mathcal G$.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14136" title="Abstract">arXiv:2312.14136</a> (cross-list from stat.ML) [<a href="/pdf/2312.14136" title="Download PDF">pdf</a>, <a href="/format/2312.14136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast kernel half-space depth for data with non-convex supports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Castellanos%2C+A">Arturo Castellanos</a>, 
<a href="/search/stat?searchtype=author&query=Mozharovskyi%2C+P">Pavlo Mozharovskyi</a>, 
<a href="/search/stat?searchtype=author&query=d%27Alch%C3%A9-Buc%2C+F">Florence d&#x27;Alch&#xe9;-Buc</a>, 
<a href="/search/stat?searchtype=author&query=Janati%2C+H">Hicham Janati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data depth is a statistical function that generalizes order and quantiles to
the multivariate setting and beyond, with applications spanning over
descriptive and visual statistics, anomaly detection, testing, etc. The
celebrated halfspace depth exploits data geometry via an optimization program
to deliver properties of invariances, robustness, and non-parametricity.
Nevertheless, it implicitly assumes convex data supports and requires
exponential computational cost. To tackle distribution's multimodality, we
extend the halfspace depth in a Reproducing Kernel Hilbert Space (RKHS). We
show that the obtained depth is intuitive and establish its consistency with
provable concentration bounds that allow for homogeneity testing. The proposed
depth can be computed using manifold gradient making faster than halfspace
depth by several orders of magnitude. The performance of our depth is
demonstrated through numerical simulations as well as applications such as
anomaly detection on real data and homogeneity testing.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14141" title="Abstract">arXiv:2312.14141</a> (cross-list from quant-ph) [<a href="/pdf/2312.14141" title="Download PDF">pdf</a>, <a href="/ps/2312.14141" title="Download PostScript">ps</a>, <a href="/format/2312.14141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Algorithms for the Pathwise Lasso
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Doriguello%2C+J+F">Jo&#xe3;o F. Doriguello</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lim%2C+D">Debbie Lim</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pun%2C+C+S">Chi Seng Pun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rebentrost%2C+P">Patrick Rebentrost</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vaidya%2C+T">Tushar Vaidya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present a novel quantum high-dimensional linear regression algorithm with
an $\ell_1$-penalty based on the classical LARS (Least Angle Regression)
pathwise algorithm. Similarly to available classical numerical algorithms for
Lasso, our quantum algorithm provides the full regularisation path as the
penalty term varies, but quadratically faster per iteration under specific
conditions. A quadratic speedup on the number of features/predictors $d$ is
possible by using the simple quantum minimum-finding subroutine from D\"urr and
Hoyer (arXiv'96) in order to obtain the joining time at each iteration. We then
improve upon this simple quantum algorithm and obtain a quadratic speedup both
in the number of features $d$ and the number of observations $n$ by using the
recent approximate quantum minimum-finding subroutine from Chen and de Wolf
(ICALP'23). As one of our main contributions, we construct a quantum unitary
based on quantum amplitude estimation to approximately compute the joining
times to be searched over by the approximate quantum minimum finding. Since the
joining times are no longer exactly computed, it is no longer clear that the
resulting approximate quantum algorithm obtains a good solution. As our second
main contribution, we prove, via an approximate version of the KKT conditions
and a duality gap, that the LARS algorithm (and therefore our quantum
algorithm) is robust to errors. This means that it still outputs a path that
minimises the Lasso cost function up to a small error if the joining times are
only approximately computed. Finally, in the model where the observations are
generated by an underlying linear model with an unknown coefficient vector, we
prove bounds on the difference between the unknown coefficient vector and the
approximate Lasso solution, which generalises known results about convergence
rates in classical statistical learning theory analysis.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 22 Dec 23</h3>
<dl>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1612.04338" title="Abstract">arXiv:1612.04338</a> (replaced) [<a href="/pdf/1612.04338" title="Download PDF">pdf</a>, <a href="/ps/1612.04338" title="Download PostScript">ps</a>, <a href="/format/1612.04338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Tensor Rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaefer%2C+M">Marcus Schaefer</a>, 
<a href="/search/cs?searchtype=author&query=Stefankovic%2C+D">Daniel Stefankovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> fixed error in Section 3.3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1712.00615" title="Abstract">arXiv:1712.00615</a> (replaced) [<a href="/pdf/1712.00615" title="Download PDF">pdf</a>, <a href="/ps/1712.00615" title="Download PostScript">ps</a>, <a href="/format/1712.00615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Group Testing Algorithms to Estimate the Number of Defectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bshouty%2C+N+H">Nader H. Bshouty</a>, 
<a href="/search/cs?searchtype=author&query=Bshouty-Hurani%2C+V+E">Vivian E. Bshouty-Hurani</a>, 
<a href="/search/cs?searchtype=author&query=Haddad%2C+G">George Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Hashem%2C+T">Thomas Hashem</a>, 
<a href="/search/cs?searchtype=author&query=Khoury%2C+F">Fadi Khoury</a>, 
<a href="/search/cs?searchtype=author&query=Sharafy%2C+O">Omar Sharafy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.01714" title="Abstract">arXiv:1908.01714</a> (replaced) [<a href="/pdf/1908.01714" title="Download PDF">pdf</a>, <a href="/ps/1908.01714" title="Download PostScript">ps</a>, <a href="/format/1908.01714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow Allocation Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertschinger%2C+N">Nils Bertschinger</a>, 
<a href="/search/cs?searchtype=author&query=Hoefer%2C+M">Martin Hoefer</a>, 
<a href="/search/cs?searchtype=author&query=Schmand%2C+D">Daniel Schmand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; General Finance (q-fin.GN); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.00062" title="Abstract">arXiv:2009.00062</a> (replaced) [<a href="/pdf/2009.00062" title="Download PDF">pdf</a>, <a href="/format/2009.00062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contingent Convertible Bonds in Financial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Calice%2C+G">Giovanni Calice</a>, 
<a href="/search/q-fin?searchtype=author&query=Sala%2C+C">Carlo Sala</a>, 
<a href="/search/q-fin?searchtype=author&query=Tantari%2C+D">Daniele Tantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Scientific Reports 13.1 (2023): 22337
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Social and Information Networks (cs.SI); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.07622" title="Abstract">arXiv:2102.07622</a> (replaced) [<a href="/pdf/2102.07622" title="Download PDF">pdf</a>, <a href="/format/2102.07622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth lower bounds in Stabbing Planes for combinatorial principles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dantchev%2C+S">Stefan Dantchev</a>, 
<a href="/search/cs?searchtype=author&query=Galesi%2C+N">Nicola Galesi</a>, 
<a href="/search/cs?searchtype=author&query=Ghani%2C+A">Abdul Ghani</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+B">Barnaby Martin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.08526" title="Abstract">arXiv:2105.08526</a> (replaced) [<a href="/pdf/2105.08526" title="Download PDF">pdf</a>, <a href="/format/2105.08526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers &#xe0; Grande Vitesse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arthaud%2C+F">Farid Arthaud</a>, 
<a href="/search/cs?searchtype=author&query=Lecoeur%2C+G">Guillaume Lecoeur</a>, 
<a href="/search/cs?searchtype=author&query=Pierre%2C+A">Alban Pierre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages including 1 page of appendices, 5 figures. Presented at IAROR RailBelgrade 2023 and published in Journal of Rail Transport P&amp;M
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Rail Transport Planning &amp; Management, Volume 29, 2024,
  100418, ISSN 2210-9706
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.10936" title="Abstract">arXiv:2107.10936</a> (replaced) [<a href="/pdf/2107.10936" title="Download PDF">pdf</a>, <a href="/ps/2107.10936" title="Download PostScript">ps</a>, <a href="/format/2107.10936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Session Types for the $&#x3c0;$-calculus (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arslanagic%2C+A">Alen Arslanagic</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+A">Jorge A. P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Palamariuc%2C+A">Anda-Amelia Palamariuc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a PPDP 2021 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.02893" title="Abstract">arXiv:2108.02893</a> (replaced) [<a href="/pdf/2108.02893" title="Download PDF">pdf</a>, <a href="/format/2108.02893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Basis Scaling and Double Pruning for Efficient Inference in  Network-Based Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+C+L">Ken C. L. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+S">Satyananda Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+M">Mehdi Moradi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.09749" title="Abstract">arXiv:2110.09749</a> (replaced) [<a href="/pdf/2110.09749" title="Download PDF">pdf</a>, <a href="/format/2110.09749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance Estimation from Multiple Perspectives for Keyphrase  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liping Jing</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lin Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, Accepted by EMNLP2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.10197" title="Abstract">arXiv:2201.10197</a> (replaced) [<a href="/pdf/2201.10197" title="Download PDF">pdf</a>, <a href="/format/2201.10197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Actuator Selection and Controller Design for Linear Quadratic  Regulation with Unknown System Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ye%2C+L">Lintao Ye</a>, 
<a href="/search/math?searchtype=author&query=Chi%2C+M">Ming Chi</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhi-Wei Liu</a>, 
<a href="/search/math?searchtype=author&query=Gupta%2C+V">Vijay Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02980" title="Abstract">arXiv:2202.02980</a> (replaced) [<a href="/pdf/2202.02980" title="Download PDF">pdf</a>, <a href="/format/2202.02980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Object Detection from Images for Autonomous Driving: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinzhu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Simonelli%2C+A">Andrea Simonelli</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by T-PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00400" title="Abstract">arXiv:2205.00400</a> (replaced) [<a href="/pdf/2205.00400" title="Download PDF">pdf</a>, <a href="/format/2205.00400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Potential of Adjacent Snippets for Weakly-supervised  Temporal Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhilin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICME2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02047" title="Abstract">arXiv:2205.02047</a> (replaced) [<a href="/pdf/2205.02047" title="Download PDF">pdf</a>, <a href="/format/2205.02047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperbolic Relevance Matching for Neural Keyphrase Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liping Jing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, Accepted by NAACL2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12597" title="Abstract">arXiv:2205.12597</a> (replaced) [<a href="/pdf/2205.12597" title="Download PDF">pdf</a>, <a href="/format/2205.12597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Leader Election in Population Protocols on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>, 
<a href="/search/cs?searchtype=author&query=Rybicki%2C+J">Joel Rybicki</a>, 
<a href="/search/cs?searchtype=author&query=Voitovych%2C+S">Sasha Voitovych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages, 2 figures, revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12703" title="Abstract">arXiv:2205.12703</a> (replaced) [<a href="/pdf/2205.12703" title="Download PDF">pdf</a>, <a href="/format/2205.12703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All about unambiguous polynomial closure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Place%2C+T">Thomas Place</a>, 
<a href="/search/cs?searchtype=author&query=Zeitoun%2C+M">Marc Zeitoun</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TheoretiCS, Volume 2 (2023), Article 11, 1-74
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08965" title="Abstract">arXiv:2206.08965</a> (replaced) [<a href="/pdf/2206.08965" title="Download PDF">pdf</a>, <a href="/format/2206.08965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KitBit: A New AI Model for Solving Intelligence Tests and Numerical  Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corsino%2C+V">V&#xed;ctor Corsino</a>, 
<a href="/search/cs?searchtype=author&query=Gilp%C3%A9rez%2C+J+M">Jos&#xe9; Manuel Gilp&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Herrera%2C+L">Luis Herrera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Corsino, V., Gilperez, J. M., &amp; Herrera, L. (2023). "KitBit: A New
  AI Model for Solving Intelligence Tests and Numerical Series." IEEE
  Transactions on Pattern Analysis and Machine Intelligence, 45(11),
  13893-13903
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14203" title="Abstract">arXiv:2206.14203</a> (replaced) [<a href="/pdf/2206.14203" title="Download PDF">pdf</a>, <a href="/format/2206.14203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Combinational Game Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Anurag Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+S">Seth Cooper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, IEEE Transactions on Games
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10752" title="Abstract">arXiv:2208.10752</a> (replaced) [<a href="/pdf/2208.10752" title="Download PDF">pdf</a>, <a href="/format/2208.10752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reach-Avoid Analysis for Polynomial Stochastic Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xue%2C+B">Bai Xue</a>, 
<a href="/search/math?searchtype=author&query=Zhan%2C+N">Naijun Zhan</a>, 
<a href="/search/math?searchtype=author&query=Fr%C3%A4nzle%2C+M">Martin Fr&#xe4;nzle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TAC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11326" title="Abstract">arXiv:2209.11326</a> (replaced) [<a href="/pdf/2209.11326" title="Download PDF">pdf</a>, <a href="/format/2209.11326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faithful Model Explanation in NLP: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Q">Qing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Apidianaki%2C+M">Marianna Apidianaki</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision round #2 for the Computational Linguistics journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02998" title="Abstract">arXiv:2210.02998</a> (replaced) [<a href="/pdf/2210.02998" title="Download PDF">pdf</a>, <a href="/format/2210.02998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ThoraX-PriorNet: A Novel Attention-Based Architecture Using Anatomical  Prior Probability Maps for Thoracic Disease Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hossain%2C+M+I">Md. Iqbal Hossain</a>, 
<a href="/search/eess?searchtype=author&query=Zunaed%2C+M">Mohammad Zunaed</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+M+K">Md. Kawsar Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Hossain%2C+S+M+J">S. M. Jawwad Hossain</a>, 
<a href="/search/eess?searchtype=author&query=Hasan%2C+A">Anwarul Hasan</a>, 
<a href="/search/eess?searchtype=author&query=Hasan%2C+T">Taufiq Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ACCESS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09964" title="Abstract">arXiv:2210.09964</a> (replaced) [<a href="/pdf/2210.09964" title="Download PDF">pdf</a>, <a href="/format/2210.09964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Evaluation of Arbitrary Relational Calculus Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raszyk%2C+M">Martin Raszyk</a>, 
<a href="/search/cs?searchtype=author&query=Basin%2C+D">David Basin</a>, 
<a href="/search/cs?searchtype=author&query=Krsti%C4%87%2C+S">Sr&#x111;an Krsti&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Traytel%2C+D">Dmitriy Traytel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10619" title="Abstract">arXiv:2210.10619</a> (replaced) [<a href="/pdf/2210.10619" title="Download PDF">pdf</a>, <a href="/format/2210.10619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restricted Bernoulli Matrix Factorization: Balancing the trade-off  between prediction accuracy and coverage in classification based  collaborative filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Prieto%2C+%C3%81">&#xc1;ngel Gonz&#xe1;lez-Prieto</a>, 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez%2C+A">Abraham Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+F">Fernando Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Lara-Cabrera%2C+R">Ra&#xfa;l Lara-Cabrera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Several changes performed, including a title change. 21 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11510" title="Abstract">arXiv:2210.11510</a> (replaced) [<a href="/pdf/2210.11510" title="Download PDF">pdf</a>, <a href="/format/2210.11510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Attitude Estimation Using Intermittent and Multi-Rate Vector  Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Miaomiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, this work has been accepted for publication in IEEE TAC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14404" title="Abstract">arXiv:2210.14404</a> (replaced) [<a href="/pdf/2210.14404" title="Download PDF">pdf</a>, <a href="/format/2210.14404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Purification with the Manifold Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Peter Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of paper accepted at AAAI 2024 with supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15136" title="Abstract">arXiv:2210.15136</a> (replaced) [<a href="/pdf/2210.15136" title="Download PDF">pdf</a>, <a href="/ps/2210.15136" title="Download PostScript">ps</a>, <a href="/format/2210.15136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Shape Knowledge Graph for Cross-domain 3D Shape Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Rihao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yongtao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+T">Tong Hao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01877" title="Abstract">arXiv:2211.01877</a> (replaced) [<a href="/pdf/2211.01877" title="Download PDF">pdf</a>, <a href="/format/2211.01877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Clustering through MM: An Efficient Algorithm to Perform  Hierarchical Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Touw%2C+D+J+W">Daniel J. W. Touw</a>, 
<a href="/search/stat?searchtype=author&query=Groenen%2C+P+J+F">Patrick J. F. Groenen</a>, 
<a href="/search/stat?searchtype=author&query=Terada%2C+Y">Yoshikazu Terada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02843" title="Abstract">arXiv:2211.02843</a> (replaced) [<a href="/pdf/2211.02843" title="Download PDF">pdf</a>, <a href="/format/2211.02843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Graph Data Augmentation on Covariate  Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yongduo Sui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qitian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiancan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06624" title="Abstract">arXiv:2211.06624</a> (replaced) [<a href="/pdf/2211.06624" title="Download PDF">pdf</a>, <a href="/ps/2211.06624" title="Download PostScript">ps</a>, <a href="/format/2211.06624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Barzilai-Borwein method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=An%2C+C">Congpei An</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07864" title="Abstract">arXiv:2211.07864</a> (replaced) [<a href="/pdf/2211.07864" title="Download PDF">pdf</a>, <a href="/format/2211.07864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Adaptive Prompt Tuning for Multi-domain Collaborative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shangchao Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingzhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13495" title="Abstract">arXiv:2211.13495</a> (replaced) [<a href="/pdf/2211.13495" title="Download PDF">pdf</a>, <a href="/format/2211.13495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Object Detection with Refined Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Z">Zeyu Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+L">Lian Huai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xingqun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14236" title="Abstract">arXiv:2211.14236</a> (replaced) [<a href="/pdf/2211.14236" title="Download PDF">pdf</a>, <a href="/format/2211.14236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategyproof Decision-Making in Panel Data Settings and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Harris%2C+K">Keegan Harris</a>, 
<a href="/search/econ?searchtype=author&query=Agarwal%2C+A">Anish Agarwal</a>, 
<a href="/search/econ?searchtype=author&query=Podimata%2C+C">Chara Podimata</a>, 
<a href="/search/econ?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the fiftieth ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14742" title="Abstract">arXiv:2211.14742</a> (replaced) [<a href="/pdf/2211.14742" title="Download PDF">pdf</a>, <a href="/format/2211.14742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Feature Pruning and Consolidation for Occluded Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">YuTeng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jiale Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chenxing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12846" title="Abstract">arXiv:2212.12846</a> (replaced) [<a href="/e-print/2212.12846" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On rate of convergence of finite difference scheme for degenerate  parabolic-hyperbolic PDE with Levy noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Behera%2C+S+R">Soumya Ranjan Behera</a>, 
<a href="/search/math?searchtype=author&query=Majee%2C+A+K">Ananta K. Majee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We found an error in Lemma 3.5.--which is used in the subsequent analysis to establish the rate of convergence. Since the error is not fixable, we would like to withdraw the article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00114" title="Abstract">arXiv:2301.00114</a> (replaced) [<a href="/pdf/2301.00114" title="Download PDF">pdf</a>, <a href="/format/2301.00114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skeletal Video Anomaly Detection using Deep Learning: Survey, Challenges  and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P+K">Pratik K. Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Mihailidis%2C+A">Alex Mihailidis</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+S">Shehroz S. Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01841" title="Abstract">arXiv:2301.01841</a> (replaced) [<a href="/pdf/2301.01841" title="Download PDF">pdf</a>, <a href="/ps/2301.01841" title="Download PostScript">ps</a>, <a href="/format/2301.01841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Single Tree Decay Stages from Combined Airborne LiDAR  Data and CIR Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+T+C">Tsz Chung Wong</a>, 
<a href="/search/cs?searchtype=author&query=Sani-Mohammed%2C+A">Abubakar Sani-Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Puzuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Heurich%2C+M">Marco Heurich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03924" title="Abstract">arXiv:2301.03924</a> (replaced) [<a href="/pdf/2301.03924" title="Download PDF">pdf</a>, <a href="/format/2301.03924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven adjoint-based calibration of port-Hamiltonian systems in  time domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=G%C3%BCnther%2C+M">Michael G&#xfc;nther</a>, 
<a href="/search/math?searchtype=author&query=Jacob%2C+B">Birgit Jacob</a>, 
<a href="/search/math?searchtype=author&query=Totzeck%2C+C">Claudia Totzeck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11442" title="Abstract">arXiv:2301.11442</a> (replaced) [<a href="/pdf/2301.11442" title="Download PDF">pdf</a>, <a href="/format/2301.11442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Collaborative Regret Minimization in Multi-Armed  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karpov%2C+N">Nikolai Karpov</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13850" title="Abstract">arXiv:2301.13850</a> (replaced) [<a href="/pdf/2301.13850" title="Download PDF">pdf</a>, <a href="/ps/2301.13850" title="Download PostScript">ps</a>, <a href="/format/2301.13850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Gaussian Noise Mechanisms and Their Optimality for Unbiased Mean  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nikolov%2C+A">Aleksandar Nikolov</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+H">Haohua Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper title was changed in v2, and more material on general Gaussian noise mechanisms was added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03616" title="Abstract">arXiv:2302.03616</a> (replaced) [<a href="/pdf/2302.03616" title="Download PDF">pdf</a>, <a href="/ps/2302.03616" title="Download PostScript">ps</a>, <a href="/format/2302.03616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can gamification reduce the burden of self-reporting in mHealth  applications? A feasibility study using machine learning from smartwatch data  to estimate cognitive load
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grzeszczyk%2C+M+K">Michal K. Grzeszczyk</a>, 
<a href="/search/cs?searchtype=author&query=Adamczyk%2C+P">Paulina Adamczyk</a>, 
<a href="/search/cs?searchtype=author&query=Marek%2C+S">Sylwia Marek</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C4%99cikowski%2C+R">Ryszard Pr&#x119;cikowski</a>, 
<a href="/search/cs?searchtype=author&query=Ku%C5%9B%2C+M">Maciej Ku&#x15b;</a>, 
<a href="/search/cs?searchtype=author&query=Lelujko%2C+M+P">M. Patrycja Lelujko</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+R">Rosmary Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Sitek%2C+A">Arkadiusz Sitek</a>, 
<a href="/search/cs?searchtype=author&query=Malawski%2C+M">Maciej Malawski</a>, 
<a href="/search/cs?searchtype=author&query=Lisowska%2C+A">Aneta Lisowska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for AMIA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07706" title="Abstract">arXiv:2302.07706</a> (replaced) [<a href="/pdf/2302.07706" title="Download PDF">pdf</a>, <a href="/format/2302.07706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional UWB Localization: A Review on an Elastic Positioning  Scheme for GNSS-deprived Zones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sang%2C+C+L">Cung Lian Sang</a>, 
<a href="/search/eess?searchtype=author&query=Adams%2C+M">Michael Adams</a>, 
<a href="/search/eess?searchtype=author&query=Hesse%2C+M">Marc Hesse</a>, 
<a href="/search/eess?searchtype=author&query=R%C3%BCckert%2C+U">Ulrich R&#xfc;ckert</a> (Cognitronics and Sensor Systems Group, CITEC, Bielefeld University, Bielefeld, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Journal of Indoor and Seamless Positioning and Navigation,
  2023, vol. 1, pp. 161 - 179
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11883" title="Abstract">arXiv:2302.11883</a> (replaced) [<a href="/pdf/2302.11883" title="Download PDF">pdf</a>, <a href="/format/2302.11883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIFON-EPT: MR-Based Electrical Property Tomography Using  Physics-Informed Fourier Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinling Yu</a>, 
<a href="/search/cs?searchtype=author&query=Serrall%C3%A9s%2C+J+E+C">Jos&#xe9; E. C. Serrall&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Giannakopoulos%2C+I+I">Ilias I. Giannakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+L">Luca Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Lattanzi%2C+R">Riccardo Lattanzi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by IEEE JMMCT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13141" title="Abstract">arXiv:2302.13141</a> (replaced) [<a href="/pdf/2302.13141" title="Download PDF">pdf</a>, <a href="/format/2302.13141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Printed Proprioceptive Soft Fluidic Actuators with Graded Porosity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willemstein%2C+N">Nick Willemstein</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Kooij%2C+H">Herman van der Kooij</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ali Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revisions to story and figures, but results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00586" title="Abstract">arXiv:2303.00586</a> (replaced) [<a href="/pdf/2303.00586" title="Download PDF">pdf</a>, <a href="/format/2303.00586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ko%2C+W">Wei-Yin Ko</a>, 
<a href="/search/stat?searchtype=author&query=D%27souza%2C+D">Daniel D&#x27;souza</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+K">Karina Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Balestriero%2C+R">Randall Balestriero</a>, 
<a href="/search/stat?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02846" title="Abstract">arXiv:2303.02846</a> (replaced) [<a href="/pdf/2303.02846" title="Download PDF">pdf</a>, <a href="/format/2303.02846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive variational information bottleneck for aspect-based  sentiment analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Mingshan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qingshan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Knowledge-Based Systems (KBS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06058" title="Abstract">arXiv:2303.06058</a> (replaced) [<a href="/pdf/2303.06058" title="Download PDF">pdf</a>, <a href="/ps/2303.06058" title="Download PostScript">ps</a>, <a href="/format/2303.06058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Recipe for the Analysis of Randomized Multi-Armed Bandit  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baudry%2C+D">Dorian Baudry</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Kazuya Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+J">Junya Honda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06088" title="Abstract">arXiv:2303.06088</a> (replaced) [<a href="/pdf/2303.06088" title="Download PDF">pdf</a>, <a href="/format/2303.06088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards domain-invariant Self-Supervised Learning with Batch Styles  Standardization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scalbert%2C+M">Marin Scalbert</a>, 
<a href="/search/cs?searchtype=author&query=Vakalopoulou%2C+M">Maria Vakalopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Couzini%C3%A9-Devy%2C+F">Florent Couzini&#xe9;-Devy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review as conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09449" title="Abstract">arXiv:2303.09449</a> (replaced) [<a href="/pdf/2303.09449" title="Download PDF">pdf</a>, <a href="/format/2303.09449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proof Number Based Monte-Carlo Tree Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+J">Jakub Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Doe%2C+E">Elliot Doe</a>, 
<a href="/search/cs?searchtype=author&query=Winands%2C+M+H+M">Mark H. M. Winands</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3rski%2C+D">Daniel G&#xf3;rski</a>, 
<a href="/search/cs?searchtype=author&query=Soemers%2C+D+J+N+J">Dennis J. N. J. Soemers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of <a href="/abs/2206.03965">arXiv:2206.03965</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10512" title="Abstract">arXiv:2303.10512</a> (replaced) [<a href="/pdf/2303.10512" title="Download PDF">pdf</a>, <a href="/format/2303.10512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minshuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bukharin%2C+A">Alexander Bukharin</a>, 
<a href="/search/cs?searchtype=author&query=Karampatziakis%2C+N">Nikos Karampatziakis</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 11th International Conference on Learning Representations (ICLR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11032" title="Abstract">arXiv:2303.11032</a> (replaced) [<a href="/pdf/2303.11032" title="Download PDF">pdf</a>, <a href="/format/2303.11032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaowei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Haixing Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+P">Peng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+F">Fang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanzheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dajiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14496" title="Abstract">arXiv:2303.14496</a> (replaced) [<a href="/pdf/2303.14496" title="Download PDF">pdf</a>, <a href="/format/2303.14496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Explanation Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pukdee%2C+R">Rattana Pukdee</a>, 
<a href="/search/cs?searchtype=author&query=Sam%2C+D">Dylan Sam</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Balcan%2C+M">Maria-Florina Balcan</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17321" title="Abstract">arXiv:2303.17321</a> (replaced) [<a href="/pdf/2303.17321" title="Download PDF">pdf</a>, <a href="/format/2303.17321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalent Conditions for the Synchronization of Identical Linear  Systems over Arbitrary Interconnections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zaupa%2C+N">Nicola Zaupa</a>, 
<a href="/search/eess?searchtype=author&query=Giordano%2C+G">Giulia Giordano</a>, 
<a href="/search/eess?searchtype=author&query=Queinnec%2C+I">Isabelle Queinnec</a>, 
<a href="/search/eess?searchtype=author&query=Tarbouriech%2C+S">Sophie Tarbouriech</a>, 
<a href="/search/eess?searchtype=author&query=Zaccarian%2C+L">Luca Zaccarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17564" title="Abstract">arXiv:2303.17564</a> (replaced) [<a href="/pdf/2303.17564" title="Download PDF">pdf</a>, <a href="/format/2303.17564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BloombergGPT: A Large Language Model for Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shijie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Irsoy%2C+O">Ozan Irsoy</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Steven Lu</a>, 
<a href="/search/cs?searchtype=author&query=Dabravolski%2C+V">Vadim Dabravolski</a>, 
<a href="/search/cs?searchtype=author&query=Dredze%2C+M">Mark Dredze</a>, 
<a href="/search/cs?searchtype=author&query=Gehrmann%2C+S">Sebastian Gehrmann</a>, 
<a href="/search/cs?searchtype=author&query=Kambadur%2C+P">Prabhanjan Kambadur</a>, 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+D">David Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+G">Gideon Mann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated to include Training Chronicles (Appendix C)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); General Finance (q-fin.GN)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01854" title="Abstract">arXiv:2304.01854</a> (replaced) [<a href="/pdf/2304.01854" title="Download PDF">pdf</a>, <a href="/format/2304.01854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fully-automatic Side-scan Sonar SLAM Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiping Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+L">Li Ling</a>, 
<a href="/search/cs?searchtype=author&query=Folkesson%2C+J">John Folkesson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03693" title="Abstract">arXiv:2304.03693</a> (replaced) [<a href="/pdf/2304.03693" title="Download PDF">pdf</a>, <a href="/format/2304.03693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Agnostic Gender Debiased Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirota%2C+Y">Yusuke Hirota</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+N">Noa Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03907" title="Abstract">arXiv:2304.03907</a> (replaced) [<a href="/pdf/2304.03907" title="Download PDF">pdf</a>, <a href="/format/2304.03907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tongzheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaolin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haitong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Compared to v1, added analysis of Nystrom features, more streamlined proofs, and more extensive numerical studies; compared to v2, corrected a small error in ordering of author list
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04273" title="Abstract">arXiv:2304.04273</a> (replaced) [<a href="/pdf/2304.04273" title="Download PDF">pdf</a>, <a href="/format/2304.04273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Brain-Computer Interface for In-Vehicle Driver Cognitive Load  Measurement: Dataset and Baselines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angkan%2C+P">Prithila Angkan</a>, 
<a href="/search/cs?searchtype=author&query=Behinaein%2C+B">Behnam Behinaein</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+Z">Zunayed Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Bhatti%2C+A">Anubhav Bhatti</a>, 
<a href="/search/cs?searchtype=author&query=Rodenburg%2C+D">Dirk Rodenburg</a>, 
<a href="/search/cs?searchtype=author&query=Hungler%2C+P">Paul Hungler</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 11 tables. This work has been accepted to the IEEE Transactions on Intelligent Transportation Systems. \c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05483" title="Abstract">arXiv:2304.05483</a> (replaced) [<a href="/pdf/2304.05483" title="Download PDF">pdf</a>, <a href="/format/2304.05483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contingency Games for Multi-Agent Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peters%2C+L">Lasse Peters</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+C">Chih-Yuan Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+F">Forrest Laine</a>, 
<a href="/search/cs?searchtype=author&query=Ferranti%2C+L">Laura Ferranti</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06762" title="Abstract">arXiv:2304.06762</a> (replaced) [<a href="/pdf/2304.06762" title="Download PDF">pdf</a>, <a href="/format/2304.06762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shall We Pretrain Autoregressive Language Models with Retrieval? A  Comprehensive Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=McAfee%2C+L">Lawrence McAfee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Kuchaiev%2C+O">Oleksii Kuchaiev</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09854" title="Abstract">arXiv:2304.09854</a> (replaced) [<a href="/pdf/2304.09854" title="Download PDF">pdf</a>, <a href="/format/2304.09854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-Based Visual Segmentation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haobo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangliang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Github: <a href="https://github.com/lxtGH/Awesome-Segmentation-With-Transformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10142" title="Abstract">arXiv:2304.10142</a> (replaced) [<a href="/pdf/2304.10142" title="Download PDF">pdf</a>, <a href="/format/2304.10142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attitude-Estimation-Free GNSS and IMU Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RA-L), vol. 9, no. 2, pp.
  1090-1097, Feb. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10549" title="Abstract">arXiv:2304.10549</a> (replaced) [<a href="/pdf/2304.10549" title="Download PDF">pdf</a>, <a href="/ps/2304.10549" title="Download PostScript">ps</a>, <a href="/format/2304.10549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on the connectedness property of union-free generic sets of  partial orders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schollmeyer%2C+G">Georg Schollmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Blocher%2C+H">Hannah Blocher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03815" title="Abstract">arXiv:2305.03815</a> (replaced) [<a href="/pdf/2305.03815" title="Download PDF">pdf</a>, <a href="/format/2305.03815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persistent Homology Meets Object Unity: Object Recognition in Clutter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samani%2C+E+U">Ekta U. Samani</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A+G">Ashis G. Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted for publication in the IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04743" title="Abstract">arXiv:2305.04743</a> (replaced) [<a href="/pdf/2305.04743" title="Download PDF">pdf</a>, <a href="/format/2305.04743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARS: Mask Attention Refinement with Sequential Quadtree Nodes for Car  Damage Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panboonyuen%2C+T">Teerapong Panboonyuen</a>, 
<a href="/search/cs?searchtype=author&query=Nithisopa%2C+N">Naphat Nithisopa</a>, 
<a href="/search/cs?searchtype=author&query=Pienroj%2C+P">Panin Pienroj</a>, 
<a href="/search/cs?searchtype=author&query=Jirachuphun%2C+L">Laphonchai Jirachuphun</a>, 
<a href="/search/cs?searchtype=author&query=Watthanasirikrit%2C+C">Chaiwasut Watthanasirikrit</a>, 
<a href="/search/cs?searchtype=author&query=Pornwiriyakul%2C+N">Naruepon Pornwiriyakul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages. arXiv admin note: substantial text overlap with <a href="/abs/2111.13673">arXiv:2111.13673</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05807" title="Abstract">arXiv:2305.05807</a> (replaced) [<a href="/pdf/2305.05807" title="Download PDF">pdf</a>, <a href="/format/2305.05807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Even Small Correlation and Diversity Shifts Pose Dataset-Bias Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bissoto%2C+A">Alceu Bissoto</a>, 
<a href="/search/cs?searchtype=author&query=Barata%2C+C">Catarina Barata</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+E">Eduardo Valle</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+S">Sandra Avila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper under consideration at Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10300" title="Abstract">arXiv:2305.10300</a> (replaced) [<a href="/pdf/2305.10300" title="Download PDF">pdf</a>, <a href="/format/2305.10300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Prompt to Segment All Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Junde Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jiayuan Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yuanpei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Y">Yueming Jin</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.12620">arXiv:2304.12620</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11650" title="Abstract">arXiv:2305.11650</a> (replaced) [<a href="/pdf/2305.11650" title="Download PDF">pdf</a>, <a href="/format/2305.11650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moment Matching Denoising Gibbs Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Hawkins-Hooker%2C+A">Alex Hawkins-Hooker</a>, 
<a href="/search/stat?searchtype=author&query=Paige%2C+B">Brooks Paige</a>, 
<a href="/search/stat?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12743" title="Abstract">arXiv:2305.12743</a> (replaced) [<a href="/pdf/2305.12743" title="Download PDF">pdf</a>, <a href="/format/2305.12743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Invariant Multi-view Clustering with Fully Incomplete  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+P">Pengxin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mouxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yiding Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Peng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14961" title="Abstract">arXiv:2305.14961</a> (replaced) [<a href="/pdf/2305.14961" title="Download PDF">pdf</a>, <a href="/format/2305.14961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Survival Analysis: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wiegrebe%2C+S">Simon Wiegrebe</a>, 
<a href="/search/stat?searchtype=author&query=Kopper%2C+P">Philipp Kopper</a>, 
<a href="/search/stat?searchtype=author&query=Sonabend%2C+R">Raphael Sonabend</a>, 
<a href="/search/stat?searchtype=author&query=Bischl%2C+B">Bernd Bischl</a>, 
<a href="/search/stat?searchtype=author&query=Bender%2C+A">Andreas Bender</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 7 figures, 2 tables, 1 interactive table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15194" title="Abstract">arXiv:2305.15194</a> (replaced) [<a href="/pdf/2305.15194" title="Download PDF">pdf</a>, <a href="/format/2305.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungnyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junsoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kibeom Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daesik Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+N">Namhyuk Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://sungnyun.github.io/diffblender/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15616" title="Abstract">arXiv:2305.15616</a> (replaced) [<a href="/pdf/2305.15616" title="Download PDF">pdf</a>, <a href="/format/2305.15616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reversible and irreversible bracket-based dynamics for deep graph neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruber%2C+A">Anthony Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Trask%2C+N">Nathaniel Trask</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15755" title="Abstract">arXiv:2305.15755</a> (replaced) [<a href="/pdf/2305.15755" title="Download PDF">pdf</a>, <a href="/format/2305.15755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic policy gradient based optimal control with probabilistic  constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Naha%2C+A">Arunava Naha</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+S">Subhrakanti Dey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to L4DC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16150" title="Abstract">arXiv:2305.16150</a> (replaced) [<a href="/pdf/2305.16150" title="Download PDF">pdf</a>, <a href="/format/2305.16150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying GANs and Score-Based Diffusion as Generative Particle Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franceschi%2C+J">Jean-Yves Franceschi</a>, 
<a href="/search/cs?searchtype=author&query=Gartrell%2C+M">Mike Gartrell</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+L+D">Ludovic Dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Issenhuth%2C+T">Thibaut Issenhuth</a>, 
<a href="/search/cs?searchtype=author&query=de+B%C3%A9zenac%2C+E">Emmanuel de B&#xe9;zenac</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Micka&#xeb;l Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rakotomamonjy%2C+A">Alain Rakotomamonjy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing
  Systems, Neural Information Processing Systems Foundation, Dec. 2023, New
  Orleans, LA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18199" title="Abstract">arXiv:2305.18199</a> (replaced) [<a href="/pdf/2305.18199" title="Download PDF">pdf</a>, <a href="/ps/2305.18199" title="Download PostScript">ps</a>, <a href="/format/2305.18199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of Rim-Located Reconfigurable Reflectarrays for Interference  Mitigation in Reflector Antennas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Budhu%2C+J">Jordan Budhu</a>, 
<a href="/search/eess?searchtype=author&query=Hum%2C+S+V">Sean V. Hum</a>, 
<a href="/search/eess?searchtype=author&query=Ellingson%2C+S">Steven Ellingson</a>, 
<a href="/search/eess?searchtype=author&query=Buehrer%2C+R+M">R. Michael Buehrer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18273" title="Abstract">arXiv:2305.18273</a> (replaced) [<a href="/pdf/2305.18273" title="Download PDF">pdf</a>, <a href="/format/2305.18273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pix2Repair: Implicit Shape Restoration from Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xinchao Song</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+N">Nikolas Lamb</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sean Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18295" title="Abstract">arXiv:2305.18295</a> (replaced) [<a href="/pdf/2305.18295" title="Download PDF">pdf</a>, <a href="/format/2305.18295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zeyue Xue</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanglu Song</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qiushan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Z">Zhuofan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18900" title="Abstract">arXiv:2305.18900</a> (replaced) [<a href="/pdf/2305.18900" title="Download PDF">pdf</a>, <a href="/format/2305.18900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Line-of-Code Data Mollification Improves Optimization of  Likelihood-based Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+B">Ba-Hien Tran</a>, 
<a href="/search/cs?searchtype=author&query=Franzese%2C+G">Giulio Franzese</a>, 
<a href="/search/cs?searchtype=author&query=Michiardi%2C+P">Pietro Michiardi</a>, 
<a href="/search/cs?searchtype=author&query=Filippone%2C+M">Maurizio Filippone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00292" title="Abstract">arXiv:2306.00292</a> (replaced) [<a href="/pdf/2306.00292" title="Download PDF">pdf</a>, <a href="/ps/2306.00292" title="Download PostScript">ps</a>, <a href="/format/2306.00292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable AI Regulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hacker%2C+P">Philipp Hacker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Privacy Law Scholars Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01423" title="Abstract">arXiv:2306.01423</a> (replaced) [<a href="/pdf/2306.01423" title="Download PDF">pdf</a>, <a href="/format/2306.01423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Gradient-Trend Identification: Fast-Adaptive Moment Estimation  with Finance-Inspired Triple Exponential Moving Average
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peleg%2C+R">Roi Peleg</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>, 
<a href="/search/cs?searchtype=author&query=Hoogi%2C+A">Assaf Hoogi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02363" title="Abstract">arXiv:2306.02363</a> (replaced) [<a href="/pdf/2306.02363" title="Download PDF">pdf</a>, <a href="/format/2306.02363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inviscid Water-Waves and interface modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Dormy%2C+E">Emmanuel Dormy</a>, 
<a href="/search/math-ph?searchtype=author&query=Lacave%2C+C">Christophe Lacave</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Quarterly of Applied Mathematics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03173" title="Abstract">arXiv:2306.03173</a> (replaced) [<a href="/pdf/2306.03173" title="Download PDF">pdf</a>, <a href="/format/2306.03173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Distance Metric Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alishahi%2C+M">Meysam Alishahi</a>, 
<a href="/search/cs?searchtype=author&query=Little%2C+A">Anna Little</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M. Phillips</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03475" title="Abstract">arXiv:2306.03475</a> (replaced) [<a href="/pdf/2306.03475" title="Download PDF">pdf</a>, <a href="/ps/2306.03475" title="Download PostScript">ps</a>, <a href="/format/2306.03475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-to-local limit for the nonlocal interaction equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Esposito%2C+A">Antonio Esposito</a>, 
<a href="/search/math?searchtype=author&query=Heinze%2C+G">Georg Heinze</a>, 
<a href="/search/math?searchtype=author&query=Schlichting%2C+A">Andr&#xe9; Schlichting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages. Added result on diagonal limits. Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07915" title="Abstract">arXiv:2306.07915</a> (replaced) [<a href="/pdf/2306.07915" title="Download PDF">pdf</a>, <a href="/format/2306.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Captioners Are Scalable Vision Learners Too
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschannen%2C+M">Michael Tschannen</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Manoj Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+A">Andreas Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Houlsby%2C+N">Neil Houlsby</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. v2 adds SugarCrepe results and more ablations, v3 has minor fixes. v4 adds a code link ( <a href="https://github.com/google-research/big_vision">this https URL</a> ). v5 has minor fixes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08927" title="Abstract">arXiv:2306.08927</a> (replaced) [<a href="/pdf/2306.08927" title="Download PDF">pdf</a>, <a href="/ps/2306.08927" title="Download PostScript">ps</a>, <a href="/format/2306.08927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital signature schemes using non-square matrices or scrap  automorphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiale Chen</a>, 
<a href="/search/cs?searchtype=author&query=Grigoriev%2C+D">Dima Grigoriev</a>, 
<a href="/search/cs?searchtype=author&query=Shpilrain%2C+V">Vladimir Shpilrain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09077" title="Abstract">arXiv:2306.09077</a> (replaced) [<a href="/pdf/2306.09077" title="Download PDF">pdf</a>, <a href="/format/2306.09077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Generic 3D Room Structures from 2D Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozumnyi%2C+D">Denys Rozumnyi</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+S">Stefan Popov</a>, 
<a href="/search/cs?searchtype=author&query=Maninis%2C+K">Kevis-Kokitsi Maninis</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+V">Vittorio Ferrari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/google-research/cad-estate">this https URL</a> Accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09200" title="Abstract">arXiv:2306.09200</a> (replaced) [<a href="/pdf/2306.09200" title="Download PDF">pdf</a>, <a href="/format/2306.09200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChessGPT: Bridging Policy Learning and Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yicheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hongrui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengyue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+K">Kun Shao</a>, 
<a href="/search/cs?searchtype=author&query=Mguni%2C+D">David Mguni</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference article in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13249" title="Abstract">arXiv:2306.13249</a> (replaced) [<a href="/pdf/2306.13249" title="Download PDF">pdf</a>, <a href="/format/2306.13249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Monte Carlo methods for the Grad-Shafranov free boundary  problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Elman%2C+H+C">Howard C. Elman</a>, 
<a href="/search/physics?searchtype=author&query=Liang%2C+J">Jiaxing Liang</a>, 
<a href="/search/physics?searchtype=author&query=S%C3%A1nchez-Vizuet%2C+T">Tonatiuh S&#xe1;nchez-Vizuet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA); Plasma Physics (physics.plasm-ph)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00764" title="Abstract">arXiv:2307.00764</a> (replaced) [<a href="/pdf/2307.00764" title="Download PDF">pdf</a>, <a href="/format/2307.00764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Open-vocabulary Universal Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shufan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kallidromitis%2C+K">Konstantinos Kallidromitis</a>, 
<a href="/search/cs?searchtype=author&query=Kato%2C+Y">Yusuke Kato</a>, 
<a href="/search/cs?searchtype=author&query=Kozuka%2C+K">Kazuki Kozuka</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project web-page: <a href="http://people.eecs.berkeley.edu/~xdwang/projects/HIPIE/">this http URL</a>; NeurIPS 2023 Camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05722" title="Abstract">arXiv:2307.05722</a> (replaced) [<a href="/pdf/2307.05722" title="Download PDF">pdf</a>, <a href="/format/2307.05722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Model for Graph Data Understanding in Online  Job Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Likang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhaopeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06971" title="Abstract">arXiv:2307.06971</a> (replaced) [<a href="/pdf/2307.06971" title="Download PDF">pdf</a>, <a href="/ps/2307.06971" title="Download PostScript">ps</a>, <a href="/format/2307.06971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short Boolean Formulas as Explanations in Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+R">Reijo Jaakkola</a>, 
<a href="/search/cs?searchtype=author&query=Janhunen%2C+T">Tomi Janhunen</a>, 
<a href="/search/cs?searchtype=author&query=Kuusisto%2C+A">Antti Kuusisto</a>, 
<a href="/search/cs?searchtype=author&query=Rankooh%2C+M+F">Masood Feyzbakhsh Rankooh</a>, 
<a href="/search/cs?searchtype=author&query=Vilander%2C+M">Miikka Vilander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long version of a paper published in JELIA 2023. Changes to version 1: typos fixed, clarifications added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07749" title="Abstract">arXiv:2307.07749</a> (replaced) [<a href="/pdf/2307.07749" title="Download PDF">pdf</a>, <a href="/ps/2307.07749" title="Download PostScript">ps</a>, <a href="/format/2307.07749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A preconditioned MINRES method for block lower triangular Toeplitz  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+C">Congcong Li</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+X">Xuelei Lin</a>, 
<a href="/search/math?searchtype=author&query=Hon%2C+S">Sean Hon</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+S">Shu-Lin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08116" title="Abstract">arXiv:2307.08116</a> (replaced) [<a href="/pdf/2307.08116" title="Download PDF">pdf</a>, <a href="/format/2307.08116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Limits of Memristor-Based Routers for Asynchronous Neuromorphic  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junren Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Siyao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huaqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Indiveri%2C+G">Giacomo Indiveri</a>, 
<a href="/search/cs?searchtype=author&query=Payvand%2C+M">Melika Payvand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08346" title="Abstract">arXiv:2307.08346</a> (replaced) [<a href="/pdf/2307.08346" title="Download PDF">pdf</a>, <a href="/format/2307.08346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-board Federated Learning for Satellite Clusters with Inter-Satellite  Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razmi%2C+N">Nasrin Razmi</a>, 
<a href="/search/cs?searchtype=author&query=Matthiesen%2C+B">Bho Matthiesen</a>, 
<a href="/search/cs?searchtype=author&query=Dekorsy%2C+A">Armin Dekorsy</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10799" title="Abstract">arXiv:2307.10799</a> (replaced) [<a href="/pdf/2307.10799" title="Download PDF">pdf</a>, <a href="/format/2307.10799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-wise Representation Fusion for Compositional Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yafang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuangtao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuxuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhaohong Lai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Biao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yidong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaodong Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by aaai24. arXiv admin note: substantial text overlap with <a href="/abs/2305.12169">arXiv:2305.12169</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14040" title="Abstract">arXiv:2307.14040</a> (replaced) [<a href="/pdf/2307.14040" title="Download PDF">pdf</a>, <a href="/ps/2307.14040" title="Download PostScript">ps</a>, <a href="/format/2307.14040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic $p$th root approximation of a stochastic matrix: A Riemannian  optimization approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Durastante%2C+F">Fabio Durastante</a>, 
<a href="/search/math?searchtype=author&query=Meini%2C+B">Beatrice Meini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14367" title="Abstract">arXiv:2307.14367</a> (replaced) [<a href="/pdf/2307.14367" title="Download PDF">pdf</a>, <a href="/format/2307.14367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prot2Text: Multimodal Protein&#x27;s Function Generation with GNNs and  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Abdine%2C+H">Hadi Abdine</a>, 
<a href="/search/q-bio?searchtype=author&query=Chatzianastasis%2C+M">Michail Chatzianastasis</a>, 
<a href="/search/q-bio?searchtype=author&query=Bouyioukos%2C+C">Costas Bouyioukos</a>, 
<a href="/search/q-bio?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14773" title="Abstract">arXiv:2307.14773</a> (replaced) [<a href="/pdf/2307.14773" title="Download PDF">pdf</a>, <a href="/format/2307.14773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Analysis of Smart Contract Migration from Ethereum to Arbitrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xueyan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lingzhi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+A">Alan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuying Du</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jing Deng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jialu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15043" title="Abstract">arXiv:2307.15043</a> (replaced) [<a href="/pdf/2307.15043" title="Download PDF">pdf</a>, <a href="/format/2307.15043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal and Transferable Adversarial Attacks on Aligned Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">Andy Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Fredrikson%2C+M">Matt Fredrikson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="http://llm-attacks.org/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15254" title="Abstract">arXiv:2307.15254</a> (replaced) [<a href="/pdf/2307.15254" title="Download PDF">pdf</a>, <a href="/format/2307.15254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Instance Learning Framework with Masked Hard Instance Mining  for Whole Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoxian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fengtao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15588" title="Abstract">arXiv:2307.15588</a> (replaced) [<a href="/pdf/2307.15588" title="Download PDF">pdf</a>, <a href="/format/2307.15588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code of OAFuser will be made publicly available at <a href="https://github.com/FeiBryantkit/OAFuser">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16586" title="Abstract">arXiv:2307.16586</a> (replaced) [<a href="/pdf/2307.16586" title="Download PDF">pdf</a>, <a href="/format/2307.16586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment  Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00788" title="Abstract">arXiv:2308.00788</a> (replaced) [<a href="/pdf/2308.00788" title="Download PDF">pdf</a>, <a href="/format/2308.00788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to Bi-level Optimization: Foundations and Applications  in Signal Processing and Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Khanduri%2C+P">Prashant Khanduri</a>, 
<a href="/search/cs?searchtype=author&query=Tsaknakis%2C+I">Ioannis Tsaknakis</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuguang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01196" title="Abstract">arXiv:2308.01196</a> (replaced) [<a href="/pdf/2308.01196" title="Download PDF">pdf</a>, <a href="/format/2308.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable Transparency in Recommender Systems: Bayesian Ranking of  Images for Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paz-Ruza%2C+J">Jorge Paz-Ruza</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Betanzos%2C+A">Amparo Alonso-Betanzos</a>, 
<a href="/search/cs?searchtype=author&query=Guijarro-Berdi%C3%B1as%2C+B">Berta Guijarro-Berdi&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Cancela%2C+B">Brais Cancela</a>, 
<a href="/search/cs?searchtype=author&query=Eiras-Franco%2C+C">Carlos Eiras-Franco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02345" title="Abstract">arXiv:2308.02345</a> (replaced) [<a href="/pdf/2308.02345" title="Download PDF">pdf</a>, <a href="/format/2308.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Decentralized Multi-Agent Reinforcement Learning  for Cooperative Adaptive Cruise Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kaixiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xunyuan Yin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>, 
<a href="/search/eess?searchtype=author&query=Filev%2C+D">Dimitar Filev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03308" title="Abstract">arXiv:2308.03308</a> (replaced) [<a href="/pdf/2308.03308" title="Download PDF">pdf</a>, <a href="/format/2308.03308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronized CTL over One-Counter Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almagor%2C+S">Shaull Almagor</a>, 
<a href="/search/cs?searchtype=author&query=Assa%2C+D">Daniel Assa</a>, 
<a href="/search/cs?searchtype=author&query=Boker%2C+U">Udi Boker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06277" title="Abstract">arXiv:2308.06277</a> (replaced) [<a href="/pdf/2308.06277" title="Download PDF">pdf</a>, <a href="/ps/2308.06277" title="Download PostScript">ps</a>, <a href="/format/2308.06277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Descriptive complexity for neural networks via Boolean networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahvonen%2C+V">Veeti Ahvonen</a>, 
<a href="/search/cs?searchtype=author&query=Heiman%2C+D">Damian Heiman</a>, 
<a href="/search/cs?searchtype=author&query=Kuusisto%2C+A">Antti Kuusisto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06338" title="Abstract">arXiv:2308.06338</a> (replaced) [<a href="/pdf/2308.06338" title="Download PDF">pdf</a>, <a href="/format/2308.06338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Size Lowerbounds for Deep Operator Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Anirbit Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Amartya Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06668" title="Abstract">arXiv:2308.06668</a> (replaced) [<a href="/pdf/2308.06668" title="Download PDF">pdf</a>, <a href="/format/2308.06668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Models in Smart Agriculture: Basics, Opportunities, and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiajia Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingle Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Lirong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Weichao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunyuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07528" title="Abstract">arXiv:2308.07528</a> (replaced) [<a href="/pdf/2308.07528" title="Download PDF">pdf</a>, <a href="/format/2308.07528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence Contours: Uncertainty-Aware Annotation for Medical Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+A">Andre Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+Z">Quan Ze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages content, 12 pages total. Accepted to HCOMP '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08309" title="Abstract">arXiv:2308.08309</a> (replaced) [<a href="/pdf/2308.08309" title="Download PDF">pdf</a>, <a href="/format/2308.08309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Data-Driven Explainability in Mathematical Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aigner%2C+K">Kevin-Martin Aigner</a>, 
<a href="/search/math?searchtype=author&query=Goerigk%2C+M">Marc Goerigk</a>, 
<a href="/search/math?searchtype=author&query=Hartisch%2C+M">Michael Hartisch</a>, 
<a href="/search/math?searchtype=author&query=Liers%2C+F">Frauke Liers</a>, 
<a href="/search/math?searchtype=author&query=Miehlich%2C+A">Arthur Miehlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08638" title="Abstract">arXiv:2308.08638</a> (replaced) [<a href="/pdf/2308.08638" title="Download PDF">pdf</a>, <a href="/format/2308.08638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair GANs through model rebalancing for extremely imbalanced class  distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Anubhav Jain</a>, 
<a href="/search/cs?searchtype=author&query=Memon%2C+N">Nasir Memon</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08746" title="Abstract">arXiv:2308.08746</a> (replaced) [<a href="/pdf/2308.08746" title="Download PDF">pdf</a>, <a href="/format/2308.08746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+W">Wenxi Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024. The source code is available at <a href="https://github.com/wenxi-yue/SurgicalSAM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10045" title="Abstract">arXiv:2308.10045</a> (replaced) [<a href="/pdf/2308.10045" title="Download PDF">pdf</a>, <a href="/format/2308.10045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of CLIP for Text-based Person Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Min Cao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziyin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Code is available at <a href="https://github.com/Flame-Chasers/TBPS-CLIP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12466" title="Abstract">arXiv:2308.12466</a> (replaced) [<a href="/pdf/2308.12466" title="Download PDF">pdf</a>, <a href="/format/2308.12466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshat Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14002" title="Abstract">arXiv:2308.14002</a> (replaced) [<a href="/pdf/2308.14002" title="Download PDF">pdf</a>, <a href="/format/2308.14002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hands-on Quantum Programming Labs for EECS Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sang%2C+J">Janche Sang</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+C">Chansu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 70 pages, 33 figures; program templates updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14034" title="Abstract">arXiv:2308.14034</a> (replaced) [<a href="/pdf/2308.14034" title="Download PDF">pdf</a>, <a href="/format/2308.14034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confucius: Iterative Tool Learning from Introspection Feedback by  Easy-to-Difficult Curriculum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengliang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minghang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+B">Bowen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03291" title="Abstract">arXiv:2309.03291</a> (replaced) [<a href="/pdf/2309.03291" title="Download PDF">pdf</a>, <a href="/format/2309.03291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-fast high-dynamic range imaging of Cygnus A with the R2D2 deep  neural network series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=A%2C+A">Aghabiglou A</a>, 
<a href="/search/astro-ph?searchtype=author&query=S%2C+C+C">Chu C S</a>, 
<a href="/search/astro-ph?searchtype=author&query=A%2C+J">Jackson A</a>, 
<a href="/search/astro-ph?searchtype=author&query=A%2C+D">Dabbech A</a>, 
<a href="/search/astro-ph?searchtype=author&query=Y%2C+W">Wiaux Y</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ApJL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05203" title="Abstract">arXiv:2309.05203</a> (replaced) [<a href="/pdf/2309.05203" title="Download PDF">pdf</a>, <a href="/format/2309.05203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Artificially Real to Real: Leveraging Pseudo Data from Large  Language Models for Low-Resource Molecule Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+N">Nuwa Xi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yanrui Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jianyu%2C+C">Chen Jianyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05584" title="Abstract">arXiv:2309.05584</a> (replaced) [<a href="/pdf/2309.05584" title="Download PDF">pdf</a>, <a href="/format/2309.05584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Probabilistic Model Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsayed-Aly%2C+I">Ingy Elsayed-Aly</a>, 
<a href="/search/cs?searchtype=author&query=Parker%2C+D">David Parker</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lu Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 pages appendix, 5 figures. Submitted for review. For associated Github repository, see <a href="https://github.com/davexparker/prism/tree/ingy">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07277" title="Abstract">arXiv:2309.07277</a> (replaced) [<a href="/pdf/2309.07277" title="Download PDF">pdf</a>, <a href="/ps/2309.07277" title="Download PostScript">ps</a>, <a href="/format/2309.07277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limitations of Face Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+H">Harrison Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Shimaa Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+G+V">Guruprasad V Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Vinayak%2C+R+K">Ramya Korlakai Vinayak</a>, 
<a href="/search/cs?searchtype=author&query=Fawaz%2C+K">Kassem Fawaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08154" title="Abstract">arXiv:2309.08154</a> (replaced) [<a href="/pdf/2309.08154" title="Download PDF">pdf</a>, <a href="/format/2309.08154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Visual Semantic Sub-Embeddings and Fast Re-Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenzhang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+Z">Zhipeng Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Anqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dehua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huayi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08173" title="Abstract">arXiv:2309.08173</a> (replaced) [<a href="/pdf/2309.08173" title="Download PDF">pdf</a>, <a href="/format/2309.08173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedJudge: Federated Legal Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Linan Yue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yichao Du</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weibo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fangzhou Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to DASFAA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08738" title="Abstract">arXiv:2309.08738</a> (replaced) [<a href="/pdf/2309.08738" title="Download PDF">pdf</a>, <a href="/format/2309.08738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV-MaskEnhancer: Enhancing Video Representations through Audio-Visual  Masked Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+X">Xingjian Diao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shitong Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12559" title="Abstract">arXiv:2309.12559</a> (replaced) [<a href="/pdf/2309.12559" title="Download PDF">pdf</a>, <a href="/format/2309.12559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Learning via Probability of Sufficient and Necessary Causes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengyue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yonggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Furui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ton%2C+J">Jean-Francois Ton</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12780" title="Abstract">arXiv:2309.12780</a> (replaced) [<a href="/pdf/2309.12780" title="Download PDF">pdf</a>, <a href="/format/2309.12780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMC: Large Model Collaboration with Cross-assessment for Training-Free  Open-Set Object Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Haoxuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+X">Xiaofei Hui</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yujun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12815" title="Abstract">arXiv:2309.12815</a> (replaced) [<a href="/pdf/2309.12815" title="Download PDF">pdf</a>, <a href="/format/2309.12815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Generalization in Game Agents with Data Augmentation in  Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadgaroff%2C+D">Derek Yadgaroff</a>, 
<a href="/search/cs?searchtype=author&query=Sestini%2C+A">Alessandro Sestini</a>, 
<a href="/search/cs?searchtype=author&query=Tollmar%2C+K">Konrad Tollmar</a>, 
<a href="/search/cs?searchtype=author&query=Ozcelikkale%2C+A">Ayca Ozcelikkale</a>, 
<a href="/search/cs?searchtype=author&query=Gissl%C3%A9n%2C+L">Linus Gissl&#xe9;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13439" title="Abstract">arXiv:2309.13439</a> (replaced) [<a href="/pdf/2309.13439" title="Download PDF">pdf</a>, <a href="/format/2309.13439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Order in Chaos: A Novel Data Augmentation Method for Time Series  in Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demirel%2C+B+U">Berken Utku Demirel</a>, 
<a href="/search/cs?searchtype=author&query=Holz%2C+C">Christian Holz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the Conference on Neural Information Processing Systems (NeurIPS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13690" title="Abstract">arXiv:2309.13690</a> (replaced) [<a href="/pdf/2309.13690" title="Download PDF">pdf</a>, <a href="/format/2309.13690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable data concentrator with baseline interconnection network for  triggerless data acquisition systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zabo%C5%82otny%2C+W+M">Wojciech M. Zabo&#x142;otny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17114" title="Abstract">arXiv:2309.17114</a> (replaced) [<a href="/pdf/2309.17114" title="Download PDF">pdf</a>, <a href="/format/2309.17114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UXsim: An open source macroscopic and mesoscopic traffic simulator in  Python -- a technical overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Seo%2C+T">Toru Seo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00526" title="Abstract">arXiv:2310.00526</a> (replaced) [<a href="/pdf/2310.00526" title="Download PDF">pdf</a>, <a href="/format/2310.00526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Graph Neural Networks Optimal Approximation Algorithms?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yau%2C+M">Morris Yau</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+E">Eric Lu</a>, 
<a href="/search/cs?searchtype=author&query=Karalias%2C+N">Nikolaos Karalias</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jessica Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jegelka%2C+S">Stefanie Jegelka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated references, fixed more typos and wording issues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02120" title="Abstract">arXiv:2310.02120</a> (replaced) [<a href="/pdf/2310.02120" title="Download PDF">pdf</a>, <a href="/format/2310.02120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HPCClusterScape: Increasing Transparency and Efficiency of Shared  High-Performance Computing Clusters for Large-scale AI Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Heungseok Park</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+A">Aeree Cho</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hyojun Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hayoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Youngil Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Heungsub Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VDS 2023 ACM 2012 CCS - Human-centered computing, Visualization, Visualization design and evaluation methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02679" title="Abstract">arXiv:2310.02679</a> (replaced) [<a href="/pdf/2310.02679" title="Download PDF">pdf</a>, <a href="/format/2310.02679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Generative Flow Samplers: Improving learning signals through  partial trajectory optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dinghuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation (stat.CO); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03223" title="Abstract">arXiv:2310.03223</a> (replaced) [<a href="/pdf/2310.03223" title="Download PDF">pdf</a>, <a href="/format/2310.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tony Shen</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+M">Mohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jason Smith</a>, 
<a href="/search/cs?searchtype=author&query=Cherkasov%2C+A">Artem Cherkasov</a>, 
<a href="/search/cs?searchtype=author&query=Ester%2C+M">Martin Ester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 AID3 and at NeurIPS 2023 GenBio as Spotlight
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Generative AI and Biology (GenBio) Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03780" title="Abstract">arXiv:2310.03780</a> (replaced) [<a href="/pdf/2310.03780" title="Download PDF">pdf</a>, <a href="/format/2310.03780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4  Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phung%2C+T">Tung Phung</a>, 
<a href="/search/cs?searchtype=author&query=P%C4%83durean%2C+V">Victor-Alexandru P&#x103;durean</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anjali Singh</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+C">Christopher Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Cambronero%2C+J">Jos&#xe9; Cambronero</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+G">Gustavo Soares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Learning Analytics and Knowledge Conference (LAK) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03900" title="Abstract">arXiv:2310.03900</a> (replaced) [<a href="/pdf/2310.03900" title="Download PDF">pdf</a>, <a href="/ps/2310.03900" title="Download PostScript">ps</a>, <a href="/format/2310.03900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Game Approach to Multi-dimensional Opinion Dynamics in Social Networks  with Stubborn Strategist Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jond%2C+H+B">Hossein B. Jond</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+A">Aykut Y&#x131;ld&#x131;z</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in European Journal of Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04247" title="Abstract">arXiv:2310.04247</a> (replaced) [<a href="/pdf/2310.04247" title="Download PDF">pdf</a>, <a href="/format/2310.04247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic segmentation of longitudinal thermal images for identification  of hot and cool spots in urban areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramani%2C+V">Vasantha Ramani</a>, 
<a href="/search/cs?searchtype=author&query=Arjunan%2C+P">Pandarasamy Arjunan</a>, 
<a href="/search/cs?searchtype=author&query=Poolla%2C+K">Kameshwar Poolla</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+C">Clayton Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Building and Environment (2023), 111112
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08868" title="Abstract">arXiv:2310.08868</a> (replaced) [<a href="/pdf/2310.08868" title="Download PDF">pdf</a>, <a href="/format/2310.08868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeCoNet: A Heterosexual Contact Network Growth Model for Human  Papillomavirus Disease Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Piraveenan%2C+M">Mahendra Piraveenan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09574" title="Abstract">arXiv:2310.09574</a> (replaced) [<a href="/pdf/2310.09574" title="Download PDF">pdf</a>, <a href="/format/2310.09574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced Policy Optimization for Continuous Control with Hard Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shutong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09583" title="Abstract">arXiv:2310.09583</a> (replaced) [<a href="/pdf/2310.09583" title="Download PDF">pdf</a>, <a href="/format/2310.09583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural  ODEs via Homotopy Continuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shutong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+T">Tianyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13174" title="Abstract">arXiv:2310.13174</a> (replaced) [<a href="/pdf/2310.13174" title="Download PDF">pdf</a>, <a href="/ps/2310.13174" title="Download PostScript">ps</a>, <a href="/format/2310.13174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Algorithms for Text-to-Pattern Hamming Distances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+T+M">Timothy M. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Ce Jin</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+V+V">Virginia Vassilevska Williams</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinzhan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in FOCS 2023. Abstract shortened to fit arXiv requirements. v2: added reference and discussion related to Lemma 2.2 and Appendix B
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14859" title="Abstract">arXiv:2310.14859</a> (replaced) [<a href="/pdf/2310.14859" title="Download PDF">pdf</a>, <a href="/ps/2310.14859" title="Download PostScript">ps</a>, <a href="/format/2310.14859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3M-TRANSFORMER: A Multi-Stage Multi-Stream Multimodal Transformer for  Embodied Turn-Taking Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatan%2C+M">Mehdi Fatan</a>, 
<a href="/search/cs?searchtype=author&query=Mincato%2C+E">Emanuele Mincato</a>, 
<a href="/search/cs?searchtype=author&query=Pintzou%2C+D">Dimitra Pintzou</a>, 
<a href="/search/cs?searchtype=author&query=Dimiccoli%2C+M">Mariella Dimiccoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16641" title="Abstract">arXiv:2310.16641</a> (replaced) [<a href="/pdf/2310.16641" title="Download PDF">pdf</a>, <a href="/format/2310.16641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Next Evolution of Artificial Sense of Touch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gro%C3%9F%2C+S">Sonja Gro&#xdf;</a>, 
<a href="/search/eess?searchtype=author&query=Ganguly%2C+A">Amartya Ganguly</a>, 
<a href="/search/eess?searchtype=author&query=Dietz%2C+H">Hendrik Dietz</a>, 
<a href="/search/eess?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16898" title="Abstract">arXiv:2310.16898</a> (replaced) [<a href="/pdf/2310.16898" title="Download PDF">pdf</a>, <a href="/format/2310.16898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCUFormer: Deploying Vision Transformers on Microcontrollers with  Limited Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yinan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiuwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18201" title="Abstract">arXiv:2310.18201</a> (replaced) [<a href="/pdf/2310.18201" title="Download PDF">pdf</a>, <a href="/format/2310.18201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Residual Minimization for PDEs: Failure of PINN, Modified Equation,  and Implicit Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+T">Tao Luo</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Q">Qixuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18608" title="Abstract">arXiv:2310.18608</a> (replaced) [<a href="/pdf/2310.18608" title="Download PDF">pdf</a>, <a href="/format/2310.18608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding in Recommender Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinjian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiansheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shucheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19583" title="Abstract">arXiv:2310.19583</a> (replaced) [<a href="/pdf/2310.19583" title="Download PDF">pdf</a>, <a href="/format/2310.19583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View  Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+V+K">Vibhas K. Vats</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sripad Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Crandall%2C+D+J">David J. Crandall</a>, 
<a href="/search/cs?searchtype=author&query=Reza%2C+M+A">Md. Alimoor Reza</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Soon-heung Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024 Link: <a href="https://openaccess.thecvf.com/content/WACV2024/html/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.html">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20331" title="Abstract">arXiv:2310.20331</a> (replaced) [<a href="/pdf/2310.20331" title="Download PDF">pdf</a>, <a href="/format/2310.20331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Aware Adaptive Sampling for Self-Sustainability in  Resource-Constrained IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Giordano%2C+M">Marco Giordano</a>, 
<a href="/search/eess?searchtype=author&query=Cortesi%2C+S">Silvano Cortesi</a>, 
<a href="/search/eess?searchtype=author&query=Mekikis%2C+P">Prodromos-Vasileios Mekikis</a>, 
<a href="/search/eess?searchtype=author&query=Crabolu%2C+M">Michele Crabolu</a>, 
<a href="/search/eess?searchtype=author&query=Bellusci%2C+G">Giovanni Bellusci</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in the Proceedings of the 11th International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems (ENSSys '23). DOI: <a href="https://doi.org/10.1145/3628353.3628545">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01304" title="Abstract">arXiv:2311.01304</a> (replaced) [<a href="/pdf/2311.01304" title="Download PDF">pdf</a>, <a href="/format/2311.01304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VM-Rec: A Variational Mapping Approach for Cold-start User  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Linan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiale Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengsheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangfa Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jinyun Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02358" title="Abstract">arXiv:2311.02358</a> (replaced) [<a href="/pdf/2311.02358" title="Download PDF">pdf</a>, <a href="/ps/2311.02358" title="Download PostScript">ps</a>, <a href="/format/2311.02358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Transfer in Latent Space (DTLS) Wins on Image Super-Resolution --  a Non-Denoising Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hui%2C+C">Chun-Chuen Hui</a>, 
<a href="/search/eess?searchtype=author&query=Siu%2C+W">Wan-Chi Siu</a>, 
<a href="/search/eess?searchtype=author&query=Law%2C+N">Ngai-Fong Law</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03830" title="Abstract">arXiv:2311.03830</a> (replaced) [<a href="/pdf/2311.03830" title="Download PDF">pdf</a>, <a href="/format/2311.03830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Spatial Fitting Error in Distillation of Denoising Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shengzhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Z">Zejian Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lefan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingyun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05152" title="Abstract">arXiv:2311.05152</a> (replaced) [<a href="/pdf/2311.05152" title="Download PDF">pdf</a>, <a href="/format/2311.05152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual  Downstream Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoyi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingze Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Li Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07919" title="Abstract">arXiv:2311.07919</a> (replaced) [<a href="/pdf/2311.07919" title="Download PDF">pdf</a>, <a href="/format/2311.07919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qwen-Audio: Advancing Universal Audio Understanding via Unified  Large-Scale Audio-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chu%2C+Y">Yunfei Chu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xiaohuan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Q">Qian Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Z">Zhijie Yan</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code, checkpoints and demo are released at <a href="https://github.com/QwenLM/Qwen-Audio">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07967" title="Abstract">arXiv:2311.07967</a> (replaced) [<a href="/pdf/2311.07967" title="Download PDF">pdf</a>, <a href="/format/2311.07967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of two data fusion approaches for land use classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cubaud%2C+M">Martin Cubaud</a> (LaSTIG), 
<a href="/search/cs?searchtype=author&query=Bris%2C+A+L">Arnaud Le Bris</a> (LaSTIG), 
<a href="/search/cs?searchtype=author&query=Jolivet%2C+L">Laurence Jolivet</a> (LaSTIG), 
<a href="/search/cs?searchtype=author&query=Olteanu-Raimond%2C+A">Ana-Maria Olteanu-Raimond</a> (LaSTIG)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ISPRS Geospatial Week 2023, Sep 2023, Cairo, Egypt., Egypt.
  pp.699-706
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09456" title="Abstract">arXiv:2311.09456</a> (replaced) [<a href="/pdf/2311.09456" title="Download PDF">pdf</a>, <a href="/format/2311.09456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepMartNet -- A Martingale Based Deep Neural Network Learning Method  for Dirichlet BVPs and Eigenvalue Problems of Elliptic PDEs in R^d
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cai%2C+W">Wei Cai</a>, 
<a href="/search/math?searchtype=author&query=He%2C+A">Andrew He</a>, 
<a href="/search/math?searchtype=author&query=Margolis%2C+D">Daniel Margolis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10501" title="Abstract">arXiv:2311.10501</a> (replaced) [<a href="/pdf/2311.10501" title="Download PDF">pdf</a>, <a href="/format/2311.10501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Word-based Pre-trained Item Representation for  Transferable Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shenghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yankai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kangping Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weizhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Haitao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Junlan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chao Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10940" title="Abstract">arXiv:2311.10940</a> (replaced) [<a href="/pdf/2311.10940" title="Download PDF">pdf</a>, <a href="/format/2311.10940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Estimation of Ensemble Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haber%2C+S">Simi Haber</a>, 
<a href="/search/cs?searchtype=author&query=Wexler%2C+Y">Yonatan Wexler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures. Accepted to InfoCOG@NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11059" title="Abstract">arXiv:2311.11059</a> (replaced) [<a href="/pdf/2311.11059" title="Download PDF">pdf</a>, <a href="/format/2311.11059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIDRO-VQA: High Dynamic Range Oracle for Video Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saini%2C+S">Shreshth Saini</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Avinab Saha</a>, 
<a href="/search/cs?searchtype=author&query=Bovik%2C+A+C">Alan C. Bovik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024 Workshop Paper. Shreshth Saini, Avinab Saha contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14523" title="Abstract">arXiv:2311.14523</a> (replaced) [<a href="/pdf/2311.14523" title="Download PDF">pdf</a>, <a href="/format/2311.14523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of a Non-Coherent Ultra-Wideband Transceiver for Micropower  Sensor Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Imfeld%2C+J">Jonah Imfeld</a>, 
<a href="/search/eess?searchtype=author&query=Cortesi%2C+S">Silvano Cortesi</a>, 
<a href="/search/eess?searchtype=author&query=Mayer%2C+P">Philipp Mayer</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in the Proceedings of the 2023 IEEE SENSORS conference. DOI: <a href="https://doi.org/10.1109/SENSORS56945.2023.10325219">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14981" title="Abstract">arXiv:2311.14981</a> (replaced) [<a href="/pdf/2311.14981" title="Download PDF">pdf</a>, <a href="/format/2311.14981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Planar Reconstruction with Feature Warping Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Luan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For code, see <a href="https://github.com/fraunhoferhhi/SOLOPlanes">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> VISAPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16512" title="Abstract">arXiv:2311.16512</a> (replaced) [<a href="/pdf/2311.16512" title="Download PDF">pdf</a>, <a href="/format/2311.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSeR: Bridging Image and Language for Cognitive Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+R">Renjing Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://coser-main.github.io">this https URL</a> ; GitHub repository: <a href="https://github.com/VINHYU/CoSeR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16816" title="Abstract">arXiv:2311.16816</a> (replaced) [<a href="/pdf/2311.16816" title="Download PDF">pdf</a>, <a href="/format/2311.16816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Packing even directed circuits quarter-integrally
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gorsky%2C+M">Maximilian Gorsky</a>, 
<a href="/search/math?searchtype=author&query=Kawarabayashi%2C+K">Ken-ichi Kawarabayashi</a>, 
<a href="/search/math?searchtype=author&query=Kreutzer%2C+S">Stephan Kreutzer</a>, 
<a href="/search/math?searchtype=author&query=Wiederrecht%2C+S">Sebastian Wiederrecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 144 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17458" title="Abstract">arXiv:2311.17458</a> (replaced) [<a href="/pdf/2311.17458" title="Download PDF">pdf</a>, <a href="/format/2311.17458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Neural Networks under Depolarization Noise: Exploring White-Box  Attacks and Defenses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Winderl%2C+D">David Winderl</a>, 
<a href="/search/quant-ph?searchtype=author&query=Franco%2C+N">Nicola Franco</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lorenz%2C+J+M">Jeanette Miriam Lorenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster at Quantum Techniques in Machine Learning (QTML) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18260" title="Abstract">arXiv:2311.18260</a> (replaced) [<a href="/pdf/2311.18260" title="Download PDF">pdf</a>, <a href="/format/2311.18260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus, dissensus and synergy between clinicians and specialist  foundation models in radiology report generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tanno%2C+R">Ryutaro Tanno</a>, 
<a href="/search/eess?searchtype=author&query=Barrett%2C+D+G+T">David G.T. Barrett</a>, 
<a href="/search/eess?searchtype=author&query=Sellergren%2C+A">Andrew Sellergren</a>, 
<a href="/search/eess?searchtype=author&query=Ghaisas%2C+S">Sumedh Ghaisas</a>, 
<a href="/search/eess?searchtype=author&query=Dathathri%2C+S">Sumanth Dathathri</a>, 
<a href="/search/eess?searchtype=author&query=See%2C+A">Abigail See</a>, 
<a href="/search/eess?searchtype=author&query=Welbl%2C+J">Johannes Welbl</a>, 
<a href="/search/eess?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Azizi%2C+S">Shekoofeh Azizi</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+T">Tao Tu</a>, 
<a href="/search/eess?searchtype=author&query=Schaekermann%2C+M">Mike Schaekermann</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+R">Rhys May</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+R">Roy Lee</a>, 
<a href="/search/eess?searchtype=author&query=Man%2C+S">SiWai Man</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+Z">Zahra Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Mahdavi%2C+S">Sara Mahdavi</a>, 
<a href="/search/eess?searchtype=author&query=Matias%2C+Y">Yossi Matias</a>, 
<a href="/search/eess?searchtype=author&query=Barral%2C+J">Joelle Barral</a>, 
<a href="/search/eess?searchtype=author&query=Eslami%2C+A">Ali Eslami</a>, 
<a href="/search/eess?searchtype=author&query=Belgrave%2C+D">Danielle Belgrave</a>, 
<a href="/search/eess?searchtype=author&query=Natarajan%2C+V">Vivek Natarajan</a>, 
<a href="/search/eess?searchtype=author&query=Shetty%2C+S">Shravya Shetty</a>, 
<a href="/search/eess?searchtype=author&query=Kohli%2C+P">Pushmeet Kohli</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+P">Po-Sen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="/search/eess?searchtype=author&query=Ktena%2C+I">Ira Ktena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00137" title="Abstract">arXiv:2312.00137</a> (replaced) [<a href="/pdf/2312.00137" title="Download PDF">pdf</a>, <a href="/format/2312.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Multiverse of Dynamic Mode Decomposition Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Colbrook%2C+M+J">Matthew J. Colbrook</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> review article, 88 pages, 28 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Spectral Theory (math.SP)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01057" title="Abstract">arXiv:2312.01057</a> (replaced) [<a href="/pdf/2312.01057" title="Download PDF">pdf</a>, <a href="/format/2312.01057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLHF and IIA: Perverse Incentives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanqiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiuyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+G">Grace Lam</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02642" title="Abstract">arXiv:2312.02642</a> (replaced) [<a href="/pdf/2312.02642" title="Download PDF">pdf</a>, <a href="/format/2312.02642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Ethereum Mempool Security under Asymmetric DoS by Symbolic  Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wanning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuzhe Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03763" title="Abstract">arXiv:2312.03763</a> (replaced) [<a href="/pdf/2312.03763" title="Download PDF">pdf</a>, <a href="/format/2312.03763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yushi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+D">Di Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiangeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Genova%2C+K">Kyle Genova</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fanello%2C+S">Sean Fanello</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Funkhouser%2C+T">Thomas Funkhouser</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project webpage: <a href="https://nirvanalan.github.io/projects/gaussian3diff/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03775" title="Abstract">arXiv:2312.03775</a> (replaced) [<a href="/pdf/2312.03775" title="Download PDF">pdf</a>, <a href="/format/2312.03775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAAC: Facial Animation Generation with Anchor Frame and Conditional  Control for Superior Fidelity and Editability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linze Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Sunqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+H">Hengjun Pu</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhaodong Bing</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tianzhu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajun Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04092" title="Abstract">arXiv:2312.04092</a> (replaced) [<a href="/pdf/2312.04092" title="Download PDF">pdf</a>, <a href="/ps/2312.04092" title="Download PostScript">ps</a>, <a href="/format/2312.04092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data stewardship: case studies from North-American, Dutch, and Finnish  universities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rousi%2C+A+M">Antti M. Rousi</a>, 
<a href="/search/cs?searchtype=author&query=Boehm%2C+R+I">Reid I. Boehm</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05964" title="Abstract">arXiv:2312.05964</a> (replaced) [<a href="/pdf/2312.05964" title="Download PDF">pdf</a>, <a href="/format/2312.05964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConSequence: Synthesizing Logically Constrained Sequences for Electronic  Health Record Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+B">Brandon Theodorou</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shrusti Jain</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Cao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06039" title="Abstract">arXiv:2312.06039</a> (replaced) [<a href="/pdf/2312.06039" title="Download PDF">pdf</a>, <a href="/format/2312.06039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singularly Perturbed Layered Control of Deformable Bodies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Molu%2C+L">Lekan Molu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06502" title="Abstract">arXiv:2312.06502</a> (replaced) [<a href="/pdf/2312.06502" title="Download PDF">pdf</a>, <a href="/ps/2312.06502" title="Download PostScript">ps</a>, <a href="/format/2312.06502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On enforcing dyadic-type homogeneous binary function product constraints  in MatBase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mancas%2C+C">Christian Mancas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted on Dec. 7, 2023, to the Journal of Data Science and Intelligent Systems (JDSIS) and on Dec. 20, 2023, to the Journal of Computational and Cognitive Engineering, both of Bon View Publishing, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06551" title="Abstract">arXiv:2312.06551</a> (replaced) [<a href="/pdf/2312.06551" title="Download PDF">pdf</a>, <a href="/ps/2312.06551" title="Download PostScript">ps</a>, <a href="/format/2312.06551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successive Bayesian Reconstructor for Channel Estimation in Flexible  Antenna Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Linglong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures. This paper proposes S-BAR as a general solution to estimate FAS channels. Unlike model-based estimators, the proposed S-BAR is prior-aided, which builds the experiential kernel for CSI acquisition. Simulation codes will be provided at: <a href="http://oa.ee.tsinghua.edu.cn/dailinglong/publications/publications.html">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06723" title="Abstract">arXiv:2312.06723</a> (replaced) [<a href="/pdf/2312.06723" title="Download PDF">pdf</a>, <a href="/format/2312.06723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to See Low-Light Images via Feature Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07019" title="Abstract">arXiv:2312.07019</a> (replaced) [<a href="/pdf/2312.07019" title="Download PDF">pdf</a>, <a href="/format/2312.07019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond 1D and oversimplified kinematics: A generic analytical framework  for surrogate safety measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/eess?searchtype=author&query=Anis%2C+M">Mohammad Anis</a>, 
<a href="/search/eess?searchtype=author&query=Lord%2C+D">Dominique Lord</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+X">Xinyue Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07069" title="Abstract">arXiv:2312.07069</a> (replaced) [<a href="/pdf/2312.07069" title="Download PDF">pdf</a>, <a href="/format/2312.07069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Matters: Data-Efficient Augmentation of Large Language Models  for Scientific Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Maravi%2C+A">Anurag Maravi</a>, 
<a href="/search/cs?searchtype=author&query=Abram%2C+M">Marcin Abram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 4 tables, 3 pages of supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07488" title="Abstract">arXiv:2312.07488</a> (replaced) [<a href="/pdf/2312.07488" title="Download PDF">pdf</a>, <a href="/format/2312.07488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMDrive: Closed-Loop End-to-End Driving with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Hao Shao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Letian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Waslander%2C+S+L">Steven L. Waslander</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://hao-shao.com/projects/lmdrive.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07871" title="Abstract">arXiv:2312.07871</a> (replaced) [<a href="/pdf/2312.07871" title="Download PDF">pdf</a>, <a href="/format/2312.07871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLNet: Mutual Learning Network with Neighborhood Invariance for  Universal Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yanzuo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Meng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A+J">Andy J Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08363" title="Abstract">arXiv:2312.08363</a> (replaced) [<a href="/pdf/2312.08363" title="Download PDF">pdf</a>, <a href="/ps/2312.08363" title="Download PostScript">ps</a>, <a href="/format/2312.08363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computational Hardness of Quantum One-Wayness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cavalar%2C+B">Bruno Cavalar</a>, 
<a href="/search/cs?searchtype=author&query=Goldin%2C+E">Eli Goldin</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+M">Matthew Gray</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+P">Peter Hall</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pelecanos%2C+A">Angelos Pelecanos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract modified to fit ArXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08887" title="Abstract">arXiv:2312.08887</a> (replaced) [<a href="/pdf/2312.08887" title="Download PDF">pdf</a>, <a href="/format/2312.08887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpeedUpNet: A Plug-and-Play Hyper-Network for Accelerating Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Weilong Chai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">DanDan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiajiong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changbao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chenguang Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Table 1. shows the comparison with existing methods, but the lack of experimental data of the LCM method under 12-step makes the table incomplete. We need to temporarily withdraw the manuscript and conduct corresponding experiments before resubmitting it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09131" title="Abstract">arXiv:2312.09131</a> (replaced) [<a href="/pdf/2312.09131" title="Download PDF">pdf</a>, <a href="/format/2312.09131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Network Lyapunov Functions: PDE  Characterization, Learning, and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+Y">Yiming Meng</a>, 
<a href="/search/math?searchtype=author&query=Fitzsimmons%2C+M">Maxwell Fitzsimmons</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+R">Ruikun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The current version has been submitted for publication; corrected some minor typos from v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09244" title="Abstract">arXiv:2312.09244</a> (replaced) [<a href="/pdf/2312.09244" title="Download PDF">pdf</a>, <a href="/format/2312.09244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate  Reward Hacking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eisenstein%2C+J">Jacob Eisenstein</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+C">Chirag Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Alekh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amour%2C+A">Alex D&#x27;Amour</a>, 
<a href="/search/cs?searchtype=author&query=Dvijotham%2C+D">DJ Dvijotham</a>, 
<a href="/search/cs?searchtype=author&query=Fisch%2C+A">Adam Fisch</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+K">Katherine Heller</a>, 
<a href="/search/cs?searchtype=author&query=Pfohl%2C+S">Stephen Pfohl</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+D">Deepak Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+P">Peter Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09577" title="Abstract">arXiv:2312.09577</a> (replaced) [<a href="/pdf/2312.09577" title="Download PDF">pdf</a>, <a href="/format/2312.09577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Data Lakes with GraphAr: Efficient Graph Data Management with  a Specialized Storage Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Weibin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Diwen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09592" title="Abstract">arXiv:2312.09592</a> (replaced) [<a href="/pdf/2312.09592" title="Download PDF">pdf</a>, <a href="/format/2312.09592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Time Discretization for Exploring Spatial Superconvergence of  Discontinuous Galerkin Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiaozhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09709" title="Abstract">arXiv:2312.09709</a> (replaced) [<a href="/pdf/2312.09709" title="Download PDF">pdf</a>, <a href="/format/2312.09709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParsNets: A Parsimonious Orthogonal and Low-Rank Linear Networks for  Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruibing Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaocheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10208" title="Abstract">arXiv:2312.10208</a> (replaced) [<a href="/pdf/2312.10208" title="Download PDF">pdf</a>, <a href="/format/2312.10208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-based Surgical Skill Assessment using Tree-based Gaussian Process  Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+A">Arefeh Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+M+J">Mohammad Javad Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Molaei%2C+A">Amir Molaei</a>, 
<a href="/search/cs?searchtype=author&query=Taghirad%2C+H+D">Hamid. D. Taghirad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10423" title="Abstract">arXiv:2312.10423</a> (replaced) [<a href="/pdf/2312.10423" title="Download PDF">pdf</a>, <a href="/format/2312.10423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Bayesian Optimization with Unknown Continuous Context  Distribution via Kernel Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaobin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lei Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+K">Ke Xue</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Accept
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10600" title="Abstract">arXiv:2312.10600</a> (replaced) [<a href="/pdf/2312.10600" title="Download PDF">pdf</a>, <a href="/format/2312.10600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Efficiently Annotate Images for Best-Performing Deep Learning  Based Segmentation Models: An Empirical Study with Weak and Noisy Annotations  and Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanxue Gu</a>, 
<a href="/search/cs?searchtype=author&query=Mazurowski%2C+M+A">Maciej A. Mazurowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10623" title="Abstract">arXiv:2312.10623</a> (replaced) [<a href="/pdf/2312.10623" title="Download PDF">pdf</a>, <a href="/format/2312.10623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Query-based API Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Moshi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Harzevili%2C+N+S">Nima Shiri Harzevili</a>, 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine Boaye Belle</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinqiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+M">Ming Zhen</a> (Jack)
<a href="/search/cs?searchtype=author&query=Jiang">Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11396" title="Abstract">arXiv:2312.11396</a> (replaced) [<a href="/pdf/2312.11396" title="Download PDF">pdf</a>, <a href="/format/2312.11396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAG-Edit: Localized Image Editing in Complex Scenarios via Mask-Based  Attention-Adjusted Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for project page, see <a href="https://mag-edit.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11460" title="Abstract">arXiv:2312.11460</a> (replaced) [<a href="/pdf/2312.11460" title="Download PDF">pdf</a>, <a href="/format/2312.11460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Internal Model: A Simple and Efficient Learner for Agile Legged  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+J">Junfeng Long</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiawei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Use 1 hour to train a quadruped robot capable of traversing any terrain under any disturbances in the open world, Project Page: <a href="https://github.com/OpenRobotLab/HIMLoco">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11462" title="Abstract">arXiv:2312.11462</a> (replaced) [<a href="/pdf/2312.11462" title="Download PDF">pdf</a>, <a href="/format/2312.11462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascade Speculative Drafting for Even Faster LLM Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaocong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiacheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenkai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11562" title="Abstract">arXiv:2312.11562</a> (replaced) [<a href="/pdf/2312.11562" title="Download PDF">pdf</a>, <a href="/format/2312.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Reasoning with Foundation Models: Concepts, Methodologies,  and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+R">Ruihang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Figures, 160 Pages, 750+ References, Project Page <a href="https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11779" title="Abstract">arXiv:2312.11779</a> (replaced) [<a href="/pdf/2312.11779" title="Download PDF">pdf</a>, <a href="/format/2312.11779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are you talking to [&#x27;xem&#x27;] or [&#x27;x&#x27;, &#x27;em&#x27;]? On Tokenization and  Addressing Misgendering in LLMs with Pronoun Tokenization Parity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ovalle%2C+A">Anaelia Ovalle</a>, 
<a href="/search/cs?searchtype=author&query=Mehrabi%2C+N">Ninareh Mehrabi</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Palash Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Dhamala%2C+J">Jwala Dhamala</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>, 
<a href="/search/cs?searchtype=author&query=Galstyan%2C+A">Aram Galstyan</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rahul Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2023 Neurips Queer in AI workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11836" title="Abstract">arXiv:2312.11836</a> (replaced) [<a href="/pdf/2312.11836" title="Download PDF">pdf</a>, <a href="/ps/2312.11836" title="Download PostScript">ps</a>, <a href="/format/2312.11836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AiDAC: A Low-Cost In-Memory Computing Architecture with All-Analog  Multi-Bit Compute and Interconnect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Z">Zihao Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Song Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yi Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11868" title="Abstract">arXiv:2312.11868</a> (replaced) [<a href="/pdf/2312.11868" title="Download PDF">pdf</a>, <a href="/format/2312.11868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Loco-manipulation on HECTOR: Humanoid for Enhanced ConTrol and  Open-source Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junchao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kolt%2C+O">Omar Kolt</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Manas Shah</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quan Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12067" title="Abstract">arXiv:2312.12067</a> (replaced) [<a href="/pdf/2312.12067" title="Download PDF">pdf</a>, <a href="/format/2312.12067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Policy Gradient in Multi-Player Markov Games with a Single  Controller: Convergence Beyond the Minty Property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anagnostides%2C+I">Ioannis Anagnostides</a>, 
<a href="/search/cs?searchtype=author&query=Panageas%2C+I">Ioannis Panageas</a>, 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Gabriele Farina</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12337" title="Abstract">arXiv:2312.12337</a> (replaced) [<a href="/pdf/2312.12337" title="Download PDF">pdf</a>, <a href="/format/2312.12337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable  Generalizable 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charatan%2C+D">David Charatan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Sitzmann%2C+V">Vincent Sitzmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://dcharatan.github.io/pixelsplat">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12450" title="Abstract">arXiv:2312.12450</a> (replaced) [<a href="/pdf/2312.12450" title="Download PDF">pdf</a>, <a href="/format/2312.12450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can It Edit? Evaluating the Ability of Large Language Models to Follow  Code Editing Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+A">Akul Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Shinn%2C+N">Noah Shinn</a>, 
<a href="/search/cs?searchtype=author&query=Brennan-Jones%2C+A">Abby Brennan-Jones</a>, 
<a href="/search/cs?searchtype=author&query=Lozhkov%2C+A">Anton Lozhkov</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12464" title="Abstract">arXiv:2312.12464</a> (replaced) [<a href="/pdf/2312.12464" title="Download PDF">pdf</a>, <a href="/format/2312.12464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Serialization of Tabular Data for Few-shot Classification  with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaitly%2C+S">Sukriti Jaitly</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+T">Tanay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Shugani%2C+A">Ashish Shugani</a>, 
<a href="/search/cs?searchtype=author&query=Grewal%2C+R+S">Razik Singh Grewal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12473" title="Abstract">arXiv:2312.12473</a> (replaced) [<a href="/pdf/2312.12473" title="Download PDF">pdf</a>, <a href="/ps/2312.12473" title="Download PostScript">ps</a>, <a href="/format/2312.12473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Social Robot Behavior in Group Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nichols%2C+E">Eric Nichols</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+R">Randy Gomez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12635" title="Abstract">arXiv:2312.12635</a> (replaced) [<a href="/pdf/2312.12635" title="Download PDF">pdf</a>, <a href="/format/2312.12635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealCraft: Attention Control as A Solution for Zero-shot Long Video  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shutong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pokorny%2C+F+T">Florian T. Pokorny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12655" title="Abstract">arXiv:2312.12655</a> (replaced) [<a href="/pdf/2312.12655" title="Download PDF">pdf</a>, <a href="/format/2312.12655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Transformers Learn Sequential Function Classes In Context?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campbell%2C+R">Ryan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+E">Emma Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+E">Evan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Vir%2C+R">Reya Vir</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+E">Ethan Hsiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12763" title="Abstract">arXiv:2312.12763</a> (replaced) [<a href="/pdf/2312.12763" title="Download PDF">pdf</a>, <a href="/format/2312.12763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMD:Anatomical Motion Diffusion with Interpretable Motion Decomposition  and Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Beibei Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12863" title="Abstract">arXiv:2312.12863</a> (replaced) [<a href="/pdf/2312.12863" title="Download PDF">pdf</a>, <a href="/format/2312.12863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning While Providing Model as a Service: Joint Training  and Inference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengchao Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Computer Communications (INFOCOM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12918" title="Abstract">arXiv:2312.12918</a> (replaced) [<a href="/pdf/2312.12918" title="Download PDF">pdf</a>, <a href="/format/2312.12918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi-Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, AAAI 2024 Workshop on Responsible Language Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12999" title="Abstract">arXiv:2312.12999</a> (replaced) [<a href="/pdf/2312.12999" title="Download PDF">pdf</a>, <a href="/format/2312.12999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Mindset: An MBTI Exploration of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+L">Liuzhenghao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">YongHong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13016" title="Abstract">arXiv:2312.13016</a> (replaced) [<a href="/pdf/2312.13016" title="Download PDF">pdf</a>, <a href="/format/2312.13016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuming Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">You Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guoxian Song</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yichun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Di Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linjie Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13032" title="Abstract">arXiv:2312.13032</a> (replaced) [<a href="/pdf/2312.13032" title="Download PDF">pdf</a>, <a href="/format/2312.13032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NodeMixup: Tackling Under-Reaching for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Long Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13115" title="Abstract">arXiv:2312.13115</a> (replaced) [<a href="/pdf/2312.13115" title="Download PDF">pdf</a>, <a href="/ps/2312.13115" title="Download PostScript">ps</a>, <a href="/format/2312.13115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach for Rapid Development Based on ChatGPT and Prompt  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Youjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianjun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13136" title="Abstract">arXiv:2312.13136</a> (replaced) [<a href="/pdf/2312.13136" title="Download PDF">pdf</a>, <a href="/format/2312.13136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular Hypergraph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+J">Junwu Chen</a>, 
<a href="/search/physics?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13139" title="Abstract">arXiv:2312.13139</a> (replaced) [<a href="/pdf/2312.13139" title="Download PDF">pdf</a>, <a href="/format/2312.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing Large-Scale Video Generative Pre-training for Visual Robot  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Ya Jing</a>, 
<a href="/search/cs?searchtype=author&query=Cheang%2C+C">Chilam Cheang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangzeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiafeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+T">Tao Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://GR1-Manipulation.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13271" title="Abstract">arXiv:2312.13271</a> (replaced) [<a href="/pdf/2312.13271" title="Download PDF">pdf</a>, <a href="/format/2312.13271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repaint123: Fast and High-quality One Image to 3D Generation with  Progressive Controllable 2D Repainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhenyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yatian Pang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yida Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://junwuzhang19.github.io/repaint123/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13279" title="Abstract">arXiv:2312.13279</a> (replaced) [<a href="/pdf/2312.13279" title="Download PDF">pdf</a>, <a href="/format/2312.13279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stretch with Stretch: Physical Therapy Exercise Games Led by a Mobile  Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamsey%2C+M">Matthew Lamsey</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">You Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wells%2C+M+D">Meredith D. Wells</a>, 
<a href="/search/cs?searchtype=author&query=Beatty%2C+M">Madeline Beatty</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zexuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Arjun Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Washington%2C+K">Kendra Washington</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+J">Jerry Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Kuppuswamy%2C+N">Naveen Kuppuswamy</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+E">Elizabeth Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Wallenstein%2C+A">Arielle Wallenstein</a>, 
<a href="/search/cs?searchtype=author&query=Hackney%2C+M+E">Madeleine E. Hackney</a>, 
<a href="/search/cs?searchtype=author&query=Kemp%2C+C+C">Charles C. Kemp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item294">Cross-lists</a></li>
<li><a href="#item342">Replacements</a></li>
</ul>
<small>[ total of 554 entries:  <b>1-554</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
