<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu  7 Dec 23  to  Fri  8 Dec 23, announced Mon, 11 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item290">Cross-lists</a></li>
<li><a href="#item324">Replacements</a></li>
</ul>
<small>[ total of 511 entries:  <b>1-511</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 11 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04569" title="Abstract">arXiv:2312.04569</a> [<a href="/pdf/2312.04569" title="Download PDF">pdf</a>, <a href="/ps/2312.04569" title="Download PostScript">ps</a>, <a href="/format/2312.04569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do referees integrate evaluation criteria into their overall  judgment? Evidence from grant peer review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hug%2C+S+E">Sven E. Hug</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Little is known whether peer reviewers use the same evaluation criteria and
how they integrate the criteria into their overall judgment. This study
therefore proposed two assessment styles based on theoretical perspectives and
normative positions. According to the case-by-case style, referees use many and
different criteria, weight criteria on a case-by-case basis, and integrate
criteria in a complex, non-mechanical way into their overall judgment.
According to the uniform style, referees use a small fraction of the available
criteria, apply the same criteria, weight the criteria in the same way, and
integrate the criteria based on simple rules (i.e., fast-and-frugal
heuristics). These two styles were examined using a unique dataset from a
career funding scheme that contained a comparatively large number of evaluation
criteria. A heuristic (fast-and-frugal trees) and a complex procedure (logistic
regression) were employed to describe how referees integrate the criteria into
their overall judgment. The logistic regression predicted the referees' overall
assessment with high accuracy and slightly more accurately than the
fast-and-frugal trees. Overall, the results of this study support the uniform
style but also indicate that the uniform style needs to be revised as follows:
referees use many criteria and integrate the criteria using complex rules.
However, and most importantly, the revised style could describe most - but not
all - of the referees' judgments. Future studies should therefore examine how
referees' judgments can be characterized in those cases where the uniform style
failed. Moreover, the evaluation process of referees should be studied in more
empirical and theoretical detail.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04570" title="Abstract">arXiv:2312.04570</a> [<a href="/pdf/2312.04570" title="Download PDF">pdf</a>, <a href="/format/2312.04570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for 2D Physics-Based Object Manipulation in  Clutter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Renna%2C+L">Luca Renna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deep Reinforcement Learning (DRL) is a quickly evolving research field rooted
in operations research and behavioural psychology, with potential applications
extending across various domains, including robotics. This thesis delineates
the background of modern Reinforcement Learning (RL), starting with the
framework constituted by the Markov decision processes, Markov properties,
goals and rewards, agent-environment interactions, and policies. We explain the
main types of algorithms commonly used in RL, including value-based, policy
gradient, and actor-critic methods, with a special emphasis on DQN, A2C and
PPO. We then give a short literature review on some widely adopted frameworks
for implementing RL algorithms and environments. Subsequently, we present
Bidimensional Gripper Environment (BGE), a virtual simulator based on the
Pymunk physics engine we developed to analyse top-down bidimensional object
manipulation. The methodology section frames our agent-environment interaction
as a Markov decision process, such that we can apply our RL algorithms. We list
various goal formulation strategies, including reward shaping and curriculum
learning. We also employ different steps of observation preprocessing to reduce
the computational workload required. In the experimental phase, we run through
a series of scenarios of increasing difficulty. We start with a simple static
scenario and then gradually increase the amount of stochasticity. Whenever the
agents show difficulty in learning, we counteract by increasing the degree of
reward shaping and curriculum learning. These experiments demonstrate the
substantial limitations and pitfalls of model-free algorithms under changing
dynamics. In conclusion, we present a summary of our findings and remarks. We
then outline potential future work to improve our methodology and possibly
expand to real-world systems.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04571" title="Abstract">arXiv:2312.04571</a> [<a href="/pdf/2312.04571" title="Download PDF">pdf</a>, <a href="/format/2312.04571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwarMer: A Decentralized Localization Framework for Flying Light Specks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alimohammadzadeh%2C+H">Hamed Alimohammadzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Ghandeharizadeh%2C+S">Shahram Ghandeharizadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code available at <a href="https://github.com/flyinglightspeck/SwarMer.">this https URL</a> See <a href="https://youtu.be/BIiBxD_aUz8">this https URL</a> for a MATLAB demonstration of SwarMer, <a href="https://youtu.be/Lh11tWWOP5Y">this https URL</a> for two relative localization techniques as SwarMer plugins. SwarMer is able to transition FLSs from illuminating one point cloud to the next point cloud, see <a href="https://youtu.be/4GhhlSq4UrM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
<p class="mathjax">Swarm-Merging, SwarMer, is a decentralized framework to localize Flying Light
Specks (FLSs) to render 2D and 3D shapes. An FLS is a miniature sized drone
equipped with one or more light sources to generate different colors and
textures with adjustable brightness. It is battery powered, network enabled
with storage and processing capability to implement a decentralized algorithm
such as SwarMer. An FLS is unable to render a shape by itself. SwarMer uses the
inter-FLS relationship effect of its organizational framework to compensate for
the simplicity of each individual FLS, enabling a swarm of cooperating FLSs to
render complex shapes. SwarMer is resilient to both FLSs failing and FLSs
leaving to charge their battery. It is fast, highly accurate, and scales to
remain effective when a shape consists of a large number of FLSs.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04572" title="Abstract">arXiv:2312.04572</a> [<a href="/pdf/2312.04572" title="Download PDF">pdf</a>, <a href="/ps/2312.04572" title="Download PostScript">ps</a>, <a href="/format/2312.04572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing LSTM for Nonlinear Ship Deck Motion Prediction in UAV  Autonomous Landing amidst High Sea States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Feifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+W">Wenyuan Cong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinmin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yue Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, accept by ICANDVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous landing of UAVs in high sea states requires the UAV to land
exclusively during the ship deck's "rest period," coinciding with minimal
movement. Given this scenario, determining the ship's "rest period" based on
its movement patterns becomes a fundamental prerequisite for addressing this
challenge. This study employs the Long Short-Term Memory (LSTM) neural network
to predict the ship's motion across three dimensions: longi-tudinal,
transverse, and vertical waves. In the absence of actual ship data under high
sea states, this paper employs a composite sine wave model to simulate ship
deck motion. Through this approach, a highly accurate model is established,
exhibiting promising outcomes within various stochastic sine wave combination
models.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04573" title="Abstract">arXiv:2312.04573</a> [<a href="/pdf/2312.04573" title="Download PDF">pdf</a>, <a href="/ps/2312.04573" title="Download PostScript">ps</a>, <a href="/format/2312.04573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Criteria and Tips for Choosing Suitable Journal for Your Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hammad%2C+M">Mohamed Hammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> No comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Selecting the right journal for your research paper is a pivotal decision in
the academic publishing journey. This paper aims to guide researchers through
the process of choosing a suitable journal for their work by discussing key
criteria and offering practical tips.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04574" title="Abstract">arXiv:2312.04574</a> [<a href="/pdf/2312.04574" title="Download PDF">pdf</a>, <a href="/format/2312.04574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Visual Computing for Inverse Problems and Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spielberg%2C+A">Andrew Spielberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+F">Fangcheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Rematas%2C+K">Konstantinos Rematas</a>, 
<a href="/search/cs?searchtype=author&query=Jatavallabhula%2C+K+M">Krishna Murthy Jatavallabhula</a>, 
<a href="/search/cs?searchtype=author&query=Oztireli%2C+C">Cengiz Oztireli</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tzu-Mao Li</a>, 
<a href="/search/cs?searchtype=author&query=Nowrouzezahrai%2C+D">Derek Nowrouzezahrai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Originally designed for applications in computer graphics, visual computing
(VC) methods synthesize information about physical and virtual worlds, using
prescribed algorithms optimized for spatial computing. VC is used to analyze
geometry, physically simulate solids, fluids, and other media, and render the
world via optical techniques. These fine-tuned computations that operate
explicitly on a given input solve so-called forward problems, VC excels at. By
contrast, deep learning (DL) allows for the construction of general algorithmic
models, side stepping the need for a purely first principles-based approach to
problem solving. DL is powered by highly parameterized neural network
architectures -- universal function approximators -- and gradient-based search
algorithms which can efficiently search that large parameter space for optimal
models. This approach is predicated by neural network differentiability, the
requirement that analytic derivatives of a given problem's task metric can be
computed with respect to neural network's parameters. Neural networks excel
when an explicit model is not known, and neural network training solves an
inverse problem in which a model is computed from data.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04576" title="Abstract">arXiv:2312.04576</a> [<a href="/pdf/2312.04576" title="Download PDF">pdf</a>, <a href="/format/2312.04576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Open Review-Based (ORB) dataset: Towards Automatic Assessment of  Scientific Papers and Experiment Proposals in High-Energy Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szumega%2C+J">Jaroslaw Szumega</a>, 
<a href="/search/cs?searchtype=author&query=Bougueroua%2C+L">Lamine Bougueroua</a>, 
<a href="/search/cs?searchtype=author&query=Gkotse%2C+B">Blerina Gkotse</a>, 
<a href="/search/cs?searchtype=author&query=Jouvelot%2C+P">Pierre Jouvelot</a>, 
<a href="/search/cs?searchtype=author&query=Ravotti%2C+F">Federico Ravotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, supplementary material included, dataset available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">With the Open Science approach becoming important for research, the evolution
towards open scientific-paper reviews is making an impact on the scientific
community. However, there is a lack of publicly available resources for
conducting research activities related to this subject, as only a limited
number of journals and conferences currently allow access to their review
process for interested parties. In this paper, we introduce the new
comprehensive Open Review-Based dataset (ORB); it includes a curated list of
more than 36,000 scientific papers with their more than 89,000 reviews and
final decisions. We gather this information from two sources: the
OpenReview.net and SciPost.org websites. However, given the volatile nature of
this domain, the software infrastructure that we introduce to supplement the
ORB dataset is designed to accommodate additional resources in the future. The
ORB deliverables include (1) Python code (interfaces and implementations) to
translate document data and metadata into a structured and high-level
representation, (2) an ETL process (Extract, Transform, Load) to facilitate the
automatic updates from defined sources and (3) data files representing the
structured data. The paper presents our data architecture and an overview of
the collected data along with relevant statistics. For illustration purposes,
we also discuss preliminary Natural-Language-Processing-based experiments that
aim to predict (1) papers' acceptance based on their textual embeddings, and
(2) grading statistics inferred from embeddings as well. We believe ORB
provides a valuable resource for researchers interested in open science and
review, with our implementation easing the use of this data for further
analysis and experimentation. We plan to update ORB as the field matures as
well as introduce new resources even more fitted to dedicated scientific
domains such as High-Energy Physics.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04577" title="Abstract">arXiv:2312.04577</a> [<a href="/pdf/2312.04577" title="Download PDF">pdf</a>, <a href="/format/2312.04577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Evolution of DNS Security and Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csikor%2C+L">Levente Csikor</a>, 
<a href="/search/cs?searchtype=author&query=Divakaran%2C+D+M">Dinil Mon Divakaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures - original manuscript submitted to IEEE Security &amp; Privacy Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">DNS, one of the fundamental protocols of the TCP/IP stack, has evolved over
the years to protect against threats and attacks. This study examines the risks
associated with DNS and explores recent advancements that contribute towards
making the DNS ecosystem resilient against various attacks while safeguarding
user privacy.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04578" title="Abstract">arXiv:2312.04578</a> [<a href="/pdf/2312.04578" title="Download PDF">pdf</a>, <a href="/format/2312.04578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Psychological Generalist AI: A Survey of Current Applications  of Large Language Models and Future Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+G">Guanghui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Changwei Song</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Hongzhi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Huijing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B+X">Bing Xiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The complexity of psychological principles underscore a significant societal
challenge, given the vast social implications of psychological problems.
Bridging the gap between understanding these principles and their actual
clinical and real-world applications demands rigorous exploration and adept
implementation. In recent times, the swift advancement of highly adaptive and
reusable artificial intelligence (AI) models has emerged as a promising way to
unlock unprecedented capabilities in the realm of psychology. This paper
emphasizes the importance of performance validation for these large-scale AI
models, emphasizing the need to offer a comprehensive assessment of their
verification from diverse perspectives. Moreover, we review the cutting-edge
advancements and practical implementations of these expansive models in
psychology, highlighting pivotal work spanning areas such as social media
analytics, clinical nursing insights, vigilant community monitoring, and the
nuanced exploration of psychological theories. Based on our review, we project
an acceleration in the progress of psychological fields, driven by these
large-scale AI models. These future generalist AI models harbor the potential
to substantially curtail labor costs and alleviate social stress. However, this
forward momentum will not be without its set of challenges, especially when
considering the paradigm changes and upgrades required for medical
instrumentation and related applications.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04579" title="Abstract">arXiv:2312.04579</a> [<a href="/pdf/2312.04579" title="Download PDF">pdf</a>, <a href="/format/2312.04579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zkFDL: An efficient and privacy-preserving decentralized federated  learning with zero knowledge proof
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+M">Mojtaba Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Nourmohammadi%2C+R">Reza Nourmohammadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated leaning (FL) has been frequently used in various field of studies
and businesses. Traditional centralized FL systems suffer from serious issues.
To address these concerns, decentralized federated learning (DFL) systems have
been introduced in recent years in which with the help of blockchains, try to
achieve more integrity and efficiency. On the other hand, privacy-preserving is
an uncovered part of these systems. To address this, and also scaling the
blockchain-based computations, we propose a zero knowledge proof (ZKP) based
aggregator (zkDFL) that allows clients to share their large-scale model
parameters with a trusted centralized server without revealing their individual
data to other clients. We utilize blockchain technology to manage the
aggregation algorithm via smart contracts. The server performs a ZKP algorithm
to prove to the clients that the aggregation is done according to the accepted
algorithm. The server can also prove that all inputs of clients have been used.
We evaluate our measure through a public dataset about wearable internet of
things. As demonstrated by numerical evaluations, zkDFL introduces
verifiability of correctness of aggregation process and enhances the privacy
protection and scalability of DFL systems, while the gas cost has declined
significantly.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04584" title="Abstract">arXiv:2312.04584</a> [<a href="/pdf/2312.04584" title="Download PDF">pdf</a>, <a href="/format/2312.04584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Sample-specific Backdoor Attack with Clean Labels via Attribute  Trigger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingyan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junfeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Currently, sample-specific backdoor attacks (SSBAs) are the most advanced and
malicious methods since they can easily circumvent most of the current backdoor
defenses. In this paper, we reveal that SSBAs are not sufficiently stealthy due
to their poisoned-label nature, where users can discover anomalies if they
check the image-label relationship. In particular, we demonstrate that it is
ineffective to directly generalize existing SSBAs to their clean-label variants
by poisoning samples solely from the target class. We reveal that it is
primarily due to two reasons, including \textbf{(1)} the `antagonistic effects'
of ground-truth features and \textbf{(2)} the learning difficulty of
sample-specific features. Accordingly, trigger-related features of existing
SSBAs cannot be effectively learned under the clean-label setting due to their
mild trigger intensity required for ensuring stealthiness. We argue that the
intensity constraint of existing SSBAs is mostly because their trigger patterns
are `content-irrelevant' and therefore act as `noises' for both humans and
DNNs. Motivated by this understanding, we propose to exploit content-relevant
features, $a.k.a.$ (human-relied) attributes, as the trigger patterns to design
clean-label SSBAs. This new attack paradigm is dubbed backdoor attack with
attribute trigger (BAAT). Extensive experiments are conducted on benchmark
datasets, which verify the effectiveness of our BAAT and its resistance to
existing defenses.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04586" title="Abstract">arXiv:2312.04586</a> [<a href="/pdf/2312.04586" title="Download PDF">pdf</a>, <a href="/format/2312.04586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated SELinux RBAC Policy Verification Using SMT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pahuja%2C+D">Divyam Pahuja</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Alvin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tsoutsman%2C+K">Klim Tsoutsman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages (excluding appendices), 2 figures, 3 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Security-Enhanced Linux (SELinux) is a Linux kernel module that allows for a
role-based access control (RBAC) mechanism. It provides a fine-grained security
framework enabling system administrators to define security policies at the
system and application level. Whilst SELinux offers robust security features
through a customisable, powerful RBAC model, its manual policy management is
prone to error, leaving the system vulnerable to accidental misconfigurations
or loopholes. We present a tool to automate the conversion of SELinux policies
into satisfiability modulo theories (SMT), enabling the verification of the
intended security configurations using automated theorem proving. Our tool is
capable of flagging common policy misconfigurations by asserting consistency
between supplied RBAC policies and the intended specification by the user in
SMT. RBAC policies are inherently complicated to verify entirely. We envision
that the automated tool presented here can be further extended to identify an
even broader range of policy misconfigurations, relieving the burden of
managing convoluted policies on system administrators.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04587" title="Abstract">arXiv:2312.04587</a> [<a href="/pdf/2312.04587" title="Download PDF">pdf</a>, <a href="/ps/2312.04587" title="Download PostScript">ps</a>, <a href="/format/2312.04587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedBayes: A Zero-Trust Federated Learning Aggregation to Defend Against  Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vucovich%2C+M">Marc Vucovich</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+D">Devin Quinn</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kevin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Redino%2C+C">Christopher Redino</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Abdul Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+E">Edward Bowen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE CCWC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning has created a decentralized method to train a machine
learning model without needing direct access to client data. The main goal of a
federated learning architecture is to protect the privacy of each client while
still contributing to the training of the global model. However, the main
advantage of privacy in federated learning is also the easiest aspect to
exploit. Without being able to see the clients' data, it is difficult to
determine the quality of the data. By utilizing data poisoning methods, such as
backdoor or label-flipping attacks, or by sending manipulated information about
their data back to the server, malicious clients are able to corrupt the global
model and degrade performance across all clients within a federation. Our novel
aggregation method, FedBayes, mitigates the effect of a malicious client by
calculating the probabilities of a client's model weights given to the prior
model's weights using Bayesian statistics. Our results show that this approach
negates the effects of malicious clients and protects the overall federation.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04590" title="Abstract">arXiv:2312.04590</a> [<a href="/pdf/2312.04590" title="Download PDF">pdf</a>, <a href="/format/2312.04590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconciling AI Performance and Data Reconstruction Resilience for  Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziller%2C+A">Alexander Ziller</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+T+T">Tamara T. Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Stieger%2C+S">Simon Stieger</a>, 
<a href="/search/cs?searchtype=author&query=Feiner%2C+L">Leonhard Feiner</a>, 
<a href="/search/cs?searchtype=author&query=Brandt%2C+J">Johannes Brandt</a>, 
<a href="/search/cs?searchtype=author&query=Braren%2C+R">Rickmer Braren</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial Intelligence (AI) models are vulnerable to information leakage of
their training data, which can be highly sensitive, for example in medical
imaging. Privacy Enhancing Technologies (PETs), such as Differential Privacy
(DP), aim to circumvent these susceptibilities. DP is the strongest possible
protection for training models while bounding the risks of inferring the
inclusion of training samples or reconstructing the original data. DP achieves
this by setting a quantifiable privacy budget. Although a lower budget
decreases the risk of information leakage, it typically also reduces the
performance of such models. This imposes a trade-off between robust performance
and stringent privacy. Additionally, the interpretation of a privacy budget
remains abstract and challenging to contextualize. In this study, we contrast
the performance of AI models at various privacy budgets against both,
theoretical risk bounds and empirical success of reconstruction attacks. We
show that using very large privacy budgets can render reconstruction attacks
impossible, while drops in performance are negligible. We thus conclude that
not using DP -- at all -- is negligent when applying AI models to sensitive
data. We deem those results to lie a foundation for further debates on striking
a balance between privacy risks and model performance.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04591" title="Abstract">arXiv:2312.04591</a> [<a href="/pdf/2312.04591" title="Download PDF">pdf</a>, <a href="/format/2312.04591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Energy-Efficient Massive MIMO: Graph Neural Network Precoding for  Mitigating Non-Linear PA Distortion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feys%2C+T">Thomas Feys</a>, 
<a href="/search/cs?searchtype=author&query=Van+der+Perre%2C+L">Liesbet Van der Perre</a>, 
<a href="/search/cs?searchtype=author&query=Rottenberg%2C+F">Fran&#xe7;ois Rottenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Massive MIMO systems are typically designed assuming linear power amplifiers
(PAs). However, PAs are most energy efficient close to saturation, where
non-linear distortion arises. For conventional precoders, this distortion can
coherently combine at user locations, limiting performance. We propose a graph
neural network (GNN) to learn a mapping between channel and precoding matrices,
which maximizes the sum rate affected by non-linear distortion, using a
high-order polynomial PA model. In the distortion-limited regime, this
GNN-based precoder outperforms zero forcing (ZF), ZF plus digital
pre-distortion (DPD) and the distortion-aware beamforming (DAB) precoder from
the state-of-the-art. At an input back-off of -3 dB the proposed precoder
compared to ZF increases the sum rate by 8.60 and 8.84 bits/channel use for two
and four users respectively. Radiation patterns show that these gains are
achieved by transmitting the non-linear distortion in non-user directions. In
the four user-case, for a fixed sum rate, the total consumed power (PA and
processing) of the GNN precoder is 3.24 and 1.44 times lower compared to ZF and
ZF plus DPD respectively. A complexity analysis shows six orders of magnitude
reduction compared to DAB precoding. This opens perspectives to operate PAs
closer to saturation, which drastically increases their energy efficiency.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04593" title="Abstract">arXiv:2312.04593</a> [<a href="/pdf/2312.04593" title="Download PDF">pdf</a>, <a href="/format/2312.04593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster Shift Keying: Covert Transmission of Information via Cluster  Synchronization in Chaotic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sar%C4%B1%2C+Z">Zekeriya Sar&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnel%2C+S">Serkan G&#xfc;nel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">A network of chaotic systems can be designed in such a way that the cluster
patterns formed by synchronous nodes can be controlled through the coupling
parameters. We present a novel approach to exploit such a network for covert
communication purposes, where controlled clusters encode the symbols
spatio-temporally. The cluster synchronization network is divided into two
subnetworks as transmitter and receiver. First, we specifically design the
network whose controlled parameters reside in the transmitter. Second, we
ensure that the nodes of the links connecting the transmitter and receiver are
not in the same clusters for all the control parameters. The former condition
ensures that the control parameters changed at the transmitter change the whole
clustering scheme. The second condition enforces the transmitted signals are
always continuous and chaotic. Hence, the transmitted signals are not modulated
by the information directly, but distributed over the links connecting the
subnetworks. The information cannot be deciphered by eavesdropping on the
channel links without knowing the network topology. The performance has been
assessed by extensive simulations of bit error rates under noisy channel
conditions.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04594" title="Abstract">arXiv:2312.04594</a> [<a href="/pdf/2312.04594" title="Download PDF">pdf</a>, <a href="/format/2312.04594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedGeo: Privacy-Preserving User Next Location Prediction with Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chung Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+T">Taekyoon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Mincheol Cho</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minsung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 31st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A User Next Location Prediction (UNLP) task, which predicts the next location
that a user will move to given his/her trajectory, is an indispensable task for
a wide range of applications. Previous studies using large-scale trajectory
datasets in a single server have achieved remarkable performance in UNLP task.
However, in real-world applications, legal and ethical issues have been raised
regarding privacy concerns leading to restrictions against sharing human
trajectory datasets to any other server. In response, Federated Learning (FL)
has emerged to address the personal privacy issue by collaboratively training
multiple clients (i.e., users) and then aggregating them. While previous
studies employed FL for UNLP, they are still unable to achieve reliable
performance because of the heterogeneity of clients' mobility. To tackle this
problem, we propose the Federated Learning for Geographic Information (FedGeo),
a FL framework specialized for UNLP, which alleviates the heterogeneity of
clients' mobility and guarantees personal privacy protection. Firstly, we
incorporate prior global geographic adjacency information to the local client
model, since the spatial correlation between locations is trained partially in
each client who has only a heterogeneous subset of the overall trajectories in
FL. We also introduce a novel aggregation method that minimizes the gap between
client models to solve the problem of client drift caused by differences
between client models when learning with their heterogeneous data. Lastly, we
probabilistically exclude clients with extremely heterogeneous data from the FL
process by focusing on clients who visit relatively diverse locations. We show
that FedGeo is superior to other FL methods for model performance in UNLP task.
We also validated our model in a real-world application using our own
customers' mobile phones and the FL agent system.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04595" title="Abstract">arXiv:2312.04595</a> [<a href="/pdf/2312.04595" title="Download PDF">pdf</a>, <a href="/ps/2312.04595" title="Download PostScript">ps</a>, <a href="/format/2312.04595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating The Accuracy of Classification Algorithms for Detecting Heart  Disease Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alariyibi%2C+A">Alhaam Alariyibi</a>, 
<a href="/search/cs?searchtype=author&query=El-Jarai%2C+M">Mohamed El-Jarai</a>, 
<a href="/search/cs?searchtype=author&query=Maatuk%2C+A">Abdelsalam Maatuk</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning and Applications: An International Journal
  (MLAIJ) Vol.10, No.4, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The healthcare industry generates enormous amounts of complex clinical data
that make the prediction of disease detection a complicated process. In medical
informatics, making effective and efficient decisions is very important. Data
Mining (DM) techniques are mainly used to identify and extract hidden patterns
and interesting knowledge to diagnose and predict diseases in medical datasets.
Nowadays, heart disease is considered one of the most important problems in the
healthcare field. Therefore, early diagnosis leads to a reduction in deaths. DM
techniques have proven highly effective for predicting and diagnosing heart
diseases. This work utilizes the classification algorithms with a medical
dataset of heart disease; namely, J48, Random Forest, and Na\"ive Bayes to
discover the accuracy of their performance. We also examine the impact of the
feature selection method. A comparative and analysis study was performed to
determine the best technique using Waikato Environment for Knowledge Analysis
(Weka) software, version 3.8.6. The performance of the utilized algorithms was
evaluated using standard metrics such as accuracy, sensitivity and specificity.
The importance of using classification techniques for heart disease diagnosis
has been highlighted. We also reduced the number of attributes in the dataset,
which showed a significant improvement in prediction accuracy. The results
indicate that the best algorithm for predicting heart disease was Random Forest
with an accuracy of 99.24%.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04596" title="Abstract">arXiv:2312.04596</a> [<a href="/pdf/2312.04596" title="Download PDF">pdf</a>, <a href="/format/2312.04596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Analysis of Encrypted Malicious Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shekhawat%2C+A+S">Anish Singh Shekhawat</a>, 
<a href="/search/cs?searchtype=author&query=Di+Troia%2C+F">Fabio Di Troia</a>, 
<a href="/search/cs?searchtype=author&query=Stamp%2C+M">Mark Stamp</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 125, 1 July 2019, Pages
  130-141
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years there has been a dramatic increase in the number of malware
attacks that use encrypted HTTP traffic for self-propagation or communication.
Antivirus software and firewalls typically will not have access to encryption
keys, and therefore direct detection of malicious encrypted data is unlikely to
succeed. However, previous work has shown that traffic analysis can provide
indications of malicious intent, even in cases where the underlying data
remains encrypted. In this paper, we apply three machine learning techniques to
the problem of distinguishing malicious encrypted HTTP traffic from benign
encrypted traffic and obtain results comparable to previous work. We then
consider the problem of feature analysis in some detail. Previous work has
often relied on human expertise to determine the most useful and informative
features in this problem domain. We demonstrate that such feature-related
information can be obtained directly from machine learning models themselves.
We argue that such a machine learning based approach to feature analysis is
preferable, as it is more reliable, and we can, for example, uncover relatively
unintuitive interactions between features.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04597" title="Abstract">arXiv:2312.04597</a> [<a href="/pdf/2312.04597" title="Download PDF">pdf</a>, <a href="/format/2312.04597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrustFed: A Reliable Federated Learning Framework with Malicious-Attack  Resistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hangn Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianhong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xianhua Niu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Gang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As a key technology in 6G research, federated learning (FL) enables
collaborative learning among multiple clients while ensuring individual data
privacy. However, malicious attackers among the participating clients can
intentionally tamper with the training data or the trained model, compromising
the accuracy and trustworthiness of the system. To address this issue, in this
paper, we propose a hierarchical audit-based FL (HiAudit-FL) framework, with
the aim to enhance the reliability and security of the learning process. The
hierarchical audit process includes two stages, namely model-audit and
parameter-audit. In the model-audit stage, a low-overhead audit method is
employed to identify suspicious clients. Subsequently, in the parameter-audit
stage, a resource-consuming method is used to detect all malicious clients with
higher accuracy among the suspicious ones. Specifically, we execute the model
audit method among partial clients for multiple rounds, which is modeled as a
partial observation Markov decision process (POMDP) with the aim to enhance the
robustness and accountability of the decision-making in complex and uncertain
environments. Meanwhile, we formulate the problem of identifying malicious
attackers through a multi-round audit as an active sequential hypothesis
testing problem and leverage a diffusion model-based AI-Enabled audit selection
strategy (ASS) to decide which clients should be audited in each round. To
accomplish efficient and effective audit selection, we design a DRL-ASS
algorithm by incorporating the ASS in a deep reinforcement learning (DRL)
framework. Our simulation results demonstrate that HiAudit-FL can effectively
identify and handle potential malicious users accurately, with small system
overhead.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04598" title="Abstract">arXiv:2312.04598</a> [<a href="/pdf/2312.04598" title="Download PDF">pdf</a>, <a href="/format/2312.04598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalization of Robot Collision Detection Method based on Conformal  Geometric Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shanyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhiping Shi</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Ximeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Cooperative robots can significantly assist people in their productive
activities, improving the quality of their works. Collision detection is vital
to ensure the safe and stable operation of cooperative robots in productive
activities. As an advanced geometric language, conformal geometric algebra can
simplify the construction of the robot collision model and the calculation of
collision distance. Compared with the formal method based on conformal
geometric algebra, the traditional method may have some defects which are
difficult to find in the modelling and calculation. We use the formal method
based on conformal geometric algebra to study the collision detection problem
of cooperative robots. This paper builds formal models of geometric primitives
and the robot body based on the conformal geometric algebra library in HOL
Light. We analyse the shortest distance between geometric primitives and prove
their collision determination conditions. Based on the above contents, we
construct a formal verification framework for the robot collision detection
method. By the end of this paper, we apply the proposed framework to collision
detection between two single-arm industrial cooperative robots. The flexibility
and reliability of the proposed framework are verified by constructing a
general collision model and a special collision model for two single-arm
industrial cooperative robots.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04602" title="Abstract">arXiv:2312.04602</a> [<a href="/pdf/2312.04602" title="Download PDF">pdf</a>, <a href="/ps/2312.04602" title="Download PostScript">ps</a>, <a href="/format/2312.04602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Channel Estimation for Extremely Large-Scale MIMO in Near  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jindan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yijian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The extremely large-scale massive multiple-input multiple-output (XL-MIMO)
has the potential to achieve boosted spectral efficiency and refined spatial
resolution for future wireless networks. However, channel estimation for
XL-MIMO is challenging since the large number of antennas results in high
computational complexity with the near-field effect. In this letter, we propose
a low-complexity sequential angle-distance channel estimation (SADCE) method
for near-field XL-MIMO systems equipped with uniformly planar arrays (UPA).
Specifically, we first successfully decouple the angle and distance parameters,
which allows us to devise a two-dimensional discrete Fourier transform (2D-DFT)
method for angle parameters estimation. Then, a low-complexity distance
estimation method is proposed with a closed-form solution. Compared with
existing methods, the proposed method achieves significant performance gain
with noticeably reduced computational complexity.Numerical results verify the
superiority of the proposed near-field channel estimation algorithm.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04603" title="Abstract">arXiv:2312.04603</a> [<a href="/pdf/2312.04603" title="Download PDF">pdf</a>, <a href="/format/2312.04603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All Polarized but Still Different: a Multi-factorial Metric to  Discriminate between Polarization Behaviors on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Treuillier%2C+C">Celina Treuillier</a> (UL, CNRS, LORIA), 
<a href="/search/cs?searchtype=author&query=Castagnos%2C+S">Sylvain Castagnos</a> (UL, CNRS, LORIA), 
<a href="/search/cs?searchtype=author&query=Brun%2C+A">Armelle Brun</a> (UL, CNRS, LORIA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM/SIGAPP Symposium On Applied Computing, Apr 2024, Avila, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Online polarization has attracted the attention of researchers for many
years. Its effects on society are a cause for concern, and the design of
personalized depolarization strategies appears to be a key solution. Such
strategies should rely on a fine and accurate measurement, and a clear
understanding of polarization behaviors. However, the literature still lacks
ways to characterize them finely. We propose GRAIL, the first individual
polarization metric, relying on multiple factors. GRAIL assesses these factors
through entropy and is based on an adaptable Generalized Additive Model. We
evaluate the proposed metric on a Twitter dataset related to the highly
controversial debate about the COVID-19 vaccine. Experiments confirm the
ability of GRAIL to discriminate between polarization behaviors. To go further,
we provide a finer characterization and explanation of the identified behaviors
through an innovative evaluation framework.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04604" title="Abstract">arXiv:2312.04604</a> [<a href="/pdf/2312.04604" title="Download PDF">pdf</a>, <a href="/format/2312.04604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferable Candidate Proposal with Bounded Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Go%2C+K">Kyeongryeol Go</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kye-Hyeon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">From an empirical perspective, the subset chosen through active learning
cannot guarantee an advantage over random sampling when transferred to another
model. While it underscores the significance of verifying transferability,
experimental design from previous works often neglected that the
informativeness of a data subset can change over model configurations. To
tackle this issue, we introduce a new experimental design, coined as Candidate
Proposal, to find transferable data candidates from which active learning
algorithms choose the informative subset. Correspondingly, a data selection
algorithm is proposed, namely Transferable candidate proposal with Bounded
Uncertainty (TBU), which constrains the pool of transferable data candidates by
filtering out the presumably redundant data points based on uncertainty
estimation. We verified the validity of TBU in image classification benchmarks,
including CIFAR-10/100 and SVHN. When transferred to different model
configurations, TBU consistency improves performance in existing active
learning algorithms. Our code is available at
https://github.com/gokyeongryeol/TBU.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04606" title="Abstract">arXiv:2312.04606</a> [<a href="/pdf/2312.04606" title="Download PDF">pdf</a>, <a href="/format/2312.04606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Urban Region Representation Learning with Attentive Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fengze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yanchuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoliang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Karunasekera%2C+S">Shanika Karunasekera</a>, 
<a href="/search/cs?searchtype=author&query=Tanin%2C+E">Egemen Tanin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">An increasing number of related urban data sources have brought forth novel
opportunities for learning urban region representations, i.e., embeddings. The
embeddings describe latent features of urban regions and enable discovering
similar regions for urban planning applications. Existing methods learn an
embedding for a region using every different type of region feature data, and
subsequently fuse all learned embeddings of a region to generate a unified
region embedding. However, these studies often overlook the significance of the
fusion process. The typical fusion methods rely on simple aggregation, such as
summation and concatenation, thereby disregarding correlations within the fused
region embeddings.
<br />To address this limitation, we propose a novel model named HAFusion. Our
model is powered by a dual-feature attentive fusion module named DAFusion,
which fuses embeddings from different region features to learn higher-order
correlations between the regions as well as between the different types of
region features. DAFusion is generic - it can be integrated into existing
models to enhance their fusion process. Further, motivated by the effective
fusion capability of an attentive module, we propose a hybrid attentive feature
learning module named HALearning to enhance the embedding learning from each
individual type of region features. Extensive experiments on three real-world
datasets demonstrate that our model HAFusion outperforms state-of-the-art
methods across three different prediction tasks. Using our learned region
embedding leads to consistent and up to 31% improvements in the prediction
accuracy.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04609" title="Abstract">arXiv:2312.04609</a> [<a href="/pdf/2312.04609" title="Download PDF">pdf</a>, <a href="/format/2312.04609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short-term prediction of construction waste transport activities using  AI-Truck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Meng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Ke Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Construction waste hauling trucks (or `slag trucks') are among the most
commonly seen heavy-duty vehicles in urban streets, which not only produce
significant NOx and PM emissions but are also a major source of on-road and
on-site fugitive dust. Slag trucks are subject to a series of spatial and
temporal access restrictions by local traffic and environmental policies. This
paper addresses the practical problem of predicting slag truck activity at a
city scale during heavy pollution episodes, such that environmental law
enforcement units can take timely and proactive measures against localized
truck aggregation. A deep ensemble learning framework (coined AI-Truck) is
designed, which employs a soft vote integrator that utilizes BI-LSTM, TCN,
STGCN, and PDFormer as base classifiers to predict the level of slag truck
activities at a resolution of 1km$\times$1km, in a 193 km$^2$ area in Chengdu,
China. As a classifier, AI-Truck yields a Macro f1 close to 80\% for 0.5h- and
1h-prediction.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04610" title="Abstract">arXiv:2312.04610</a> [<a href="/pdf/2312.04610" title="Download PDF">pdf</a>, <a href="/ps/2312.04610" title="Download PostScript">ps</a>, <a href="/format/2312.04610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Semi-supervised Machine Learning with Surrogate Safety  Measures for Abnormal Driving Behavior Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lanxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yongqi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Farah%2C+H">Haneen Farah</a>, 
<a href="/search/cs?searchtype=author&query=Zgonnikov%2C+A">Arkady Zgonnikov</a>, 
<a href="/search/cs?searchtype=author&query=van+Arem%2C+B">Bart van Arem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures, accepted by the 103rd Transportation Research Board (TRB) Annual Meeting, under review by Transportation Research Record: Journal of the Transportation Research Board
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Other Statistics (stat.OT)

</div>
<p class="mathjax">Detecting abnormal driving behavior is critical for road traffic safety and
the evaluation of drivers' behavior. With the advancement of machine learning
(ML) algorithms and the accumulation of naturalistic driving data, many ML
models have been adopted for abnormal driving behavior detection. Most existing
ML-based detectors rely on (fully) supervised ML methods, which require
substantial labeled data. However, ground truth labels are not always available
in the real world, and labeling large amounts of data is tedious. Thus, there
is a need to explore unsupervised or semi-supervised methods to make the
anomaly detection process more feasible and efficient. To fill this research
gap, this study analyzes large-scale real-world data revealing several abnormal
driving behaviors (e.g., sudden acceleration, rapid lane-changing) and develops
a Hierarchical Extreme Learning Machines (HELM) based semi-supervised ML method
using partly labeled data to accurately detect the identified abnormal driving
behaviors. Moreover, previous ML-based approaches predominantly utilize basic
vehicle motion features (such as velocity and acceleration) to label and detect
abnormal driving behaviors, while this study seeks to introduce Surrogate
Safety Measures (SSMs) as the input features for ML models to improve the
detection performance. Results from extensive experiments demonstrate the
effectiveness of the proposed semi-supervised ML model with the introduced SSMs
serving as important features. The proposed semi-supervised ML method
outperforms other baseline semi-supervised or unsupervised methods regarding
various metrics, e.g., delivering the best accuracy at 99.58% and the best F-1
measure at 0.9913. The ablation study further highlights the significance of
SSMs for advancing detection performance.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04615" title="Abstract">arXiv:2312.04615</a> [<a href="/pdf/2312.04615" title="Download PDF">pdf</a>, <a href="/format/2312.04615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relational Deep Learning: Graph Representation Learning on Relational  Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fey%2C+M">Matthias Fey</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weihua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kexin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lenssen%2C+J+E">Jan Eric Lenssen</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+R">Rishabh Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+J">Joshua Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+J">Jiaxuan You</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://relbench.stanford.edu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Much of the world's most valued data is stored in relational databases and
data warehouses, where the data is organized into many tables connected by
primary-foreign key relations. However, building machine learning models using
this data is both challenging and time consuming. The core problem is that no
machine learning method is capable of learning on multiple tables
interconnected by primary-foreign key relations. Current methods can only learn
from a single table, so the data must first be manually joined and aggregated
into a single training table, the process known as feature engineering. Feature
engineering is slow, error prone and leads to suboptimal models. Here we
introduce an end-to-end deep representation learning approach to directly learn
on data laid out across multiple tables. We name our approach Relational Deep
Learning (RDL). The core idea is to view relational databases as a temporal,
heterogeneous graph, with a node for each row in each table, and edges
specified by primary-foreign key links. Message Passing Graph Neural Networks
can then automatically learn across the graph to extract representations that
leverage all input data, without any manual feature engineering. Relational
Deep Learning leads to more accurate models that can be built much faster. To
facilitate research in this area, we develop RelBench, a set of benchmark
datasets and an implementation of Relational Deep Learning. The data covers a
wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon
Product Catalog. Overall, we define a new research area that generalizes graph
machine learning and broadens its applicability to a wide set of AI use cases.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04616" title="Abstract">arXiv:2312.04616</a> [<a href="/pdf/2312.04616" title="Download PDF">pdf</a>, <a href="/ps/2312.04616" title="Download PostScript">ps</a>, <a href="/format/2312.04616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can apparent bystanders distinctively shape an outcome? Global south  countries and global catastrophic risk-focused governance of artificial  intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abungu%2C+C">Cecil Abungu</a>, 
<a href="/search/cs?searchtype=author&query=Malonza%2C+M">Michelle Malonza</a>, 
<a href="/search/cs?searchtype=author&query=Adan%2C+S+N">Sumaya Nur Adan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Increasingly, there is well-grounded concern that through perpetual
scaling-up of computation power and data, current deep learning techniques will
create highly capable artificial intelligence that could pursue goals in a
manner that is not aligned with human values. In turn, such AI could have the
potential of leading to a scenario in which there is serious global-scale
damage to human wellbeing. Against this backdrop, a number of researchers and
public policy professionals have been developing ideas about how to govern AI
in a manner that reduces the chances that it could lead to a global
catastrophe. The jurisdictional focus of a vast majority of their assessments
so far has been the United States, China, and Europe. That preference seems to
reveal an assumption underlying most of the work in this field: That global
south countries can only have a marginal role in attempts to govern AI
development from a global catastrophic risk -focused perspective. Our paper
sets out to undermine this assumption. We argue that global south countries
like India and Singapore (and specific coalitions) could in fact be fairly
consequential in the global catastrophic risk-focused governance of AI. We
support our position using 4 key claims. 3 are constructed out of the current
ways in which advanced foundational AI models are built and used while one is
constructed on the strategic roles that global south countries and coalitions
have historically played in the design and use of multilateral rules and
institutions. As each claim is elaborated, we also suggest some ways through
which global south countries can play a positive role in designing,
strengthening and operationalizing global catastrophic risk-focused AI
governance.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04642" title="Abstract">arXiv:2312.04642</a> [<a href="/pdf/2312.04642" title="Download PDF">pdf</a>, <a href="/format/2312.04642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Sarcasm Detection with OpenAI GPT-based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gole%2C+M">Montgomery Gole</a>, 
<a href="/search/cs?searchtype=author&query=Nwadiugwu%2C+W">Williams-Paul Nwadiugwu</a>, 
<a href="/search/cs?searchtype=author&query=Miranskyy%2C+A">Andriy Miranskyy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sarcasm is a form of irony that requires readers or listeners to interpret
its intended meaning by considering context and social cues. Machine learning
classification models have long had difficulty detecting sarcasm due to its
social complexity and contradictory nature.
<br />This paper explores the applications of the Generative Pretrained Transformer
(GPT) models, including GPT-3, InstructGPT, GPT-3.5, and GPT-4, in detecting
sarcasm in natural language. It tests fine-tuned and zero-shot models of
different sizes and releases.
<br />The GPT models were tested on the political and balanced (pol-bal) portion of
the popular Self-Annotated Reddit Corpus (SARC 2.0) sarcasm dataset. In the
fine-tuning case, the largest fine-tuned GPT-3 model achieves accuracy and
$F_1$-score of 0.81, outperforming prior models. In the zero-shot case, one of
GPT-4 models yields an accuracy of 0.70 and $F_1$-score of 0.75. Other models
score lower. Additionally, a model's performance may improve or deteriorate
with each release, highlighting the need to reassess performance after each
release.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04649" title="Abstract">arXiv:2312.04649</a> [<a href="/pdf/2312.04649" title="Download PDF">pdf</a>, <a href="/format/2312.04649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyThaiNLP: Thai Natural Language Processing in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phatthiyaphaibun%2C+W">Wannaphong Phatthiyaphaibun</a>, 
<a href="/search/cs?searchtype=author&query=Chaovavanich%2C+K">Korakot Chaovavanich</a>, 
<a href="/search/cs?searchtype=author&query=Polpanumas%2C+C">Charin Polpanumas</a>, 
<a href="/search/cs?searchtype=author&query=Suriyawongkul%2C+A">Arthit Suriyawongkul</a>, 
<a href="/search/cs?searchtype=author&query=Lowphansirikul%2C+L">Lalita Lowphansirikul</a>, 
<a href="/search/cs?searchtype=author&query=Chormai%2C+P">Pattarawat Chormai</a>, 
<a href="/search/cs?searchtype=author&query=Limkonchotiwat%2C+P">Peerat Limkonchotiwat</a>, 
<a href="/search/cs?searchtype=author&query=Suntorntip%2C+T">Thanathip Suntorntip</a>, 
<a href="/search/cs?searchtype=author&query=Udomcharoenchaikit%2C+C">Can Udomcharoenchaikit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, LaTeX; typos corrected, timeline clarified for section 2. In Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023), pages 25-36, Singapore, Singapore. Empirical Methods in Natural Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present PyThaiNLP, a free and open-source natural language processing
(NLP) library for Thai language implemented in Python. It provides a wide range
of software, models, and datasets for Thai language. We first provide a brief
historical context of tools for Thai language prior to the development of
PyThaiNLP. We then outline the functionalities it provided as well as datasets
and pre-trained language models. We later summarize its development milestones
and discuss our experience during its development. We conclude by demonstrating
how industrial and research communities utilize PyThaiNLP in their work. The
library is freely available at https://github.com/pythainlp/pythainlp.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04651" title="Abstract">arXiv:2312.04651</a> [<a href="/pdf/2312.04651" title="Download PDF">pdf</a>, <a href="/format/2312.04651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VOODOO 3D: Volumetric Portrait Disentanglement for One-Shot 3D Head  Reenactment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+P">Phong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+E">Egor Zakharov</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L">Long-Nhat Ho</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A+T">Anh Tuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a 3D-aware one-shot head reenactment method based on a fully
volumetric neural disentanglement framework for source appearance and driver
expressions. Our method is real-time and produces high-fidelity and
view-consistent output, suitable for 3D teleconferencing systems based on
holographic displays. Existing cutting-edge 3D-aware reenactment methods often
use neural radiance fields or 3D meshes to produce view-consistent appearance
encoding, but, at the same time, they rely on linear face models, such as 3DMM,
to achieve its disentanglement with facial expressions. As a result, their
reenactment results often exhibit identity leakage from the driver or have
unnatural expressions. To address these problems, we propose a neural
self-supervised disentanglement approach that lifts both the source image and
driver video frame into a shared 3D volumetric representation based on
tri-planes. This representation can then be freely manipulated with expression
tri-planes extracted from the driving images and rendered from an arbitrary
view using neural radiance fields. We achieve this disentanglement via
self-supervised learning on a large in-the-wild video dataset. We further
introduce a highly effective fine-tuning approach to improve the
generalizability of the 3D lifting using the same real-world data. We
demonstrate state-of-the-art performance on a wide range of datasets, and also
showcase high-quality 3D-aware head reenactment on highly challenging and
diverse subjects, including non-frontal head poses and complex expressions for
both source and driver.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04653" title="Abstract">arXiv:2312.04653</a> [<a href="/pdf/2312.04653" title="Download PDF">pdf</a>, <a href="/format/2312.04653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Thresholds with Latent Values and Censored Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weiqiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhe Feng</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yifeng Teng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaotie Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In this paper, we investigate a problem of actively learning threshold in
latent space, where the unknown reward $g(\gamma, v)$ depends on the proposed
threshold $\gamma$ and latent value $v$ and it can be $only$ achieved if the
threshold is lower than or equal to the unknown latent value. This problem has
broad applications in practical scenarios, e.g., reserve price optimization in
online auctions, online task assignments in crowdsourcing, setting recruiting
bars in hiring, etc. We first characterize the query complexity of learning a
threshold with the expected reward at most $\epsilon$ smaller than the optimum
and prove that the number of queries needed can be infinitely large even when
$g(\gamma, v)$ is monotone with respect to both $\gamma$ and $v$. On the
positive side, we provide a tight query complexity
$\tilde{\Theta}(1/\epsilon^3)$ when $g$ is monotone and the CDF of value
distribution is Lipschitz. Moreover, we show a tight
$\tilde{\Theta}(1/\epsilon^3)$ query complexity can be achieved as long as $g$
satisfies one-sided Lipschitzness, which provides a complete characterization
for this problem. Finally, we extend this model to an online learning setting
and demonstrate a tight $\Theta(T^{2/3})$ regret bound using continuous-arm
bandit techniques and the aforementioned query complexity results.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04654" title="Abstract">arXiv:2312.04654</a> [<a href="/pdf/2312.04654" title="Download PDF">pdf</a>, <a href="/format/2312.04654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuSD: Surface Completion with Multi-View Text-to-Image Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ignatyev%2C+S">Savva Ignatyev</a>, 
<a href="/search/cs?searchtype=author&query=Selikhanovych%2C+D">Daniil Selikhanovych</a>, 
<a href="/search/cs?searchtype=author&query=Voynov%2C+O">Oleg Voynov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>, 
<a href="/search/cs?searchtype=author&query=Lefkimmiatis%2C+S">Stamatios Lefkimmiatis</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We present a novel method for 3D surface reconstruction from multiple images
where only a part of the object of interest is captured. Our approach builds on
two recent developments: surface reconstruction using neural radiance fields
for the reconstruction of the visible parts of the surface, and guidance of
pre-trained 2D diffusion models in the form of Score Distillation Sampling
(SDS) to complete the shape in unobserved regions in a plausible manner. We
introduce three components. First, we suggest employing normal maps as a pure
geometric representation for SDS instead of color renderings which are
entangled with the appearance information. Second, we introduce the freezing of
the SDS noise during training which results in more coherent gradients and
better convergence. Third, we propose Multi-View SDS as a way to condition the
generation of the non-observable part of the surface without fine-tuning or
making changes to the underlying 2D Stable Diffusion model. We evaluate our
approach on the BlendedMVS dataset demonstrating significant qualitative and
quantitative improvements over competing methods.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04655" title="Abstract">arXiv:2312.04655</a> [<a href="/pdf/2312.04655" title="Download PDF">pdf</a>, <a href="/format/2312.04655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECLIPSE: A Resource-Efficient Text-to-Image Prior for Image Generations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Maitreya Patel</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changhoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yezhou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://eclipse-t2i.vercel.app/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image (T2I) diffusion models, notably the unCLIP models (e.g.,
DALL-E-2), achieve state-of-the-art (SOTA) performance on various compositional
T2I benchmarks, at the cost of significant computational resources. The unCLIP
stack comprises T2I prior and diffusion image decoder. The T2I prior model
alone adds a billion parameters compared to the Latent Diffusion Models, which
increases the computational and high-quality data requirements. We introduce
ECLIPSE, a novel contrastive learning method that is both parameter and
data-efficient. ECLIPSE leverages pre-trained vision-language models (e.g.,
CLIP) to distill the knowledge into the prior model. We demonstrate that the
ECLIPSE trained prior, with only 3.3% of the parameters and trained on a mere
2.8% of the data, surpasses the baseline T2I priors with an average of 71.6%
preference score under resource-limited setting. It also attains performance on
par with SOTA big models, achieving an average of 63.36% preference score in
terms of the ability to follow the text compositions. Extensive experiments on
two unCLIP diffusion image decoders, Karlo and Kandinsky, affirm that ECLIPSE
priors consistently deliver high performance while significantly reducing
resource dependency.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04657" title="Abstract">arXiv:2312.04657</a> [<a href="/pdf/2312.04657" title="Download PDF">pdf</a>, <a href="/format/2312.04657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+P">Peter Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we introduce a self-supervised behavior cloning transformer for
text games, which are challenging benchmarks for multi-step reasoning in
virtual environments. Traditionally, Behavior Cloning Transformers excel in
such tasks but rely on supervised training data. Our approach auto-generates
training data by exploring trajectories (defined by common macro-action
sequences) that lead to reward within the games, while determining the
generality and utility of these trajectories by rapidly training small models
then evaluating their performance on unseen development games. Through
empirical analysis, we show our method consistently uncovers generalizable
training data, achieving about 90\% performance of supervised systems across
three benchmark text games.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04658" title="Abstract">arXiv:2312.04658</a> [<a href="/pdf/2312.04658" title="Download PDF">pdf</a>, <a href="/format/2312.04658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC-Bayes Generalization Certificates for Learned Inductive Conformal  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Apoorva Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Veer%2C+S">Sushant Veer</a>, 
<a href="/search/cs?searchtype=author&query=Hancock%2C+A">Asher Hancock</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Heng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Inductive Conformal Prediction (ICP) provides a practical and effective
approach for equipping deep learning models with uncertainty estimates in the
form of set-valued predictions which are guaranteed to contain the ground truth
with high probability. Despite the appeal of this coverage guarantee, these
sets may not be efficient: the size and contents of the prediction sets are not
directly controlled, and instead depend on the underlying model and choice of
score function. To remedy this, recent work has proposed learning model and
score function parameters using data to directly optimize the efficiency of the
ICP prediction sets. While appealing, the generalization theory for such an
approach is lacking: direct optimization of empirical efficiency may yield
prediction sets that are either no longer efficient on test data, or no longer
obtain the required coverage on test data. In this work, we use PAC-Bayes
theory to obtain generalization bounds on both the coverage and the efficiency
of set-valued predictors which can be directly optimized to maximize efficiency
while satisfying a desired test coverage. In contrast to prior work, our
framework allows us to utilize the entire calibration dataset to learn the
parameters of the model and score function, instead of requiring a separate
hold-out set for obtaining test-time coverage guarantees. We leverage these
theoretical results to provide a practical algorithm for using calibration data
to simultaneously fine-tune the parameters of a model and score function while
guaranteeing test-time coverage and efficiency of the resulting prediction
sets. We evaluate the approach on regression and classification tasks, and
outperform baselines calibrated using a Hoeffding bound-based PAC guarantee on
ICP, especially in the low-data regime.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04662" title="Abstract">arXiv:2312.04662</a> [<a href="/pdf/2312.04662" title="Download PDF">pdf</a>, <a href="/format/2312.04662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based Digital Twins of Medicine Dispensers for Healthcare IoT  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sartaj%2C+H">Hassan Sartaj</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Moberg%2C+K">Kjetil Moberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Healthcare applications with the Internet of Things (IoT) are often
safety-critical, thus, require extensive testing. Such applications are often
connected to smart medical devices from various vendors. System-level testing
of such applications requires test infrastructures physically integrating
medical devices, which is time and monetary-wise expensive. Moreover,
applications continuously evolve, e.g., introducing new devices and users and
updating software. Nevertheless, a test infrastructure enabling testing with a
few devices is insufficient for testing healthcare IoT systems, hence
compromising their dependability. In this paper, we propose a model-based
approach for the creation and operation of digital twins (DTs) of medicine
dispensers as a replacement for physical devices to support the automated
testing of IoT applications at scale. We evaluate our approach with an
industrial IoT system with medicine dispensers in the context of Oslo City and
its industrial partners, providing healthcare services to its residents. We
study the fidelity of DTs in terms of their functional similarities with their
physical counterparts: medicine dispensers. Results show that the DTs behave
more than 92% similar to the physical medicine dispensers, providing a faithful
replacement for the dispenser.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04668" title="Abstract">arXiv:2312.04668</a> [<a href="/pdf/2312.04668" title="Download PDF">pdf</a>, <a href="/format/2312.04668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TOD-Flow: Modeling the Structure of Task-Oriented Dialogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sohn%2C+S">Sungryull Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yiwei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anthony Liu</a>, 
<a href="/search/cs?searchtype=author&query=Logeswaran%2C+L">Lajanugen Logeswaran</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dong-Ki Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+D">Dongsub Shim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Task-Oriented Dialogue (TOD) systems have become crucial components in
interactive artificial intelligence applications. While recent advances have
capitalized on pre-trained language models (PLMs), they exhibit limitations
regarding transparency and controllability. To address these challenges, we
propose a novel approach focusing on inferring the TOD-Flow graph from dialogue
data annotated with dialog acts, uncovering the underlying task structure in
the form of a graph. The inferred TOD-Flow graph can be easily integrated with
any dialogue model to improve its prediction performance, transparency, and
controllability. Our TOD-Flow graph learns what a model can, should, and should
not predict, effectively reducing the search space and providing a rationale
for the model's prediction. We show that the proposed TOD-Flow graph better
resembles human-annotated graphs compared to prior approaches. Furthermore,
when combined with several dialogue policies and end-to-end dialogue models, we
demonstrate that our approach significantly improves dialog act classification
and end-to-end response generation performance in the MultiWOZ and SGD
benchmarks. Code available at: https://github.com/srsohn/TOD-Flow
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04670" title="Abstract">arXiv:2312.04670</a> [<a href="/pdf/2312.04670" title="Download PDF">pdf</a>, <a href="/format/2312.04670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Motor Adaptation for Robotic Manipulator Arms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yichao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+K">Kevin Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+J">Jo&#xe3;o Henriques</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review. 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Developing generalizable manipulation skills is a core challenge in embodied
AI. This includes generalization across diverse task configurations,
encompassing variations in object shape, density, friction coefficient, and
external disturbances such as forces applied to the robot. Rapid Motor
Adaptation (RMA) offers a promising solution to this challenge. It posits that
essential hidden variables influencing an agent's task performance, such as
object mass and shape, can be effectively inferred from the agent's action and
proprioceptive history. Drawing inspiration from RMA in locomotion and in-hand
rotation, we use depth perception to develop agents tailored for rapid motor
adaptation in a variety of manipulation tasks. We evaluated our agents on four
challenging tasks from the Maniskill2 benchmark, namely pick-and-place
operations with hundreds of objects from the YCB and EGAD datasets, peg
insertion with precise position and orientation, and operating a variety of
faucets and handles, with customized environment variations. Empirical results
demonstrate that our agents surpass state-of-the-art methods like automatic
domain randomization and vision-based policies, obtaining better generalization
performance and sample efficiency.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04674" title="Abstract">arXiv:2312.04674</a> [<a href="/pdf/2312.04674" title="Download PDF">pdf</a>, <a href="/ps/2312.04674" title="Download PostScript">ps</a>, <a href="/format/2312.04674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Multi-Pass Lower Bounds for MST in Dynamic Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assadi%2C+S">Sepehr Assadi</a>, 
<a href="/search/cs?searchtype=author&query=Kol%2C+G">Gillat Kol</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhijun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The seminal work of Ahn, Guha, and McGregor in 2012 introduced the graph
sketching technique and used it to present the first streaming algorithms for
various graph problems over dynamic streams with both insertions and deletions
of edges. This includes algorithms for cut sparsification, spanners, matchings,
and minimum spanning trees (MSTs). These results have since been improved or
generalized in various directions, leading to a vastly rich host of efficient
algorithms for processing dynamic graph streams.
<br />A curious omission from the list of improvements has been the MST problem.
The best algorithm for this problem remains the original AGM algorithm that for
every integer $p \geq 1$, uses $n^{1+O(1/p)}$ space in $p$ passes on $n$-vertex
graphs, and thus achieves the desired semi-streaming space of $\tilde{O}(n)$ at
a relatively high cost of $O(\frac{\log{n}}{\log\log{n}})$ passes. On the other
hand, no lower bounds beyond a folklore one-pass lower bound is known for this
problem.
<br />We provide a simple explanation for this lack of improvements: The AGM
algorithm for MSTs is optimal for the entire range of its number of passes! We
prove that even for the simplest decision version of the problem -- deciding
whether the weight of MSTs is at least a given threshold or not -- any $p$-pass
dynamic streaming algorithm requires $n^{1+\Omega(1/p)}$ space. This implies
that semi-streaming algorithms do need $\Omega(\frac{\log{n}}{\log\log{n}})$
passes.
<br />Our result relies on proving new multi-round communication complexity lower
bounds for a variant of the universal relation problem that has been
instrumental in proving prior lower bounds for single-pass dynamic streaming
algorithms. The proof also involves proving new composition theorems in
communication complexity, including majority lemmas and multi-party XOR lemmas,
via information complexity approaches.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04675" title="Abstract">arXiv:2312.04675</a> [<a href="/pdf/2312.04675" title="Download PDF">pdf</a>, <a href="/ps/2312.04675" title="Download PostScript">ps</a>, <a href="/format/2312.04675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reverse Engineering Deep ReLU Networks An Optimization-based Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamidi%2C+M">Mehrab Hamidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 supplementary pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reverse engineering deep ReLU networks is a critical problem in understanding
the complex behavior and interpretability of neural networks. In this research,
we present a novel method for reconstructing deep ReLU networks by leveraging
convex optimization techniques and a sampling-based approach. Our method begins
by sampling points in the input space and querying the black box model to
obtain the corresponding hyperplanes. We then define a convex optimization
problem with carefully chosen constraints and conditions to guarantee its
convexity. The objective function is designed to minimize the discrepancy
between the reconstructed networks output and the target models output, subject
to the constraints. We employ gradient descent to optimize the objective
function, incorporating L1 or L2 regularization as needed to encourage sparse
or smooth solutions. Our research contributes to the growing body of work on
reverse engineering deep ReLU networks and paves the way for new advancements
in neural network interpretability and security.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04684" title="Abstract">arXiv:2312.04684</a> [<a href="/pdf/2312.04684" title="Download PDF">pdf</a>, <a href="/format/2312.04684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Skill Discovery for Chain-of-Thought Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bespalov%2C+D">Dmitriy Bespalov</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanjun Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in Large Language Models (LLMs) have led to an emergent
ability of chain-of-thought (CoT) prompting, a prompt reasoning strategy that
adds intermediate rationale steps between questions and answers to construct
prompts. Conditioned on these prompts, LLMs can effectively learn in context to
generate rationales that lead to more accurate answers than when answering the
same question directly. To design LLM prompts, one important setting, called
demonstration selection, considers selecting demonstrations from an example
bank. Existing methods use various heuristics for this selection, but for CoT
prompting, which involves unique rationales, it is essential to base the
selection upon the intrinsic skills that CoT rationales need, for instance, the
skills of addition or subtraction for math word problems.
<br />To address this requirement, we introduce a novel approach named Reasoning
Skill Discovery (RSD) that use unsupervised learning to create a latent space
representation of rationales, called a reasoning skill. Simultaneously, RSD
learns a reasoning policy to determine the required reasoning skill for a given
question. This can then guide the selection of examples that demonstrate the
required reasoning skills. Our approach offers several desirable properties: it
is (1) theoretically grounded, (2) sample-efficient, requiring no LLM inference
or manual prompt design, and (3) LLM-agnostic. Empirically, RSD outperforms
existing methods by up to 6% in terms of the answer accuracy across multiple
reasoning tasks.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04687" title="Abstract">arXiv:2312.04687</a> [<a href="/pdf/2312.04687" title="Download PDF">pdf</a>, <a href="/format/2312.04687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4TDD: Best Practices for Test Driven Development Using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piya%2C+S">Sanyogita Piya</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+A">Allison Sullivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In today's society, we are becoming increasingly dependent on software
systems. However, we also constantly witness the negative impacts of buggy
software. Program synthesis aims to improve software correctness by
automatically generating the program given an outline of the expected behavior.
For decades, program synthesis has been an active research field, with recent
approaches looking to incorporate Large Language Models to help generate code.
This paper explores the concept of LLM4TDD, where we guide Large Language
Models to generate code iteratively using a test-driven development
methodology. We conduct an empirical evaluation using ChatGPT and coding
problems from LeetCode to investigate the impact of different test, prompt and
problem attributes on the efficacy of LLM4TDD.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04688" title="Abstract">arXiv:2312.04688</a> [<a href="/pdf/2312.04688" title="Download PDF">pdf</a>, <a href="/format/2312.04688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and  Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Driss%2C+M+B">Maryam Ben Driss</a>, 
<a href="/search/cs?searchtype=author&query=Sabir%2C+E">Essaid Sabir</a>, 
<a href="/search/cs?searchtype=author&query=Elbiaze%2C+H">Halima Elbiaze</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures; 9 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Artificial Intelligence (AI) is expected to play an instrumental role in the
next generation of wireless systems, such as sixth-generation (6G) mobile
network. However, massive data, energy consumption, training complexity, and
sensitive data protection in wireless systems are all crucial challenges that
must be addressed for training AI models and gathering intelligence and
knowledge from distributed devices. Federated Learning (FL) is a recent
framework that has emerged as a promising approach for multiple learning agents
to build an accurate and robust machine learning models without sharing raw
data. By allowing mobile handsets and devices to collaboratively learn a global
model without explicit sharing of training data, FL exhibits high privacy and
efficient spectrum utilization. While there are a lot of survey papers
exploring FL paradigms and usability in 6G privacy, none of them has clearly
addressed how FL can be used to improve the protocol stack and wireless
operations. The main goal of this survey is to provide a comprehensive overview
on FL usability to enhance mobile services and enable smart ecosystems to
support novel use-cases. This paper examines the added-value of implementing FL
throughout all levels of the protocol stack. Furthermore, it presents important
FL applications, addresses hot topics, provides valuable insights and explicits
guidance for future research and developments. Our concluding remarks aim to
leverage the synergy between FL and future 6G, while highlighting FL's
potential to revolutionize wireless industry and sustain the development of
cutting-edge mobile services.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04690" title="Abstract">arXiv:2312.04690</a> [<a href="/pdf/2312.04690" title="Download PDF">pdf</a>, <a href="/format/2312.04690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynthScribe: Deep Multimodal Tools for Synthesizer Sound Retrieval and  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brade%2C+S">Stephen Brade</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bryan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+M">Mauricio Sousa</a>, 
<a href="/search/cs?searchtype=author&query=Newsome%2C+G+L">Gregory Lee Newsome</a>, 
<a href="/search/cs?searchtype=author&query=Oore%2C+S">Sageev Oore</a>, 
<a href="/search/cs?searchtype=author&query=Grossman%2C+T">Tovi Grossman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Synthesizers are powerful tools that allow musicians to create dynamic and
original sounds. Existing commercial interfaces for synthesizers typically
require musicians to interact with complex low-level parameters or to manage
large libraries of premade sounds. To address these challenges, we implement
SynthScribe -- a fullstack system that uses multimodal deep learning to let
users express their intentions at a much higher level. We implement features
which address a number of difficulties, namely 1) searching through existing
sounds, 2) creating completely new sounds, 3) making meaningful modifications
to a given sound. This is achieved with three main features: a multimodal
search engine for a large library of synthesizer sounds; a user centered
genetic algorithm by which completely new sounds can be created and selected
given the users preferences; a sound editing support feature which highlights
and gives examples for key control parameters with respect to a text or audio
based query. The results of our user studies show SynthScribe is capable of
reliably retrieving and modifying sounds while also affording the ability to
create completely new sounds that expand a musicians creative horizon.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04691" title="Abstract">arXiv:2312.04691</a> [<a href="/pdf/2312.04691" title="Download PDF">pdf</a>, <a href="/format/2312.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simul-LLM: A Framework for Exploring High-Quality Simultaneous  Translation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agostinelli%2C+V">Victor Agostinelli</a>, 
<a href="/search/cs?searchtype=author&query=Wild%2C+M">Max Wild</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+M">Matthew Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Fuad%2C+K+A">Kazi Asif Fuad</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lizhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) with billions of parameters and pretrained on
massive amounts of data are now capable of near or better than state-of-the-art
performance in a variety of downstream natural language processing tasks.
Neural machine translation (NMT) is one such task that LLMs have been applied
to with great success. However, little research has focused on applying LLMs to
the more difficult subset of NMT called simultaneous translation (SimulMT),
where translation begins before the entire source context is available to the
model. In this paper, we address key challenges facing LLMs fine-tuned for
SimulMT, validate classical SimulMT concepts and practices in the context of
LLMs, explore adapting LLMs that are fine-tuned for NMT to the task of SimulMT,
and introduce Simul-LLM, the first open-source fine-tuning and evaluation
pipeline development framework for LLMs focused on SimulMT.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04692" title="Abstract">arXiv:2312.04692</a> [<a href="/pdf/2312.04692" title="Download PDF">pdf</a>, <a href="/format/2312.04692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffence: Fencing Membership Privacy With Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yuefeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Naseh%2C+A">Ali Naseh</a>, 
<a href="/search/cs?searchtype=author&query=Houmansadr%2C+A">Amir Houmansadr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models, while achieving remarkable performance across various
tasks, are vulnerable to member inference attacks, wherein adversaries identify
if a specific data point was part of a model's training set. This
susceptibility raises substantial privacy concerns, especially when models are
trained on sensitive datasets. Current defense methods often struggle to
provide robust protection without hurting model utility, and they often require
retraining the model or using extra data. In this work, we introduce a novel
defense framework against membership attacks by leveraging generative models.
The key intuition of our defense is to remove the differences between member
and non-member inputs which can be used to perform membership attacks, by
re-generating input samples before feeding them to the target model. Therefore,
our defense works \emph{pre-inference}, which is unlike prior defenses that are
either training-time (modify the model) or post-inference time (modify the
model's output).
<br />A unique feature of our defense is that it works on input samples only,
without modifying the training or inference phase of the target model.
Therefore, it can be cascaded with other defense mechanisms as we demonstrate
through experiments. Through extensive experimentation, we show that our
approach can serve as a robust plug-n-play defense mechanism, enhancing
membership privacy without compromising model utility in both baseline and
defended settings. For example, our method enhanced the effectiveness of recent
state-of-the-art defenses, reducing attack accuracy by an average of 5.7\% to
12.4\% across three datasets, without any impact on the model's accuracy. By
integrating our method with prior defenses, we achieve new state-of-the-art
performance in the privacy-utility trade-off.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04693" title="Abstract">arXiv:2312.04693</a> [<a href="/pdf/2312.04693" title="Download PDF">pdf</a>, <a href="/format/2312.04693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphMETRO: Mitigating Complex Distribution Shifts in GNNs via Mixture  of Aligned Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shirley Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Kaidi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+B">Bruno Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Graph Neural Networks, Mixture-of-experts, Distribution Shifts, Generalization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks' (GNNs) ability to generalize across complex
distributions is crucial for real-world applications. However, prior research
has primarily focused on specific types of distribution shifts, such as larger
graph size, or inferred shifts from constructed data environments, which is
highly limited when confronted with multiple and nuanced distribution shifts.
For instance, in a social graph, a user node might experience increased
interactions and content alterations, while other user nodes encounter distinct
shifts. Neglecting such complexities significantly impedes generalization. To
address it, we present GraphMETRO, a novel framework that enhances GNN
generalization under complex distribution shifts in both node and graph-level
tasks. Our approach employs a mixture-of-experts (MoE) architecture with a
gating model and expert models aligned in a shared representation space. The
gating model identifies key mixture components governing distribution shifts,
while each expert generates invariant representations w.r.t. a mixture
component. Finally, GraphMETRO aggregates representations from multiple experts
to generate the final invariant representation. Our experiments on synthetic
and realworld datasets demonstrate GraphMETRO's superiority and
interpretability. To highlight, GraphMETRO achieves state-of-the-art
performances on four real-world datasets from GOOD benchmark, outperforming the
best baselines on WebKB and Twitch datasets by 67% and 4.2%, respectively.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04704" title="Abstract">arXiv:2312.04704</a> [<a href="/pdf/2312.04704" title="Download PDF">pdf</a>, <a href="/format/2312.04704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Distributed Reinforcement Learning with Reactor Model and  Lingua Franca
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J">Jacky Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Lohstroh%2C+M">Marten Lohstroh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E+A">Edward A. Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Distributed Reinforcement Learning (RL) frameworks are essential for mapping
RL workloads to multiple computational resources, allowing for faster
generation of samples, estimation of values, and policy improvement. These
computational paradigms require a seamless integration of training, serving,
and simulation workloads. Existing frameworks, such as Ray, are not managing
this orchestration efficiently. In this study, we've proposed a solution
implementing Reactor Model, which enforces a set of actors to have a fixed
communication pattern. This allows the scheduler to eliminate works needed for
synchronization, such as acquiring and releasing locks for each actor or
sending and processing coordination-related messages. Our framework, Lingua
Franca (LF), a coordination language based on the Reactor Model, also provides
a unified interface that allows users to automatically generate dataflow graphs
for distributed RL. On average, LF outperformed Ray in generating samples from
OpenAI Gym and Atari environments by 1.21x and 11.62x, reduced the average
training time of synchronized parallel Q-learning by 31.2%, and accelerated
Multi-Agent RL inference by 5.12x.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04709" title="Abstract">arXiv:2312.04709</a> [<a href="/pdf/2312.04709" title="Download PDF">pdf</a>, <a href="/format/2312.04709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to guess a gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+U">Utkarsh Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+B">Brian Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+K">Kartik Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Ragan-Kelley%2C+J">Jonathan Ragan-Kelley</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Poggio%2C+T+A">Tomaso A. Poggio</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">How much can you say about the gradient of a neural network without computing
a loss or knowing the label? This may sound like a strange question: surely the
answer is "very little." However, in this paper, we show that gradients are
more structured than previously thought. Gradients lie in a predictable
low-dimensional subspace which depends on the network architecture and incoming
features. Exploiting this structure can significantly improve gradient-free
optimization schemes based on directional derivatives, which have struggled to
scale beyond small networks trained on toy datasets. We study how to narrow the
gap in optimization performance between methods that calculate exact gradients
and those that use directional derivatives. Furthermore, we highlight new
challenges in overcoming the large gap between optimizing with exact gradients
and guessing the gradients.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04712" title="Abstract">arXiv:2312.04712</a> [<a href="/pdf/2312.04712" title="Download PDF">pdf</a>, <a href="/format/2312.04712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Discovery by Clustering Influence Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fulton Wang</a>, 
<a href="/search/cs?searchtype=author&query=Adebayo%2C+J">Julius Adebayo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Sarah Tan</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Olano%2C+D">Diego Garcia-Olano</a>, 
<a href="/search/cs?searchtype=author&query=Kokhlikyan%2C+N">Narine Kokhlikyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeuRIPs 2023 conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a method for identifying groups of test examples -- slices -- on
which a model under-performs, a task now known as slice discovery. We formalize
coherence -- a requirement that erroneous predictions, within a slice, should
be wrong for the same reason -- as a key property that any slice discovery
method should satisfy. We then use influence functions to derive a new slice
discovery method, InfEmbed, which satisfies coherence by returning slices whose
examples are influenced similarly by the training data. InfEmbed is simple, and
consists of applying K-Means clustering to a novel representation we deem
influence embeddings. We show InfEmbed outperforms current state-of-the-art
methods on 2 benchmarks, and is effective for model debugging across several
case studies.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04713" title="Abstract">arXiv:2312.04713</a> [<a href="/pdf/2312.04713" title="Download PDF">pdf</a>, <a href="/format/2312.04713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gcDLSeg: Integrating Graph-cut into Deep Learning for Binary Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+X">Ya Xing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Buatti%2C+J">John Buatti</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaodong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Binary semantic segmentation in computer vision is a fundamental problem. As
a model-based segmentation method, the graph-cut approach was one of the most
successful binary segmentation methods thanks to its global optimality
guarantee of the solutions and its practical polynomial-time complexity.
Recently, many deep learning (DL) based methods have been developed for this
task and yielded remarkable performance, resulting in a paradigm shift in this
field. To combine the strengths of both approaches, we propose in this study to
integrate the graph-cut approach into a deep learning network for end-to-end
learning. Unfortunately, backward propagation through the graph-cut module in
the DL network is challenging due to the combinatorial nature of the graph-cut
algorithm. To tackle this challenge, we propose a novel residual graph-cut loss
and a quasi-residual connection, enabling the backward propagation of the
gradients of the residual graph-cut loss for effective feature learning guided
by the graph-cut segmentation model. In the inference phase, globally optimal
segmentation is achieved with respect to the graph-cut energy defined on the
optimized image features learned from DL networks. Experiments on the public
AZH chronic wound data set and the pancreas cancer data set from the medical
segmentation decathlon (MSD) demonstrated promising segmentation accuracy, and
improved robustness against adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04714" title="Abstract">arXiv:2312.04714</a> [<a href="/pdf/2312.04714" title="Download PDF">pdf</a>, <a href="/format/2312.04714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of AI Innovations on U.S. Occupations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Septiandri%2C+A+A">Ali Akbar Septiandri</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+M">Marios Constantinides</a>, 
<a href="/search/cs?searchtype=author&query=Quercia%2C+D">Daniele Quercia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">AI's impact has traditionally been assessed in terms of occupations. However,
an occupation is comprised of interconnected tasks, and it is these tasks, not
occupations themselves, that are affected by AI. To evaluate how tasks may be
impacted, previous approaches utilized subjective manual annotations or
coarse-grained matching with patents. Leveraging recent advancements in machine
learning, we replace coarse-grained matching with more precise deep learning
approaches. Introducing the AI Impact (AII) measure, we employ Deep Learning
Natural Language Processing to automatically identify AI patents that impact
various occupational tasks at scale. Our methodology relies on a comprehensive
dataset of 19,498 task descriptions and quantifies AI's impact through analysis
of 12,984 AI patents filed with the United States Patent and Trademark Office
(USPTO) between 2015 and 2020. Our observations reveal that the impact of AI on
occupations defies simplistic categorizations based on task complexity,
challenging the conventional belief that the dichotomy between basic and
advanced skills alone explains the effects of AI. Instead, the impact is
intricately linked to specific skills, whether basic or advanced, associated
with particular tasks. For instance, while basic skills like scanning items may
be affected, others like cooking may not. Similarly, certain advanced skills,
such as image analysis in radiology, may face impact, while skills involving
interpersonal relationships may remain unaffected. Furthermore, the influence
of AI extends beyond knowledge-centric regions. Regions in the U.S. that
heavily rely on industries susceptible to AI changes, often characterized by
economic inequality or a lack of economic diversification, will experience
notable AI impact.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04715" title="Abstract">arXiv:2312.04715</a> [<a href="/pdf/2312.04715" title="Download PDF">pdf</a>, <a href="/format/2312.04715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Emotions Across Languages: A Novel Approach for Sentiment  Propagation in Multilingual WordNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koco%C5%84%2C+J">Jan Koco&#x144;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, presented at ICDM Workshop: SENTIRE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Sentiment analysis involves using WordNets enriched with emotional metadata,
which are valuable resources. However, manual annotation is time-consuming and
expensive, resulting in only a few WordNet Lexical Units being annotated. This
paper introduces two new techniques for automatically propagating sentiment
annotations from a partially annotated WordNet to its entirety and to a WordNet
in a different language: Multilingual Structured Synset Embeddings (MSSE) and
Cross-Lingual Deep Neural Sentiment Propagation (CLDNS). We evaluated the
proposed MSSE+CLDNS method extensively using Princeton WordNet and Polish
WordNet, which have many inter-lingual relations. Our results show that the
MSSE+CLDNS method outperforms existing propagation methods, indicating its
effectiveness in enriching WordNets with emotional metadata across multiple
languages. This work provides a solid foundation for large-scale, multilingual
sentiment analysis and is valuable for academic research and practical
applications.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04717" title="Abstract">arXiv:2312.04717</a> [<a href="/pdf/2312.04717" title="Download PDF">pdf</a>, <a href="/format/2312.04717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A kinetic Monte Carlo Approach for Boolean Logic Functionality in Gold  Nanoparticle Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mensing%2C+J">Jonas Mensing</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wiel%2C+W+G">Wilfred G. van der Wiel</a>, 
<a href="/search/cs?searchtype=author&query=Heuer%2C+A">Andreas Heuer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR); Neural and Evolutionary Computing (cs.NE); Computational Physics (physics.comp-ph); Methodology (stat.ME)

</div>
<p class="mathjax">Nanoparticles interconnected by insulating organic molecules exhibit
nonlinear switching behavior at low temperatures. By assembling these switches
into a network and manipulating charge transport dynamics through surrounding
electrodes, the network can be reconfigurably functionalized to act as any
Boolean logic gate. This work introduces a kinetic Monte Carlo-based simulation
tool, applying established principles of single electronics to model charge
transport dynamics in nanoparticle networks. We functionalize nanoparticle
networks as Boolean logic gates and assess their quality using a fitness
function. Based on the definition of fitness, we derive new metrics to quantify
essential nonlinear properties of the network, including negative differential
resistance and nonlinear separability. These nonlinear properties are crucial
not only for functionalizing the network as Boolean logic gates but also when
our networks are functionalized for brain-inspired computing applications in
the future. We address fundamental questions about the dependence of fitness
and nonlinear properties on system size, number of surrounding electrodes, and
electrode positioning. We assert the overall benefit of having more electrodes,
with proximity to the network's output being pivotal for functionality and
nonlinearity. Additionally, we demonstrate a optimal system size and argue for
breaking symmetry in electrode positioning to favor nonlinear properties.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04719" title="Abstract">arXiv:2312.04719</a> [<a href="/pdf/2312.04719" title="Download PDF">pdf</a>, <a href="/format/2312.04719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Optimization via Kernelized Multi-armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Ayush Rai</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+S">Shaoshuai Mou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Multi-armed bandit algorithms provide solutions for sequential
decision-making where learning takes place by interacting with the environment.
In this work, we model a distributed optimization problem as a multi-agent
kernelized multi-armed bandit problem with a heterogeneous reward setting. In
this setup, the agents collaboratively aim to maximize a global objective
function which is an average of local objective functions. The agents can
access only bandit feedback (noisy reward) obtained from the associated unknown
local function with a small norm in reproducing kernel Hilbert space (RKHS). We
present a fully decentralized algorithm, Multi-agent IGP-UCB (MA-IGP-UCB),
which achieves a sub-linear regret bound for popular classes for kernels while
preserving privacy. It does not necessitate the agents to share their actions,
rewards, or estimates of their local function. In the proposed approach, the
agents sample their individual local functions in a way that benefits the whole
network by utilizing a running consensus to estimate the upper confidence bound
on the global function. Furthermore, we propose an extension, Multi-agent
Delayed IGP-UCB (MAD-IGP-UCB) algorithm, which reduces the dependence of the
regret bound on the number of agents in the network. It provides improved
performance by utilizing a delay in the estimation update step at the cost of
more communication.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04720" title="Abstract">arXiv:2312.04720</a> [<a href="/pdf/2312.04720" title="Download PDF">pdf</a>, <a href="/format/2312.04720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Big to Small Without Losing It All: Text Augmentation with ChatGPT  for Efficient Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wo%C5%BAniak%2C+S">Stanis&#x142;aw Wo&#x17a;niak</a>, 
<a href="/search/cs?searchtype=author&query=Koco%C5%84%2C+J">Jan Koco&#x144;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, presented at ICDM Workshop: SENTIRE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of artificial intelligence, data is gold but costly to annotate.
The paper demonstrates a groundbreaking solution to this dilemma using ChatGPT
for text augmentation in sentiment analysis. We leverage ChatGPT's generative
capabilities to create synthetic training data that significantly improves the
performance of smaller models, making them competitive with, or even
outperforming, their larger counterparts. This innovation enables models to be
both efficient and effective, thereby reducing computational cost, inference
time, and memory usage without compromising on quality. Our work marks a key
advancement in the cost-effective development and deployment of robust
sentiment analysis models.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04724" title="Abstract">arXiv:2312.04724</a> [<a href="/pdf/2312.04724" title="Download PDF">pdf</a>, <a href="/format/2312.04724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+M">Manish Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Chennabasappa%2C+S">Sahana Chennabasappa</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+C">Cyrus Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+S">Shengye Wan</a>, 
<a href="/search/cs?searchtype=author&query=Evtimov%2C+I">Ivan Evtimov</a>, 
<a href="/search/cs?searchtype=author&query=Gabi%2C+D">Dominik Gabi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Daniel Song</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+F">Faizan Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Aschermann%2C+C">Cornelius Aschermann</a>, 
<a href="/search/cs?searchtype=author&query=Fontana%2C+L">Lorenzo Fontana</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+S">Sasha Frolov</a>, 
<a href="/search/cs?searchtype=author&query=Giri%2C+R+P">Ravi Prakash Giri</a>, 
<a href="/search/cs?searchtype=author&query=Kapil%2C+D">Dhaval Kapil</a>, 
<a href="/search/cs?searchtype=author&query=Kozyrakis%2C+Y">Yiannis Kozyrakis</a>, 
<a href="/search/cs?searchtype=author&query=LeBlanc%2C+D">David LeBlanc</a>, 
<a href="/search/cs?searchtype=author&query=Milazzo%2C+J">James Milazzo</a>, 
<a href="/search/cs?searchtype=author&query=Straumann%2C+A">Aleksandar Straumann</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Vontimitta%2C+V">Varun Vontimitta</a>, 
<a href="/search/cs?searchtype=author&query=Whitman%2C+S">Spencer Whitman</a>, 
<a href="/search/cs?searchtype=author&query=Saxe%2C+J">Joshua Saxe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents CyberSecEval, a comprehensive benchmark developed to help
bolster the cybersecurity of Large Language Models (LLMs) employed as coding
assistants. As what we believe to be the most extensive unified cybersecurity
safety benchmark to date, CyberSecEval provides a thorough evaluation of LLMs
in two crucial security domains: their propensity to generate insecure code and
their level of compliance when asked to assist in cyberattacks. Through a case
study involving seven models from the Llama 2, Code Llama, and OpenAI GPT large
language model families, CyberSecEval effectively pinpointed key cybersecurity
risks. More importantly, it offered practical insights for refining these
models. A significant observation from the study was the tendency of more
advanced models to suggest insecure code, highlighting the critical need for
integrating security considerations in the development of sophisticated LLMs.
CyberSecEval, with its automated test case generation and evaluation pipeline
covers a broad scope and equips LLM designers and researchers with a tool to
broadly measure and enhance the cybersecurity safety properties of LLMs,
contributing to the development of more secure AI systems.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04726" title="Abstract">arXiv:2312.04726</a> [<a href="/pdf/2312.04726" title="Download PDF">pdf</a>, <a href="/format/2312.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MR-conditional Robotic Actuation of Concentric Tendon-Driven Cardiac  Catheters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tokuda%2C+J">Junichi Tokuda</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+E+J">Ehud J. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Kolandaivelu%2C+A">Aravindan Kolandaivelu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, submitted to IEEE ISMR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Atrial fibrillation (AF) and ventricular tachycardia (VT) are two of the
sustained arrhythmias that significantly affect the quality of life of
patients. Treatment of AF and VT often requires radiofrequency ablation of
heart tissues using an ablation catheter. Recent progress in ablation therapy
leverages magnetic resonance imaging (MRI) for higher contrast visual feedback,
and additionally utilizes a guiding sheath with an actively deflectable tip to
improve the dexterity of the catheter inside the heart. This paper presents the
design and validation of an MR-conditional robotic module for automated
actuation of both the ablation catheter and the sheath. The robotic module
features a compact design for improved accessibility inside the MR scanner bore
and is driven by piezoelectric motors to ensure MR-conditionality. The combined
catheter-sheath mechanism is essentially a concentric tendon-driven continuum
robot and its kinematics is modeled by the constant curvature model for
closed-loop position control. Path following experiments were conducted to
validate the actuation module and control scheme, achieving &lt; 2 mm average tip
position error.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04727" title="Abstract">arXiv:2312.04727</a> [<a href="/pdf/2312.04727" title="Download PDF">pdf</a>, <a href="/format/2312.04727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Q">Qiao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
<a href="/search/cs?searchtype=author&query=Mocanu%2C+D+C">Decebal Constantin Mocanu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Keulen%2C+M">Maurice Van Keulen</a>, 
<a href="/search/cs?searchtype=author&query=Mocanu%2C+E">Elena Mocanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks have evolved as the leading approach in 3D medical image
segmentation due to their outstanding performance. However, the ever-increasing
model size and computation cost of deep neural networks have become the primary
barrier to deploying them on real-world resource-limited hardware. In pursuit
of improving performance and efficiency, we propose a 3D medical image
segmentation model, named Efficient to Efficient Network (E2ENet),
incorporating two parametrically and computationally efficient designs. i.
Dynamic sparse feature fusion (DSFF) mechanism: it adaptively learns to fuse
informative multi-scale features while reducing redundancy. ii. Restricted
depth-shift in 3D convolution: it leverages the 3D spatial information while
keeping the model and computational complexity as 2D-based methods. We conduct
extensive experiments on BTCV, AMOS-CT and Brain Tumor Segmentation Challenge,
demonstrating that E2ENet consistently achieves a superior trade-off between
accuracy and efficiency than prior arts across various resource constraints.
E2ENet achieves comparable accuracy on the large-scale challenge AMOS-CT, while
saving over 68\% parameter count and 29\% FLOPs in the inference phase,
compared with the previous best-performing method. Our code has been made
available at: https://github.com/boqian333/E2ENet-Medical.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04728" title="Abstract">arXiv:2312.04728</a> [<a href="/pdf/2312.04728" title="Download PDF">pdf</a>, <a href="/format/2312.04728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Subnet-Drift in D2D-Enabled Fog Learning: A Hierarchical Gradient  Tracking Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Evan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted for publication in the proceedings of 2024 IEEE International Conference on Computer Communications (INFOCOM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Federated learning (FL) encounters scalability challenges when implemented
over fog networks. Semi-decentralized FL (SD-FL) proposes a solution that
divides model cooperation into two stages: at the lower stage, device-to-device
(D2D) communications is employed for local model aggregations within
subnetworks (subnets), while the upper stage handles device-server (DS)
communications for global model aggregations. However, existing SD-FL schemes
are based on gradient diversity assumptions that become performance bottlenecks
as data distributions become more heterogeneous. In this work, we develop
semi-decentralized gradient tracking (SD-GT), the first SD-FL methodology that
removes the need for such assumptions by incorporating tracking terms into
device updates for each communication layer. Analytical characterization of
SD-GT reveals convergence upper bounds for both non-convex and strongly-convex
problems, for a suitable choice of step size. We employ the resulting bounds in
the development of a co-optimization algorithm for optimizing subnet sampling
rates and D2D rounds according to a performance-efficiency trade-off. Our
subsequent numerical evaluations demonstrate that SD-GT obtains substantial
improvements in trained model quality and communication cost relative to
baselines in SD-FL and gradient tracking on several datasets.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04729" title="Abstract">arXiv:2312.04729</a> [<a href="/pdf/2312.04729" title="Download PDF">pdf</a>, <a href="/format/2312.04729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Internet of Responsibilities-Connecting Human Responsibilities using  Big Data and Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xuejiao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Toure%2C+I">Ibrahim Toure</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+E">Enza Messina</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xueping Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuebing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Accountability in the workplace is critically important and remains a
challenging problem, especially with respect to workplace safety management. In
this paper, we introduce a novel notion, the Internet of Responsibilities, for
accountability management. Our method sorts through the list of
responsibilities with respect to hazardous positions. The positions are
interconnected using directed acyclic graphs (DAGs) indicating the hierarchy of
responsibilities in the organization. In addition, the system detects and
collects responsibilities, and represents risk areas in terms of the positions
of the responsibility nodes. Finally, an automatic reminder and assignment
system is used to enforce a strict responsibility control without human
intervention. Using blockchain technology, we further extend our system with
the capability to store, recover and encrypt responsibility data. We show that
through the application of the Internet of Responsibility network model driven
by Big Data, enterprise and government agencies can attain a highly secured and
safe workplace. Therefore, our model offers a combination of interconnected
responsibilities, accountability, monitoring, and safety which is crucial for
the protection of employees and the success of organizations.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04730" title="Abstract">arXiv:2312.04730</a> [<a href="/pdf/2312.04730" title="Download PDF">pdf</a>, <a href="/format/2312.04730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial  Natural Language Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangzhou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaogeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the advancement of Large Language Models (LLMs), significant progress
has been made in code generation, enabling LLMs to transform natural language
into programming code. These Code LLMs have been widely accepted by massive
users and organizations. However, a dangerous nature is hidden in the code,
which is the existence of fatal vulnerabilities. While some LLM providers have
attempted to address these issues by aligning with human guidance, these
efforts fall short of making Code LLMs practical and robust. Without a deep
understanding of the performance of the LLMs under the practical worst cases,
it would be concerning to apply them to various real-world applications. In
this paper, we answer the critical issue: Are existing Code LLMs immune to
generating vulnerable code? If not, what is the possible maximum severity of
this issue in practical deployment scenarios? In this paper, we introduce
DeceptPrompt, a novel algorithm that can generate adversarial natural language
instructions that drive the Code LLMs to generate functionality correct code
with vulnerabilities. DeceptPrompt is achieved through a systematic
evolution-based algorithm with a fine grain loss design. The unique advantage
of DeceptPrompt enables us to find natural prefix/suffix with totally benign
and non-directional semantic meaning, meanwhile, having great power in inducing
the Code LLMs to generate vulnerable code. This feature can enable us to
conduct the almost-worstcase red-teaming on these LLMs in a real scenario,
where users are using natural language. Our extensive experiments and analyses
on DeceptPrompt not only validate the effectiveness of our approach but also
shed light on the huge weakness of LLMs in the code generation task. When
applying the optimized prefix/suffix, the attack success rate (ASR) will
improve by average 50% compared with no prefix/suffix applying.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04731" title="Abstract">arXiv:2312.04731</a> [<a href="/pdf/2312.04731" title="Download PDF">pdf</a>, <a href="/format/2312.04731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STraceBERT: Source Code Retrieval using Semantic Application Traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spiess%2C+C">Claudio Spiess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Software reverse engineering is an essential task in software engineering and
security, but it can be a challenging process, especially for adversarial
artifacts. To address this challenge, we present STraceBERT, a novel approach
that utilizes a Java dynamic analysis tool to record calls to core Java
libraries, and pretrain a BERT-style model on the recorded application traces
for effective method source code retrieval from a candidate set. Our
experiments demonstrate the effectiveness of STraceBERT in retrieving the
source code compared to existing approaches. Our proposed approach offers a
promising solution to the problem of code retrieval in software reverse
engineering and opens up new avenues for further research in this area.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04736" title="Abstract">arXiv:2312.04736</a> [<a href="/pdf/2312.04736" title="Download PDF">pdf</a>, <a href="/format/2312.04736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Feedback All You Need? Leveraging Natural Language Feedback in  Goal-Conditioned Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCallum%2C+S">Sabrina McCallum</a>, 
<a href="/search/cs?searchtype=author&query=Taylor-Davies%2C+M">Max Taylor-Davies</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+S+V">Stefano V. Albrecht</a>, 
<a href="/search/cs?searchtype=author&query=Suglia%2C+A">Alessandro Suglia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Workshop on Goal-conditioned Reinforcement Learning, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite numerous successes, the field of reinforcement learning (RL) remains
far from matching the impressive generalisation power of human behaviour
learning. One possible way to help bridge this gap be to provide RL agents with
richer, more human-like feedback expressed in natural language. To investigate
this idea, we first extend BabyAI to automatically generate language feedback
from the environment dynamics and goal condition success. Then, we modify the
Decision Transformer architecture to take advantage of this additional signal.
We find that training with language feedback either in place of or in addition
to the return-to-go or goal descriptions improves agents' generalisation
performance, and that agents can benefit from feedback even when this is only
available during training, but not at inference.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04737" title="Abstract">arXiv:2312.04737</a> [<a href="/pdf/2312.04737" title="Download PDF">pdf</a>, <a href="/format/2312.04737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Large Language Models Fine-Tuning On Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+R">Rui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xipeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Ruozhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaorui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Learning from Text-Attributed Graphs (TAGs) has attracted significant
attention due to its wide range of real-world applications. The rapid evolution
of large language models (LLMs) has revolutionized the way we process textual
data, which indicates a strong potential to replace shallow text embedding
generally used in Graph Neural Networks (GNNs). However, we find that existing
LLM approaches that exploit text information in graphs suffer from inferior
computation and data efficiency. In this work, we introduce a novel and
efficient approach for the end-to-end fine-tuning of Large Language Models
(LLMs) on TAGs, named LEADING. The proposed approach maintains computation cost
and memory overhead comparable to the graph-less fine-tuning of LLMs. Moreover,
it transfers the rick knowledge in LLMs to downstream graph learning tasks
effectively with limited labeled data in semi-supervised learning. Its superior
computation and data efficiency are demonstrated through comprehensive
experiments, offering a promising solution for a wide range of LLMs and graph
learning tasks on TAGs.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04738" title="Abstract">arXiv:2312.04738</a> [<a href="/pdf/2312.04738" title="Download PDF">pdf</a>, <a href="/format/2312.04738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPI: Ensuring Strict Differential Privacy for Infinite Data Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shuya Feng</a>, 
<a href="/search/cs?searchtype=author&query=Mohammady%2C+M">Meisam Mohammady</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yuan Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE S&amp;P 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Streaming data, crucial for applications like crowdsourcing analytics,
behavior studies, and real-time monitoring, faces significant privacy risks due
to the large and diverse data linked to individuals. In particular, recent
efforts to release data streams, using the rigorous privacy notion of
differential privacy (DP), have encountered issues with unbounded privacy
leakage. This challenge limits their applicability to only a finite number of
time slots (''finite data stream'') or relaxation to protecting the events
(''event or $w$-event DP'') rather than all the records of users. A persistent
challenge is managing the sensitivity of outputs to inputs in situations where
users contribute many activities and data distributions evolve over time. In
this paper, we present a novel technique for Differentially Private data
streaming over Infinite disclosure (DPI) that effectively bounds the total
privacy leakage of each user in infinite data streams while enabling accurate
data collection and analysis. Furthermore, we also maximize the accuracy of DPI
via a novel boosting mechanism. Finally, extensive experiments across various
streaming applications and real datasets (e.g., COVID-19, Network Traffic, and
USDA Production), show that DPI maintains high utility for infinite data
streams in diverse settings. Code for DPI is available at
https://github.com/ShuyaFeng/DPI.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04740" title="Abstract">arXiv:2312.04740</a> [<a href="/pdf/2312.04740" title="Download PDF">pdf</a>, <a href="/format/2312.04740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Train &#x27;n Trade: Foundations of Parameter Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tzu-Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+H">Harit Vishwakarma</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Organizations typically train large models individually. This is costly and
time-consuming, particularly for large-scale foundation models. Such vertical
production is known to be suboptimal. Inspired by this economic insight, we ask
whether it is possible to leverage others' expertise by trading the constituent
parts in models, i.e., sets of weights, as if they were market commodities.
While recent advances in aligning and interpolating models suggest that doing
so may be possible, a number of fundamental questions must be answered to
create viable parameter markets. In this work, we address these basic
questions, propose a framework containing the infrastructure necessary for
market operations to take place, study strategies for exchanging parameters,
and offer means for agents to monetize parameters. Excitingly, compared to
agents who train siloed models from scratch, we show that it is possible to
mutually gain by using the market, even in competitive settings. This suggests
that the notion of parameter markets may be a useful paradigm for improving
large-scale model training in the future.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04742" title="Abstract">arXiv:2312.04742</a> [<a href="/pdf/2312.04742" title="Download PDF">pdf</a>, <a href="/format/2312.04742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning Based Dynamic Power Control for UAV Mobility  Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meer%2C+I+A">Irshad A. Meer</a>, 
<a href="/search/cs?searchtype=author&query=Besser%2C+K">Karl-Ludwig Besser</a>, 
<a href="/search/cs?searchtype=author&query=Ozger%2C+M">Mustafa Ozger</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Modern communication systems need to fulfill multiple and often conflicting
objectives at the same time. In particular, new applications require high
reliability while operating at low transmit powers. Moreover, reliability
constraints may vary over time depending on the current state of the system.
One solution to address this problem is to use joint transmissions from a
number of base stations (BSs) to meet the reliability requirements. However,
this approach is inefficient when considering the overall total transmit power.
In this work, we propose a reinforcement learning-based power allocation scheme
for an unmanned aerial vehicle (UAV) communication system with varying
communication reliability requirements. In particular, the proposed scheme aims
to minimize the total transmit power of all BSs while achieving an outage
probability that is less than a tolerated threshold. This threshold varies over
time, e.g., when the UAV enters a critical zone with high-reliability
requirements. Our results show that the proposed learning scheme uses dynamic
power allocation to meet varying reliability requirements, thus effectively
conserving energy.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04743" title="Abstract">arXiv:2312.04743</a> [<a href="/pdf/2312.04743" title="Download PDF">pdf</a>, <a href="/format/2312.04743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hiding Functions within Functions: Steganography by Implicit Neural  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Peng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Y">Yan Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deep steganography utilizes the powerful capabilities of deep neural networks
to embed and extract messages, but its reliance on an additional message
extractor limits its practical use due to the added suspicion it can raise from
steganalyzers. To address this problem, we propose StegaINR, which utilizes
Implicit Neural Representation (INR) to implement steganography. StegaINR
embeds a secret function into a stego function, which serves as both the
message extractor and the stego media for secure transmission on a public
channel. Recipients need only use a shared key to recover the secret function
from the stego function, allowing them to obtain the secret message. Our
approach makes use of continuous functions, enabling it to handle various types
of messages. To our knowledge, this is the first work to introduce INR into
steganography. We performed evaluations on image and climate data to test our
method in different deployment contexts.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04744" title="Abstract">arXiv:2312.04744</a> [<a href="/pdf/2312.04744" title="Download PDF">pdf</a>, <a href="/format/2312.04744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Extraction of Road Networks via Joint Learning of  Connectivity and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yijia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wuming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Suhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuebin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Road network extraction from satellite images is widely applicated in
intelligent traffic management and autonomous driving fields. The
high-resolution remote sensing images contain complex road areas and distracted
background, which make it a challenge for road extraction. In this study, we
present a stacked multitask network for end-to-end segmenting roads while
preserving connectivity correctness. In the network, a global-aware module is
introduced to enhance pixel-level road feature representation and eliminate
background distraction from overhead images; a road-direction-related
connectivity task is added to ensure that the network preserves the graph-level
relationships of the road segments. We also develop a stacked multihead
structure to jointly learn and effectively utilize the mutual information
between connectivity learning and segmentation learning. We evaluate the
performance of the proposed network on three public remote sensing datasets.
The experimental results demonstrate that the network outperforms the
state-of-the-art methods in terms of road segmentation accuracy and
connectivity maintenance.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04746" title="Abstract">arXiv:2312.04746</a> [<a href="/pdf/2312.04746" title="Download PDF">pdf</a>, <a href="/format/2312.04746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized  Narratives from Open-Source Histopathology Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seyfioglu%2C+M+S">Mehmet Saygin Seyfioglu</a>, 
<a href="/search/cs?searchtype=author&query=Ikezogwo%2C+W+O">Wisdom O. Ikezogwo</a>, 
<a href="/search/cs?searchtype=author&query=Ghezloo%2C+F">Fatemeh Ghezloo</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+L">Linda Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The gigapixel scale of whole slide images (WSIs) poses a challenge for
histopathology multi-modal chatbots, requiring a global WSI analysis for
diagnosis, compounding evidence from different WSI patches. Current visual
instruction datasets, generated through large language models, focus on
creating question/answer pairs for individual image patches, which may lack
diagnostic capacity on their own in histopathology, further complicated by the
absence of spatial grounding in histopathology image captions. To bridge this
gap, we introduce Quilt-Instruct, a large-scale dataset of 107,131
histopathology-specific instruction question/answer pairs, that is collected by
leveraging educational histopathology videos from YouTube, which provides
spatial localization of captions by automatically extracting narrators' cursor
movements. In addition, we provide contextual reasoning by extracting diagnosis
and supporting facts from the entire video content to guide the extrapolative
reasoning of GPT-4. Using Quilt-Instruct, we train Quilt-LLaVA, which can
reason beyond the given single image patch, enabling diagnostic reasoning and
the capability of spatial awareness. To evaluate Quilt-LLaVA, we propose a
comprehensive evaluation dataset created from 985 images and 1283
human-generated question-answers. We also thoroughly evaluate Quilt-LLaVA using
public histopathology datasets, where Quilt-LLaVA significantly outperforms
SOTA by over 10% on relative GPT-4 score and 4% and 9% on open and closed set
VQA. Our code, data, and model are publicly available at quilt-llava.github.io.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04747" title="Abstract">arXiv:2312.04747</a> [<a href="/pdf/2312.04747" title="Download PDF">pdf</a>, <a href="/format/2312.04747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaDetect: Metamorphic Testing Based Anomaly Detection for Multi-UAV  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Boyang Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Software Engineering (cs.SE); Methodology (stat.ME)

</div>
<p class="mathjax">The reliability of wireless Ad Hoc Networks (WANET) communication is much
lower than wired networks. WANET will be impacted by node overload, routing
protocol, weather, obstacle blockage, and many other factors, all those
anomalies cannot be avoided. Accurate prediction of the network entirely
stopping in advance is essential after people could do networking re-routing or
changing to different bands. In the present study, there are two primary goals.
Firstly, design anomaly events detection patterns based on Metamorphic Testing
(MT) methodology. Secondly, compare the performance of evaluation metrics, such
as Transfer Rate, Occupancy rate, and the Number of packets received. Compared
to other studies, the most significant advantage of mathematical
interpretability, as well as not requiring dependence on physical environmental
information, only relies on the networking physical layer and Mac layer data.
The analysis of the results demonstrates that the proposed MT detection method
is helpful for automatically identifying incidents/accident events on WANET.
The physical layer transfer Rate metric could get the best performance.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04748" title="Abstract">arXiv:2312.04748</a> [<a href="/pdf/2312.04748" title="Download PDF">pdf</a>, <a href="/format/2312.04748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forcing Generative Models to Degenerate Ones: The Power of Data  Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuli Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kadhe%2C+S+R">Swanand Ravindra Kadhe</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Ling Cai</a>, 
<a href="/search/cs?searchtype=author&query=Baracaldo%2C+N">Nathalie Baracaldo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures. Published at NeurIPS 2023 Workshop on Backdoors in Deep Learning: The Good, the Bad, and the Ugly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Growing applications of large language models (LLMs) trained by a third party
raise serious concerns on the security vulnerability of LLMs.It has been
demonstrated that malicious actors can covertly exploit these vulnerabilities
in LLMs through poisoning attacks aimed at generating undesirable outputs.
While poisoning attacks have received significant attention in the image domain
(e.g., object detection), and classification tasks, their implications for
generative models, particularly in the realm of natural language generation
(NLG) tasks, remain poorly understood. To bridge this gap, we perform a
comprehensive exploration of various poisoning techniques to assess their
effectiveness across a range of generative tasks. Furthermore, we introduce a
range of metrics designed to quantify the success and stealthiness of poisoning
attacks specifically tailored to NLG tasks. Through extensive experiments on
multiple NLG tasks, LLMs and datasets, we show that it is possible to
successfully poison an LLM during the fine-tuning stage using as little as 1\%
of the total tuning data samples. Our paper presents the first systematic
approach to comprehend poisoning attacks targeting NLG tasks considering a wide
range of triggers and attack settings. We hope our findings will assist the AI
security community in devising appropriate defenses against such threats.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04749" title="Abstract">arXiv:2312.04749</a> [<a href="/pdf/2312.04749" title="Download PDF">pdf</a>, <a href="/format/2312.04749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make out like a (Multi-Armed) Bandit: Improving the Odds of Fuzzer Seed  Scheduling with T-Scheduler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Simon Luo</a>, 
<a href="/search/cs?searchtype=author&query=Herrera%2C+A">Adrian Herrera</a>, 
<a href="/search/cs?searchtype=author&query=Quirk%2C+P">Paul Quirk</a>, 
<a href="/search/cs?searchtype=author&query=Chase%2C+M">Michael Chase</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+D+C">Damith C. Ranasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Kanhere%2C+S+S">Salil S. Kanhere</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, Accepted paper at AsiaCCS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Fuzzing is a highly-scalable software testing technique that uncovers bugs in
a target program by executing it with mutated inputs. Over the life of a
fuzzing campaign, the fuzzer accumulates inputs inducing new and interesting
target behaviors, drawing from these inputs for further mutation. This rapidly
results in a large number of inputs to select from, making it challenging to
quickly and accurately select the "most promising" input for mutation.
Reinforcement learning (RL) provides a natural solution to this "seed
scheduling" problem: the fuzzer dynamically adapts its selection strategy by
learning from past results. However, existing RL approaches are (a)
computationally expensive (reducing fuzzer throughput) and/or (b) require
hyperparameter tuning (reducing generality across targets and input types). To
this end, we propose T-Scheduler, a seed scheduler built on multi-armed bandit
theory that automatically adapts to the target without any hyperparameter
tuning. We evaluate T-Scheduler over 35 CPU-yr of fuzzing, comparing it to 11
state-of-the-art schedulers. Our results show that T-Scheduler improves on
these 11 schedulers on both bug-finding and coverage-expansion abilities.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04752" title="Abstract">arXiv:2312.04752</a> [<a href="/pdf/2312.04752" title="Download PDF">pdf</a>, <a href="/format/2312.04752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Test-Time Learning Approach to Reparameterize the Geophysical Inverse  Problem with a Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+A">Anran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Heagy%2C+L+J">Lindsey J. Heagy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Regularization is critical in solving the ill-posed geo-physical inversion
problems. Explicit regularization is often used, but there are opportunities to
explore the implicit regularization effect inherently from a Neural Network
structure. Researchers in Computer Vision (CV) have discovered that the
Convolutional Neural Network (CNN) architecture inherently enforces a
regularization that is advantageous for addressing diverse CV inverse problems,
including de-noising and in-painting. In this study, we examine the
applicability of this implicit regularization to geophysical inversions. The
CNN maps an arbitrary vector to the model space (e.g. log-conductivity on the
simulation mesh). The predicted subsurface model is then fed into a forward
numerical simulation process to generate corresponding predicted measurements.
Subsequently, the objective function value is computed by comparing these
predicted measurements with the observed field measurements. The
backpropagation algorithm is employed to update the trainable parameters of the
CNN during the inversion. Note that the CNN in our proposed method does not
require training before the inversion, rather, the CNN weights are estimated in
the inversion algorithm, hence this is a test-time learning (TTL) approach. The
results demonstrate that the implicit regularization provided by the CNN can be
useful in DC resistivity inversions. We also provide a detailed discussion of
the potential sources of this implicit regularization and some practical guides
for applying the proposed method to other geophysical scenarios. The proposed
approach for reparameterizing the inverse problem can be adapted to other
Tikhonov-style geophysical inversions.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04754" title="Abstract">arXiv:2312.04754</a> [<a href="/pdf/2312.04754" title="Download PDF">pdf</a>, <a href="/format/2312.04754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Learning-based Distributed Algorithm for Scheduling in Multi-hop  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Daehyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sunjung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+C">Changhee Joo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Communications and Networks, Vol. 24, No. 1, February
  2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We address the joint problem of learning and scheduling in multi-hop wireless
network without a prior knowledge on link rates. Previous scheduling algorithms
need the link rate information, and learning algorithms often require a
centralized entity and polynomial complexity. These become a major obstacle to
develop an efficient learning-based distributed scheme for resource allocation
in large-scale multi-hop networks. In this work, by incorporating with learning
algorithm, we develop provably efficient scheduling scheme under packet arrival
dynamics without a priori link rate information. We extend the results to
distributed implementation and evaluation their performance through
simulations.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04758" title="Abstract">arXiv:2312.04758</a> [<a href="/pdf/2312.04758" title="Download PDF">pdf</a>, <a href="/format/2312.04758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Convolutional Autoencoder for Cyber Anomaly Detection  in Power Distribution Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zideh%2C+M+J">Mehdi Jabbari Zideh</a>, 
<a href="/search/eess?searchtype=author&query=Solanki%2C+S+K">Sarika Khushalani Solanki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The growing trend toward the modernization of power distribution systems has
facilitated the installation of advanced measurement units and promotion of the
cyber communication systems. However, these infrastructures are still prone to
stealth cyber attacks. The existing data-driven anomaly detection methods
suffer from a lack of knowledge about the system's physics, lack of
interpretability, and scalability issues hindering their practical applications
in real-world scenarios. To address these concerns, physics-informed neural
networks (PINNs) were introduced. This paper proposes a multivariate
physics-informed convolutional autoencoder (PIConvAE) to detect stealthy
cyber-attacks in power distribution grids. The proposed model integrates the
physical principles into the loss function of the neural network by applying
Kirchhoff's law. Simulations are performed on the modified IEEE 13-bus and
123-bus systems using OpenDSS software to validate the efficacy of the proposed
model for stealth attacks. The numerical results prove the superior performance
of the proposed PIConvAE in three aspects: a) it provides more accurate results
compared to the data-driven ConvAE model, b) it requires less training time to
converge c) the model excels in effectively detecting a wide range of attack
magnitudes making it powerful in detecting stealth attacks.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04762" title="Abstract">arXiv:2312.04762</a> [<a href="/pdf/2312.04762" title="Download PDF">pdf</a>, <a href="/format/2312.04762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Graph Lottery Ticket Hypothesis: Finding Sparse, Informative Graph  Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsitsulin%2C+A">Anton Tsitsulin</a>, 
<a href="/search/cs?searchtype=author&query=Perozzi%2C+B">Bryan Perozzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph learning methods help utilize implicit relationships among data items,
thereby reducing training label requirements and improving task performance.
However, determining the optimal graph structure for a particular learning task
remains a challenging research problem.
<br />In this work, we introduce the Graph Lottery Ticket (GLT) Hypothesis - that
there is an extremely sparse backbone for every graph, and that graph learning
algorithms attain comparable performance when trained on that subgraph as on
the full graph. We identify and systematically study 8 key metrics of interest
that directly influence the performance of graph learning algorithms.
Subsequently, we define the notion of a "winning ticket" for graph structure -
an extremely sparse subset of edges that can deliver a robust approximation of
the entire graph's performance. We propose a straightforward and efficient
algorithm for finding these GLTs in arbitrary graphs. Empirically, we observe
that performance of different graph learning algorithms can be matched or even
exceeded on graphs with the average degree as low as 5.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04763" title="Abstract">arXiv:2312.04763</a> [<a href="/pdf/2312.04763" title="Download PDF">pdf</a>, <a href="/format/2312.04763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAR: Consolidation, Augmentation and Regulation for Recipe Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fangzhou Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yanbin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Learning recipe and food image representation in common embedding space is
non-trivial but crucial for cross-modal recipe retrieval. In this paper, we
propose CAR framework with three novel techniques, i.e., Consolidation,
Augmentation and Regulation, for cross-modal recipe retrieval. We introduce
adapter layers to consolidate pre-trained CLIP model with much less computation
cost than fully cumbersome fine-tuning all the parameters. Furthermore,
leveraging on the strong capability of foundation models (i.e., SAM and LLM),
we propose to augment recipe and food image by extracting information related
to the counterpart. SAM generates image segments corresponding to ingredients
in the recipe, while LLM produces a visual imagination description from the
recipe, aiming to capture the visual cues of a food image. In addition, we
introduce circle loss to regulate cross-modal embedding space, which assigns
different penalties for positive and negative pairs. With the extra augmented
data from recipe and image, multi-level circle loss is proposed, which applies
circle loss not only to original image-recipe pairs, but also to image segments
and recipe, visual imagination description and food image as well as any two
sections within a recipe. On Recipe1M dataset, our proposed CAR outperforms all
the existing methods by a large margin. Extensive ablation studies are
conducted to validate the effectiveness of each component of CAR. We will make
our code and models publicly available.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04764" title="Abstract">arXiv:2312.04764</a> [<a href="/pdf/2312.04764" title="Download PDF">pdf</a>, <a href="/format/2312.04764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First Attempt at Building Parallel Corpora for Machine Translation of  Northeast India&#x27;s Very Low-Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonja%2C+A+L">Atnafu Lambebo Tonja</a>, 
<a href="/search/cs?searchtype=author&query=Mersha%2C+M">Melkamu Mersha</a>, 
<a href="/search/cs?searchtype=author&query=Kalita%2C+A">Ananya Kalita</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikova%2C+O">Olga Kolesnikova</a>, 
<a href="/search/cs?searchtype=author&query=Kalita%2C+J">Jugal Kalita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents the creation of initial bilingual corpora for thirteen
very low-resource languages of India, all from Northeast India. It also
presents the results of initial translation efforts in these languages. It
creates the first-ever parallel corpora for these languages and provides
initial benchmark neural machine translation results for these languages. We
intend to extend these corpora to include a large number of low-resource Indian
languages and integrate the effort with our prior work with African and
American-Indian languages to create corpora covering a large number of
languages from across the world.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04767" title="Abstract">arXiv:2312.04767</a> [<a href="/pdf/2312.04767" title="Download PDF">pdf</a>, <a href="/format/2312.04767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Horizon Reinforcement Learning in Solving Optimal Control of  State-Dependent Switched Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+M">Mi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this article, the deep deterministic policy gradient (DDPG) method is used
to learn an optimal control policy of a multi-region state-dependent switched
system. We observe good performance of this model-free method and explain it in
a rigorous mathematical language. The performance of the learning-based methods
is compared with the optimal solution given by vanilla differential dynamic
programming (DDP) in three customized environments.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04772" title="Abstract">arXiv:2312.04772</a> [<a href="/pdf/2312.04772" title="Download PDF">pdf</a>, <a href="/ps/2312.04772" title="Download PostScript">ps</a>, <a href="/format/2312.04772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remembering to Be Fair: On Non-Markovian Fairness in Sequential  DecisionMaking (Preliminary Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alamdari%2C+P+A">Parand A. Alamdari</a>, 
<a href="/search/cs?searchtype=author&query=Klassen%2C+T+Q">Toryn Q. Klassen</a>, 
<a href="/search/cs?searchtype=author&query=Creager%2C+E">Elliot Creager</a>, 
<a href="/search/cs?searchtype=author&query=McIlraith%2C+S+A">Sheila A. McIlraith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fair decision making has largely been studied with respect to a single
decision. In this paper we investigate the notion of fairness in the context of
sequential decision making where multiple stakeholders can be affected by the
outcomes of decisions, and where decision making may be informed by additional
constraints and criteria beyond the requirement of fairness. In this setting,
we observe that fairness often depends on the history of the sequential
decision-making process and not just on the current state. To advance our
understanding of this class of fairness problems, we define the notion of
non-Markovian fairness in the context of sequential decision making. We
identify properties of non-Markovian fairness, including notions of long-term,
anytime, periodic, and bounded fairness. We further explore the interplay
between non-Markovian fairness and memory, and how this can support
construction of fair policies in sequential decision-making settings.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04775" title="Abstract">arXiv:2312.04775</a> [<a href="/pdf/2312.04775" title="Download PDF">pdf</a>, <a href="/format/2312.04775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Determine the Most Powerful Pre-trained Language Model without  Brute Force Fine-tuning? An Empirical Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jun Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hanhua Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+W">Wenge Rong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Transferability estimation has been attached to great attention in the
computer vision fields. Researchers try to estimate with low computational cost
the performance of a model when transferred from a source task to a given
target task. Considering the effectiveness of such estimations, the communities
of natural language processing also began to study similar problems for the
selection of pre-trained language models. However, there is a lack of a
comprehensive comparison between these estimation methods yet. Also, the
differences between vision and language scenarios make it doubtful whether
previous conclusions can be established across fields. In this paper, we first
conduct a thorough survey of existing transferability estimation methods being
able to find the most suitable model, then we conduct a detailed empirical
study for the surveyed methods based on the GLUE benchmark. From qualitative
and quantitative analyses, we demonstrate the strengths and weaknesses of
existing methods and show that H-Score generally performs well with
superiorities in effectiveness and efficiency. We also outline the difficulties
of consideration of training details, applicability to text generation, and
consistency to certain metrics which shed light on future directions.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04776" title="Abstract">arXiv:2312.04776</a> [<a href="/pdf/2312.04776" title="Download PDF">pdf</a>, <a href="/format/2312.04776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence of restarted Anderson acceleration for symmetric  linear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=De+Sterck%2C+H">Hans De Sterck</a>, 
<a href="/search/math?searchtype=author&query=Krzysik%2C+O+A">Oliver A. Krzysik</a>, 
<a href="/search/math?searchtype=author&query=Smith%2C+A">Adam Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Anderson acceleration (AA) is a technique for accelerating the convergence of
an underlying fixed-point iteration. AA is widely used within computational
science, with applications ranging from electronic structure calculation to the
training of neural networks. Despite AA's widespread use, relatively little is
understood about it theoretically. An important and unanswered question in this
context is: To what extent can AA actually accelerate convergence of the
underlying fixed-point iteration? While simple enough to state, this question
appears rather difficult to answer. For example, it is unanswered even in the
simplest (non-trivial) case where the underlying fixed-point iteration consists
of applying a two-dimensional affine function. In this note we consider a
restarted variant of AA applied to solve symmetric linear systems with restart
window of size one. Several results are derived from the analytical solution of
a nonlinear eigenvalue problem characterizing residual propagation of the AA
iteration. This includes a complete characterization of the method to solve $2
\times 2$ linear systems, rigorously quantifying how the asymptotic convergence
factor depends on the initial iterate, and quantifying by how much AA
accelerates the underlying fixed-point iteration. We also prove that even if
the underlying fixed-point iteration diverges, the associated AA iteration may
still converge.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04777" title="Abstract">arXiv:2312.04777</a> [<a href="/pdf/2312.04777" title="Download PDF">pdf</a>, <a href="/ps/2312.04777" title="Download PostScript">ps</a>, <a href="/format/2312.04777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inclusive Online Learning in Australia: Barriers and Enablers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marsden%2C+L">Linda Marsden</a>, 
<a href="/search/cs?searchtype=author&query=Munn%2C+L">Luke Munn</a>, 
<a href="/search/cs?searchtype=author&query=Magee%2C+L">Liam Magee</a>, 
<a href="/search/cs?searchtype=author&query=Ferrinda%2C+M">Matthew Ferrinda</a>, 
<a href="/search/cs?searchtype=author&query=Pierre%2C+J+S">Justin St. Pierre</a>, 
<a href="/search/cs?searchtype=author&query=Third%2C+A">Amanda Third</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">While the pandemic highlighted the critical role technology plays in
children's lives, not all Australian children have reliable access to
technology. This situation exacerbates educational disadvantage for children
who are already amongst our nation's most vulnerable. In this research project,
we carried out a pilot project with three schools in Western Australia,
conducting a series of workshops and interviews with students, parents, school
staff members, and teachers. Drawing on rich empirical material, we identify
key barriers and enablers for digitally inclusive online learning at the
individual, interpersonal, organizational, and infrastructural levels. Of
particular importance is that technology is only part of this story - an array
of social, environmental, and skills "infrastructure" is needed to facilitate
inclusive online learning. Building on this finding, we ran a Digital Inclusion
Studio to address this holistic set of issues with strongly positive feedback
from participants. We conclude with a set of recommendations for stakeholders
(parents, schools, government agencies) who wish to support more digitally
inclusive learning.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04780" title="Abstract">arXiv:2312.04780</a> [<a href="/pdf/2312.04780" title="Download PDF">pdf</a>, <a href="/format/2312.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning InstructPix2Pix for Advanced Image Colorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zifeng An</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zijing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+E">Eric Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel approach to human image colorization by
fine-tuning the InstructPix2Pix model, which integrates a language model
(GPT-3) with a text-to-image model (Stable Diffusion). Despite the original
InstructPix2Pix model's proficiency in editing images based on textual
instructions, it exhibits limitations in the focused domain of colorization. To
address this, we fine-tuned the model using the IMDB-WIKI dataset, pairing
black-and-white images with a diverse set of colorization prompts generated by
ChatGPT. This paper contributes by (1) applying fine-tuning techniques to
stable diffusion models specifically for colorization tasks, and (2) employing
generative models to create varied conditioning prompts. After finetuning, our
model outperforms the original InstructPix2Pix model on multiple metrics
quantitatively, and we produce more realistically colored images qualitatively.
The code for this project is provided on the GitHub Repository
https://github.com/AllenAnZifeng/DeepLearning282.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04782" title="Abstract">arXiv:2312.04782</a> [<a href="/pdf/2312.04782" title="Download PDF">pdf</a>, <a href="/format/2312.04782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Them Spill the Beans! Coercive Knowledge Extraction from  (Production) LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guangyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guanhong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) are now widely used in various applications,
making it crucial to align their ethical standards with human values. However,
recent jail-breaking methods demonstrate that this alignment can be undermined
using carefully constructed prompts. In our study, we reveal a new threat to
LLM alignment when a bad actor has access to the model's output logits, a
common feature in both open-source LLMs and many commercial LLM APIs (e.g.,
certain GPT models). It does not rely on crafting specific prompts. Instead, it
exploits the fact that even when an LLM rejects a toxic request, a harmful
response often hides deep in the output logits. By forcefully selecting
lower-ranked output tokens during the auto-regressive generation process at a
few critical output positions, we can compel the model to reveal these hidden
responses. We term this process model interrogation. This approach differs from
and outperforms jail-breaking methods, achieving 92% effectiveness compared to
62%, and is 10 to 20 times faster. The harmful content uncovered through our
method is more relevant, complete, and clear. Additionally, it can complement
jail-breaking strategies, with which results in further boosting attack
performance. Our findings indicate that interrogation can extract toxic
knowledge even from models specifically designed for coding tasks.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04783" title="Abstract">arXiv:2312.04783</a> [<a href="/pdf/2312.04783" title="Download PDF">pdf</a>, <a href="/ps/2312.04783" title="Download PostScript">ps</a>, <a href="/format/2312.04783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Repetition of k-Player Projection Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhangale%2C+A">Amey Bhangale</a>, 
<a href="/search/cs?searchtype=author&query=Braverman%2C+M">Mark Braverman</a>, 
<a href="/search/cs?searchtype=author&query=Khot%2C+S">Subhash Khot</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We study parallel repetition of k-player games where the constraints satisfy
the projection property. We prove exponential decay in the value of a parallel
repetition of projection games with value less than 1.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04784" title="Abstract">arXiv:2312.04784</a> [<a href="/pdf/2312.04784" title="Download PDF">pdf</a>, <a href="/format/2312.04784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reality&#x27;s Canvas, Language&#x27;s Brush: Crafting 3D Avatars from Monocular  Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+Y">Yuchen Rao</a>, 
<a href="/search/cs?searchtype=author&query=Pellitero%2C+E+P">Eduardo Perez Pellitero</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jifei Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Video link: <a href="https://youtu.be/Oz83z1es2J4">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in 3D avatar generation excel with multi-view supervision
for photorealistic models. However, monocular counterparts lag in quality
despite broader applicability. We propose ReCaLab to close this gap. ReCaLab is
a fully-differentiable pipeline that learns high-fidelity 3D human avatars from
just a single RGB video. A pose-conditioned deformable NeRF is optimized to
volumetrically represent a human subject in canonical T-pose. The canonical
representation is then leveraged to efficiently associate viewpoint-agnostic
textures using 2D-3D correspondences. This enables to separately generate
albedo and shading which jointly compose an RGB prediction. The design allows
to control intermediate results for human pose, body shape, texture, and
lighting with text prompts. An image-conditioned diffusion model thereby helps
to animate appearance and pose of the 3D avatar to create video sequences with
previously unseen human motion. Extensive experiments show that ReCaLab
outperforms previous monocular approaches in terms of image quality for image
synthesis tasks. ReCaLab even outperforms multi-view methods that leverage up
to 19x more synchronized videos for the task of novel pose rendering. Moreover,
natural language offers an intuitive user interface for creative manipulation
of 3D human avatars.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04786" title="Abstract">arXiv:2312.04786</a> [<a href="/pdf/2312.04786" title="Download PDF">pdf</a>, <a href="/format/2312.04786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint User Association, Interference Cancellation and Power Control for  Multi-IRS Assisted UAV Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zhaolong Ning</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F+R">F. Richard Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Intelligent reflecting surface (IRS)-assisted unmanned aerial vehicle (UAV)
communications are expected to alleviate the load of ground base stations in a
cost-effective way. Existing studies mainly focus on the deployment and
resource allocation of a single IRS instead of multiple IRSs, whereas it is
extremely challenging for joint multi-IRS multi-user association in UAV
communications with constrained reflecting resources and dynamic scenarios. To
address the aforementioned challenges, we propose a new optimization algorithm
for joint IRS-user association, trajectory optimization of UAVs, successive
interference cancellation (SIC) decoding order scheduling and power allocation
to maximize system energy efficiency. We first propose an inverse soft-Q
learning-based algorithm to optimize multi-IRS multi-user association. Then,
SCA and Dinkelbach-based algorithm are leveraged to optimize UAV trajectory
followed by the optimization of SIC decoding order scheduling and power
allocation. Finally, theoretical analysis and performance results show
significant advantages of the designed algorithm in convergence rate and energy
efficiency.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04789" title="Abstract">arXiv:2312.04789</a> [<a href="/pdf/2312.04789" title="Download PDF">pdf</a>, <a href="/format/2312.04789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Frequency-Based Tiering for CXL Memory Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kevin Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiacheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sihang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pekhimenko%2C+G">Gennady Pekhimenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">Modern workloads are demanding increasingly larger memory capacity. Compute
Express Link (CXL)-based memory tiering has emerged as a promising solution for
addressing this trend by utilizing traditional DRAM alongside slow-tier
CXL-memory devices in the same system. Unfortunately, most prior tiering
systems are recency-based, which cannot accurately identify hot and cold pages,
since a recently accessed page is not necessarily a hot page. On the other
hand, more accurate frequency-based systems suffer from high memory and runtime
overhead as a result of tracking large memories.
<br />In this paper, we propose FreqTier, a fast and accurate frequency-based
tiering system for CXL memory. We observe that memory tiering systems can
tolerate a small amount of tracking inaccuracy without compromising the overall
application performance. Based on this observation, FreqTier probabilistically
tracks the access frequency of each page, enabling accurate identification of
hot and cold pages while maintaining minimal memory overhead. Finally, FreqTier
intelligently adjusts the intensity of tiering operations based on the
application's memory access behavior, thereby significantly reducing the amount
of migration traffic and application interference.
<br />We evaluate FreqTier on two emulated CXL memory devices with different
bandwidths. On the high bandwidth CXL device, FreqTier can outperform
state-of-the-art tiering systems while using 4$\times$ less local DRAM memory
for in-memory caching workloads. On GAP graph analytics and XGBoost workloads
with 1:32 local DRAM to CXL-memory ratio, FreqTier outperforms prior works by
1.04$-$2.04$\times$ (1.39$\times$ on average). Even on the low bandwidth CXL
device, FreqTier outperforms AutoNUMA by 1.14$\times$ on average.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04790" title="Abstract">arXiv:2312.04790</a> [<a href="/pdf/2312.04790" title="Download PDF">pdf</a>, <a href="/ps/2312.04790" title="Download PostScript">ps</a>, <a href="/format/2312.04790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction from Noisy Substrings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hengjia Wei</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+M">Moshe Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+G">Gennian Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">This paper studies the problem of encoding messages into sequences which can
be uniquely recovered from some noisy observations about their substrings. The
observed reads comprise consecutive substrings with some given minimum overlap.
This coded reconstruction problem has applications to DNA storage. We consider
both single-strand reconstruction codes and multi-strand reconstruction codes,
where the message is encoded into a single strand or a set of multiple strands,
respectively. Various parameter regimes are studied. New codes are constructed,
some of whose rates asymptotically attain the upper bounds.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04792" title="Abstract">arXiv:2312.04792</a> [<a href="/pdf/2312.04792" title="Download PDF">pdf</a>, <a href="/ps/2312.04792" title="Download PostScript">ps</a>, <a href="/format/2312.04792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI safety by debate via regret minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Angelica Chen</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+D">Dean Foster</a>, 
<a href="/search/cs?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the setting of AI safety by debate as a repeated game. We
consider the question of efficient regret minimization in this setting, when
the players are either AIs or humans, equipped with access to computationally
superior AIs. In such a setting, we characterize when internal and external
regret can be minimized efficiently. We conclude with conditions in which a
sequence of strategies converges to a correlated equilibrium.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04793" title="Abstract">arXiv:2312.04793</a> [<a href="/pdf/2312.04793" title="Download PDF">pdf</a>, <a href="/format/2312.04793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-Aware Prefix-Tuning is a Good Learner for Personalized Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image captioning bridges the gap between vision and language by automatically
generating natural language descriptions for images. Traditional image
captioning methods often overlook the preferences and characteristics of users.
Personalized image captioning solves this problem by incorporating user prior
knowledge into the model, such as writing styles and preferred vocabularies.
Most existing methods emphasize the user context fusion process by memory
networks or transformers. However, these methods ignore the distinct domains of
each dataset. Therefore, they need to update the entire caption model
parameters when meeting new samples, which is time-consuming and
calculation-intensive. To address this challenge, we propose a novel
personalized image captioning framework that leverages user context to consider
personality factors. Additionally, our framework utilizes the prefix-tuning
paradigm to extract knowledge from a frozen large language model, reducing the
gap between different language domains. Specifically, we employ CLIP to extract
the visual features of an image and align the semantic space using a
query-guided mapping network. By incorporating the transformer layer, we merge
the visual features with the user's contextual prior knowledge to generate
informative prefixes. Moreover, we employ GPT-2 as the frozen large language
model. With a small number of parameters to be trained, our model performs
efficiently and effectively. Our model outperforms existing baseline models on
Instagram and YFCC100M datasets across five evaluation metrics, demonstrating
its superiority, including twofold improvements in metrics such as BLEU-4 and
CIDEr.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04794" title="Abstract">arXiv:2312.04794</a> [<a href="/pdf/2312.04794" title="Download PDF">pdf</a>, <a href="/format/2312.04794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Grounding of Whole Radiology Reports for 3D CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichinose%2C+A">Akimichi Ichinose</a>, 
<a href="/search/cs?searchtype=author&query=Hatsutani%2C+T">Taro Hatsutani</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+K">Keigo Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Kitamura%2C+Y">Yoshiro Kitamura</a>, 
<a href="/search/cs?searchtype=author&query=Iizuka%2C+S">Satoshi Iizuka</a>, 
<a href="/search/cs?searchtype=author&query=Simo-Serra%2C+E">Edgar Simo-Serra</a>, 
<a href="/search/cs?searchtype=author&query=Kido%2C+S">Shoji Kido</a>, 
<a href="/search/cs?searchtype=author&query=Tomiyama%2C+N">Noriyuki Tomiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures. Accepted at MICCAI 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Computing and Computer Assisted Intervention Lecture
  Notes in Computer Science 14224 (2023) 611-621
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Building a large-scale training dataset is an essential problem in the
development of medical image recognition systems. Visual grounding techniques,
which automatically associate objects in images with corresponding
descriptions, can facilitate labeling of large number of images. However,
visual grounding of radiology reports for CT images remains challenging,
because so many kinds of anomalies are detectable via CT imaging, and resulting
report descriptions are long and complex. In this paper, we present the first
visual grounding framework designed for CT image and report pairs covering
various body parts and diverse anomaly types. Our framework combines two
components of 1) anatomical segmentation of images, and 2) report structuring.
The anatomical segmentation provides multiple organ masks of given CT images,
and helps the grounding model recognize detailed anatomies. The report
structuring helps to accurately extract information regarding the presence,
location, and type of each anomaly described in corresponding reports. Given
the two additional image/report features, the grounding model can achieve
better localization. In the verification process, we constructed a large-scale
dataset with region-description correspondence annotations for 10,410 studies
of 7,321 unique patients. We evaluated our framework using grounding accuracy,
the percentage of correctly localized anomalies, as a metric and demonstrated
that the combination of the anatomical segmentation and the report structuring
improves the performance with a large margin over the baseline model (66.0% vs
77.8%). Comparison with the prior techniques also showed higher performance of
our method.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04799" title="Abstract">arXiv:2312.04799</a> [<a href="/pdf/2312.04799" title="Download PDF">pdf</a>, <a href="/format/2312.04799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview of MLCommons Cloud Mask Benchmark: Related Research and Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=von+Laszewski%2C+G">Gregor von Laszewski</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Ruochen Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 tables 7 figures, 3 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cloud masking is a crucial task that is well-motivated for meteorology and
its applications in environmental and atmospheric sciences. Its goal is, given
satellite images, to accurately generate cloud masks that identify each pixel
in image to contain either cloud or clear sky. In this paper, we summarize some
of the ongoing research activities in cloud masking, with a focus on the
research and benchmark currently conducted in MLCommons Science Working Group.
This overview is produced with the hope that others will have an easier time
getting started and collaborate on the activities related to MLCommons Cloud
Mask Benchmark.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04802" title="Abstract">arXiv:2312.04802</a> [<a href="/pdf/2312.04802" title="Download PDF">pdf</a>, <a href="/format/2312.04802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hanjiang Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) are vulnerable to adversarial perturbation, where
an imperceptible perturbation is added to the image that can fool the DNNs.
Diffusion-based adversarial purification focuses on using the diffusion model
to generate a clean image against such adversarial attacks. Unfortunately, the
generative process of the diffusion model is also inevitably affected by
adversarial perturbation since the diffusion model is also a deep network where
its input has adversarial perturbation. In this work, we propose
MimicDiffusion, a new diffusion-based adversarial purification technique, that
directly approximates the generative process of the diffusion model with the
clean image as input. Concretely, we analyze the differences between the guided
terms using the clean image and the adversarial sample. After that, we first
implement MimicDiffusion based on Manhattan distance. Then, we propose two
guidance to purify the adversarial perturbation and approximate the clean
diffusion model. Extensive experiments on three image datasets including
CIFAR-10, CIFAR-100, and ImageNet with three classifier backbones including
WideResNet-70-16, WideResNet-28-10, and ResNet50 demonstrate that
MimicDiffusion significantly performs better than the state-of-the-art
baselines. On CIFAR-10, CIFAR-100, and ImageNet, it achieves 92.67\%, 61.35\%,
and 61.53\% average robust accuracy, which are 18.49\%, 13.23\%, and 17.64\%
higher, respectively. The code is available in the supplementary material.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04803" title="Abstract">arXiv:2312.04803</a> [<a href="/pdf/2312.04803" title="Download PDF">pdf</a>, <a href="/format/2312.04803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperNormal: Neural Surface Reconstruction via Multi-View Normal  Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Taketomi%2C+T">Takafumi Taketomi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present SuperNormal, a fast, high-fidelity approach to multi-view 3D
reconstruction using surface normal maps. With a few minutes, SuperNormal
produces detailed surfaces on par with 3D scanners. We harness volume rendering
to optimize a neural signed distance function (SDF) powered by multi-resolution
hash encoding. To accelerate training, we propose directional finite difference
and patch-based ray marching to approximate the SDF gradients numerically.
While not compromising reconstruction quality, this strategy is nearly twice as
efficient as analytical gradients and about three times faster than
axis-aligned finite difference. Experiments on the benchmark dataset
demonstrate the superiority of SuperNormal in efficiency and accuracy compared
to existing multi-view photometric stereo methods. On our captured objects,
SuperNormal produces more fine-grained geometry than recent neural 3D
reconstruction methods.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04804" title="Abstract">arXiv:2312.04804</a> [<a href="/pdf/2312.04804" title="Download PDF">pdf</a>, <a href="/format/2312.04804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hate Cannot Drive out Hate: Forecasting Conversation Incivility  following Replies to Hate Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinchen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+E">Eduardo Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lingzi Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 18th International AAAI Conference on Web and Social Media (ICWSM 2024) Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">User-generated replies to hate speech are promising means to combat hatred,
but questions about whether they can stop incivility in follow-up conversations
linger. We argue that effective replies stop incivility from emerging in
follow-up conversations - replies that elicit more incivility are
counterproductive. This study introduces the task of predicting the incivility
of conversations following replies to hate speech. We first propose a metric to
measure conversation incivility based on the number of civil and uncivil
comments as well as the unique authors involved in the discourse. Our metric
approximates human judgments more accurately than previous metrics. We then use
the metric to evaluate the outcomes of replies to hate speech. A linguistic
analysis uncovers the differences in the language of replies that elicit
follow-up conversations with high and low incivility. Experimental results show
that forecasting incivility is challenging. We close with a qualitative
analysis shedding light into the most common errors made by the best model.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04805" title="Abstract">arXiv:2312.04805</a> [<a href="/pdf/2312.04805" title="Download PDF">pdf</a>, <a href="/format/2312.04805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and Assessment of Autonomous Vehicles in Both Fully  Automated and Mixed Traffic Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelrahman%2C+A">Ahmed Abdelrahman</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> https://ml4ad.github.io/files/papers2023/Development%20and%20Assessment%20of%20Autonomous%20Vehicles%20in%20Both%20Fully%20Automated%20and%20Mixed%20Traffic%20Conditions.pdf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous Vehicle (AV) technology is advancing rapidly, promising a
significant shift in road transportation safety and potentially resolving
various complex transportation issues. With the increasing deployment of AVs by
various companies, questions emerge about how AVs interact with each other and
with human drivers, especially when AVs are prevalent on the roads. Ensuring
cooperative interaction between AVs and between AVs and human drivers is
critical, though there are concerns about possible negative competitive
behaviors. This paper presents a multi-stage approach, starting with the
development of a single AV and progressing to connected AVs, incorporating
sharing and caring V2V communication strategy to enhance mutual coordination. A
survey is conducted to validate the driving performance of the AV and will be
utilized for a mixed traffic case study, which focuses on how the human drivers
will react to the AV driving alongside them on the same road. Results show that
using deep reinforcement learning, the AV acquired driving behavior that
reached human driving performance. The adoption of sharing and caring based V2V
communication within AV networks enhances their driving behavior, aids in more
effective action planning, and promotes collaborative behavior amongst the AVs.
The survey shows that safety in mixed traffic cannot be guaranteed, as we
cannot control human ego-driven actions if they decide to compete with AV.
Consequently, this paper advocates for enhanced research into the safe
incorporation of AVs on public roads.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04806" title="Abstract">arXiv:2312.04806</a> [<a href="/pdf/2312.04806" title="Download PDF">pdf</a>, <a href="/format/2312.04806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL Dreams: Policy Gradient Optimization for Score Distillation based 3D  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathur%2C+A+N">Aradhya N. Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+P">Phu Pham</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+O">Ojaswa Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D generation has rapidly accelerated in the past decade owing to the
progress in the field of generative modeling. Score Distillation Sampling (SDS)
based rendering has improved 3D asset generation to a great extent. Further,
the recent work of Denoising Diffusion Policy Optimization (DDPO) demonstrates
that the diffusion process is compatible with policy gradient methods and has
been demonstrated to improve the 2D diffusion models using an aesthetic scoring
function. We first show that this aesthetic scorer acts as a strong guide for a
variety of SDS-based methods and demonstrates its effectiveness in text-to-3D
synthesis. Further, we leverage the DDPO approach to improve the quality of the
3D rendering obtained from 2D diffusion models. Our approach, DDPO3D, employs
the policy gradient method in tandem with aesthetic scoring. To the best of our
knowledge, this is the first method that extends policy gradient methods to 3D
score-based rendering and shows improvement across SDS-based methods such as
DreamGaussian, which are currently driving research in text-to-3D synthesis.
Our approach is compatible with score distillation-based methods, which would
facilitate the integration of diverse reward functions into the generative
process. Our project page can be accessed via https://ddpo3d.github.io.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04807" title="Abstract">arXiv:2312.04807</a> [<a href="/pdf/2312.04807" title="Download PDF">pdf</a>, <a href="/format/2312.04807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Neural Machine Translation by Multi-Knowledge Integration with  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yu Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready. Accepted by EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Improving neural machine translation (NMT) systems with prompting has
achieved significant progress in recent years. In this work, we focus on how to
integrate multi-knowledge, multiple types of knowledge, into NMT models to
enhance the performance with prompting. We propose a unified framework, which
can integrate effectively multiple types of knowledge including sentences,
terminologies/phrases and translation templates into NMT models. We utilize
multiple types of knowledge as prefix-prompts of input for the encoder and
decoder of NMT models to guide the translation process. The approach requires
no changes to the model architecture and effectively adapts to domain-specific
translation without retraining. The experiments on English-Chinese and
English-German translation demonstrate that our approach significantly
outperform strong baselines, achieving high translation quality and terminology
match accuracy.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04808" title="Abstract">arXiv:2312.04808</a> [<a href="/pdf/2312.04808" title="Download PDF">pdf</a>, <a href="/ps/2312.04808" title="Download PostScript">ps</a>, <a href="/format/2312.04808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review On Table Recognition Based On Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiyuan%2C+S">Shi Jiyuan</a>, 
<a href="/search/cs?searchtype=author&query=chunqi%2C+S">Shi chunqi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 figures,6 tables, in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Table recognition is using the computer to automatically understand the
table, to detect the position of the table from the document or picture, and to
correctly extract and identify the internal structure and content of the table.
After earlier mainstream approaches based on heuristic rules and machine
learning, the development of deep learning techniques has brought a new
paradigm to this field. This review mainly discusses the table recognition
problem from five aspects. The first part introduces data sets, benchmarks, and
commonly used evaluation indicators. This section selects representative data
sets, benchmarks, and evaluation indicators that are frequently used by
researchers. The second part introduces the table recognition model. This
survey introduces the development of the table recognition model, especially
the table recognition model based on deep learning. It is generally accepted
that table recognition is divided into two stages: table detection and table
structure recognition. This section introduces the models that follow this
paradigm (TD and TSR). The third part is the End-to-End method, this section
introduces some scholars' attempts to use an end-to-end approach to solve the
table recognition problem once and for all and the part are Data-centric
methods, such as data augmentation, aligning benchmarks, and other methods. The
fourth part is the data-centric approach, such as data enhancement, alignment
benchmark, and so on. The fifth part summarizes and compares the experimental
data in the field of form recognition, and analyzes the mainstream and more
advantageous methods. Finally, this paper also discusses the possible
development direction and trend of form processing in the future, to provide
some ideas for researchers in the field of table recognition. (Resource will be
released at https://github.com/Wa1den-jy/Topic-on-Table-Recognition .)
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04809" title="Abstract">arXiv:2312.04809</a> [<a href="/pdf/2312.04809" title="Download PDF">pdf</a>, <a href="/ps/2312.04809" title="Download PostScript">ps</a>, <a href="/format/2312.04809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Path of Women in Software Engineering: From Academia to  Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+T">Tatalina Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Barcomb%2C+A">Ann Barcomb</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza+Santos%2C+R">Ronnie de Souza Santos</a>, 
<a href="/search/cs?searchtype=author&query=Barros%2C+H">Helda Barros</a>, 
<a href="/search/cs?searchtype=author&query=Baldassarre%2C+M+T">Maria Teresa Baldassarre</a>, 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7a%2C+C">C&#xe9;sar Fran&#xe7;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context. Women remain significantly underrepresented in software engineering,
leading to a lasting gender gap in the software industry. This disparity starts
in education and extends into the industry, causing challenges such as hostile
work environments and unequal opportunities. Addressing these issues is crucial
for fostering an inclusive and diverse software engineering workforce. Aim.
This study aims to enhance the literature on women in software engineering,
exploring their journey from academia to industry and discussing perspectives,
challenges, and support. We focus on Brazilian women to extend existing
research, which has largely focused on North American and European contexts.
Method. In this study, we conducted a cross-sectional survey, collecting both
quantitative and qualitative data, focusing on women's experiences in software
engineering to explore their journey from university to the software industry.
Findings. Our findings highlight persistent challenges faced by women in
software engineering, including gender bias, harassment, work-life imbalance,
undervaluation, low sense of belonging, and impostor syndrome. These
difficulties commonly emerge from university experiences and continue to affect
women throughout their entire careers. Conclusion. In summary, our study
identifies systemic challenges in women's software engineering journey,
emphasizing the need for organizational commitment to address these issues. We
provide actionable recommendations for practitioners.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04810" title="Abstract">arXiv:2312.04810</a> [<a href="/pdf/2312.04810" title="Download PDF">pdf</a>, <a href="/format/2312.04810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RS-Corrector: Correcting the Racial Stereotypes in Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yueming Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tianxiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent text-conditioned image generation models have demonstrated an
exceptional capacity to produce diverse and creative imagery with high visual
quality. However, when pre-trained on billion-sized datasets randomly collected
from the Internet, where potential biased human preferences exist, these models
tend to produce images with common and recurring stereotypes, particularly for
certain racial groups. In this paper, we conduct an initial analysis of the
publicly available Stable Diffusion model and its derivatives, highlighting the
presence of racial stereotypes. These models often generate distorted or biased
images for certain racial groups, emphasizing stereotypical characteristics. To
address these issues, we propose a framework called "RS-Corrector", designed to
establish an anti-stereotypical preference in the latent space and update the
latent code for refined generated results. The correction process occurs during
the inference stage without requiring fine-tuning of the original model.
Extensive empirical evaluations demonstrate that the introduced \themodel
effectively corrects the racial stereotypes of the well-trained Stable
Diffusion model while leaving the original model unchanged.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04813" title="Abstract">arXiv:2312.04813</a> [<a href="/pdf/2312.04813" title="Download PDF">pdf</a>, <a href="/format/2312.04813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DARNet: Bridging Domain Gaps in Cross-Domain Few-Shot Segmentation with  Dynamic Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pagnucco%2C+M">Maurice Pagnucco</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot segmentation (FSS) aims to segment novel classes in a query image by
using only a small number of supporting images from base classes. However, in
cross-domain few-shot segmentation (CD-FSS), leveraging features from
label-rich domains for resource-constrained domains poses challenges due to
domain discrepancies. This work presents a Dynamically Adaptive Refine (DARNet)
method that aims to balance generalization and specificity for CD-FSS. Our
method includes the Channel Statistics Disruption (CSD) strategy, which
perturbs feature channel statistics in the source domain, bolstering
generalization to unknown target domains. Moreover, recognizing the variability
across target domains, an Adaptive Refine Self-Matching (ARSM) method is also
proposed to adjust the matching threshold and dynamically refine the prediction
result with the self-matching method, enhancing accuracy. We also present a
Test-Time Adaptation (TTA) method to refine the model's adaptability to diverse
feature distributions. Our approach demonstrates superior performance against
state-of-the-art methods in CD-FSS tasks.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04814" title="Abstract">arXiv:2312.04814</a> [<a href="/pdf/2312.04814" title="Download PDF">pdf</a>, <a href="/format/2312.04814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Particle-Based Solver for Non-Newtonian Behaviors Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunlei Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayi He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tianwei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+A">Aimin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hong Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this paper, we present a unified framework to simulate non-Newtonian
behaviors. We combine viscous and elasto-plastic stress into a unified particle
solver to achieve various non-Newtonian behaviors ranging from fluid-like to
solid-like. Our constitutive model is based on a Generalized Maxwell model,
which incorporates viscosity, elasticity and plasticity in one non-linear
framework by a unified way. On the one hand, taking advantage of the viscous
term, we construct a series of strain-rate dependent models for classical
non-Newtonian behaviors such as shear-thickening, shear-thinning, Bingham
plastic, etc. On the other hand, benefiting from the elasto-plastic model, we
empower our framework with the ability to simulate solid-like non-Newtonian
behaviors, i.e., visco-elasticity/plasticity. In addition, we enrich our method
with a heat diffusion model to make our method flexible in simulating phase
change. Through sufficient experiments, we demonstrate a wide range of
non-Newtonian behaviors ranging from viscous fluid to deformable objects. We
believe this non-Newtonian model will enhance the realism of physically-based
animation, which has great potential for computer graphics.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04815" title="Abstract">arXiv:2312.04815</a> [<a href="/pdf/2312.04815" title="Download PDF">pdf</a>, <a href="/format/2312.04815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Negatives AreWorth Attending to: Meta-Bootstrapping Negative  Sampling Framework for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yakun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Meiqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guo Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Huimei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The rapid development of graph neural networks (GNNs) encourages the rising
of link prediction, achieving promising performance with various applications.
Unfortunately, through a comprehensive analysis, we surprisingly find that
current link predictors with dynamic negative samplers (DNSs) suffer from the
migration phenomenon between "easy" and "hard" samples, which goes against the
preference of DNS of choosing "hard" negatives, thus severely hindering
capability. Towards this end, we propose the MeBNS framework, serving as a
general plugin that can potentially improve current negative sampling based
link predictors. In particular, we elaborately devise a Meta-learning Supported
Teacher-student GNN (MST-GNN) that is not only built upon teacher-student
architecture for alleviating the migration between "easy" and "hard" samples
but also equipped with a meta learning based sample re-weighting module for
helping the student GNN distinguish "hard" samples in a fine-grained manner. To
effectively guide the learning of MST-GNN, we prepare a Structure enhanced
Training Data Generator (STD-Generator) and an Uncertainty based Meta Data
Collector (UMD-Collector) for supporting the teacher and student GNN,
respectively. Extensive experiments show that the MeBNS achieves remarkable
performance across six link prediction benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04817" title="Abstract">arXiv:2312.04817</a> [<a href="/pdf/2312.04817" title="Download PDF">pdf</a>, <a href="/format/2312.04817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoVQA: A Benchmark of Versatile Question-Answering for Long-Form Movie  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Lu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zhen-Hua Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While several long-form VideoQA datasets have been introduced, the length of
both videos used to curate questions and sub-clips of clues leveraged to answer
those questions have not yet reached the criteria for genuine long-form video
understanding. Moreover, their QAs are unduly narrow and modality-biased,
lacking a wider view of understanding long-term video content with rich
dynamics and complex narratives. To remedy this, we introduce MoVQA, a
long-form movie question-answering dataset, and benchmark to assess the diverse
cognitive capabilities of multimodal systems rely on multi-level temporal
lengths, with considering both video length and clue length. Additionally, to
take a step towards human-level understanding in long-form video, versatile and
multimodal question-answering is designed from the moviegoer-perspective to
assess the model capabilities on various perceptual and cognitive axes.Through
analysis involving various baselines reveals a consistent trend: the
performance of all methods significantly deteriorate with increasing video and
clue length. Meanwhile, our established baseline method has shown some
improvements, but there is still ample scope for enhancement on our challenging
MoVQA dataset. We expect our MoVQA to provide a new perspective and encourage
inspiring works on long-form video understanding research.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04818" title="Abstract">arXiv:2312.04818</a> [<a href="/pdf/2312.04818" title="Download PDF">pdf</a>, <a href="/format/2312.04818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Program Knowledge Graph to Uncover Software Vulnerabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">M. Xie</a>, 
<a href="/search/cs?searchtype=author&query=Rahat%2C+T">T. Rahat</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">W. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Y. Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2-page poster accepted at Annual Computer Security Applications Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In an increasingly interconnected and data-driven world, the importance of
robust security measures cannot be overstated. A knowledge graph constructed
with information extracted from the system along with the desired security
behavior can be utilized to identify complex security vulnerabilities hidden
underneath the systems. Unfortunately, existing security knowledge graphs are
constructed from coarse-grained information extracted from publicly available
vulnerability reports, which are not equipped to check actual security
violations in real-world system implementations. In this poster, we present a
novel approach of using Program Knowledge Graph that is embedded with
fine-grained execution information of the systems (e.g., callgraph, data-flow,
etc.) along with information extracted from the public vulnerability and
weakness datasets (e.g., CVE and CWE). We further demonstrate that our custom
security knowledge graph can be checked against the standard queries generated
by LLM, providing a powerful way to identify security vulnerabilities and
weaknesses in critical systems.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04819" title="Abstract">arXiv:2312.04819</a> [<a href="/pdf/2312.04819" title="Download PDF">pdf</a>, <a href="/format/2312.04819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Guided Contrastive Role Representations for Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zican Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zongzhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hongyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Real-world multi-agent tasks usually involve dynamic team composition with
the emergence of roles, which should also be a key to efficient cooperation in
multi-agent reinforcement learning (MARL). Drawing inspiration from the
correlation between roles and agent's behavior patterns, we propose a novel
framework of Attention-guided COntrastive Role representation learning for MARL
(ACORM) to promote behavior heterogeneity, knowledge transfer, and skillful
coordination across agents. First, we introduce mutual information maximization
to formalize role representation learning, derive a contrastive learning
objective, and concisely approximate the distribution of negative pairs.
Second, we leverage an attention mechanism to prompt the global state to attend
to learned role representations in value decomposition, implicitly guiding
agent coordination in a skillful role space to yield more expressive credit
assignment. Experiments and visualizations on challenging StarCraft II
micromanagement tasks demonstrate the state-of-the-art performance of our
method and its advantages over existing approaches. Our code is available at
https://github.com/NJU-RL/ACORM}{https://github.com/NJU-RL/ACORM.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04820" title="Abstract">arXiv:2312.04820</a> [<a href="/pdf/2312.04820" title="Download PDF">pdf</a>, <a href="/format/2312.04820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn to Optimize Denoising Scores for 3D Generation: A Unified and  Improved Diffusion Prior on NeRF and 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaofeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xulei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a unified framework aimed at enhancing the diffusion priors for 3D
generation tasks. Despite the critical importance of these tasks, existing
methodologies often struggle to generate high-caliber results. We begin by
examining the inherent limitations in previous diffusion priors. We identify a
divergence between the diffusion priors and the training procedures of
diffusion models that substantially impairs the quality of 3D generation. To
address this issue, we propose a novel, unified framework that iteratively
optimizes both the 3D model and the diffusion prior. Leveraging the different
learnable parameters of the diffusion prior, our approach offers multiple
configurations, affording various trade-offs between performance and
implementation complexity. Notably, our experimental results demonstrate that
our method markedly surpasses existing techniques, establishing new
state-of-the-art in the realm of text-to-3D generation. Furthermore, our
approach exhibits impressive performance on both NeRF and the newly introduced
3D Gaussian Splatting backbones. Additionally, our framework yields insightful
contributions to the understanding of recent score distillation methods, such
as the VSD and DDS loss.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04821" title="Abstract">arXiv:2312.04821</a> [<a href="/pdf/2312.04821" title="Download PDF">pdf</a>, <a href="/ps/2312.04821" title="Download PostScript">ps</a>, <a href="/format/2312.04821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unify Change Point Detection and Segment Classification in a Regression  Task for Transportation Mode Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+X">Xin Pei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identifying travelers' transportation modes is important in transportation
science and location-based services. It's appealing for researchers to leverage
GPS trajectory data to infer transportation modes with the popularity of
GPS-enabled devices, e.g., smart phones. Existing studies frame this problem as
classification task. The dominant two-stage studies divide the trip into
single-one mode segments first and then categorize these segments. The over
segmentation strategy and inevitable error propagation bring difficulties to
classification stage and make optimizing the whole system hard. The recent
one-stage works throw out trajectory segmentation entirely to avoid these by
directly conducting point-wise classification for the trip, whereas leaving
predictions dis-continuous. To solve above-mentioned problems, inspired by YOLO
and SSD in object detection, we propose to reframe change point detection and
segment classification as a unified regression task instead of the existing
classification task. We directly regress coordinates of change points and
classify associated segments. In this way, our method divides the trip into
segments under a supervised manner and leverage more contextual information,
obtaining predictions with high accuracy and continuity. Two frameworks,
TrajYOLO and TrajSSD, are proposed to solve the regression task and various
feature extraction backbones are exploited. Exhaustive experiments on GeoLife
dataset show that the proposed method has competitive overall identification
accuracy of 0.853 when distinguishing five modes: walk, bike, bus, car, train.
As for change point detection, our method increases precision at the cost of
drop in recall. All codes are available at
https://github.com/RadetzkyLi/TrajYOLO-SSD.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04822" title="Abstract">arXiv:2312.04822</a> [<a href="/pdf/2312.04822" title="Download PDF">pdf</a>, <a href="/format/2312.04822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiCP: Simultaneous Individual and Cooperative Perception for 3D Object  Detection in Connected and Automated Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+D">Deyuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+T">Tianyu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+A">Andy Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongsheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Song Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cooperative perception for connected and automated vehicles is traditionally
achieved through the fusion of feature maps from two or more vehicles. However,
the absence of feature maps shared from other vehicles can lead to a
significant decline in object detection performance for cooperative perception
models compared to standalone 3D detection models. This drawback impedes the
adoption of cooperative perception as vehicle resources are often insufficient
to concurrently employ two perception models. To tackle this issue, we present
Simultaneous Individual and Cooperative Perception (SiCP), a generic framework
that supports a wide range of the state-of-the-art standalone perception
backbones and enhances them with a novel Dual-Perception Network (DP-Net)
designed to facilitate both individual and cooperative perception. In addition
to its lightweight nature with only 0.13M parameters, DP-Net is robust and
retains crucial gradient information during feature map fusion. As demonstrated
in a comprehensive evaluation on the OPV2V dataset, thanks to DP-Net, SiCP
surpasses state-of-the-art cooperative perception solutions while preserving
the performance of standalone perception solutions.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04823" title="Abstract">arXiv:2312.04823</a> [<a href="/pdf/2312.04823" title="Download PDF">pdf</a>, <a href="/format/2312.04823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Neural Network Representations During Training Using  Noise-Resilient Diffusion Spectral Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Danqi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+B+W">Benjamin W. Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+A">Alexander Tong</a>, 
<a href="/search/cs?searchtype=author&query=Huguet%2C+G">Guillaume Huguet</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+G">Guy Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Nickel%2C+M">Maximilian Nickel</a>, 
<a href="/search/cs?searchtype=author&query=Adelstein%2C+I">Ian Adelstein</a>, 
<a href="/search/cs?searchtype=author&query=Krishnaswamy%2C+S">Smita Krishnaswamy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICML 2023 Workshop on Topology, Algebra, and Geometry in Machine
  Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Entropy and mutual information in neural networks provide rich information on
the learning process, but they have proven difficult to compute reliably in
high dimensions. Indeed, in noisy and high-dimensional data, traditional
estimates in ambient dimensions approach a fixed entropy and are prohibitively
hard to compute. To address these issues, we leverage data geometry to access
the underlying manifold and reliably compute these information-theoretic
measures. Specifically, we define diffusion spectral entropy (DSE) in neural
representations of a dataset as well as diffusion spectral mutual information
(DSMI) between different variables representing data. First, we show that they
form noise-resistant measures of intrinsic dimensionality and relationship
strength in high-dimensional simulated data that outperform classic Shannon
entropy, nonparametric estimation, and mutual information neural estimation
(MINE). We then study the evolution of representations in classification
networks with supervised learning, self-supervision, or overfitting. We observe
that (1) DSE of neural representations increases during training; (2) DSMI with
the class label increases during generalizable learning but stays stagnant
during overfitting; (3) DSMI with the input signal shows differing trends: on
MNIST it increases, while on CIFAR-10 and STL-10 it decreases. Finally, we show
that DSE can be used to guide better network initialization and that DSMI can
be used to predict downstream classification accuracy across 962 models on
ImageNet. The official implementation is available at
https://github.com/ChenLiu-1996/DiffusionSpectralEntropy.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04825" title="Abstract">arXiv:2312.04825</a> [<a href="/pdf/2312.04825" title="Download PDF">pdf</a>, <a href="/format/2312.04825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Combinatorial Laplacian and its Application to Coverage Repair  in Sensor Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadokoro%2C+S">Shunsaku Yadokoro</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Subhrajit Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">We define the weighted combinatorial Laplacian operators on a simplicial
complex and investigate their spectral properties. Eigenvalues close to zero
and the corresponding eigenvectors of them are especially of our interest, and
we show that they can detect almost $n$-dimensional holes in the given complex.
Real-valued weights on simplices allow gradient descent based optimization,
which in turn gives an efficient dynamic coverage repair algorithm for the
sensor network of a mobile robot team.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04828" title="Abstract">arXiv:2312.04828</a> [<a href="/pdf/2312.04828" title="Download PDF">pdf</a>, <a href="/format/2312.04828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HuRef: HUman-REadable Fingerprint for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Boyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouhan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Protecting the copyright of large language models (LLMs) has become crucial
due to their resource-intensive training and accompanying carefully designed
licenses. However, identifying the original base model of an LLM is challenging
due to potential parameter alterations through fine-tuning or continued
pretraining. In this study, we introduce HuRef, a human-readable fingerprint
for LLMs that uniquely identifies the base model without exposing model
parameters or interfering with training. We first observe that the vector
direction of LLM parameters remains stable after the model has converged during
pretraining, showing negligible perturbations through subsequent training
steps, including continued pretraining, supervised fine-tuning (SFT), and RLHF,
which makes it a sufficient condition to identify the base model. The necessity
is validated by continuing to train an LLM with an extra term to drive away the
model parameters' direction and the model becomes damaged. However, this
direction is vulnerable to simple attacks like dimension permutation or matrix
rotation, which significantly change it without affecting performance. To
address this, leveraging the Transformer structure, we systematically analyze
potential attacks and define three invariant terms that identify an LLM's base
model. We make these invariant terms human-readable by mapping them to a
Gaussian vector using a convolutional encoder and then converting it into a
natural image with StyleGAN2. Our method generates a dog image as an identity
fingerprint for an LLM, where the dog's appearance strongly indicates the LLM's
base model. Experimental results across various LLMs demonstrate the
effectiveness of our method, the generated dog image remains invariant to
different training steps, including SFT, RLHF, or even continued pretraining
with augmented vocabulary in a new language.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04831" title="Abstract">arXiv:2312.04831</a> [<a href="/pdf/2312.04831" title="Download PDF">pdf</a>, <a href="/format/2312.04831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Stable and Faithful Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chenjie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yikai-wang.github.io/asuka/">this https URL</a> Yikai Wang and Chenjie Cao contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent progress in inpainting increasingly relies on generative models,
leveraging their strong generation capabilities for addressing ill-conditioned
problems. However, this enhanced generation often introduces instability,
leading to arbitrary object generation within masked regions. This paper
proposes a balanced solution, emphasizing the importance of unmasked regions in
guiding inpainting while preserving generative capacity. Our approach, Aligned
Stable Inpainting with UnKnown Areas Prior (ASUKA), employs a
reconstruction-based masked auto-encoder (MAE) as a stable prior. Aligned with
the robust Stable Diffusion inpainting model (SD), ASUKA significantly improves
inpainting stability. ASUKA further aligns masked and unmasked regions through
an inpainting-specialized decoder, ensuring more faithful inpainting. To
validate effectiveness across domains and masking scenarios, we evaluate on
MISATO, a collection of several existing dataset. Results confirm ASUKA's
efficacy in both stability and fidelity compared to SD and other inpainting
algorithms.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04832" title="Abstract">arXiv:2312.04832</a> [<a href="/pdf/2312.04832" title="Download PDF">pdf</a>, <a href="/ps/2312.04832" title="Download PostScript">ps</a>, <a href="/format/2312.04832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposing Algorithmic Discrimination and Its Consequences in Modern  Society: Insights from a Scoping Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehal%2C+R+S">Ramandeep Singh Dehal</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mehak Sharma</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza+Santos%2C+R">Ronnie de Souza Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Algorithmic discrimination is a condition that arises when data-driven
software unfairly treats users based on attributes like ethnicity, race,
gender, sexual orientation, religion, age, disability, or other personal
characteristics. Nowadays, as machine learning gains popularity, cases of
algorithmic discrimination are increasingly being reported in several contexts.
This study delves into various studies published over the years reporting
algorithmic discrimination. We aim to support software engineering researchers
and practitioners in addressing this issue by discussing key characteristics of
the problem
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04833" title="Abstract">arXiv:2312.04833</a> [<a href="/pdf/2312.04833" title="Download PDF">pdf</a>, <a href="/format/2312.04833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Look at 5G Core Deployments on Public Cloud: Performance  Evaluation of Control and User Planes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atalay%2C+T+O">Tolga O. Atalay</a>, 
<a href="/search/cs?searchtype=author&query=Stojadinovic%2C+D">Dragoslav Stojadinovic</a>, 
<a href="/search/cs?searchtype=author&query=Famili%2C+A">Alireza Famili</a>, 
<a href="/search/cs?searchtype=author&query=Stavrou%2C+A">Angelos Stavrou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haining Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Fifth Generation (5G) mobile core network is designed as a set of Virtual
Network Functions (VNFs) hosted on Commercial-Off-the-Shelf (COTS) hardware.
This creates a growing demand for general-purpose compute resources as 5G
deployments continue to expand. Given their elastic infrastructure, cloud
services such as Amazon Web Services (AWS) are attractive platforms to address
this need. Therefore, it is crucial to understand the control and user plane
Quality of Service (QoS) performance associated with deploying the 5G core on
top of a public cloud. To account for both software and communication costs, we
build a 5G testbed using open-source components spanning multiple locations
within AWS. We present an operational breakdown of the performance overhead for
various 5G use cases using different core deployment strategies. Our results
indicate that moving specific VNFs into edge regions reduces the latency
overhead for key 5G operations. Furthermore, we instantiated multiple user
plane connections between availability zones and edge regions with different
traffic loads. We observed that the deterioration of connection quality varies
depending on traffic loads and is use case specific. Ultimately, our findings
provide new insights for Mobile Virtual Network Operators (MVNOs) for optimal
placements of their 5G core functions.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04835" title="Abstract">arXiv:2312.04835</a> [<a href="/pdf/2312.04835" title="Download PDF">pdf</a>, <a href="/ps/2312.04835" title="Download PostScript">ps</a>, <a href="/format/2312.04835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Epidemiology after COVID-19: impact and prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mesquita%2C+S">Sara Mesquita</a>, 
<a href="/search/cs?searchtype=author&query=Perfeito%2C+L">L&#xed;lia Perfeito</a>, 
<a href="/search/cs?searchtype=author&query=Paolotti%2C+D">Daniela Paolotti</a>, 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves-S%C3%A1%2C+J">Joana Gon&#xe7;alves-S&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures and a supplement material file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Epidemiology and Public Health have increasingly relied on structured and
unstructured data, collected inside and outside of typical health systems, to
study, identify, and mitigate diseases at the population level. Focusing on
infectious disease, we review how Digital Epidemiology (DE) was at the
beginning of 2020 and how it was changed by the COVID-19 pandemic, in both
nature and breadth. We argue that DE will become a progressively useful tool as
long as its potential is recognized and its risks are minimized. Therefore, we
expand on the current views and present a new definition of DE that, by
highlighting the statistical nature of the datasets, helps in identifying
possible biases. We offer some recommendations to reduce inequity and threats
to privacy and argue in favour of complex multidisciplinary approaches to
tackling infectious diseases.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04836" title="Abstract">arXiv:2312.04836</a> [<a href="/pdf/2312.04836" title="Download PDF">pdf</a>, <a href="/format/2312.04836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thermodynamic Computing System for AI Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melanson%2C+D">Denis Melanson</a>, 
<a href="/search/cs?searchtype=author&query=Khater%2C+M+A">Mohammad Abu Khater</a>, 
<a href="/search/cs?searchtype=author&query=Aifer%2C+M">Maxwell Aifer</a>, 
<a href="/search/cs?searchtype=author&query=Donatella%2C+K">Kaelan Donatella</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+M+H">Max Hunter Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Ahle%2C+T">Thomas Ahle</a>, 
<a href="/search/cs?searchtype=author&query=Crooks%2C+G">Gavin Crooks</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+A+J">Antonio J. Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Sbahi%2C+F">Faris Sbahi</a>, 
<a href="/search/cs?searchtype=author&query=Coles%2C+P+J">Patrick J. Coles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent breakthroughs in artificial intelligence (AI) algorithms have
highlighted the need for novel computing hardware in order to truly unlock the
potential for AI. Physics-based hardware, such as thermodynamic computing, has
the potential to provide a fast, low-power means to accelerate AI primitives,
especially generative AI and probabilistic AI. In this work, we present the
first continuous-variable thermodynamic computer, which we call the stochastic
processing unit (SPU). Our SPU is composed of RLC circuits, as unit cells, on a
printed circuit board, with 8 unit cells that are all-to-all coupled via
switched capacitances. It can be used for either sampling or linear algebra
primitives, and we demonstrate Gaussian sampling and matrix inversion on our
hardware. The latter represents the first thermodynamic linear algebra
experiment. We also illustrate the applicability of the SPU to uncertainty
quantification for neural network classification. We envision that this
hardware, when scaled up in size, will have significant impact on accelerating
various probabilistic AI applications.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04837" title="Abstract">arXiv:2312.04837</a> [<a href="/pdf/2312.04837" title="Download PDF">pdf</a>, <a href="/format/2312.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localized Symbolic Knowledge Distillation for Visual Commonsense Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J+S">Jae Sung Park</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K+R">Khyathi Raghavi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+P">Peter West</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiuyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Instruction following vision-language (VL) models offer a flexible interface
that supports a broad range of multimodal tasks in a zero-shot fashion.
However, interfaces that operate on full images do not directly enable the user
to "point to" and access specific regions within images. This capability is
important not only to support reference-grounded VL benchmarks, but also, for
practical applications that require precise within-image reasoning. We build
Localized Visual Commonsense models, which allow users to specify (multiple)
regions as input. We train our model by sampling localized commonsense
knowledge from a large language model (LLM): specifically, we prompt an LLM to
collect commonsense knowledge given a global literal image description and a
local literal region description automatically generated by a set of VL models.
With a separately trained critic model that selects high-quality examples, we
find that training on the localized commonsense corpus can successfully distill
existing VL models to support a reference-as-input interface. Empirical results
and human evaluations in a zero-shot setup demonstrate that our distillation
method results in more precise VL models of reasoning compared to a baseline of
passing a generated referring expression to an LLM.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04838" title="Abstract">arXiv:2312.04838</a> [<a href="/pdf/2312.04838" title="Download PDF">pdf</a>, <a href="/format/2312.04838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Generalizable Perceptual Representations for Data-Efficient  No-Reference Image Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srinath%2C+S">Suhas Srinath</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Shankhanil Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+S">Shika Rao</a>, 
<a href="/search/cs?searchtype=author&query=Soundararajan%2C+R">Rajiv Soundararajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/CVF WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">No-reference (NR) image quality assessment (IQA) is an important tool in
enhancing the user experience in diverse visual applications. A major drawback
of state-of-the-art NR-IQA techniques is their reliance on a large number of
human annotations to train models for a target IQA application. To mitigate
this requirement, there is a need for unsupervised learning of generalizable
quality representations that capture diverse distortions. We enable the
learning of low-level quality features agnostic to distortion types by
introducing a novel quality-aware contrastive loss. Further, we leverage the
generalizability of vision-language models by fine-tuning one such model to
extract high-level image quality information through relevant text prompts. The
two sets of features are combined to effectively predict quality by training a
simple regressor with very few samples on a target dataset. Additionally, we
design zero-shot quality predictions from both pathways in a completely blind
setting. Our experiments on diverse datasets encompassing various distortions
show the generalizability of the features and their superior performance in the
data-efficient and zero-shot settings. Code will be made available at
https://github.com/suhas-srinath/GRepQ.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04839" title="Abstract">arXiv:2312.04839</a> [<a href="/pdf/2312.04839" title="Download PDF">pdf</a>, <a href="/ps/2312.04839" title="Download PostScript">ps</a>, <a href="/format/2312.04839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Teacher Perspectives and Experiences after Deployment of  AI Literacy Curriculum in Middle-school Classrooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravi%2C+P">Prerna Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Broski%2C+A">Annalisa Broski</a>, 
<a href="/search/cs?searchtype=author&query=Stump%2C+G">Glenda Stump</a>, 
<a href="/search/cs?searchtype=author&query=Abelson%2C+H">Hal Abelson</a>, 
<a href="/search/cs?searchtype=author&query=Klopfer%2C+E">Eric Klopfer</a>, 
<a href="/search/cs?searchtype=author&query=Breazeal%2C+C">Cynthia Breazeal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at 16th annual International Conference of Education, Research and Innovation (ICERI) 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICERI2023 Proceedings, pp. 6875-6884
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Artificial Intelligence (AI) and its associated applications are ubiquitous
in today's world, making it imperative that students and their teachers
understand how it works and the ramifications arising from its usage. In this
study, we investigate the experiences of seven teachers following their
implementation of modules from the MIT RAICA (Responsible AI for Computational
Action) curriculum. Through semi-structured interviews, we investigated their
instructional strategies as they engaged with the AI curriculum in their
classroom, how their teaching and learning beliefs about AI evolved with the
curriculum as well as how those beliefs impacted their implementation of the
curriculum. Our analysis suggests that the AI modules not only expanded our
teachers' knowledge in the field, but also prompted them to recognize its daily
applications and their ethical and societal implications, so that they could
better engage with the content they deliver to students. Teachers were able to
leverage their own interdisciplinary backgrounds to creatively introduce
foundational AI topics to students to maximize engagement and playful learning.
Our teachers advocated their need for better external support when navigating
technological resources, additional time for preparation given the novelty of
the curriculum, more flexibility within curriculum timelines, and additional
accommodations for students of determination. Our findings provide valuable
insights for enhancing future iterations of AI literacy curricula and teacher
professional development (PD) resources.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04840" title="Abstract">arXiv:2312.04840</a> [<a href="/pdf/2312.04840" title="Download PDF">pdf</a>, <a href="/format/2312.04840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis on Effects of Fault Elements in Memristive Neuromorphic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyun-Jong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">Jae-Han Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 5 tables, IJCAI 2023 GLOW workshop(<a href="https://sites.google.com/view/glow-ijcai-23/home">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Nowadays, neuromorphic systems based on Spiking Neural Networks (SNNs)
attract attentions of many researchers. There are many studies to improve
performances of neuromorphic systems. These studies have been showing
satisfactory results. To magnify performances of neuromorphic systems,
developing actual neuromorphic systems is essential. For developing them,
memristors play key role due to their useful characteristics. Although
memristors are essential for actual neuromorphic systems, they are vulnerable
to faults. However, there are few studies analyzing effects of fault elements
in neuromorphic systems using memristors. To solve this problem, we analyze
performance of a memristive neuromorphic system with fault elements changing
fault ratios, types, and positions. We choose neurons and synapses to inject
faults. We inject two types of faults to synapses: SA0 and SA1 faults. The
fault synapses appear in random and important positions. Through our analysis,
we discover the following four interesting points. First, memristive
characteristics increase vulnerability of neuromorphic systems to fault
elements. Second, fault neuron ratios reducing performance sharply exist.
Third, performance degradation by fault synapses depends on fault types.
Finally, SA1 fault synapses improve performance when they appear in important
positions.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04843" title="Abstract">arXiv:2312.04843</a> [<a href="/pdf/2312.04843" title="Download PDF">pdf</a>, <a href="/format/2312.04843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FREDSum: A Dialogue Summarization Corpus for French Political Debates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rennard%2C+V">Virgile Rennard</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+G">Guokan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Grari%2C+D">Damien Grari</a>, 
<a href="/search/cs?searchtype=author&query=Hunter%2C+J">Julie Hunter</a>, 
<a href="/search/cs?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in deep learning, and especially the invention of
encoder-decoder architectures, has significantly improved the performance of
abstractive summarization systems. The majority of research has focused on
written documents, however, neglecting the problem of multi-party dialogue
summarization. In this paper, we present a dataset of French political debates
for the purpose of enhancing resources for multi-lingual dialogue
summarization. Our dataset consists of manually transcribed and annotated
political debates, covering a range of topics and perspectives. We highlight
the importance of high quality transcription and annotations for training
accurate and effective dialogue summarization models, and emphasize the need
for multilingual resources to support dialogue summarization in non-English
languages. We also provide baseline experiments using state-of-the-art methods,
and encourage further research in this area to advance the field of dialogue
summarization. Our dataset will be made publicly available for use by the
research community.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04845" title="Abstract">arXiv:2312.04845</a> [<a href="/pdf/2312.04845" title="Download PDF">pdf</a>, <a href="/format/2312.04845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Identification of Attack-free Sensors in Networked Control  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Anand%2C+S+C">Sribalaji C. Anand</a>, 
<a href="/search/eess?searchtype=author&query=Chong%2C+M+S">Michelle S. Chong</a>, 
<a href="/search/eess?searchtype=author&query=Teixeira%2C+A+M+H">Andr&#xe9; M. H. Teixeira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper proposes a data-driven framework to identify the attack-free
sensors in a networked control system when some of the sensors are corrupted by
an adversary. An operator with access to offline input-output attack-free
trajectories of the plant is considered. Then, a data-driven algorithm is
proposed to identify the attack-free sensors when the plant is controlled
online. We also provide necessary conditions, based on the properties of the
plant, under which the algorithm is feasible. An extension of the algorithm is
presented to identify the sensors completely online against certain classes of
attacks. The efficacy of our algorithm is depicted through numerical examples.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04846" title="Abstract">arXiv:2312.04846</a> [<a href="/pdf/2312.04846" title="Download PDF">pdf</a>, <a href="/format/2312.04846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound Source Localization for a Source inside a Structure using  Ac-CycleGAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kita%2C+S">Shunsuke Kita</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C+S">Choong Sik Park</a>, 
<a href="/search/cs?searchtype=author&query=Kajikawa%2C+Y">Yoshinobu Kajikawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose a method for sound source localization (SSL) for a source inside a
structure using Ac-CycleGAN under unpaired data conditions. The proposed method
utilizes a large amount of simulated data and a small amount of actual
experimental data to locate a sound source inside a structure in a real
environment. An Ac-CycleGAN generator contributes to the transformation of
simulated data into real data, or vice versa, using unpaired data from both
domains. The discriminator of an Ac-CycleGAN model is designed to differentiate
between the transformed data generated by the generator and real data, while
also predicting the location of the sound source. Vectors representing the
frequency spectrum of the accelerometers (FSAs) measured at three points
outside the structure are used as input data and the source areas inside the
structure are used as labels. The input data vectors are concatenated
vertically to form an image. Labels are defined by dividing the interior of the
structure into eight areas with one-hot encoding for each area. Thus, the SSL
problem is redefined as an image-classification problem to stochastically
estimate the location of the sound source. We show that it is possible to
estimate the sound source location using the Ac-CycleGAN discriminator for
unpaired data across domains. Furthermore, we analyze the discriminative
factors for distinguishing the data. The proposed model exhibited an accuracy
exceeding 90\% when trained on 80\% of actual data (12.5\% of simulated data).
Despite potential imperfections in the domain transformation process carried
out by the Ac-CycleGAN generator, the discriminator can effectively distinguish
between transferred and real data by selectively utilizing only those features
that generate a relatively small transformation error.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04854" title="Abstract">arXiv:2312.04854</a> [<a href="/pdf/2312.04854" title="Download PDF">pdf</a>, <a href="/format/2312.04854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Apollo&#x27;s Oracle: Retrieval-Augmented Reasoning in Multi-Agent Debates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiyuan Du</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zheng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yi Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-agent debate systems are designed to derive accurate and consistent
conclusions through adversarial interactions among agents. However, these
systems often encounter challenges due to cognitive constraints, manifesting as
(1) agents' obstinate adherence to incorrect viewpoints and (2) their
propensity to abandon correct viewpoints. These issues are primarily
responsible for the ineffectiveness of such debates. Addressing the challenge
of cognitive constraints, we introduce a novel framework, the Multi-Agent
Debate with Retrieval Augmented (MADRA). MADRA incorporates retrieval of prior
knowledge into the debate process, effectively breaking cognitive constraints
and enhancing the agents' reasoning capabilities. Furthermore, we have
developed a self-selection module within this framework, enabling agents to
autonomously select pertinent evidence, thereby minimizing the impact of
irrelevant or noisy data. We have comprehensively tested and analyzed MADRA
across six diverse datasets. The experimental results demonstrate that our
approach significantly enhances performance across various tasks, proving the
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04856" title="Abstract">arXiv:2312.04856</a> [<a href="/pdf/2312.04856" title="Download PDF">pdf</a>, <a href="/format/2312.04856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCALER: Versatile Multi-Limbed Robot for Free-Climbing in Extreme  Terrains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+Y">Yusuke Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Shirai%2C+Y">Yuki Shirai</a>, 
<a href="/search/cs?searchtype=author&query=Schperberg%2C+A">Alexander Schperberg</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Dennis Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents SCALER, a versatile free-climbing multi-limbed robot that
is designed to achieve tightly coupled simultaneous locomotion and dexterous
grasping. Although existing quadruped-limbed robots have shown impressive
dexterous skills such as object manipulation, it is essential to balance
power-intensive locomotion and dexterous grasping capabilities. We design a
torso linkage and a parallel-serial limb to meet such conflicting skills that
pose unique challenges in the hardware designs. SCALER employs underactuated
two-fingered GOAT grippers that can mechanically adapt and offer 7 modes of
grasping, enabling SCALER to traverse extreme terrains with multi-modal
grasping strategies. We study the whole-body approach, where SCALER uses its
body and limbs to generate additional forces for stable grasping with
environments, further enhancing versatility. Furthermore, we improve the GOAT
gripper actuation speed to realize more dynamic climbing in a closed-loop
control fashion. With these proposed technologies, SCALER can traverse
vertical, overhang, upside-down, slippery terrains, and bouldering walls with
non-convex-shaped climbing holds under the Earth's gravity.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04857" title="Abstract">arXiv:2312.04857</a> [<a href="/pdf/2312.04857" title="Download PDF">pdf</a>, <a href="/format/2312.04857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application-Defined Receive Side Dispatching on the NIC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinkun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Antichi%2C+G">Gianni Antichi</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+A">Aurojit Panda</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+A">Anirudh Sivaraman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Recently, some application (L7) processing has been moved to the network
stack (including proxies) as a way to provide a common and application-agnostic
interface for security policies, simplify service management, etc. This paper
looks at whether L7 network functionality can be offloaded to SmartNICs to
improve performance and reduce overheads. We investigate this question by
examining how to offload to FPGA NICs the task of L7 dispatch: determining
which application process must handle a particular application request. We find
that existing protocols, e.g., gRPC on TCP or QUIC, are a hindrance for
offloading because the data required to make L7 dispatch decisions can be
spread out over many packets, requiring the NIC to buffer and parse a large
number of packets to reconstruct L7 data. This paper presents QingNiao-an
approach that co-designs application libraries, network protocols, and
hardware-to make L7 dispatch feasible under NIC memory constraints. We
prototype QingNiao on a 100Gbps FPGA NIC. Experiments with real-world
applications show that QingNiao supports a variety of dispatch rules and
achieves 7.5x to 8x throughput compared to state-of-the-art software L7
dispatcher. We have open-sourced QingNiao at [1].
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04860" title="Abstract">arXiv:2312.04860</a> [<a href="/pdf/2312.04860" title="Download PDF">pdf</a>, <a href="/ps/2312.04860" title="Download PostScript">ps</a>, <a href="/format/2312.04860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are We Testing or Being Tested? Exploring the Practical Applications of  Large Language Models in Software Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+R">Robson Santos</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+I">Italo Santos</a>, 
<a href="/search/cs?searchtype=author&query=Magalhaes%2C+C">Cleyton Magalhaes</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza+Santos%2C+R">Ronnie de Souza Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">A Large Language Model (LLM) represents a cutting-edge artificial
intelligence model that generates coherent content, including grammatically
precise sentences, human-like paragraphs, and syntactically accurate code
snippets. LLMs can play a pivotal role in software development, including
software testing. LLMs go beyond traditional roles such as requirement analysis
and documentation and can support test case generation, making them valuable
tools that significantly enhance testing practices within the field. Hence, we
explore the practical application of LLMs in software testing within an
industrial setting, focusing on their current use by professional testers. In
this context, rather than relying on existing data, we conducted a
cross-sectional survey and collected data within real working contexts,
specifically, engaging with practitioners in industrial settings. We applied
quantitative and qualitative techniques to analyze and synthesize our collected
data. Our findings demonstrate that LLMs effectively enhance testing documents
and significantly assist testing professionals in programming tasks like
debugging and test case automation. LLMs can support individuals engaged in
manual testing who need to code. However, it is crucial to emphasize that, at
this early stage, software testing professionals should use LLMs with caution
while well-defined methods and guidelines are being built for the secure
adoption of these tools.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04861" title="Abstract">arXiv:2312.04861</a> [<a href="/pdf/2312.04861" title="Download PDF">pdf</a>, <a href="/format/2312.04861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radar Perception in Autonomous Driving: Exploring Different Data  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shanliang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+R">Runwei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zitian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenhang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yilu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E+G">Eng Gee Lim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+H">Hyungjoon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+K+L">Ka Lok Man</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaohui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yutao Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures, 4 tables. arXiv admin note: substantial text overlap with <a href="/abs/2304.10410">arXiv:2304.10410</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid advancements of sensor technology and deep learning,
autonomous driving systems are providing safe and efficient access to
intelligent vehicles as well as intelligent transportation. Among these
equipped sensors, the radar sensor plays a crucial role in providing robust
perception information in diverse environmental conditions. This review focuses
on exploring different radar data representations utilized in autonomous
driving systems. Firstly, we introduce the capabilities and limitations of the
radar sensor by examining the working principles of radar perception and signal
processing of radar measurements. Then, we delve into the generation process of
five radar representations, including the ADC signal, radar tensor, point
cloud, grid map, and micro-Doppler signature. For each radar representation, we
examine the related datasets, methods, advantages and limitations. Furthermore,
we discuss the challenges faced in these data representations and propose
potential research directions. Above all, this comprehensive review offers an
in-depth insight into how these representations enhance autonomous system
capabilities, providing guidance for radar perception researchers. To
facilitate retrieval and comparison of different data representations, datasets
and methods, we provide an interactive website at
https://radar-camera-fusion.github.io/radar.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04862" title="Abstract">arXiv:2312.04862</a> [<a href="/pdf/2312.04862" title="Download PDF">pdf</a>, <a href="/format/2312.04862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Damage GAN: A Generative Model for Imbalanced Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anaissi%2C+A">Ali Anaissi</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuanzhe Jia</a>, 
<a href="/search/cs?searchtype=author&query=Braytee%2C+A">Ali Braytee</a>, 
<a href="/search/cs?searchtype=author&query=Naji%2C+M">Mohamad Naji</a>, 
<a href="/search/cs?searchtype=author&query=Alyassine%2C+W">Widad Alyassine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AusDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study delves into the application of Generative Adversarial Networks
(GANs) within the context of imbalanced datasets. Our primary aim is to enhance
the performance and stability of GANs in such datasets. In pursuit of this
objective, we introduce a novel network architecture known as Damage GAN,
building upon the ContraD GAN framework which seamlessly integrates GANs and
contrastive learning. Through the utilization of contrastive learning, the
discriminator is trained to develop an unsupervised representation capable of
distinguishing all provided samples. Our approach draws inspiration from the
straightforward framework for contrastive learning of visual representations
(SimCLR), leading to the formulation of a distinctive loss function. We also
explore the implementation of self-damaging contrastive learning (SDCLR) to
further enhance the optimization of the ContraD GAN model. Comparative
evaluations against baseline models including the deep convolutional GAN
(DCGAN) and ContraD GAN demonstrate the evident superiority of our proposed
model, Damage GAN, in terms of generated image distribution, model stability,
and image quality when applied to imbalanced datasets.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04863" title="Abstract">arXiv:2312.04863</a> [<a href="/pdf/2312.04863" title="Download PDF">pdf</a>, <a href="/ps/2312.04863" title="Download PostScript">ps</a>, <a href="/format/2312.04863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information divergences of Markov chains and their applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M+C+H">Michael C.H. Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Probability (math.PR); Computation (stat.CO)

</div>
<p class="mathjax">In this paper, we first introduce and define several new information
divergences in the space of transition matrices of finite Markov chains which
measure the discrepancy between two Markov chains. These divergences offer
natural generalizations of classical information-theoretic divergences, such as
the $f$-divergences and the R\'enyi divergence between probability measures, to
the context of finite Markov chains. We begin by detailing and deriving
fundamental properties of these divergences and notably gives a Markov chain
version of the Pinsker's inequality and Chernoff information. We then utilize
these notions in a few applications. First, we investigate the binary
hypothesis testing problem of Markov chains, where the newly defined R\'enyi
divergence between Markov chains and its geometric interpretation play an
important role in the analysis. Second, we propose and analyze
information-theoretic (Ces\`aro) mixing times and ergodicity coefficients,
along with spectral bounds of these notions in the reversible setting. Examples
of the random walk on the hypercube, as well as the connections between the
critical height of the low-temperature Metropolis-Hastings chain and these
proposed ergodicity coefficients, are highlighted.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04864" title="Abstract">arXiv:2312.04864</a> [<a href="/pdf/2312.04864" title="Download PDF">pdf</a>, <a href="/ps/2312.04864" title="Download PostScript">ps</a>, <a href="/format/2312.04864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Analysis of 5G Networks Traffic Intrusion using PCA, t-SNE and  UMAP Visualization and Classifying Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghani%2C+H">Humera Ghani</a>, 
<a href="/search/cs?searchtype=author&query=Salekzamankhani%2C+S">Shahram Salekzamankhani</a>, 
<a href="/search/cs?searchtype=author&query=Virdee%2C+B">Bal Virdee</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Data Analytics and Management
  (ICDAM2023), 23 June 2023. London Metropolitan University, London, UK.
  Proceedings of Data Analytics and Management ICDAM 2023, Volume 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Networks, threat models, and malicious actors are advancing quickly. With the
increased deployment of the 5G networks, the security issues of the attached 5G
physical devices have also increased. Therefore, artificial intelligence based
autonomous end-to-end security design is needed that can deal with incoming
threats by detecting network traffic anomalies. To address this requirement, in
this research, we used a recently published 5G traffic dataset, 5G-NIDD, to
detect network traffic anomalies using machine and deep learning approaches.
First, we analyzed the dataset using three visualization techniques:
t-Distributed Stochastic Neighbor Embedding (t-SNE), Uniform Manifold
Approximation and Projection (UMAP), and Principal Component Analysis (PCA).
Second, we reduced the data dimensionality using mutual information and PCA
techniques. Third, we solve the class imbalance issue by inserting synthetic
records of minority classes. Last, we performed classification using six
different classifiers and presented the evaluation metrics. We received the
best results when K-Nearest Neighbors classifier was used: accuracy (97.2%),
detection rate (96.7%), and false positive rate (2.2%).
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04865" title="Abstract">arXiv:2312.04865</a> [<a href="/pdf/2312.04865" title="Download PDF">pdf</a>, <a href="/format/2312.04865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StructComp: Substituting propagation with Structural Compression in  Training Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengzhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zengfeng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph contrastive learning (GCL) has become a powerful tool for learning
graph data, but its scalability remains a significant challenge. In this work,
we propose a simple yet effective training framework called Structural
Compression (StructComp) to address this issue. Inspired by a sparse low-rank
approximation on the diffusion matrix, StructComp trains the encoder with the
compressed nodes. This allows the encoder not to perform any message passing
during the training stage, and significantly reduces the number of sample pairs
in the contrastive loss. We theoretically prove that the original GCL loss can
be approximated with the contrastive loss computed by StructComp. Moreover,
StructComp can be regarded as an additional regularization term for GCL models,
resulting in a more robust encoder. Empirical studies on seven benchmark
datasets show that StructComp greatly reduces the time and memory consumption
while improving model performance compared to the vanilla GCL models and
scalable training methods.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04867" title="Abstract">arXiv:2312.04867</a> [<a href="/pdf/2312.04867" title="Download PDF">pdf</a>, <a href="/format/2312.04867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandDiffuse: Generative Controllers for Two-Hand Interactions via  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sihang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongdi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing hands datasets are largely short-range and the interaction is weak
due to the self-occlusion and self-similarity of hands, which can not yet fit
the need for interacting hands motion generation. To rescue the data scarcity,
we propose HandDiffuse12.5M, a novel dataset that consists of temporal
sequences with strong two-hand interactions. HandDiffuse12.5M has the largest
scale and richest interactions among the existing two-hand datasets. We further
present a strong baseline method HandDiffuse for the controllable motion
generation of interacting hands using various controllers. Specifically, we
apply the diffusion model as the backbone and design two motion representations
for different controllers. To reduce artifacts, we also propose Interaction
Loss which explicitly quantifies the dynamic interaction process. Our
HandDiffuse enables various applications with vivid two-hand interactions,
i.e., motion in-betweening and trajectory control. Experiments show that our
method outperforms the state-of-the-art techniques in motion generation and can
also contribute to data augmentation for other datasets. Our dataset,
corresponding codes, and pre-trained models will be disseminated to the
community for future research towards two-hand interaction modeling.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04868" title="Abstract">arXiv:2312.04868</a> [<a href="/pdf/2312.04868" title="Download PDF">pdf</a>, <a href="/ps/2312.04868" title="Download PostScript">ps</a>, <a href="/format/2312.04868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulator control of the Robotized TMS System with Incurved TMS Coil  Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaewoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gi-hun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Objective: This study shows the force/torque control strategy for the
robotized TMS system whose TMS coil's floor is incurved. The strategy
considered the adhesion and friction between the coil and the subject's head.
Methods: Hybrid position/force control and proportional torque were used for
the strategy. The force magnitude applied for the force control was scheduled
by the error between the coil's current position and the target point. Results:
The larger desired force for the force controller makes the error quickly. By
scheduling the force magnitude applied for the force control, the low error
between the coil's current and target positions is maintained with the
relatively small force after the larger force is applied for around 10 seconds.
The proportional torque made the adhesion better by locating the contact area
between the coil and the head close to the coil. I was shown by checking the
${\tau}_c/F_c$ value from the experimental results. While the head slowly moved
away from the coil during the TMS treatment, the coil still interacted with the
head. Using that characteristic, the coil could locate the new target point
using the force/torque strategy without any trajectory planning. Conclusion:
The proposed force/torque controller enhanced the adhesion between the incurved
TMS coil and the subject's head. It also reduced the error quickly by
scheduling the magnitude of the force applied. Significance: This study
proposes the robotized TMS system's force/torque control strategy considering
the physical characteristics from the contact between the incurved TMS coil
case and the subject's head.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04869" title="Abstract">arXiv:2312.04869</a> [<a href="/pdf/2312.04869" title="Download PDF">pdf</a>, <a href="/ps/2312.04869" title="Download PostScript">ps</a>, <a href="/format/2312.04869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Vision Transformer for Efficient Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yanni Dong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most change detection models based on vision transformers currently follow a
"pretraining then fine-tuning" strategy. This involves initializing the model
weights using large scale classification datasets, which can be either natural
images or remote sensing images. However, fully tuning such a model requires
significant time and resources. In this paper, we propose an efficient tuning
approach that involves freezing the parameters of the pretrained image encoder
and introducing additional training parameters. Through this approach, we have
achieved competitive or even better results while maintaining extremely low
resource consumption across six change detection benchmarks. For example,
training time on LEVIR-CD, a change detection benchmark, is only half an hour
with 9 GB memory usage, which could be very convenient for most researchers.
Additionally, the decoupled tuning framework can be extended to any pretrained
model for semantic change detection and multi temporal change detection as
well. We hope that our proposed approach will serve as a part of foundational
model to inspire more unified training approaches on change detection in the
future.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04871" title="Abstract">arXiv:2312.04871</a> [<a href="/pdf/2312.04871" title="Download PDF">pdf</a>, <a href="/format/2312.04871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYSFLOW: Efficient Execution Platform for IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhenya Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yinggang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Ju Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaoxue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">Traditional executable delivery models pose challenges for IoT devices with
limited storage, necessitating the download of complete executables and
dependencies. Network solutions like NFS, designed for data files, encounter
high IO overhead for irregular access patterns. This paper introduces SYSFLOW,
a lightweight network-based executable delivery system for IoT. SYSFLOW
delivers on-demand, redirecting local disk IO to the server through optimized
network IO. To optimize cache hit rates, SYSFLOW employs server-side
action-based prefetching, reducing latency by 45.1% to 75.8% compared to native
Linux filesystems on SD cards. In wired environments, SYSFLOW's latency is up
to 67.7% lower than NFS. In wireless scenarios, SYSFLOW performs 22.9% worse
than Linux, comparable with Linux and outperforming NFS by up to 60.7%. While
SYSFLOW's power consumption may be 6.7% higher than NFS, it offers energy
savings due to lower processing time.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04874" title="Abstract">arXiv:2312.04874</a> [<a href="/pdf/2312.04874" title="Download PDF">pdf</a>, <a href="/format/2312.04874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Underwater Diver Gesture Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mangalvedhekar%2C+S">Sudeep Mangalvedhekar</a>, 
<a href="/search/cs?searchtype=author&query=Nahar%2C+S">Shreyas Nahar</a>, 
<a href="/search/cs?searchtype=author&query=Maskare%2C+S">Sudarshan Maskare</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+K">Kaushal Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Bagade%2C+D+A">Dr. Anant Bagade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, usage and applications of Autonomous Underwater Vehicles has
grown rapidly. Interaction of divers with the AUVs remains an integral part of
the usage of AUVs for various applications and makes building robust and
efficient underwater gesture recognition systems extremely important. In this
paper, we propose an Underwater Gesture Recognition system trained on the
Cognitive Autonomous Diving Buddy Underwater gesture dataset using deep
learning that achieves 98.01\% accuracy on the dataset, which to the best of
our knowledge is the best performance achieved on this dataset at the time of
writing this paper. We also improve the Gesture Recognition System
Interpretability by using XAI techniques to visualize the model's predictions.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04875" title="Abstract">arXiv:2312.04875</a> [<a href="/pdf/2312.04875" title="Download PDF">pdf</a>, <a href="/format/2312.04875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVDD: Multi-View Depth Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiangeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+M">Menglei Chai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Fanello%2C+S">Sean Fanello</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Denoising diffusion models have demonstrated outstanding results in 2D image
generation, yet it remains a challenge to replicate its success in 3D shape
generation. In this paper, we propose leveraging multi-view depth, which
represents complex 3D shapes in a 2D data format that is easy to denoise. We
pair this representation with a diffusion model, MVDD, that is capable of
generating high-quality dense point clouds with 20K+ points with fine-grained
details. To enforce 3D consistency in multi-view depth, we introduce an
epipolar line segment attention that conditions the denoising step for a view
on its neighboring views. Additionally, a depth fusion module is incorporated
into diffusion steps to further ensure the alignment of depth maps. When
augmented with surface reconstruction, MVDD can also produce high-quality 3D
meshes. Furthermore, MVDD stands out in other tasks such as depth completion,
and can serve as a 3D prior, significantly boosting many downstream tasks, such
as GAN inversion. State-of-the-art results from extensive experiments
demonstrate MVDD's excellent ability in 3D shape generation, depth completion,
and its potential as a 3D prior for downstream tasks.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04876" title="Abstract">arXiv:2312.04876</a> [<a href="/pdf/2312.04876" title="Download PDF">pdf</a>, <a href="/format/2312.04876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVE-Louvain: Fast Louvain Algorithm for Community Detection in Shared  Memory Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Community detection is the problem of identifying natural divi sions in
networks. Efficient parallel algorithms for identifying such divisions is
critical in a number of applications, where the size of datasets have reached
significant scales. This technical report presents an optimized parallel
implementation of Louvain, a high quality community detection method, for
shared memory multicore systems. On a server equipped with dual 16-core Intel
Xeon Gold 6226R processors, our Louvain, which we term as GVE-Louvain,
outperforms Vite, Grappolo, and NetworKit Louvain by 50x, 22x, and 20x
respectively - achieving a processing rate of 560M edges/s on a 3.8B edge
graph. In addition, GVE-Louvain improves perfor mance at an average rate of
1.6x for every doubling of threads
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04877" title="Abstract">arXiv:2312.04877</a> [<a href="/pdf/2312.04877" title="Download PDF">pdf</a>, <a href="/format/2312.04877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Explanations to Understand and Repair Embedding-based Entity  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xiaobin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zequn Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 40th IEEE International Conference on Data Engineering (ICDE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Entity alignment seeks identical entities in different knowledge graphs,
which is a long-standing task in the database research. Recent work leverages
deep learning to embed entities in vector space and align them via nearest
neighbor search. Although embedding-based entity alignment has gained marked
success in recent years, it lacks explanations for alignment decisions. In this
paper, we present the first framework that can generate explanations for
understanding and repairing embedding-based entity alignment results. Given an
entity alignment pair produced by an embedding model, we first compare its
neighbor entities and relations to build a matching subgraph as a local
explanation. We then construct an alignment dependency graph to understand the
pair from an abstract perspective. Finally, we repair the pair by resolving
three types of alignment conflicts based on dependency graphs. Experiments on
five datasets demonstrate the effectiveness and generalization of our framework
in explaining and repairing embedding-based entity alignment results.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04879" title="Abstract">arXiv:2312.04879</a> [<a href="/pdf/2312.04879" title="Download PDF">pdf</a>, <a href="/ps/2312.04879" title="Download PostScript">ps</a>, <a href="/format/2312.04879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HC-Ref: Hierarchical Constrained Refinement for Robust Adversarial  Training of GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+X">Xiaobing Pei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haoran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Gang Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent studies have shown that attackers can catastrophically reduce the
performance of GNNs by maliciously modifying the graph structure or node
features on the graph. Adversarial training, which has been shown to be one of
the most effective defense mechanisms against adversarial attacks in computer
vision, holds great promise for enhancing the robustness of GNNs. There is
limited research on defending against attacks by performing adversarial
training on graphs, and it is crucial to delve deeper into this approach to
optimize its effectiveness. Therefore, based on robust adversarial training on
graphs, we propose a hierarchical constraint refinement framework (HC-Ref) that
enhances the anti-perturbation capabilities of GNNs and downstream classifiers
separately, ultimately leading to improved robustness. We propose corresponding
adversarial regularization terms that are conducive to adaptively narrowing the
domain gap between the normal part and the perturbation part according to the
characteristics of different layers, promoting the smoothness of the predicted
distribution of both parts. Moreover, existing research on graph robust
adversarial training primarily concentrates on training from the standpoint of
node feature perturbations and seldom takes into account alterations in the
graph structure. This limitation makes it challenging to prevent attacks based
on topological changes in the graph. This paper generates adversarial examples
by utilizing graph structure perturbations, offering an effective approach to
defend against attack methods that are based on topological changes. Extensive
experiments on two real-world graph benchmarks show that HC-Ref successfully
resists various attacks and has better node classification performance compared
to several baseline methods.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04881" title="Abstract">arXiv:2312.04881</a> [<a href="/pdf/2312.04881" title="Download PDF">pdf</a>, <a href="/format/2312.04881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Chemistry Augmented with Text Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yujie Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhening Li</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhengkai Tu</a>, 
<a href="/search/cs?searchtype=author&query=Coley%2C+C+W">Connor W. Coley</a>, 
<a href="/search/cs?searchtype=author&query=Barzilay%2C+R">Regina Barzilay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">This paper focuses on using natural language descriptions to enhance
predictive models in the chemistry field. Conventionally, chemoinformatics
models are trained with extensive structured data manually extracted from the
literature. In this paper, we introduce TextReact, a novel method that directly
augments predictive chemistry with texts retrieved from the literature.
TextReact retrieves text descriptions relevant for a given chemical reaction,
and then aligns them with the molecular representation of the reaction. This
alignment is enhanced via an auxiliary masked LM objective incorporated in the
predictor training. We empirically validate the framework on two chemistry
tasks: reaction condition recommendation and one-step retrosynthesis. By
leveraging text retrieval, TextReact significantly outperforms state-of-the-art
chemoinformatics models trained solely on molecular data.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04882" title="Abstract">arXiv:2312.04882</a> [<a href="/pdf/2312.04882" title="Download PDF">pdf</a>, <a href="/format/2312.04882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Human- and AI-Generated Texts for English, French,  German, and Spanish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaaff%2C+K">Kristina Schaaff</a>, 
<a href="/search/cs?searchtype=author&query=Schlippe%2C+T">Tim Schlippe</a>, 
<a href="/search/cs?searchtype=author&query=Mindner%2C+L">Lorenz Mindner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper we analyze features to classify human- and AI-generated text
for English, French, German and Spanish and compare them across languages. We
investigate two scenarios: (1) The detection of text generated by AI from
scratch, and (2) the detection of text rephrased by AI. For training and
testing the classifiers in this multilingual setting, we created a new text
corpus covering 10 topics for each language. For the detection of AI-generated
text, the combination of all proposed features performs best, indicating that
our features are portable to other related languages: The F1-scores are close
with 99% for Spanish, 98% for English, 97% for German and 95% for French. For
the detection of AI-rephrased text, the systems with all features outperform
systems with other features in many cases, but using only document features
performs best for German (72%) and Spanish (86%) and only text vector features
leads to best results for English (78%).
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04883" title="Abstract">arXiv:2312.04883</a> [<a href="/pdf/2312.04883" title="Download PDF">pdf</a>, <a href="/format/2312.04883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Community Bias Amplification in Graph Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengzhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yimin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Divin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zengfeng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this work, we discover a phenomenon of community bias amplification in
graph representation learning, which refers to the exacerbation of performance
bias between different classes by graph representation learning. We conduct an
in-depth theoretical study of this phenomenon from a novel spectral
perspective. Our analysis suggests that structural bias between communities
results in varying local convergence speeds for node embeddings. This
phenomenon leads to bias amplification in the classification results of
downstream tasks. Based on the theoretical insights, we propose random graph
coarsening, which is proved to be effective in dealing with the above issue.
Finally, we propose a novel graph contrastive learning model called Random
Graph Coarsening Contrastive Learning (RGCCL), which utilizes random coarsening
as data augmentation and mitigates community bias by contrasting the coarsened
graph with the original graph. Extensive experiments on various datasets
demonstrate the advantage of our method when dealing with community bias
amplification.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04884" title="Abstract">arXiv:2312.04884</a> [<a href="/pdf/2312.04884" title="Download PDF">pdf</a>, <a href="/format/2312.04884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UDiffText: A Unified Framework for High-quality Text Synthesis in  Arbitrary Images via Character-aware Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zhouhui Lian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-Image (T2I) generation methods based on diffusion model have garnered
significant attention in the last few years. Although these image synthesis
methods produce visually appealing results, they frequently exhibit spelling
errors when rendering text within the generated images. Such errors manifest as
missing, incorrect or extraneous characters, thereby severely constraining the
performance of text image generation based on diffusion models. To address the
aforementioned issue, this paper proposes a novel approach for text image
generation, utilizing a pre-trained diffusion model (i.e., Stable Diffusion
[27]). Our approach involves the design and training of a light-weight
character-level text encoder, which replaces the original CLIP encoder and
provides more robust text embeddings as conditional guidance. Then, we
fine-tune the diffusion model using a large-scale dataset, incorporating local
attention control under the supervision of character-level segmentation maps.
Finally, by employing an inference stage refinement process, we achieve a
notably high sequence accuracy when synthesizing text in arbitrarily given
images. Both qualitative and quantitative results demonstrate the superiority
of our method to the state of the art. Furthermore, we showcase several
potential applications of the proposed UDiffText, including text-centric image
synthesis, scene text editing, etc. Code and model will be available at
https://github.com/ZYM-PKU/UDiffText .
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04885" title="Abstract">arXiv:2312.04885</a> [<a href="/pdf/2312.04885" title="Download PDF">pdf</a>, <a href="/format/2312.04885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VISAGE: Video Instance Segmentation with Appearance-Guided Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hanjung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaehyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+M">Miran Heo</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Sukjun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+W">Seoung Wug Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Seon Joo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, online Video Instance Segmentation (VIS) methods have shown
remarkable advancement with their powerful query-based detectors. Utilizing the
output queries of the detector at the frame level, these methods achieve high
accuracy on challenging benchmarks. However, we observe the heavy reliance of
these methods on the location information that leads to incorrect matching when
positional cues are insufficient for resolving ambiguities. Addressing this
issue, we present VISAGE that enhances instance association by explicitly
leveraging appearance information. Our method involves a generation of queries
that embed appearances from backbone feature maps, which in turn get used in
our suggested simple tracker for robust associations. Finally, enabling
accurate matching in complex scenarios by resolving the issue of over-reliance
on location information, we achieve competitive performance on multiple VIS
benchmarks. For instance, on YTVIS19 and YTVIS21, our method achieves 54.5 AP
and 50.8 AP. Furthermore, to highlight appearance-awareness not fully addressed
by existing benchmarks, we generate a synthetic dataset where our method
outperforms others significantly by leveraging the appearance cue. Code will be
made available at https://github.com/KimHanjung/VISAGE.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04889" title="Abstract">arXiv:2312.04889</a> [<a href="/pdf/2312.04889" title="Download PDF">pdf</a>, <a href="/format/2312.04889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KwaiAgents: Generalized Information-seeking Agent System with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Haojie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Z">Zepeng Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yaojia Lv</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Ruiji Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Driven by curiosity, humans have continually sought to explore and understand
the world around them, leading to the invention of various tools to satiate
this inquisitiveness. Despite not having the capacity to process and memorize
vast amounts of information in their brains, humans excel in critical thinking,
planning, reflection, and harnessing available tools to interact with and
interpret the world, enabling them to find answers efficiently. The recent
advancements in large language models (LLMs) suggest that machines might also
possess the aforementioned human-like capabilities, allowing them to exhibit
powerful abilities even with a constrained parameter count. In this paper, we
introduce KwaiAgents, a generalized information-seeking agent system based on
LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its
cognitive core, which is capable of understanding a user's query, behavior
guidelines, and referencing external documents. The agent can also update and
retrieve information from its internal memory, plan and execute actions using a
time-aware search-browse toolkit, and ultimately provide a comprehensive
response. We further investigate the system's performance when powered by LLMs
less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,
designed to ensure even an open-sourced 7B or 13B model performs well among
many agent systems. We exploit both benchmark and human evaluations to
systematically validate these capabilities. Extensive experiments show the
superiority of our agent system compared to other autonomous agents and
highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04891" title="Abstract">arXiv:2312.04891</a> [<a href="/pdf/2312.04891" title="Download PDF">pdf</a>, <a href="/format/2312.04891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-BERT for Point Cloud Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeyong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mingqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+L">Liangliang Nan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F+L">Fu Lee Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Introducing BERT into cross-modal settings raises difficulties in its
optimization for handling multiple modalities. Both the BERT architecture and
training objective need to be adapted to incorporate and model information from
different modalities. In this paper, we address these challenges by exploring
the implicit semantic and geometric correlations between 2D and 3D data of the
same objects/scenes. We propose a new cross-modal BERT-style self-supervised
learning paradigm, called Cross-BERT. To facilitate pretraining for irregular
and sparse point clouds, we design two self-supervised tasks to boost
cross-modal interaction. The first task, referred to as Point-Image Alignment,
aims to align features between unimodal and cross-modal representations to
capture the correspondences between the 2D and 3D modalities. The second task,
termed Masked Cross-modal Modeling, further improves mask modeling of BERT by
incorporating high-dimensional semantic information obtained by cross-modal
interaction. By performing cross-modal interaction, Cross-BERT can smoothly
reconstruct the masked tokens during pretraining, leading to notable
performance enhancements for downstream tasks. Through empirical evaluation, we
demonstrate that Cross-BERT outperforms existing state-of-the-art methods in 3D
downstream applications. Our work highlights the effectiveness of leveraging
cross-modal 2D knowledge to strengthen 3D point cloud representation and the
transferable capability of BERT across modalities.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04893" title="Abstract">arXiv:2312.04893</a> [<a href="/pdf/2312.04893" title="Download PDF">pdf</a>, <a href="/format/2312.04893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Annotation-Free Group Robustness via Loss-Based Resampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaznavi%2C+M">Mahdi Ghaznavi</a>, 
<a href="/search/cs?searchtype=author&query=Asadollahzadeh%2C+H">Hesam Asadollahzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+H+Y">HamidReza Yaghoubi Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Noohdani%2C+F+H">Fahimeh Hosseini Noohdani</a>, 
<a href="/search/cs?searchtype=author&query=Rohban%2C+M+H">Mohammad Hossein Rohban</a>, 
<a href="/search/cs?searchtype=author&query=Baghshah%2C+M+S">Mahdieh Soleymani Baghshah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a short paper in OOD-CV workshop at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It is well-known that training neural networks for image classification with
empirical risk minimization (ERM) makes them vulnerable to relying on spurious
attributes instead of causal ones for prediction. Previously, deep feature
re-weighting (DFR) has proposed retraining the last layer of a pre-trained
network on balanced data concerning spurious attributes, making it robust to
spurious correlation. However, spurious attribute annotations are not always
available. In order to provide group robustness without such annotations, we
propose a new method, called loss-based feature re-weighting (LFR), in which we
infer a grouping of the data by evaluating an ERM-pre-trained model on a small
left-out split of the training data. Then, a balanced number of samples is
chosen by selecting high-loss samples from misclassified data points and
low-loss samples from correctly-classified ones. Finally, we retrain the last
layer on the selected balanced groups to make the model robust to spurious
correlation. For a complete assessment, we evaluate LFR on various versions of
Waterbirds and CelebA datasets with different spurious correlations, which is a
novel technique for observing the model's performance in a wide range of
spuriosity rates. While LFR is extremely fast and straightforward, it
outperforms the previous methods that do not assume group label availability,
as well as the DFR with group annotations provided, in cases of high spurious
correlation in the training data.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04900" title="Abstract">arXiv:2312.04900</a> [<a href="/pdf/2312.04900" title="Download PDF">pdf</a>, <a href="/ps/2312.04900" title="Download PostScript">ps</a>, <a href="/format/2312.04900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph for Science: From API based Programming to Graph Engine based  Programming for HPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuluo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiying Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xuanhua Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xiaofei Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Modern scientific applications predominantly run on large-scale computing
platforms, necessitating collaboration between scientific domain experts and
high-performance computing (HPC) experts. While domain experts are often
skilled in customizing domain-specific scientific computing routines, which
often involves various matrix computations, HPC experts are essential for
achieving efficient execution of these computations on large-scale platforms.
This process often involves utilizing complex parallel computing libraries
tailored to specific matrix computation scenarios. However, the intricate
programming procedure and the need for deep understanding in both application
domains and HPC poses significant challenges to the widespread adoption of
scientific computing. In this research, we observe that matrix computations can
be transformed into equivalent graph representations, and that by utilizing
graph processing engines, HPC experts can be freed from the burden of
implementing efficient scientific computations. Based on this observation, we
introduce a graph engine-based scientific computing (Graph for Science)
paradigm, which provides a unified graph programming interface, enabling domain
experts to promptly implement various types of matrix computations. The
proposed paradigm leverages the underlying graph processing engine to achieve
efficient execution, eliminating the needs for HPC expertise in programming
large-scale scientific applications. Our results show that the graph
engine-based scientific computing paradigm achieves performance comparable to
the best-performing implementations based on existing parallel computing
libraries and bespoke implementations. Importantly, the paradigm greatly
simplifies the development of scientific computations on large-scale platforms,
reducing the programming difficulty for scientists and facilitating broader
adoption of scientific computing.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04902" title="Abstract">arXiv:2312.04902</a> [<a href="/pdf/2312.04902" title="Download PDF">pdf</a>, <a href="/format/2312.04902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense  with Backdoor Exclusivity Lifting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Huming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Junjie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xudong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural networks (DNNs) are susceptible to backdoor attacks, where
malicious functionality is embedded to allow attackers to trigger incorrect
classifications. Old-school backdoor attacks use strong trigger features that
can easily be learned by victim models. Despite robustness against input
variation, the robustness however increases the likelihood of unintentional
trigger activations. This leaves traces to existing defenses, which find
approximate replacements for the original triggers that can activate the
backdoor without being identical to the original trigger via, e.g., reverse
engineering and sample overlay.
<br />In this paper, we propose and investigate a new characteristic of backdoor
attacks, namely, backdoor exclusivity, which measures the ability of backdoor
triggers to remain effective in the presence of input variation. Building upon
the concept of backdoor exclusivity, we propose Backdoor Exclusivity LifTing
(BELT), a novel technique which suppresses the association between the backdoor
and fuzzy triggers to enhance backdoor exclusivity for defense evasion.
Extensive evaluation on three popular backdoor benchmarks validate, our
approach substantially enhances the stealthiness of four old-school backdoor
attacks, which, after backdoor exclusivity lifting, is able to evade six
state-of-the-art backdoor countermeasures, at almost no cost of the attack
success rate and normal utility. For example, one of the earliest backdoor
attacks BadNet, enhanced by BELT, evades most of the state-of-the-art defenses
including ABS and MOTH which would otherwise recognize the backdoored model.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04905" title="Abstract">arXiv:2312.04905</a> [<a href="/pdf/2312.04905" title="Download PDF">pdf</a>, <a href="/ps/2312.04905" title="Download PostScript">ps</a>, <a href="/format/2312.04905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Timescale Q-Learning with Function Approximation in Zero-Sum  Stochastic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zaiwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+E">Eric Mazumdar</a>, 
<a href="/search/cs?searchtype=author&query=Ozdaglar%2C+A">Asuman Ozdaglar</a>, 
<a href="/search/cs?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We consider two-player zero-sum stochastic games and propose a two-timescale
$Q$-learning algorithm with function approximation that is payoff-based,
convergent, rational, and symmetric between the two players. In two-timescale
$Q$-learning, the fast-timescale iterates are updated in spirit to the
stochastic gradient descent and the slow-timescale iterates (which we use to
compute the policies) are updated by taking a convex combination between its
previous iterate and the latest fast-timescale iterate. Introducing the slow
timescale as well as its update equation marks as our main algorithmic novelty.
In the special case of linear function approximation, we establish, to the best
of our knowledge, the first last-iterate finite-sample bound for payoff-based
independent learning dynamics of these types. The result implies a polynomial
sample complexity to find a Nash equilibrium in such stochastic games.
<br />To establish the results, we model our proposed algorithm as a two-timescale
stochastic approximation and derive the finite-sample bound through a
Lyapunov-based approach. The key novelty lies in constructing a valid Lyapunov
function to capture the evolution of the slow-timescale iterates. Specifically,
through a change of variable, we show that the update equation of the
slow-timescale iterates resembles the classical smoothed best-response
dynamics, where the regularized Nash gap serves as a valid Lyapunov function.
This insight enables us to construct a valid Lyapunov function via a
generalized variant of the Moreau envelope of the regularized Nash gap. The
construction of our Lyapunov function might be of broad independent interest in
studying the behavior of stochastic approximation algorithms.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04906" title="Abstract">arXiv:2312.04906</a> [<a href="/pdf/2312.04906" title="Download PDF">pdf</a>, <a href="/format/2312.04906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ophtha-LLaMA2: A Large Language Model for Ophthalmology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Q">Qian Ling</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianyang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jin-Yu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Junjie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fengqian Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhenxiang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">San-Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shi-Nan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Min Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yi Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, pre-trained large language models (LLMs) have achieved
tremendous success in the field of Natural Language Processing (NLP). Prior
studies have primarily focused on general and generic domains, with relatively
less research on specialized LLMs in the medical field. The specialization and
high accuracy requirements for diagnosis in the medical field, as well as the
challenges in collecting large-scale data, have constrained the application and
development of LLMs in medical scenarios. In the field of ophthalmology,
clinical diagnosis mainly relies on doctors' interpretation of reports and
making diagnostic decisions. In order to take advantage of LLMs to provide
decision support for doctors, we collected three modalities of ophthalmic
report data and fine-tuned the LLaMA2 model, successfully constructing an LLM
termed the "Ophtha-LLaMA2" specifically tailored for ophthalmic disease
diagnosis. Inference test results show that even with a smaller fine-tuning
dataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis
compared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits
satisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a
valuable tool for ophthalmologists to provide improved diagnostic support for
patients. This research provides a useful reference for the application of LLMs
in the field of ophthalmology, while showcasing the immense potential and
prospects in this domain.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04911" title="Abstract">arXiv:2312.04911</a> [<a href="/pdf/2312.04911" title="Download PDF">pdf</a>, <a href="/format/2312.04911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collinear datasets augmentation using Procrustes validation sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kucheryavskiy%2C+S">Sergey Kucheryavskiy</a>, 
<a href="/search/cs?searchtype=author&query=Zhilin%2C+S">Sergei Zhilin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we propose a new method for the augmentation of numeric and
mixed datasets. The method generates additional data points by utilizing
cross-validation resampling and latent variable modeling. It is particularly
efficient for datasets with moderate to high degrees of collinearity, as it
directly utilizes this property for generation. The method is simple, fast, and
has very few parameters, which, as shown in the paper, do not require specific
tuning. It has been tested on several real datasets; here, we report detailed
results for two cases, prediction of protein in minced meat based on near
infrared spectra (fully numeric data with high degree of collinearity) and
discrimination of patients referred for coronary angiography (mixed data, with
both numeric and categorical variables, and moderate collinearity). In both
cases, artificial neural networks were employed for developing the regression
and the discrimination models. The results show a clear improvement in the
performance of the models; thus for the prediction of meat protein, fitting the
model to the augmented data resulted in a reduction in the root mean squared
error computed for the independent test set by 1.5 to 3 times.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04913" title="Abstract">arXiv:2312.04913</a> [<a href="/pdf/2312.04913" title="Download PDF">pdf</a>, <a href="/format/2312.04913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA-Attack: Improving Adversarial Transferability of Vision-Language  Pre-training Models via Self-Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bangyan He</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaojun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+T">Tianrui Lou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Current Visual-Language Pre-training (VLP) models are vulnerable to
adversarial examples. These adversarial examples present substantial security
risks to VLP models, as they can leverage inherent weaknesses in the models,
resulting in incorrect predictions. In contrast to white-box adversarial
attacks, transfer attacks (where the adversary crafts adversarial examples on a
white-box model to fool another black-box model) are more reflective of
real-world scenarios, thus making them more meaningful for research. By
summarizing and analyzing existing research, we identified two factors that can
influence the efficacy of transfer attacks on VLP models: inter-modal
interaction and data diversity. Based on these insights, we propose a
self-augment-based transfer attack method, termed SA-Attack. Specifically,
during the generation of adversarial images and adversarial texts, we apply
different data augmentation methods to the image modality and text modality,
respectively, with the aim of improving the adversarial transferability of the
generated adversarial images and texts. Experiments conducted on the FLickr30K
and COCO datasets have validated the effectiveness of our method. Our code will
be available after this paper is accepted.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04916" title="Abstract">arXiv:2312.04916</a> [<a href="/pdf/2312.04916" title="Download PDF">pdf</a>, <a href="/format/2312.04916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language  Models with 3D Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We will continuously update the codebase and arXiv version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We present EE-LLM, a framework for large-scale training and inference of
early-exit large language models (LLMs). While recent works have shown
preliminary evidence for the efficacy of early exiting in accelerating LLM
inference, EE-LLM makes a foundational step towards scaling up early-exit LLMs
by supporting their training and inference with massive 3D parallelism. Built
upon Megatron-LM, EE-LLM implements a variety of algorithmic innovations and
performance optimizations tailored to early exiting, including a lightweight
method that facilitates backpropagation for the early-exit training objective
with pipeline parallelism, techniques of leveraging idle resources in the
original pipeline schedule for computation related to early-exit layers, and
two approaches of early-exit inference that are compatible with KV caching for
autoregressive generation. Our analytical and empirical study shows that EE-LLM
achieves great training efficiency with negligible computational overhead
compared to standard LLM training, as well as outstanding inference speedup
without compromising output quality. To facilitate further research and
adoption, we release EE-LLM at https://github.com/pan-x-c/EE-LLM.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04917" title="Abstract">arXiv:2312.04917</a> [<a href="/pdf/2312.04917" title="Download PDF">pdf</a>, <a href="/ps/2312.04917" title="Download PostScript">ps</a>, <a href="/format/2312.04917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operationalizing Assurance Cases for Data Scientists: A Showcase of  Concepts and Tooling in the Context of Test Data Quality for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%B6ckel%2C+L">Lisa J&#xf6;ckel</a>, 
<a href="/search/cs?searchtype=author&query=Kl%C3%A4s%2C+M">Michael Kl&#xe4;s</a>, 
<a href="/search/cs?searchtype=author&query=Gro%C3%9F%2C+J">Janek Gro&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Gerber%2C+P">Pascal Gerber</a>, 
<a href="/search/cs?searchtype=author&query=Scholz%2C+M">Markus Scholz</a>, 
<a href="/search/cs?searchtype=author&query=Eberle%2C+J">Jonathan Eberle</a>, 
<a href="/search/cs?searchtype=author&query=Teschner%2C+M">Marc Teschner</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+D">Daniel Seifert</a>, 
<a href="/search/cs?searchtype=author&query=Hawkins%2C+R">Richard Hawkins</a>, 
<a href="/search/cs?searchtype=author&query=Molloy%2C+J">John Molloy</a>, 
<a href="/search/cs?searchtype=author&query=Ottnad%2C+J">Jens Ottnad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at International Conference on Product-Focused Software Process Improvement (Profes 2023), <a href="https://conf.researchr.org/home/profes-2023">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Assurance Cases (ACs) are an established approach in safety engineering to
argue quality claims in a structured way. In the context of quality assurance
for Machine Learning (ML)-based software components, ACs are also being
discussed and appear promising. Tools for operationalizing ACs do exist, yet
mainly focus on supporting safety engineers on the system level. However,
assuring the quality of an ML component within the system is commonly the
responsibility of data scientists, who are usually less familiar with these
tools. To address this gap, we propose a framework to support the
operationalization of ACs for ML components based on technologies that data
scientists use on a daily basis: Python and Jupyter Notebook. Our aim is to
make the process of creating ML-related evidence in ACs more effective. Results
from the application of the framework, documented through notebooks, can be
integrated into existing AC tools. We illustrate the application of the
framework on an example excerpt concerned with the quality of the test data.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04918" title="Abstract">arXiv:2312.04918</a> [<a href="/pdf/2312.04918" title="Download PDF">pdf</a>, <a href="/format/2312.04918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pruning Convolutional Filters via Reinforcement Learning with Entropy  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Musat%2C+B">Bogdan Musat</a>, 
<a href="/search/cs?searchtype=author&query=Andonie%2C+R">Razvan Andonie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Structural pruning has become an integral part of neural network
optimization, used to achieve architectural configurations which can be
deployed and run more efficiently on embedded devices. Previous results showed
that pruning is possible with minimum performance loss by utilizing a
reinforcement learning agent which makes decisions about the sparsity level of
each neural layer by maximizing as a reward the accuracy of the network. We
introduce a novel information-theoretic reward function which minimizes the
spatial entropy of convolutional activations. This minimization ultimately acts
as a proxy for maintaining accuracy, although these two criteria are not
related in any way. Our method shows that there is another possibility to
preserve accuracy without the need to directly optimize it in the agent's
reward function. In our experiments, we were able to reduce the total number of
FLOPS of multiple popular neural network architectures by 5-10x, incurring
minimal or no performance drop and being on par with the solution found by
maximizing the accuracy.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04919" title="Abstract">arXiv:2312.04919</a> [<a href="/pdf/2312.04919" title="Download PDF">pdf</a>, <a href="/format/2312.04919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> neural concatenative singing voice conversion: rethinking  concatenation-based approach for one-shot singing voice conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sha%2C+B">Binzhu Sha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Any-to-any singing voice conversion is confronted with a significant
challenge of ``timbre leakage'' issue caused by inadequate disentanglement
between the content and the speaker timbre. To address this issue, this study
introduces a novel neural concatenative singing voice conversion (NeuCoSVC)
framework. The NeuCoSVC framework comprises a self-supervised learning (SSL)
representation extractor, a neural harmonic signal generator, and a waveform
synthesizer. Specifically, the SSL extractor condenses the audio into a
sequence of fixed-dimensional SSL features. The harmonic signal generator
produces both raw and filtered harmonic signals as the pitch information by
leveraging a linear time-varying (LTV) filter. Finally, the audio generator
reconstructs the audio waveform based on the SSL features, as well as the
harmonic signals and the loudness information. During inference, the system
performs voice conversion by substituting source SSL features with their
nearest counterparts from a matching pool, which comprises SSL representations
extracted from the target audio, while the raw harmonic signals and the
loudness are extracted from the source audio and are kept unchanged. Since the
utilized SSL features in the conversion stage are directly from the target
audio, the proposed framework has great potential to address the ``timbre
leakage'' issue caused by previous disentanglement-based approaches.
Experimental results confirm that the proposed system delivers much better
performance than the speaker embedding approach (disentanglement-based) in the
context of one-shot SVC across intra-language, cross-language, and cross-domain
evaluations.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04920" title="Abstract">arXiv:2312.04920</a> [<a href="/pdf/2312.04920" title="Download PDF">pdf</a>, <a href="/format/2312.04920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Secure Aggregation in FL: Partial Vector Freezing for  Cost Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Secure aggregation of user vectors has become a critical issue in the field
of federated learning. Many Secure Aggregation Protocols (SAP) face exorbitant
computation costs, which severely limit their applicability. We uncover that
current endeavors to reduce computation costs tend to overlook a crucial fact:
a considerable portion of SAP's computation burden stems from processing each
entry in the private vectors. Given this observation, we propose PVF, a
portable module for compressing computation costs. PVF is able to ``freeze'' a
substantial portion of the private vector through specific linear
transformations, only requiring $\frac{1}{\lambda}$ of the original vector to
participate in SAP. Eventually, users can ``thaw'' the public sum of the
``frozen entries" by the result of SAP. To enhance functionality, we introduce
extensions that can enforce consistency constraints on users' original vectors,
verify aggregated results, and enhance security when a portion of the private
vector is known to the server. We demonstrate that PVF can seamlessly integrate
with various SAP and prove that it poses no threat to user privacy in the
semi-honest and active adversary settings. We select $8$ baselines,
encompassing $6$ distinct types of SAP, and explore the acceleration effects of
PVF on these SAP. Empirical investigations indicate that when $\lambda=100$,
PVF yields up to $99.5\times$ speedup and up to $32.3\times$ communication
reduction, with the potential to approach nearly $1000\times$ acceleration as
$\lambda$ increases.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04922" title="Abstract">arXiv:2312.04922</a> [<a href="/pdf/2312.04922" title="Download PDF">pdf</a>, <a href="/format/2312.04922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cyclic Placement Strategy for Multi-access Coded Caching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wei Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We investigate the multi-access coded caching problem, which involves $N$
files, $K$ users, and $K$ caches in this paper. Each user can access $L$
adjacent caches in a cyclic manner. We present a coded placement scheme for the
case of cache $M=\frac{K-1}{KL}$, when $\frac{K-1}{L}$ is an integer. The
scheme is based on coded placement and involves cyclic placement in caches. In
many parameter settings, our scheme achieves a lower transmission rate compared
to schemes without coded placement. Additionally, the achieved transmission
rate of the proposed scheme is optimal when $L=K-1$ and $N\leq K$.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04926" title="Abstract">arXiv:2312.04926</a> [<a href="/pdf/2312.04926" title="Download PDF">pdf</a>, <a href="/format/2312.04926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Convolutional Neural Network Pruning via Spatial Aura  Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Musat%2C+B">Bogdan Musat</a>, 
<a href="/search/cs?searchtype=author&query=Andonie%2C+R">Razvan Andonie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, pruning has emerged as a popular technique to reduce the
computational complexity and memory footprint of Convolutional Neural Network
(CNN) models. Mutual Information (MI) has been widely used as a criterion for
identifying unimportant filters to prune. However, existing methods for MI
computation suffer from high computational cost and sensitivity to noise,
leading to suboptimal pruning performance. We propose a novel method to improve
MI computation for CNN pruning, using the spatial aura entropy. The spatial
aura entropy is useful for evaluating the heterogeneity in the distribution of
the neural activations over a neighborhood, providing information about local
features. Our method effectively improves the MI computation for CNN pruning,
leading to more robust and efficient pruning. Experimental results on the
CIFAR-10 benchmark dataset demonstrate the superiority of our approach in terms
of pruning performance and computational efficiency.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04927" title="Abstract">arXiv:2312.04927</a> [<a href="/pdf/2312.04927" title="Download PDF">pdf</a>, <a href="/format/2312.04927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zoology: Measuring and Improving Recall in Efficient Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Simran Arora</a>, 
<a href="/search/cs?searchtype=author&query=Eyuboglu%2C+S">Sabri Eyuboglu</a>, 
<a href="/search/cs?searchtype=author&query=Timalsina%2C+A">Aman Timalsina</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+I">Isys Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Poli%2C+M">Michael Poli</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Rudra%2C+A">Atri Rudra</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Attention-free language models that combine gating and convolutions are
growing in popularity due to their efficiency and increasingly competitive
performance. To better understand these architectures, we pretrain a suite of
17 attention and "gated-convolution" language models, finding that SoTA
gated-convolution architectures still underperform attention by up to 2.1
perplexity points on the Pile. In fine-grained analysis, we find 82% of the gap
is explained by each model's ability to recall information that is previously
mentioned in-context, e.g. "Hakuna Matata means no worries Hakuna Matata it
means no" $\rightarrow$ "??". On this task, termed "associative recall", we
find that attention outperforms gated-convolutions by a large margin: a 70M
parameter attention model outperforms a 1.4 billion parameter gated-convolution
model on associative recall. This is surprising because prior work shows gated
convolutions can perfectly solve synthetic tests for AR capability. To close
the gap between synthetics and real language, we develop a new formalization of
the task called multi-query associative recall (MQAR) that better reflects
actual language. We perform an empirical and theoretical study of MQAR that
elucidates differences in the parameter-efficiency of attention and
gated-convolution recall. Informed by our analysis, we evaluate simple
convolution-attention hybrids and show that hybrids with input-dependent sparse
attention patterns can close 97.4% of the gap to attention, while maintaining
sub-quadratic scaling. Our code is accessible at:
https://github.com/HazyResearch/zoology.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04931" title="Abstract">arXiv:2312.04931</a> [<a href="/pdf/2312.04931" title="Download PDF">pdf</a>, <a href="/format/2312.04931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-based Video Language Model for Efficient Long Video Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+C">Cuiling Lan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenxuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuejin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The remarkable natural language understanding, reasoning, and generation
capabilities of large language models (LLMs) have made them attractive for
application to video question answering (Video QA) tasks, utilizing video
tokens as contextual input. However, employing LLMs for long video
understanding presents significant challenges and remains under-explored. The
extensive number of video tokens leads to considerable computational costs for
LLMs while using aggregated tokens results in loss of vision details. Moreover,
the presence of abundant question-irrelevant tokens introduces noise to the
video QA process. To address these issues, we introduce a simple yet effective
retrieval-based video language model (R-VLM) for efficient and interpretable
long video QA. Specifically, given a question (query) and a long video, our
model identifies and selects the most relevant $K$ video chunks and uses their
associated visual tokens to serve as context for the LLM inference. This
effectively reduces the number of video tokens, eliminates noise interference,
and enhances system performance. Our experimental results validate the
effectiveness of our framework for comprehending long videos. Furthermore,
based on the retrieved chunks, our model is interpretable that provides the
justifications on where we get the answers.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04936" title="Abstract">arXiv:2312.04936</a> [<a href="/pdf/2312.04936" title="Download PDF">pdf</a>, <a href="/format/2312.04936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SKT-Hang: Hanging Everyday Objects via Object-Agnostic Semantic Keypoint  Trajectory Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuo%2C+C">Chia-Liang Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+Y">Yu-Wei Chao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We study the problem of hanging a wide range of grasped objects on diverse
supporting items. Hanging objects is a ubiquitous task that is encountered in
numerous aspects of our everyday lives. However, both the objects and
supporting items can exhibit substantial variations in their shapes and
structures, bringing two challenging issues: (1) determining the task-relevant
geometric structures across different objects and supporting items, and (2)
identifying a robust action sequence to accommodate the shape variations of
supporting items. To this end, we propose Semantic Keypoint Trajectory (SKT),
an object-agnostic representation that is highly versatile and applicable to
various everyday objects. We also propose Shape-conditioned Trajectory
Deformation Network (SCTDN), a model that learns to generate SKT by deforming a
template trajectory based on the task-relevant geometric structure features of
the supporting items. We conduct extensive experiments and demonstrate
substantial improvements in our framework over existing robot hanging methods
in the success rate and inference time. Finally, our simulation-trained
framework shows promising hanging results in the real world. For videos and
supplementary materials, please visit our project webpage:
https://hcis-lab.github.io/SKT-Hang/.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04937" title="Abstract">arXiv:2312.04937</a> [<a href="/pdf/2312.04937" title="Download PDF">pdf</a>, <a href="/format/2312.04937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AHSecAgg and TSKG: Lightweight Secure Aggregation for Federated Learning  Without Compromise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Leveraging federated learning (FL) to enable cross-domain privacy-sensitive
data mining represents a vital breakthrough to accomplish privacy-preserving
learning. However, attackers can infer the original user data by analyzing the
uploaded intermediate parameters during the aggregation process. Therefore,
secure aggregation has become a critical issue in the field of FL. Many secure
aggregation protocols face the problem of high computation costs, which
severely limits their applicability. To this end, we propose AHSecAgg, a
lightweight secure aggregation protocol using additive homomorphic masks.
AHSecAgg significantly reduces computation overhead without compromising the
dropout handling capability or model accuracy. We prove the security of
AHSecAgg in semi-honest and active adversary settings. In addition, in
cross-silo scenarios where the group of participants is relatively fixed during
each round, we propose TSKG, a lightweight Threshold Signature based masking
key generation method. TSKG can generate different temporary secrets and shares
for different aggregation rounds using the initial key and thus effectively
eliminates the cost of secret sharing and key agreement. We prove TSKG does not
sacrifice security. Extensive experiments show that AHSecAgg significantly
outperforms state-of-the-art mask-based secure aggregation protocols in terms
of computational efficiency, and TSKG effectively reduces the computation and
communication costs for existing secure aggregation protocols.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04939" title="Abstract">arXiv:2312.04939</a> [<a href="/pdf/2312.04939" title="Download PDF">pdf</a>, <a href="/format/2312.04939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent finite element methods for antiferromagnetic and  ferrimagnetic materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Normington%2C+H">Hywel Normington</a>, 
<a href="/search/math?searchtype=author&query=Ruggeri%2C+M">Michele Ruggeri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the numerical approximation of a continuum model of
antiferromagnetic and ferrimagnetic materials. The state of the material is
described in terms of two unit-length vector fields, which can be interpreted
as the magnetizations averaging the spins of two sublattices. For the static
setting, which requires the solution of a constrained energy minimization
problem, we introduce a discretization based on first-order finite elements and
prove its $\Gamma$-convergence. Then, we propose and analyze two iterative
algorithms for the computation of low-energy stationary points. The algorithms
are obtained from (semi-)implicit time discretizations of gradient flows of the
energy. Finally, we extend the algorithms to the dynamic setting, which
consists of a nonlinear system of two Landau-Lifshitz-Gilbert equations solved
by the two fields, and we prove unconditional stability and convergence of the
finite element approximations toward a weak solution of the problem. Numerical
experiments assess the performance of the algorithms and demonstrate their
applicability for the simulation of physical processes involving
antiferromagnetic and ferrimagnetic materials.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04940" title="Abstract">arXiv:2312.04940</a> [<a href="/pdf/2312.04940" title="Download PDF">pdf</a>, <a href="/format/2312.04940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Canaries and Whistles: Resilient Drone Communication Networks with (or  without) Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hicks%2C+C">Chris Hicks</a>, 
<a href="/search/cs?searchtype=author&query=Mavroudis%2C+V">Vasilios Mavroudis</a>, 
<a href="/search/cs?searchtype=author&query=Foley%2C+M">Myles Foley</a>, 
<a href="/search/cs?searchtype=author&query=Davies%2C+T">Thomas Davies</a>, 
<a href="/search/cs?searchtype=author&query=Highnam%2C+K">Kate Highnam</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+T">Tim Watson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AISec '23. This version fixes some terminology to improve readability
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 16th ACM Workshop on Artificial Intelligence
  and Security. Association for Computing Machinery, 91-101 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Communication networks able to withstand hostile environments are critically
important for disaster relief operations. In this paper, we consider a
challenging scenario where drones have been compromised in the supply chain,
during their manufacture, and harbour malicious software capable of
wide-ranging and infectious disruption. We investigate multi-agent deep
reinforcement learning as a tool for learning defensive strategies that
maximise communications bandwidth despite continual adversarial interference.
Using a public challenge for learning network resilience strategies, we propose
a state-of-the-art expert technique and study its superiority over deep
reinforcement learning agents. Correspondingly, we identify three specific
methods for improving the performance of our learning-based agents: (1)
ensuring each observation contains the necessary information, (2) using expert
agents to provide a curriculum for learning, and (3) paying close attention to
reward. We apply our methods and present a new mixed strategy enabling expert
and learning-based agents to work together and improve on all prior results.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04941" title="Abstract">arXiv:2312.04941</a> [<a href="/pdf/2312.04941" title="Download PDF">pdf</a>, <a href="/format/2312.04941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting DBMS Bugs with Context-Sensitive Instantiation and Multi-Plan  Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaoguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yajin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">DBMS bugs can cause serious consequences, posing severe security and privacy
concerns. This paper works towards the detection of memory bugs and logic bugs
in DBMSs, and aims to solve the two innate challenges, including how to
generate semantically correct SQL queries in a test case, and how to propose
effective oracles to capture logic bugs. To this end, our system proposes two
key techniques. The first key technique is called context-sensitive
instantiation, which considers all static semantic requirements (including but
not limited to the identifier type used by existing systems) to generate
semantically valid SQL queries. The second key technique is called multi-plan
execution, which can effectively capture logic bugs. Given a test case,
multi-plan execution makes the DBMS execute all query plans instead of the
default optimal one, and compares the results. A logic bug is detected if a
difference is found among the execution results of the executed query plans. We
have implemented a prototype system called Kangaroo and applied it to three
widely used and well-tested DBMSs, including SQLite, PostgreSQL, and MySQL. Our
system successfully detected 50 new bugs. The comparison between our system
with the state-of-the-art systems shows that our system outperforms them in
terms of the number of generated semantically valid SQL queries, the explored
code paths during testing, and the detected bugs.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04943" title="Abstract">arXiv:2312.04943</a> [<a href="/pdf/2312.04943" title="Download PDF">pdf</a>, <a href="/ps/2312.04943" title="Download PostScript">ps</a>, <a href="/format/2312.04943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV Path Planning for Object Observation with Quality Constraints: A  Dynamic Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+V">Vincent Chau</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weiwei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper addresses a UAV path planning task that seeks to observe a set of
objects while satisfying the observation quality constraint. A dynamic
programming algorithm is proposed that enables the UAV to observe the target
objects with shortest path while subjecting to the observation quality
constraint. The objects have their own facing direction and restricted
observation range. With an observing order, the algorithm achieves
(1+$\epsilon$)-approximation ratio in theory and runs in polynomial time. The
extensive results show that the algorithm produces near-optimal solutions, the
effectiveness of which is also tested and proved in the Airsim simulator, a
realistic virtual environment.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04944" title="Abstract">arXiv:2312.04944</a> [<a href="/pdf/2312.04944" title="Download PDF">pdf</a>, <a href="/ps/2312.04944" title="Download PostScript">ps</a>, <a href="/format/2312.04944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Illicit Darkweb Classification via Natural-language Processing:  Classifying Illicit Content of Webpages based on Textual Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cascavilla%2C+G">Giuseppe Cascavilla</a>, 
<a href="/search/cs?searchtype=author&query=Catolino%2C+G">Gemma Catolino</a>, 
<a href="/search/cs?searchtype=author&query=Sangiovanni%2C+M">Mirella Sangiovanni</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 19th International Conference on Security
  and Cryptography - Volume 1: SECRYPT, 2022, ISBN 978-989-758-590-6, pages
  620-626
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This work aims at expanding previous works done in the context of illegal
activities classification, performing three different steps. First, we created
a heterogeneous dataset of 113995 onion sites and dark marketplaces. Then, we
compared pre-trained transferable models, i.e., ULMFit (Universal Language
Model Fine-tuning), Bert (Bidirectional Encoder Representations from
Transformers), and RoBERTa (Robustly optimized BERT approach) with a
traditional text classification approach like LSTM (Long short-term memory)
neural networks. Finally, we developed two illegal activities classification
approaches, one for illicit content on the Dark Web and one for identifying the
specific types of drugs. Results show that Bert obtained the best approach,
classifying the dark web's general content and the types of Drugs with 96.08%
and 91.98% of accuracy.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04945" title="Abstract">arXiv:2312.04945</a> [<a href="/pdf/2312.04945" title="Download PDF">pdf</a>, <a href="/format/2312.04945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The ICL Consistency Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+L">Lucas Weber</a>, 
<a href="/search/cs?searchtype=author&query=Bruni%2C+E">Elia Bruni</a>, 
<a href="/search/cs?searchtype=author&query=Hupkes%2C+D">Dieuwke Hupkes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as non-archival submission to the GenBench Workshop 2023. arXiv admin note: substantial text overlap with <a href="/abs/2310.13486">arXiv:2310.13486</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Just like the previous generation of task-tuned models, large language models
(LLMs) that are adapted to tasks via prompt-based methods like
in-context-learning (ICL) perform well in some setups but not in others. This
lack of consistency in prompt-based learning hints at a lack of robust
generalisation. We here introduce the ICL consistency test -- a contribution to
the GenBench collaborative benchmark task (CBT) -- which evaluates how
consistent a model makes predictions across many different setups while using
the same data. The test is based on different established natural language
inference tasks. We provide preprocessed data constituting 96 different
'setups' and a metric that estimates model consistency across these setups. The
metric is provided on a fine-grained level to understand what properties of a
setup render predictions unstable and on an aggregated level to compare overall
model consistency. We conduct an empirical analysis of eight state-of-the-art
models, and our consistency metric reveals how all tested LLMs lack robust
generalisation.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04947" title="Abstract">arXiv:2312.04947</a> [<a href="/pdf/2312.04947" title="Download PDF">pdf</a>, <a href="/format/2312.04947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking and Analysis of Unsupervised Object Segmentation from  Real-world Single Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yafei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCV 2023. Code and data are available at: <a href="https://github.com/vLAR-group/UnsupObjSeg.">this https URL</a> This article extends from <a href="/abs/2210.02324">arXiv:2210.02324</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we study the problem of unsupervised object segmentation from
single images. We do not introduce a new algorithm, but systematically
investigate the effectiveness of existing unsupervised models on challenging
real-world images. We first introduce seven complexity factors to
quantitatively measure the distributions of background and foreground object
biases in appearance and geometry for datasets with human annotations. With the
aid of these factors, we empirically find that, not surprisingly, existing
unsupervised models fail to segment generic objects in real-world images,
although they can easily achieve excellent performance on numerous simple
synthetic datasets, due to the vast gap in objectness biases between synthetic
and real images. By conducting extensive experiments on multiple groups of
ablated real-world datasets, we ultimately find that the key factors underlying
the failure of existing unsupervised models on real-world images are the
challenging distributions of background and foreground object biases in
appearance and geometry. Because of this, the inductive biases introduced in
existing unsupervised models can hardly capture the diverse object
distributions. Our research results suggest that future work should exploit
more explicit objectness biases in the network design.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04948" title="Abstract">arXiv:2312.04948</a> [<a href="/pdf/2312.04948" title="Download PDF">pdf</a>, <a href="/format/2312.04948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scientific Preparation for CSST: Classification of Galaxy and  Nebula/Star Cluster Based on Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, Lam, 
<a href="/search/cs?searchtype=author&query=I%2C+M">Man I</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Ying Mei</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Lei Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Astrophysics of Galaxies (astro-ph.GA); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Chinese Space Station Telescope (abbreviated as CSST) is a future
advanced space telescope. Real-time identification of galaxy and nebula/star
cluster (abbreviated as NSC) images is of great value during CSST survey. While
recent research on celestial object recognition has progressed, the rapid and
efficient identification of high-resolution local celestial images remains
challenging. In this study, we conducted galaxy and NSC image classification
research using deep learning methods based on data from the Hubble Space
Telescope. We built a Local Celestial Image Dataset and designed a deep
learning model named HR-CelestialNet for classifying images of the galaxy and
NSC. HR-CelestialNet achieved an accuracy of 89.09% on the testing set,
outperforming models such as AlexNet, VGGNet and ResNet, while demonstrating
faster recognition speeds. Furthermore, we investigated the factors influencing
CSST image quality and evaluated the generalization ability of HR-CelestialNet
on the blurry image dataset, demonstrating its robustness to low image quality.
The proposed method can enable real-time identification of celestial images
during CSST survey mission.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04956" title="Abstract">arXiv:2312.04956</a> [<a href="/pdf/2312.04956" title="Download PDF">pdf</a>, <a href="/format/2312.04956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stacked ensemble learning IDS model for Software-defined VANET
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+S+I">Shakil Ibne Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=Legg%2C+P">Phil Legg</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S+M+I">S M Iftekharul Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">ntrusion Detection Systems (IDS) are widely employed to detect and mitigate
external network security events. VANETs (Vehicle ad-hoc Networks) are
evolving, especially with the development of Connected Autonomous Vehicles
(CAVs). So, it is crucial to assess how traditional IDS approaches can be
utilised for emerging technologies. To address this concern, our work presents
a stacked ensemble learning approach for IDS, which combines multiple machine
learning algorithms to detect threats more effectively than single algorithm
methods. Using the CICIDS2017 and the VeReMi benchmark data sets, we compare
the performance of our approach with existing machine learning methods and find
that it is more accurate at identifying threats. Our method also incorporates
hyperparameter optimization and feature selection to improve its performance
further. Overall, our results suggest that stacked ensemble learning is a
promising technique for enhancing the effectiveness of IDS.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04960" title="Abstract">arXiv:2312.04960</a> [<a href="/pdf/2312.04960" title="Download PDF">pdf</a>, <a href="/format/2312.04960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMIR: Masked Image Modeling for Mutual Information-based Adversarial  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoyun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shujian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingzheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+S">Stjepan Picek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision Transformers (ViTs) achieve superior performance on various tasks
compared to convolutional neural networks (CNNs), but ViTs are also vulnerable
to adversarial attacks. Adversarial training is one of the most successful
methods to build robust CNN models. Thus, recent works explored new
methodologies for adversarial training of ViTs based on the differences between
ViTs and CNNs, such as better training strategies, preventing attention from
focusing on a single block, or discarding low-attention embeddings. However,
these methods still follow the design of traditional supervised adversarial
training, limiting the potential of adversarial training on ViTs. This paper
proposes a novel defense method, MIMIR, which aims to build a different
adversarial training methodology by utilizing Masked Image Modeling at
pre-training. We create an autoencoder that accepts adversarial examples as
input but takes the clean examples as the modeling target. Then, we create a
mutual information (MI) penalty following the idea of the Information
Bottleneck. Among the two information source inputs and corresponding
adversarial perturbation, the perturbation information is eliminated due to the
constraint of the modeling target. Next, we provide a theoretical analysis of
MIMIR using the bounds of the MI penalty. We also design two adaptive attacks
when the adversary is aware of the MIMIR defense and show that MIMIR still
performs well. The experimental results show that MIMIR improves (natural and
adversarial) accuracy on average by 4.19\% on CIFAR-10 and 5.52\% on
ImageNet-1K, compared to baselines. On Tiny-ImageNet, we obtained improved
natural accuracy of 2.99\% on average and comparable adversarial accuracy. Our
code and trained models are publicly
available\footnote{\url{https://anonymous.4open.science/r/MIMIR-5444/README.md}}.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04961" title="Abstract">arXiv:2312.04961</a> [<a href="/pdf/2312.04961" title="Download PDF">pdf</a>, <a href="/format/2312.04961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepFidelity: Perceptual Forgery Fidelity Assessment for Deepfake  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huiqing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deepfake detection refers to detecting artificially generated or edited faces
in images or videos, which plays an essential role in visual information
security. Despite promising progress in recent years, Deepfake detection
remains a challenging problem due to the complexity and variability of face
forgery techniques. Existing Deepfake detection methods are often devoted to
extracting features by designing sophisticated networks but ignore the
influence of perceptual quality of faces. Considering the complexity of the
quality distribution of both real and fake faces, we propose a novel Deepfake
detection framework named DeepFidelity to adaptively distinguish real and fake
faces with varying image quality by mining the perceptual forgery fidelity of
face images. Specifically, we improve the model's ability to identify complex
samples by mapping real and fake face data of different qualities to different
scores to distinguish them in a more detailed way. In addition, we propose a
network structure called Symmetric Spatial Attention Augmentation based vision
Transformer (SSAAFormer), which uses the symmetry of face images to promote the
network to model the geographic long-distance relationship at the shallow level
and augment local features. Extensive experiments on multiple benchmark
datasets demonstrate the superiority of the proposed method over
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04962" title="Abstract">arXiv:2312.04962</a> [<a href="/pdf/2312.04962" title="Download PDF">pdf</a>, <a href="/format/2312.04962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point2CAD: Reverse Engineering CAD Models from 3D Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Obukhov%2C+A">Anton Obukhov</a>, 
<a href="/search/cs?searchtype=author&query=Wegner%2C+J+D">Jan Dirk Wegner</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer-Aided Design (CAD) model reconstruction from point clouds is an
important problem at the intersection of computer vision, graphics, and machine
learning; it saves the designer significant time when iterating on in-the-wild
objects. Recent advancements in this direction achieve relatively reliable
semantic segmentation but still struggle to produce an adequate topology of the
CAD model. In this work, we analyze the current state of the art for that
ill-posed task and identify shortcomings of existing methods. We propose a
hybrid analytic-neural reconstruction scheme that bridges the gap between
segmented point clouds and structured CAD models and can be readily combined
with different segmentation backbones. Moreover, to power the surface fitting
stage, we propose a novel implicit neural representation of freeform surfaces,
driving up the performance of our overall CAD reconstruction scheme. We
extensively evaluate our method on the popular ABC benchmark of CAD models and
set a new state-of-the-art for that dataset. Project page:
https://www.obukhov.ai/point2cad}{https://www.obukhov.ai/point2cad.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04963" title="Abstract">arXiv:2312.04963</a> [<a href="/pdf/2312.04963" title="Download PDF">pdf</a>, <a href="/format/2312.04963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D  priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lihe Ding</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shaocong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhanpeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+K">Kaixiong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most 3D generation research focuses on up-projecting 2D foundation models
into the 3D space, either by minimizing 2D Score Distillation Sampling (SDS)
loss or fine-tuning on multi-view datasets. Without explicit 3D priors, these
methods often lead to geometric anomalies and multi-view inconsistency.
Recently, researchers have attempted to improve the genuineness of 3D objects
by directly training on 3D datasets, albeit at the cost of low-quality texture
generation due to the limited texture diversity in 3D datasets. To harness the
advantages of both approaches, we propose Bidirectional Diffusion(BiDiff), a
unified framework that incorporates both a 3D and a 2D diffusion process, to
preserve both 3D fidelity and 2D texture richness, respectively. Moreover, as a
simple combination may yield inconsistent generation results, we further bridge
them with novel bidirectional guidance. In addition, our method can be used as
an initialization of optimization-based models to further improve the quality
of 3D model and efficiency of optimization, reducing the generation process
from 3.4 hours to 20 minutes. Experimental results have shown that our model
achieves high-quality, diverse, and scalable 3D generation. Project website:
https://bidiff.github.io/.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04964" title="Abstract">arXiv:2312.04964</a> [<a href="/pdf/2312.04964" title="Download PDF">pdf</a>, <a href="/format/2312.04964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZePT: Zero-Shot Pan-Tumor Segmentation via Query-Disentangling and  Self-Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yankai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The long-tailed distribution problem in medical image analysis reflects a
high prevalence of common conditions and a low prevalence of rare ones, which
poses a significant challenge in developing a unified model capable of
identifying rare or novel tumor categories not encountered during training. In
this paper, we propose a new zero-shot pan-tumor segmentation framework (ZePT)
based on query-disentangling and self-prompting to segment unseen tumor
categories beyond the training set. ZePT disentangles the object queries into
two subsets and trains them in two stages. Initially, it learns a set of
fundamental queries for organ segmentation through an object-aware feature
grouping strategy, which gathers organ-level visual features. Subsequently, it
refines the other set of advanced queries that focus on the auto-generated
visual prompts for unseen tumor segmentation. Moreover, we introduce
query-knowledge alignment at the feature level to enhance each query's
discriminative representation and generalizability. Extensive experiments on
various tumor segmentation tasks demonstrate the performance superiority of
ZePT, which surpasses the previous counterparts and evidence the promising
ability for zero-shot tumor segmentation in real-world settings. Codes will be
made publicly available.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04965" title="Abstract">arXiv:2312.04965</a> [<a href="/pdf/2312.04965" title="Download PDF">pdf</a>, <a href="/format/2312.04965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inversion-Free Image Editing with Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sihan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yidong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiayi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziqiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Joyce Chai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://sled-group.github.io/InfEdit/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Despite recent advances in inversion-based editing, text-guided image
manipulation remains challenging for diffusion models. The primary bottlenecks
include 1) the time-consuming nature of the inversion process; 2) the struggle
to balance consistency with accuracy; 3) the lack of compatibility with
efficient consistency sampling methods used in consistency models. To address
the above issues, we start by asking ourselves if the inversion process can be
eliminated for editing. We show that when the initial sample is known, a
special variance schedule reduces the denoising step to the same form as the
multi-step consistency sampling. We name this Denoising Diffusion Consistent
Model (DDCM), and note that it implies a virtual inversion strategy without
explicit inversion in sampling. We further unify the attention control
mechanisms in a tuning-free framework for text-guided editing. Combining them,
we present inversion-free editing (InfEdit), which allows for consistent and
faithful editing for both rigid and non-rigid semantic changes, catering to
intricate modifications without compromising on the image's integrity and
explicit inversion. Through extensive experiments, InfEdit shows strong
performance in various editing tasks and also maintains a seamless workflow
(less than 3 seconds on one single A40), demonstrating the potential for
real-time applications. Project Page: https://sled-group.github.io/InfEdit/
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04966" title="Abstract">arXiv:2312.04966</a> [<a href="/pdf/2312.04966" title="Download PDF">pdf</a>, <a href="/format/2312.04966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customizing Motion in Text-to-Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Materzynska%2C+J">Joanna Materzynska</a>, 
<a href="/search/cs?searchtype=author&query=Sivic%2C+J">Josef Sivic</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+B">Bryan Russell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: this website <a href="https://joaanna.github.io/customizing_motion/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce an approach for augmenting text-to-video generation models with
customized motions, extending their capabilities beyond the motions depicted in
the original training data. By leveraging a few video samples demonstrating
specific movements as input, our method learns and generalizes the input motion
patterns for diverse, text-specified scenarios. Our contributions are
threefold. First, to achieve our results, we finetune an existing text-to-video
model to learn a novel mapping between the depicted motion in the input
examples to a new unique token. To avoid overfitting to the new custom motion,
we introduce an approach for regularization over videos. Second, by leveraging
the motion priors in a pretrained model, our method can produce novel videos
featuring multiple people doing the custom motion, and can invoke the motion in
combination with other motions. Furthermore, our approach extends to the
multimodal customization of motion and appearance of individualized subjects,
enabling the generation of videos featuring unique characters and distinct
motions. Third, to validate our method, we introduce an approach for
quantitatively evaluating the learned custom motion and perform a systematic
ablation study. We show that our method significantly outperforms prior
appearance-based customization approaches when extended to the motion
customization task.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04967" title="Abstract">arXiv:2312.04967</a> [<a href="/pdf/2312.04967" title="Download PDF">pdf</a>, <a href="/format/2312.04967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control of a pendulum system: From simulation to reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+I+V">Iyer Venkataraman Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Campolo%2C+D">Domenico Campolo</a>, 
<a href="/search/cs?searchtype=author&query=Turlapati%2C+S+H">Sri Harsha Turlapati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Control theory deals with the study of controlling dynamical systems. Robots
today are growing increasingly complex and moving out of factory floors to real
world environment. These robots have to interact with real world environment
factors such as disturbances and this requires the robot to have a control
system that is robust. Testing control algorithms on robots in real world
environment can pose critical safety issues and can be financially expensive.
This has resulted in a heavy emphasis on using simulation to test control
algorithms before deploying them in real world environments. Designing control
algorithms is an iterative process that starts with modelling the target system
in simulation, designing a controller, testing the controller in simulation and
then changing the controller parameters to design a better controller. This
report explores how an approximated system model of a target hardware system
can be developed, which can then be used to design a LQR controller for the
target system. The controller is then tested under a disturbance, on hardware
and in simulation, and the system response is recorded. The system response
from hardware and simulation are then compared to validate the use of
approximated system models in simulation for designing and testing control
algorithms.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04969" title="Abstract">arXiv:2312.04969</a> [<a href="/pdf/2312.04969" title="Download PDF">pdf</a>, <a href="/format/2312.04969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D Sinc Interpolation-Based Fractional Delay and Doppler Estimation  Using Time and Frequency Shifted Gaussian Pulses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jitsumatsu%2C+Y">Yutaka Jitsumatsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, submitted to 4th IEEE Symposium on Joint Communication and Sensing (JC&amp;S) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">An accurate delay and Doppler estimation method for a radar system using time
and frequency-shifted pulses with pseudo-random numbers is proposed. The
ambiguity function of the transmitted signal has a strong peak at the origin
and is close to zero if delay and Doppler are more than the inverses of the
bandwidth and time-width. A two-dimensional (2D) sinc function gives a good
approximation of the ambiguity function around the origin, by which fractional
delay and Doppler are accurately estimated.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04970" title="Abstract">arXiv:2312.04970</a> [<a href="/pdf/2312.04970" title="Download PDF">pdf</a>, <a href="/format/2312.04970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Datasets, Models, and Algorithms for Multi-Sensor, Multi-agent Autonomy  Using AVstack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hallyburton%2C+R+S">R. Spencer Hallyburton</a>, 
<a href="/search/cs?searchtype=author&query=Pajic%2C+M">Miroslav Pajic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recent advancements in assured autonomy have brought autonomous vehicles
(AVs) closer to fruition. Despite strong evidence that multi-sensor,
multi-agent (MSMA) systems can yield substantial improvements in the safety and
security of AVs, there exists no unified framework for developing and testing
representative MSMA configurations. Using the recently-released autonomy
platform, AVstack, this work proposes a new framework for datasets, models, and
algorithms in MSMA autonomy. Instead of releasing a single dataset, we deploy a
dataset generation pipeline capable of generating unlimited volumes of
ground-truth-labeled MSMA perception data. The data derive from cameras
(semantic segmentation, RGB, depth), LiDAR, and radar, and are sourced from
ground-vehicles and, for the first time, infrastructure platforms. Pipelining
generating labeled MSMA data along with AVstack's third-party integrations
defines a model training framework that allows training multi-sensor perception
for vehicle and infrastructure applications. We provide the framework and
pretrained models open-source. Finally, the dataset and model training
pipelines culminate in insightful multi-agent case studies. While previous
works used specific ego-centric multi-agent designs, our framework considers
the collaborative autonomy space as a network of noisy, time-correlated
sensors. Within this environment, we quantify the impact of the network
topology and data fusion pipeline on an agent's situational awareness.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04973" title="Abstract">arXiv:2312.04973</a> [<a href="/pdf/2312.04973" title="Download PDF">pdf</a>, <a href="/format/2312.04973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ex-post Individually Rational Bayesian Persuasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuran Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Leme%2C+R+P">Renato Paes Leme</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The success of Bayesian persuasion relies on the key assumption that the
sender will commit to a predetermined information disclosure policy (signaling
scheme). However, in practice, it is usually difficult for the receiver to
monitor whether the sender sticks to the disclosure policy, which makes the
credibility of the sender's disclosure policy questionable. The sender's
credibility is particularly tenuous when there are obvious deviations that
benefit the sender. In this work, we identify such a deviation: the sender may
be unwilling to send a signal that will lead to a less desirable outcome
compared to no information disclosure. We thus propose the notion of ex-post
individually rational (ex-post IR) Bayesian persuasion: after observing the
state, the sender is never required to send a signal that will make the outcome
worse off (compared to no information disclosure). An ex-post IR Bayesian
persuasion policy is more likely to be truthfully followed by the sender, and
thus more credible for the receiver. Our contribution is threefold. Firstly, we
demonstrate that the optimal ex-post IR Bayesian persuasion policy can be
efficiently computed through a linear program, while also offering geometric
characterizations of this optimal policy. Second, we show that surprisingly,
for non-trivial classes of games, the imposition of ex-post IR constraints does
not affect the sender's expected utility. Finally, we compare ex-post IR
Bayesian persuasion to other information disclosure models that ensure
different notions of credibility.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04974" title="Abstract">arXiv:2312.04974</a> [<a href="/pdf/2312.04974" title="Download PDF">pdf</a>, <a href="/format/2312.04974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shifting Climates: Climate Change Communication from YouTube to TikTok
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pera%2C+A">Arianna Pera</a>, 
<a href="/search/cs?searchtype=author&query=Aiello%2C+L+M">Luca Maria Aiello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Public discourse on critical issues such as climate change is progressively
shifting to social media platforms that prioritize short-form video content. To
improve our understanding of this transition, we studied the video content
produced by 21 prominent YouTube creators who have expanded their influence to
TikTok as information disseminators. Using dictionary-based tools and
BERT-based embeddings, we analyzed the transcripts of nearly 7k climate-related
videos across both platforms and the 574k comments they received. We found
that, when using TikTok, creators use a more emotionally resonant,
self-referential, and action-oriented language compared to YouTube. We also
observed a strong semantic alignment between videos and comments, with creators
who excel at diversifying their TikTok content from YouTube typically receiving
responses that more closely align with their produced content. This suggests
that tailored communication strategies hold greater promise in directing public
discussion towards desired topics, which bears implications for the design of
effective climate communication campaigns.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04982" title="Abstract">arXiv:2312.04982</a> [<a href="/pdf/2312.04982" title="Download PDF">pdf</a>, <a href="/format/2312.04982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Prompt-Based Self-Training With Mapping-Free Automatic  Verbalizer for Multi-Class Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kho%2C+Y">Yookyung Kho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+P">Pilsung Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, prompt-based fine-tuning has garnered considerable interest as a
core technique for few-shot text classification task. This approach
reformulates the fine-tuning objective to align with the Masked Language
Modeling (MLM) objective. Leveraging unlabeled data, prompt-based self-training
has shown greater effectiveness in binary and three-class classification.
However, prompt-based self-training for multi-class classification has not been
adequately investigated, despite its significant applicability to real-world
scenarios. Moreover, extending current methods to multi-class classification
suffers from the verbalizer that extracts the predicted value of manually
pre-defined single label word for each class from MLM predictions.
Consequently, we introduce a novel, efficient verbalizer structure, named
Mapping-free Automatic Verbalizer (MAV). Comprising two fully connected layers,
MAV serves as a trainable verbalizer that automatically extracts the requisite
word features for classification by capitalizing on all available information
from MLM predictions. Experimental results on five multi-class classification
datasets indicate MAV's superior self-training efficacy.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04985" title="Abstract">arXiv:2312.04985</a> [<a href="/pdf/2312.04985" title="Download PDF">pdf</a>, <a href="/format/2312.04985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparQ Attention: Bandwidth-Efficient LLM Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ribar%2C+L">Luka Ribar</a>, 
<a href="/search/cs?searchtype=author&query=Chelombiev%2C+I">Ivan Chelombiev</a>, 
<a href="/search/cs?searchtype=author&query=Hudlass-Galley%2C+L">Luke Hudlass-Galley</a>, 
<a href="/search/cs?searchtype=author&query=Blake%2C+C">Charlie Blake</a>, 
<a href="/search/cs?searchtype=author&query=Luschi%2C+C">Carlo Luschi</a>, 
<a href="/search/cs?searchtype=author&query=Orr%2C+D">Douglas Orr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Generative large language models (LLMs) have opened up numerous novel
possibilities, but due to their significant computational requirements their
ubiquitous use remains challenging. Some of the most useful applications
require processing large numbers of samples at a time and using long contexts,
both significantly increasing the memory communication load of the models. We
introduce SparQ Attention, a technique for increasing the inference throughput
of LLMs by reducing the memory bandwidth requirements within the attention
blocks through selective fetching of the cached history. Our proposed technique
can be applied directly to off-the-shelf LLMs during inference, without
requiring any modification to the pre-training setup or additional fine-tuning.
We show how SparQ Attention can decrease the attention memory bandwidth
requirements up to eight times without any loss in accuracy by evaluating Llama
2 and Pythia models on a wide range of downstream tasks.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04986" title="Abstract">arXiv:2312.04986</a> [<a href="/pdf/2312.04986" title="Download PDF">pdf</a>, <a href="/format/2312.04986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of Context: How important is Local Context in Neural Program Repair?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prenner%2C+J+A">Julian Aron Prenner</a>, 
<a href="/search/cs?searchtype=author&query=Robbes%2C+R">Romain Robbes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning source code models have been applied very successfully to the
problem of automated program repair. One of the standing issues is the small
input window of current models which often cannot fully fit the context code
required for a bug fix (e.g., method or class declarations of a project).
Instead, input is often restricted to the local context, that is, the lines
below and above the bug location. In this work we study the importance of this
local context on repair success: how much local context is needed?; is context
before or after the bug location more important? how is local context tied to
the bug type? To answer these questions we train and evaluate Transformer
models in many different local context configurations on three datasets and two
programming languages. Our results indicate that overall repair success
increases with the size of the local context (albeit not for all bug types) and
confirm the common practice that roughly 50-60% of the input window should be
used for context leading the bug. Our results are not only relevant for
researchers working on Transformer-based APR tools but also for benchmark and
dataset creators who must decide what and how much context to include in their
datasets.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04991" title="Abstract">arXiv:2312.04991</a> [<a href="/pdf/2312.04991" title="Download PDF">pdf</a>, <a href="/ps/2312.04991" title="Download PostScript">ps</a>, <a href="/format/2312.04991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to Transshipments Over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skutella%2C+M">Martin Skutella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Surveys in Combinatorics 2024, edited by Felix Fischer and Robert Johnson, Cambridge University Press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Network flows over time are a fascinating generalization of classical
(static) network flows, introducing an element of time. They naturally model
problems where travel and transmission are not instantaneous and flow may vary
over time. Not surprisingly, flow over time problems turn out to be more
challenging to solve than their static counterparts. In this survey, we mainly
focus on the efficient computation of transshipments over time in networks with
several source and sink nodes with given supplies and demands, which is
arguably the most difficult flow over time problem that can still be solved in
polynomial time.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04992" title="Abstract">arXiv:2312.04992</a> [<a href="/pdf/2312.04992" title="Download PDF">pdf</a>, <a href="/ps/2312.04992" title="Download PostScript">ps</a>, <a href="/format/2312.04992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PFLlib: Personalized Federated Learning Algorithm Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tao Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhengui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jian Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Amid the ongoing advancements in Federated Learning (FL), a machine learning
paradigm that allows collaborative learning with data privacy protection,
personalized FL (pFL) has gained significant prominence as a research direction
within the FL domain. Whereas traditional FL (tFL) focuses on jointly learning
a global model, pFL aims to achieve a balance between the global and
personalized objectives of each client in FL settings. To foster the pFL
research community, we propose PFLlib, a comprehensive pFL algorithm library
with an integrated evaluation platform. In PFLlib, We implement 34
state-of-the-art FL algorithms (including 7 classic tFL algorithms and 27 pFL
algorithms) and provide various evaluation environments with three
statistically heterogeneous scenarios and 14 datasets. At present, PFLlib has
already gained 850 stars and 199 forks on GitHub.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04997" title="Abstract">arXiv:2312.04997</a> [<a href="/pdf/2312.04997" title="Download PDF">pdf</a>, <a href="/format/2312.04997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Transduction: A Survey on Inductive, Few Shot, and Zero Shot Link  Prediction in Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubert%2C+N">Nicolas Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Paulheim%2C+H">Heiko Paulheim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge graphs (KGs) comprise entities interconnected by relations of
different semantic meanings. KGs are being used in a wide range of
applications. However, they inherently suffer from incompleteness, i.e.
entities or facts about entities are missing. Consequently, a larger body of
works focuses on the completion of missing information in KGs, which is
commonly referred to as link prediction (LP). This task has traditionally and
extensively been studied in the transductive setting, where all entities and
relations in the testing set are observed during training. Recently, several
works have tackled the LP task under more challenging settings, where entities
and relations in the test set may be unobserved during training, or appear in
only a few facts. These works are known as inductive, few-shot, and zero-shot
link prediction. In this work, we conduct a systematic review of existing works
in this area. A thorough analysis leads us to point out the undesirable
existence of diverging terminologies and task definitions for the
aforementioned settings, which further limits the possibility of comparison
between recent works. We consequently aim at dissecting each setting
thoroughly, attempting to reveal its intrinsic characteristics. A unifying
nomenclature is ultimately proposed to refer to each of them in a simple and
consistent manner.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05003" title="Abstract">arXiv:2312.05003</a> [<a href="/pdf/2312.05003" title="Download PDF">pdf</a>, <a href="/format/2312.05003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Regret of Online Coded Caching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Anupam Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sheel Shah</a>, 
<a href="/search/cs?searchtype=author&query=Karamchandani%2C+N">Nikhil Karamchandani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider the widely studied problem of coded caching under non-uniform
requests where users independently request files according to some underlying
popularity distribution in each slot. This work is a first step towards
analyzing this framework through the lens of online learning. We consider the
case where the underlying request distribution is apriori unknown and propose
an online policy as well as study its regret with respect to an oracle which
knows the underlying distribution and employs a well-known order-optimal
placement and coded delivery strategy. We also bound the switching cost of this
strategy and also discuss a lower bound on the regret of any online scheme in a
restricted but natural class of policies.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05006" title="Abstract">arXiv:2312.05006</a> [<a href="/pdf/2312.05006" title="Download PDF">pdf</a>, <a href="/format/2312.05006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Degradation and Content Processing for Adverse Weather Image  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xueyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng-Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adverse weather image restoration strives to recover clear images from those
affected by various weather types, such as rain, haze, and snow. Each weather
type calls for a tailored degradation removal approach due to its unique impact
on images. Conversely, content reconstruction can employ a uniform approach, as
the underlying image content remains consistent. Although previous techniques
can handle multiple weather types within a single network, they neglect the
crucial distinction between these two processes, limiting the quality of
restored images. This work introduces a novel adverse weather image restoration
method, called DDCNet, which decouples the degradation removal and content
reconstruction process at the feature level based on their channel statistics.
Specifically, we exploit the unique advantages of the Fourier transform in both
these two processes: (1) the degradation information is mainly located in the
amplitude component of the Fourier domain, and (2) the Fourier domain contains
global information. The former facilitates channel-dependent degradation
removal operation, allowing the network to tailor responses to various adverse
weather types; the latter, by integrating Fourier's global properties into
channel-independent content features, enhances network capacity for consistent
global content reconstruction. We further augment the degradation removal
process with a degradation mapping loss function. Extensive experiments
demonstrate our method achieves state-of-the-art performance in multiple
adverse weather removal benchmarks.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05010" title="Abstract">arXiv:2312.05010</a> [<a href="/pdf/2312.05010" title="Download PDF">pdf</a>, <a href="/format/2312.05010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Thickness of Multigraphs is $\exists \mathbb{R}$-complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+H">Henry F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Miltzow%2C+T">Tillmann Miltzow</a>, 
<a href="/search/cs?searchtype=author&query=Parada%2C+I">Irene Parada</a>, 
<a href="/search/cs?searchtype=author&query=Terziadis%2C+S">Soeren Terziadis</a>, 
<a href="/search/cs?searchtype=author&query=Vogtenhuber%2C+B">Birgit Vogtenhuber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We say that a (multi)graph $G = (V,E)$ has geometric thickness $t$ if there
exists a straight-line drawing $\varphi : V \rightarrow \mathbb{R}^2$ and a
$t$-coloring of its edges where no two edges sharing a point in their relative
interior have the same color. The Geometric Thickness problem asks whether a
given multigraph has geometric thickness at most $t$. This problem was shown to
be NP-hard for $t=2$ [Durocher, Gethner, and Mondal, CG 2016]. In this paper,
we settle the computational complexity of Geometric Thickness by showing that
it is $\exists \mathbb{R}$-complete already for thickness $57$. Moreover, our
reduction shows that the problem is $\exists \mathbb{R}$-complete for
$8280$-planar graphs, where a graph is $k$-planar if it admits a topological
drawing with at most $k$ crossings per edge. In the course of our paper, we
answer previous questions on the geometric thickness and on other related
problems, in particular, that simultaneous graph embeddings of $58$
edge-disjoint graphs and pseudo-segment stretchability with chromatic number
$57$ are $\exists \mathbb{R}$-complete.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05011" title="Abstract">arXiv:2312.05011</a> [<a href="/pdf/2312.05011" title="Download PDF">pdf</a>, <a href="/format/2312.05011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time- and Behavior-Preserving Execution of Determinate Supervisory  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohamadkhani%2C+A">Alireza Mohamadkhani</a>, 
<a href="/search/eess?searchtype=author&query=Geilen%2C+M">Marc Geilen</a>, 
<a href="/search/eess?searchtype=author&query=Voeten%2C+J">Jeroen Voeten</a>, 
<a href="/search/eess?searchtype=author&query=Basten%2C+T">Twan Basten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The activity framework is a promising model-based design approach for
Flexible Manufacturing Systems (FMS). It is used in industry for specification
and analysis of FMS. It provides an intuitive specification language with a
hierarchical view of the system's actions and events, activities built from
them, and an automaton that captures the overall behavior of the system in
terms of sequences of activities corresponding to its accepted words. It also
provides a scalable timing analysis method using max-plus linear systems
theory. The framework currently requires manual implementation of the
supervisory controller that governs the system behavior. This is
labor-intensive and error-prone. In this article, we turn the framework into a
model-driven approach by introducing an execution architecture and execution
engine that allow a specification to be executed in a time- and
behavior-preserving fashion. We prove that the architecture and engine preserve
the specified ordering of actions and events in the specification as well as
the timing thereof up to a specified bound. We validate our approach on a
prototype production system.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05017" title="Abstract">arXiv:2312.05017</a> [<a href="/pdf/2312.05017" title="Download PDF">pdf</a>, <a href="/format/2312.05017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Filtering Of Accidental Clicks in Verizon Media Native  Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+Y">Yohay Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Krasne%2C+N">Naama Krasne</a>, 
<a href="/search/cs?searchtype=author&query=Shtoff%2C+A">Alex Shtoff</a>, 
<a href="/search/cs?searchtype=author&query=Somekh%2C+O">Oren Somekh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc. CIKM'2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Verizon Media (VZM) native advertising is one of VZM largest and fastest
growing businesses, reaching a run-rate of several hundred million USDs in the
past year. Driving the VZM native models that are used to predict event
probabilities, such as click and conversion probabilities, is OFFSET - a
feature enhanced collaborative-filtering based event-prediction algorithm. In
this work we focus on the challenge of predicting click-through rates (CTR)
when we are aware that some of the clicks have short dwell-time and are defined
as accidental clicks. An accidental click implies little affinity between the
user and the ad, so predicting that similar users will click on the ad is
inaccurate. Therefore, it may be beneficial to remove clicks with dwell-time
lower than a predefined threshold from the training set. However, we cannot
ignore these positive events, as filtering these will cause the model to under
predict. Previous approaches have tried to apply filtering and then adding
corrective biases to the CTR predictions, but did not yield revenue lifts and
therefore were not adopted. In this work, we present a new approach where the
positive weight of the accidental clicks is distributed among all of the
negative events (skips), based on their likelihood of causing accidental
clicks, as predicted by an auxiliary model. These likelihoods are taken as the
correct labels of the negative events, shifting our training from using only
binary labels and adopting a binary cross-entropy loss function in our training
process. After showing offline performance improvements, the modified model was
tested online serving VZM native users, and provided 1.18% revenue lift over
the production model which is agnostic to accidental clicks.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05019" title="Abstract">arXiv:2312.05019</a> [<a href="/pdf/2312.05019" title="Download PDF">pdf</a>, <a href="/format/2312.05019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-based Learning for Drones: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiaping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rangya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feroskhan%2C+M">Mir Feroskhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Drones as advanced cyber-physical systems are undergoing a transformative
shift with the advent of vision-based learning, a field that is rapidly gaining
prominence due to its profound impact on drone autonomy and functionality.
Different from existing task-specific surveys, this review offers a
comprehensive overview of vision-based learning in drones, emphasizing its
pivotal role in enhancing their operational capabilities. We start by
elucidating the fundamental principles of vision-based learning, highlighting
how it significantly improves drones' visual perception and decision-making
processes. We then categorize vision-based control methods into indirect,
semi-direct, and end-to-end approaches from the perception-control perspective.
We further explore various applications of vision-based drones with learning
capabilities, ranging from single-agent systems to more complex multi-agent and
heterogeneous system scenarios, and underscore the challenges and innovations
characterizing each area. Finally, we explore open questions and potential
solutions, paving the way for ongoing research and development in this dynamic
and rapidly evolving field. With growing large language models (LLMs) and
embodied intelligence, vision-based learning for drones provides a promising
but challenging road towards artificial general intelligence (AGI) in 3D
physical world.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05021" title="Abstract">arXiv:2312.05021</a> [<a href="/pdf/2312.05021" title="Download PDF">pdf</a>, <a href="/format/2312.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Negative Result on Gradient Matching for Selective Backprop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balles%2C+L">Lukas Balles</a>, 
<a href="/search/cs?searchtype=author&query=Archambeau%2C+C">Cedric Archambeau</a>, 
<a href="/search/cs?searchtype=author&query=Zappella%2C+G">Giovanni Zappella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at the ICBINB Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">With increasing scale in model and dataset size, the training of deep neural
networks becomes a massive computational burden. One approach to speed up the
training process is Selective Backprop. For this approach, we perform a forward
pass to obtain a loss value for each data point in a minibatch. The backward
pass is then restricted to a subset of that minibatch, prioritizing high-loss
examples. We build on this approach, but seek to improve the subset selection
mechanism by choosing the (weighted) subset which best matches the mean
gradient over the entire minibatch. We use the gradients w.r.t. the model's
last layer as a cheap proxy, resulting in virtually no overhead in addition to
the forward pass. At the same time, for our experiments we add a simple random
selection baseline which has been absent from prior work. Surprisingly, we find
that both the loss-based as well as the gradient-matching strategy fail to
consistently outperform the random baseline.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05023" title="Abstract">arXiv:2312.05023</a> [<a href="/pdf/2312.05023" title="Download PDF">pdf</a>, <a href="/format/2312.05023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning-Based Bionic Reflex Control for Anthropomorphic  Robotic Grasping exploiting Domain Randomization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basumatary%2C+H">Hirakjyoti Basumatary</a>, 
<a href="/search/cs?searchtype=author&query=Adhar%2C+D">Daksh Adhar</a>, 
<a href="/search/cs?searchtype=author&query=Shrawge%2C+A">Atharva Shrawge</a>, 
<a href="/search/cs?searchtype=author&query=Kanbaskar%2C+P">Prathamesh Kanbaskar</a>, 
<a href="/search/cs?searchtype=author&query=Hazarika%2C+S+M">Shyamanta M. Hazarika</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Achieving human-level dexterity in robotic grasping remains a challenging
endeavor. Robotic hands frequently encounter slippage and deformation during
object manipulation, issues rarely encountered by humans due to their sensory
receptors, experiential learning, and motor memory. The emulation of the human
grasping reflex within robotic hands is referred to as the ``bionic reflex".
Past endeavors in the realm of bionic reflex control predominantly relied on
model-based and supervised learning approaches, necessitating human
intervention during thresholding and labeling tasks. In this study, we
introduce an innovative bionic reflex control pipeline, leveraging
reinforcement learning (RL); thereby eliminating the need for human
intervention during control design. Our proposed bionic reflex controller has
been designed and tested on an anthropomorphic hand, manipulating deformable
objects in the PyBullet physics simulator, incorporating domain randomization
(DR) for enhanced Sim2Real transferability. Our findings underscore the promise
of RL as a potent tool for advancing bionic reflex control within
anthropomorphic robotic hands. We anticipate that this autonomous, RL-based
bionic reflex controller will catalyze the development of dependable and highly
efficient robotic and prosthetic hands, revolutionizing human-robot interaction
and assistive technologies.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05024" title="Abstract">arXiv:2312.05024</a> [<a href="/pdf/2312.05024" title="Download PDF">pdf</a>, <a href="/format/2312.05024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Unsupervised Domain Adaptation based on Instance  Weighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinjing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Feiyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Q">Qiao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the progress made in domain adaptation, solving Unsupervised Domain
Adaptation (UDA) problems with a general method under complex conditions caused
by label shifts between domains remains a formidable task. In this work, we
comprehensively investigate four distinct UDA settings including closed set
domain adaptation, partial domain adaptation, open set domain adaptation, and
universal domain adaptation, where shared common classes between source and
target domains coexist alongside domain-specific private classes. The prominent
challenges inherent in diverse UDA settings center around the discrimination of
common/private classes and the precise measurement of domain discrepancy. To
surmount these challenges effectively, we propose a novel yet effective method
called Learning Instance Weighting for Unsupervised Domain Adaptation (LIWUDA),
which caters to various UDA settings. Specifically, the proposed LIWUDA method
constructs a weight network to assign weights to each instance based on its
probability of belonging to common classes, and designs Weighted Optimal
Transport (WOT) for domain alignment by leveraging instance weights.
Additionally, the proposed LIWUDA method devises a Separate and Align (SA) loss
to separate instances with low similarities and align instances with high
similarities. To guide the learning of the weight network, Intra-domain Optimal
Transport (IOT) is proposed to enforce the weights of instances in common
classes to follow a uniform distribution. Through the integration of those
three components, the proposed LIWUDA method demonstrates its capability to
address all four UDA settings in a unified manner. Experimental evaluations
conducted on three benchmark datasets substantiate the effectiveness of the
proposed LIWUDA method.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05025" title="Abstract">arXiv:2312.05025</a> [<a href="/pdf/2312.05025" title="Download PDF">pdf</a>, <a href="/format/2312.05025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Eavesdropper Mitigation via Orthogonal Channel Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marti%2C+G">Gian Marti</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 International Zurich Seminar on Information and Communication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Beamforming is a powerful tool for physical layer security, as it can be used
for steering signals towards legitimate receivers and away from eavesdroppers.
An active eavesdropper, however, can interfere with the pilot phase that the
transmitter needs to acquire the channel knowledge necessary for beamforming.
By doing so, the eavesdropper can make the transmitter form beams towards the
eavesdropper rather than towards the legitimate receiver. To mitigate active
eavesdroppers, we propose VILLAIN, a novel channel estimator that uses secret
pilots. When an eavesdropper interferes with the pilot phase, VILLAIN produces
a channel estimate that is orthogonal to the eavesdropper's channel (in the
noiseless case). We prove that beamforming based on this channel estimate
delivers the highest possible signal power to the legitimate receiver without
delivering any signal power to the eavesdropper. Simulations show that VILLAIN
mitigates active eavesdroppers also in the noisy case.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05026" title="Abstract">arXiv:2312.05026</a> [<a href="/pdf/2312.05026" title="Download PDF">pdf</a>, <a href="/format/2312.05026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating the Faults/Attacks using a Fast Adaptive Unknown Input  Observer: An Enhanced LMI Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohite%2C+S">Shivaraj Mohite</a>, 
<a href="/search/eess?searchtype=author&query=Sheikh%2C+A">Adil Sheikh</a>, 
<a href="/search/eess?searchtype=author&query=Wagh%2C+S+R">S. R. Wagh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper deals with the problem of robust fault estimation for the
Lipschitz nonlinear systems under the influence of sensor faults and actuator
faults. In the proposed methodology, a descriptor system is formulated by
augmenting sensor fault vectors with the states of the system. A novel fast
adaptive unknown input observer (FAUIO) structure is proposed for the
simultaneous estimation of both faults and states of a class of nonlinear
systems. A new LMI condition is established by utilizing the
$\mathcal{H}_\infty$ criterion to ensure the asymptotic convergence of the
estimation error of the developed observer. This derived LMI condition is
deduced by incorporating the reformulated Lipschitz property, a new variant of
Young inequality, and the well-known linear parameter varying (LPV) approach.
It is less conservative than the existing ones in the literature, and its
effectiveness is compared with the other proposed approaches. Further, the
proposed observer methodology is extended for the disturbance-affected
nonlinear system for the purpose of the reconstruction of states and faults
with optimal noise attenuation. Later on, both designed approaches are
validated through an application of a single-link robotic arm manipulator in
MATLAB Simulink.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05028" title="Abstract">arXiv:2312.05028</a> [<a href="/pdf/2312.05028" title="Download PDF">pdf</a>, <a href="/format/2312.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster images with AntClust: a clustering algorithm based on the  chemical recognition system of ants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oed%2C+W+G">Winfried Gero Oed</a>, 
<a href="/search/cs?searchtype=author&query=Memarmoshrefi%2C+P">Parisa Memarmoshrefi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We implement AntClust, a clustering algorithm based on the chemical
recognition system of ants and use it to cluster images of cars. We will give a
short recap summary of the main working principles of the algorithm as devised
by the original paper [1]. Further, we will describe how to define a similarity
function for images and how the implementation is used to cluster images of
cars from the vehicle re-identification data set. We then test the clustering
performance of AntClust against DBSCAN, HDBSCAN and OPTICS. Finally one of the
core parts in AntClust, the rule set can be easily redefined with our
implementation, enabling a way for other bio-inspired algorithms to find rules
in an automated process. The implementation can be found on GitLab [9].
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05029" title="Abstract">arXiv:2312.05029</a> [<a href="/pdf/2312.05029" title="Download PDF">pdf</a>, <a href="/format/2312.05029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges, Strengths, and Strategies of Software Engineers with ADHD: A  Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liebel%2C+G">Grischa Liebel</a>, 
<a href="/search/cs?searchtype=author&query=Langlois%2C+N">Noah Langlois</a>, 
<a href="/search/cs?searchtype=author&query=Gama%2C+K">Kiev Gama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Neurodiversity describes brain function variation in individuals, including
Attention deficit hyperactivity disorder (ADHD) and Autism spectrum disorder.
Neurodivergent individuals both experience challenges and exhibit strengths in
the workplace. As an important disorder included under the neurodiversity term,
an estimated 5.0% to 7.1% of the world population have ADHD. However, existing
studies involving ADHD in the workplace are of general nature and do not focus
on software engineering (SE) activities. To address this gap, we performed an
exploratory qualitative case study on the experiences of people with ADHD
working in SE. We find that people with ADHD struggle with several important
SE-related activities, e.g., task organisation and estimation, attention to
work, relation to others. Furthermore, they experience issues with physical and
mental health. In terms of strengths, they exhibit, e.g., increased creative
skills, perform well when solving puzzles, and have the capability to think
ahead. Our findings align well with existing clinical ADHD research, and have
important implications to SE practice.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05031" title="Abstract">arXiv:2312.05031</a> [<a href="/pdf/2312.05031" title="Download PDF">pdf</a>, <a href="/format/2312.05031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Traffic Datasets using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez-Criado%2C+D">Daniel Rodriguez-Criado</a>, 
<a href="/search/cs?searchtype=author&query=Chli%2C+M">Maria Chli</a>, 
<a href="/search/cs?searchtype=author&query=Manso%2C+L+J">Luis J. Manso</a>, 
<a href="/search/cs?searchtype=author&query=Vogiatzis%2C+G">George Vogiatzis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 26th International Conference on Intelligent Transportation Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Traffic congestion in urban areas presents significant challenges, and
Intelligent Transportation Systems (ITS) have sought to address these via
automated and adaptive controls. However, these systems often struggle to
transfer simulated experiences to real-world scenarios. This paper introduces a
novel methodology for bridging this `sim-real' gap by creating photorealistic
images from 2D traffic simulations and recorded junction footage. We propose a
novel image generation approach, integrating a Conditional Generative
Adversarial Network with a Graph Neural Network (GNN) to facilitate the
creation of realistic urban traffic images. We harness GNNs' ability to process
information at different levels of abstraction alongside segmented images for
preserving locality data. The presented architecture leverages the power of
SPADE and Graph ATtention (GAT) network models to create images based on
simulated traffic scenarios. These images are conditioned by factors such as
entity positions, colors, and time of day. The uniqueness of our approach lies
in its ability to effectively translate structured and human-readable
conditions, encoded as graphs, into realistic images. This advancement
contributes to applications requiring rich traffic image datasets, from data
augmentation to urban traffic solutions. We further provide an application to
test the model's capabilities, including generating images with manually
defined positions for various entities.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05034" title="Abstract">arXiv:2312.05034</a> [<a href="/pdf/2312.05034" title="Download PDF">pdf</a>, <a href="/format/2312.05034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grasp Force Optimization as a Bilinear Matrix Inequality Problem: A Deep  Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basumatary%2C+H">Hirakjyoti Basumatary</a>, 
<a href="/search/cs?searchtype=author&query=Adhar%2C+D">Daksh Adhar</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+R">Riddhiman Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Hazarika%2C+S+M">Shyamanta M. Hazarika</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Grasp force synthesis is a non-convex optimization problem involving
constraints that are bilinear. Traditional approaches to this problem involve
general-purpose gradient-based nonlinear optimization and semi-definite
programming. With a view towards dealing with postural synergies and non-smooth
but convex positive semidefinite constraints, we look beyond gradient-based
optimization. The focus of this paper is to undertake a grasp analysis of
biomimetic grasping in multi-fingered robotic hands as a bilinear matrix
inequality (BMI) problem. Our analysis is to solve it using a deep learning
approach to make the algorithm efficiently generate force closure grasps with
optimal grasp quality on untrained/unseen objects.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05038" title="Abstract">arXiv:2312.05038</a> [<a href="/pdf/2312.05038" title="Download PDF">pdf</a>, <a href="/format/2312.05038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-In-Prompt Learning for Universal Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zilong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yiming Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chenglong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Hongming Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image restoration, which aims to retrieve and enhance degraded images, is
fundamental across a wide range of applications. While conventional deep
learning approaches have notably improved the image quality across various
tasks, they still suffer from (i) the high storage cost needed for various
task-specific models and (ii) the lack of interactivity and flexibility,
hindering their wider application. Drawing inspiration from the pronounced
success of prompts in both linguistic and visual domains, we propose novel
Prompt-In-Prompt learning for universal image restoration, named PIP. First, we
present two novel prompts, a degradation-aware prompt to encode high-level
degradation knowledge and a basic restoration prompt to provide essential
low-level information. Second, we devise a novel prompt-to-prompt interaction
module to fuse these two prompts into a universal restoration prompt. Third, we
introduce a selective prompt-to-feature interaction module to modulate the
degradation-related feature. By doing so, the resultant PIP works as a
plug-and-play module to enhance existing restoration models for universal image
restoration. Extensive experimental results demonstrate the superior
performance of PIP on multiple restoration tasks, including image denoising,
deraining, dehazing, deblurring, and low-light enhancement. Remarkably, PIP is
interpretable, flexible, efficient, and easy-to-use, showing promising
potential for real-world applications. The code is available at
https://github.com/longzilicart/pip_universal.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05039" title="Abstract">arXiv:2312.05039</a> [<a href="/pdf/2312.05039" title="Download PDF">pdf</a>, <a href="/format/2312.05039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartMask: Context Aware High-Fidelity Mask Generation for Fine-grained  Object Insertion and Layout Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jaskirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+C">Cameron Smith</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">The field of generative image inpainting and object insertion has made
significant progress with the recent advent of latent diffusion models.
Utilizing a precise object mask can greatly enhance these applications.
However, due to the challenges users encounter in creating high-fidelity masks,
there is a tendency for these methods to rely on more coarse masks (e.g.,
bounding box) for these applications. This results in limited control and
compromised background content preservation. To overcome these limitations, we
introduce SmartMask, which allows any novice user to create detailed masks for
precise object insertion. Combined with a ControlNet-Inpaint model, our
experiments demonstrate that SmartMask achieves superior object insertion
quality, preserving the background content more effectively than previous
methods. Notably, unlike prior works the proposed approach can also be used
even without user-mask guidance, which allows it to perform mask-free object
insertion at diverse positions and scales. Furthermore, we find that when used
iteratively with a novel instruction-tuning based planning model, SmartMask can
be used to design detailed layouts from scratch. As compared with user-scribble
based layout design, we observe that SmartMask allows for better quality
outputs with layout-to-image generation methods. Project page is available at
https://smartmask-gen.github.io
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05042" title="Abstract">arXiv:2312.05042</a> [<a href="/pdf/2312.05042" title="Download PDF">pdf</a>, <a href="/ps/2312.05042" title="Download PostScript">ps</a>, <a href="/format/2312.05042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Septic Hermite Collocation technique for Dirichlet Boundary  Condition Heat Conduction Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kutluay%2C+S">Sel&#xe7;uk Kutluay</a>, 
<a href="/search/math?searchtype=author&query=Ya%C4%9Fmurlu%2C+N+M">Nuri Murat Ya&#x11f;murlu</a>, 
<a href="/search/math?searchtype=author&query=Karaka%C5%9F%2C+A+S">Ali Sercan Karaka&#x15f;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In the present manuscript, approximate solution for 1D heat conduction
equation will be sought with the Septic Hermite Collocation Method (SHCM). To
achieve this goal, by means of the roots of both Chebyschev and Legendre
polinomials used at the inner collocation points, the pseudo code of this
method is found out and applied using Matlab, one of the widely used symbolic
programming platforms. Furthermore, to illustrate the accuracy and
effectiveness of this newly presented scheme, a comparison among analytical and
numerical values is investigated. It has been illustrated that this scheme is
both accurate and effective one and at the same time can be utilized in a
successful way for finding out numerical solutions of several problems both
linear and nonlinear.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05043" title="Abstract">arXiv:2312.05043</a> [<a href="/pdf/2312.05043" title="Download PDF">pdf</a>, <a href="/format/2312.05043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical-Layer Semantic-Aware Network for Zero-Shot Wireless Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huixiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE International Conference on Network Protocols (ICNP) Workshop, Reykjavik, Iceland, October 10-13, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Device-free wireless sensing has recently attracted significant interest due
to its potential to support a wide range of immersive human-machine interactive
applications. However, data heterogeneity in wireless signals and data privacy
regulation of distributed sensing have been considered as the major challenges
that hinder the wide applications of wireless sensing in large area networking
systems. Motivated by the observation that signals recorded by wireless
receivers are closely related to a set of physical-layer semantic features, in
this paper we propose a novel zero-shot wireless sensing solution that allows
models constructed in one or a limited number of locations to be directly
transferred to other locations without any labeled data. We develop a novel
physical-layer semantic-aware network (pSAN) framework to characterize the
correlation between physical-layer semantic features and the sensing data
distributions across different receivers. We then propose a pSAN-based
zero-shot learning solution in which each receiver can obtain a
location-specific gesture recognition model by directly aggregating the already
constructed models of other receivers. We theoretically prove that models
obtained by our proposed solution can approach the optimal model without
requiring any local model training. Experimental results once again verify that
the accuracy of models derived by our proposed solution matches that of the
models trained by the real labeled data based on supervised learning approach.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05044" title="Abstract">arXiv:2312.05044</a> [<a href="/pdf/2312.05044" title="Download PDF">pdf</a>, <a href="/format/2312.05044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backward Learning for Goal-Conditioned Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%B6ftmann%2C+M">Marc H&#xf6;ftmann</a>, 
<a href="/search/cs?searchtype=author&query=Robine%2C+J">Jan Robine</a>, 
<a href="/search/cs?searchtype=author&query=Harmeling%2C+S">Stefan Harmeling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> World Models, Goal-conditioned, Reward-free, Workshop on Goal-Conditioned Reinforcement Learning - NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Can we learn policies in reinforcement learning without rewards? Can we learn
a policy just by trying to reach a goal state? We answer these questions
positively by proposing a multi-step procedure that first learns a world model
that goes backward in time, secondly generates goal-reaching backward
trajectories, thirdly improves those sequences using shortest path finding
algorithms, and finally trains a neural network policy by imitation learning.
We evaluate our method on a deterministic maze environment where the
observations are $64\times 64$ pixel bird's eye images and can show that it
consistently reaches several goals.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05046" title="Abstract">arXiv:2312.05046</a> [<a href="/pdf/2312.05046" title="Download PDF">pdf</a>, <a href="/format/2312.05046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuVieCAST: Multi-View Consistent Artistic Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibrahimli%2C+N">Nail Ibrahimli</a>, 
<a href="/search/cs?searchtype=author&query=Kooij%2C+J+F+P">Julian F. P. Kooij</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+L">Liangliang Nan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce MuVieCAST, a modular multi-view consistent style transfer
network architecture that enables consistent style transfer between multiple
viewpoints of the same scene. This network architecture supports both sparse
and dense views, making it versatile enough to handle a wide range of
multi-view image datasets. The approach consists of three modules that perform
specific tasks related to style transfer, namely content preservation, image
transformation, and multi-view consistency enforcement. We extensively evaluate
our approach across multiple application domains including depth-map-based
point cloud fusion, mesh reconstruction, and novel-view synthesis. Our
experiments reveal that the proposed framework achieves an exceptional
generation of stylized images, exhibiting consistent outcomes across
perspectives. A user study focusing on novel-view synthesis further confirms
these results, with approximately 68\% of cases participants expressing a
preference for our generated outputs compared to the recent state-of-the-art
method. Our modular framework is extensible and can easily be integrated with
various backbone architectures, making it a flexible solution for multi-view
style transfer. More results are demonstrated on our project page:
muviecast.github.io
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05047" title="Abstract">arXiv:2312.05047</a> [<a href="/pdf/2312.05047" title="Download PDF">pdf</a>, <a href="/format/2312.05047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Converting Epics/Stories into Pseudocode using Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolhatkar%2C+G">Gaurav Kolhatkar</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+A">Akshit Madan</a>, 
<a href="/search/cs?searchtype=author&query=Kowtal%2C+N">Nidhi Kowtal</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Satyajit Roy</a>, 
<a href="/search/cs?searchtype=author&query=Sonawane%2C+S">Sheetal Sonawane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE - INDICON
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The conversion of user epics or stories into their appropriate representation
in pseudocode or code is a time-consuming task, which can take up a large
portion of the time in an industrial project. With this research paper, we aim
to present a methodology to generate pseudocode from a given agile user story
of small functionalities so as to reduce the overall time spent on the
industrial project. Pseudocode is a programming language agnostic
representation of the steps involved in a computer program, which can be easily
converted into any programming language. Leveraging the potential of Natural
Language Processing, we want to simplify the development process in
organizations that use the Agile Model of Software Development. We present a
methodology to convert a problem described in the English language into
pseudocode. This methodology divides the Text to Pseudocode conversion task
into two stages or subtasks, each of which is treated like an individual
machine translation task. Stage 1 is Text to Code Conversion and Stage 2 is
Code to Pseudocode Conversion. We find that the CodeT5 model gives the best
results in terms of BLEU score when trained separately on the two subtasks
mentioned above. BLEU score is a metric that is used to measure the similarity
between a machine-translated text and a set of reference translations.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05052" title="Abstract">arXiv:2312.05052</a> [<a href="/pdf/2312.05052" title="Download PDF">pdf</a>, <a href="/format/2312.05052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Frequency Capping for Improved Ad Click Prediction in Yahoo Gemini  Native
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aharon%2C+M">Michal Aharon</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+Y">Yohay Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+R">Rina Levy</a>, 
<a href="/search/cs?searchtype=author&query=Somekh%2C+O">Oren Somekh</a>, 
<a href="/search/cs?searchtype=author&query=Blanc%2C+A">Ayelet Blanc</a>, 
<a href="/search/cs?searchtype=author&query=Eshel%2C+N">Neetai Eshel</a>, 
<a href="/search/cs?searchtype=author&query=Shahar%2C+A">Avi Shahar</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+A">Assaf Singer</a>, 
<a href="/search/cs?searchtype=author&query=Zlotnik%2C+A">Alex Zlotnik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc. CIKM'2019. arXiv admin note: text overlap with <a href="/abs/2111.07866">arXiv:2111.07866</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Yahoo's native advertising (also known as Gemini native) serves billions of
ad impressions daily, reaching a yearly run-rate of many hundred of millions
USD. Driving the Gemini native models that are used to predict both click
probability (pCTR) and conversion probability (pCONV) is OFFSET - a feature
enhanced collaborative-filtering (CF) based event prediction algorithm. \offset
is a one-pass algorithm that updates its model for every new batch of logged
data using a stochastic gradient descent (SGD) based approach. Since OFFSET
represents its users by their features (i.e., user-less model) due to sparsity
issues, rule based hard frequency capping (HFC) is used to control the number
of times a certain user views a certain ad. Moreover, related statistics reveal
that user ad fatigue results in a dramatic drop in click through rate (CTR).
Therefore, to improve click prediction accuracy, we propose a soft frequency
capping (SFC) approach, where the frequency feature is incorporated into the
OFFSET model as a user-ad feature and its weight vector is learned via logistic
regression as part of OFFSET training. Online evaluation of the soft frequency
capping algorithm via bucket testing showed a significant 7.3% revenue lift.
Since then, the frequency feature enhanced model has been pushed to production
serving all traffic, and is generating a hefty revenue lift for Yahoo Gemini
native. We also report related statistics that reveal, among other things, that
while users' gender does not affect ad fatigue, the latter seems to increase
with users' age.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05055" title="Abstract">arXiv:2312.05055</a> [<a href="/pdf/2312.05055" title="Download PDF">pdf</a>, <a href="/format/2312.05055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Implementation of Automatic Assisted Aiming System For  Robomaster EP Based on YOLOv5
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Junjia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kangli Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the crucial stages of the Robomaster Youth Championship, the Robomaster EP
Robot must operate exclusively on autonomous algorithms to remain competitive.
Target recognition and automatic assisted aiming are indispensable for the EP
robot. In this study, we use YOLOv5 for multi-object detection to identify the
Robomaster EP Robot and its armor. Additionally, we integrate the DeepSORT
algorithm for vehicle identification and tracking. As a result, we introduce a
refined YOLOv5-based system that allows the robot to recognize and aim at
multiple targets simultaneously. To ensure precise tracking, we use a PID
controller with Feedforward Enhancement and an FIR controller paired with a
Kalman filter. This setup enables quick gimbal movement towards the target and
predicts its next position, optimizing potential damage during motion. Our
proposed system enhances the robot's accuracy in targeting armor, improving its
competitive performance.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05056" title="Abstract">arXiv:2312.05056</a> [<a href="/pdf/2312.05056" title="Download PDF">pdf</a>, <a href="/format/2312.05056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Control of the Deformation of Soft Linear Objects Using Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zakaria%2C+M+H+D">M&#xe9;lodie Hani Daniel Zakaria</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Lequi%C3%A8vre%2C+L">Laurent Lequi&#xe8;vre</a>, 
<a href="/search/cs?searchtype=author&query=Lengagne%2C+S">S&#xe9;bastien Lengagne</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%B3n%2C+J+A+C">Juan Antonio Corrales Ram&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Mezouar%2C+Y">Youcef Mezouar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table, Accepted for IEEE CASE 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes a new control framework for manipulating soft objects. A
Deep Reinforcement Learning (DRL) approach is used to make the shape of a
deformable object reach a set of desired points by controlling a robotic arm
which manipulates it. Our framework is more easily generalizable than existing
ones: it can work directly with different initial and desired final shapes
without need for relearning. We achieve this by using learning parallelization,
i.e., executing multiple agents in parallel on various environment instances.
We focus our study on deformable linear objects. These objects are interesting
in industrial and agricultural domains, yet their manipulation with robots,
especially in 3D workspaces, remains challenging. We simulate the entire
environment, i.e., the soft object and the robot, for the training and the
testing using PyBullet and OpenAI Gym. We use a combination of state-of-the-art
DRL techniques, the main ingredient being a training approach for the learning
agent (i.e., the robot) based on Deep Deterministic Policy Gradient (DDPG). Our
simulation results support the usefulness and enhanced generality of the
proposed approach.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05058" title="Abstract">arXiv:2312.05058</a> [<a href="/pdf/2312.05058" title="Download PDF">pdf</a>, <a href="/format/2312.05058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial and Temporal Hierarchy for Autonomous Navigation using Active  Inference in Minigrid Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Tinguy%2C+D">Daria de Tinguy</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Maele%2C+T">Toon van de Maele</a>, 
<a href="/search/cs?searchtype=author&query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="/search/cs?searchtype=author&query=Dhoedt%2C+B">Bart Dhoedt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted paper Entropy. arXiv admin note: text overlap with <a href="/abs/2309.09864">arXiv:2309.09864</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robust evidence suggests that humans explore their environment using a
combination of topological landmarks and coarse grained path-integration. This
approach relies on identifiable environmental features (topological landmarks)
in tandem with estimations of distance and direction (coarse grained
path-integration) to construct cognitive maps of the surroundings. This
cognitive map is believed to exhibit a hierarchical structure, allowing
efficient planning when solving complex navigation tasks. Inspired by the human
behaviour, this paper presents a scalable hierarchical active inference model
for autonomous navigation, exploration, and goal-oriented behaviour. The model
uses visual observation and motion perception to combine curiosity-driven
exploration with goal-oriented behaviour. Motion is planned using different
levels of reasoning, i.e. from context to place to motion. This allows for
efficient navigation in new spaces and rapid progress toward a target. By
incorporating these human navigational strategies and their hierarchical
representation of the environment, this model proposes a new solution for
autonomous navigation and exploration. The approach is validated through
simulations in a mini-grid environment.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05059" title="Abstract">arXiv:2312.05059</a> [<a href="/pdf/2312.05059" title="Download PDF">pdf</a>, <a href="/format/2312.05059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Kernel Method for Electrical Resistance Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tamburrino%2C+A">Antonello Tamburrino</a>, 
<a href="/search/math?searchtype=author&query=Mottola%2C+V">Vincenzo Mottola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper we consider the inverse problem of electrical conductivity
retrieval starting from boundary measurements, in the framework of Electrical
Resistance Tomography (ERT). In particular, the focus is on non-iterative
reconstruction algorithms, compatible with real-time applications. In this work
a new non-iterative reconstruction method for Electrical Resistance Tomography,
termed Kernel Method, is presented. The imaging algorithm deals with the
problem of retrieving the shape of one or more anomalies embedded in a known
background. The foundation of the proposed method is given by the idea that if
there exists a current flux at the boundary (Neumann data) able to produce the
same voltage measurements on two different configurations, with and without the
anomaly, respectively, then the corresponding electric current density for the
problem involving only the background material vanishes in the region occupied
by the anomaly. Coherently with this observation, the Kernel Method consists in
(i) evaluating a proper current flux at the boundary $g$, (ii) solving one
direct problem on a configuration without anomaly and driven by $g$, (iii)
reconstructing the anomaly from the spatial plot of the power density as the
region in which the power density vanishes. This new tomographic method has a
very simple numerical implementation at a very low computational cost. Beside
theoretical results and justifications of our method, we present a large number
of numerical examples to show the potential of this new algorithm.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05061" title="Abstract">arXiv:2312.05061</a> [<a href="/pdf/2312.05061" title="Download PDF">pdf</a>, <a href="/format/2312.05061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaCour!: Enabling Research on Argumentation in Hearings of the European  Court of Human Rights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Held%2C+L">Lena Held</a>, 
<a href="/search/cs?searchtype=author&query=Habernal%2C+I">Ivan Habernal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Why does an argument end up in the final court decision? Was it deliberated
or questioned during the oral hearings? Was there something in the hearings
that triggered a particular judge to write a dissenting opinion? Despite the
availability of the final judgments of the European Court of Human Rights
(ECHR), none of these legal research questions can currently be answered as the
ECHR's multilingual oral hearings are not transcribed, structured, or
speaker-attributed. We address this fundamental gap by presenting LaCour!, the
first corpus of textual oral arguments of the ECHR, consisting of 154 full
hearings (2.1 million tokens from over 267 hours of video footage) in English,
French, and other court languages, each linked to the corresponding final
judgment documents. In addition to the transcribed and partially manually
corrected text from the video, we provide sentence-level timestamps and
manually annotated role and language labels. We also showcase LaCour! in a set
of preliminary experiments that explore the interplay between questions and
dissenting opinions. Apart from the use cases in legal NLP, we hope that law
students or other interested parties will also use LaCour! as a learning
resource, as it is freely available in various formats at
https://huggingface.co/datasets/TrustHLT/LaCour.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05067" title="Abstract">arXiv:2312.05067</a> [<a href="/pdf/2312.05067" title="Download PDF">pdf</a>, <a href="/format/2312.05067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Reweighting for Mitigating Label Quality Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weikai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yukai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lan-Zhe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu-Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shixia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TVCG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Label quality issues, such as noisy labels and imbalanced class
distributions, have negative effects on model performance. Automatic
reweighting methods identify problematic samples with label quality issues by
recognizing their negative effects on validation samples and assigning lower
weights to them. However, these methods fail to achieve satisfactory
performance when the validation samples are of low quality. To tackle this, we
develop Reweighter, a visual analysis tool for sample reweighting. The
reweighting relationships between validation samples and training samples are
modeled as a bipartite graph. Based on this graph, a validation sample
improvement method is developed to improve the quality of validation samples.
Since the automatic improvement may not always be perfect, a co-cluster-based
bipartite graph visualization is developed to illustrate the reweighting
relationships and support the interactive adjustments to validation samples and
reweighting results. The adjustments are converted into the constraints of the
validation sample improvement method to further improve validation samples. We
demonstrate the effectiveness of Reweighter in improving reweighting results
through quantitative evaluation and two case studies.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05072" title="Abstract">arXiv:2312.05072</a> [<a href="/pdf/2312.05072" title="Download PDF">pdf</a>, <a href="/ps/2312.05072" title="Download PostScript">ps</a>, <a href="/format/2312.05072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A recursive construction for projective Reed-Muller codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=San-Jos%C3%A9%2C+R">Rodrigo San-Jos&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">We give a recursive construction for projective Reed-Muller codes in terms of
affine Reed-Muller codes and projective Reed-Muller codes in fewer variables.
From this construction, we obtain the dimension of the subfield subcodes of
projective Reed-Muller codes for some particular degrees that give codes with
good parameters. Moreover, from this recursive construction we are able to
derive a lower bound for the generalized Hamming weights of projective
Reed-Muller codes which, together with the basic properties of the generalized
Hamming weights, allows us to determine most of the weight hierarchy of
projective Reed-Muller codes in many cases.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05086" title="Abstract">arXiv:2312.05086</a> [<a href="/pdf/2312.05086" title="Download PDF">pdf</a>, <a href="/format/2312.05086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Can&#x27;t Believe It&#x27;s Not Better: In-air Movement For Alzheimer  Handwriting Synthetic Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bensalah%2C+A">Asma Bensalah</a>, 
<a href="/search/cs?searchtype=author&query=Parziale%2C+A">Antonio Parziale</a>, 
<a href="/search/cs?searchtype=author&query=De+Gregorio%2C+G">Giuseppe De Gregorio</a>, 
<a href="/search/cs?searchtype=author&query=Marcelli%2C+A">Angelo Marcelli</a>, 
<a href="/search/cs?searchtype=author&query=Forn%C3%A9s%2C+A">Alicia Forn&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Llad%5C%27os">Llad&#xf3;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">During recent years, there here has been a boom in terms of deep learning use
for handwriting analysis and recognition. One main application for handwriting
analysis is early detection and diagnosis in the health field. Unfortunately,
most real case problems still suffer a scarcity of data, which makes difficult
the use of deep learning-based models. To alleviate this problem, some works
resort to synthetic data generation. Lately, more works are directed towards
guided data synthetic generation, a generation that uses the domain and data
knowledge to generate realistic data that can be useful to train deep learning
models. In this work, we combine the domain knowledge about the Alzheimer's
disease for handwriting and use it for a more guided data generation.
Concretely, we have explored the use of in-air movements for synthetic data
generation.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05090" title="Abstract">arXiv:2312.05090</a> [<a href="/pdf/2312.05090" title="Download PDF">pdf</a>, <a href="/format/2312.05090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniTSA: A Universal Reinforcement Learning Framework for V2X Traffic  Signal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Maonan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+X">Xi Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Kan%2C+Y">Yuheng Kan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+C">Chengcheng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Pun%2C+M">Man-On Pun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Traffic congestion is a persistent problem in urban areas, which calls for
the development of effective traffic signal control (TSC) systems. While
existing Reinforcement Learning (RL)-based methods have shown promising
performance in optimizing TSC, it is challenging to generalize these methods
across intersections of different structures. In this work, a universal
RL-based TSC framework is proposed for Vehicle-to-Everything (V2X)
environments. The proposed framework introduces a novel agent design that
incorporates a junction matrix to characterize intersection states, making the
proposed model applicable to diverse intersections. To equip the proposed
RL-based framework with enhanced capability of handling various intersection
structures, novel traffic state augmentation methods are tailor-made for signal
light control systems. Finally, extensive experimental results derived from
multiple intersection configurations confirm the effectiveness of the proposed
framework. The source code in this work is available at
https://github.com/wmn7/Universal_Light
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05092" title="Abstract">arXiv:2312.05092</a> [<a href="/pdf/2312.05092" title="Download PDF">pdf</a>, <a href="/format/2312.05092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INSPECT: Intrinsic and Systematic Probing Evaluation for Code  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karmakar%2C+A">Anjan Karmakar</a>, 
<a href="/search/cs?searchtype=author&query=Robbes%2C+R">Romain Robbes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Software Engineering. Extension of our previous paper "What do pre-trained code models know about code?" (ASE 2021, <a href="/abs/2108.11308">arXiv:2108.11308</a>). 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained models of source code have recently been successfully applied to
a wide variety of Software Engineering tasks; they have also seen some
practical adoption in practice, e.g. for code completion. Yet, we still know
very little about what these pre-trained models learn about source code. In
this article, we use probing--simple diagnostic tasks that do not further train
the models--to discover to what extent pre-trained models learn about specific
aspects of source code. We use an extensible framework to define 15 probing
tasks that exercise surface, syntactic, structural and semantic characteristics
of source code. We probe 8 pre-trained source code models, as well as a natural
language model (BERT) as our baseline. We find that models that incorporate
some structural information (such as GraphCodeBERT) have a better
representation of source code characteristics. Surprisingly, we find that for
some probing tasks, BERT is competitive with the source code models, indicating
that there are ample opportunities to improve source-code specific pre-training
on the respective code characteristics. We encourage other researchers to
evaluate their models with our probing task suite, so that they may peer into
the hidden layers of the models and identify what intrinsic code
characteristics are encoded.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05096" title="Abstract">arXiv:2312.05096</a> [<a href="/pdf/2312.05096" title="Download PDF">pdf</a>, <a href="/format/2312.05096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScalO-RAN: Energy-aware Network Intelligence Scaling in Open RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maxenti%2C+S">Stefano Maxenti</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oro%2C+S">Salvatore D&#x27;Oro</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Capone%2C+A">Antonio Capone</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Network virtualization, software-defined infrastructure, and orchestration
are pivotal elements in contemporary networks, yielding new vectors for
optimization and novel capabilities. In line with these principles, O-RAN
presents an avenue to bypass vendor lock-in, circumvent vertical
configurations, enable network programmability, and facilitate integrated
Artificial Intelligence (AI) support. Moreover, modern container orchestration
frameworks (e.g., Kubernetes, Red Hat OpenShift) simplify the way cellular base
stations, as well as the newly introduced RAN Intelligent Controllers (RICs),
are deployed, managed, and orchestrated. While this enables cost reduction via
infrastructure sharing, it also makes it more challenging to meet O-RAN control
latency requirements, especially during peak resource utilization. To address
this problem, we propose ScalO-RAN, a control framework rooted in optimization
and designed as an O-RAN rApp that allocates and scales AI-based O-RAN
applications (xApps, rApps, dApps) to: (i) abide by application-specific
latency requirements, and (ii) monetize the shared infrastructure while
reducing energy consumption. We prototype ScalO-RAN on an OpenShift cluster
with base stations, RIC, and a set of AI-based xApps deployed as
micro-services. We evaluate ScalO-RAN both numerically and experimentally. Our
results show that ScalO-RAN can optimally allocate and distribute O-RAN
applications within available computing nodes to accommodate even stringent
latency requirements. More importantly, we show that scaling O-RAN applications
is primarily a time-constrained problem rather than a resource-constrained one,
where scaling policies must account for stringent inference time of AI
applications, and not only how many resources they consume.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05100" title="Abstract">arXiv:2312.05100</a> [<a href="/pdf/2312.05100" title="Download PDF">pdf</a>, <a href="/format/2312.05100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual learning for surface defect segmentation by subnetwork  creation and selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dekhovich%2C+A">Aleksandr Dekhovich</a>, 
<a href="/search/cs?searchtype=author&query=Bessa%2C+M+A">Miguel A. Bessa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a new continual (or lifelong) learning algorithm called LDA-CP&amp;S
that performs segmentation tasks without undergoing catastrophic forgetting.
The method is applied to two different surface defect segmentation problems
that are learned incrementally, i.e. providing data about one type of defect at
a time, while still being capable of predicting every defect that was seen
previously. Our method creates a defect-related subnetwork for each defect type
via iterative pruning and trains a classifier based on linear discriminant
analysis (LDA). At the inference stage, we first predict the defect type with
LDA and then predict the surface defects using the selected subnetwork. We
compare our method with other continual learning methods showing a significant
improvement -- mean Intersection over Union better by a factor of two when
compared to existing methods on both datasets. Importantly, our approach shows
comparable results with joint training when all the training data (all defects)
are seen simultaneously
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05102" title="Abstract">arXiv:2312.05102</a> [<a href="/pdf/2312.05102" title="Download PDF">pdf</a>, <a href="/format/2312.05102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Measurement of Application-level Energy Consumption for  Energy-Aware Large-Scale Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simsek%2C+O+S">Osman Seckin Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Piccinali%2C+J">Jean-Guillaume Piccinali</a>, 
<a href="/search/cs?searchtype=author&query=Ciorba%2C+F+M">Florina M. Ciorba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in Proceedings of the SC 23 Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Sustainability in high performance computing (HPC) is a major challenge not
only for HPC centers and their users, but also for society as the climate goals
become stricter. A lot of effort went into reducing the energy consumption of
systems in general. Even though certain efforts to optimize the
energy-efficiency of HPC workloads exist, most such efforts propose solutions
targeting CPUs. As HPC systems shift more and more to GPU-centric
architectures, simulation codes increasingly adopt GPU-programming models. This
leads to an urgent need to increase the energy-efficiency of GPU-enabled codes.
However, studies for reducing the energy consumption of large-scale simulations
executing on CPUs and GPUs have received insufficient attention. In this work,
we enable accurate power and energy measurements using an open-source toolkit
across a range of CPU+GPU node architectures. We use this approach in SPH-EXA,
an open-source GPU-centric astrophysical and cosmological simulation framework.
We show that with simple code instrumentation, users can accurately measure
power and energy related data about their application, beyond data provided by
HPC systems alone. The accurate power and energy data provide significant
insight to users for conducting energy-aware computational experiments and
future energy-aware code development.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05103" title="Abstract">arXiv:2312.05103</a> [<a href="/pdf/2312.05103" title="Download PDF">pdf</a>, <a href="/format/2312.05103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMID: A Comprehensive Real-world Dataset for Trademark Infringement  Detection in E-Commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tongxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Lizhen Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023, Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Annually, e-commerce platforms incur substantial financial losses due to
trademark infringements, making it crucial to identify and mitigate potential
legal risks tied to merchant information registered to the platforms. However,
the absence of high-quality datasets hampers research in this area. To address
this gap, our study introduces TMID, a novel dataset to detect trademark
infringement in merchant registrations. This is a real-world dataset sourced
directly from Alipay, one of the world's largest e-commerce and digital payment
platforms. As infringement detection is a legal reasoning task requiring an
understanding of the contexts and legal rules, we offer a thorough collection
of legal rules and merchant and trademark-related contextual information with
annotations from legal experts. We ensure the data quality by performing an
extensive statistical analysis. Furthermore, we conduct an empirical study on
this dataset to highlight its value and the key challenges. Through this study,
we aim to contribute valuable resources to advance research into legal
compliance related to trademark infringement within the e-commerce sphere. The
dataset is available at https://github.com/emnlpTMID/emnlpTMID.github.io .
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05104" title="Abstract">arXiv:2312.05104</a> [<a href="/pdf/2312.05104" title="Download PDF">pdf</a>, <a href="/ps/2312.05104" title="Download PostScript">ps</a>, <a href="/format/2312.05104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Autonomous Driving model with BEV-V2X Perception, Trajectory  Prediction and Driving Planning in Complex Traffic Intersections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fukang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+O">Owen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kunpeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 7 figures; references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The comprehensiveness of vehicle-to-everything (V2X) recognition enriches and
holistically shapes the global Birds-Eye-View (BEV) perception, incorporating
rich semantics and integrating driving scene information, thereby serving
features of trajectory prediction, decision-making and driving planning.
Utilizing V2X message sets to form BEV format proves to be an effective
perception method for connected and automated vehicles (CAVs). Specifically,
MAP, SPAT and RSI data contributes to the achievement of road connectivity,
synchronized traffic signal navigation and obstacle warning. Moreover, using
time-sequential BSMs information from multiple vehicles allows for the
perception of current state and the prediction of future trajectories.
Therefore, this paper develops a comprehensive autonomous driving model that
relies on BEV-V2X perception, Interacting Multiple model Unscented Kalman
Filter (IMM-UKF)-based trajectory prediction, and deep reinforcement learning
(DRL)-based decision making and planing. We establish a DRL environment with
reward-shaping methods to formulate a unified set of optimal driving behaviors
that encompass obstacle avoidance, lane changes, overtaking, turning maneuver,
and synchronized traffic signal navigation. Consequently, a complex traffic
intersection scenario was simulated, and the well-trained model was applied for
driving control. The observed driving behavior closely resembled that of an
experienced driver, exhibiting anticipatory actions and revealing notable
operational highlights of driving policy.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05107" title="Abstract">arXiv:2312.05107</a> [<a href="/pdf/2312.05107" title="Download PDF">pdf</a>, <a href="/format/2312.05107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreaMoving: A Human Dance Video Generation Framework based on Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Z">Zheng Hui</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiefan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianhui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haolan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Miaomiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Peiran Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, Tech. Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present DreaMoving, a diffusion-based controllable video
generation framework to produce high-quality customized human dance videos.
Specifically, given target identity and posture sequences, DreaMoving can
generate a video of the target identity dancing anywhere driven by the posture
sequences. To this end, we propose a Video ControlNet for motion-controlling
and a Content Guider for identity preserving. The proposed model is easy to use
and can be adapted to most stylized diffusion models to generate diverse
results. The project page is available at
https://dreamoving.github.io/dreamoving.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05108" title="Abstract">arXiv:2312.05108</a> [<a href="/pdf/2312.05108" title="Download PDF">pdf</a>, <a href="/format/2312.05108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Energy Flexibility From Thermal Inertia of Buildings: A Robust  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yun Li</a>, 
<a href="/search/eess?searchtype=author&query=Yorke-Smith%2C+N">Neil Yorke-Smith</a>, 
<a href="/search/eess?searchtype=author&query=Keviczky%2C+T">Tamas Keviczky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted to the 62nd IEEE Conference on Decision and Control (CDC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Towards integrating renewable electricity generation sources into the grid,
an important facilitator is the energy flexibility provided by buildings'
thermal inertia. Most of the existing research follows a single-step price- or
incentive-based scheme for unlocking the flexibility potential of buildings. In
contrast, this paper proposes a novel two-step design approach for better
harnessing buildings' energy flexibility. In a first step, a robust
optimization model is formulated for assessing the energy flexibility of
buildings in the presence of uncertain predictions of external conditions, such
as ambient temperature, solar irradiation, etc. In a second step, energy
flexibility is activated in response to a feasible demand response (DR) request
from grid operators without violating indoor temperature constraints, even in
the presence of uncertain external conditions. The proposed approach is tested
on a high-fidelity Modelica simulator to evaluate its effectiveness. Simulation
results show that, compared with price-based demand-side management, the
proposed approach achieves greater energy reduction during peak hours.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05110" title="Abstract">arXiv:2312.05110</a> [<a href="/pdf/2312.05110" title="Download PDF">pdf</a>, <a href="/format/2312.05110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soliro -- a hybrid dynamic tilt-wing aerial manipulator with minimal  actuators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pantic%2C+M">Michael Pantic</a>, 
<a href="/search/cs?searchtype=author&query=Hampp%2C+E">Elias Hampp</a>, 
<a href="/search/cs?searchtype=author&query=Flammer%2C+R">Ramon Flammer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Stastny%2C+T">Thomas Stastny</a>, 
<a href="/search/cs?searchtype=author&query=Ott%2C+L">Lionel Ott</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at the 18th International Symposium on Experimental Robotics (ISER 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The ability to enter in contact with and manipulate physical objects with a
flying robot enables many novel applications, such as contact inspection,
painting, drilling, and sample collection. Generally, these aerial robots need
more degrees of freedom than a standard quadrotor. While there is active
research of over-actuated, omnidirectional MAVs and aerial manipulators as well
as VTOL and hybrid platforms, the two concepts have not been combined. We
address the problem of conceptualization, characterization, control, and
testing of a 5DOF rotary-/fixed-wing hybrid, tilt-rotor, split tilt-wing,
nearly omnidirectional aerial robot. We present an elegant solution with a
minimal set of actuators and that does not need any classical control surfaces
or flaps. The concept is validated in a wind tunnel study and in multiple
flights with forward and backward transitions. Fixed-wing flight speeds up to
10 m/s were reached, with a power reduction of 30% as compared to rotary wing
flight.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05114" title="Abstract">arXiv:2312.05114</a> [<a href="/pdf/2312.05114" title="Download PDF">pdf</a>, <a href="/format/2312.05114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Inadequacy of Similarity-based Privacy Metrics: Reconstruction  Attacks against &quot;Truly Anonymous Synthetic Data&#x27;&#x27;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganev%2C+G">Georgi Ganev</a>, 
<a href="/search/cs?searchtype=author&query=De+Cristofaro%2C+E">Emiliano De Cristofaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Training generative models to produce synthetic data is meant to provide a
privacy-friendly approach to data release. However, we get robust guarantees
only when models are trained to satisfy Differential Privacy (DP). Alas, this
is not the standard in industry as many companies use ad-hoc strategies to
empirically evaluate privacy based on the statistical similarity between
synthetic and real data. In this paper, we review the privacy metrics offered
by leading companies in this space and shed light on a few critical flaws in
reasoning about privacy entirely via empirical evaluations. We analyze the
undesirable properties of the most popular metrics and filters and demonstrate
their unreliability and inconsistency through counter-examples. We then present
a reconstruction attack, ReconSyn, which successfully recovers (i.e., leaks all
attributes of) at least 78% of the low-density train records (or outliers) with
only black-box access to a single fitted generative model and the privacy
metrics. Finally, we show that applying DP only to the model or using
low-utility generators does not mitigate ReconSyn as the privacy leakage
predominantly comes from the metrics. Overall, our work serves as a warning to
practitioners not to deviate from established privacy-preserving mechanisms.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05125" title="Abstract">arXiv:2312.05125</a> [<a href="/pdf/2312.05125" title="Download PDF">pdf</a>, <a href="/format/2312.05125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Fly Omnidirectional Micro Aerial Vehicles with an End-To-End  Control Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cuniato%2C+E">Eugenio Cuniato</a>, 
<a href="/search/cs?searchtype=author&query=Andersson%2C+O">Olov Andersson</a>, 
<a href="/search/cs?searchtype=author&query=Oleynikova%2C+H">Helen Oleynikova</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Pantic%2C+M">Michael Pantic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at the 18th International Symposium on Experimental Robotics (ISER 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Overactuated tilt-rotor platforms offer many advantages over traditional
fixed-arm drones, allowing the decoupling of the applied force from the
attitude of the robot. This expands their application areas to aerial
interaction and manipulation, and allows them to overcome disturbances such as
from ground or wall effects by exploiting the additional degrees of freedom
available to their controllers. However, the overactuation also complicates the
control problem, especially if the motors that tilt the arms have slower
dynamics than those spinning the propellers. Instead of building a complex
model-based controller that takes all of these subtleties into account, we
attempt to learn an end-to-end pose controller using reinforcement learning,
and show its superior behavior in the presence of inertial and force
disturbances compared to a state-of-the-art traditional controller.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05128" title="Abstract">arXiv:2312.05128</a> [<a href="/pdf/2312.05128" title="Download PDF">pdf</a>, <a href="/format/2312.05128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model selection focusing on longtime behavior of differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reisch%2C+C">Cordula Reisch</a>, 
<a href="/search/math?searchtype=author&query=Burmester%2C+H">Hannah Burmester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contribution to ENUMATH Proceedings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Modeling biological processes is a highly demanding task because not all
processes are fully understood. Mathematical models allow us to test hypotheses
about possible mechanisms of biological processes. The mathematical mechanisms
oftentimes abstract from the biological micro-scale mechanisms. Experimental
parameter calibration is extremely challenging as the connection between
abstract and micro-scale mechanisms is unknown. Even if some microscopic
parameters can be determined by isolated experiments, the connection to the
abstract mathematical model is challenging. We present ideas for overcoming
these difficulties by using longtime characteristics of solutions for, first,
finding abstract mechanisms covering large-scale observations and, second,
determining parameter values for the abstract mechanisms. The parameter values
are not directly connected to experimental data but serve as a link between
known mechanisms and observations. The framework combines machine learning
techniques with the characteristic solution behavior of differential equations.
This setting gives insight into challenges by using rare data only that can
later be used for partial differential equations.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05133" title="Abstract">arXiv:2312.05133</a> [<a href="/pdf/2312.05133" title="Download PDF">pdf</a>, <a href="/format/2312.05133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIR: 3D Gaussian Inverse Rendering for Relightable Scene Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yahao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Haocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingtuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+E">Errui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents GIR, a 3D Gaussian Inverse Rendering method for
relightable scene factorization. Compared to existing methods leveraging
discrete meshes or neural implicit fields for inverse rendering, our method
utilizes 3D Gaussians to estimate the material properties, illumination, and
geometry of an object from multi-view images. Our study is motivated by the
evidence showing that 3D Gaussian is a more promising backbone than neural
fields in terms of performance, versatility, and efficiency. In this paper, we
aim to answer the question: ``How can 3D Gaussian be applied to improve the
performance of inverse rendering?'' To address the complexity of estimating
normals based on discrete and often in-homogeneous distributed 3D Gaussian
representations, we proposed an efficient self-regularization method that
facilitates the modeling of surface normals without the need for additional
supervision. To reconstruct indirect illumination, we propose an approach that
simulates ray tracing. Extensive experiments demonstrate our proposed GIR's
superior performance over existing methods across multiple tasks on a variety
of widely used datasets in inverse rendering. This substantiates its efficacy
and broad applicability, highlighting its potential as an influential tool in
relighting and reconstruction. Project page: https://3dgir.github.io
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05134" title="Abstract">arXiv:2312.05134</a> [<a href="/pdf/2312.05134" title="Download PDF">pdf</a>, <a href="/format/2312.05134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Multi-Distribution Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wenhao Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-distribution learning (MDL), which seeks to learn a shared model that
minimizes the worst-case risk across $k$ distinct data distributions, has
emerged as a unified framework in response to the evolving demand for
robustness, fairness, multi-group collaboration, etc. Achieving data-efficient
MDL necessitates adaptive sampling, also called on-demand sampling, throughout
the learning process. However, there exist substantial gaps between the
state-of-the-art upper and lower bounds on the optimal sample complexity.
Focusing on a hypothesis class of Vapnik-Chervonenkis (VC) dimension $d$, we
propose a novel algorithm that yields an $varepsilon$-optimal randomized
hypothesis with a sample complexity on the order of $(d+k)/\varepsilon^2$
(modulo some logarithmic factor), matching the best-known lower bound. Our
algorithmic ideas and theory have been further extended to accommodate
Rademacher classes. The proposed algorithms are oracle-efficient, which access
the hypothesis class solely through an empirical risk minimization oracle.
Additionally, we establish the necessity of randomization, unveiling a large
sample size barrier when only deterministic hypotheses are permitted. These
findings successfully resolve three open problems presented in COLT 2023 (i.e.,
Awasthi et al., (2023, Problem 1, 3 and 4)).
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05139" title="Abstract">arXiv:2312.05139</a> [<a href="/pdf/2312.05139" title="Download PDF">pdf</a>, <a href="/ps/2312.05139" title="Download PostScript">ps</a>, <a href="/format/2312.05139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clearing Financial Networks with Derivatives: From Intractability to  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S+D">Stavros D. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=de+Keijzer%2C+B">Bart de Keijzer</a>, 
<a href="/search/cs?searchtype=author&query=Ventre%2C+C">Carmine Ventre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Financial networks raise a significant computational challenge in identifying
insolvent firms and evaluating their exposure to systemic risk. This task,
known as the clearing problem, is computationally tractable when dealing with
simple debt contracts. However under the presence of certain derivatives called
credit default swaps (CDSes) the clearing problem is $\textsf{FIXP}$-complete.
Existing techniques only show $\textsf{PPAD}$-hardness for finding an
$\epsilon$-solution for the clearing problem with CDSes within an unspecified
small range for $\epsilon$.
<br />We present significant progress in both facets of the clearing problem: (i)
intractability of approximate solutions; (ii) algorithms and heuristics for
computable solutions. Leveraging $\textsf{Pure-Circuit}$ (FOCS'22), we provide
the first explicit inapproximability bound for the clearing problem involving
CDSes. Our primal contribution is a reduction from $\textsf{Pure-Circuit}$
which establishes that finding approximate solutions is $\textsf{PPAD}$-hard
within a range of roughly 5%.
<br />To alleviate the complexity of the clearing problem, we identify two
meaningful restrictions of the class of financial networks motivated by
regulations: (i) the presence of a central clearing authority; and (ii) the
restriction to covered CDSes. We provide the following results: (i.) The
$\textsf{PPAD}$-hardness of approximation persists when central clearing
authorities are introduced; (ii.) An optimisation-based method for solving the
clearing problem with central clearing authorities; (iii.) A polynomial-time
algorithm when the two restrictions hold simultaneously.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05140" title="Abstract">arXiv:2312.05140</a> [<a href="/pdf/2312.05140" title="Download PDF">pdf</a>, <a href="/format/2312.05140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Membership Inference Attacks on Diffusion Models via Quantile Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shuai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Aydore%2C+S">Sergul Aydore</a>, 
<a href="/search/cs?searchtype=author&query=Kearns%2C+M">Michael Kearns</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+A">Aaron Roth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recently, diffusion models have become popular tools for image synthesis
because of their high-quality outputs. However, like other large-scale models,
they may leak private information about their training data. Here, we
demonstrate a privacy vulnerability of diffusion models through a
\emph{membership inference (MI) attack}, which aims to identify whether a
target example belongs to the training set when given the trained diffusion
model. Our proposed MI attack learns quantile regression models that predict (a
quantile of) the distribution of reconstruction loss on examples not used in
training. This allows us to define a granular hypothesis test for determining
the membership of a point in the training set, based on thresholding the
reconstruction loss of that point using a custom threshold tailored to the
example. We also provide a simple bootstrap technique that takes a majority
membership prediction over ``a bag of weak attackers'' which improves the
accuracy over individual quantile regression models. We show that our attack
outperforms the prior state-of-the-art attack while being substantially less
computationally expensive -- prior attacks required training multiple ``shadow
models'' with the same architecture as the model under attack, whereas our
attack requires training only much smaller models.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05141" title="Abstract">arXiv:2312.05141</a> [<a href="/pdf/2312.05141" title="Download PDF">pdf</a>, <a href="/format/2312.05141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Domain Generalization with a Single Network by Regularization  Exploiting Pre-trained Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+I">Inseop Chung</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+K">KiYoon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open Domain Generalization (ODG) is a challenging task as it not only deals
with distribution shifts but also category shifts between the source and target
datasets. To handle this task, the model has to learn a generalizable
representation that can be applied to unseen domains while also identify
unknown classes that were not present during training. Previous work has used
multiple source-specific networks, which involve a high computation cost.
Therefore, this paper proposes a method that can handle ODG using only a single
network. The proposed method utilizes a head that is pre-trained by
linear-probing and employs two regularization terms, each targeting the
regularization of feature extractor and the classification head, respectively.
The two regularization terms fully utilize the pre-trained features and
collaborate to modify the head of the model without excessively altering the
feature extractor. This ensures a smoother softmax output and prevents the
model from being biased towards the source domains. The proposed method shows
improved adaptability to unseen domains and increased capability to detect
unseen classes as well. Extensive experiments show that our method achieves
competitive performance in several benchmarks. We also justify our method with
careful analysis of the effect on the logits, features, and the head.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05144" title="Abstract">arXiv:2312.05144</a> [<a href="/pdf/2312.05144" title="Download PDF">pdf</a>, <a href="/format/2312.05144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kraken: enabling joint trajectory prediction by utilizing Mode  Transformer and Greedy Mode Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antonenko%2C+D+S">Daniil S. Antonenko</a>, 
<a href="/search/cs?searchtype=author&query=Konev%2C+S">Stepan Konev</a>, 
<a href="/search/cs?searchtype=author&query=Biktairov%2C+Y">Yuriy Biktairov</a>, 
<a href="/search/cs?searchtype=author&query=Yangel%2C+B">Boris Yangel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate and reliable motion prediction is essential for safe urban autonomy.
The most prominent motion prediction approaches are based on modeling the
distribution of possible future trajectories of each actor in autonomous
system's vicinity. These "independent" marginal predictions might be accurate
enough to properly describe casual driving situations where the prediction
target is not likely to interact with other actors. They are, however,
inadequate for modeling interactive situations where the actors' future
trajectories are likely to intersect. To mitigate this issue we propose Kraken
-- a real-time trajectory prediction model capable of approximating pairwise
interactions between the actors as well as producing accurate marginal
predictions. Kraken relies on a simple Greedy Mode Processing technique
allowing it to convert a factorized prediction for a pair of agents into a
physically-plausible joint prediction. It also utilizes the Mode Transformer
module to increase the diversity of predicted trajectories and make the joint
prediction more informative. We evaluate Kraken on Waymo Motion Prediction
challenge where it held the first place in the Interaction leaderboard and the
second place in the Motion leaderboard in October 2021.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05161" title="Abstract">arXiv:2312.05161</a> [<a href="/pdf/2312.05161" title="Download PDF">pdf</a>, <a href="/format/2312.05161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TriHuman : A Real-time and Controllable Tri-plane Representation for  Detailed Human Geometry and Appearance Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Heming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+F">Fangneng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating controllable, photorealistic, and geometrically detailed digital
doubles of real humans solely from video data is a key challenge in Computer
Graphics and Vision, especially when real-time performance is required. Recent
methods attach a neural radiance field (NeRF) to an articulated structure,
e.g., a body model or a skeleton, to map points into a pose canonical space
while conditioning the NeRF on the skeletal pose. These approaches typically
parameterize the neural field with a multi-layer perceptron (MLP) leading to a
slow runtime. To address this drawback, we propose TriHuman a novel
human-tailored, deformable, and efficient tri-plane representation, which
achieves real-time performance, state-of-the-art pose-controllable geometry
synthesis as well as photorealistic rendering quality. At the core, we
non-rigidly warp global ray samples into our undeformed tri-plane texture
space, which effectively addresses the problem of global points being mapped to
the same tri-plane locations. We then show how such a tri-plane feature
representation can be conditioned on the skeletal motion to account for dynamic
appearance and geometry changes. Our results demonstrate a clear step towards
higher quality in terms of geometry and appearance modeling of humans as well
as runtime performance.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05162" title="Abstract">arXiv:2312.05162</a> [<a href="/pdf/2312.05162" title="Download PDF">pdf</a>, <a href="/format/2312.05162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Cooperation in Multi-agent Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Leibo%2C+J+Z">Joel Z. Leibo</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+U">Usman Islam</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+R">Richard Willis</a>, 
<a href="/search/cs?searchtype=author&query=Sunehag%2C+P">Peter Sunehag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cooperation in multi-agent learning (MAL) is a topic at the intersection of
numerous disciplines, including game theory, economics, social sciences, and
evolutionary biology. Research in this area aims to understand both how agents
can coordinate effectively when goals are aligned and how they may cooperate in
settings where gains from working together are possible but possibilities for
conflict abound. In this paper we provide an overview of the fundamental
concepts, problem settings and algorithms of multi-agent learning. This
encompasses reinforcement learning, multi-agent sequential decision-making,
challenges associated with multi-agent cooperation, and a comprehensive review
of recent progress, along with an evaluation of relevant metrics. Finally we
discuss open challenges in the field with the aim of inspiring new avenues for
research.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05166" title="Abstract">arXiv:2312.05166</a> [<a href="/pdf/2312.05166" title="Download PDF">pdf</a>, <a href="/format/2312.05166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning via Distributed MPC as a Function  Approximator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mallick%2C+S">Samuel Mallick</a>, 
<a href="/search/eess?searchtype=author&query=Airaldi%2C+F">Filippo Airaldi</a>, 
<a href="/search/eess?searchtype=author&query=Dabiri%2C+A">Azita Dabiri</a>, 
<a href="/search/eess?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel approach to multi-agent reinforcement learning
(RL) for linear systems with convex polytopic constraints. Existing works on RL
has demonstrated the use of model predictive control (MPC) as a function
approximator for the policy and value functions. The current paper is the first
work to extend this idea to the multi-agent setting. We propose the use of a
distributed MPC scheme as a function approximator, with a structure allowing
for distributed learning and deployment, while maintaining the properties of
centralized learning. The structured MPC scheme is introduced, and it is shown
that the global policy and value functions can be approximated in a fully
distributed manner. We then show that Q-learning updates can be performed
distributively without introducing nonstationarity, by reconstructing a
centralized learning update. The effectiveness of the approach is demonstrated
on an academic example and a power systems case study.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05171" title="Abstract">arXiv:2312.05171</a> [<a href="/pdf/2312.05171" title="Download PDF">pdf</a>, <a href="/format/2312.05171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DARLEI: Deep Accelerated Reinforcement Learning with Evolutionary  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+S">Saeejith Nair</a>, 
<a href="/search/cs?searchtype=author&query=Shafiee%2C+M+J">Mohammad Javad Shafiee</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We present DARLEI, a framework that combines evolutionary algorithms with
parallelized reinforcement learning for efficiently training and evolving
populations of UNIMAL agents. Our approach utilizes Proximal Policy
Optimization (PPO) for individual agent learning and pairs it with a tournament
selection-based generational learning mechanism to foster morphological
evolution. By building on Nvidia's Isaac Gym, DARLEI leverages GPU accelerated
simulation to achieve over 20x speedup using just a single workstation,
compared to previous work which required large distributed CPU clusters. We
systematically characterize DARLEI's performance under various conditions,
revealing factors impacting diversity of evolved morphologies. For example, by
enabling inter-agent collisions within the simulator, we find that we can
simulate some multi-agent interactions between the same morphology, and see how
it influences individual agent capabilities and long-term evolutionary
adaptation. While current results demonstrate limited diversity across
generations, we hope to extend DARLEI in future work to include interactions
between diverse morphologies in richer environments, and create a platform that
allows for coevolving populations and investigating emergent behaviours in
them. Our source code is also made publicly at
https://saeejithnair.github.io/darlei.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05172" title="Abstract">arXiv:2312.05172</a> [<a href="/pdf/2312.05172" title="Download PDF">pdf</a>, <a href="/format/2312.05172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Lengthy to Lucid: A Systematic Literature Review on NLP Techniques  for Taming Long Sentences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Passali%2C+T">Tatiana Passali</a>, 
<a href="/search/cs?searchtype=author&query=Chatzikyriakidis%2C+E">Efstathios Chatzikyriakidis</a>, 
<a href="/search/cs?searchtype=author&query=Andreadis%2C+S">Stelios Andreadis</a>, 
<a href="/search/cs?searchtype=author&query=Stavropoulos%2C+T+G">Thanos G. Stavropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Matonaki%2C+A">Anastasia Matonaki</a>, 
<a href="/search/cs?searchtype=author&query=Fachantidis%2C+A">Anestis Fachantidis</a>, 
<a href="/search/cs?searchtype=author&query=Tsoumakas%2C+G">Grigorios Tsoumakas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Author's Version, Submitted to ACM CSUR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Long sentences have been a persistent issue in written communication for many
years since they make it challenging for readers to grasp the main points or
follow the initial intention of the writer. This survey, conducted using the
PRISMA guidelines, systematically reviews two main strategies for addressing
the issue of long sentences: a) sentence compression and b) sentence splitting.
An increased trend of interest in this area has been observed since 2005, with
significant growth after 2017. Current research is dominated by supervised
approaches for both sentence compression and splitting. Yet, there is a
considerable gap in weakly and self-supervised techniques, suggesting an
opportunity for further research, especially in domains with limited data. In
this survey, we categorize and group the most representative methods into a
comprehensive taxonomy. We also conduct a comparative evaluation analysis of
these methods on common sentence compression and splitting datasets. Finally,
we discuss the challenges and limitations of current methods, providing
valuable insights for future research directions. This survey is meant to serve
as a comprehensive resource for addressing the complexities of long sentences.
We aim to enable researchers to make further advancements in the field until
long sentences are no longer a barrier to effective communication.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05178" title="Abstract">arXiv:2312.05178</a> [<a href="/pdf/2312.05178" title="Download PDF">pdf</a>, <a href="/format/2312.05178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Single-Frame Supervision for Better Temporal Action  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiashu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weikai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Knittel%2C+J">Johannes Knittel</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+S">Steffen Koch</a>, 
<a href="/search/cs?searchtype=author&query=Ertl%2C+T">Thomas Ertl</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shixia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Temporal action localization aims to identify the boundaries and categories
of actions in videos, such as scoring a goal in a football match. Single-frame
supervision has emerged as a labor-efficient way to train action localizers as
it requires only one annotated frame per action. However, it often suffers from
poor performance due to the lack of precise boundary annotations. To address
this issue, we propose a visual analysis method that aligns similar actions and
then propagates a few user-provided annotations (e.g. , boundaries, category
labels) to similar actions via the generated alignments. Our method models the
alignment between actions as a heaviest path problem and the annotation
propagation as a quadratic optimization problem. As the automatically generated
alignments may not accurately match the associated actions and could produce
inaccurate localization results, we develop a storyline visualization to
explain the localization results of actions and their alignments. This
visualization facilitates users in correcting wrong localization results and
misalignments. The corrections are then used to improve the localization
results of other actions. The effectiveness of our method in improving
localization performance is demonstrated through quantitative evaluation and a
case study.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05179" title="Abstract">arXiv:2312.05179</a> [<a href="/pdf/2312.05179" title="Download PDF">pdf</a>, <a href="/ps/2312.05179" title="Download PostScript">ps</a>, <a href="/format/2312.05179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Based Rendering Techniques: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anjos%2C+R+K+d">Rafael Kuffner dos Anjos</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J+M">Jo&#xe3;o Madeiras Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Gaspar%2C+J+A">Jos&#xe9; Antonio Gaspar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Three-dimensional reconstruction of events recorded on images has been a
common challenge between computer vision and computer graphics for a long time.
Estimating the real position of objects and surfaces using vision as an input
is no trivial task and has been approached in several different ways. Although
huge progress has been made so far, there are several open issues to which an
answer is needed. The use of videos as an input for a rendering process
(video-based rendering, VBR) is something that recently has been started to be
looked upon and has added many other challenges and also solutions to the
classical image-based rendering issue (IBR). This article presents the state of
art on video-based rendering and image-based techniques that can be applied on
this scenario, evaluating the open issues yet to be solved, indicating where
future work should be focused.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05180" title="Abstract">arXiv:2312.05180</a> [<a href="/pdf/2312.05180" title="Download PDF">pdf</a>, <a href="/format/2312.05180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PathFinder: Guided Search over Multi-Step Reasoning Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golovneva%2C+O">Olga Golovneva</a>, 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+S">Sean O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Pasunuru%2C+R">Ramakanth Pasunuru</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianlu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Fazel-Zarandi%2C+M">Maryam Fazel-Zarandi</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 R0-FoMo Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With recent advancements in large language models, methods like
chain-of-thought prompting to elicit reasoning chains have been shown to
improve results on reasoning tasks. However, tasks that require multiple steps
of reasoning still pose significant challenges to state-of-the-art models.
Drawing inspiration from the beam search algorithm, we propose PathFinder, a
tree-search-based reasoning path generation approach. It enhances diverse
branching and multi-hop reasoning through the integration of dynamic decoding,
enabled by varying sampling methods and parameters. Using constrained
reasoning, PathFinder integrates novel quality constraints, pruning, and
exploration methods to enhance the efficiency and the quality of generation.
Moreover, it includes scoring and ranking features to improve candidate
selection. Our approach outperforms competitive baselines on three complex
arithmetic and commonsense reasoning tasks by 6% on average. Our model
generalizes well to longer, unseen reasoning chains, reflecting similar
complexities to beam search with large branching factors.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05181" title="Abstract">arXiv:2312.05181</a> [<a href="/pdf/2312.05181" title="Download PDF">pdf</a>, <a href="/format/2312.05181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TENPLEX: Changing Resources of Deep Learning Jobs using Parallelizable  Tensor Collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagenl%C3%A4nder%2C+M">Marcel Wagenl&#xe4;nder</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+L">Luo Mai</a>, 
<a href="/search/cs?searchtype=author&query=Pietzuch%2C+P">Peter Pietzuch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning (DL) jobs use multi-dimensional parallelism, i.e they combine
data, model, and pipeline parallelism, to use large GPU clusters efficiently.
This couples jobs tightly to a set of GPU devices, but jobs may experience
changes to the device allocation: (i) resource elasticity during training adds
or removes devices; (ii) hardware maintenance may require redeployment on
different devices; and (iii) device failures force jobs to run with fewer
devices. Current DL frameworks lack support for these scenarios, as they cannot
change the multi-dimensional parallelism of an already-running job in an
efficient and model-independent way.
<br />We describe Tenplex, a state management library for DL frameworks that
enables jobs to change the GPU allocation and job parallelism at runtime.
Tenplex achieves this by externalizing the DL job state during training as a
parallelizable tensor collection (PTC). When the GPU allocation for the DL job
changes, Tenplex uses the PTC to transform the DL job state: for the dataset
state, Tenplex repartitions it under data parallelism and exposes it to workers
through a virtual file system; for the model state, Tenplex obtains it as
partitioned checkpoints and transforms them to reflect the new parallelization
configuration. For efficiency, these PTC transformations are executed in
parallel with a minimum amount of data movement between devices and workers.
Our experiments show that Tenplex enables DL jobs to support dynamic
parallelization with low overhead.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05183" title="Abstract">arXiv:2312.05183</a> [<a href="/pdf/2312.05183" title="Download PDF">pdf</a>, <a href="/format/2312.05183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Privacy-Preserving Framework for Cloud-Based HVAC Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhenan Feng</a>, 
<a href="/search/eess?searchtype=author&query=Nekouei%2C+E">Ehsan Nekouei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The objective of this work is (i) to develop an encrypted cloud-based HVAC
control framework to ensure the privacy of occupancy information, (ii) to
reduce the communication and computation costs of encrypted HVAC control.
Occupancy of a building is sensitive and private information that can be
accurately inferred by cloud-based HVAC controllers. To ensure the privacy of
the privacy information, in our framework, the measurements of an HVAC system
are encrypted by a fully homomorphic encryption prior to communication with the
cloud controller. We first develop an encrypted fast gradient algorithm that
allows the cloud controller to regulate the indoor temperature and CO$_2$ of a
building by solving two model predictive control problems. We next develop an
event-triggered control policy to reduce the communication and computation
costs of the encrypted HVAC control. We cast the optimal design of the
event-triggered policy as an optimal control problem wherein the objective is
to minimize a linear combination of the control and communication costs. Using
Bellman's optimality principle, we study the structural properties of the
optimal event-triggered policy and show that the optimal triggering policy is a
function of the current state, the last communicated state with the cloud, and
the time since the last communication with the cloud. We also show that the
optimal design of the event-triggered policy can be transformed into a Markov
decision process by introducing two new states. We finally study the
performance of the developed encrypted HVAC control framework using the TRNSYS
simulator. Our numerical results show that the proposed framework not only
ensures efficient control of the indoor temperature and CO$_2$ but also reduces
the computation and communication costs of encrypted HVAC control by at least
60%.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05185" title="Abstract">arXiv:2312.05185</a> [<a href="/pdf/2312.05185" title="Download PDF">pdf</a>, <a href="/ps/2312.05185" title="Download PostScript">ps</a>, <a href="/format/2312.05185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Competitions and Benchmarks: Competition platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ustyuzhanin%2C+A">Andrey Ustyuzhanin</a>, 
<a href="/search/cs?searchtype=author&query=Carlens%2C+H">Harald Carlens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The ecosystem of artificial intelligence competitions is a diverse and
multifaceted landscape, encompassing a variety of platforms that each host
numerous competitions annually, alongside a plethora of specialized websites
dedicated to singular contests. These platforms adeptly manage the overarching
administrative responsibilities inherent in orchestrating competitions, thus
affording organizers the liberty to allocate greater attention to other facets
of their contests. Notably, these platforms exhibit considerable diversity in
their operational functionalities, economic models, and community dynamics.
This chapter conducts an extensive review of the foremost services in this
realm and elucidates several alternative methodologies that facilitate the
independent hosting of such challenges. Keywords: competition platform,
challenge hosting services, comparison.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05187" title="Abstract">arXiv:2312.05187</a> [<a href="/pdf/2312.05187" title="Download PDF">pdf</a>, <a href="/format/2312.05187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seamless: Multilingual Expressive and Streaming Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Communication%2C+S">Seamless Communication</a>, 
<a href="/search/cs?searchtype=author&query=Barrault%2C+L">Lo&#xef;c Barrault</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+Y">Yu-An Chung</a>, 
<a href="/search/cs?searchtype=author&query=Meglioli%2C+M+C">Mariano Coria Meglioli</a>, 
<a href="/search/cs?searchtype=author&query=Dale%2C+D">David Dale</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Ning Dong</a>, 
<a href="/search/cs?searchtype=author&query=Duppenthaler%2C+M">Mark Duppenthaler</a>, 
<a href="/search/cs?searchtype=author&query=Duquenne%2C+P">Paul-Ambroise Duquenne</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+B">Brian Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Elsahar%2C+H">Hady Elsahar</a>, 
<a href="/search/cs?searchtype=author&query=Haaheim%2C+J">Justin Haaheim</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">John Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+M">Min-Jae Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Inaguma%2C+H">Hirofumi Inaguma</a>, 
<a href="/search/cs?searchtype=author&query=Klaiber%2C+C">Christopher Klaiber</a>, 
<a href="/search/cs?searchtype=author&query=Kulikov%2C+I">Ilia Kulikov</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Licht%2C+D">Daniel Licht</a>, 
<a href="/search/cs?searchtype=author&query=Maillard%2C+J">Jean Maillard</a>, 
<a href="/search/cs?searchtype=author&query=Mavlyutov%2C+R">Ruslan Mavlyutov</a>, 
<a href="/search/cs?searchtype=author&query=Rakotoarison%2C+A">Alice Rakotoarison</a>, 
<a href="/search/cs?searchtype=author&query=Sadagopan%2C+K+R">Kaushik Ram Sadagopan</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+A">Abinesh Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Tuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Wenzek%2C+G">Guillaume Wenzek</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yilin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+E">Ethan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Evtimov%2C+I">Ivan Evtimov</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+P">Pierre Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cynthia Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hansanti%2C+P">Prangthip Hansanti</a>, 
<a href="/search/cs?searchtype=author&query=Kalbassi%2C+E">Elahe Kalbassi</a>, 
<a href="/search/cs?searchtype=author&query=Kallet%2C+A">Amanda Kallet</a>, 
<a href="/search/cs?searchtype=author&query=Kozhevnikov%2C+A">Artyom Kozhevnikov</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+G+M">Gabriel Mejia Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Roman%2C+R+S">Robin San Roman</a>, 
<a href="/search/cs?searchtype=author&query=Touret%2C+C">Christophe Touret</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Corinne Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+C">Carleigh Wood</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bokai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+P">Pierre Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Balioglu%2C+C">Can Balioglu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng-Jen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Costa-juss%C3%A0%2C+M+R">Marta R. Costa-juss&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Elbayad%2C+M">Maha Elbayad</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">Hongyu Gong</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n%2C+F">Francisco Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Heffernan%2C+K">Kevin Heffernan</a>,  et al. (17 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Large-scale automatic speech translation systems today lack key features that
help machine-mediated communication feel seamless when compared to
human-to-human dialogue. In this work, we introduce a family of models that
enable end-to-end expressive and multilingual translations in a streaming
fashion. First, we contribute an improved version of the massively multilingual
and multimodal SeamlessM4T model-SeamlessM4T v2. This newer model,
incorporating an updated UnitY2 framework, was trained on more low-resource
language data. SeamlessM4T v2 provides the foundation on which our next two
models are initiated. SeamlessExpressive enables translation that preserves
vocal styles and prosody. Compared to previous efforts in expressive speech
research, our work addresses certain underexplored aspects of prosody, such as
speech rate and pauses, while also preserving the style of one's voice. As for
SeamlessStreaming, our model leverages the Efficient Monotonic Multihead
Attention mechanism to generate low-latency target translations without waiting
for complete source utterances. As the first of its kind, SeamlessStreaming
enables simultaneous speech-to-speech/text translation for multiple source and
target languages. To ensure that our models can be used safely and responsibly,
we implemented the first known red-teaming effort for multimodal machine
translation, a system for the detection and mitigation of added toxicity, a
systematic evaluation of gender bias, and an inaudible localized watermarking
mechanism designed to dampen the impact of deepfakes. Consequently, we bring
major components from SeamlessExpressive and SeamlessStreaming together to form
Seamless, the first publicly available system that unlocks expressive
cross-lingual communication in real-time. The contributions to this work are
publicly released and accessible at
https://github.com/facebookresearch/seamless_communication
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05189" title="Abstract">arXiv:2312.05189</a> [<a href="/pdf/2312.05189" title="Download PDF">pdf</a>, <a href="/format/2312.05189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Autonomous Organizations as Public Services Supplying  Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Gasperis%2C+G">Giovanni De Gasperis</a>, 
<a href="/search/cs?searchtype=author&query=Facchini%2C+S+D">Sante Dino Facchini</a>, 
<a href="/search/cs?searchtype=author&query=Michilli%2C+M">Maurizio Michilli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 8th Italian Conference on ICT for Smart Cities And Communities, 14-16 September 2022 - University of Camerino - Ascoli Piceno, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Servizi Elaborazioni Dati SpA is a public company owned by Municipality of L
Aquila, it supplies the institution with network services and software
applications for distributing services to citizens. The future policy of the
company is to enlarge the offer of its services to nearby communities that are
unable to set up and maintain their own network and software structures. This
paper presents thus a possible architecture model to support small
municipalities in supplying public services to citizens, with the aid of SED
Spa. Through second level platforms based on Blockchain networks and
Multi-agents Systems running on smart contracts, the system will focus on Waste
Tax (Ta.Ri) management system in the Fascicolo del Cittadino environment.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05190" title="Abstract">arXiv:2312.05190</a> [<a href="/pdf/2312.05190" title="Download PDF">pdf</a>, <a href="/format/2312.05190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine Dense Alignment of Image Bursts through Camera Pose and Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lecouat%2C+B">Bruno Lecouat</a>, 
<a href="/search/cs?searchtype=author&query=de+Mont-Marin%2C+Y+D">Yann Dubois de Mont-Marin</a>, 
<a href="/search/cs?searchtype=author&query=Bodrito%2C+T">Th&#xe9;o Bodrito</a>, 
<a href="/search/cs?searchtype=author&query=Mairal%2C+J">Julien Mairal</a>, 
<a href="/search/cs?searchtype=author&query=Ponce%2C+J">Jean Ponce</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel approach to the fine alignment of images in a
burst captured by a handheld camera. In contrast to traditional techniques that
estimate two-dimensional transformations between frame pairs or rely on
discrete correspondences, the proposed algorithm establishes dense
correspondences by optimizing both the camera motion and surface depth and
orientation at every pixel. This approach improves alignment, particularly in
scenarios with parallax challenges. Extensive experiments with synthetic bursts
featuring small and even tiny baselines demonstrate that it outperforms the
best optical flow methods available today in this setting, without requiring
any training. Beyond enhanced alignment, our method opens avenues for tasks
beyond simple image restoration, such as depth estimation and 3D
reconstruction, as supported by promising preliminary results. This positions
our approach as a versatile tool for various burst image processing
applications.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05195" title="Abstract">arXiv:2312.05195</a> [<a href="/pdf/2312.05195" title="Download PDF">pdf</a>, <a href="/format/2312.05195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Prediction in Multi-User Settings: An Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Ceja%2C+E">Enrique Garcia-Ceja</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Banuelos%2C+L">Luciano Garcia-Banuelos</a>, 
<a href="/search/cs?searchtype=author&query=Jourdan%2C+N">Nicolas Jourdan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Typically, machine learning models are trained and evaluated without making
any distinction between users (e.g, using traditional hold-out and
cross-validation). However, this produces inaccurate performance metrics
estimates in multi-user settings. That is, situations where the data were
collected by multiple users with different characteristics (e.g., age, gender,
height, etc.) which is very common in user computer interaction and medical
applications. For these types of scenarios model evaluation strategies that
provide better performance estimates have been proposed such as mixed,
user-independent, user-dependent, and user-adaptive models. Although those
strategies are better suited for multi-user systems, they are typically
assessed with respect to performance metrics that capture the overall behavior
of the models and do not provide any performance guarantees for individual
predictions nor they provide any feedback about the predictions' uncertainty.
In order to overcome those limitations, in this work we evaluated the conformal
prediction framework in several multi-user settings. Conformal prediction is a
model agnostic method that provides confidence guarantees on the predictions,
thus, increasing the trustworthiness and robustness of the models. We conducted
extensive experiments using different evaluation strategies and found
significant differences in terms of conformal performance measures. We also
proposed several visualizations based on matrices, graphs, and charts that
capture different aspects of the resulting prediction sets.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05198" title="Abstract">arXiv:2312.05198</a> [<a href="/pdf/2312.05198" title="Download PDF">pdf</a>, <a href="/format/2312.05198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fluidic FlowBots: Intelligence embodied in the characteristics of  recirculating fluid flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gepner%2C+M">Maks Gepner</a>, 
<a href="/search/cs?searchtype=author&query=Mack%2C+J">Jonah Mack</a>, 
<a href="/search/cs?searchtype=author&query=Giorgio-Serchi%2C+F">Francesco Giorgio-Serchi</a>, 
<a href="/search/cs?searchtype=author&query=Stokes%2C+A+A">Adam A. Stokes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 and a half pages, 6 figures, pre-print submitted to RoboSoft 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The one-to-one mapping of control inputs to actuator outputs results in
elaborate routing architectures that limit how complex fluidic soft robot
behaviours can currently become. Embodied intelligence can be used as a tool to
counteract this phenomenon. Control functionality can be embedded directly into
actuators by leveraging the characteristics of fluid flow phenomena. Whilst
prior soft robotics work has focused exclusively on actuators operating in a
state of transient/no flow (constant pressure), or pulsatile/alternating flow,
our work begins to explore the possibilities granted by operating in the
closed-loop flow recirculation regime. Here we introduce the concept of
FlowBots: soft robots that utilise the characteristics of continuous fluid flow
to enable the embodiment of complex control functionality directly into the
structure of the robot. FlowBots have robust, integrated, no-moving-part
control systems, and these architectures enable: monolithic additive
manufacturing methods, rapid prototyping, greater sustainability, and an
expansive range of applications. Based on three FlowBot examples: a
bidirectional actuator, a gripper, and a quadruped swimmer - we demonstrate how
the characteristics of flow recirculation contribute to simplifications in
fluidic analogue control architectures. We conclude by outlining our design and
rapid prototyping methodology to empower others in the field to explore this
new, emerging design field, and design their own FlowBots.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05200" title="Abstract">arXiv:2312.05200</a> [<a href="/pdf/2312.05200" title="Download PDF">pdf</a>, <a href="/format/2312.05200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DelucionQA: Detecting Hallucinations in Domain-specific Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadat%2C+M">Mobashir Sadat</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+L">Lukas Lange</a>, 
<a href="/search/cs?searchtype=author&query=Araki%2C+J">Jun Araki</a>, 
<a href="/search/cs?searchtype=author&query=Gundroo%2C+A">Arsalan Gundroo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+R+R">Rakesh R Menon</a>, 
<a href="/search/cs?searchtype=author&query=Parvez%2C+M+R">Md Rizwan Parvez</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhe Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Hallucination is a well-known phenomenon in text generated by large language
models (LLMs). The existence of hallucinatory responses is found in almost all
application scenarios e.g., summarization, question-answering (QA) etc. For
applications requiring high reliability (e.g., customer-facing assistants), the
potential existence of hallucination in LLM-generated text is a critical
problem. The amount of hallucination can be reduced by leveraging information
retrieval to provide relevant background information to the LLM. However, LLMs
can still generate hallucinatory content for various reasons (e.g.,
prioritizing its parametric knowledge over the context, failure to capture the
relevant information from the context, etc.). Detecting hallucinations through
automated methods is thus paramount. To facilitate research in this direction,
we introduce a sophisticated dataset, DelucionQA, that captures hallucinations
made by retrieval-augmented LLMs for a domain-specific QA task. Furthermore, we
propose a set of hallucination detection methods to serve as baselines for
future works from the research community. Analysis and case study are also
provided to share valuable insights on hallucination phenomena in the target
scenario.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05208" title="Abstract">arXiv:2312.05208</a> [<a href="/pdf/2312.05208" title="Download PDF">pdf</a>, <a href="/format/2312.05208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlRoom3D: Room Generation using Semantic Proxy Rooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schult%2C+J">Jonas Schult</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+S">Sam Tsai</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6llein%2C+L">Lukas H&#xf6;llein</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chih-Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wimbauer%2C+F">Felix Wimbauer</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zijian He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Leibe%2C+B">Bastian Leibe</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://jonasschult.github.io/ControlRoom3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Manually creating 3D environments for AR/VR applications is a complex process
requiring expert knowledge in 3D modeling software. Pioneering works facilitate
this process by generating room meshes conditioned on textual style
descriptions. Yet, many of these automatically generated 3D meshes do not
adhere to typical room layouts, compromising their plausibility, e.g., by
placing several beds in one bedroom. To address these challenges, we present
ControlRoom3D, a novel method to generate high-quality room meshes. Central to
our approach is a user-defined 3D semantic proxy room that outlines a rough
room layout based on semantic bounding boxes and a textual description of the
overall room style. Our key insight is that when rendered to 2D, this 3D
representation provides valuable geometric and semantic information to control
powerful 2D models to generate 3D consistent textures and geometry that aligns
well with the proxy room. Backed up by an extensive study including
quantitative metrics and qualitative user evaluations, our method generates
diverse and globally plausible 3D room meshes, thus empowering users to design
3D rooms effortlessly without specialized knowledge.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05209" title="Abstract">arXiv:2312.05209</a> [<a href="/pdf/2312.05209" title="Download PDF">pdf</a>, <a href="/format/2312.05209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HALO: An Ontology for Representing Hallucinations in Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nananukul%2C+N">Navapat Nananukul</a>, 
<a href="/search/cs?searchtype=author&query=Kejriwal%2C+M">Mayank Kejriwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent progress in generative AI, including large language models (LLMs) like
ChatGPT, has opened up significant opportunities in fields ranging from natural
language processing to knowledge discovery and data mining. However, there is
also a growing awareness that the models can be prone to problems such as
making information up or `hallucinations', and faulty reasoning on seemingly
simple problems. Because of the popularity of models like ChatGPT, both
academic scholars and citizen scientists have documented hallucinations of
several different types and severity. Despite this body of work, a formal model
for describing and representing these hallucinations (with relevant meta-data)
at a fine-grained level, is still lacking. In this paper, we address this gap
by presenting the Hallucination Ontology or HALO, a formal, extensible ontology
written in OWL that currently offers support for six different types of
hallucinations known to arise in LLMs, along with support for provenance and
experimental metadata. We also collect and publish a dataset containing
hallucinations that we inductively gathered across multiple independent Web
sources, and show that HALO can be successfully used to model this dataset and
answer competency questions.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05210" title="Abstract">arXiv:2312.05210</a> [<a href="/pdf/2312.05210" title="Download PDF">pdf</a>, <a href="/format/2312.05210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans  from Monocular Videos via Explicit Ray Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+B">Bo&#x17e;idar Anti&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures. Project page: <a href="https://neuralbodies.github.io/IntrinsicAvatar">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present IntrinsicAvatar, a novel approach to recovering the intrinsic
properties of clothed human avatars including geometry, albedo, material, and
environment lighting from only monocular videos. Recent advancements in
human-based neural rendering have enabled high-quality geometry and appearance
reconstruction of clothed humans from just monocular videos. However, these
methods bake intrinsic properties such as albedo, material, and environment
lighting into a single entangled neural representation. On the other hand, only
a handful of works tackle the problem of estimating geometry and disentangled
appearance properties of clothed humans from monocular videos. They usually
achieve limited quality and disentanglement due to approximations of secondary
shading effects via learned MLPs. In this work, we propose to model secondary
shading effects explicitly via Monte-Carlo ray tracing. We model the rendering
process of clothed humans as a volumetric scattering process, and combine ray
tracing with body articulation. Our approach can recover high-quality geometry,
albedo, material, and lighting properties of clothed humans from a single
monocular video, without requiring supervised pre-training using ground truth
materials. Furthermore, since we explicitly model the volumetric scattering
process and ray tracing, our model naturally generalizes to novel poses,
enabling animation of the reconstructed avatar in novel lighting conditions.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05212" title="Abstract">arXiv:2312.05212</a> [<a href="/pdf/2312.05212" title="Download PDF">pdf</a>, <a href="/format/2312.05212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Normally-off In-Situ Computing with a Magneto-Electric  FET-based SRAM Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Najafi%2C+D">Deniz Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Morsali%2C+M">Mehrdad Morsali</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ranyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Roohi%2C+A">Arman Roohi</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+A">Andrew Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Durga Misra</a>, 
<a href="/search/cs?searchtype=author&query=Angizi%2C+S">Shaahin Angizi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 10 Figures, 4 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">As an emerging post-CMOS Field Effect Transistor, Magneto-Electric FETs
(MEFETs) offer compelling design characteristics for logic and memory
applications, such as high-speed switching, low power consumption, and
non-volatility. In this paper, for the first time, a non-volatile MEFET-based
SRAM design named ME-SRAM is proposed for edge applications which can
remarkably save the SRAM static power consumption in the idle state through a
fast backup-restore process. To enable normally-off in-situ computing, the
ME-SRAM cell is integrated into a novel processing-in-SRAM architecture that
exploits a hardware-optimized bit-line computing approach for the execution of
Boolean logic operations between operands housed in a memory sub-array within a
single clock cycle. Our device-to-architecture evaluation results on Binary
convolutional neural network acceleration show the robust performance of ME-
SRAM while reducing energy consumption on average by a factor of 5.3 times
compared to the best in-SRAM designs.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05213" title="Abstract">arXiv:2312.05213</a> [<a href="/pdf/2312.05213" title="Download PDF">pdf</a>, <a href="/format/2312.05213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Consensus on Spectrum Usage in the Presence of Faults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mollakhani%2C+A">Arman Mollakhani</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongning Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">A consensus mechanism is proposed to facilitate radio spectrum sharing with
accountability in a network of multiple operators, a subset of which may even
be adversarial. A distributed ledger is used to securely record and keep track
of the state of consensus on spectrum usage, including interference incidents
and the corresponding responsible parties. A key challenge is that the
operators generally do not have initial agreement due to noise in their analog
measurements. To meet this challenge, two categories of spectrum-sharing
solutions are studied in detail. The first category employs an exact Byzantine
fault tolerant (BFT) agreement model; the second category utilizes an
approximate BFT agreement model. This paper also delves into the application of
consensus protocols to the specific context of low Earth orbit (LEO)
non-geostationary satellite networks, also known as mega-constellations.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05215" title="Abstract">arXiv:2312.05215</a> [<a href="/pdf/2312.05215" title="Download PDF">pdf</a>, <a href="/format/2312.05215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeltaZip: Multi-Tenant Language Model Serving via Delta Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiaozhe Yao</a>, 
<a href="/search/cs?searchtype=author&query=Klimovic%2C+A">Ana Klimovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fine-tuning large language models (LLMs) for downstream tasks can greatly
improve model quality, however serving many different fine-tuned LLMs
concurrently for users in multi-tenant environments is challenging. Dedicating
GPU memory for each model is prohibitively expensive and naively swapping large
model weights in and out of GPU memory is slow. Our key insight is that
fine-tuned models can be quickly swapped in and out of GPU memory by extracting
and compressing the delta between each model and its pre-trained base model. We
propose DeltaZip, an LLM serving system that efficiently serves multiple
full-parameter fine-tuned models concurrently by aggressively compressing model
deltas by a factor of $6\times$ to $8\times$ while maintaining high model
quality. DeltaZip increases serving throughput by $1.5\times$ to $3\times$ and
improves SLO attainment compared to a vanilla HuggingFace serving system.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05219" title="Abstract">arXiv:2312.05219</a> [<a href="/pdf/2312.05219" title="Download PDF">pdf</a>, <a href="/format/2312.05219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Facial Classification and Recognition using 3D Facial Models  and Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houting Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mengxuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lui%2C+L+M">Lok Ming Lui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1903.08527">arXiv:1903.08527</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate analysis and classification of facial attributes are essential in
various applications, from human-computer interaction to security systems. In
this work, a novel approach to enhance facial classification and recognition
tasks through the integration of 3D facial models with deep learning methods
was proposed. We extract the most useful information for various tasks using
the 3D Facial Model, leading to improved classification accuracy. Combining 3D
facial insights with ResNet architecture, our approach achieves notable
results: 100% individual classification, 95.4% gender classification, and 83.5%
expression classification accuracy. This method holds promise for advancing
facial analysis and recognition research.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05225" title="Abstract">arXiv:2312.05225</a> [<a href="/pdf/2312.05225" title="Download PDF">pdf</a>, <a href="/format/2312.05225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Spectral Methods: Self-supervised learning in the spectral domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yiheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Chalapathi%2C+N">Nithin Chalapathi</a>, 
<a href="/search/cs?searchtype=author&query=Krishnapriyan%2C+A">Aditi Krishnapriyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present Neural Spectral Methods, a technique to solve parametric Partial
Differential Equations (PDEs), grounded in classical spectral methods. Our
method uses orthogonal bases to learn PDE solutions as mappings between
spectral coefficients. In contrast to current machine learning approaches which
enforce PDE constraints by minimizing the numerical quadrature of the residuals
in the spatiotemporal domain, we leverage Parseval's identity and introduce a
new training strategy through a \textit{spectral loss}. Our spectral loss
enables more efficient differentiation through the neural network, and
substantially reduces training complexity. At inference time, the computational
cost of our method remains constant, regardless of the spatiotemporal
resolution of the domain. Our experimental results demonstrate that our method
significantly outperforms previous machine learning approaches in terms of
speed and accuracy by one to two orders of magnitude on multiple different
problems. When compared to numerical solvers of the same accuracy, our method
demonstrates a $10\times$ increase in performance speed.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05229" title="Abstract">arXiv:2312.05229</a> [<a href="/pdf/2312.05229" title="Download PDF">pdf</a>, <a href="/format/2312.05229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Class-Incremental Learning via Training-Free Prototype  Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi-Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Da-Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi-Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-Chuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Han-Jia Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Code is available at: <a href="https://github.com/wangkiw/TEEN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-world scenarios are usually accompanied by continuously appearing
classes with scare labeled samples, which require the machine learning model to
incrementally learn new classes and maintain the knowledge of base classes. In
this Few-Shot Class-Incremental Learning (FSCIL) scenario, existing methods
either introduce extra learnable components or rely on a frozen feature
extractor to mitigate catastrophic forgetting and overfitting problems.
However, we find a tendency for existing methods to misclassify the samples of
new classes into base classes, which leads to the poor performance of new
classes. In other words, the strong discriminability of base classes distracts
the classification of new classes. To figure out this intriguing phenomenon, we
observe that although the feature extractor is only trained on base classes, it
can surprisingly represent the semantic similarity between the base and unseen
new classes. Building upon these analyses, we propose a simple yet effective
Training-frEE calibratioN (TEEN) strategy to enhance the discriminability of
new classes by fusing the new prototypes (i.e., mean features of a class) with
weighted base prototypes. In addition to standard benchmarks in FSCIL, TEEN
demonstrates remarkable performance and consistent improvements over baseline
methods in the few-shot learning scenario. Code is available at:
https://github.com/wangkiw/TEEN
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05230" title="Abstract">arXiv:2312.05230</a> [<a href="/pdf/2312.05230" title="Download PDF">pdf</a>, <a href="/format/2312.05230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models, Agent Models, and World Models: The LAW for Machine  Reasoning and Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+T">Tianmin Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Position paper. Accompanying NeurIPS2023 Tutorial: <a href="https://sites.google.com/view/neurips2023law/home">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Despite their tremendous success in many applications, large language models
often fall short of consistent reasoning and planning in various (language,
embodied, and social) scenarios, due to inherent limitations in their
inference, learning, and modeling capabilities. In this position paper, we
present a new perspective of machine reasoning, LAW, that connects the concepts
of Language models, Agent models, and World models, for more robust and
versatile reasoning capabilities. In particular, we propose that world and
agent models are a better abstraction of reasoning, that introduces the crucial
elements of deliberate human-like reasoning, including beliefs about the world
and other agents, anticipation of consequences, goals/rewards, and strategic
planning. Crucially, language models in LAW serve as a backend to implement the
system or its elements and hence provide the computational power and
adaptability. We review the recent studies that have made relevant progress and
discuss future research directions towards operationalizing the LAW framework.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05231" title="Abstract">arXiv:2312.05231</a> [<a href="/pdf/2312.05231" title="Download PDF">pdf</a>, <a href="/format/2312.05231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Risk in Reinforcement Learning: A Literature Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villalobos-Arias%2C+L">Leonardo Villalobos-Arias</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+D">Derek Martin</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+A">Abhijeet Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Gagn%C3%A9%2C+M">Madeleine Gagn&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+C+M">Colin M. Potts</a>, 
<a href="/search/cs?searchtype=author&query=Jhala%2C+A">Arnav Jhala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 8 figures, Submitted to Artificial Intelligence Reviews
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Safe reinforcement learning deals with mitigating or avoiding unsafe
situations by reinforcement learning (RL) agents. Safe RL approaches are based
on specific risk representations for particular problems or domains. In order
to analyze agent behaviors, compare safe RL approaches, and effectively
transfer techniques between application domains, it is necessary to understand
the types of risk specific to safe RL problems. We performed a systematic
literature mapping with the objective to characterize risk in safe RL. Based on
the obtained results, we present definitions, characteristics, and types of
risk that hold on multiple application domains. Our literature mapping covers
literature from the last 5 years (2017-2022), from a variety of knowledge areas
(AI, finance, engineering, medicine) where RL approaches emphasize risk
representation and management. Our mapping covers 72 papers filtered
systematically from over thousands of papers on the topic. Our proposed notion
of risk covers a variety of representations, disciplinary differences, common
training exercises, and types of techniques. We encourage researchers to
include explicit and detailed accounts of risk in future safe RL research
reports, using this mapping as a starting point. With this information,
researchers and practitioners could draw stronger conclusions on the
effectiveness of techniques on different problems.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05232" title="Abstract">arXiv:2312.05232</a> [<a href="/pdf/2312.05232" title="Download PDF">pdf</a>, <a href="/ps/2312.05232" title="Download PostScript">ps</a>, <a href="/format/2312.05232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Entropy Correction with SIAC Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Picklo%2C+M+J">Matthew J. Picklo</a>, 
<a href="/search/math?searchtype=author&query=Edoh%2C+A+K">Ayaboe K. Edoh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This article considers the application of Smoothness-Increasing
Accuracy-Conserving (SIAC) filtering for the non-linear stabilization of
discontinuous Galerkin (DG) discretizations via entropy correction. Upon
constructing discrete filters from continuous convolution SIAC kernels, the
schemes are made to be conservative and are then appended to the DG method in a
semi-discrete fashion. Performance of these tunable SIAC filters is compared to
the local averaging typically employed in the entropy correction of finite
element methods, and their capabilities are demonstrated for energy
conservation as well as a shock regularization strategy based on an artificial
viscosity estimate. Relaxation Runge-Kutta time integration methods are further
employed in order to ensure a fully-discrete energy preserving procedure, with
impacts of the overall solution accuracy being investigated for calculations of
the one- and two-dimensional Burgers equation.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05235" title="Abstract">arXiv:2312.05235</a> [<a href="/pdf/2312.05235" title="Download PDF">pdf</a>, <a href="/ps/2312.05235" title="Download PostScript">ps</a>, <a href="/format/2312.05235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing ChatGPT Through Universities&#x27; Policies, Resources and Guidelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+A">Anh Dang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mac%2C+S">Son Mac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The advancements in Artificial Intelligence (AI) technologies such as ChatGPT
have gained popularity in recent days. The integration of ChatGPT in
educational contexts has already created attractions due to a wide range of
applications. However, the automatic generation of human-like texts also poses
potential risks to academic integrity, especially when faced with
writing-intensive language courses. Considering the ongoing debates, this study
aims to investigate the academic policies and guidelines established by US
universities regarding the use of ChatGPT in teaching and learning. The data
sources include academic policies, statements, guidelines as well as relevant
resources that were provided by the top 50 universities in the United States,
according to U.S. News. Thematic analysis and qualitative analysis were
employed in the analysis and showed that most top 50 universities were open but
cautious towards the integration of generative AI in teaching and learning and
also expressed their concerns on ethical usage, accuracy, and data privacy.
Most universities also provided a variety of resources and guidelines,
including syllabus templates/samples, workshops and discussions, shared
articles, and one-on-one consultations, with focuses on general technical
introduction, ethical concerns, pedagogical applications, preventive
strategies, data privacy, limitations, and detective tools. The findings will
inform future policy-making regarding the integration of ChatGPT in
college-level education and influence the provision of supportive resources by
universities for the appropriate application of ChatGPT in education.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05239" title="Abstract">arXiv:2312.05239</a> [<a href="/pdf/2312.05239" title="Download PDF">pdf</a>, <a href="/format/2312.05239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational  Score Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thuan Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://thuanz123.github.io/swiftbrush/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite their ability to generate high-resolution and diverse images from
text prompts, text-to-image diffusion models often suffer from slow iterative
sampling processes. Model distillation is one of the most effective directions
to accelerate these models. However, previous distillation methods fail to
retain the generation quality while requiring a significant amount of images
for training, either from real data or synthetically generated by the teacher
model. In response to this limitation, we present a novel image-free
distillation scheme named $\textbf{SwiftBrush}$. Drawing inspiration from
text-to-3D synthesis, in which a 3D neural radiance field that aligns with the
input prompt can be obtained from a 2D text-to-image diffusion prior via a
specialized loss without the use of any 3D data ground-truth, our approach
re-purposes that same loss for distilling a pretrained multi-step text-to-image
model to a student network that can generate high-fidelity images with just a
single inference step. In spite of its simplicity, our model stands as one of
the first one-step text-to-image generators that can produce images of
comparable quality to Stable Diffusion without reliance on any training image
data. Remarkably, SwiftBrush achieves an FID score of $\textbf{16.67}$ and a
CLIP score of $\textbf{0.29}$ on the COCO-30K benchmark, achieving competitive
results or even substantially surpassing existing state-of-the-art distillation
techniques.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05241" title="Abstract">arXiv:2312.05241</a> [<a href="/pdf/2312.05241" title="Download PDF">pdf</a>, <a href="/ps/2312.05241" title="Download PostScript">ps</a>, <a href="/format/2312.05241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contra generative AI detection in higher education assessments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ardito%2C+C+G">Cesare G. Ardito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper presents a critical analysis of generative Artificial Intelligence
(AI) detection tools in higher education assessments. The rapid advancement and
widespread adoption of generative AI, particularly in education, necessitates a
reevaluation of traditional academic integrity mechanisms. We explore the
effectiveness, vulnerabilities, and ethical implications of AI detection tools
in the context of preserving academic integrity. Our study synthesises insights
from various case studies, newspaper articles, and student testimonies to
scrutinise the practical and philosophical challenges associated with AI
detection. We argue that the reliance on detection mechanisms is misaligned
with the educational landscape, where AI plays an increasingly widespread role.
This paper advocates for a strategic shift towards robust assessment methods
and educational policies that embrace generative AI usage while ensuring
academic integrity and authenticity in assessments.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05243" title="Abstract">arXiv:2312.05243</a> [<a href="/pdf/2312.05243" title="Download PDF">pdf</a>, <a href="/format/2312.05243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Model-free Safety Verification for Markov Decision Processes  Without Safety Violation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mazumdar%2C+A">Abhijit Mazumdar</a>, 
<a href="/search/eess?searchtype=author&query=Wisniewski%2C+R">Rafal Wisniewski</a>, 
<a href="/search/eess?searchtype=author&query=Bujorianu%2C+M+L">Manuela L. Bujorianu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we consider the problem of safety assessment for Markov
decision processes without explicit knowledge of the model. We aim to learn
probabilistic safety specifications associated with a given policy without
compromising the safety of the process. To accomplish our goal, we characterize
a subset of the state-space called proxy set, which contains the states that
are near in a probabilistic sense to the forbidden set consisting of all unsafe
states. We compute the safety function using the single-step temporal
difference method. To this end, we relate the safety function computation to
that of the value function estimation using temporal difference learning. Since
the given control policy could be unsafe, we use a safe baseline subpolicy to
generate data for learning. We then use an off-policy temporal difference
learning method with importance sampling to learn the safety function
corresponding to the given policy. Finally, we demonstrate our results using a
numerical example
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05247" title="Abstract">arXiv:2312.05247</a> [<a href="/pdf/2312.05247" title="Download PDF">pdf</a>, <a href="/format/2312.05247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic LiDAR Re-simulation using Compositional Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+X">Xingxing Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Litany%2C+O">Or Litany</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shengyu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://shengyuh.github.io/dynfl/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce DyNFL, a novel neural field-based approach for high-fidelity
re-simulation of LiDAR scans in dynamic driving scenes. DyNFL processes LiDAR
measurements from dynamic environments, accompanied by bounding boxes of moving
objects, to construct an editable neural field. This field, comprising
separately reconstructed static backgrounds and dynamic objects, allows users
to modify viewpoints, adjust object positions, and seamlessly add or remove
objects in the re-simulated scene. A key innovation of our method is the neural
field composition technique, which effectively integrates reconstructed neural
assets from various scenes through a ray drop test, accounting for occlusions
and transparent surfaces. Our evaluation with both synthetic and real-world
environments demonstrates that \ShortName substantial improves dynamic scene
simulation based on LiDAR scans, offering a combination of physical fidelity
and flexible editing capabilities.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05248" title="Abstract">arXiv:2312.05248</a> [<a href="/pdf/2312.05248" title="Download PDF">pdf</a>, <a href="/ps/2312.05248" title="Download PostScript">ps</a>, <a href="/format/2312.05248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Based Reconstruction Prevention for Decentralised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dekker%2C+F+W">Florine W. Dekker</a> (1), 
<a href="/search/cs?searchtype=author&query=Erkin%2C+Z">Zekeriya Erkin</a> (1), 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a> (2 and 1) ((1) Delft University of Technology, the Netherlands and (2) Universit&#xe0; di Padova, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures, submitted to IEEE S&amp;P 2024, for associated experiment source code see doi:10.4121/21572601
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Decentralised learning has recently gained traction as an alternative to
federated learning in which both data and coordination are distributed over its
users. To preserve the confidentiality of users' data, decentralised learning
relies on differential privacy, multi-party computation, or a combination
thereof. However, running multiple privacy-preserving summations in sequence
may allow adversaries to perform reconstruction attacks. Unfortunately, current
reconstruction countermeasures either cannot trivially be adapted to the
distributed setting, or add excessive amounts of noise.
<br />In this work, we first show that passive honest-but-curious adversaries can
reconstruct other users' private data after several privacy-preserving
summations. For example, in subgraphs with 18 users, we show that only three
passive honest-but-curious adversaries succeed at reconstructing private data
11.0% of the time, requiring an average of 8.8 summations per adversary. The
success rate is independent of the size of the full network. We consider weak
adversaries, who do not control the graph topology and can exploit neither the
workings of the summation protocol nor the specifics of users' data.
<br />We develop a mathematical understanding of how reconstruction relates to
topology and propose the first topology-based decentralised defence against
reconstruction attacks. Specifically, we show that reconstruction requires a
number of adversaries linear in the length of the network's shortest cycle.
Consequently, reconstructing private data from privacy-preserving summations is
impossible in acyclic networks.
<br />Our work is a stepping stone for a formal theory of decentralised
reconstruction defences based on topology. Such a theory would generalise our
countermeasure beyond summation, define confidentiality in terms of entropy,
and describe the effects of (topology-aware) differential privacy.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05250" title="Abstract">arXiv:2312.05250</a> [<a href="/pdf/2312.05250" title="Download PDF">pdf</a>, <a href="/format/2312.05250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaskMet: Task-Driven Metric Learning for Model Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+D">Dishank Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mukadam%2C+M">Mustafa Mukadam</a>, 
<a href="/search/cs?searchtype=author&query=Amos%2C+B">Brandon Amos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep learning models are often deployed in downstream tasks that the training
procedure may not be aware of. For example, models solely trained to achieve
accurate predictions may struggle to perform well on downstream tasks because
seemingly small prediction errors may incur drastic task errors. The standard
end-to-end learning approach is to make the task loss differentiable or to
introduce a differentiable surrogate that the model can be trained on. In these
settings, the task loss needs to be carefully balanced with the prediction loss
because they may have conflicting objectives. We propose take the task loss
signal one level deeper than the parameters of the model and use it to learn
the parameters of the loss function the model is trained on, which can be done
by learning a metric in the prediction space. This approach does not alter the
optimal prediction model itself, but rather changes the model learning to
emphasize the information important for the downstream task. This enables us to
achieve the best of both worlds: a prediction model trained in the original
prediction space while also being valuable for the desired downstream task. We
validate our approach through experiments conducted in two main settings: 1)
decision-focused model learning scenarios involving portfolio optimization and
budget allocation, and 2) reinforcement learning in noisy environments with
distracting states. The source code to reproduce our experiments is available
at https://github.com/facebookresearch/taskmet
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05251" title="Abstract">arXiv:2312.05251</a> [<a href="/pdf/2312.05251" title="Download PDF">pdf</a>, <a href="/format/2312.05251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Hands in 3D with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlakos%2C+G">Georgios Pavlakos</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+D">Dandan Shan</a>, 
<a href="/search/cs?searchtype=author&query=Radosavovic%2C+I">Ilija Radosavovic</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Fouhey%2C+D">David Fouhey</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present an approach that can reconstruct hands in 3D from monocular input.
Our approach for Hand Mesh Recovery, HaMeR, follows a fully transformer-based
architecture and can analyze hands with significantly increased accuracy and
robustness compared to previous work. The key to HaMeR's success lies in
scaling up both the data used for training and the capacity of the deep network
for hand reconstruction. For training data, we combine multiple datasets that
contain 2D or 3D hand annotations. For the deep model, we use a large scale
Vision Transformer architecture. Our final model consistently outperforms the
previous baselines on popular 3D hand pose benchmarks. To further evaluate the
effect of our design in non-controlled settings, we annotate existing
in-the-wild datasets with 2D hand keypoint annotations. On this newly collected
dataset of annotations, HInt, we demonstrate significant improvements over
existing baselines. We make our code, data and models available on the project
website: https://geopavlakos.github.io/hamer/.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05253" title="Abstract">arXiv:2312.05253</a> [<a href="/pdf/2312.05253" title="Download PDF">pdf</a>, <a href="/format/2312.05253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KBFormer: A Diffusion Model for Structured Entity Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitouni%2C+O">Ouail Kitouni</a>, 
<a href="/search/cs?searchtype=author&query=Nolte%2C+N">Niklas Nolte</a>, 
<a href="/search/cs?searchtype=author&query=Hensman%2C+J">James Hensman</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+B">Bhaskar Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We develop a generative attention-based approach to modeling structured
entities comprising different property types, such as numerical, categorical,
string, and composite. This approach handles such heterogeneous data through a
mixed continuous-discrete diffusion process over the properties. Our flexible
framework can model entities with arbitrary hierarchical properties, enabling
applications to structured Knowledge Base (KB) entities and tabular data. Our
approach obtains state-of-the-art performance on a majority of cases across 15
datasets. In addition, experiments with a device KB and a nuclear physics
dataset demonstrate the model's ability to learn representations useful for
entity completion in diverse settings. This has many downstream use cases,
including modeling numerical properties with high accuracy - critical for
science applications, which also benefit from the model's inherent
probabilistic nature.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 11 Dec 23</h3>
<dl>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04600" title="Abstract">arXiv:2312.04600</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2312.04600" title="Download PDF">pdf</a>, <a href="/format/2312.04600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Haldane Bundles: A Dataset for Learning to Predict the Chern Number of  Line Bundles on the Torus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Tipton%2C+C">Cody Tipton</a>, 
<a href="/search/cond-mat?searchtype=author&query=Coda%2C+E">Elizabeth Coda</a>, 
<a href="/search/cond-mat?searchtype=author&query=Brown%2C+D">Davis Brown</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bittner%2C+A">Alyson Bittner</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+J">Jung Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Jorgenson%2C+G">Grayson Jorgenson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Emerson%2C+T">Tegan Emerson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Machine Learning (cs.LG); Algebraic Topology (math.AT)

</div>
<p class="mathjax">Characteristic classes, which are abstract topological invariants associated
with vector bundles, have become an important notion in modern physics with
surprising real-world consequences. As a representative example, the incredible
properties of topological insulators, which are insulators in their bulk but
conductors on their surface, can be completely characterized by a specific
characteristic class associated with their electronic band structure, the first
Chern class. Given their importance to next generation computing and the
computational challenge of calculating them using first-principles approaches,
there is a need to develop machine learning approaches to predict the
characteristic classes associated with a material system. To aid in this
program we introduce the {\emph{Haldane bundle dataset}}, which consists of
synthetically generated complex line bundles on the $2$-torus. We envision this
dataset, which is not as challenging as noisy and sparsely measured real-world
datasets but (as we show) still difficult for off-the-shelf architectures, to
be a testing ground for architectures that incorporate the rich topological and
geometric priors underlying characteristic classes.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04601" title="Abstract">arXiv:2312.04601</a> (cross-list from stat.ML) [<a href="/pdf/2312.04601" title="Download PDF">pdf</a>, <a href="/format/2312.04601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Fr&#xe9;chet bounds for validating programmatic weak supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Polo%2C+F+M">Felipe Maia Polo</a>, 
<a href="/search/stat?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>, 
<a href="/search/stat?searchtype=author&query=Banerjee%2C+M">Moulinath Banerjee</a>, 
<a href="/search/stat?searchtype=author&query=Maity%2C+S">Subha Maity</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+Y">Yuekai Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We develop methods for estimating Fr\'echet bounds on (possibly
high-dimensional) distribution classes in which some variables are
continuous-valued. We establish the statistical correctness of the computed
bounds under uncertainty in the marginal constraints and demonstrate the
usefulness of our algorithms by evaluating the performance of machine learning
(ML) models trained with programmatic weak supervision (PWS). PWS is a
framework for principled learning from weak supervision inputs (e.g.,
crowdsourced labels, knowledge bases, pre-trained models on related tasks,
etc), and it has achieved remarkable success in many areas of science and
engineering. Unfortunately, it is generally difficult to validate the
performance of ML models trained with PWS due to the absence of labeled data.
Our algorithms address this issue by estimating sharp lower and upper bounds
for performance metrics such as accuracy/recall/precision/F1 score.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04613" title="Abstract">arXiv:2312.04613</a> (cross-list from physics.ed-ph) [<a href="/pdf/2312.04613" title="Download PDF">pdf</a>, <a href="/format/2312.04613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing LLM performance on the Physics GRE: some observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gupta%2C+P">Pranav Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the recent developments in large language models (LLMs) and their
widespread availability through open source models and/or low-cost APIs,
several exciting products and applications are emerging, many of which are in
the field of STEM educational technology for K-12 and university students.
There is a need to evaluate these powerful language models on several
benchmarks, in order to understand their risks and limitations. In this short
paper, we summarize and analyze the performance of Bard, a popular LLM-based
conversational service made available by Google, on the standardized Physics
GRE examination.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04640" title="Abstract">arXiv:2312.04640</a> (cross-list from astro-ph.HE) [<a href="/pdf/2312.04640" title="Download PDF">pdf</a>, <a href="/format/2312.04640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoding Labeled Interpolator, Inferring Parameters From Image, And  Image From Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=SaraerToosi%2C+A">Ali SaraerToosi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Broderick%2C+A">Avery Broderick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Event Horizon Telescope (EHT) provides an avenue to study black hole
accretion flows on event-horizon scales. Fitting a semi-analytical model to EHT
observations requires the construction of synthetic images, which is
computationally expensive. This study presents an image generation tool in the
form of a generative machine learning model, which extends the capabilities of
a variational autoencoder. This tool can rapidly and continuously interpolate
between a training set of images and can retrieve the defining parameters of
those images. Trained on a set of synthetic black hole images, our tool
showcases success in both interpolating black hole images and their associated
physical parameters. By reducing the computational cost of generating an image,
this tool facilitates parameter estimation and model validation for
observations of black hole system.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04648" title="Abstract">arXiv:2312.04648</a> (cross-list from stat.ML) [<a href="/pdf/2312.04648" title="Download PDF">pdf</a>, <a href="/format/2312.04648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Polynomial Chaos Expansion Based Surrogate Modeling using a  Novel Probabilistic Transfer Learning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bridgman%2C+W">Wyatt Bridgman</a>, 
<a href="/search/stat?searchtype=author&query=Balakrishnan%2C+U">Uma Balakrishnan</a>, 
<a href="/search/stat?searchtype=author&query=Jones%2C+R">Reese Jones</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+J">Jiefu Chen</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+X">Xuqing Wu</a>, 
<a href="/search/stat?searchtype=author&query=Safta%2C+C">Cosmin Safta</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+Y">Yueqin Huang</a>, 
<a href="/search/stat?searchtype=author&query=Khalil%2C+M">Mohammad Khalil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of surrogate modeling, polynomial chaos expansion (PCE) allows
practitioners to construct inexpensive yet accurate surrogates to be used in
place of the expensive forward model simulations. For black-box simulations,
non-intrusive PCE allows the construction of these surrogates using a set of
simulation response evaluations. In this context, the PCE coefficients can be
obtained using linear regression, which is also known as point collocation or
stochastic response surfaces. Regression exhibits better scalability and can
handle noisy function evaluations in contrast to other non-intrusive
approaches, such as projection. However, since over-sampling is generally
advisable for the linear regression approach, the simulation requirements
become prohibitive for expensive forward models. We propose to leverage
transfer learning whereby knowledge gained through similar PCE surrogate
construction tasks (source domains) is transferred to a new
surrogate-construction task (target domain) which has a limited number of
forward model simulations (training data). The proposed transfer learning
strategy determines how much, if any, information to transfer using new
techniques inspired by Bayesian modeling and data assimilation. The strategy is
scrutinized using numerical investigations and applied to an engineering
problem from the oil and gas industry.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04660" title="Abstract">arXiv:2312.04660</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.04660" title="Download PDF">pdf</a>, <a href="/format/2312.04660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of machine learning technique for a fast forecast of  aggregation kinetics in space-inhomogeneous systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Larchenko%2C+M+A">M.A. Larchenko</a>, 
<a href="/search/physics?searchtype=author&query=Zagidullin%2C+R+R">R.R. Zagidullin</a>, 
<a href="/search/physics?searchtype=author&query=Palyulin%2C+V+V">V.V. Palyulin</a>, 
<a href="/search/physics?searchtype=author&query=Brilliantov%2C+N+V">N.V. Brilliantov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
<p class="mathjax">Modeling of aggregation processes in space-inhomogeneous systems is extremely
numerically challenging since complicated aggregation equations -- Smoluchowski
equations are to be solved at each space point along with the computation of
particle propagation. Low rank approximation for the aggregation kernels can
significantly speed up the solution of Smoluchowski equations, while particle
propagation could be done in parallel. Yet the simulations with many aggregate
sizes remain quite resource-demanding. Here, we explore the way to reduce the
amount of direct computations with the use of modern machine learning (ML)
techniques. Namely, we propose to replace the actual numerical solution of the
Smoluchowki equations with the respective density transformations learned with
the application of the conditional normalising flow. We demonstrate that the ML
predictions for the space distribution of aggregates and their size
distribution requires drastically less computation time and agrees fairly well
with the results of direct numerical simulations. Such an opportunity of a
quick forecast of space-dependent particle size distribution could be important
in practice, especially for the online prediction and visualisation of
pollution processes, providing a tool with a reasonable tradeoff between the
prediction accuracy and the computational time.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04671" title="Abstract">arXiv:2312.04671</a> (cross-list from eess.IV) [<a href="/pdf/2312.04671" title="Download PDF">pdf</a>, <a href="/ps/2312.04671" title="Download PostScript">ps</a>, <a href="/format/2312.04671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The automatic detection of lumber anatomy in epidural injections for  ultrasound guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Piri%2C+F">Farhad Piri</a>, 
<a href="/search/eess?searchtype=author&query=Sobhiyeh%2C+S">Sima Sobhiyeh</a>, 
<a href="/search/eess?searchtype=author&query=Rezaie%2C+A+H">Amir H. Rezaie</a>, 
<a href="/search/eess?searchtype=author&query=Mosaffa%2C+F">Faramarz Mosaffa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, To be published in Medical Hypotheses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The purpose of this paper is to help the anesthesiologist to find the
epidural depth automatically to make the first attempt to enter the path of the
needle into the patient's body while it is clogged with bone and avoid causing
a puncture in the surrounding areas of the patient`s back. In this regard, a
morphology-based bone enhancement and detection followed by a
Ramer-Douglas-Peucker algorithm and Hough transform is proposed. The proposed
algorithm is tested on synthetic and real ultrasound images of laminar bone,
and the results are compared with the template matching based Ligamentum Flavum
(LF) detection method. Results indicate that the proposed method can faster
detect the diagonal shape of the laminar bone and its corresponding epidural
depth. Furthermore, the proposed method is reliable enough providing
anesthesiologists with real-time information while an epidural needle insertion
is performed. It has to be noted that using the ultrasound images is to help
anesthesiologists to perform the blind injection, and due to quite a lot of
errors occurred in ultrasound-imaging-based methods, these methods can not
completely replace the tissue pressure-based method. And in the end, when the
needle is injected into the area (dura space) measurements can only be trusted
to the extent of tissue resistance. Despite the fairly limited amount of
training data available in this study, a significant improvement of the
segmentation speed of lumbar bones and epidural depth in ultrasound scans with
a rational accuracy compared to the LF-based detection method was found.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04679" title="Abstract">arXiv:2312.04679</a> (cross-list from eess.IV) [<a href="/pdf/2312.04679" title="Download PDF">pdf</a>, <a href="/format/2312.04679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConVRT: Consistent Video Restoration Through Turbulence with Test-time  Optimization of Neural Video Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+H">Haoming Cai</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingxi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+B+Y">Brandon Y. Feng</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Weiyun Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+M">Mingyang Xie</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kevin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Veeraraghavan%2C+A">Ashok Veeraraghavan</a>, 
<a href="/search/eess?searchtype=author&query=Metzler%2C+C">Christopher Metzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://convrt-2024.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">tmospheric turbulence presents a significant challenge in long-range imaging.
Current restoration algorithms often struggle with temporal inconsistency, as
well as limited generalization ability across varying turbulence levels and
scene content different than the training data. To tackle these issues, we
introduce a self-supervised method, Consistent Video Restoration through
Turbulence (ConVRT) a test-time optimization method featuring a neural video
representation designed to enhance temporal consistency in restoration. A key
innovation of ConVRT is the integration of a pretrained vision-language model
(CLIP) for semantic-oriented supervision, which steers the restoration towards
sharp, photorealistic images in the CLIP latent space. We further develop a
principled selection strategy of text prompts, based on their statistical
correlation with a perceptual metric. ConVRT's test-time optimization allows it
to adapt to a wide range of real-world turbulence conditions, effectively
leveraging the insights gained from pre-trained models on simulated data.
ConVRT offers a comprehensive and effective solution for mitigating real-world
turbulence in dynamic videos.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04718" title="Abstract">arXiv:2312.04718</a> (cross-list from eess.SP) [<a href="/pdf/2312.04718" title="Download PDF">pdf</a>, <a href="/format/2312.04718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Online Modulation Recognition using Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Owfi%2C+A">Ali Owfi</a>, 
<a href="/search/eess?searchtype=author&query=Abbasi%2C+A">Ali Abbasi</a>, 
<a href="/search/eess?searchtype=author&query=Afghah%2C+F">Fatemeh Afghah</a>, 
<a href="/search/eess?searchtype=author&query=Ashdown%2C+J">Jonathan Ashdown</a>, 
<a href="/search/eess?searchtype=author&query=Turck%2C+K">Kurt Turck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in International Workshop on Computing, Networking and Communications (CNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modulation recognition is a fundamental task in communication systems as the
accurate identification of modulation schemes is essential for reliable signal
processing, interference mitigation for coexistent communication technologies,
and network optimization. Incorporating deep learning (DL) models into
modulation recognition has demonstrated promising results in various scenarios.
However, conventional DL models often fall short in online dynamic contexts,
particularly in class incremental scenarios where new modulation schemes are
encountered during online deployment. Retraining these models on all previously
seen modulation schemes is not only time-consuming but may also not be feasible
due to storage limitations. On the other hand, training solely on new
modulation schemes often results in catastrophic forgetting of previously
learned classes. This issue renders DL-based modulation recognition models
inapplicable in real-world scenarios because the dynamic nature of
communication systems necessitate the effective adaptability to new modulation
schemes. This paper addresses this challenge by evaluating the performance of
multiple Incremental Learning (IL) algorithms in dynamic modulation recognition
scenarios, comparing them against conventional DL-based modulation recognition.
Our results demonstrate that modulation recognition frameworks based on IL
effectively prevent catastrophic forgetting, enabling models to perform
robustly in dynamic scenarios.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04733" title="Abstract">arXiv:2312.04733</a> (cross-list from math.OC) [<a href="/pdf/2312.04733" title="Download PDF">pdf</a>, <a href="/format/2312.04733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neighboring Extremal Optimal Control Theory for Parameter-Dependent  Closed-loop Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rai%2C+A">Ayush Rai</a>, 
<a href="/search/math?searchtype=author&query=Mou%2C+S">Shaoshuai Mou</a>, 
<a href="/search/math?searchtype=author&query=Anderson%2C+B+D+O">Brian D. O. Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">This study introduces an approach to obtain a neighboring extremal optimal
control (NEOC) solution for a closed-loop optimal control problem, applicable
to a wide array of nonlinear systems and not necessarily quadratic performance
indices. The approach involves investigating the variation incurred in the
functional form of a known closed-loop optimal control law due to small, known
parameter variations in the system equations or the performance index. The NEOC
solution can formally be obtained by solving a linear partial differential
equation, akin to those encountered in the iterative solution of a nonlinear
Hamilton-Jacobi equation. Motivated by numerical procedures for solving these
latter equations, we also propose a numerical algorithm based on the Galerkin
algorithm, leveraging the use of basis functions to solve the underlying
Hamilton-Jacobi equation of the original optimal control problem. The proposed
approach simplifies the NEOC problem by reducing it to the solution of a simple
set of linear equations, thereby eliminating the need for a full re-solution of
the adjusted optimal control problem. Furthermore, the variation to the optimal
performance index can be obtained as a function of both the system state and
small changes in parameters, allowing the determination of the adjustment to an
optimal control law given a small adjustment of parameters in the system or the
performance index. Moreover, in order to handle large known parameter
perturbations, we propose a homotopic approach that breaks down the single
calculation of NEOC into a finite set of multiple steps. Finally, the validity
of the claims and theory is supported by theoretical analysis and numerical
simulations.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04739" title="Abstract">arXiv:2312.04739</a> (cross-list from stat.ML) [<a href="/pdf/2312.04739" title="Download PDF">pdf</a>, <a href="/ps/2312.04739" title="Download PostScript">ps</a>, <a href="/format/2312.04739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unnatural Algorithms in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Goodbrake%2C+C">Christian Goodbrake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Category Theory (math.CT)

</div>
<p class="mathjax">Natural gradient descent has a remarkable property that in the small learning
rate limit, it displays an invariance with respect to network
reparameterizations, leading to robust training behavior even for highly
covariant network parameterizations. We show that optimization algorithms with
this property can be viewed as discrete approximations of natural
transformations from the functor determining an optimizer's state space from
the diffeomorphism group if its configuration manifold, to the functor
determining that state space's tangent bundle from this group. Algorithms with
this property enjoy greater efficiency when used to train poorly parameterized
networks, as the network evolution they generate is approximately invariant to
network reparameterizations. More specifically, the flow generated by these
algorithms in the limit as the learning rate vanishes is invariant under smooth
reparameterizations, the respective flows of the parameters being determined by
equivariant maps. By casting this property a natural transformation, we allow
for generalizations beyond equivariance with respect to group actions; this
framework can account for non-invertible maps such as projections, creating a
framework for the direct comparison of training behavior across non-isomorphic
network architectures, and the formal examination of limiting behavior as
network size increases by considering inverse limits of these projections,
should they exist. We introduce a simple method of introducing this naturality
more generally and examine a number of popular machine learning training
algorithms, finding that most are unnatural.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04745" title="Abstract">arXiv:2312.04745</a> (cross-list from stat.AP) [<a href="/pdf/2312.04745" title="Download PDF">pdf</a>, <a href="/format/2312.04745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brief Tutorial on Sample Size Calculations for Fairness Audits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Singh%2C+H">Harvineet Singh</a>, 
<a href="/search/stat?searchtype=author&query=Xia%2C+F">Fan Xia</a>, 
<a href="/search/stat?searchtype=author&query=Kim%2C+M">Mi-Ok Kim</a>, 
<a href="/search/stat?searchtype=author&query=Pirracchio%2C+R">Romain Pirracchio</a>, 
<a href="/search/stat?searchtype=author&query=Chunara%2C+R">Rumi Chunara</a>, 
<a href="/search/stat?searchtype=author&query=Feng%2C+J">Jean Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, 1 table, Workshop on Regulatable Machine Learning at the 37th Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In fairness audits, a standard objective is to detect whether a given
algorithm performs substantially differently between subgroups. Properly
powering the statistical analysis of such audits is crucial for obtaining
informative fairness assessments, as it ensures a high probability of detecting
unfairness when it exists. However, limited guidance is available on the amount
of data necessary for a fairness audit, lacking directly applicable results
concerning commonly used fairness metrics. Additionally, the consideration of
unequal subgroup sample sizes is also missing. In this tutorial, we address
these issues by providing guidance on how to determine the required subgroup
sample sizes to maximize the statistical power of hypothesis tests for
detecting unfairness. Our findings are applicable to audits of binary
classification models and multiple fairness metrics derived as summaries of the
confusion matrix. Furthermore, we discuss other aspects of audit study designs
that can increase the reliability of audit results.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04757" title="Abstract">arXiv:2312.04757</a> (cross-list from hep-ex) [<a href="/pdf/2312.04757" title="Download PDF">pdf</a>, <a href="/format/2312.04757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Induced Generative Adversarial Particle Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Li%2C+A">Anni Li</a>, 
<a href="/search/hep-ex?searchtype=author&query=Krishnamohan%2C+V">Venkat Krishnamohan</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kansal%2C+R">Raghav Kansal</a>, 
<a href="/search/hep-ex?searchtype=author&query=Sen%2C+R">Rounak Sen</a>, 
<a href="/search/hep-ex?searchtype=author&query=Tsan%2C+S">Steven Tsan</a>, 
<a href="/search/hep-ex?searchtype=author&query=Zhang%2C+Z">Zhaoyu Zhang</a>, 
<a href="/search/hep-ex?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2 tables, to appear in the workshop on Machine Learning and the Physical Sciences (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">In high energy physics (HEP), machine learning methods have emerged as an
effective way to accurately simulate particle collisions at the Large Hadron
Collider (LHC). The message-passing generative adversarial network (MPGAN) was
the first model to simulate collisions as point, or ``particle'', clouds, with
state-of-the-art results, but suffered from quadratic time complexity.
Recently, generative adversarial particle transformers (GAPTs) were introduced
to address this drawback; however, results did not surpass MPGAN. We introduce
induced GAPT (iGAPT) which, by integrating ``induced particle-attention
blocks'' and conditioning on global jet attributes, not only offers linear time
complexity but is also able to capture intricate jet substructure, surpassing
MPGAN in many metrics. Our experiments demonstrate the potential of iGAPT to
simulate complex HEP data accurately and efficiently.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04779" title="Abstract">arXiv:2312.04779</a> (cross-list from eess.IV) [<a href="/pdf/2312.04779" title="Download PDF">pdf</a>, <a href="/format/2312.04779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Synthesis-based Late Stage Cancer Augmentation and Semi-Supervised  Segmentation for MRI Rectal Cancer Staging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sasuga%2C+S">Saeko Sasuga</a>, 
<a href="/search/eess?searchtype=author&query=Kudo%2C+A">Akira Kudo</a>, 
<a href="/search/eess?searchtype=author&query=Kitamura%2C+Y">Yoshiro Kitamura</a>, 
<a href="/search/eess?searchtype=author&query=Iizuka%2C+S">Satoshi Iizuka</a>, 
<a href="/search/eess?searchtype=author&query=Simo-Serra%2C+E">Edgar Simo-Serra</a>, 
<a href="/search/eess?searchtype=author&query=Hamabe%2C+A">Atsushi Hamabe</a>, 
<a href="/search/eess?searchtype=author&query=Ishii%2C+M">Masayuki Ishii</a>, 
<a href="/search/eess?searchtype=author&query=Takemasa%2C+I">Ichiro Takemasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, Accepted to Data Augmentation, Labeling, and Imperfections (DALI) at MICCAI 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Rectal cancer is one of the most common diseases and a major cause of
mortality. For deciding rectal cancer treatment plans, T-staging is important.
However, evaluating the index from preoperative MRI images requires high
radiologists' skill and experience. Therefore, the aim of this study is to
segment the mesorectum, rectum, and rectal cancer region so that the system can
predict T-stage from segmentation results. Generally, shortage of large and
diverse dataset and high quality annotation are known to be the bottlenecks in
computer aided diagnostics development. Regarding rectal cancer, advanced
cancer images are very rare, and per-pixel annotation requires high
radiologists' skill and time. Therefore, it is not feasible to collect
comprehensive disease patterns in a training dataset. To tackle this, we
propose two kinds of approaches of image synthesis-based late stage cancer
augmentation and semi-supervised learning which is designed for T-stage
prediction. In the image synthesis data augmentation approach, we generated
advanced cancer images from labels. The real cancer labels were deformed to
resemble advanced cancer labels by artificial cancer progress simulation. Next,
we introduce a T-staging loss which enables us to train segmentation models
from per-image T-stage labels. The loss works to keep inclusion/invasion
relationships between rectum and cancer region consistent to the ground truth
T-stage. The verification tests show that the proposed method obtains the best
sensitivity (0.76) and specificity (0.80) in distinguishing between over T3
stage and underT2. In the ablation studies, our semi-supervised learning
approach with the T-staging loss improved specificity by 0.13. Adding the image
synthesis-based data augmentation improved the DICE score of invasion cancer
area by 0.08 from baseline.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04796" title="Abstract">arXiv:2312.04796</a> (cross-list from eess.IV) [<a href="/pdf/2312.04796" title="Download PDF">pdf</a>, <a href="/format/2312.04796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of Kidney Tumors on Non-Contrast CT Images using  Protuberance Detection Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hatsutani%2C+T">Taro Hatsutani</a>, 
<a href="/search/eess?searchtype=author&query=Ichinose%2C+A">Akimichi Ichinose</a>, 
<a href="/search/eess?searchtype=author&query=Nakamura%2C+K">Keigo Nakamura</a>, 
<a href="/search/eess?searchtype=author&query=Kitamura%2C+Y">Yoshiro Kitamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in MICCAI 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Computing and Computer Assisted Intervention -
  MICCAI 2023. MICCAI 2023. Lecture Notes in Computer Science, vol 14226.
  Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Many renal cancers are incidentally found on non-contrast CT (NCCT) images.
On contrast-enhanced CT (CECT) images, most kidney tumors, especially renal
cancers, have different intensity values compared to normal tissues. However,
on NCCT images, some tumors called isodensity tumors, have similar intensity
values to the surrounding normal tissues, and can only be detected through a
change in organ shape. Several deep learning methods which segment kidney
tumors from CECT images have been proposed and showed promising results.
However, these methods fail to capture such changes in organ shape on NCCT
images. In this paper, we present a novel framework, which can explicitly
capture protruded regions in kidneys to enable a better segmentation of kidney
tumors. We created a synthetic mask dataset that simulates a protuberance, and
trained a segmentation network to separate the protruded regions from the
normal kidney regions. To achieve the segmentation of whole tumors, our
framework consists of three networks. The first network is a conventional
semantic segmentation network which extracts a kidney region mask and an
initial tumor region mask. The second network, which we name protuberance
detection network, identifies the protruded regions from the kidney region
mask. Given the initial tumor region mask and the protruded region mask, the
last network fuses them and predicts the final kidney tumor mask accurately.
The proposed method was evaluated on a publicly available KiTS19 dataset, which
contains 108 NCCT images, and showed that our method achieved a higher dice
score of 0.615 (+0.097) and sensitivity of 0.721 (+0.103) compared to 3D-UNet.
To the best of our knowledge, this is the first deep learning method that is
specifically designed for kidney tumor segmentation on NCCT images.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04853" title="Abstract">arXiv:2312.04853</a> (cross-list from eess.IV) [<a href="/pdf/2312.04853" title="Download PDF">pdf</a>, <a href="/format/2312.04853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffCMR: Fast Cardiac MRI Reconstruction with Diffusion Probabilistic  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiang%2C+T">Tianqi Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+W">Wenjun Yue</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yiqun Lin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jiewen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhenkun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023 STACOM-CMRxRecon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Performing magnetic resonance imaging (MRI) reconstruction from under-sampled
k-space data can accelerate the procedure to acquire MRI scans and reduce
patients' discomfort. The reconstruction problem is usually formulated as a
denoising task that removes the noise in under-sampled MRI image slices.
Although previous GAN-based methods have achieved good performance in image
denoising, they are difficult to train and require careful tuning of
hyperparameters. In this paper, we propose a novel MRI denoising framework
DiffCMR by leveraging conditional denoising diffusion probabilistic models.
Specifically, DiffCMR perceives conditioning signals from the under-sampled MRI
image slice and generates its corresponding fully-sampled MRI image slice.
During inference, we adopt a multi-round ensembling strategy to stabilize the
performance. We validate DiffCMR with cine reconstruction and T1/T2 mapping
tasks on MICCAI 2023 Cardiac MRI Reconstruction Challenge (CMRxRecon) dataset.
Results show that our method achieves state-of-the-art performance, exceeding
previous methods by a significant margin. Code is available at
https://github.com/xmed-lab/DiffCMR.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04921" title="Abstract">arXiv:2312.04921</a> (cross-list from astro-ph.IM) [<a href="/pdf/2312.04921" title="Download PDF">pdf</a>, <a href="/format/2312.04921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating the PanDA Workload Management System with the Vera C. Rubin  Observatory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Karavakis%2C+E">Edward Karavakis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Guan%2C+W">Wen Guan</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yang%2C+Z">Zhaoyu Yang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Maeno%2C+T">Tadashi Maeno</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wenaus%2C+T">Torre Wenaus</a>, 
<a href="/search/astro-ph?searchtype=author&query=Adelman-McCarthy%2C+J">Jennifer Adelman-McCarthy</a>, 
<a href="/search/astro-ph?searchtype=author&query=Megino%2C+F+B">Fernando Barreiro Megino</a>, 
<a href="/search/astro-ph?searchtype=author&query=De%2C+K">Kaushik De</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dubois%2C+R">Richard Dubois</a>, 
<a href="/search/astro-ph?searchtype=author&query=Gower%2C+M">Michelle Gower</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jenness%2C+T">Tim Jenness</a>, 
<a href="/search/astro-ph?searchtype=author&query=Klimentov%2C+A">Alexei Klimentov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Korchuganova%2C+T">Tatiana Korchuganova</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kowalik%2C+M">Mikolaj Kowalik</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lin%2C+F">Fa-Hui Lin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nilsson%2C+P">Paul Nilsson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Padolski%2C+S">Sergey Padolski</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ye%2C+S">Shuwei Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 26th International Conference on Computing in High Energy &amp; Nuclear Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The Vera C. Rubin Observatory will produce an unprecedented astronomical data
set for studies of the deep and dynamic universe. Its Legacy Survey of Space
and Time (LSST) will image the entire southern sky every three to four days and
produce tens of petabytes of raw image data and associated calibration data
over the course of the experiment's run. More than 20 terabytes of data must be
stored every night, and annual campaigns to reprocess the entire dataset since
the beginning of the survey will be conducted over ten years. The Production
and Distributed Analysis (PanDA) system was evaluated by the Rubin Observatory
Data Management team and selected to serve the Observatory's needs due to its
demonstrated scalability and flexibility over the years, for its Directed
Acyclic Graph (DAG) support, its support for multi-site processing, and its
highly scalable complex workflows via the intelligent Data Delivery Service
(iDDS). PanDA is also being evaluated for prompt processing where data must be
processed within 60 seconds after image capture. This paper will briefly
describe the Rubin Data Management system and its Data Facilities (DFs).
Finally, it will describe in depth the work performed in order to integrate the
PanDA system with the Rubin Observatory to be able to run the Rubin Science
Pipelines using PanDA.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04933" title="Abstract">arXiv:2312.04933</a> (cross-list from quant-ph) [<a href="/pdf/2312.04933" title="Download PDF">pdf</a>, <a href="/format/2312.04933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Classical-Quantum HPC Workload
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Esposito%2C+A">Aniello Esposito</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cabaniols%2C+S">Sebastien Cabaniols</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jones%2C+J+R">Jessica R. Jones</a>, 
<a href="/search/quant-ph?searchtype=author&query=Brayford%2C+D">David Brayford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 listings, 4 figures. Presented at WIHPQC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">A strategy for the orchestration of hybrid classical-quantum workloads on
supercomputers featuring quantum devices is proposed. The method makes use of
heterogeneous job launches with Slurm to interleave classical and quantum
computation, thereby reducing idle time of the quantum components. To better
understand the possible shortcomings and bottlenecks of such a workload, an
example application is investigated that offloads parts of the computation to a
quantum device. It executes on a classical HPC system, with a server mimicking
the quantum device, within the MPMD paradigm in Slurm. Quantum circuits are
synthesized by means of the Classiq software suite according to the needs of
the scientific application, and the Qiskit Aer circuit simulator computes the
state vectors. The HHL quantum algorithm for linear systems of equations is
used to solve the algebraic problem from the discretization of a linear
differential equation. Communication takes place over the MPI, which is broadly
employed in the HPC community. Extraction of state vectors and circuit
synthesis are the most time consuming, while communication is negligible in
this setup. The present test bed serves as a basis for more advanced hybrid
workloads eventually involving a real quantum device.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04950" title="Abstract">arXiv:2312.04950</a> (cross-list from stat.ME) [<a href="/pdf/2312.04950" title="Download PDF">pdf</a>, <a href="/format/2312.04950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential inductive prediction intervals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Avelin%2C+B">Benny Avelin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper we explore the concept of sequential inductive prediction
intervals using theory from sequential testing. We furthermore introduce a
3-parameter PAC definition of prediction intervals that allows us via
simulation to achieve almost sharp bounds with high probability.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05063" title="Abstract">arXiv:2312.05063</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.05063" title="Download PDF">pdf</a>, <a href="/format/2312.05063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individualizing Glioma Radiotherapy Planning by Optimization of a Data  and Physics Informed Discrete Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Balcerak%2C+M">Michal Balcerak</a>, 
<a href="/search/physics?searchtype=author&query=Ezhov%2C+I">Ivan Ezhov</a>, 
<a href="/search/physics?searchtype=author&query=Karnakov%2C+P">Petr Karnakov</a>, 
<a href="/search/physics?searchtype=author&query=Litvinov%2C+S">Sergey Litvinov</a>, 
<a href="/search/physics?searchtype=author&query=Koumoutsakos%2C+P">Petros Koumoutsakos</a>, 
<a href="/search/physics?searchtype=author&query=Weidner%2C+J">Jonas Weidner</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+R+Z">Ray Zirui Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Lowengrub%2C+J+S">John S. Lowengrub</a>, 
<a href="/search/physics?searchtype=author&query=Wiestler%2C+B">Bene Wiestler</a>, 
<a href="/search/physics?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures. Associated GitHub: <a href="https://github.com/m1balcerak/GliODIL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Numerical Analysis (math.NA); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The growth and progression of brain tumors is governed by patient-specific
dynamics. Even when the tumor appears well-delineated in medical imaging scans,
tumor cells typically already have infiltrated the surrounding brain tissue
beyond the visible lesion boundaries. Quantifying and understanding these
growth dynamics promises to reveal this otherwise hidden spread and is key to
individualized therapies. Current treatment plans for brain tumors, such as
radiotherapy, typically involve delineating a standard uniform margin around
the visible tumor on imaging scans to target this invisible tumor growth. This
"one size fits all" approach is derived from population studies and often fails
to account for the nuances of individual patient conditions. Here, we present
the framework GliODIL which infers the full spatial distribution of tumor cell
concentration from available imaging data based on PDE-constrained
optimization. The framework builds on the newly introduced method of Optimizing
the Discrete Loss (ODIL), data are assimilated in the solution of the Partial
Differential Equations (PDEs) by optimizing a cost function that combines the
discrete form of the equations and data as penalty terms. By utilizing
consistent and stable discrete approximations of the PDEs, employing a
multigrid method, and leveraging automatic differentiation, we achieve
computation times suitable for clinical application such as radiotherapy
planning. Our method performs parameter estimation in a manner that is
consistent with the PDEs. Through a harmonious blend of physics-based
constraints and data-driven approaches, GliODIL improves the accuracy of
estimating tumor cell distribution and, clinically highly relevant, also
predicting tumor recurrences, outperforming all other studied benchmarks.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05073" title="Abstract">arXiv:2312.05073</a> (cross-list from math.OC) [<a href="/pdf/2312.05073" title="Download PDF">pdf</a>, <a href="/format/2312.05073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributed ADMM-based Deep Learning Approach for Thermal Control in  Multi-Zone Buildings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Taboga%2C+V">Vincent Taboga</a> (1, 2, 3), 
<a href="/search/math?searchtype=author&query=Dagdougui%2C+H">Hanane Dagdougui</a> (1, 2, 3) ((1) Polytechnique Montreal, Department of Mathematics and Industrial Engineering (2) Quebec Artificial Intelligence Institute (Mila) (3) Groupe d&#x27;etudes et de recherche en analyse des decisions (GERAD))
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures submitted to IEEE Transactions on Automation Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The surge in electricity use, coupled with the dependency on intermittent
renewable energy sources, poses significant hurdles to effectively managing
power grids, particularly during times of peak demand. Demand Response programs
and energy conservation measures are essential to operate energy grids while
ensuring a responsible use of our resources This research combines distributed
optimization using ADMM with Deep Learning models to plan indoor temperature
setpoints effectively. A two-layer hierarchical structure is used, with a
central building coordinator at the upper layer and local controllers at the
thermal zone layer. The coordinator must limit the building's maximum power by
translating the building's total power to local power targets for each zone.
Local controllers can modify the temperature setpoints to meet the local power
targets. The resulting control algorithm, called Distributed Planning Networks,
is designed to be both adaptable and scalable to many types of buildings,
tackling two of the main challenges in the development of such systems. The
proposed approach is tested on an 18-zone building modeled in EnergyPlus. The
algorithm successfully manages Demand Response peak events.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05080" title="Abstract">arXiv:2312.05080</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.05080" title="Download PDF">pdf</a>, <a href="/format/2312.05080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust self-assembly of nonconvex shapes in 2D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mayrhofer%2C+L">Lukas Mayrhofer</a>, 
<a href="/search/physics?searchtype=author&query=Evans%2C+M+E">Myfanwy E. Evans</a>, 
<a href="/search/physics?searchtype=author&query=Friesecke%2C+G">Gero Friesecke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present fast simulation methods for the self-assembly of complex shapes in
two dimensions. The shapes are modeled via a general boundary curve and
interact via a standard volume term promoting overlap and an interpenetration
penalty. To efficiently realize the Gibbs measure on the space of possible
configurations we employ the hybrid Monte Carlo algorithm together with a
careful use of signed distance functions for energy evaluation.
<br />Motivated by the self-assembly of identical coat proteins of the tobacco
mosaic virus which assemble into a helical shell, we design a particular
nonconvex 2D model shape and demonstrate its robust self-assembly into a unique
final state. Our numerical experiments reveal two essential prerequisites for
this self-assembly process: blocking and matching (i.e., local repulsion and
attraction) of different parts of the boundary; and nonconvexity and handedness
of the shape.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05119" title="Abstract">arXiv:2312.05119</a> (cross-list from eess.IV) [<a href="/pdf/2312.05119" title="Download PDF">pdf</a>, <a href="/format/2312.05119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying white matter hyperintensity and brain volumes in  heterogeneous clinical and low-field portable MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Laso%2C+P">Pablo Laso</a>, 
<a href="/search/eess?searchtype=author&query=Cerri%2C+S">Stefano Cerri</a>, 
<a href="/search/eess?searchtype=author&query=Sorby-Adams%2C+A">Annabel Sorby-Adams</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jennifer Guo</a>, 
<a href="/search/eess?searchtype=author&query=Mateen%2C+F">Farrah Mateen</a>, 
<a href="/search/eess?searchtype=author&query=Goebl%2C+P">Philipp Goebl</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jiaming Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+P">Peirong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hongwei Li</a>, 
<a href="/search/eess?searchtype=author&query=Young%2C+S+I">Sean I. Young</a>, 
<a href="/search/eess?searchtype=author&query=Billot%2C+B">Benjamin Billot</a>, 
<a href="/search/eess?searchtype=author&query=Puonti%2C+O">Oula Puonti</a>, 
<a href="/search/eess?searchtype=author&query=Sze%2C+G">Gordon Sze</a>, 
<a href="/search/eess?searchtype=author&query=Payabavash%2C+S">Sam Payabavash</a>, 
<a href="/search/eess?searchtype=author&query=DeHavenon%2C+A">Adam DeHavenon</a>, 
<a href="/search/eess?searchtype=author&query=Sheth%2C+K+N">Kevin N. Sheth</a>, 
<a href="/search/eess?searchtype=author&query=Rosen%2C+M+S">Matthew S. Rosen</a>, 
<a href="/search/eess?searchtype=author&query=Kirsch%2C+J">John Kirsch</a>, 
<a href="/search/eess?searchtype=author&query=Strisciuglio%2C+N">Nicola Strisciuglio</a>, 
<a href="/search/eess?searchtype=author&query=Wolterink%2C+J+M">Jelmer M. Wolterink</a>, 
<a href="/search/eess?searchtype=author&query=Eshaghi%2C+A">Arman Eshaghi</a>, 
<a href="/search/eess?searchtype=author&query=Barkhof%2C+F">Frederik Barkhof</a>, 
<a href="/search/eess?searchtype=author&query=Kimberly%2C+W+T">W. Taylor Kimberly</a>, 
<a href="/search/eess?searchtype=author&query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Brain atrophy and white matter hyperintensity (WMH) are critical neuroimaging
features for ascertaining brain injury in cerebrovascular disease and multiple
sclerosis. Automated segmentation and quantification is desirable but existing
methods require high-resolution MRI with good signal-to-noise ratio (SNR). This
precludes application to clinical and low-field portable MRI (pMRI) scans, thus
hampering large-scale tracking of atrophy and WMH progression, especially in
underserved areas where pMRI has huge potential. Here we present a method that
segments white matter hyperintensity and 36 brain regions from scans of any
resolution and contrast (including pMRI) without retraining. We show results on
six public datasets and on a private dataset with paired high- and low-field
scans (3T and 64mT), where we attain strong correlation between the WMH
($\rho$=.85) and hippocampal volumes (r=.89) estimated at both fields. Our
method is publicly available as part of FreeSurfer, at:
<a href="http://surfer.nmr.mgh.harvard.edu/fswiki/WMH-SynthSeg.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05143" title="Abstract">arXiv:2312.05143</a> (cross-list from math.OC) [<a href="/pdf/2312.05143" title="Download PDF">pdf</a>, <a href="/format/2312.05143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic optimization for unit commitment applied to the security of  supply
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dumas%2C+J">Jonathan Dumas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Transmission system operators employ reserves to deal with unexpected
variations of demand and generation to guarantee the security of supply. The
French transmission system operator RTE dynamically sizes the required margins
using a probabilistic approach relying on continuous forecasts of the main
drivers of the uncertainties of the system imbalance and a 1 % risk threshold.
However, this criterion does not specify which means to activate
upward/downward and when to face a deficit of available margins versus the
required margins. Thus, this work presents a strategy using a probabilistic
unit commitment with a stochastic optimization-based approach, including the
fixed and variable costs of units and the costs of lost load and production.
The abstract problem is formulated with a multi-stage stochastic program and
approximated with a heuristic called two-stage stochastic model predictive
control. It solves a sequence of two-stage stochastic programs to conduct the
central dispatch. An implementation is conducted by solving an approximated
version with a single two-stage stochastic program. This method is tested on a
real case study comprising nuclear and fossil-based units with French
electrical consumption and renewable production.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05148" title="Abstract">arXiv:2312.05148</a> (cross-list from eess.IV) [<a href="/pdf/2312.05148" title="Download PDF">pdf</a>, <a href="/format/2312.05148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape-aware Segmentation of the Placenta in BOLD Fetal MRI Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abulnaga%2C+S+M">S. Mazdak Abulnaga</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+N">Neel Dey</a>, 
<a href="/search/eess?searchtype=author&query=Young%2C+S+I">Sean I. Young</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+E">Eileen Pan</a>, 
<a href="/search/eess?searchtype=author&query=Hobgood%2C+K+I">Katherine I. Hobgood</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C+J">Clinton J. Wang</a>, 
<a href="/search/eess?searchtype=author&query=Grant%2C+P+E">P. Ellen Grant</a>, 
<a href="/search/eess?searchtype=author&query=Turk%2C+E+A">Esra Abaci Turk</a>, 
<a href="/search/eess?searchtype=author&query=Golland%2C+P">Polina Golland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2023:017.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2208.02895">arXiv:2208.02895</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Blood oxygen level dependent (BOLD) MRI time series with maternal hyperoxia
can assess placental oxygenation and function. Measuring precise BOLD changes
in the placenta requires accurate temporal placental segmentation and is
confounded by fetal and maternal motion, contractions, and hyperoxia-induced
intensity changes. Current BOLD placenta segmentation methods warp a manually
annotated subject-specific template to the entire time series. However, as the
placenta is a thin, elongated, and highly non-rigid organ subject to large
deformations and obfuscated edges, existing work cannot accurately segment the
placental shape, especially near boundaries. In this work, we propose a machine
learning segmentation framework for placental BOLD MRI and apply it to
segmenting each volume in a time series. We use a placental-boundary weighted
loss formulation and perform a comprehensive evaluation across several popular
segmentation objectives. Our model is trained and tested on a cohort of 91
subjects containing healthy fetuses, fetuses with fetal growth restriction, and
mothers with high BMI. Biomedically, our model performs reliably in segmenting
volumes in both normoxic and hyperoxic points in the BOLD time series. We
further find that boundary-weighting increases placental segmentation
performance by 8.3% and 6.0% Dice coefficient for the cross-entropy and signed
distance transform objectives, respectively. Our code and trained model is
available at https://github.com/mabulnaga/automatic-placenta-segmentation.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05153" title="Abstract">arXiv:2312.05153</a> (cross-list from stat.ML) [<a href="/pdf/2312.05153" title="Download PDF">pdf</a>, <a href="/format/2312.05153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification and Propagation in Surrogate-based Bayesian  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Reiser%2C+P">Philipp Reiser</a>, 
<a href="/search/stat?searchtype=author&query=Aguilar%2C+J+E">Javier Enrique Aguilar</a>, 
<a href="/search/stat?searchtype=author&query=Guthke%2C+A">Anneli Guthke</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Surrogate models are statistical or conceptual approximations for more
complex simulation models. In this context, it is crucial to propagate the
uncertainty induced by limited simulation budget and surrogate approximation
error to predictions, inference, and subsequent decision-relevant quantities.
However, quantifying and then propagating the uncertainty of surrogates is
usually limited to special analytic cases or is otherwise computationally very
expensive. In this paper, we propose a framework enabling a scalable, Bayesian
approach to surrogate modeling with thorough uncertainty quantification,
propagation, and validation. Specifically, we present three methods for
Bayesian inference with surrogate models given measurement data. This is a task
where the propagation of surrogate uncertainty is especially relevant, because
failing to account for it may lead to biased and/or overconfident estimates of
the parameters of interest. We showcase our approach in two detailed case
studies for both linear and nonlinear modeling scenarios. Uncertainty
propagation in surrogate models enables more reliable and safe approximation of
expensive simulators and will therefore be useful in various fields of
applications.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05158" title="Abstract">arXiv:2312.05158</a> (cross-list from eess.SP) [<a href="/pdf/2312.05158" title="Download PDF">pdf</a>, <a href="/format/2312.05158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Pilotless Spatial Multiplexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Korpi%2C+D">Dani Korpi</a>, 
<a href="/search/eess?searchtype=author&query=Honkala%2C+M">Mikko Honkala</a>, 
<a href="/search/eess?searchtype=author&query=Huttunen%2C+J+M+J">Janne M.J. Huttunen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in the 57th Asilomar Conference on Signals, Systems, and Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper investigates the feasibility of machine learning (ML)-based
pilotless spatial multiplexing in multiple-input and multiple-output (MIMO)
communication systems. Especially, it is shown that by training the transmitter
and receiver jointly, the transmitter can learn such constellation shapes for
the spatial streams which facilitate completely blind separation and detection
by the simultaneously learned receiver. To the best of our knowledge, this is
the first time ML-based spatial multiplexing without channel estimation pilots
is demonstrated. The results show that the learned pilotless scheme can
outperform a conventional pilot-based system by as much as 15-20% in terms of
spectral efficiency, depending on the modulation order and signal-to-noise
ratio.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05160" title="Abstract">arXiv:2312.05160</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.05160" title="Download PDF">pdf</a>, <a href="/ps/2312.05160" title="Download PostScript">ps</a>, <a href="/format/2312.05160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Atomic Scale Surface Defects in STM of TMDs with Ensemble Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Smalley%2C+D">Darian Smalley</a> (1 and 2), 
<a href="/search/cond-mat?searchtype=author&query=Lough%2C+S+D">Stephanie D. Lough</a> (1 and 2), 
<a href="/search/cond-mat?searchtype=author&query=Holtzman%2C+L">Luke Holtzman</a> (3), 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+K">Kaikui Xu</a> (4), 
<a href="/search/cond-mat?searchtype=author&query=Holbrook%2C+M">Madisen Holbrook</a> (3), 
<a href="/search/cond-mat?searchtype=author&query=Rosenberger%2C+M+R">Matthew R. Rosenberger</a> (4), 
<a href="/search/cond-mat?searchtype=author&query=Hone%2C+J+C">J.C. Hone</a> (3), 
<a href="/search/cond-mat?searchtype=author&query=Barmak%2C+K">Katayun Barmak</a> (3), 
<a href="/search/cond-mat?searchtype=author&query=Ishigami%2C+M">Masahiro Ishigami</a> (1 and 2) ((1) Department of Physics, University of Central Florida, (2) NanoScience Technology Center, University of Central Florida, (3) Department of Applied Physics and Applied Mathematics, University of Columbia, (4) Department of Aerospace and Mechanical Engineering, University of Notre Dame)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, submitted to MRS Advances as a conference preceding for the 2023 MRS Fall Meeting &amp; Exhibit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Atomic-scale defect detection is shown in scanning tunneling microscopy
images of single crystal WSe2 using an ensemble of U-Net-like convolutional
neural networks. Standard deep learning test metrics indicated good detection
performance with an average F1 score of 0.66 and demonstrated ensemble
generalization to C-AFM images of WSe2 and STM images of MoSe2. Defect
coordinates were automatically extracted from defect detections maps showing
that STM image analysis enhanced by machine learning can be used to
dramatically increase sample characterization throughput.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05169" title="Abstract">arXiv:2312.05169</a> (cross-list from q-fin.PM) [<a href="/pdf/2312.05169" title="Download PDF">pdf</a>, <a href="/format/2312.05169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Onflow: an online portfolio allocation algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Turinici%2C+G">Gabriel Turinici</a>, 
<a href="/search/q-fin?searchtype=author&query=Brugiere%2C+P">Pierre Brugiere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Numerical Analysis (math.NA); Computational Finance (q-fin.CP); Machine Learning (stat.ML)

</div>
<p class="mathjax">We introduce Onflow, a reinforcement learning technique that enables online
optimization of portfolio allocation policies based on gradient flows. We
devise dynamic allocations of an investment portfolio to maximize its expected
log return while taking into account transaction fees. The portfolio allocation
is parameterized through a softmax function, and at each time step, the
gradient flow method leads to an ordinary differential equation whose solutions
correspond to the updated allocations. This algorithm belongs to the large
class of stochastic optimization procedures; we measure its efficiency by
comparing our results to the mathematical theoretical values in a log-normal
framework and to standard benchmarks from the 'old NYSE' dataset. For
log-normal assets, the strategy learned by Onflow, with transaction costs at
zero, mimics Markowitz's optimal portfolio and thus the best possible asset
allocation strategy. Numerical experiments from the 'old NYSE' dataset show
that Onflow leads to dynamic asset allocation strategies whose performances
are: a) comparable to benchmark strategies such as Cover's Universal Portfolio
or Helmbold et al. "multiplicative updates" approach when transaction costs are
zero, and b) better than previous procedures when transaction costs are high.
Onflow can even remain efficient in regimes where other dynamical allocation
techniques do not work anymore. Therefore, as far as tested, Onflow appears to
be a promising dynamic portfolio management strategy based on observed prices
only and without any assumption on the laws of distributions of the underlying
assets' returns. In particular it could avoid model risk when building a
trading strategy.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05173" title="Abstract">arXiv:2312.05173</a> (cross-list from eess.AS) [<a href="/pdf/2312.05173" title="Download PDF">pdf</a>, <a href="/format/2312.05173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binaural multichannel blind speaker separation with a causal low-latency  and low-complexity approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Westhausen%2C+N+L">Nils L. Westhausen</a>, 
<a href="/search/eess?searchtype=author&query=Meyer%2C+B+T">Bernd T. Meyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE ICASSP 2024 OJSP track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we introduce a causal low-latency low-complexity approach for
binaural multichannel blind speaker separation in noisy reverberant conditions.
<br />The model, referred to as Group Communication Binaural Filter and Sum Network
(GCBFSnet) predicts complex filters for filter-and-sum beamforming in the
time-frequency domain.
<br />We apply Group Communication (GC),
<br />i.e., latent model variables are split into groups and processed with a
shared sequence model with the aim of reducing the complexity of a simple model
only containing one convolutional and one recurrent module.
<br />With GC we are able to reduce the size of the model by up to 83 % and the
complexity up to 73 % compared to the model without GC, while mostly retaining
performance.
<br />Even for the smallest model configuration, GCBFSnet matches the performance
of a low-complexity TasNet baseline in most metrics despite the larger size and
higher number of required operations of the baseline.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05176" title="Abstract">arXiv:2312.05176</a> (cross-list from eess.IV) [<a href="/pdf/2312.05176" title="Download PDF">pdf</a>, <a href="/format/2312.05176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRI Scan Synthesis Methods based on Clustering and Pix2Pix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baldini%2C+G">Giulia Baldini</a>, 
<a href="/search/eess?searchtype=author&query=Schmidt%2C+M">Melanie Schmidt</a>, 
<a href="/search/eess?searchtype=author&query=Z%C3%A4ske%2C+C">Charlotte Z&#xe4;ske</a>, 
<a href="/search/eess?searchtype=author&query=Caldeira%2C+L+L">Liliana L. Caldeira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider a missing data problem in the context of automatic segmentation
methods for Magnetic Resonance Imaging (MRI) brain scans. Usually, automated
MRI scan segmentation is based on multiple scans (e.g., T1-weighted,
T2-weighted, T1CE, FLAIR). However, quite often a scan is blurry, missing or
otherwise unusable. We investigate the question whether a missing scan can be
synthesized. We exemplify that this is in principle possible by synthesizing a
T2-weighted scan from a given T1-weighted scan. Our first aim is to compute a
picture that resembles the missing scan closely, measured by average mean
squared error (MSE). We develop/use several methods for this, including a
random baseline approach, a clustering-based method and pixel-to-pixel
translation method by (Pix2Pix) which is based on conditional GANs. The lowest
MSE is achieved by our clustering-based method. Our second aim is to compare
the methods with respect to the affect that using the synthesized scan has on
the segmentation process. For this, we use a DeepMedic model trained with the
four input scan modalities named above. We replace the T2-weighted scan by the
synthesized picture and evaluate the segmentations with respect to the tumor
identification, using Dice scores as numerical evaluation. The evaluation shows
that the segmentation works well with synthesized scans (in particular, with
Pix2Pix methods) in many cases.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05220" title="Abstract">arXiv:2312.05220</a> (cross-list from eess.IV) [<a href="/pdf/2312.05220" title="Download PDF">pdf</a>, <a href="/format/2312.05220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape Matters: Detecting Vertebral Fractures Using Differentiable  Point-Based Shape Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hempe%2C+H">Hellena Hempe</a>, 
<a href="/search/eess?searchtype=author&query=Bigalke%2C+A">Alexander Bigalke</a>, 
<a href="/search/eess?searchtype=author&query=Heinrich%2C+M+P">Mattias P. Heinrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Degenerative spinal pathologies are highly prevalent among the elderly
population. Timely diagnosis of osteoporotic fractures and other degenerative
deformities facilitates proactive measures to mitigate the risk of severe back
pain and disability. In this study, we specifically explore the use of shape
auto-encoders for vertebrae, taking advantage of advancements in automated
multi-label segmentation and the availability of large datasets for
unsupervised learning. Our shape auto-encoders are trained on a large set of
vertebrae surface patches, leveraging the vast amount of available data for
vertebra segmentation. This addresses the label scarcity problem faced when
learning shape information of vertebrae from image intensities. Based on the
learned shape features we train an MLP to detect vertebral body fractures.
Using segmentation masks that were automatically generated using the
TotalSegmentator, our proposed method achieves an AUC of 0.901 on the VerSe19
testset. This outperforms image-based and surface-based end-to-end trained
models. Additionally, our results demonstrate that pre-training the models in
an unsupervised manner enhances geometric methods like PointNet and DGCNN. Our
findings emphasise the advantages of explicitly learning shape features for
diagnosing osteoporotic vertebrae fractures. This approach improves the
reliability of classification results and reduces the need for annotated
labels. This study provides novel insights into the effectiveness of various
encoder-decoder models for shape analysis of vertebrae and proposes a new
decoder architecture: the point-based shape decoder.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05234" title="Abstract">arXiv:2312.05234</a> (cross-list from stat.ML) [<a href="/pdf/2312.05234" title="Download PDF">pdf</a>, <a href="/format/2312.05234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The impact of heteroskedasticity on uplift modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bokelmann%2C+B">Bj&#xf6;rn Bokelmann</a>, 
<a href="/search/stat?searchtype=author&query=Lessmann%2C+S">Stefan Lessmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There are various applications, where companies need to decide to which
individuals they should best allocate treatment. To support such decisions,
uplift models are applied to predict treatment effects on an individual level.
Based on the predicted treatment effects, individuals can be ranked and
treatment allocation can be prioritized according to this ranking. An implicit
assumption, which has not been doubted in the previous uplift modeling
literature, is that this treatment prioritization approach tends to bring
individuals with high treatment effects to the top and individuals with low
treatment effects to the bottom of the ranking. In our research, we show that
heteroskedastictity in the training data can cause a bias of the uplift model
ranking: individuals with the highest treatment effects can get accumulated in
large numbers at the bottom of the ranking. We explain theoretically how
heteroskedasticity can bias the ranking of uplift models and show this process
in a simulation and on real-world data. We argue that this problem of ranking
bias due to heteroskedasticity might occur in many real-world applications and
requires modification of the treatment prioritization to achieve an efficient
treatment allocation.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05254" title="Abstract">arXiv:2312.05254</a> (cross-list from astro-ph.EP) [<a href="/pdf/2312.05254" title="Download PDF">pdf</a>, <a href="/format/2312.05254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling CO Chemistry in a Protoplanetary Disk Using Explanatory  Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Diop%2C+A">Amina Diop</a> (1), 
<a href="/search/astro-ph?searchtype=author&query=Cleeves%2C+I">Ilse Cleeves</a> (1), 
<a href="/search/astro-ph?searchtype=author&query=Anderson%2C+D">Dana Anderson</a> (2), 
<a href="/search/astro-ph?searchtype=author&query=Pegues%2C+J">Jamila Pegues</a> (3), 
<a href="/search/astro-ph?searchtype=author&query=Plunkett%2C+A">Adele Plunkett</a> (4) ((1) University of Virginia, (2) Earth and Planets Laboratory, Carnegie Institution for Science, (3) Space Telescope Science Institute, (4) National Radio Astronomy Observatory)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ApJ, 17 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Molecular abundances in protoplanetary disks are highly sensitive to the
local physical conditions, including gas temperature, gas density, radiation
field, and dust properties. Often multiple factors are intertwined, impacting
the abundances of both simple and complex species. We present a new approach to
understanding these chemical and physical interdependencies using machine
learning. Specifically we explore the case of CO modeled under the conditions
of a generic disk and build an explanatory regression model to study the
dependence of CO spatial density on the gas density, gas temperature, cosmic
ray ionization rate, X-ray ionization rate, and UV flux. Our findings indicate
that combinations of parameters play a surprisingly powerful role in regulating
CO compared to any singular physical parameter. Moreover, in general, we find
the conditions in the disk are destructive toward CO. CO depletion is further
enhanced in an increased cosmic ray environment and in disks with higher
initial C/O ratios. These dependencies uncovered by our new approach are
consistent with previous studies, which are more modeling intensive and
computationally expensive. Our work thus shows that machine learning can be a
powerful tool not only for creating efficient predictive models, but also for
enabling a deeper understanding of complex chemical processes.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 11 Dec 23</h3>
<dl>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1708.02130" title="Abstract">arXiv:1708.02130</a> (replaced) [<a href="/pdf/1708.02130" title="Download PDF">pdf</a>, <a href="/ps/1708.02130" title="Download PostScript">ps</a>, <a href="/format/1708.02130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classical Homomorphic Encryption for Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mahadev%2C+U">Urmila Mahadev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.05556" title="Abstract">arXiv:1908.05556</a> (replaced) [<a href="/pdf/1908.05556" title="Download PDF">pdf</a>, <a href="/ps/1908.05556" title="Download PostScript">ps</a>, <a href="/format/1908.05556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Verification in Mechanism Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ball%2C+I">Ian Ball</a>, 
<a href="/search/econ?searchtype=author&query=Kattwinkel%2C+D">Deniz Kattwinkel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.06666" title="Abstract">arXiv:2005.06666</a> (replaced) [<a href="/pdf/2005.06666" title="Download PDF">pdf</a>, <a href="/format/2005.06666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guessing Cost: Bounds and Applications to Data Repair in Distributed  Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arslan%2C+S+S">Suayb S. Arslan</a>, 
<a href="/search/cs?searchtype=author&query=Haytaoglu%2C+E">Elif Haytaoglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures, 1 table. Accepted to IEEE Transactions on Information Theory, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.11753" title="Abstract">arXiv:2005.11753</a> (replaced) [<a href="/pdf/2005.11753" title="Download PDF">pdf</a>, <a href="/format/2005.11753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Release of Data Streams under both Centralized and Local  Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+Q">Joann Qiongna Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Dong Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yueqiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ninghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.00245" title="Abstract">arXiv:2007.00245</a> (replaced) [<a href="/pdf/2007.00245" title="Download PDF">pdf</a>, <a href="/format/2007.00245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fighting Failures with FIRE: Failure Identification to Reduce Expert  Burden in Intervention-Based Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ablett%2C+T">Trevor Ablett</a>, 
<a href="/search/cs?searchtype=author&query=Mari%C4%87%2C+F">Filip Mari&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report STARS-2020-001, University of Toronto Institute for Aerospace Studies (14 pages, 7 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.11505" title="Abstract">arXiv:2101.11505</a> (replaced) [<a href="/pdf/2101.11505" title="Download PDF">pdf</a>, <a href="/ps/2101.11505" title="Download PostScript">ps</a>, <a href="/format/2101.11505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-skilled Occupations Face the Highest Upskilling Pressure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+D">Di Tong</a> (Massachusetts Institute of Technology), 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a> (University of Pittsburgh), 
<a href="/search/cs?searchtype=author&query=Evans%2C+J+A">James Allen Evans</a> (University of Chicago)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages; 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.07246" title="Abstract">arXiv:2102.07246</a> (replaced) [<a href="/pdf/2102.07246" title="Download PDF">pdf</a>, <a href="/format/2102.07246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsibility Management through Responsibility Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xuejiao Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.01671" title="Abstract">arXiv:2107.01671</a> (replaced) [<a href="/pdf/2107.01671" title="Download PDF">pdf</a>, <a href="/format/2107.01671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Visual Commonsense Reasoning Using Dynamic Working Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xuejiao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Child%2C+T+B">Travers B. Child</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DaWaK 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.02924" title="Abstract">arXiv:2108.02924</a> (replaced) [<a href="/pdf/2108.02924" title="Download PDF">pdf</a>, <a href="/format/2108.02924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Visual Understanding with Cognitive Attention Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xuejiao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+K">Kea Turner</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ntoutsi%2C+E">Eirini Ntoutsi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICANN21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.11328" title="Abstract">arXiv:2108.11328</a> (replaced) [<a href="/pdf/2108.11328" title="Download PDF">pdf</a>, <a href="/format/2108.11328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Census Survey Response Rates With Parsimonious Additive  Models and Structured Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ibrahim%2C+S">Shibal Ibrahim</a>, 
<a href="/search/stat?searchtype=author&query=Radchenko%2C+P">Peter Radchenko</a>, 
<a href="/search/stat?searchtype=author&query=Ben-David%2C+E">Emanuel Ben-David</a>, 
<a href="/search/stat?searchtype=author&query=Mazumder%2C+R">Rahul Mazumder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.12989" title="Abstract">arXiv:2112.12989</a> (replaced) [<a href="/pdf/2112.12989" title="Download PDF">pdf</a>, <a href="/format/2112.12989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Aware Continual Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kai Yi</a>, 
<a href="/search/cs?searchtype=author&query=Janson%2C+P">Paul Janson</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.04754" title="Abstract">arXiv:2202.04754</a> (replaced) [<a href="/pdf/2202.04754" title="Download PDF">pdf</a>, <a href="/format/2202.04754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wireless Transmission of Images With The Assistance of Multi-level  Semantic Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhenguo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10705" title="Abstract">arXiv:2202.10705</a> (replaced) [<a href="/pdf/2202.10705" title="Download PDF">pdf</a>, <a href="/format/2202.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointMatch: A Consistency Training Framework for Weakly Supervised  Semantic Segmentation of 3D Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yushuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zizheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shengcai Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.17255" title="Abstract">arXiv:2203.17255</a> (replaced) [<a href="/pdf/2203.17255" title="Download PDF">pdf</a>, <a href="/ps/2203.17255" title="Download PostScript">ps</a>, <a href="/format/2203.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cognitive Architecture for Machine Consciousness and Artificial  Superintelligence: Thought Is Structured by the Iterative Updating of Working  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Reser%2C+J+E">Jared Edward Reser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.03897" title="Abstract">arXiv:2204.03897</a> (replaced) [<a href="/pdf/2204.03897" title="Download PDF">pdf</a>, <a href="/format/2204.03897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-to-Real Transfer of Compliant Bipedal Locomotion on Torque  Sensor-Less Gear-Driven Humanoid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masuda%2C+S">Shimpei Masuda</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+K">Kuniyuki Takahashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An accompanying video is available at the following link: <a href="https://www.youtube.com/watch?v=-QHx5V9oZDc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.07421" title="Abstract">arXiv:2205.07421</a> (replaced) [<a href="/pdf/2205.07421" title="Download PDF">pdf</a>, <a href="/format/2205.07421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Julia Cloud Matrix Machine: Dynamic Matrix Language Acceleration on  Multicore Clusters in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jay Hwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yeonsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+Y">Younghyun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Sodsong%2C+W">Wasuwee Sodsong</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hyunjun Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinsik Park</a>, 
<a href="/search/cs?searchtype=author&query=Burgstaller%2C+B">Bernd Burgstaller</a>, 
<a href="/search/cs?searchtype=author&query=Scholz%2C+B">Bernhard Scholz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12276" title="Abstract">arXiv:2206.12276</a> (replaced) [<a href="/pdf/2206.12276" title="Download PDF">pdf</a>, <a href="/format/2206.12276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Frequency Joint Community Detection and Phase Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhizhen Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed a minor error and several typos. Accepted by IEEE Transactions on Signal and Information Processing over Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13962" title="Abstract">arXiv:2206.13962</a> (replaced) [<a href="/e-print/2206.13962" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Prior Learning via Neural Architecture Search for Blind Face  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanjiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Puyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We found some problems with the article and need to withdrawal it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14444" title="Abstract">arXiv:2206.14444</a> (replaced) [<a href="/pdf/2206.14444" title="Download PDF">pdf</a>, <a href="/format/2206.14444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry parameter estimation for sparse X-ray log imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Senchukova%2C+A">Angelina Senchukova</a>, 
<a href="/search/cs?searchtype=author&query=Suuronen%2C+J">Jarkko Suuronen</a>, 
<a href="/search/cs?searchtype=author&query=Heikkinen%2C+J">Jere Heikkinen</a>, 
<a href="/search/cs?searchtype=author&query=Roininen%2C+L">Lassi Roininen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14769" title="Abstract">arXiv:2207.14769</a> (replaced) [<a href="/pdf/2207.14769" title="Download PDF">pdf</a>, <a href="/format/2207.14769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Quality Assessment: Integrating Model-Centric and Data-Centric  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Peibei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dingquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kede Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07084" title="Abstract">arXiv:2208.07084</a> (replaced) [<a href="/pdf/2208.07084" title="Download PDF">pdf</a>, <a href="/format/2208.07084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Z-BERT-A: a zero-shot Pipeline for Unknown Intent detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Comi%2C+D">Daniele Comi</a>, 
<a href="/search/cs?searchtype=author&query=Christofidellis%2C+D">Dimitrios Christofidellis</a>, 
<a href="/search/cs?searchtype=author&query=Piazza%2C+P+F">Pier Francesco Piazza</a>, 
<a href="/search/cs?searchtype=author&query=Manica%2C+M">Matteo Manica</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 14 tables, <a href="https://github.com/GT4SD/zberta">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07898" title="Abstract">arXiv:2208.07898</a> (replaced) [<a href="/pdf/2208.07898" title="Download PDF">pdf</a>, <a href="/format/2208.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative causal inference on distributed data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kawamata%2C+Y">Yuji Kawamata</a>, 
<a href="/search/stat?searchtype=author&query=Motai%2C+R">Ryoki Motai</a>, 
<a href="/search/stat?searchtype=author&query=Okada%2C+Y">Yukihiko Okada</a>, 
<a href="/search/stat?searchtype=author&query=Imakura%2C+A">Akira Imakura</a>, 
<a href="/search/stat?searchtype=author&query=Sakurai%2C+T">Tetsuya Sakurai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12464" title="Abstract">arXiv:2208.12464</a> (replaced) [<a href="/pdf/2208.12464" title="Download PDF">pdf</a>, <a href="/format/2208.12464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Depth Distillation with Out-of-Distribution Simulated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenyou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+M">Mete Ozay</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hualie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+T+L">Tin Lun Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04688" title="Abstract">arXiv:2210.04688</a> (replaced) [<a href="/pdf/2210.04688" title="Download PDF">pdf</a>, <a href="/format/2210.04688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yunpeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junda He</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jieke Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kecen Li</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Arunesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinwen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12637" title="Abstract">arXiv:2210.12637</a> (replaced) [<a href="/pdf/2210.12637" title="Download PDF">pdf</a>, <a href="/format/2210.12637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Eigenfunctions Are Structured Representation Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiaxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15194" title="Abstract">arXiv:2210.15194</a> (replaced) [<a href="/pdf/2210.15194" title="Download PDF">pdf</a>, <a href="/format/2210.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Image Generation via Masked Discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huimin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiansheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jian Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00385" title="Abstract">arXiv:2211.00385</a> (replaced) [<a href="/pdf/2211.00385" title="Download PDF">pdf</a>, <a href="/format/2211.00385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behavioral Intention Prediction in Driving Scenes: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jianwu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jianru Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 254 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01842" title="Abstract">arXiv:2211.01842</a> (replaced) [<a href="/pdf/2211.01842" title="Download PDF">pdf</a>, <a href="/format/2211.01842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of Hierarchical Neural Architecture Search Spaces based on  Context-free Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schrodi%2C+S">Simon Schrodi</a>, 
<a href="/search/cs?searchtype=author&query=Stoll%2C+D">Danny Stoll</a>, 
<a href="/search/cs?searchtype=author&query=Ru%2C+B">Binxin Ru</a>, 
<a href="/search/cs?searchtype=author&query=Sukthanker%2C+R">Rhea Sukthanker</a>, 
<a href="/search/cs?searchtype=author&query=Brox%2C+T">Thomas Brox</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03408" title="Abstract">arXiv:2211.03408</a> (replaced) [<a href="/pdf/2211.03408" title="Download PDF">pdf</a>, <a href="/format/2211.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RITA: Boost Driving Simulators with Realistic Interactive Traffic Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhengbang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuzheng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuecheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Liyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Ziqin Gong</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+S">Shixiong Kai</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, 5 tables, DAI 2023 (Best Student Paper Award)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13220" title="Abstract">arXiv:2211.13220</a> (replaced) [<a href="/pdf/2211.13220" title="Download PDF">pdf</a>, <a href="/format/2211.13220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TetraDiffusion: Tetrahedral Diffusion Models for 3D Shape Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalischek%2C+N">Nikolai Kalischek</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+T">Torben Peters</a>, 
<a href="/search/cs?searchtype=author&query=Wegner%2C+J+D">Jan D. Wegner</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version introduces a substantial update of <a href="/abs/2211.13220">arXiv:2211.13220v1</a> with significant changes in the framework and entirely new results. Project page <a href="https://tetradiffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15417" title="Abstract">arXiv:2211.15417</a> (replaced) [<a href="/pdf/2211.15417" title="Download PDF">pdf</a>, <a href="/format/2211.15417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proof-of-randomness protocol for blockchain consensus: a case of Macau  algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen-Zhuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+V">Victor Kai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07311" title="Abstract">arXiv:2212.07311</a> (replaced) [<a href="/pdf/2212.07311" title="Download PDF">pdf</a>, <a href="/format/2212.07311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian data fusion with shared priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Imbiriba%2C+T">Tales Imbiriba</a>, 
<a href="/search/cs?searchtype=author&query=Elvira%2C+V">Victor Elvira</a>, 
<a href="/search/cs?searchtype=author&query=Closas%2C+P">Pau Closas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07679" title="Abstract">arXiv:2212.07679</a> (replaced) [<a href="/pdf/2212.07679" title="Download PDF">pdf</a>, <a href="/format/2212.07679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast exact fixed-radius nearest neighbor search based on sorting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinye Chen</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCttel%2C+S">Stefan G&#xfc;ttel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.01456">arXiv:2202.01456</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09744" title="Abstract">arXiv:2212.09744</a> (replaced) [<a href="/pdf/2212.09744" title="Download PDF">pdf</a>, <a href="/format/2212.09744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSI++: Updating Transformer Memory with New Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S+V">Sanket Vaibhav Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J">Jai Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y">Yi Tay</a>, 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mostafa Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+V+Q">Vinh Q. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinfeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Najork%2C+M">Marc Najork</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Metzler%2C+D">Donald Metzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09568" title="Abstract">arXiv:2301.09568</a> (replaced) [<a href="/pdf/2301.09568" title="Download PDF">pdf</a>, <a href="/format/2301.09568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Classification of Early Stage Parkinson&#x27;s Disease from EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sahota%2C+A">Amarpal Sahota</a>, 
<a href="/search/q-bio?searchtype=author&query=Roguski%2C+A">Amber Roguski</a>, 
<a href="/search/q-bio?searchtype=author&query=Jones%2C+M+W">Matthew W. Jones</a>, 
<a href="/search/q-bio?searchtype=author&query=Rolinski%2C+M">Michal Rolinski</a>, 
<a href="/search/q-bio?searchtype=author&query=Whone%2C+A">Alan Whone</a>, 
<a href="/search/q-bio?searchtype=author&query=Santos-Rodriguez%2C+R">Raul Santos-Rodriguez</a>, 
<a href="/search/q-bio?searchtype=author&query=Abdallah%2C+Z+S">Zahraa S. Abdallah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01404" title="Abstract">arXiv:2302.01404</a> (replaced) [<a href="/pdf/2302.01404" title="Download PDF">pdf</a>, <a href="/format/2302.01404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Bounding Neural Network Preimages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotha%2C+S">Suhas Kotha</a>, 
<a href="/search/cs?searchtype=author&query=Brix%2C+C">Christopher Brix</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+Z">Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Dvijotham%2C+K">Krishnamurthy Dvijotham</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02407" title="Abstract">arXiv:2302.02407</a> (replaced) [<a href="/pdf/2302.02407" title="Download PDF">pdf</a>, <a href="/format/2302.02407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyPHEN: A Hybrid Packing Method and Optimizations for Homomorphic  Encryption-Based Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaiyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangpyo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J+H">Jung Ho Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02524" title="Abstract">arXiv:2302.02524</a> (replaced) [<a href="/pdf/2302.02524" title="Download PDF">pdf</a>, <a href="/format/2302.02524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Fundus Image Preprocessing for Retcam Images to Improve Deep  Learning Classification of Retinopathy of Prematurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rahim%2C+S">Sajid Rahim</a>, 
<a href="/search/eess?searchtype=author&query=Sabri%2C+K">Kourosh Sabri</a>, 
<a href="/search/eess?searchtype=author&query=Ells%2C+A">Anna Ells</a>, 
<a href="/search/eess?searchtype=author&query=Wassyng%2C+A">Alan Wassyng</a>, 
<a href="/search/eess?searchtype=author&query=Lawford%2C+M">Mark Lawford</a>, 
<a href="/search/eess?searchtype=author&query=Chu%2C+L">Linyang Chu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+W">Wenbo He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 7 tables. arXiv admin note: text overlap with <a href="/abs/1904.08796">arXiv:1904.08796</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06359" title="Abstract">arXiv:2302.06359</a> (replaced) [<a href="/pdf/2302.06359" title="Download PDF">pdf</a>, <a href="/format/2302.06359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixing Overconfidence in Dynamic Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meronen%2C+L">Lassi Meronen</a>, 
<a href="/search/cs?searchtype=author&query=Trapp%2C+M">Martin Trapp</a>, 
<a href="/search/cs?searchtype=author&query=Pilzer%2C+A">Andrea Pilzer</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Le Yang</a>, 
<a href="/search/cs?searchtype=author&query=Solin%2C+A">Arno Solin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11593" title="Abstract">arXiv:2302.11593</a> (replaced) [<a href="/pdf/2302.11593" title="Download PDF">pdf</a>, <a href="/format/2302.11593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum spherical codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jain%2C+S+P">Shubham P. Jain</a>, 
<a href="/search/quant-ph?searchtype=author&query=Iosue%2C+J+T">Joseph T. Iosue</a>, 
<a href="/search/quant-ph?searchtype=author&query=Barg%2C+A">Alexander Barg</a>, 
<a href="/search/quant-ph?searchtype=author&query=Albert%2C+V+V">Victor V. Albert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 + 12 pages, 3 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Information Theory (cs.IT); Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12199" title="Abstract">arXiv:2302.12199</a> (replaced) [<a href="/pdf/2302.12199" title="Download PDF">pdf</a>, <a href="/format/2302.12199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineering Massively Parallel MST Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanders%2C+P">Peter Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Schimek%2C+M">Matthias Schimek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12253" title="Abstract">arXiv:2302.12253</a> (replaced) [<a href="/pdf/2302.12253" title="Download PDF">pdf</a>, <a href="/format/2302.12253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DisCO: Portrait Distortion Correction with Perspective-Aware 3D GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Lun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+S">Shin&#x27;ichi Satoh</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Sizhuo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+G">Gurunandan Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://portrait-disco.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02304" title="Abstract">arXiv:2303.02304</a> (replaced) [<a href="/pdf/2303.02304" title="Download PDF">pdf</a>, <a href="/format/2303.02304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupled Multiwavelet Neural Operator Learning for Coupled Partial  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Defu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruochen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gaurav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gengshuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Chenzhong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Balan%2C+R">Radu Balan</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03470" title="Abstract">arXiv:2303.03470</a> (replaced) [<a href="/pdf/2303.03470" title="Download PDF">pdf</a>, <a href="/format/2303.03470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial-Information, Longitudinal Cyber Attacks on LiDAR in Autonomous  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hallyburton%2C+R+S">R. Spencer Hallyburton</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z+M">Z. Morley Mao</a>, 
<a href="/search/cs?searchtype=author&query=Pajic%2C+M">Miroslav Pajic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05066" title="Abstract">arXiv:2303.05066</a> (replaced) [<a href="/pdf/2303.05066" title="Download PDF">pdf</a>, <a href="/format/2303.05066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distortion-Disentangled Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Sifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jionglong Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Oral in WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05221" title="Abstract">arXiv:2303.05221</a> (replaced) [<a href="/pdf/2303.05221" title="Download PDF">pdf</a>, <a href="/format/2303.05221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEAM: An Integrated Activation-Coupled Model of Sentence Processing and  Eye Movements in Reading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rabe%2C+M+M">Maximilian M. Rabe</a>, 
<a href="/search/q-bio?searchtype=author&query=Paape%2C+D">Dario Paape</a>, 
<a href="/search/q-bio?searchtype=author&query=Mertzen%2C+D">Daniela Mertzen</a>, 
<a href="/search/q-bio?searchtype=author&query=Vasishth%2C+S">Shravan Vasishth</a>, 
<a href="/search/q-bio?searchtype=author&query=Engbert%2C+R">Ralf Engbert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07683" title="Abstract">arXiv:2304.07683</a> (replaced) [<a href="/pdf/2304.07683" title="Download PDF">pdf</a>, <a href="/ps/2304.07683" title="Download PostScript">ps</a>, <a href="/format/2304.07683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources,  Impacts, And Mitigation Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09424" title="Abstract">arXiv:2304.09424</a> (replaced) [<a href="/pdf/2304.09424" title="Download PDF">pdf</a>, <a href="/format/2304.09424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss Minimization Yields Multicalibration for Large Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C5%82asiok%2C+J">Jaros&#x142;aw B&#x142;asiok</a>, 
<a href="/search/cs?searchtype=author&query=Gopalan%2C+P">Parikshit Gopalan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lunjia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Nakkiran%2C+P">Preetum Nakkiran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11090" title="Abstract">arXiv:2304.11090</a> (replaced) [<a href="/pdf/2304.11090" title="Download PDF">pdf</a>, <a href="/format/2304.11090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Responsible AI in the Era of Generative AI: A Reference  Architecture for Designing Foundation Model based Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Whittle%2C+J">Jon Whittle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14061" title="Abstract">arXiv:2304.14061</a> (replaced) [<a href="/pdf/2304.14061" title="Download PDF">pdf</a>, <a href="/ps/2304.14061" title="Download PostScript">ps</a>, <a href="/format/2304.14061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier-Gegenbauer Pseudospectral Method for Solving Time-Dependent  One-Dimensional Fractional Partial Differential Equations with Variable  Coefficients and Periodic Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Elgindy%2C+K+T">Kareem T. Elgindy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14310" title="Abstract">arXiv:2304.14310</a> (replaced) [<a href="/pdf/2304.14310" title="Download PDF">pdf</a>, <a href="/format/2304.14310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Generalized Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Aodha%2C+O">Oisin Mac Aodha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01260" title="Abstract">arXiv:2305.01260</a> (replaced) [<a href="/pdf/2305.01260" title="Download PDF">pdf</a>, <a href="/format/2305.01260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal MIMO Jammer Mitigation via Secret Temporal Subspace Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marti%2C+G">Gian Marti</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Asilomar 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01416" title="Abstract">arXiv:2305.01416</a> (replaced) [<a href="/pdf/2305.01416" title="Download PDF">pdf</a>, <a href="/format/2305.01416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trade-off Between Optimal Efficiency and Envelope Correlation  Coefficient for Antenna Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neuman%2C+V">Vojtech Neuman</a>, 
<a href="/search/cs?searchtype=author&query=Capek%2C+M">Miloslav Capek</a>, 
<a href="/search/cs?searchtype=author&query=Jelinek%2C+L">Lukas Jelinek</a>, 
<a href="/search/cs?searchtype=author&query=Lehtovuori%2C+A">Anu Lehtovuori</a>, 
<a href="/search/cs?searchtype=author&query=Viikari%2C+V">Ville Viikari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10214" title="Abstract">arXiv:2305.10214</a> (replaced) [<a href="/pdf/2305.10214" title="Download PDF">pdf</a>, <a href="/ps/2305.10214" title="Download PostScript">ps</a>, <a href="/format/2305.10214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error-Correcting Codes for Nanopore Sequencing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Anisha Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Yehezkeally%2C+Y">Yonatan Yehezkeally</a>, 
<a href="/search/cs?searchtype=author&query=Wachter-Zeh%2C+A">Antonia Wachter-Zeh</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10406" title="Abstract">arXiv:2305.10406</a> (replaced) [<a href="/pdf/2305.10406" title="Download PDF">pdf</a>, <a href="/format/2305.10406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhuliawala%2C+S">Shehzaad Dhuliawala</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+C">Carl Allen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12397" title="Abstract">arXiv:2305.12397</a> (replaced) [<a href="/pdf/2305.12397" title="Download PDF">pdf</a>, <a href="/format/2305.12397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Aware Spatio-Temporal Reasoning via Answering Questions in  Dynamics Audio-Visual Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuanyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13877" title="Abstract">arXiv:2305.13877</a> (replaced) [<a href="/pdf/2305.13877" title="Download PDF">pdf</a>, <a href="/format/2305.13877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NarrativeXL: A Large-scale Dataset For Long-Term Memory Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskvichev%2C+A">Arseny Moskvichev</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+K">Ky-Vinh Mai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14160" title="Abstract">arXiv:2305.14160</a> (replaced) [<a href="/pdf/2305.14160" title="Download PDF">pdf</a>, <a href="/format/2305.14160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Words are Anchors: An Information Flow Perspective for  Understanding In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lean Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Damai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14208" title="Abstract">arXiv:2305.14208</a> (replaced) [<a href="/pdf/2305.14208" title="Download PDF">pdf</a>, <a href="/format/2305.14208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Private Transformers for Multi-Domain Dialog Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabra%2C+A">Anmol Kabra</a>, 
<a href="/search/cs?searchtype=author&query=Elenberg%2C+E+R">Ethan R. Elenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023 (short paper). Code available at <a href="https://github.com/asappresearch/domain-private-transformers">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14591" title="Abstract">arXiv:2305.14591</a> (replaced) [<a href="/pdf/2305.14591" title="Download PDF">pdf</a>, <a href="/format/2305.14591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALGO: Synthesizing Algorithmic Programs with LLM-Generated Oracle  Verifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jingtao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14876" title="Abstract">arXiv:2305.14876</a> (replaced) [<a href="/pdf/2305.14876" title="Download PDF">pdf</a>, <a href="/format/2305.14876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructive Neuron Pruning for Backdoor Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yige Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xixiang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingjun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Koren%2C+N">Nodens Koren</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lingjuan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICML23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14938" title="Abstract">arXiv:2305.14938</a> (replaced) [<a href="/pdf/2305.14938" title="Download PDF">pdf</a>, <a href="/format/2305.14938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large  Language Models with SocKET Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minje Choi</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jiaxin Pei</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sagar Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+C">Chang Shu</a>, 
<a href="/search/cs?searchtype=author&query=Jurgens%2C+D">David Jurgens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version for EMNLP'23. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15036" title="Abstract">arXiv:2305.15036</a> (replaced) [<a href="/pdf/2305.15036" title="Download PDF">pdf</a>, <a href="/format/2305.15036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Adapter-based Transfer Learning for Recommender Systems:  Empirical Studies and Practical Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Junchen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fajie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yu Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingyue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shenghui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yunzhu Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15987" title="Abstract">arXiv:2305.15987</a> (replaced) [<a href="/pdf/2305.15987" title="Download PDF">pdf</a>, <a href="/format/2305.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A graphon-signal analysis of graph neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levie%2C+R">Ron Levie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17017" title="Abstract">arXiv:2305.17017</a> (replaced) [<a href="/pdf/2305.17017" title="Download PDF">pdf</a>, <a href="/format/2305.17017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating how ReLU-networks encode symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+F">Fredrik Kahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS camera ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18764" title="Abstract">arXiv:2305.18764</a> (replaced) [<a href="/pdf/2305.18764" title="Download PDF">pdf</a>, <a href="/format/2305.18764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Does Optimizing a Proper Loss Yield Calibration?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C5%82asiok%2C+J">Jaros&#x142;aw B&#x142;asiok</a>, 
<a href="/search/cs?searchtype=author&query=Gopalan%2C+P">Parikshit Gopalan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lunjia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nakkiran%2C+P">Preetum Nakkiran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In NeurIPS 2023. Selected for spotlight presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19776" title="Abstract">arXiv:2305.19776</a> (replaced) [<a href="/pdf/2305.19776" title="Download PDF">pdf</a>, <a href="/format/2305.19776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Off-By-One Implementation Error in J-UNIWARD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorch%2C+B">Benedikt Lorch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00006" title="Abstract">arXiv:2306.00006</a> (replaced) [<a href="/pdf/2306.00006" title="Download PDF">pdf</a>, <a href="/format/2306.00006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truncated Affinity Maximization: One-class Homophily Modeling for Graph  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+H">Hezhe Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00945" title="Abstract">arXiv:2306.00945</a> (replaced) [<a href="/pdf/2306.00945" title="Download PDF">pdf</a>, <a href="/format/2306.00945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CS4ML: A general framework for active learning with arbitrary data based  on Christoffel functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adcock%2C+B">Ben Adcock</a>, 
<a href="/search/cs?searchtype=author&query=Cardenas%2C+J+M">Juan M. Cardenas</a>, 
<a href="/search/cs?searchtype=author&query=Dexter%2C+N">Nick Dexter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02204" title="Abstract">arXiv:2306.02204</a> (replaced) [<a href="/pdf/2306.02204" title="Download PDF">pdf</a>, <a href="/format/2306.02204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cycle Consistency Driven Object Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Didolkar%2C+A">Aniket Didolkar</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03623" title="Abstract">arXiv:2306.03623</a> (replaced) [<a href="/pdf/2306.03623" title="Download PDF">pdf</a>, <a href="/format/2306.03623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spike-based computation using classical recurrent neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Geeter%2C+F">Florent De Geeter</a> (1), 
<a href="/search/cs?searchtype=author&query=Ernst%2C+D">Damien Ernst</a> (1), 
<a href="/search/cs?searchtype=author&query=Drion%2C+G">Guillaume Drion</a> (1) ((1) Montefiore Institute, University of Li&#xe8;ge, Li&#xe8;ge, Belgium)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04829" title="Abstract">arXiv:2306.04829</a> (replaced) [<a href="/pdf/2306.04829" title="Download PDF">pdf</a>, <a href="/format/2306.04829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Learning for Real-World Videos by Predicting Temporal  Feature Similarities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zadaianchuk%2C+A">Andrii Zadaianchuk</a>, 
<a href="/search/cs?searchtype=author&query=Seitzer%2C+M">Maximilian Seitzer</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Website and code available at <a href="https://martius-lab.github.io/videosaur">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04984" title="Abstract">arXiv:2306.04984</a> (replaced) [<a href="/pdf/2306.04984" title="Download PDF">pdf</a>, <a href="/format/2306.04984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks  through Attributed Client Graph Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05415" title="Abstract">arXiv:2306.05415</a> (replaced) [<a href="/pdf/2306.05415" title="Download PDF">pdf</a>, <a href="/format/2306.05415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal normalizing flows: from theory to practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javaloy%2C+A">Adri&#xe1;n Javaloy</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Mart%C3%ADn%2C+P">Pablo S&#xe1;nchez-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Valera%2C+I">Isabel Valera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 15 figures. Accepted as an Oral presentation at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05668" title="Abstract">arXiv:2306.05668</a> (replaced) [<a href="/pdf/2306.05668" title="Download PDF">pdf</a>, <a href="/format/2306.05668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F+R">F. Richard Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">You Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI 2023 Accepted (Main Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08707" title="Abstract">arXiv:2306.08707</a> (replaced) [<a href="/pdf/2306.08707" title="Download PDF">pdf</a>, <a href="/format/2306.08707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidEdit: Zero-Shot and Spatially Aware Text-Driven Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Couairon%2C+P">Paul Couairon</a>, 
<a href="/search/cs?searchtype=author&query=Rambour%2C+C">Cl&#xe9;ment Rambour</a>, 
<a href="/search/cs?searchtype=author&query=Haugeard%2C+J">Jean-Emmanuel Haugeard</a>, 
<a href="/search/cs?searchtype=author&query=Thome%2C+N">Nicolas Thome</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project web-page at <a href="https://videdit.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11072" title="Abstract">arXiv:2306.11072</a> (replaced) [<a href="/pdf/2306.11072" title="Download PDF">pdf</a>, <a href="/format/2306.11072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Effect Regularization: Automated Detection and Removal of  Spurious Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhinav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Amit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Amit Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11290" title="Abstract">arXiv:2306.11290</a> (replaced) [<a href="/pdf/2306.11290" title="Download PDF">pdf</a>, <a href="/format/2306.11290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene  Scale and Realism Tradeoffs for ObjectGoal Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanna%2C+M">Mukul Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongsen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hanxiao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Haresh%2C+S">Sanjay Haresh</a>, 
<a href="/search/cs?searchtype=author&query=Shacklett%2C+B">Brennan Shacklett</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Clegg%2C+A">Alexander Clegg</a>, 
<a href="/search/cs?searchtype=author&query=Undersander%2C+E">Eric Undersander</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12333" title="Abstract">arXiv:2306.12333</a> (replaced) [<a href="/pdf/2306.12333" title="Download PDF">pdf</a>, <a href="/format/2306.12333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Navigation with Convergence Guarantees in Complex Dynamic  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dahlin%2C+A">Albin Dahlin</a>, 
<a href="/search/cs?searchtype=author&query=Karayiannidis%2C+Y">Yiannis Karayiannidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12357" title="Abstract">arXiv:2306.12357</a> (replaced) [<a href="/pdf/2306.12357" title="Download PDF">pdf</a>, <a href="/format/2306.12357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Constraint Learning and Generalization by Transferable Reward  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jaehwi Jang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Minjae Song</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Daehyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13331" title="Abstract">arXiv:2306.13331</a> (replaced) [<a href="/pdf/2306.13331" title="Download PDF">pdf</a>, <a href="/format/2306.13331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-optimal control of adaptive structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schaller%2C+M">Manuel Schaller</a>, 
<a href="/search/eess?searchtype=author&query=Zeller%2C+A">Amelie Zeller</a>, 
<a href="/search/eess?searchtype=author&query=B%C3%B6hm%2C+M">Michael B&#xf6;hm</a>, 
<a href="/search/eess?searchtype=author&query=Sawodny%2C+O">Oliver Sawodny</a>, 
<a href="/search/eess?searchtype=author&query=Tar%C3%ADn%2C+C">Cristina Tar&#xed;n</a>, 
<a href="/search/eess?searchtype=author&query=Worthmann%2C+K">Karl Worthmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13596" title="Abstract">arXiv:2306.13596</a> (replaced) [<a href="/pdf/2306.13596" title="Download PDF">pdf</a>, <a href="/format/2306.13596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max-Margin Token Selection in Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarzanagh%2C+D+A">Davoud Ataee Tarzanagh</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised proof of Theorem 2 - Gradient descent path globally converges only when n=1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13693" title="Abstract">arXiv:2306.13693</a> (replaced) [<a href="/pdf/2306.13693" title="Download PDF">pdf</a>, <a href="/ps/2306.13693" title="Download PostScript">ps</a>, <a href="/format/2306.13693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSMA for Overloaded MIMO Networks: Low-Complexity Design for Max-Min  Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dizdar%2C+O">Onur Dizdar</a>, 
<a href="/search/cs?searchtype=author&query=Sattarzadeh%2C+A">Ata Sattarzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+Y+X">Yi Xien Yap</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Stephen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.13414">arXiv:2306.13414</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15657" title="Abstract">arXiv:2306.15657</a> (replaced) [<a href="/pdf/2306.15657" title="Download PDF">pdf</a>, <a href="/ps/2306.15657" title="Download PostScript">ps</a>, <a href="/format/2306.15657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Distortion of Binomial Voting Defies Expectation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonczarowski%2C+Y+A">Yannai A. Gonczarowski</a>, 
<a href="/search/cs?searchtype=author&query=Kehne%2C+G">Gregory Kehne</a>, 
<a href="/search/cs?searchtype=author&query=Procaccia%2C+A+D">Ariel D. Procaccia</a>, 
<a href="/search/cs?searchtype=author&query=Schiffer%2C+B">Ben Schiffer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shirley Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01915" title="Abstract">arXiv:2307.01915</a> (replaced) [<a href="/pdf/2307.01915" title="Download PDF">pdf</a>, <a href="/ps/2307.01915" title="Download PostScript">ps</a>, <a href="/format/2307.01915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using mathematics to study how people influence each other&#x27;s opinions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+G+J">Grace J. Li</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+J">Jiajie Luo</a>, 
<a href="/search/physics?searchtype=author&query=Peng%2C+K">Kaiyan Peng</a>, 
<a href="/search/physics?searchtype=author&query=Porter%2C+M+A">Mason A. Porter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is written for teenagers and preteens. Revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Dynamical Systems (math.DS); History and Overview (math.HO); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02251" title="Abstract">arXiv:2307.02251</a> (replaced) [<a href="/pdf/2307.02251" title="Download PDF">pdf</a>, <a href="/format/2307.02251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RanPAC: Random Projections and Pre-trained Models for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDonnell%2C+M+D">Mark D. McDonnell</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Dong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Parveneh%2C+A">Amin Parveneh</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Annual Conference on Neural Information Processing Systems
  (NeurIPS 2023), Dec 2023, New Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04684" title="Abstract">arXiv:2307.04684</a> (replaced) [<a href="/pdf/2307.04684" title="Download PDF">pdf</a>, <a href="/format/2307.04684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeDrag: Feature Dragging for Reliable Point-based Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+P">Pengyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinjin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05178" title="Abstract">arXiv:2307.05178</a> (replaced) [<a href="/pdf/2307.05178" title="Download PDF">pdf</a>, <a href="/ps/2307.05178" title="Download PostScript">ps</a>, <a href="/format/2307.05178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Minimal Residual Methods in $W^{-1,p&#x27;}$ with large Exponents $p$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Storn%2C+J">Johannes Storn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09961" title="Abstract">arXiv:2307.09961</a> (replaced) [<a href="/pdf/2307.09961" title="Download PDF">pdf</a>, <a href="/ps/2307.09961" title="Download PostScript">ps</a>, <a href="/format/2307.09961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Dynamic Graph Algorithms with Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+J">Jan van den Brand</a>, 
<a href="/search/cs?searchtype=author&query=Forster%2C+S">Sebastian Forster</a>, 
<a href="/search/cs?searchtype=author&query=Nazari%2C+Y">Yasamin Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+A">Adam Polak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in proceedings of SODA 2024. Abstract shortened to meet arXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10284" title="Abstract">arXiv:2307.10284</a> (replaced) [<a href="/pdf/2307.10284" title="Download PDF">pdf</a>, <a href="/format/2307.10284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECSIC: Epipolar Cross Attention for Stereo Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=W%C3%B6dlinger%2C+M">Matthias W&#xf6;dlinger</a>, 
<a href="/search/eess?searchtype=author&query=Kotera%2C+J">Jan Kotera</a>, 
<a href="/search/eess?searchtype=author&query=Keglevic%2C+M">Manuel Keglevic</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jan Xu</a>, 
<a href="/search/eess?searchtype=author&query=Sablatnig%2C+R">Robert Sablatnig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13237" title="Abstract">arXiv:2307.13237</a> (replaced) [<a href="/pdf/2307.13237" title="Download PDF">pdf</a>, <a href="/ps/2307.13237" title="Download PostScript">ps</a>, <a href="/format/2307.13237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank Optimization for MIMO Channel with RIS: Simulation and Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shengguo Meng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weicong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jifeng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q+Y">Qun Yan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by IEEE WCL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13818" title="Abstract">arXiv:2307.13818</a> (replaced) [<a href="/pdf/2307.13818" title="Download PDF">pdf</a>, <a href="/format/2307.13818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-Based Spectral Embeddings of Random Dot Product Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiori%2C+M">Marcelo Fiori</a>, 
<a href="/search/cs?searchtype=author&query=Marenco%2C+B">Bernardo Marenco</a>, 
<a href="/search/cs?searchtype=author&query=Larroca%2C+F">Federico Larroca</a>, 
<a href="/search/cs?searchtype=author&query=Bermolen%2C+P">Paola Bermolen</a>, 
<a href="/search/cs?searchtype=author&query=Mateos%2C+G">Gonzalo Mateos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13917" title="Abstract">arXiv:2307.13917</a> (replaced) [<a href="/pdf/2307.13917" title="Download PDF">pdf</a>, <a href="/format/2307.13917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BayesDAG: Gradient-Based Posterior Inference for Causal Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Annadani%2C+Y">Yashas Annadani</a>, 
<a href="/search/cs?searchtype=author&query=Pawlowski%2C+N">Nick Pawlowski</a>, 
<a href="/search/cs?searchtype=author&query=Jennings%2C+J">Joel Jennings</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wenbo Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16680" title="Abstract">arXiv:2307.16680</a> (replaced) [<a href="/pdf/2307.16680" title="Download PDF">pdf</a>, <a href="/ps/2307.16680" title="Download PostScript">ps</a>, <a href="/format/2307.16680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trustworthiness Landscape of State-of-the-art Generative Models:  A Survey and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A big update, draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03321" title="Abstract">arXiv:2308.03321</a> (replaced) [<a href="/pdf/2308.03321" title="Download PDF">pdf</a>, <a href="/format/2308.03321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFN: Adaptive Fusion Normalization via Encoder-Decoder Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2106.01899">arXiv:2106.01899</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04435" title="Abstract">arXiv:2308.04435</a> (replaced) [<a href="/pdf/2308.04435" title="Download PDF">pdf</a>, <a href="/ps/2308.04435" title="Download PostScript">ps</a>, <a href="/format/2308.04435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UJI Probes: Dataset of Wi-Fi Probe Requests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bravenec%2C+T">Tom&#xe1;&#x161; Bravenec</a>, 
<a href="/search/cs?searchtype=author&query=Torres-Sospedra%2C+J">Joaqu&#xed;n Torres-Sospedra</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+M">Michael Gould</a>, 
<a href="/search/cs?searchtype=author&query=Fryza%2C+T">Tomas Fryza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, submitted and accepted to IPIN2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04753" title="Abstract">arXiv:2308.04753</a> (replaced) [<a href="/pdf/2308.04753" title="Download PDF">pdf</a>, <a href="/format/2308.04753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAfER: Layer-Level Sensitivity Assessment for Efficient and Robust  Neural Network Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yvinec%2C+E">Edouard Yvinec</a>, 
<a href="/search/cs?searchtype=author&query=Dapogny%2C+A">Arnaud Dapogny</a>, 
<a href="/search/cs?searchtype=author&query=Bailly%2C+K">Kevin Bailly</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+X">Xavier Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07051" title="Abstract">arXiv:2308.07051</a> (replaced) [<a href="/pdf/2308.07051" title="Download PDF">pdf</a>, <a href="/format/2308.07051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier neural operator for learning solutions to macroscopic traffic  flow models: Application to the forward and inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thodi%2C+B+T">Bilal Thonnam Thodi</a>, 
<a href="/search/cs?searchtype=author&query=Ambadipudi%2C+S+V+R">Sai Venkata Ramana Ambadipudi</a>, 
<a href="/search/cs?searchtype=author&query=Jabari%2C+S+E">Saif Eddin Jabari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09835" title="Abstract">arXiv:2308.09835</a> (replaced) [<a href="/pdf/2308.09835" title="Download PDF">pdf</a>, <a href="/format/2308.09835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microscopy Image Segmentation via Point and Shape Regularized Data  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ach%2C+T">Thomas Ach</a>, 
<a href="/search/cs?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 3rd MICCAI Workshop on Data Augmentation, Labeling, and Imperfections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11471" title="Abstract">arXiv:2308.11471</a> (replaced) [<a href="/pdf/2308.11471" title="Download PDF">pdf</a>, <a href="/format/2308.11471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence  (DOVESEI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bong%2C+H+M">Haechan Mark Bong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=de+Azambuja%2C+R">Ricardo de Azambuja</a>, 
<a href="/search/cs?searchtype=author&query=Beltrame%2C+G">Giovanni Beltrame</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023 The Last-Mile Robotics Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16355" title="Abstract">arXiv:2308.16355</a> (replaced) [<a href="/pdf/2308.16355" title="Download PDF">pdf</a>, <a href="/format/2308.16355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Recycling Training Strategy for Medical Image Segmentation with  Diffusion Denoising Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fu%2C+Y">Yunguan Fu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yiwen Li</a>, 
<a href="/search/eess?searchtype=author&query=Saeed%2C+S+U">Shaheer U Saeed</a>, 
<a href="/search/eess?searchtype=author&query=Clarkson%2C+M+J">Matthew J Clarkson</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yipeng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2023:016">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00597" title="Abstract">arXiv:2309.00597</a> (replaced) [<a href="/pdf/2309.00597" title="Download PDF">pdf</a>, <a href="/format/2309.00597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The QUATRO Application Suite: Quantum Computing for Models of Human  Cognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pothukuchi%2C+R+P">Raghavendra Pradyumna Pothukuchi</a>, 
<a href="/search/cs?searchtype=author&query=Lufkin%2C+L">Leon Lufkin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y+J">Yu Jun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+A">Alejandro Simon</a>, 
<a href="/search/cs?searchtype=author&query=Thorstenson%2C+R">Rome Thorstenson</a>, 
<a href="/search/cs?searchtype=author&query=Trevisan%2C+B+E">Bernardo Eilert Trevisan</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+M">Michael Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mudi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Foxman%2C+B">Ben Foxman</a>, 
<a href="/search/cs?searchtype=author&query=Pothukuchi%2C+V+S">Viswanatha Srinivas Pothukuchi</a>, 
<a href="/search/cs?searchtype=author&query=Epping%2C+G">Gunnar Epping</a>, 
<a href="/search/cs?searchtype=author&query=Kyaw%2C+T+H">Thi Ha Kyaw</a>, 
<a href="/search/cs?searchtype=author&query=Jongkees%2C+B+J">Bryant J Jongkees</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yongshan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Busemeyer%2C+J+R">Jerome R Busemeyer</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+D">Jonathan D Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Abhishek Bhattacharjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET); Neurons and Cognition (q-bio.NC); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02446" title="Abstract">arXiv:2309.02446</a> (replaced) [<a href="/pdf/2309.02446" title="Download PDF">pdf</a>, <a href="/format/2309.02446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Generation-based Operator Learning for Solving Partial Differential  Equations on Unbounded Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+J">Jihong Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02833" title="Abstract">arXiv:2309.02833</a> (replaced) [<a href="/pdf/2309.02833" title="Download PDF">pdf</a>, <a href="/format/2309.02833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-Object-Specific Prompt Learning for Few-Shot Class-Incremental  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+I">In-Ug Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+T">Tae-Min Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sun-Kyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Young-Min Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jong-Hwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03251" title="Abstract">arXiv:2309.03251</a> (replaced) [<a href="/pdf/2309.03251" title="Download PDF">pdf</a>, <a href="/format/2309.03251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Inductive Path Neural Network for Temporal Knowledge Graph  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zhiyuan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanchun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03886" title="Abstract">arXiv:2309.03886</a> (replaced) [<a href="/pdf/2309.03886" title="Download PDF">pdf</a>, <a href="/format/2309.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIND: A Function Description Benchmark for Evaluating Interpretability  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwettmann%2C+S">Sarah Schwettmann</a>, 
<a href="/search/cs?searchtype=author&query=Shaham%2C+T+R">Tamar Rott Shaham</a>, 
<a href="/search/cs?searchtype=author&query=Materzynska%2C+J">Joanna Materzynska</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+N">Neil Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05254" title="Abstract">arXiv:2309.05254</a> (replaced) [<a href="/pdf/2309.05254" title="Download PDF">pdf</a>, <a href="/format/2309.05254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Data Exploitation in Self-Supervised Monocular Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingtong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, accepted by IEEE Robotics and Automation Letters (RA-L 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06207" title="Abstract">arXiv:2309.06207</a> (replaced) [<a href="/pdf/2309.06207" title="Download PDF">pdf</a>, <a href="/format/2309.06207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGNet: Salient Geometric Network for Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianliang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yaqing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chuanwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08003" title="Abstract">arXiv:2309.08003</a> (replaced) [<a href="/pdf/2309.08003" title="Download PDF">pdf</a>, <a href="/format/2309.08003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Decomposition of Multivariate Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varley%2C+T+F">Thomas F. Varley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 39 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11830" title="Abstract">arXiv:2309.11830</a> (replaced) [<a href="/pdf/2309.11830" title="Download PDF">pdf</a>, <a href="/format/2309.11830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Oriented Prompt Attack and Safety Evaluation for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fubang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+L">Lizhi Qing</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yangyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changlong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11955" title="Abstract">arXiv:2309.11955</a> (replaced) [<a href="/pdf/2309.11955" title="Download PDF">pdf</a>, <a href="/format/2309.11955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Forward-Forward Algorithm for Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brenig%2C+J">Jonas Brenig</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14348" title="Abstract">arXiv:2309.14348</a> (replaced) [<a href="/pdf/2309.14348" title="Download PDF">pdf</a>, <a href="/format/2309.14348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bochuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuanpu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghui Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 Pages, 5 Figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15730" title="Abstract">arXiv:2309.15730</a> (replaced) [<a href="/pdf/2309.15730" title="Download PDF">pdf</a>, <a href="/format/2309.15730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal graph models fail to capture global temporal dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniluk%2C+M">Micha&#x142; Daniluk</a>, 
<a href="/search/cs?searchtype=author&query=D%C4%85browski%2C+J">Jacek D&#x105;browski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16046" title="Abstract">arXiv:2309.16046</a> (replaced) [<a href="/pdf/2309.16046" title="Download PDF">pdf</a>, <a href="/format/2309.16046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precision estimation and second-order errors in cortical circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Granier%2C+A">Arno Granier</a>, 
<a href="/search/q-bio?searchtype=author&query=Petrovici%2C+M+A">Mihai A. Petrovici</a>, 
<a href="/search/q-bio?searchtype=author&query=Senn%2C+W">Walter Senn</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilmes%2C+K+A">Katharina A. Wilmes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16248" title="Abstract">arXiv:2309.16248</a> (replaced) [<a href="/pdf/2309.16248" title="Download PDF">pdf</a>, <a href="/format/2309.16248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph  Question Answering Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosten%2C+C">Catherine Kosten</a>, 
<a href="/search/cs?searchtype=author&query=Cudr%C3%A9-Mauroux%2C+P">Philippe Cudr&#xe9;-Mauroux</a>, 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+K">Kurt Stockinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, accepted at IEEE BigData Conference 2023, 8th IEEE Special Session on Machine Learning on Big Data (MLBD 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Big Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16620" title="Abstract">arXiv:2309.16620</a> (replaced) [<a href="/pdf/2309.16620" title="Download PDF">pdf</a>, <a href="/format/2309.16620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and  Scaling Limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bordelon%2C+B">Blake Bordelon</a>, 
<a href="/search/stat?searchtype=author&query=Noci%2C+L">Lorenzo Noci</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+M+B">Mufan Bill Li</a>, 
<a href="/search/stat?searchtype=author&query=Hanin%2C+B">Boris Hanin</a>, 
<a href="/search/stat?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00085" title="Abstract">arXiv:2310.00085</a> (replaced) [<a href="/pdf/2310.00085" title="Download PDF">pdf</a>, <a href="/format/2310.00085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEACE: Prompt Engineering Automation for CLIPSeg Enhancement in Aerial  Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bong%2C+H+M">Haechan Mark Bong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=de+Azambuja%2C+R">Ricardo de Azambuja</a>, 
<a href="/search/cs?searchtype=author&query=Beltrame%2C+G">Giovanni Beltrame</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024. arXiv admin note: substantial text overlap with <a href="/abs/2308.11471">arXiv:2308.11471</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00132" title="Abstract">arXiv:2310.00132</a> (replaced) [<a href="/pdf/2310.00132" title="Download PDF">pdf</a>, <a href="/format/2310.00132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Audiovisual Segmentation in Complex Environments with  Quantization-based Semantic Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinglu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiulian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rita Singh</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01557" title="Abstract">arXiv:2310.01557</a> (replaced) [<a href="/pdf/2310.01557" title="Download PDF">pdf</a>, <a href="/format/2310.01557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartPlay: A Benchmark for LLMs as Intelligent Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+T+M">Tom M. Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01994" title="Abstract">arXiv:2310.01994</a> (replaced) [<a href="/pdf/2310.01994" title="Download PDF">pdf</a>, <a href="/format/2310.01994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Masked Autoencoders From a Local Contrastive Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiaoyu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Meng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02374" title="Abstract">arXiv:2310.02374</a> (replaced) [<a href="/pdf/2310.02374" title="Download PDF">pdf</a>, <a href="/format/2310.02374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Health Agents: A Personalized LLM-Powered Agent Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasian%2C+M">Mahyar Abbasian</a>, 
<a href="/search/cs?searchtype=author&query=Azimi%2C+I">Iman Azimi</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+A+M">Amir M. Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ramesh Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03234" title="Abstract">arXiv:2310.03234</a> (replaced) [<a href="/pdf/2310.03234" title="Download PDF">pdf</a>, <a href="/format/2310.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+Q">Quanqi Hu</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+D">Dixian Zhu</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04852" title="Abstract">arXiv:2310.04852</a> (replaced) [<a href="/pdf/2310.04852" title="Download PDF">pdf</a>, <a href="/format/2310.04852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing utility and cognitive cost in social representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taylor-Davies%2C+M">Max Taylor-Davies</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+C+G">Christopher G. Lucas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on Information-Theoretic Principles in Cognitive Systems, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04935" title="Abstract">arXiv:2310.04935</a> (replaced) [<a href="/pdf/2310.04935" title="Download PDF">pdf</a>, <a href="/format/2310.04935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Guarantees for Variational Autoencoders using PAC-Bayesian  Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mbacke%2C+S+D">Sokhna Diarra Mbacke</a>, 
<a href="/search/cs?searchtype=author&query=Clerc%2C+F">Florence Clerc</a>, 
<a href="/search/cs?searchtype=author&query=Germain%2C+P">Pascal Germain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight Paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06089" title="Abstract">arXiv:2310.06089</a> (replaced) [<a href="/pdf/2310.06089" title="Download PDF">pdf</a>, <a href="/format/2310.06089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive auxiliary objectives in deep RL mimic learning in the brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Ching Fang</a>, 
<a href="/search/cs?searchtype=author&query=Stachenfeld%2C+K+L">Kimberly L Stachenfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10624" title="Abstract">arXiv:2310.10624</a> (replaced) [<a href="/pdf/2310.10624" title="Download PDF">pdf</a>, <a href="/format/2310.10624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and  View-Change Human-Centric Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weijia Mao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Keppo%2C+J">Jussi Keppo</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://showlab.github.io/DynVideo-E/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11288" title="Abstract">arXiv:2310.11288</a> (replaced) [<a href="/pdf/2310.11288" title="Download PDF">pdf</a>, <a href="/format/2310.11288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriching Diagrams with Algebraic Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villoria%2C+A">Alejandro Villoria</a>, 
<a href="/search/cs?searchtype=author&query=Basold%2C+H">Henning Basold</a>, 
<a href="/search/cs?searchtype=author&query=Laarman%2C+A">Alfons Laarman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 appendix pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11374" title="Abstract">arXiv:2310.11374</a> (replaced) [<a href="/pdf/2310.11374" title="Download PDF">pdf</a>, <a href="/format/2310.11374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for  Emotion Recognition in Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yazhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+P">Prayag Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiuchi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12214" title="Abstract">arXiv:2310.12214</a> (replaced) [<a href="/pdf/2310.12214" title="Download PDF">pdf</a>, <a href="/format/2310.12214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InferDPT: Privacy-Preserving Inference for Black-box Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meng Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12262" title="Abstract">arXiv:2310.12262</a> (replaced) [<a href="/pdf/2310.12262" title="Download PDF">pdf</a>, <a href="/format/2310.12262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving SCGAN&#x27;s Similarity Constraint and Learning a Better  Disentangled Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdanpanah%2C+I">Iman Yazdanpanah</a>, 
<a href="/search/cs?searchtype=author&query=Eslamian%2C+A">Ali Eslamian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12300" title="Abstract">arXiv:2310.12300</a> (replaced) [<a href="/pdf/2310.12300" title="Download PDF">pdf</a>, <a href="/format/2310.12300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Pointwise $\mathcal{V}$-Usable Information In-Context-ly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Sheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingya Li</a>, 
<a href="/search/cs?searchtype=author&query=Bitterman%2C+D">Danielle Bitterman</a>, 
<a href="/search/cs?searchtype=author&query=Savova%2C+G">Guergana Savova</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13032" title="Abstract">arXiv:2310.13032</a> (replaced) [<a href="/pdf/2310.13032" title="Download PDF">pdf</a>, <a href="/format/2310.13032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality-Diversity through AI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradley%2C+H">Herbie Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Andrew Dai</a>, 
<a href="/search/cs?searchtype=author&query=Teufel%2C+H">Hannah Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jenny Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Oostermeijer%2C+K">Koen Oostermeijer</a>, 
<a href="/search/cs?searchtype=author&query=Bellagente%2C+M">Marco Bellagente</a>, 
<a href="/search/cs?searchtype=author&query=Clune%2C+J">Jeff Clune</a>, 
<a href="/search/cs?searchtype=author&query=Stanley%2C+K">Kenneth Stanley</a>, 
<a href="/search/cs?searchtype=author&query=Schott%2C+G">Gr&#xe9;gory Schott</a>, 
<a href="/search/cs?searchtype=author&query=Lehman%2C+J">Joel Lehman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> minor additions to supplementary results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13139" title="Abstract">arXiv:2310.13139</a> (replaced) [<a href="/pdf/2310.13139" title="Download PDF">pdf</a>, <a href="/ps/2310.13139" title="Download PostScript">ps</a>, <a href="/format/2310.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks with polynomial activations have limited  expressivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalife%2C+S">Sammy Khalife</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15064" title="Abstract">arXiv:2310.15064</a> (replaced) [<a href="/pdf/2310.15064" title="Download PDF">pdf</a>, <a href="/format/2310.15064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power-free Complementary Binary Morphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="/search/math?searchtype=author&query=Shur%2C+A+M">Arseny M. Shur</a>, 
<a href="/search/math?searchtype=author&query=Zorcic%2C+S">Stefan Zorcic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15825" title="Abstract">arXiv:2310.15825</a> (replaced) [<a href="/pdf/2310.15825" title="Download PDF">pdf</a>, <a href="/format/2310.15825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spline-Based Collocation Method for Stokes and Navier-Stokes equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+J">Jinsil Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19385" title="Abstract">arXiv:2310.19385</a> (replaced) [<a href="/pdf/2310.19385" title="Download PDF">pdf</a>, <a href="/format/2310.19385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-free online learning of subgrid-scale dynamics with neural  emulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Frezat%2C+H">Hugo Frezat</a>, 
<a href="/search/physics?searchtype=author&query=Fablet%2C+R">Ronan Fablet</a>, 
<a href="/search/physics?searchtype=author&query=Balarac%2C+G">Guillaume Balarac</a>, 
<a href="/search/physics?searchtype=author&query=Sommer%2C+J+L">Julien Le Sommer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, submitted for publication in Journal of Advances in Modeling Earth Systems (JAMES)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20426" title="Abstract">arXiv:2310.20426</a> (replaced) [<a href="/pdf/2310.20426" title="Download PDF">pdf</a>, <a href="/format/2310.20426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Pareto Set Learning with Structure Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingfu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03052" title="Abstract">arXiv:2311.03052</a> (replaced) [<a href="/pdf/2311.03052" title="Download PDF">pdf</a>, <a href="/format/2311.03052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixUp-MIL: A Study on Linear &amp; Multilinear Interpolation-Based Data  Augmentation for Whole Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadermayr%2C+M">Michael Gadermayr</a>, 
<a href="/search/cs?searchtype=author&query=Koller%2C+L">Lukas Koller</a>, 
<a href="/search/cs?searchtype=author&query=Tschuchnig%2C+M">Maximilian Tschuchnig</a>, 
<a href="/search/cs?searchtype=author&query=Stangassinger%2C+L+M">Lea Maria Stangassinger</a>, 
<a href="/search/cs?searchtype=author&query=Kreutzer%2C+C">Christina Kreutzer</a>, 
<a href="/search/cs?searchtype=author&query=Couillard-Despres%2C+S">Sebastien Couillard-Despres</a>, 
<a href="/search/cs?searchtype=author&query=Oostingh%2C+G+J">Gertie Janneke Oostingh</a>, 
<a href="/search/cs?searchtype=author&query=Hittmair%2C+A">Anton Hittmair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for code and data, see gitlab repo: <a href="https://gitlab.com/mgadermayr/mixupmil.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2211.05862">arXiv:2211.05862</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03393" title="Abstract">arXiv:2311.03393</a> (replaced) [<a href="/pdf/2311.03393" title="Download PDF">pdf</a>, <a href="/format/2311.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketching Multidimensional Time Series for Fast Discord Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Menghai Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M. Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Keogh%2C+E">Eamonn Keogh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06563" title="Abstract">arXiv:2311.06563</a> (replaced) [<a href="/pdf/2311.06563" title="Download PDF">pdf</a>, <a href="/ps/2311.06563" title="Download PostScript">ps</a>, <a href="/format/2311.06563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All instances of MONOTONE 3-SAT-(3,1) are satisfiable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Santvliet%2C+H">Hannah Van Santvliet</a>, 
<a href="/search/cs?searchtype=author&query=de+Haan%2C+R">Ronald de Haan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07361" title="Abstract">arXiv:2311.07361</a> (replaced) [<a href="/pdf/2311.07361" title="Download PDF">pdf</a>, <a href="/format/2311.07361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Large Language Models on Scientific Discovery: a  Preliminary Study using GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AI4Science%2C+M+R">Microsoft Research AI4Science</a>, 
<a href="/search/cs?searchtype=author&query=Quantum%2C+M+A">Microsoft Azure Quantum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 230 pages report; 181 pages for main contents
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07794" title="Abstract">arXiv:2311.07794</a> (replaced) [<a href="/pdf/2311.07794" title="Download PDF">pdf</a>, <a href="/ps/2311.07794" title="Download PostScript">ps</a>, <a href="/format/2311.07794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Use Quantum Indistinguishability Obfuscation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Coladangelo%2C+A">Andrea Coladangelo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gunn%2C+S">Sam Gunn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07923" title="Abstract">arXiv:2311.07923</a> (replaced) [<a href="/pdf/2311.07923" title="Download PDF">pdf</a>, <a href="/format/2311.07923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> bpftime: userspace eBPF Runtime for Uprobe, Syscall and Kernel-User  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yusheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yanpeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+X">Xiaozheng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+A">Andrew Quinn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10407" title="Abstract">arXiv:2311.10407</a> (replaced) [<a href="/pdf/2311.10407" title="Download PDF">pdf</a>, <a href="/ps/2311.10407" title="Download PostScript">ps</a>, <a href="/format/2311.10407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Counting on the Complete Bipartite Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bezerra%2C+G+A">Gustavo A. Bezerra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Santos%2C+R+A+M">Raqueline A. M. Santos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Portugal%2C+R">Renato Portugal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, title changed, references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10586" title="Abstract">arXiv:2311.10586</a> (replaced) [<a href="/pdf/2311.10586" title="Download PDF">pdf</a>, <a href="/format/2311.10586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Manipulators -- the Strategic Implications of Binding Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+M+A">Maria Alejandra Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Kolumbus%2C+Y">Yoav Kolumbus</a>, 
<a href="/search/cs?searchtype=author&query=Nagel%2C+R">Rosemarie Nagel</a>, 
<a href="/search/cs?searchtype=author&query=Wolpert%2C+D">David Wolpert</a>, 
<a href="/search/cs?searchtype=author&query=Jost%2C+J">J&#xfc;rgen Jost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11841" title="Abstract">arXiv:2311.11841</a> (replaced) [<a href="/pdf/2311.11841" title="Download PDF">pdf</a>, <a href="/format/2311.11841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Probability Guarantees for Random Reshuffling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+H">Hengxu Yu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13443" title="Abstract">arXiv:2311.13443</a> (replaced) [<a href="/pdf/2311.13443" title="Download PDF">pdf</a>, <a href="/format/2311.13443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Flows for Generative Modeling and Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+M">Matt Le</a>, 
<a href="/search/cs?searchtype=author&query=Shaul%2C+N">Neta Shaul</a>, 
<a href="/search/cs?searchtype=author&query=Lipman%2C+Y">Yaron Lipman</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13534" title="Abstract">arXiv:2311.13534</a> (replaced) [<a href="/pdf/2311.13534" title="Download PDF">pdf</a>, <a href="/format/2311.13534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-Cocktail: Resilient Tuning of Language Models via Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xingrun Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work is in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13713" title="Abstract">arXiv:2311.13713</a> (replaced) [<a href="/pdf/2311.13713" title="Download PDF">pdf</a>, <a href="/format/2311.13713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Somewhat Robust Image Watermark against Diffusion-based Editing Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingtian Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14387" title="Abstract">arXiv:2311.14387</a> (replaced) [<a href="/pdf/2311.14387" title="Download PDF">pdf</a>, <a href="/format/2311.14387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Margin Maximization Exponentially Fast via Progressive Norm  Rescaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Z">Zeping Min</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14391" title="Abstract">arXiv:2311.14391</a> (replaced) [<a href="/pdf/2311.14391" title="Download PDF">pdf</a>, <a href="/format/2311.14391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#xda;FAL CorPipe at CRAC 2023: Larger Context Improves Multilingual  Coreference Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straka%2C+M">Milan Straka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CRAC 2023 (the Sixth Workshop on Computational Models of Reference, Anaphora and Coreference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15167" title="Abstract">arXiv:2311.15167</a> (replaced) [<a href="/pdf/2311.15167" title="Download PDF">pdf</a>, <a href="/format/2311.15167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised OCT Image Denoising with Slice-to-Slice Registration and  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijie Li</a>, 
<a href="/search/eess?searchtype=author&query=Alexopoulos%2C+P">Palaiologos Alexopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Vellappally%2C+A">Anse Vellappally</a>, 
<a href="/search/eess?searchtype=author&query=Zambrano%2C+R">Ronald Zambrano</a>, 
<a href="/search/eess?searchtype=author&query=Gadi%2C+W">Wollstein Gadi</a>, 
<a href="/search/eess?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 1 table, submitted to International Symposium on Biomedical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15766" title="Abstract">arXiv:2311.15766</a> (replaced) [<a href="/pdf/2311.15766" title="Download PDF">pdf</a>, <a href="/format/2311.15766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+N">Nianwen Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Heyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+D">Dan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiqiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16111" title="Abstract">arXiv:2311.16111</a> (replaced) [<a href="/pdf/2311.16111" title="Download PDF">pdf</a>, <a href="/ps/2311.16111" title="Download PostScript">ps</a>, <a href="/format/2311.16111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Crystals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Karamintziou%2C+S">Sofia Karamintziou</a>, 
<a href="/search/q-bio?searchtype=author&query=Mavropoulos%2C+T">Thanassis Mavropoulos</a>, 
<a href="/search/q-bio?searchtype=author&query=Ntioudis%2C+D">Dimos Ntioudis</a>, 
<a href="/search/q-bio?searchtype=author&query=Meditskos%2C+G">Georgios Meditskos</a>, 
<a href="/search/q-bio?searchtype=author&query=Vrochidis%2C+S">Stefanos Vrochidis</a>, 
<a href="/search/q-bio?searchtype=author&query=Ioannis">Ioannis</a> (Yiannis)
<a href="/search/q-bio?searchtype=author&query=Kompatsiaris">Kompatsiaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint revised; to appear In Proceedings of the IEEE International Conference on Big Data 2023/ 3rd Workshop on Multimodal AI (MMAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16214" title="Abstract">arXiv:2311.16214</a> (replaced) [<a href="/pdf/2311.16214" title="Download PDF">pdf</a>, <a href="/format/2311.16214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGR: Tackling Drifted and Correlated Noise in Quantum Error Correction  via Decoding Graph Re-weighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+P">Pengyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yilian Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Baker%2C+J">Jonathan Baker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17098" title="Abstract">arXiv:2311.17098</a> (replaced) [<a href="/pdf/2311.17098" title="Download PDF">pdf</a>, <a href="/format/2311.17098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyRA: Dynamic Resolution Adjustment for Scale-robust Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+D">Daeun Seo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hoeseok Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungshin Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17117" title="Abstract">arXiv:2311.17117</a> (replaced) [<a href="/pdf/2311.17117" title="Download PDF">pdf</a>, <a href="/format/2311.17117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for  Character Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Li Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Page: <a href="https://humanaigc.github.io/animate-anyone/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17245" title="Abstract">arXiv:2311.17245</a> (replaced) [<a href="/pdf/2311.17245" title="Download PDF">pdf</a>, <a href="/format/2311.17245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and  200+ FPS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kairun Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16pages, 8figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17774" title="Abstract">arXiv:2311.17774</a> (replaced) [<a href="/pdf/2311.17774" title="Download PDF">pdf</a>, <a href="/ps/2311.17774" title="Download PostScript">ps</a>, <a href="/format/2311.17774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration of Minimum Weight Codewords of Pre-Transformed Polar Codes  by Tree Intersection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunker%2C+A">Andreas Zunker</a>, 
<a href="/search/cs?searchtype=author&query=Geiselhart%2C+M">Marvin Geiselhart</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17961" title="Abstract">arXiv:2311.17961</a> (replaced) [<a href="/pdf/2311.17961" title="Download PDF">pdf</a>, <a href="/format/2311.17961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skilful Precipitation Nowcasting Using NowcastNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+A">Ajitabh Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00271" title="Abstract">arXiv:2312.00271</a> (replaced) [<a href="/pdf/2312.00271" title="Download PDF">pdf</a>, <a href="/format/2312.00271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Clinical Prediction with Transparency: An Explainable AI  Approach to Survival Modelling in Residential Aged Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Susnjak%2C+T">Teo Susnjak</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+E">Elise Griffin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00296" title="Abstract">arXiv:2312.00296</a> (replaced) [<a href="/pdf/2312.00296" title="Download PDF">pdf</a>, <a href="/format/2312.00296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Aligned Canonical Correlation Analysis: Preliminary Formulation  and Proof-of-Concept Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Biqian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Papalexakis%2C+E+E">Evangelos E. Papalexakis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jia Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 7 figures, KDD SoCal symposium 2023 (extended version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00481" title="Abstract">arXiv:2312.00481</a> (replaced) [<a href="/pdf/2312.00481" title="Download PDF">pdf</a>, <a href="/format/2312.00481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Glued lattices are better quantizers than $K_{12}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrell%2C+E">Erik Agrell</a>, 
<a href="/search/cs?searchtype=author&query=Pook-Kolb%2C+D">Daniel Pook-Kolb</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+B">Bruce Allen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Mathematical Physics (math-ph); Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00483" title="Abstract">arXiv:2312.00483</a> (replaced) [<a href="/pdf/2312.00483" title="Download PDF">pdf</a>, <a href="/format/2312.00483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MalDicom: A Memory Forensic Framework for Detecting Malicious Payload in  DICOM Files
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Ayushi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Bagade%2C+P">Priyanka Bagade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00844" title="Abstract">arXiv:2312.00844</a> (replaced) [<a href="/pdf/2312.00844" title="Download PDF">pdf</a>, <a href="/format/2312.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Beats Dense: Rethinking Supervision in Radar-Camera Depth  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huadong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">Minhao Jing</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoqiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Renhe Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00858" title="Abstract">arXiv:2312.00858</a> (replaced) [<a href="/pdf/2312.00858" title="Download PDF">pdf</a>, <a href="/format/2312.00858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCache: Accelerating Diffusion Models for Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Gongfan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Project Page: <a href="https://horseee.github.io/Diffusion_DeepCache/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00966" title="Abstract">arXiv:2312.00966</a> (replaced) [<a href="/pdf/2312.00966" title="Download PDF">pdf</a>, <a href="/format/2312.00966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Temporal Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morin%2C+S">Sacha Morin</a>, 
<a href="/search/cs?searchtype=author&query=Nath%2C+S">Somjit Nath</a>, 
<a href="/search/cs?searchtype=author&query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+G">Guy Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Self-Supervised Learning - Theory and Practice, NeurIPS Workshop, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01523" title="Abstract">arXiv:2312.01523</a> (replaced) [<a href="/pdf/2312.01523" title="Download PDF">pdf</a>, <a href="/format/2312.01523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A+K">Abhay Kumar Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Arjun Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02366" title="Abstract">arXiv:2312.02366</a> (replaced) [<a href="/pdf/2312.02366" title="Download PDF">pdf</a>, <a href="/format/2312.02366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General Purpose Vision Foundation Models for Medical Image  Analysis: An Experimental Study of DINOv2 on Radiology Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baharoon%2C+M">Mohammed Baharoon</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+W">Waseem Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jiahong Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Aljouie%2C+A">Abdulrhman Aljouie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02428" title="Abstract">arXiv:2312.02428</a> (replaced) [<a href="/pdf/2312.02428" title="Download PDF">pdf</a>, <a href="/format/2312.02428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreestyleRet: Retrieving Images from Style-Diversified Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Curise Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zesen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kehan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+J">Jialu Sui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02617" title="Abstract">arXiv:2312.02617</a> (replaced) [<a href="/pdf/2312.02617" title="Download PDF">pdf</a>, <a href="/format/2312.02617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreaMo: Articulated 3D Reconstruction From A Single Casual Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+T">Tao Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming-Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C+H">Chieh Hubert Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yen-Chi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ttaoretw.github.io/DreaMo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03032" title="Abstract">arXiv:2312.03032</a> (replaced) [<a href="/pdf/2312.03032" title="Download PDF">pdf</a>, <a href="/format/2312.03032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+G">Guofeng Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03044" title="Abstract">arXiv:2312.03044</a> (replaced) [<a href="/pdf/2312.03044" title="Download PDF">pdf</a>, <a href="/format/2312.03044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REST: Enhancing Group Robustness in DNNs through Reweighted Sparse  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03046" title="Abstract">arXiv:2312.03046</a> (replaced) [<a href="/pdf/2312.03046" title="Download PDF">pdf</a>, <a href="/format/2312.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversified in-domain synthesis with efficient fine-tuning for few-shot  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Costa%2C+V+G+T">Victor G. Turrisi da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Dall%27Asen%2C+N">Nicola Dall&#x27;Asen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03126" title="Abstract">arXiv:2312.03126</a> (replaced) [<a href="/pdf/2312.03126" title="Download PDF">pdf</a>, <a href="/format/2312.03126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Curricula in Open-Ended Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD dissertation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03490" title="Abstract">arXiv:2312.03490</a> (replaced) [<a href="/pdf/2312.03490" title="Download PDF">pdf</a>, <a href="/format/2312.03490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PneumoLLM: Harnessing the Power of Large Language Model for  Pneumoconiosis Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+M">Meiyue Song</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zhihua Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiaxin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiarui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yuting Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Baicun Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaoxu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Q">Qinghua Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhijun Li</a>, 
<a href="/search/eess?searchtype=author&query=Kanellakis%2C+N+I">Nikolaos I.Kanellakis</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiangfeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Binglu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Juntao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03701" title="Abstract">arXiv:2312.03701</a> (replaced) [<a href="/pdf/2312.03701" title="Download PDF">pdf</a>, <a href="/format/2312.03701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-conditioned Image Generation via Generating Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Katabi%2C+D">Dina Katabi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kaiming He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv v2: update related work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03721" title="Abstract">arXiv:2312.03721</a> (replaced) [<a href="/pdf/2312.03721" title="Download PDF">pdf</a>, <a href="/ps/2312.03721" title="Download PostScript">ps</a>, <a href="/format/2312.03721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Robustness of Model-Graded Evaluations and Automated  Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lermen%2C+S">Simon Lermen</a>, 
<a href="/search/cs?searchtype=author&query=Kvapil%2C+O">Ond&#x159;ej Kvapil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03733" title="Abstract">arXiv:2312.03733</a> (replaced) [<a href="/pdf/2312.03733" title="Download PDF">pdf</a>, <a href="/ps/2312.03733" title="Download PostScript">ps</a>, <a href="/format/2312.03733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods to Estimate Large Language Model Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotelanski%2C+M">Maia Kotelanski</a>, 
<a href="/search/cs?searchtype=author&query=Gallo%2C+R">Robert Gallo</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Savage%2C+T">Thomas Savage</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03777" title="Abstract">arXiv:2312.03777</a> (replaced) [<a href="/pdf/2312.03777" title="Download PDF">pdf</a>, <a href="/format/2312.03777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Large Multimodal Models Against Image Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xuanming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Aparcedo%2C+A">Alejandro Aparcedo</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y+K">Young Kyun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03919" title="Abstract">arXiv:2312.03919</a> (replaced) [<a href="/pdf/2312.03919" title="Download PDF">pdf</a>, <a href="/ps/2312.03919" title="Download PostScript">ps</a>, <a href="/format/2312.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indivisibility and uniform computational strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gill%2C+K">Kenneth Gill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures. This work extends the results of Sections 1.2 and 1.3 of the author's Ph.D. thesis at Penn State University. Version 2: minor clarifications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04308" title="Abstract">arXiv:2312.04308</a> (replaced) [<a href="/pdf/2312.04308" title="Download PDF">pdf</a>, <a href="/format/2312.04308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Actor-Critic DDPG for Robot Action Space Decomposition: A  Framework to Control Large 3D Deformation of Soft Linear Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniel%2C+M">M&#xe9;lodie Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Magassouba%2C+A">Aly Magassouba</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Lequi%C3%A8vre%2C+L">Laurent Lequi&#xe8;vre</a>, 
<a href="/search/cs?searchtype=author&query=Ramon%2C+J+A+C">Juan Antonio Corrales Ramon</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+R+I">Roberto Iglesias Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Mezouar%2C+Y">Youcef Mezouar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, 5 tables, Accepted for IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04333" title="Abstract">arXiv:2312.04333</a> (replaced) [<a href="/pdf/2312.04333" title="Download PDF">pdf</a>, <a href="/format/2312.04333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Surface: Probing LLaMA Across Scales and Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shining Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04367" title="Abstract">arXiv:2312.04367</a> (replaced) [<a href="/pdf/2312.04367" title="Download PDF">pdf</a>, <a href="/ps/2312.04367" title="Download PostScript">ps</a>, <a href="/format/2312.04367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paraconsistent Existential Graphs Gamma Peirce System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sierra-Aristizabal%2C+M">Manuel Sierra-Aristizabal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04369" title="Abstract">arXiv:2312.04369</a> (replaced) [<a href="/pdf/2312.04369" title="Download PDF">pdf</a>, <a href="/format/2312.04369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SingingHead: A Large-scale 4D Dataset for Singing Head Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sijing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yucheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://wsj-sjtu.github.io/SingingHead/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04404" title="Abstract">arXiv:2312.04404</a> (replaced) [<a href="/pdf/2312.04404" title="Download PDF">pdf</a>, <a href="/format/2312.04404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of Multi-dimensional Local Differential Privacy on  Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makhlouf%2C+K">Karima Makhlouf</a>, 
<a href="/search/cs?searchtype=author&query=Arcolezi%2C+H+H">Heber H. Arcolezi</a>, 
<a href="/search/cs?searchtype=author&query=Zhioua%2C+S">Sami Zhioua</a>, 
<a href="/search/cs?searchtype=author&query=Brahim%2C+G+B">Ghassen Ben Brahim</a>, 
<a href="/search/cs?searchtype=author&query=Palamidessi%2C+C">Catuscia Palamidessi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04470" title="Abstract">arXiv:2312.04470</a> (replaced) [<a href="/pdf/2312.04470" title="Download PDF">pdf</a>, <a href="/format/2312.04470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaitGuard: Towards Private Gait in Mixed Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+D">Diana Romero</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R+J">Ruchi Jagdish Patel</a>, 
<a href="/search/cs?searchtype=author&query=Markopoulou%2C+A">Athina Markopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Elmalaki%2C+S">Salma Elmalaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04474" title="Abstract">arXiv:2312.04474</a> (replaced) [<a href="/pdf/2312.04474" title="Download PDF">pdf</a>, <a href="/format/2312.04474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Code: Reasoning with a Language Model-Augmented Code Emulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengshu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jacky Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item290">Cross-lists</a></li>
<li><a href="#item324">Replacements</a></li>
</ul>
<small>[ total of 511 entries:  <b>1-511</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
